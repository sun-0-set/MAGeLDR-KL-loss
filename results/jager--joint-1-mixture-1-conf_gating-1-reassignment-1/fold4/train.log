[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.8464 
[epoch 1] step 4/44: loss=6.4736 
[epoch 1] step 6/44: loss=6.3676 
[epoch 1] step 8/44: loss=6.2173 
[epoch 1] step 10/44: loss=6.2482 
[epoch 1] step 12/44: loss=6.2832 
[epoch 1] step 14/44: loss=6.2779 
[epoch 1] step 16/44: loss=6.2723 
[epoch 1] step 18/44: loss=6.2184 
[epoch 1] step 20/44: loss=6.1961 
[epoch 1] step 22/44: loss=6.2169 
[epoch 1] step 24/44: loss=6.2058 
[epoch 1] step 26/44: loss=6.2179 
[epoch 1] step 28/44: loss=6.2258 
[epoch 1] step 30/44: loss=6.2339 
[epoch 1] step 32/44: loss=6.2581 
[epoch 1] step 34/44: loss=6.3008 
[epoch 1] step 36/44: loss=6.3159 
[epoch 1] step 38/44: loss=6.3517 
[epoch 1] step 40/44: loss=6.3936 
[epoch 1] step 42/44: loss=6.4245 
[epoch 1] step 44/44: loss=6.4564 
[epoch 1] train_loss(avg per step)=12.9128 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=7.3452 qwk=('0.1009', '0.0800', '0.0000') averageQWK=0.0603 macroEMD=0.3927 tailR0=('0.0000', '0.5000', '0.0000') tailR0avg=0.1667
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   15    0    0    0
     0   80    0    2    0
     0  151    0    4    0
     0   64    0    9    0
     0    7    0    3    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     9    0    0    0    0
    73    0    2    1    0
   154    0    8    2    0
    66    0    6    8    0
     1    0    1    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    0   92    0    0
     0    1  164    1    0
     0    0   72    0    0
     0    0    1    0    0
[epoch 2] step 2/44: loss=9.9190 
[epoch 2] step 4/44: loss=9.7996 
[epoch 2] step 6/44: loss=9.8625 
[epoch 2] step 8/44: loss=9.8999 
[epoch 2] step 10/44: loss=9.9231 
[epoch 2] step 12/44: loss=10.0637 
[epoch 2] step 14/44: loss=10.1572 
[epoch 2] step 16/44: loss=10.2369 
[epoch 2] step 18/44: loss=10.3594 
[epoch 2] step 20/44: loss=10.4224 
[epoch 2] step 22/44: loss=10.5351 
[epoch 2] step 24/44: loss=10.5822 
[epoch 2] step 26/44: loss=10.6726 
[epoch 2] step 28/44: loss=10.7658 
[epoch 2] step 30/44: loss=10.9169 
[epoch 2] step 32/44: loss=11.0191 
[epoch 2] step 34/44: loss=11.0919 
[epoch 2] step 36/44: loss=11.2176 
[epoch 2] step 38/44: loss=11.2991 
[epoch 2] step 40/44: loss=11.3966 
[epoch 2] step 42/44: loss=11.5218 
[epoch 2] step 44/44: loss=11.5906 
[epoch 2] train_loss(avg per step)=23.1812 lambda[min,max]=[0.501047,1.000000]
[epoch 2] val_loss=13.3127 qwk=('0.1525', '0.1604', '0.0618') averageQWK=0.1249 macroEMD=0.3924 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0   11    0
     0   22    0   59    1
     0   10    0  145    0
     0    2    0   70    1
     0    1    0    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    4    0
     0    0   30   46    0
     0    0   25  139    0
     0    0    0   80    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    3    0
     0    3   11   78    0
     0    0   10  156    0
     0    0    0   72    0
     0    0    0    1    0
[epoch 3] step 2/44: loss=12.9402 
[epoch 3] step 4/44: loss=12.6007 
[epoch 3] step 6/44: loss=12.7311 
[epoch 3] step 8/44: loss=12.5079 
[epoch 3] step 10/44: loss=12.4214 
[epoch 3] step 12/44: loss=12.7039 
[epoch 3] step 14/44: loss=12.7922 
[epoch 3] step 16/44: loss=12.8540 
[epoch 3] step 18/44: loss=12.8467 
[epoch 3] step 20/44: loss=12.8177 
[epoch 3] step 22/44: loss=12.8550 
[epoch 3] step 24/44: loss=12.8168 
[epoch 3] step 26/44: loss=12.7515 
[epoch 3] step 28/44: loss=12.8116 
[epoch 3] step 30/44: loss=12.8183 
[epoch 3] step 32/44: loss=12.8174 
[epoch 3] step 34/44: loss=12.8234 
[epoch 3] step 36/44: loss=12.8529 
[epoch 3] step 38/44: loss=12.8490 
[epoch 3] step 40/44: loss=12.8816 
[epoch 3] step 42/44: loss=12.7903 
[epoch 3] step 44/44: loss=12.6342 
[epoch 3] train_loss(avg per step)=25.2684 lambda[min,max]=[0.523011,1.000000]
[epoch 3] val_loss=15.1114 qwk=('0.2450', '0.0623', '0.1057') averageQWK=0.1376 macroEMD=0.3866 tailR0=('0.0500', '0.0000', '0.1250') tailR0avg=0.0583
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   14    1    0
     0    0   79    0    3
     0    0  128   26    1
     0    0   33   39    1
     0    0    8    1    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    6    0
     0    1    7   68    0
     0    0    3  161    0
     0    0    0   80    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    1    0
     3    1   14   73    1
     1    0   19  144    2
     0    0    1   71    0
     0    0    0    1    0
[epoch 4] step 2/44: loss=12.9479 
[epoch 4] step 4/44: loss=12.9484 
[epoch 4] step 6/44: loss=12.7558 
[epoch 4] step 8/44: loss=12.5834 
[epoch 4] step 10/44: loss=12.2022 
[epoch 4] step 12/44: loss=11.9079 
[epoch 4] step 14/44: loss=11.9713 
[epoch 4] step 16/44: loss=12.1440 
[epoch 4] step 18/44: loss=12.1794 
[epoch 4] step 20/44: loss=12.0816 
[epoch 4] step 22/44: loss=12.1081 
[epoch 4] step 24/44: loss=12.0351 
[epoch 4] step 26/44: loss=11.9315 
[epoch 4] step 28/44: loss=11.8321 
[epoch 4] step 30/44: loss=11.8851 
[epoch 4] step 32/44: loss=11.8946 
[epoch 4] step 34/44: loss=11.9212 
[epoch 4] step 36/44: loss=11.8403 
[epoch 4] step 38/44: loss=11.8120 
[epoch 4] step 40/44: loss=11.7320 
[epoch 4] step 42/44: loss=11.6463 
[epoch 4] step 44/44: loss=11.6799 
[epoch 4] train_loss(avg per step)=23.3599 lambda[min,max]=[0.506022,1.000000]
[epoch 4] val_loss=13.4292 qwk=('0.2376', '0.0143', '0.2122') averageQWK=0.1547 macroEMD=0.3886 tailR0=('0.1000', '0.0000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    1    9    0
    13    5   12   52    0
     4    0   17  134    0
     1    0    1   71    0
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    9    0
     0    2    0   74    0
     0    0    0  164    0
     0    0    0   80    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    3   51   38    0
     0    1   70   95    0
     0    0   10   62    0
     0    0    0    1    0
[epoch 5] step 2/44: loss=10.5460 
[epoch 5] step 4/44: loss=10.4228 
[epoch 5] step 6/44: loss=10.2890 
[epoch 5] step 8/44: loss=10.3210 
[epoch 5] step 10/44: loss=10.3484 
[epoch 5] step 12/44: loss=10.4508 
[epoch 5] step 14/44: loss=10.4939 
[epoch 5] step 16/44: loss=10.4506 
[epoch 5] step 18/44: loss=10.2664 
[epoch 5] step 20/44: loss=10.1402 
[epoch 5] step 22/44: loss=10.1551 
[epoch 5] step 24/44: loss=10.2817 
[epoch 5] step 26/44: loss=10.2798 
[epoch 5] step 28/44: loss=10.1798 
[epoch 5] step 30/44: loss=10.1834 
[epoch 5] step 32/44: loss=10.1008 
[epoch 5] step 34/44: loss=10.0373 
[epoch 5] step 36/44: loss=9.9807 
[epoch 5] step 38/44: loss=9.9870 
[epoch 5] step 40/44: loss=10.0167 
[epoch 5] step 42/44: loss=9.9721 
[epoch 5] step 44/44: loss=9.9205 
[epoch 5] train_loss(avg per step)=19.8410 lambda[min,max]=[0.556496,1.000000]
[epoch 5] val_loss=11.7362 qwk=('0.1878', '0.2824', '0.0614') averageQWK=0.1772 macroEMD=0.3835 tailR0=('0.0333', '0.0000', '0.0000') tailR0avg=0.0111
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    6    7    0
     2    3   26   50    1
     0    0   26  125    4
     0    0    0   73    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    3    0
     0    7   38   31    0
     0    2   48  114    0
     0    0    0   80    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    2    2    0
     0    2   11   79    0
     0    0   15  151    0
     0    0    0   72    0
     0    0    0    1    0
[epoch 6] step 2/44: loss=8.2909 
[epoch 6] step 4/44: loss=9.3594 
[epoch 6] step 6/44: loss=9.8507 
[epoch 6] step 8/44: loss=9.8825 
[epoch 6] step 10/44: loss=9.6997 
[epoch 6] step 12/44: loss=9.4968 
[epoch 6] step 14/44: loss=9.5037 
[epoch 6] step 16/44: loss=9.5754 
[epoch 6] step 18/44: loss=9.5272 
[epoch 6] step 20/44: loss=9.3661 
[epoch 6] step 22/44: loss=9.3112 
[epoch 6] step 24/44: loss=9.3169 
[epoch 6] step 26/44: loss=9.3424 
[epoch 6] step 28/44: loss=9.3031 
[epoch 6] step 30/44: loss=9.3089 
[epoch 6] step 32/44: loss=9.2705 
[epoch 6] step 34/44: loss=9.2749 
[epoch 6] step 36/44: loss=9.1933 
[epoch 6] step 38/44: loss=9.0842 
[epoch 6] step 40/44: loss=9.0111 
[epoch 6] step 42/44: loss=9.0289 
[epoch 6] step 44/44: loss=9.1335 
[epoch 6] train_loss(avg per step)=18.2670 lambda[min,max]=[0.500024,1.000000]
[epoch 6] val_loss=10.8052 qwk=('0.4560', '0.1287', '0.2848') averageQWK=0.2898 macroEMD=0.3773 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   11    2    2    0
     0   50    8   23    1
     0   47   25   83    0
     0    2    4   67    0
     0    1    0    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    5    0
     0    0   25   51    0
     0    0   17  147    0
     0    0    0   80    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    1   66   25    0
     0    0  108   58    0
     0    0   11   61    0
     0    0    0    1    0
[epoch 7] step 2/44: loss=9.9941 
[epoch 7] step 4/44: loss=9.2888 
[epoch 7] step 6/44: loss=8.8985 
[epoch 7] step 8/44: loss=9.0256 
[epoch 7] step 10/44: loss=9.0027 
[epoch 7] step 12/44: loss=8.9930 
[epoch 7] step 14/44: loss=8.8272 
[epoch 7] step 16/44: loss=8.7360 
[epoch 7] step 18/44: loss=8.5996 
[epoch 7] step 20/44: loss=8.5833 
[epoch 7] step 22/44: loss=8.6009 
[epoch 7] step 24/44: loss=8.6789 
[epoch 7] step 26/44: loss=8.7653 
[epoch 7] step 28/44: loss=8.7037 
[epoch 7] step 30/44: loss=8.6358 
[epoch 7] step 32/44: loss=8.5649 
[epoch 7] step 34/44: loss=8.5942 
[epoch 7] step 36/44: loss=8.5864 
[epoch 7] step 38/44: loss=8.5972 
[epoch 7] step 40/44: loss=8.6451 
[epoch 7] step 42/44: loss=8.7235 
[epoch 7] step 44/44: loss=8.7207 
[epoch 7] train_loss(avg per step)=17.4414 lambda[min,max]=[0.500010,1.000000]
[epoch 7] val_loss=10.6607 qwk=('0.1897', '0.2300', '0.2916') averageQWK=0.2371 macroEMD=0.3797 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    7    0
     0    1   38   43    0
     0    0   29  126    0
     0    0    0   73    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    4    0
     0    0   45   31    0
     0    0   46  118    0
     0    0    2   78    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    0   75   17    0
     0    0  124   42    0
     0    0   20   52    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=8.1597 
[epoch 8] step 4/44: loss=7.5638 
[epoch 8] step 6/44: loss=7.5141 
[epoch 8] step 8/44: loss=7.5380 
[epoch 8] step 10/44: loss=7.7744 
[epoch 8] step 12/44: loss=7.8139 
[epoch 8] step 14/44: loss=7.7782 
[epoch 8] step 16/44: loss=7.8702 
[epoch 8] step 18/44: loss=8.0135 
[epoch 8] step 20/44: loss=8.0313 
[epoch 8] step 22/44: loss=7.9770 
[epoch 8] step 24/44: loss=8.0025 
[epoch 8] step 26/44: loss=8.0892 
[epoch 8] step 28/44: loss=8.1336 
[epoch 8] step 30/44: loss=8.0830 
[epoch 8] step 32/44: loss=8.0476 
[epoch 8] step 34/44: loss=8.0356 
[epoch 8] step 36/44: loss=7.9722 
[epoch 8] step 38/44: loss=8.0163 
[epoch 8] step 40/44: loss=8.0490 
[epoch 8] step 42/44: loss=8.0512 
[epoch 8] step 44/44: loss=7.9067 
[epoch 8] train_loss(avg per step)=15.8134 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=9.6292 qwk=('0.3795', '0.4469', '0.3818') averageQWK=0.4027 macroEMD=0.3730 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   14    1    0
     0    1   79    2    0
     0    0  113   42    0
     0    0   19   54    0
     0    0    3    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    6   62    8    0
     0    2  105   57    0
     0    0    8   72    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   33   31   28    0
     0   27   58   81    0
     0    3    5   64    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=8.8449 
[epoch 9] step 4/44: loss=8.6495 
[epoch 9] step 6/44: loss=8.4805 
[epoch 9] step 8/44: loss=8.2341 
[epoch 9] step 10/44: loss=8.1255 
[epoch 9] step 12/44: loss=8.0540 
[epoch 9] step 14/44: loss=8.0633 
[epoch 9] step 16/44: loss=8.1490 
[epoch 9] step 18/44: loss=8.2203 
[epoch 9] step 20/44: loss=8.2536 
[epoch 9] step 22/44: loss=8.1859 
[epoch 9] step 24/44: loss=8.0977 
[epoch 9] step 26/44: loss=8.0938 
[epoch 9] step 28/44: loss=8.0675 
[epoch 9] step 30/44: loss=8.1075 
[epoch 9] step 32/44: loss=8.1159 
[epoch 9] step 34/44: loss=8.2076 
[epoch 9] step 36/44: loss=8.2297 
[epoch 9] step 38/44: loss=8.1815 
[epoch 9] step 40/44: loss=8.1023 
[epoch 9] step 42/44: loss=8.0319 
[epoch 9] step 44/44: loss=7.9769 
[epoch 9] train_loss(avg per step)=15.9538 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=10.0287 qwk=('0.3133', '0.1933', '0.2329') averageQWK=0.2465 macroEMD=0.3747 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    2    0
     0    1   64   17    0
     0    0   75   78    2
     0    0    9   62    2
     0    0    2    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    4    0
     0    5   28   43    0
     0    0   29  135    0
     0    0    0   80    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    2   89    1    0
     0    1  152   13    0
     0    0   51   21    0
     0    0    0    1    0
[epoch 10] step 2/44: loss=9.1536 
[epoch 10] step 4/44: loss=9.1083 
[epoch 10] step 6/44: loss=8.7642 
[epoch 10] step 8/44: loss=8.5854 
[epoch 10] step 10/44: loss=8.5199 
[epoch 10] step 12/44: loss=8.2966 
[epoch 10] step 14/44: loss=8.1796 
[epoch 10] step 16/44: loss=8.1200 
[epoch 10] step 18/44: loss=8.0013 
[epoch 10] step 20/44: loss=8.1439 
[epoch 10] step 22/44: loss=8.2457 
[epoch 10] step 24/44: loss=8.3089 
[epoch 10] step 26/44: loss=8.2781 
[epoch 10] step 28/44: loss=8.2779 
[epoch 10] step 30/44: loss=8.2418 
[epoch 10] step 32/44: loss=8.2346 
[epoch 10] step 34/44: loss=8.1801 
[epoch 10] step 36/44: loss=8.1358 
[epoch 10] step 38/44: loss=8.1655 
[epoch 10] step 40/44: loss=8.1792 
[epoch 10] step 42/44: loss=8.1678 
[epoch 10] step 44/44: loss=8.0987 
[epoch 10] train_loss(avg per step)=16.1975 lambda[min,max]=[0.565194,1.000000]
[epoch 10] val_loss=10.5416 qwk=('0.2543', '0.3054', '0.2252') averageQWK=0.2616 macroEMD=0.3709 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    5    0
     0    5   40   37    0
     0   10   38  107    0
     0    0    0   73    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    1   52   23    0
     0    0   71   93    0
     0    0    3   77    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    1    0
     0    9   37   46    0
     0   14   42  110    0
     0    0    2   70    0
     0    0    0    1    0
[epoch 11] step 2/44: loss=8.9963 
[epoch 11] step 4/44: loss=8.6056 
[epoch 11] step 6/44: loss=8.2315 
[epoch 11] step 8/44: loss=7.9739 
[epoch 11] step 10/44: loss=7.9541 
[epoch 11] step 12/44: loss=7.9272 
[epoch 11] step 14/44: loss=7.8937 
[epoch 11] step 16/44: loss=7.7605 
[epoch 11] step 18/44: loss=7.5618 
[epoch 11] step 20/44: loss=7.5890 
[epoch 11] step 22/44: loss=7.6931 
[epoch 11] step 24/44: loss=7.7242 
[epoch 11] step 26/44: loss=7.7592 
[epoch 11] step 28/44: loss=7.6960 
[epoch 11] step 30/44: loss=7.6500 
[epoch 11] step 32/44: loss=7.6913 
[epoch 11] step 34/44: loss=7.7346 
[epoch 11] step 36/44: loss=7.7516 
[epoch 11] step 38/44: loss=7.7514 
[epoch 11] step 40/44: loss=7.7435 
[epoch 11] step 42/44: loss=7.6796 
[epoch 11] step 44/44: loss=7.7539 
[epoch 11] train_loss(avg per step)=15.5079 lambda[min,max]=[0.574476,1.000000]
[epoch 11] val_loss=9.3825 qwk=('0.2474', '0.4190', '0.3458') averageQWK=0.3374 macroEMD=0.3734 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   14    1    0
     0    1   81    0    0
     0    0  140   15    0
     0    0   41   28    4
     0    0    9    1    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   21   37   18    0
     0   23   54   87    0
     0    1    5   74    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    4   79    9    0
     0    2  132   32    0
     0    0   27   45    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=6.7863 
[epoch 12] step 4/44: loss=7.1777 
[epoch 12] step 6/44: loss=7.5383 
[epoch 12] step 8/44: loss=7.4988 
[epoch 12] step 10/44: loss=7.7261 
[epoch 12] step 12/44: loss=7.6703 
[epoch 12] step 14/44: loss=7.8502 
[epoch 12] step 16/44: loss=7.9598 
[epoch 12] step 18/44: loss=7.9882 
[epoch 12] step 20/44: loss=8.0052 
[epoch 12] step 22/44: loss=8.0636 
[epoch 12] step 24/44: loss=8.0240 
[epoch 12] step 26/44: loss=8.0171 
[epoch 12] step 28/44: loss=7.9010 
[epoch 12] step 30/44: loss=7.8362 
[epoch 12] step 32/44: loss=7.8136 
[epoch 12] step 34/44: loss=7.8463 
[epoch 12] step 36/44: loss=7.9174 
[epoch 12] step 38/44: loss=7.9401 
[epoch 12] step 40/44: loss=7.9386 
[epoch 12] step 42/44: loss=7.9077 
[epoch 12] step 44/44: loss=7.8105 
[epoch 12] train_loss(avg per step)=15.6209 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=10.4994 qwk=('0.2711', '0.1585', '0.1939') averageQWK=0.2078 macroEMD=0.3723 tailR0=('0.0333', '0.0000', '0.0000') tailR0avg=0.0111
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0   11    3    0
     0    1   47   34    0
     0    0   54  101    0
     0    0    2   71    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    3    6    0
     1    0   31   44    0
     0    0   23  141    0
     0    0    0   80    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    5   34   53    0
     0    6   49  111    0
     0    0    2   70    0
     0    0    0    1    0
[epoch 13] step 2/44: loss=8.3772 
[epoch 13] step 4/44: loss=9.1726 
[epoch 13] step 6/44: loss=8.9092 
[epoch 13] step 8/44: loss=8.6747 
[epoch 13] step 10/44: loss=8.5579 
[epoch 13] step 12/44: loss=8.4429 
[epoch 13] step 14/44: loss=8.2368 
[epoch 13] step 16/44: loss=8.1356 
[epoch 13] step 18/44: loss=8.0316 
[epoch 13] step 20/44: loss=7.9514 
[epoch 13] step 22/44: loss=7.9016 
[epoch 13] step 24/44: loss=7.8339 
[epoch 13] step 26/44: loss=7.9253 
[epoch 13] step 28/44: loss=7.9743 
[epoch 13] step 30/44: loss=8.0463 
[epoch 13] step 32/44: loss=8.0455 
[epoch 13] step 34/44: loss=8.0000 
[epoch 13] step 36/44: loss=7.9426 
[epoch 13] step 38/44: loss=7.8972 
[epoch 13] step 40/44: loss=7.8324 
[epoch 13] step 42/44: loss=7.8379 
[epoch 13] step 44/44: loss=7.9184 
[epoch 13] train_loss(avg per step)=15.8368 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=9.7459 qwk=('0.4108', '0.5152', '0.3764') averageQWK=0.4341 macroEMD=0.3739 tailR0=('0.0333', '0.0556', '0.0000') tailR0avg=0.0296
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2   11    1    0
     1   13   60    8    0
     0    9   98   48    0
     0    0   20   53    0
     0    0    3    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     4   21   41   10    0
     1   25   94   44    0
     0    1   11   68    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    7   77    8    0
     0    3  140   23    0
     0    0   27   45    0
     0    0    0    1    0
[epoch 14] step 2/44: loss=7.4733 
[epoch 14] step 4/44: loss=7.5067 
[epoch 14] step 6/44: loss=7.6464 
[epoch 14] step 8/44: loss=7.5980 
[epoch 14] step 10/44: loss=7.6546 
[epoch 14] step 12/44: loss=7.6647 
[epoch 14] step 14/44: loss=7.6767 
[epoch 14] step 16/44: loss=7.6662 
[epoch 14] step 18/44: loss=7.6873 
[epoch 14] step 20/44: loss=7.8187 
[epoch 14] step 22/44: loss=7.8792 
[epoch 14] step 24/44: loss=7.9008 
[epoch 14] step 26/44: loss=7.8199 
[epoch 14] step 28/44: loss=7.8116 
[epoch 14] step 30/44: loss=7.8503 
[epoch 14] step 32/44: loss=7.8625 
[epoch 14] step 34/44: loss=7.8221 
[epoch 14] step 36/44: loss=7.7931 
[epoch 14] step 38/44: loss=7.7080 
[epoch 14] step 40/44: loss=7.6625 
[epoch 14] step 42/44: loss=7.6689 
[epoch 14] step 44/44: loss=7.6944 
[epoch 14] train_loss(avg per step)=15.3888 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=9.8885 qwk=('0.2997', '0.3608', '0.3284') averageQWK=0.3297 macroEMD=0.3698 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    2    0
     0    1   59   22    0
     0    0   67   88    0
     0    0    7   66    0
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    1   62   13    0
     0    0  100   64    0
     0    0   12   68    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    3   70   19    0
     0    0  111   55    0
     0    0   12   60    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=10.0707 
[epoch 15] step 4/44: loss=9.3399 
[epoch 15] step 6/44: loss=8.6580 
[epoch 15] step 8/44: loss=7.9848 
[epoch 15] step 10/44: loss=7.6675 
[epoch 15] step 12/44: loss=7.6382 
[epoch 15] step 14/44: loss=7.7325 
[epoch 15] step 16/44: loss=7.8537 
[epoch 15] step 18/44: loss=7.8767 
[epoch 15] step 20/44: loss=7.8458 
[epoch 15] step 22/44: loss=7.7729 
[epoch 15] step 24/44: loss=7.7328 
[epoch 15] step 26/44: loss=7.8982 
[epoch 15] step 28/44: loss=7.9127 
[epoch 15] step 30/44: loss=7.9519 
[epoch 15] step 32/44: loss=7.9386 
[epoch 15] step 34/44: loss=7.8513 
[epoch 15] step 36/44: loss=7.8114 
[epoch 15] step 38/44: loss=7.8161 
[epoch 15] step 40/44: loss=7.8280 
[epoch 15] step 42/44: loss=7.8700 
[epoch 15] step 44/44: loss=7.9091 
[epoch 15] train_loss(avg per step)=15.8183 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=10.0721 qwk=('0.3591', '0.4070', '0.3047') averageQWK=0.3569 macroEMD=0.3720 tailR0=('0.1000', '0.0000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   12    1    0
     0    9   58   14    1
     0    3   91   61    0
     0    0   16   56    1
     0    0    3    5    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     1   18   38   19    0
     0   12   74   78    0
     0    1    6   73    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    6   68   18    0
     0    2  119   45    0
     0    0   23   49    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=7.7708 
[epoch 16] step 4/44: loss=7.6378 
[epoch 16] step 6/44: loss=7.5622 
[epoch 16] step 8/44: loss=7.4210 
[epoch 16] step 10/44: loss=7.6453 
[epoch 16] step 12/44: loss=7.8478 
[epoch 16] step 14/44: loss=7.9085 
[epoch 16] step 16/44: loss=7.9013 
[epoch 16] step 18/44: loss=7.7793 
[epoch 16] step 20/44: loss=7.7079 
[epoch 16] step 22/44: loss=7.6470 
[epoch 16] step 24/44: loss=7.6247 
[epoch 16] step 26/44: loss=7.6392 
[epoch 16] step 28/44: loss=7.6702 
[epoch 16] step 30/44: loss=7.7111 
[epoch 16] step 32/44: loss=7.7665 
[epoch 16] step 34/44: loss=7.7850 
[epoch 16] step 36/44: loss=7.8099 
[epoch 16] step 38/44: loss=7.8062 
[epoch 16] step 40/44: loss=7.7890 
[epoch 16] step 42/44: loss=7.7742 
[epoch 16] step 44/44: loss=7.7422 
[epoch 16] train_loss(avg per step)=15.4844 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=10.2109 qwk=('0.4140', '0.4350', '0.3276') averageQWK=0.3922 macroEMD=0.3744 tailR0=('0.0333', '0.0556', '0.0000') tailR0avg=0.0296
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    5    2    0
     0   33   27   22    0
     0   25   51   79    0
     0    0   11   62    0
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    5    1    0
     2   16   39   19    0
     0   12   73   79    0
     0    0    4   76    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    7   68   17    0
     0    4  121   41    0
     0    0   23   49    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=6.8486 
[epoch 17] step 4/44: loss=7.2916 
[epoch 17] step 6/44: loss=7.4335 
[epoch 17] step 8/44: loss=7.5372 
[epoch 17] step 10/44: loss=7.6808 
[epoch 17] step 12/44: loss=7.6553 
[epoch 17] step 14/44: loss=7.6883 
[epoch 17] step 16/44: loss=7.5926 
[epoch 17] step 18/44: loss=7.6523 
[epoch 17] step 20/44: loss=7.6574 
[epoch 17] step 22/44: loss=7.7107 
[epoch 17] step 24/44: loss=7.7225 
[epoch 17] step 26/44: loss=7.7637 
[epoch 17] step 28/44: loss=7.7839 
[epoch 17] step 30/44: loss=7.8519 
[epoch 17] step 32/44: loss=7.8410 
[epoch 17] step 34/44: loss=7.8627 
[epoch 17] step 36/44: loss=7.8576 
[epoch 17] step 38/44: loss=7.8388 
[epoch 17] step 40/44: loss=7.8035 
[epoch 17] step 42/44: loss=7.7914 
[epoch 17] step 44/44: loss=7.8263 
[epoch 17] train_loss(avg per step)=15.6526 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=10.3028 qwk=('0.2653', '0.3573', '0.3005') averageQWK=0.3077 macroEMD=0.3723 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   14    1    0
     0    1   67   14    0
     0    0   93   62    0
     0    0   24   49    0
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    5   57   14    0
     0    1   90   73    0
     0    0   11   69    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    2   75   15    0
     0    1  119   46    0
     0    0   22   50    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=8.6838 
[epoch 18] step 4/44: loss=8.3921 
[epoch 18] step 6/44: loss=8.1689 
[epoch 18] step 8/44: loss=8.0051 
[epoch 18] step 10/44: loss=7.7743 
[epoch 18] step 12/44: loss=7.6426 
[epoch 18] step 14/44: loss=7.6526 
[epoch 18] step 16/44: loss=7.8237 
[epoch 18] step 18/44: loss=7.9423 
[epoch 18] step 20/44: loss=8.0058 
[epoch 18] step 22/44: loss=8.0028 
[epoch 18] step 24/44: loss=7.9654 
[epoch 18] step 26/44: loss=7.9317 
[epoch 18] step 28/44: loss=7.8766 
[epoch 18] step 30/44: loss=7.8960 
[epoch 18] step 32/44: loss=7.9060 
[epoch 18] step 34/44: loss=7.8634 
[epoch 18] step 36/44: loss=7.8436 
[epoch 18] step 38/44: loss=7.7827 
[epoch 18] step 40/44: loss=7.7726 
[epoch 18] step 42/44: loss=7.7963 
[epoch 18] step 44/44: loss=7.8499 
[epoch 18] train_loss(avg per step)=15.6999 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=10.6427 qwk=('0.3509', '0.3249', '0.2710') averageQWK=0.3156 macroEMD=0.3715 tailR0=('0.1500', '0.0000', '0.0000') tailR0avg=0.0500
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   11    2    0
     0    7   57   17    1
     0    1   71   78    5
     0    0   11   52   10
     0    0    3    4    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    7   45   24    0
     0    1   62  101    0
     0    0    1   79    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    2   62   28    0
     0    1   86   79    0
     0    0    9   63    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=8.2815 
[epoch 19] step 4/44: loss=8.5184 
[epoch 19] step 6/44: loss=8.4838 
[epoch 19] step 8/44: loss=8.4343 
[epoch 19] step 10/44: loss=8.1570 
[epoch 19] step 12/44: loss=7.9130 
[epoch 19] step 14/44: loss=7.8674 
[epoch 19] step 16/44: loss=7.8402 
[epoch 19] step 18/44: loss=7.7644 
[epoch 19] step 20/44: loss=7.7690 
[epoch 19] step 22/44: loss=7.7780 
[epoch 19] step 24/44: loss=7.7862 
[epoch 19] step 26/44: loss=7.8239 
[epoch 19] step 28/44: loss=7.8643 
[epoch 19] step 30/44: loss=7.8129 
[epoch 19] step 32/44: loss=7.7532 
[epoch 19] step 34/44: loss=7.7259 
[epoch 19] step 36/44: loss=7.6915 
[epoch 19] step 38/44: loss=7.7247 
[epoch 19] step 40/44: loss=7.7394 
[epoch 19] step 42/44: loss=7.7889 
[epoch 19] step 44/44: loss=7.7621 
[epoch 19] train_loss(avg per step)=15.5242 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=10.3153 qwk=('0.3324', '0.3716', '0.3090') averageQWK=0.3376 macroEMD=0.3703 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    9    2    0
     0   13   43   26    0
     0    2   69   84    0
     0    0    6   67    0
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    9   47   20    0
     0    4   84   76    0
     0    0    6   74    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   10   64   18    0
     0    8  116   42    0
     0    2   22   48    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=8.9859 
[epoch 20] step 4/44: loss=8.9400 
[epoch 20] step 6/44: loss=8.7259 
[epoch 20] step 8/44: loss=8.4709 
[epoch 20] step 10/44: loss=8.1209 
[epoch 20] step 12/44: loss=7.9449 
[epoch 20] step 14/44: loss=7.8772 
[epoch 20] step 16/44: loss=7.7971 
[epoch 20] step 18/44: loss=7.8080 
[epoch 20] step 20/44: loss=7.8913 
[epoch 20] step 22/44: loss=7.8941 
[epoch 20] step 24/44: loss=7.8582 
[epoch 20] step 26/44: loss=7.8714 
[epoch 20] step 28/44: loss=7.9311 
[epoch 20] step 30/44: loss=8.0028 
[epoch 20] step 32/44: loss=8.0861 
[epoch 20] step 34/44: loss=8.0706 
[epoch 20] step 36/44: loss=7.9874 
[epoch 20] step 38/44: loss=7.9202 
[epoch 20] step 40/44: loss=7.8540 
[epoch 20] step 42/44: loss=7.8369 
[epoch 20] step 44/44: loss=7.8628 
[epoch 20] train_loss(avg per step)=15.7256 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=10.4642 qwk=('0.3541', '0.3842', '0.3959') averageQWK=0.3781 macroEMD=0.3711 tailR0=('0.0333', '0.0000', '0.0000') tailR0avg=0.0111
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    8    2    0
     1   12   49   20    0
     0    2   74   79    0
     0    0   13   60    0
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     1    8   51   16    0
     0    2   97   65    0
     0    0   10   70    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   27   47   18    0
     0   26   88   52    0
     0    3   15   54    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=7.9330 
[epoch 21] step 4/44: loss=8.5442 
[epoch 21] step 6/44: loss=8.2747 
[epoch 21] step 8/44: loss=8.0616 
[epoch 21] step 10/44: loss=7.9888 
[epoch 21] step 12/44: loss=7.8746 
[epoch 21] step 14/44: loss=7.8943 
[epoch 21] step 16/44: loss=7.8118 
[epoch 21] step 18/44: loss=7.7567 
[epoch 21] step 20/44: loss=7.7453 
[epoch 21] step 22/44: loss=7.7336 
[epoch 21] step 24/44: loss=7.8485 
[epoch 21] step 26/44: loss=7.9043 
[epoch 21] step 28/44: loss=7.8884 
[epoch 21] step 30/44: loss=7.9443 
[epoch 21] step 32/44: loss=7.9881 
[epoch 21] step 34/44: loss=7.9794 
[epoch 21] step 36/44: loss=7.9713 
[epoch 21] step 38/44: loss=7.9186 
[epoch 21] step 40/44: loss=7.8747 
[epoch 21] step 42/44: loss=7.8731 
[epoch 21] step 44/44: loss=7.8771 
[epoch 21] train_loss(avg per step)=15.7541 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=10.5083 qwk=('0.3966', '0.4198', '0.3296') averageQWK=0.3820 macroEMD=0.3745 tailR0=('0.1333', '0.0000', '0.0000') tailR0avg=0.0444
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    7    2    0
     2   17   41   21    1
     0    6   64   85    0
     0    0    9   62    2
     0    0    3    5    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   16   44   16    0
     0    7   78   79    0
     0    0    5   75    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   11   58   23    0
     0    4  111   51    0
     0    1   15   56    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=7.0556 
[epoch 22] step 4/44: loss=7.1797 
[epoch 22] step 6/44: loss=7.4433 
[epoch 22] step 8/44: loss=7.6792 
[epoch 22] step 10/44: loss=7.7736 
[epoch 22] step 12/44: loss=7.8809 
[epoch 22] step 14/44: loss=7.8876 
[epoch 22] step 16/44: loss=7.9965 
[epoch 22] step 18/44: loss=8.0057 
[epoch 22] step 20/44: loss=7.9783 
[epoch 22] step 22/44: loss=7.9106 
[epoch 22] step 24/44: loss=7.8616 
[epoch 22] step 26/44: loss=7.8484 
[epoch 22] step 28/44: loss=7.9001 
[epoch 22] step 30/44: loss=7.9418 
[epoch 22] step 32/44: loss=7.9307 
[epoch 22] step 34/44: loss=7.9246 
[epoch 22] step 36/44: loss=7.9062 
[epoch 22] step 38/44: loss=7.8766 
[epoch 22] step 40/44: loss=7.8642 
[epoch 22] step 42/44: loss=7.8448 
[epoch 22] step 44/44: loss=7.8272 
[epoch 22] train_loss(avg per step)=15.6544 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=10.4284 qwk=('0.3121', '0.3743', '0.3100') averageQWK=0.3321 macroEMD=0.3749 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0   13    1    0
     0    2   70    9    1
     0    0  107   47    1
     0    0   25   44    4
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    4   58   14    0
     0    1   98   65    0
     0    0   10   70    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    6   77    9    0
     0    2  136   28    0
     0    0   35   37    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=8.0275 
[epoch 23] step 4/44: loss=8.1680 
[epoch 23] step 6/44: loss=7.9431 
[epoch 23] step 8/44: loss=7.8196 
[epoch 23] step 10/44: loss=7.7410 
[epoch 23] step 12/44: loss=7.6267 
[epoch 23] step 14/44: loss=7.5924 
[epoch 23] step 16/44: loss=7.6848 
[epoch 23] step 18/44: loss=7.8026 
[epoch 23] step 20/44: loss=7.8566 
[epoch 23] step 22/44: loss=7.9114 
[epoch 23] step 24/44: loss=8.0148 
[epoch 23] step 26/44: loss=7.9456 
[epoch 23] step 28/44: loss=7.8806 
[epoch 23] step 30/44: loss=7.8417 
[epoch 23] step 32/44: loss=7.8072 
[epoch 23] step 34/44: loss=7.7957 
[epoch 23] step 36/44: loss=7.7782 
[epoch 23] step 38/44: loss=7.8072 
[epoch 23] step 40/44: loss=7.8373 
[epoch 23] step 42/44: loss=7.8861 
[epoch 23] step 44/44: loss=7.9046 
[epoch 23] train_loss(avg per step)=15.8092 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=10.5455 qwk=('0.4205', '0.4147', '0.3386') averageQWK=0.3913 macroEMD=0.3719 tailR0=('0.1333', '0.0000', '0.0000') tailR0avg=0.0444
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    8    1    0
     2   22   45   12    1
     0   13   79   61    2
     0    0   21   45    7
     0    0    5    3    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   11   52   13    0
     0    8   95   61    0
     0    0    8   72    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   24   53   15    0
     0   33  101   32    0
     0    4   25   43    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=8.2548 
[epoch 24] step 4/44: loss=8.2345 
[epoch 24] step 6/44: loss=7.9946 
[epoch 24] step 8/44: loss=7.7984 
[epoch 24] step 10/44: loss=7.7450 
[epoch 24] step 12/44: loss=7.7233 
[epoch 24] step 14/44: loss=7.7257 
[epoch 24] step 16/44: loss=7.7286 
[epoch 24] step 18/44: loss=7.6038 
[epoch 24] step 20/44: loss=7.6410 
[epoch 24] step 22/44: loss=7.6947 
[epoch 24] step 24/44: loss=7.8463 
[epoch 24] step 26/44: loss=7.9040 
[epoch 24] step 28/44: loss=7.9227 
[epoch 24] step 30/44: loss=7.9044 
[epoch 24] step 32/44: loss=7.8571 
[epoch 24] step 34/44: loss=7.8460 
[epoch 24] step 36/44: loss=7.8454 
[epoch 24] step 38/44: loss=7.8575 
[epoch 24] step 40/44: loss=7.9046 
[epoch 24] step 42/44: loss=7.8900 
[epoch 24] step 44/44: loss=7.8001 
[epoch 24] train_loss(avg per step)=15.6001 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=10.3851 qwk=('0.4150', '0.4692', '0.3399') averageQWK=0.4080 macroEMD=0.3721 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    9    1    0
     3   21   48    9    1
     0   13   92   49    1
     0    0   23   42    8
     0    0    7    2    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   26   36   14    0
     0   23   73   68    0
     0    1    5   74    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   18   59   15    0
     0   20  109   37    0
     0    4   20   48    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=6.5174 
[epoch 25] step 4/44: loss=6.7503 
[epoch 25] step 6/44: loss=7.3365 
[epoch 25] step 8/44: loss=7.4934 
[epoch 25] step 10/44: loss=7.7033 
[epoch 25] step 12/44: loss=7.8165 
[epoch 25] step 14/44: loss=7.8835 
[epoch 25] step 16/44: loss=7.9697 
[epoch 25] step 18/44: loss=8.0440 
[epoch 25] step 20/44: loss=8.0534 
[epoch 25] step 22/44: loss=8.0031 
[epoch 25] step 24/44: loss=7.9033 
[epoch 25] step 26/44: loss=7.8508 
[epoch 25] step 28/44: loss=7.8630 
[epoch 25] step 30/44: loss=7.8425 
[epoch 25] step 32/44: loss=7.8138 
[epoch 25] step 34/44: loss=7.8216 
[epoch 25] step 36/44: loss=7.8015 
[epoch 25] step 38/44: loss=7.7858 
[epoch 25] step 40/44: loss=7.8019 
[epoch 25] step 42/44: loss=7.7929 
[epoch 25] step 44/44: loss=7.8453 
[epoch 25] train_loss(avg per step)=15.6905 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=10.3899 qwk=('0.4166', '0.3808', '0.3330') averageQWK=0.3768 macroEMD=0.3744 tailR0=('0.1667', '0.0000', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    9    1    0
     1   11   59   10    1
     0    1  100   50    4
     0    0   19   43   11
     0    0    5    3    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    7   55   14    0
     0    1  110   53    0
     0    0   12   68    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   13   64   15    0
     0    7  123   36    0
     0    2   25   45    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=7.7639 
[epoch 26] step 4/44: loss=7.7641 
[epoch 26] step 6/44: loss=7.6261 
[epoch 26] step 8/44: loss=7.8735 
[epoch 26] step 10/44: loss=7.8253 
[epoch 26] step 12/44: loss=7.9098 
[epoch 26] step 14/44: loss=7.9412 
[epoch 26] step 16/44: loss=8.0766 
[epoch 26] step 18/44: loss=8.0508 
[epoch 26] step 20/44: loss=8.0733 
[epoch 26] step 22/44: loss=8.0107 
[epoch 26] step 24/44: loss=7.9995 
[epoch 26] step 26/44: loss=7.9919 
[epoch 26] step 28/44: loss=8.0201 
[epoch 26] step 30/44: loss=8.0150 
[epoch 26] step 32/44: loss=8.0079 
[epoch 26] step 34/44: loss=7.9911 
[epoch 26] step 36/44: loss=7.9896 
[epoch 26] step 38/44: loss=7.9998 
[epoch 26] step 40/44: loss=7.9576 
[epoch 26] step 42/44: loss=7.9052 
[epoch 26] step 44/44: loss=7.9841 
[epoch 26] train_loss(avg per step)=15.9682 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=10.6178 qwk=('0.3971', '0.3804', '0.3155') averageQWK=0.3643 macroEMD=0.3750 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    8    1    0
     3   14   46   18    1
     0    3   74   78    0
     0    0   12   60    1
     0    0    4    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    8   55   13    0
     0    1  100   63    0
     0    1   12   67    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    9   60   23    0
     0    9   99   58    0
     0    1   12   59    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=6.9114 
[epoch 27] step 4/44: loss=7.1062 
[epoch 27] step 6/44: loss=6.9240 
[epoch 27] step 8/44: loss=6.9756 
[epoch 27] step 10/44: loss=7.1001 
[epoch 27] step 12/44: loss=7.2814 
[epoch 27] step 14/44: loss=7.4395 
[epoch 27] step 16/44: loss=7.5209 
[epoch 27] step 18/44: loss=7.6053 
[epoch 27] step 20/44: loss=7.7373 
[epoch 27] step 22/44: loss=7.7221 
[epoch 27] step 24/44: loss=7.6804 
[epoch 27] step 26/44: loss=7.6812 
[epoch 27] step 28/44: loss=7.6757 
[epoch 27] step 30/44: loss=7.6310 
[epoch 27] step 32/44: loss=7.6590 
[epoch 27] step 34/44: loss=7.6538 
[epoch 27] step 36/44: loss=7.7145 
[epoch 27] step 38/44: loss=7.7720 
[epoch 27] step 40/44: loss=7.7714 
[epoch 27] step 42/44: loss=7.7699 
[epoch 27] step 44/44: loss=7.7964 
[epoch 27] train_loss(avg per step)=15.5928 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=10.4950 qwk=('0.3970', '0.3846', '0.3651') averageQWK=0.3822 macroEMD=0.3730 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    8    1    0
     1   11   58   11    1
     0    3   89   61    2
     0    0   20   48    5
     0    0    4    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    5   59   12    0
     0    1  101   62    0
     0    0   10   70    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   15   61   16    0
     0   14  111   41    0
     0    2   19   51    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=8.1934 
[epoch 28] step 4/44: loss=8.0942 
[epoch 28] step 6/44: loss=7.8347 
[epoch 28] step 8/44: loss=7.9507 
[epoch 28] step 10/44: loss=7.8583 
[epoch 28] step 12/44: loss=7.9113 
[epoch 28] step 14/44: loss=7.8886 
[epoch 28] step 16/44: loss=7.8436 
[epoch 28] step 18/44: loss=7.8612 
[epoch 28] step 20/44: loss=7.9100 
[epoch 28] step 22/44: loss=7.9381 
[epoch 28] step 24/44: loss=7.9311 
[epoch 28] step 26/44: loss=7.9076 
[epoch 28] step 28/44: loss=7.9333 
[epoch 28] step 30/44: loss=7.8841 
[epoch 28] step 32/44: loss=7.8595 
[epoch 28] step 34/44: loss=7.8653 
[epoch 28] step 36/44: loss=7.8372 
[epoch 28] step 38/44: loss=7.8368 
[epoch 28] step 40/44: loss=7.8198 
[epoch 28] step 42/44: loss=7.7943 
[epoch 28] step 44/44: loss=7.8505 
[epoch 28] train_loss(avg per step)=15.7010 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=10.5074 qwk=('0.3589', '0.3637', '0.3263') averageQWK=0.3496 macroEMD=0.3762 tailR0=('0.1167', '0.0000', '0.0000') tailR0avg=0.0389
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    9    1    0
     2    6   57   16    1
     0    1   86   65    3
     0    0   19   49    5
     0    0    4    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   10   49   17    0
     0    6   86   72    0
     0    1    9   70    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   14   58   20    0
     0   11  107   48    0
     0    3   16   53    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=7.3253 
[epoch 29] step 4/44: loss=7.2859 
[epoch 29] step 6/44: loss=7.0922 
[epoch 29] step 8/44: loss=7.2478 
[epoch 29] step 10/44: loss=7.3051 
[epoch 29] step 12/44: loss=7.4165 
[epoch 29] step 14/44: loss=7.4725 
[epoch 29] step 16/44: loss=7.5150 
[epoch 29] step 18/44: loss=7.6182 
[epoch 29] step 20/44: loss=7.6940 
[epoch 29] step 22/44: loss=7.8143 
[epoch 29] step 24/44: loss=7.8766 
[epoch 29] step 26/44: loss=7.8648 
[epoch 29] step 28/44: loss=7.8437 
[epoch 29] step 30/44: loss=7.8074 
[epoch 29] step 32/44: loss=7.8554 
[epoch 29] step 34/44: loss=7.8514 
[epoch 29] step 36/44: loss=7.8503 
[epoch 29] step 38/44: loss=7.8718 
[epoch 29] step 40/44: loss=7.8883 
[epoch 29] step 42/44: loss=7.8805 
[epoch 29] step 44/44: loss=7.8886 
[epoch 29] train_loss(avg per step)=15.7772 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=10.6879 qwk=('0.3541', '0.4005', '0.3179') averageQWK=0.3575 macroEMD=0.3749 tailR0=('0.1167', '0.0000', '0.0000') tailR0avg=0.0389
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2   10    1    0
     0    4   67   10    1
     0    1   95   58    1
     0    0   23   47    3
     0    0    4    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   11   50   15    0
     0    2   96   66    0
     0    0   11   69    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    9   62   21    0
     0    3  110   53    0
     0    1   18   53    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=7.7368 
[epoch 30] step 4/44: loss=8.1374 
[epoch 30] step 6/44: loss=8.3430 
[epoch 30] step 8/44: loss=8.1534 
[epoch 30] step 10/44: loss=8.2160 
[epoch 30] step 12/44: loss=8.1249 
[epoch 30] step 14/44: loss=8.0511 
[epoch 30] step 16/44: loss=7.9602 
[epoch 30] step 18/44: loss=7.8227 
[epoch 30] step 20/44: loss=7.7692 
[epoch 30] step 22/44: loss=7.8065 
[epoch 30] step 24/44: loss=7.7910 
[epoch 30] step 26/44: loss=7.8016 
[epoch 30] step 28/44: loss=7.8847 
[epoch 30] step 30/44: loss=7.8650 
[epoch 30] step 32/44: loss=7.8710 
[epoch 30] step 34/44: loss=7.8942 
[epoch 30] step 36/44: loss=7.8721 
[epoch 30] step 38/44: loss=7.8467 
[epoch 30] step 40/44: loss=7.8478 
[epoch 30] step 42/44: loss=7.8403 
[epoch 30] step 44/44: loss=7.8310 
[epoch 30] train_loss(avg per step)=15.6620 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=10.7916 qwk=('0.3931', '0.3815', '0.3124') averageQWK=0.3624 macroEMD=0.3749 tailR0=('0.1667', '0.0000', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2   10    1    0
     0    6   66    9    1
     0    1   95   57    2
     0    0   21   42   10
     0    0    4    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   10   49   17    0
     0    4   89   71    0
     0    0   10   70    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   11   60   21    0
     0    8  108   50    0
     0    1   22   49    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=8.2311 
[epoch 31] step 4/44: loss=8.1921 
[epoch 31] step 6/44: loss=8.2157 
[epoch 31] step 8/44: loss=8.0768 
[epoch 31] step 10/44: loss=8.0637 
[epoch 31] step 12/44: loss=7.9747 
[epoch 31] step 14/44: loss=7.9196 
[epoch 31] step 16/44: loss=7.8324 
[epoch 31] step 18/44: loss=7.7322 
[epoch 31] step 20/44: loss=7.8249 
[epoch 31] step 22/44: loss=7.8085 
[epoch 31] step 24/44: loss=7.8412 
[epoch 31] step 26/44: loss=7.8380 
[epoch 31] step 28/44: loss=7.9154 
[epoch 31] step 30/44: loss=7.9127 
[epoch 31] step 32/44: loss=7.9225 
[epoch 31] step 34/44: loss=7.9096 
[epoch 31] step 36/44: loss=7.9139 
[epoch 31] step 38/44: loss=7.8801 
[epoch 31] step 40/44: loss=7.8600 
[epoch 31] step 42/44: loss=7.8397 
[epoch 31] step 44/44: loss=7.7137 
[epoch 31] train_loss(avg per step)=15.4275 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=10.6330 qwk=('0.3942', '0.3661', '0.3141') averageQWK=0.3581 macroEMD=0.3747 tailR0=('0.1167', '0.0000', '0.0000') tailR0avg=0.0389
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    9    1    0
     0    8   65    8    1
     0    2   95   56    2
     0    0   21   44    8
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    9   49   18    0
     0    2   93   69    0
     0    0   10   70    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   15   50   27    0
     0   12   91   63    0
     0    2   13   57    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=8.0016 
[epoch 32] step 4/44: loss=8.0150 
[epoch 32] step 6/44: loss=7.9428 
[epoch 32] step 8/44: loss=8.0125 
[epoch 32] step 10/44: loss=8.0236 
[epoch 32] step 12/44: loss=7.9744 
[epoch 32] step 14/44: loss=8.0543 
[epoch 32] step 16/44: loss=7.9164 
[epoch 32] step 18/44: loss=7.8102 
[epoch 32] step 20/44: loss=7.8726 
[epoch 32] step 22/44: loss=7.8625 
[epoch 32] step 24/44: loss=7.8000 
[epoch 32] step 26/44: loss=7.8339 
[epoch 32] step 28/44: loss=7.8670 
[epoch 32] step 30/44: loss=7.8632 
[epoch 32] step 32/44: loss=7.8761 
[epoch 32] step 34/44: loss=7.8779 
[epoch 32] step 36/44: loss=7.9046 
[epoch 32] step 38/44: loss=7.8997 
[epoch 32] step 40/44: loss=7.9359 
[epoch 32] step 42/44: loss=7.9536 
[epoch 32] step 44/44: loss=8.0005 
[epoch 32] train_loss(avg per step)=16.0010 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=10.7926 qwk=('0.3998', '0.3840', '0.3178') averageQWK=0.3672 macroEMD=0.3745 tailR0=('0.1167', '0.0000', '0.0000') tailR0avg=0.0389
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    9    1    0
     1    9   60   11    1
     0    2   91   60    2
     0    0   20   43   10
     0    0    4    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   11   47   18    0
     0    3   85   76    0
     0    0    8   72    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   16   54   22    0
     0   15  100   51    0
     0    2   18   52    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=7.8427 
[epoch 33] step 4/44: loss=7.9510 
[epoch 33] step 6/44: loss=7.7987 
[epoch 33] step 8/44: loss=7.8941 
[epoch 33] step 10/44: loss=7.7789 
[epoch 33] step 12/44: loss=7.7788 
[epoch 33] step 14/44: loss=7.8381 
[epoch 33] step 16/44: loss=7.7981 
[epoch 33] step 18/44: loss=7.7246 
[epoch 33] step 20/44: loss=7.7546 
[epoch 33] step 22/44: loss=7.7765 
[epoch 33] step 24/44: loss=7.7259 
[epoch 33] step 26/44: loss=7.6718 
[epoch 33] step 28/44: loss=7.6966 
[epoch 33] step 30/44: loss=7.7186 
[epoch 33] step 32/44: loss=7.7330 
[epoch 33] step 34/44: loss=7.7580 
[epoch 33] step 36/44: loss=7.7875 
[epoch 33] step 38/44: loss=7.7815 
[epoch 33] step 40/44: loss=7.8084 
[epoch 33] step 42/44: loss=7.7959 
[epoch 33] step 44/44: loss=7.7076 
[epoch 33] train_loss(avg per step)=15.4151 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=10.7039 qwk=('0.3902', '0.3809', '0.3295') averageQWK=0.3668 macroEMD=0.3739 tailR0=('0.1167', '0.0000', '0.0000') tailR0avg=0.0389
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    9    1    0
     0    7   64   10    1
     0    2   92   59    2
     0    0   20   45    8
     0    0    4    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   11   47   18    0
     0    5   86   73    0
     0    0    9   71    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   14   56   22    0
     0   17   95   54    0
     0    2   13   57    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=7.5034 
[epoch 34] step 4/44: loss=8.0285 
[epoch 34] step 6/44: loss=7.8808 
[epoch 34] step 8/44: loss=8.1440 
[epoch 34] step 10/44: loss=8.2502 
[epoch 34] step 12/44: loss=8.1820 
[epoch 34] step 14/44: loss=8.1052 
[epoch 34] step 16/44: loss=8.1307 
[epoch 34] step 18/44: loss=8.0566 
[epoch 34] step 20/44: loss=8.0037 
[epoch 34] step 22/44: loss=8.0518 
[epoch 34] step 24/44: loss=8.0008 
[epoch 34] step 26/44: loss=8.0110 
[epoch 34] step 28/44: loss=8.0367 
[epoch 34] step 30/44: loss=8.0035 
[epoch 34] step 32/44: loss=7.9702 
[epoch 34] step 34/44: loss=7.9300 
[epoch 34] step 36/44: loss=7.9195 
[epoch 34] step 38/44: loss=7.9027 
[epoch 34] step 40/44: loss=7.8951 
[epoch 34] step 42/44: loss=7.8626 
[epoch 34] step 44/44: loss=7.7832 
[epoch 34] train_loss(avg per step)=15.5664 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=10.6513 qwk=('0.3737', '0.3946', '0.3164') averageQWK=0.3616 macroEMD=0.3747 tailR0=('0.1167', '0.0000', '0.0000') tailR0avg=0.0389
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    9    1    0
     0   10   58   12    2
     0    2   88   62    3
     0    0   20   45    8
     0    0    4    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   11   49   16    0
     0    4   88   72    0
     0    0    9   71    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   11   60   21    0
     0    7  108   51    0
     0    2   17   53    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=7.6800 
[epoch 35] step 4/44: loss=7.7512 
[epoch 35] step 6/44: loss=7.6202 
[epoch 35] step 8/44: loss=7.5086 
[epoch 35] step 10/44: loss=7.5092 
[epoch 35] step 12/44: loss=7.6000 
[epoch 35] step 14/44: loss=7.5922 
[epoch 35] step 16/44: loss=7.6631 
[epoch 35] step 18/44: loss=7.6892 
[epoch 35] step 20/44: loss=7.7581 
[epoch 35] step 22/44: loss=7.7787 
[epoch 35] step 24/44: loss=7.8130 
[epoch 35] step 26/44: loss=7.8550 
[epoch 35] step 28/44: loss=7.8488 
[epoch 35] step 30/44: loss=7.8772 
[epoch 35] step 32/44: loss=7.8812 
[epoch 35] step 34/44: loss=7.8686 
[epoch 35] step 36/44: loss=7.8813 
[epoch 35] step 38/44: loss=7.8398 
[epoch 35] step 40/44: loss=7.8284 
[epoch 35] step 42/44: loss=7.8148 
[epoch 35] step 44/44: loss=7.7489 
[epoch 35] train_loss(avg per step)=15.4978 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=10.7408 qwk=('0.3956', '0.3955', '0.3265') averageQWK=0.3725 macroEMD=0.3741 tailR0=('0.1167', '0.0000', '0.0000') tailR0avg=0.0389
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    9    1    0
     0    9   65    7    1
     0    1   96   56    2
     0    0   21   44    8
     0    0    6    3    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   12   48   16    0
     0    7   89   68    0
     0    0   10   70    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   15   56   21    0
     0   18   98   50    0
     0    2   16   54    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-1-reassignment-1/fold4/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-1-reassignment-1/fold4/metrics.json
Done.
