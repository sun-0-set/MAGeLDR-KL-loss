[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=5.8770 
[epoch 1] step 4/44: loss=6.0662 
[epoch 1] step 6/44: loss=5.8599 
[epoch 1] step 8/44: loss=5.6764 
[epoch 1] step 10/44: loss=5.8144 
[epoch 1] step 12/44: loss=5.8349 
[epoch 1] step 14/44: loss=5.7865 
[epoch 1] step 16/44: loss=5.8076 
[epoch 1] step 18/44: loss=5.8926 
[epoch 1] step 20/44: loss=5.9513 
[epoch 1] step 22/44: loss=5.9810 
[epoch 1] step 24/44: loss=6.0006 
[epoch 1] step 26/44: loss=6.0445 
[epoch 1] step 28/44: loss=6.0379 
[epoch 1] step 30/44: loss=6.0296 
[epoch 1] step 32/44: loss=6.0621 
[epoch 1] step 34/44: loss=6.0713 
[epoch 1] step 36/44: loss=6.1151 
[epoch 1] step 38/44: loss=6.1295 
[epoch 1] step 40/44: loss=6.1653 
[epoch 1] step 42/44: loss=6.2031 
[epoch 1] step 44/44: loss=6.2533 
[epoch 1] train_loss(avg per step)=12.5065 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=7.6013 qwk=('-0.0878', '-0.0931', '0.0260') averageQWK=-0.0516 macroEMD=0.3985 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    8    0
     0   23    0   17    0
     0   71    0   57    0
     0   73    0   49    0
     0   16    0   11    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
    13    0   33    2    0
    46    0   65    2    0
    73    0   66    9    0
     5    0    5    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    3   68    0    0
     0    1  150    0    0
     0    1   98    0    0
     0    0    3    0    0
[epoch 2] step 2/44: loss=9.7734 
[epoch 2] step 4/44: loss=9.6941 
[epoch 2] step 6/44: loss=10.0290 
[epoch 2] step 8/44: loss=10.0100 
[epoch 2] step 10/44: loss=10.1222 
[epoch 2] step 12/44: loss=10.2010 
[epoch 2] step 14/44: loss=10.3244 
[epoch 2] step 16/44: loss=10.4145 
[epoch 2] step 18/44: loss=10.5004 
[epoch 2] step 20/44: loss=10.5750 
[epoch 2] step 22/44: loss=10.6725 
[epoch 2] step 24/44: loss=10.7666 
[epoch 2] step 26/44: loss=10.8339 
[epoch 2] step 28/44: loss=10.9472 
[epoch 2] step 30/44: loss=11.0472 
[epoch 2] step 32/44: loss=11.1985 
[epoch 2] step 34/44: loss=11.2647 
[epoch 2] step 36/44: loss=11.3507 
[epoch 2] step 38/44: loss=11.4376 
[epoch 2] step 40/44: loss=11.5434 
[epoch 2] step 42/44: loss=11.6219 
[epoch 2] step 44/44: loss=11.6817 
[epoch 2] train_loss(avg per step)=23.3634 lambda[min,max]=[0.500564,1.000000]
[epoch 2] val_loss=13.3521 qwk=('0.4198', '0.1639', '0.3518') averageQWK=0.3118 macroEMD=0.3918 tailR0=('0.0185', '0.0833', '0.0000') tailR0avg=0.0340
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    1    0
    11   15    9    4    1
    19   29   15   60    5
     3   16   12   89    2
     0    1    0   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    4    1    0
     0    0    8   40    0
     2    0    6  105    0
     0    0    0  148    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    3   68    0    0
     0    0  137   14    0
     0    0   62   37    0
     0    0    0    3    0
[epoch 3] step 2/44: loss=12.0223 
[epoch 3] step 4/44: loss=12.7780 
[epoch 3] step 6/44: loss=12.9978 
[epoch 3] step 8/44: loss=12.8782 
[epoch 3] step 10/44: loss=12.9360 
[epoch 3] step 12/44: loss=12.9127 
[epoch 3] step 14/44: loss=12.8680 
[epoch 3] step 16/44: loss=12.8098 
[epoch 3] step 18/44: loss=12.6939 
[epoch 3] step 20/44: loss=12.6235 
[epoch 3] step 22/44: loss=12.6109 
[epoch 3] step 24/44: loss=12.6591 
[epoch 3] step 26/44: loss=12.6859 
[epoch 3] step 28/44: loss=12.6628 
[epoch 3] step 30/44: loss=12.6331 
[epoch 3] step 32/44: loss=12.6177 
[epoch 3] step 34/44: loss=12.6180 
[epoch 3] step 36/44: loss=12.6002 
[epoch 3] step 38/44: loss=12.5853 
[epoch 3] step 40/44: loss=12.6616 
[epoch 3] step 42/44: loss=12.7193 
[epoch 3] step 44/44: loss=12.7725 
[epoch 3] train_loss(avg per step)=25.5450 lambda[min,max]=[0.564393,1.000000]
[epoch 3] val_loss=15.0473 qwk=('0.0263', '0.0000', '0.1119') averageQWK=0.0461 macroEMD=0.3919 tailR0=('0.0370', '0.0000', '0.0000') tailR0avg=0.0123
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    0    0
     3   36    0    0    1
     0  121    0    0    7
     0  118    0    2    2
     0   24    0    1    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   48    0    0
     0    0  113    0    0
     0    0  148    0    0
     0    0   10    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    9   62    0    0
     0    2  149    0    0
     0    1   98    0    0
     0    0    3    0    0
[epoch 4] step 2/44: loss=11.1843 
[epoch 4] step 4/44: loss=11.5162 
[epoch 4] step 6/44: loss=11.4781 
[epoch 4] step 8/44: loss=11.5465 
[epoch 4] step 10/44: loss=11.6981 
[epoch 4] step 12/44: loss=11.9939 
[epoch 4] step 14/44: loss=12.0847 
[epoch 4] step 16/44: loss=11.9692 
[epoch 4] step 18/44: loss=11.9732 
[epoch 4] step 20/44: loss=11.9748 
[epoch 4] step 22/44: loss=11.8965 
[epoch 4] step 24/44: loss=11.8095 
[epoch 4] step 26/44: loss=11.7150 
[epoch 4] step 28/44: loss=11.7405 
[epoch 4] step 30/44: loss=11.7338 
[epoch 4] step 32/44: loss=11.7185 
[epoch 4] step 34/44: loss=11.7426 
[epoch 4] step 36/44: loss=11.7383 
[epoch 4] step 38/44: loss=11.7737 
[epoch 4] step 40/44: loss=11.7213 
[epoch 4] step 42/44: loss=11.6979 
[epoch 4] step 44/44: loss=11.7248 
[epoch 4] train_loss(avg per step)=23.4495 lambda[min,max]=[0.557408,1.000000]
[epoch 4] val_loss=13.1839 qwk=('0.3886', '0.3324', '0.3964') averageQWK=0.3725 macroEMD=0.3822 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    1    0
     0    0   29   11    0
     0    0   51   77    0
     0    0   11  111    0
     0    0    0   27    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   29   19    0
     0    0   30   83    0
     0    0    8  140    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    0   63    8    0
     0    0   92   59    0
     0    0   20   79    0
     0    0    1    2    0
[epoch 5] step 2/44: loss=13.4052 
[epoch 5] step 4/44: loss=13.2660 
[epoch 5] step 6/44: loss=12.6249 
[epoch 5] step 8/44: loss=12.0165 
[epoch 5] step 10/44: loss=11.4935 
[epoch 5] step 12/44: loss=11.1969 
[epoch 5] step 14/44: loss=11.1421 
[epoch 5] step 16/44: loss=11.2058 
[epoch 5] step 18/44: loss=11.3925 
[epoch 5] step 20/44: loss=11.4706 
[epoch 5] step 22/44: loss=11.3748 
[epoch 5] step 24/44: loss=11.1932 
[epoch 5] step 26/44: loss=11.0034 
[epoch 5] step 28/44: loss=10.7694 
[epoch 5] step 30/44: loss=10.6248 
[epoch 5] step 32/44: loss=10.6736 
[epoch 5] step 34/44: loss=10.7490 
[epoch 5] step 36/44: loss=10.8354 
[epoch 5] step 38/44: loss=10.8211 
[epoch 5] step 40/44: loss=10.7379 
[epoch 5] step 42/44: loss=10.6475 
[epoch 5] step 44/44: loss=10.5848 
[epoch 5] train_loss(avg per step)=21.1696 lambda[min,max]=[0.500341,1.000000]
[epoch 5] val_loss=12.1299 qwk=('0.4873', '0.4835', '0.4743') averageQWK=0.4817 macroEMD=0.3834 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0   13   21    6    0
     0   17   59   52    0
     0    6   21   95    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   28    1   19    0
     0   29    0   84    0
     0    8    1  139    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   67    2    2    0
     0   99   26   26    0
     0   22   20   57    0
     0    0    2    1    0
[epoch 6] step 2/44: loss=8.9347 
[epoch 6] step 4/44: loss=8.8082 
[epoch 6] step 6/44: loss=9.5230 
[epoch 6] step 8/44: loss=9.6792 
[epoch 6] step 10/44: loss=9.7312 
[epoch 6] step 12/44: loss=9.6138 
[epoch 6] step 14/44: loss=9.5047 
[epoch 6] step 16/44: loss=9.4014 
[epoch 6] step 18/44: loss=9.2738 
[epoch 6] step 20/44: loss=9.2528 
[epoch 6] step 22/44: loss=9.3525 
[epoch 6] step 24/44: loss=9.4623 
[epoch 6] step 26/44: loss=9.5243 
[epoch 6] step 28/44: loss=9.5265 
[epoch 6] step 30/44: loss=9.4840 
[epoch 6] step 32/44: loss=9.3594 
[epoch 6] step 34/44: loss=9.3209 
[epoch 6] step 36/44: loss=9.2505 
[epoch 6] step 38/44: loss=9.2393 
[epoch 6] step 40/44: loss=9.2143 
[epoch 6] step 42/44: loss=9.2347 
[epoch 6] step 44/44: loss=9.1600 
[epoch 6] train_loss(avg per step)=18.3201 lambda[min,max]=[0.500014,1.000000]
[epoch 6] val_loss=10.9903 qwk=('0.2223', '0.4385', '0.5412') averageQWK=0.4007 macroEMD=0.3847 tailR0=('0.0926', '0.0000', '0.0000') tailR0avg=0.0309
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    0    0
     1   39    0    0    0
     1  116    2    8    1
     3   77    6   33    3
     2   12    0    8    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   23    0   25    0
     0   22    0   91    0
     0    5    0  143    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   39   30    2    0
     0   37   80   34    0
     0    3   37   59    0
     0    0    1    2    0
[epoch 7] step 2/44: loss=6.7947 
[epoch 7] step 4/44: loss=7.3440 
[epoch 7] step 6/44: loss=7.6377 
[epoch 7] step 8/44: loss=7.7191 
[epoch 7] step 10/44: loss=8.0315 
[epoch 7] step 12/44: loss=8.2870 
[epoch 7] step 14/44: loss=8.2937 
[epoch 7] step 16/44: loss=8.3378 
[epoch 7] step 18/44: loss=8.2533 
[epoch 7] step 20/44: loss=8.1926 
[epoch 7] step 22/44: loss=8.1452 
[epoch 7] step 24/44: loss=8.2117 
[epoch 7] step 26/44: loss=8.2743 
[epoch 7] step 28/44: loss=8.2926 
[epoch 7] step 30/44: loss=8.3511 
[epoch 7] step 32/44: loss=8.4389 
[epoch 7] step 34/44: loss=8.4236 
[epoch 7] step 36/44: loss=8.3851 
[epoch 7] step 38/44: loss=8.3692 
[epoch 7] step 40/44: loss=8.3646 
[epoch 7] step 42/44: loss=8.3690 
[epoch 7] step 44/44: loss=8.3455 
[epoch 7] train_loss(avg per step)=16.6911 lambda[min,max]=[0.500002,1.000000]
[epoch 7] val_loss=9.9746 qwk=('0.1047', '0.3445', '0.3357') averageQWK=0.2617 macroEMD=0.3772 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    0    0
     0    0   40    0    0
     0    0  127    1    0
     0    0  111   11    0
     0    0   24    3    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   48    0    0
     0    0  101   12    0
     0    0   94   54    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   49    0    0
     0    9  141    1    0
     0    0   85   14    0
     0    0    3    0    0
[epoch 8] step 2/44: loss=9.4111 
[epoch 8] step 4/44: loss=9.1486 
[epoch 8] step 6/44: loss=8.7993 
[epoch 8] step 8/44: loss=8.4671 
[epoch 8] step 10/44: loss=8.2235 
[epoch 8] step 12/44: loss=8.0677 
[epoch 8] step 14/44: loss=8.0888 
[epoch 8] step 16/44: loss=8.2270 
[epoch 8] step 18/44: loss=8.2565 
[epoch 8] step 20/44: loss=8.3197 
[epoch 8] step 22/44: loss=8.3831 
[epoch 8] step 24/44: loss=8.4391 
[epoch 8] step 26/44: loss=8.4616 
[epoch 8] step 28/44: loss=8.4012 
[epoch 8] step 30/44: loss=8.3013 
[epoch 8] step 32/44: loss=8.2149 
[epoch 8] step 34/44: loss=8.1575 
[epoch 8] step 36/44: loss=8.1766 
[epoch 8] step 38/44: loss=8.2028 
[epoch 8] step 40/44: loss=8.2186 
[epoch 8] step 42/44: loss=8.2628 
[epoch 8] step 44/44: loss=8.2653 
[epoch 8] train_loss(avg per step)=16.5306 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=10.1752 qwk=('0.3269', '0.3165', '0.4141') averageQWK=0.3525 macroEMD=0.3778 tailR0=('0.1481', '0.0000', '0.0000') tailR0avg=0.0494
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    0    0
     0    1   39    0    0
     0    0  122    1    5
     0    0   94   20    8
     0    0   16    3    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    2   46    0    0
     0    0  108    5    0
     0    0  102   46    0
     0    0    6    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   57    0    0
     0    4  140    7    0
     0    0   62   37    0
     0    0    3    0    0
[epoch 9] step 2/44: loss=7.8504 
[epoch 9] step 4/44: loss=7.4662 
[epoch 9] step 6/44: loss=7.2933 
[epoch 9] step 8/44: loss=7.1982 
[epoch 9] step 10/44: loss=7.1372 
[epoch 9] step 12/44: loss=7.0875 
[epoch 9] step 14/44: loss=7.2450 
[epoch 9] step 16/44: loss=7.3976 
[epoch 9] step 18/44: loss=7.5156 
[epoch 9] step 20/44: loss=7.6512 
[epoch 9] step 22/44: loss=7.7387 
[epoch 9] step 24/44: loss=7.7757 
[epoch 9] step 26/44: loss=7.7731 
[epoch 9] step 28/44: loss=7.7417 
[epoch 9] step 30/44: loss=7.7247 
[epoch 9] step 32/44: loss=7.7722 
[epoch 9] step 34/44: loss=7.7932 
[epoch 9] step 36/44: loss=7.7957 
[epoch 9] step 38/44: loss=7.7836 
[epoch 9] step 40/44: loss=7.8120 
[epoch 9] step 42/44: loss=7.8184 
[epoch 9] step 44/44: loss=7.8058 
[epoch 9] train_loss(avg per step)=15.6116 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=9.5317 qwk=('0.3909', '0.4397', '0.5138') averageQWK=0.4481 macroEMD=0.3677 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    0    0
     0    1   26   13    0
     0    0   54   74    0
     0    0   17  105    0
     0    0    0   27    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    8   23   17    0
     0    2   44   67    0
     0    0   22  126    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   37   10    0
     0    9   69   73    0
     0    0   14   85    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=8.7463 
[epoch 10] step 4/44: loss=9.0260 
[epoch 10] step 6/44: loss=9.1485 
[epoch 10] step 8/44: loss=9.0813 
[epoch 10] step 10/44: loss=8.6972 
[epoch 10] step 12/44: loss=8.4162 
[epoch 10] step 14/44: loss=8.2303 
[epoch 10] step 16/44: loss=8.0962 
[epoch 10] step 18/44: loss=7.9403 
[epoch 10] step 20/44: loss=7.9648 
[epoch 10] step 22/44: loss=8.0150 
[epoch 10] step 24/44: loss=8.0521 
[epoch 10] step 26/44: loss=8.0770 
[epoch 10] step 28/44: loss=8.1191 
[epoch 10] step 30/44: loss=8.1024 
[epoch 10] step 32/44: loss=8.0849 
[epoch 10] step 34/44: loss=8.0180 
[epoch 10] step 36/44: loss=7.9939 
[epoch 10] step 38/44: loss=8.0146 
[epoch 10] step 40/44: loss=8.0371 
[epoch 10] step 42/44: loss=8.0444 
[epoch 10] step 44/44: loss=8.0184 
[epoch 10] train_loss(avg per step)=16.0368 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=10.0354 qwk=('0.3833', '0.5152', '0.5083') averageQWK=0.4689 macroEMD=0.3699 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    3   37    0    0
     0    1  114   13    0
     0    0   74   48    0
     0    0   13   14    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   15   26    7    0
     0    6   73   34    0
     0    3   49   96    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   34   37    0    0
     0   23  124    4    0
     0    0   64   35    0
     0    0    3    0    0
[epoch 11] step 2/44: loss=8.7346 
[epoch 11] step 4/44: loss=8.1567 
[epoch 11] step 6/44: loss=7.8962 
[epoch 11] step 8/44: loss=7.8016 
[epoch 11] step 10/44: loss=7.8008 
[epoch 11] step 12/44: loss=7.8352 
[epoch 11] step 14/44: loss=7.8405 
[epoch 11] step 16/44: loss=7.8891 
[epoch 11] step 18/44: loss=8.0086 
[epoch 11] step 20/44: loss=7.9430 
[epoch 11] step 22/44: loss=7.9558 
[epoch 11] step 24/44: loss=7.9269 
[epoch 11] step 26/44: loss=7.8578 
[epoch 11] step 28/44: loss=7.8691 
[epoch 11] step 30/44: loss=7.9298 
[epoch 11] step 32/44: loss=7.9311 
[epoch 11] step 34/44: loss=7.9350 
[epoch 11] step 36/44: loss=7.9013 
[epoch 11] step 38/44: loss=7.9750 
[epoch 11] step 40/44: loss=8.0244 
[epoch 11] step 42/44: loss=8.0298 
[epoch 11] step 44/44: loss=8.0161 
[epoch 11] train_loss(avg per step)=16.0323 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=10.0133 qwk=('0.4052', '0.3885', '0.5394') averageQWK=0.4444 macroEMD=0.3693 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    0    0
     0    3   33    4    0
     1    1  105   21    0
     0    1   56   65    0
     0    0    9   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    5   24   19    0
     1    1   36   75    0
     0    0   15  133    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   19   52    0    0
     0    8  111   32    0
     0    0   35   64    0
     0    0    2    1    0
[epoch 12] step 2/44: loss=8.0713 
[epoch 12] step 4/44: loss=7.7778 
[epoch 12] step 6/44: loss=7.6654 
[epoch 12] step 8/44: loss=7.5582 
[epoch 12] step 10/44: loss=7.6817 
[epoch 12] step 12/44: loss=7.8299 
[epoch 12] step 14/44: loss=7.7705 
[epoch 12] step 16/44: loss=7.7572 
[epoch 12] step 18/44: loss=7.7894 
[epoch 12] step 20/44: loss=7.7669 
[epoch 12] step 22/44: loss=7.7682 
[epoch 12] step 24/44: loss=7.7297 
[epoch 12] step 26/44: loss=7.7603 
[epoch 12] step 28/44: loss=7.7641 
[epoch 12] step 30/44: loss=7.7837 
[epoch 12] step 32/44: loss=7.7951 
[epoch 12] step 34/44: loss=7.7548 
[epoch 12] step 36/44: loss=7.7274 
[epoch 12] step 38/44: loss=7.7045 
[epoch 12] step 40/44: loss=7.7016 
[epoch 12] step 42/44: loss=7.7748 
[epoch 12] step 44/44: loss=7.8133 
[epoch 12] train_loss(avg per step)=15.6265 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=9.9601 qwk=('0.5229', '0.4647', '0.5648') averageQWK=0.5175 macroEMD=0.3666 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    0    0
     0   30    5    5    0
     0   59   27   42    0
     0   16   23   83    0
     0    0    3   24    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   29   13    6    0
     0   42   39   32    0
     0   22   37   89    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   53   17    1    0
     0   69   54   28    0
     0    6   29   64    0
     0    0    2    1    0
[epoch 13] step 2/44: loss=8.5534 
[epoch 13] step 4/44: loss=8.2788 
[epoch 13] step 6/44: loss=8.2822 
[epoch 13] step 8/44: loss=8.2373 
[epoch 13] step 10/44: loss=8.2427 
[epoch 13] step 12/44: loss=8.2001 
[epoch 13] step 14/44: loss=8.0435 
[epoch 13] step 16/44: loss=7.8488 
[epoch 13] step 18/44: loss=7.8073 
[epoch 13] step 20/44: loss=7.9143 
[epoch 13] step 22/44: loss=8.0046 
[epoch 13] step 24/44: loss=7.9983 
[epoch 13] step 26/44: loss=8.0328 
[epoch 13] step 28/44: loss=7.9956 
[epoch 13] step 30/44: loss=7.9615 
[epoch 13] step 32/44: loss=7.9563 
[epoch 13] step 34/44: loss=7.9518 
[epoch 13] step 36/44: loss=7.9902 
[epoch 13] step 38/44: loss=7.9536 
[epoch 13] step 40/44: loss=7.9423 
[epoch 13] step 42/44: loss=7.9192 
[epoch 13] step 44/44: loss=7.9287 
[epoch 13] train_loss(avg per step)=15.8575 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=10.2470 qwk=('0.4408', '0.3697', '0.5243') averageQWK=0.4449 macroEMD=0.3728 tailR0=('0.0741', '0.0000', '0.0000') tailR0avg=0.0247
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    4   21   15    0
     0    2   49   75    2
     0    0   15  104    3
     0    0    0   23    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2   26   20    0
     1    1   29   82    0
     0    0   12  136    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   19   46    6    0
     0    6   93   52    0
     0    0   21   78    0
     0    0    1    2    0
[epoch 14] step 2/44: loss=6.7378 
[epoch 14] step 4/44: loss=6.8011 
[epoch 14] step 6/44: loss=6.6661 
[epoch 14] step 8/44: loss=6.8302 
[epoch 14] step 10/44: loss=7.0191 
[epoch 14] step 12/44: loss=7.1983 
[epoch 14] step 14/44: loss=7.3051 
[epoch 14] step 16/44: loss=7.4876 
[epoch 14] step 18/44: loss=7.6575 
[epoch 14] step 20/44: loss=7.6976 
[epoch 14] step 22/44: loss=7.5996 
[epoch 14] step 24/44: loss=7.5073 
[epoch 14] step 26/44: loss=7.5141 
[epoch 14] step 28/44: loss=7.6168 
[epoch 14] step 30/44: loss=7.6753 
[epoch 14] step 32/44: loss=7.6973 
[epoch 14] step 34/44: loss=7.6775 
[epoch 14] step 36/44: loss=7.7048 
[epoch 14] step 38/44: loss=7.7536 
[epoch 14] step 40/44: loss=7.7079 
[epoch 14] step 42/44: loss=7.7010 
[epoch 14] step 44/44: loss=7.6579 
[epoch 14] train_loss(avg per step)=15.3157 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=9.9623 qwk=('0.5018', '0.4646', '0.4748') averageQWK=0.4804 macroEMD=0.3695 tailR0=('0.0185', '0.0000', '0.0000') tailR0avg=0.0062
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     1   14   12   13    0
     1   12   40   75    0
     0    1   18  102    1
     0    0    0   26    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    5   34    9    0
     1    2   61   49    0
     0    0   37  111    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    8   58    5    0
     0    1  108   42    0
     0    0   27   72    0
     0    0    1    2    0
[epoch 15] step 2/44: loss=7.5478 
[epoch 15] step 4/44: loss=7.4908 
[epoch 15] step 6/44: loss=7.8522 
[epoch 15] step 8/44: loss=8.0260 
[epoch 15] step 10/44: loss=8.1253 
[epoch 15] step 12/44: loss=8.0987 
[epoch 15] step 14/44: loss=8.1764 
[epoch 15] step 16/44: loss=8.1344 
[epoch 15] step 18/44: loss=8.1558 
[epoch 15] step 20/44: loss=8.1186 
[epoch 15] step 22/44: loss=8.0269 
[epoch 15] step 24/44: loss=7.9389 
[epoch 15] step 26/44: loss=7.9751 
[epoch 15] step 28/44: loss=8.0374 
[epoch 15] step 30/44: loss=8.0095 
[epoch 15] step 32/44: loss=8.0163 
[epoch 15] step 34/44: loss=7.9415 
[epoch 15] step 36/44: loss=7.8711 
[epoch 15] step 38/44: loss=7.8860 
[epoch 15] step 40/44: loss=7.9064 
[epoch 15] step 42/44: loss=7.8510 
[epoch 15] step 44/44: loss=7.8154 
[epoch 15] train_loss(avg per step)=15.6307 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=10.1867 qwk=('0.5174', '0.4891', '0.5609') averageQWK=0.5225 macroEMD=0.3683 tailR0=('0.0741', '0.0833', '0.0000') tailR0avg=0.0525
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     2   10   20    8    0
     1    9   77   39    2
     0    1   38   80    3
     0    0    3   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     2    9   28    9    0
     4    6   61   42    0
     0    0   45  103    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   57    9    5    0
     0   67   37   47    0
     0    5   18   76    0
     0    1    1    1    0
[epoch 16] step 2/44: loss=6.8899 
[epoch 16] step 4/44: loss=7.5938 
[epoch 16] step 6/44: loss=8.2874 
[epoch 16] step 8/44: loss=8.3425 
[epoch 16] step 10/44: loss=8.1204 
[epoch 16] step 12/44: loss=7.9724 
[epoch 16] step 14/44: loss=7.9939 
[epoch 16] step 16/44: loss=7.9462 
[epoch 16] step 18/44: loss=8.1436 
[epoch 16] step 20/44: loss=8.1484 
[epoch 16] step 22/44: loss=8.0779 
[epoch 16] step 24/44: loss=8.0915 
[epoch 16] step 26/44: loss=7.9637 
[epoch 16] step 28/44: loss=7.9868 
[epoch 16] step 30/44: loss=7.9463 
[epoch 16] step 32/44: loss=7.9208 
[epoch 16] step 34/44: loss=7.9114 
[epoch 16] step 36/44: loss=7.8797 
[epoch 16] step 38/44: loss=7.8671 
[epoch 16] step 40/44: loss=7.8634 
[epoch 16] step 42/44: loss=7.9233 
[epoch 16] step 44/44: loss=7.9892 
[epoch 16] train_loss(avg per step)=15.9784 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=10.2681 qwk=('0.4814', '0.4802', '0.4278') averageQWK=0.4632 macroEMD=0.3669 tailR0=('0.0741', '0.0000', '0.0000') tailR0avg=0.0247
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    7   22   11    0
     0    3   55   67    3
     0    0   23   95    4
     0    0    0   23    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    7   31   10    0
     0    5   66   42    0
     0    1   36  111    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   57    7    0
     0    4   95   52    0
     0    0   25   74    0
     0    0    1    2    0
[epoch 17] step 2/44: loss=8.2841 
[epoch 17] step 4/44: loss=8.4312 
[epoch 17] step 6/44: loss=8.2192 
[epoch 17] step 8/44: loss=7.9290 
[epoch 17] step 10/44: loss=7.6054 
[epoch 17] step 12/44: loss=7.6828 
[epoch 17] step 14/44: loss=7.5661 
[epoch 17] step 16/44: loss=7.5592 
[epoch 17] step 18/44: loss=7.5217 
[epoch 17] step 20/44: loss=7.5407 
[epoch 17] step 22/44: loss=7.5808 
[epoch 17] step 24/44: loss=7.6110 
[epoch 17] step 26/44: loss=7.6522 
[epoch 17] step 28/44: loss=7.7867 
[epoch 17] step 30/44: loss=7.8681 
[epoch 17] step 32/44: loss=7.9222 
[epoch 17] step 34/44: loss=7.9153 
[epoch 17] step 36/44: loss=7.8877 
[epoch 17] step 38/44: loss=7.8144 
[epoch 17] step 40/44: loss=7.7277 
[epoch 17] step 42/44: loss=7.7279 
[epoch 17] step 44/44: loss=7.7277 
[epoch 17] train_loss(avg per step)=15.4553 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=10.1138 qwk=('0.5137', '0.4943', '0.4271') averageQWK=0.4784 macroEMD=0.3649 tailR0=('0.0185', '0.0000', '0.0000') tailR0avg=0.0062
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     2    8   19   11    0
     1    7   59   61    0
     0    0   22  100    0
     0    0    0   26    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0   14   23   11    0
     1   11   43   58    0
     0    0   30  118    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   10   51   10    0
     0    4   74   73    0
     0    0   18   81    0
     0    0    0    3    0
[epoch 18] step 2/44: loss=8.3546 
[epoch 18] step 4/44: loss=8.3921 
[epoch 18] step 6/44: loss=8.5461 
[epoch 18] step 8/44: loss=8.4475 
[epoch 18] step 10/44: loss=8.4121 
[epoch 18] step 12/44: loss=8.5007 
[epoch 18] step 14/44: loss=8.4423 
[epoch 18] step 16/44: loss=8.4000 
[epoch 18] step 18/44: loss=8.1527 
[epoch 18] step 20/44: loss=7.9949 
[epoch 18] step 22/44: loss=7.8311 
[epoch 18] step 24/44: loss=7.7785 
[epoch 18] step 26/44: loss=7.7935 
[epoch 18] step 28/44: loss=7.8627 
[epoch 18] step 30/44: loss=7.9203 
[epoch 18] step 32/44: loss=7.9467 
[epoch 18] step 34/44: loss=7.9095 
[epoch 18] step 36/44: loss=7.8860 
[epoch 18] step 38/44: loss=7.8462 
[epoch 18] step 40/44: loss=7.8545 
[epoch 18] step 42/44: loss=7.8319 
[epoch 18] step 44/44: loss=7.8596 
[epoch 18] train_loss(avg per step)=15.7193 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=10.2229 qwk=('0.5616', '0.4934', '0.5548') averageQWK=0.5366 macroEMD=0.3671 tailR0=('0.0185', '0.0000', '0.0000') tailR0avg=0.0062
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     3   10   19    8    0
     0    8   84   35    1
     0    0   34   87    1
     0    0    1   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1   13   23   11    0
     1   14   49   49    0
     0    0   37  111    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   40    0    0
     0   21  100   30    0
     0    2   36   61    0
     0    0    2    1    0
[epoch 19] step 2/44: loss=8.2243 
[epoch 19] step 4/44: loss=8.7636 
[epoch 19] step 6/44: loss=8.3965 
[epoch 19] step 8/44: loss=8.2908 
[epoch 19] step 10/44: loss=8.0811 
[epoch 19] step 12/44: loss=7.9122 
[epoch 19] step 14/44: loss=7.8405 
[epoch 19] step 16/44: loss=7.7597 
[epoch 19] step 18/44: loss=7.8032 
[epoch 19] step 20/44: loss=7.8408 
[epoch 19] step 22/44: loss=7.9655 
[epoch 19] step 24/44: loss=7.9635 
[epoch 19] step 26/44: loss=7.9103 
[epoch 19] step 28/44: loss=7.8808 
[epoch 19] step 30/44: loss=7.8854 
[epoch 19] step 32/44: loss=7.8957 
[epoch 19] step 34/44: loss=7.9289 
[epoch 19] step 36/44: loss=7.9209 
[epoch 19] step 38/44: loss=7.8931 
[epoch 19] step 40/44: loss=7.8608 
[epoch 19] step 42/44: loss=7.8627 
[epoch 19] step 44/44: loss=7.8619 
[epoch 19] train_loss(avg per step)=15.7239 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=10.3644 qwk=('0.5101', '0.4899', '0.5163') averageQWK=0.5054 macroEMD=0.3669 tailR0=('0.1551', '0.0000', '0.0000') tailR0avg=0.0517
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     2    9   18   11    0
     1   12   57   54    4
     0    1   28   89    4
     0    0    1   21    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0   15   20   13    0
     0   12   48   53    0
     0    2   27  119    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   44    3    0
     0   19   85   47    0
     0    2   27   70    0
     0    0    1    2    0
[epoch 20] step 2/44: loss=8.5232 
[epoch 20] step 4/44: loss=8.1370 
[epoch 20] step 6/44: loss=8.0737 
[epoch 20] step 8/44: loss=8.0896 
[epoch 20] step 10/44: loss=8.0910 
[epoch 20] step 12/44: loss=8.2473 
[epoch 20] step 14/44: loss=8.0518 
[epoch 20] step 16/44: loss=7.9877 
[epoch 20] step 18/44: loss=7.9692 
[epoch 20] step 20/44: loss=7.9483 
[epoch 20] step 22/44: loss=7.9099 
[epoch 20] step 24/44: loss=7.9040 
[epoch 20] step 26/44: loss=7.8582 
[epoch 20] step 28/44: loss=7.8356 
[epoch 20] step 30/44: loss=7.8503 
[epoch 20] step 32/44: loss=7.9192 
[epoch 20] step 34/44: loss=7.9668 
[epoch 20] step 36/44: loss=7.9815 
[epoch 20] step 38/44: loss=7.9727 
[epoch 20] step 40/44: loss=7.9359 
[epoch 20] step 42/44: loss=7.9519 
[epoch 20] step 44/44: loss=7.9536 
[epoch 20] train_loss(avg per step)=15.9073 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=10.5533 qwk=('0.4566', '0.4934', '0.4979') averageQWK=0.4826 macroEMD=0.3698 tailR0=('0.0370', '0.1333', '0.0000') tailR0avg=0.0568
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     2    4   25    9    0
     1    8   78   40    1
     0    1   45   76    0
     0    0    3   22    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     1   10   26   11    0
     0    9   54   49    1
     0    0   37  109    2
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   46    5    0
     0   11   95   45    0
     0    1   29   69    0
     0    0    1    2    0
[epoch 21] step 2/44: loss=7.3791 
[epoch 21] step 4/44: loss=7.6366 
[epoch 21] step 6/44: loss=7.4291 
[epoch 21] step 8/44: loss=7.2803 
[epoch 21] step 10/44: loss=7.2511 
[epoch 21] step 12/44: loss=7.1548 
[epoch 21] step 14/44: loss=7.2468 
[epoch 21] step 16/44: loss=7.4135 
[epoch 21] step 18/44: loss=7.5971 
[epoch 21] step 20/44: loss=7.7695 
[epoch 21] step 22/44: loss=7.8327 
[epoch 21] step 24/44: loss=7.7652 
[epoch 21] step 26/44: loss=7.6875 
[epoch 21] step 28/44: loss=7.6375 
[epoch 21] step 30/44: loss=7.6230 
[epoch 21] step 32/44: loss=7.7065 
[epoch 21] step 34/44: loss=7.7470 
[epoch 21] step 36/44: loss=7.8346 
[epoch 21] step 38/44: loss=7.8738 
[epoch 21] step 40/44: loss=7.9052 
[epoch 21] step 42/44: loss=7.8830 
[epoch 21] step 44/44: loss=7.9481 
[epoch 21] train_loss(avg per step)=15.8963 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=10.5320 qwk=('0.4749', '0.4233', '0.4608') averageQWK=0.4530 macroEMD=0.3698 tailR0=('0.1435', '0.0000', '0.0000') tailR0avg=0.0478
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    0    0
     7    6   18    9    0
     6    8   70   43    1
     2    0   42   77    1
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     1    3   38    6    0
     4    4   71   34    0
     0    0   57   91    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   57    1    0
     0    8  117   26    0
     0    0   45   54    0
     0    0    2    1    0
[epoch 22] step 2/44: loss=7.8259 
[epoch 22] step 4/44: loss=7.6936 
[epoch 22] step 6/44: loss=7.6331 
[epoch 22] step 8/44: loss=7.4326 
[epoch 22] step 10/44: loss=7.2727 
[epoch 22] step 12/44: loss=7.1896 
[epoch 22] step 14/44: loss=7.2494 
[epoch 22] step 16/44: loss=7.3857 
[epoch 22] step 18/44: loss=7.4727 
[epoch 22] step 20/44: loss=7.5412 
[epoch 22] step 22/44: loss=7.5713 
[epoch 22] step 24/44: loss=7.5756 
[epoch 22] step 26/44: loss=7.6180 
[epoch 22] step 28/44: loss=7.6400 
[epoch 22] step 30/44: loss=7.6784 
[epoch 22] step 32/44: loss=7.6964 
[epoch 22] step 34/44: loss=7.7180 
[epoch 22] step 36/44: loss=7.7432 
[epoch 22] step 38/44: loss=7.7519 
[epoch 22] step 40/44: loss=7.7636 
[epoch 22] step 42/44: loss=7.7496 
[epoch 22] step 44/44: loss=7.7710 
[epoch 22] train_loss(avg per step)=15.5420 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=10.4603 qwk=('0.4766', '0.4611', '0.3994') averageQWK=0.4457 macroEMD=0.3697 tailR0=('0.0370', '0.0833', '0.0000') tailR0avg=0.0401
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     1   12   16   11    0
     1    8   47   69    3
     0    0   26   93    3
     0    0    1   24    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     2   15   12   19    0
     3   10   29   70    1
     0    2   16  130    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   38   15    0
     0   14   56   81    0
     0    1   18   80    0
     0    0    1    2    0
[epoch 23] step 2/44: loss=7.8900 
[epoch 23] step 4/44: loss=7.7965 
[epoch 23] step 6/44: loss=7.5955 
[epoch 23] step 8/44: loss=7.5261 
[epoch 23] step 10/44: loss=7.6481 
[epoch 23] step 12/44: loss=7.6327 
[epoch 23] step 14/44: loss=7.6101 
[epoch 23] step 16/44: loss=7.5819 
[epoch 23] step 18/44: loss=7.7414 
[epoch 23] step 20/44: loss=7.7535 
[epoch 23] step 22/44: loss=7.7134 
[epoch 23] step 24/44: loss=7.7219 
[epoch 23] step 26/44: loss=7.7298 
[epoch 23] step 28/44: loss=7.7172 
[epoch 23] step 30/44: loss=7.7936 
[epoch 23] step 32/44: loss=7.7649 
[epoch 23] step 34/44: loss=7.7810 
[epoch 23] step 36/44: loss=7.8043 
[epoch 23] step 38/44: loss=7.7925 
[epoch 23] step 40/44: loss=7.7547 
[epoch 23] step 42/44: loss=7.7207 
[epoch 23] step 44/44: loss=7.6938 
[epoch 23] train_loss(avg per step)=15.3877 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=10.2440 qwk=('0.4664', '0.5369', '0.5259') averageQWK=0.5097 macroEMD=0.3672 tailR0=('0.0185', '0.2167', '0.0000') tailR0avg=0.0784
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     3    8   21    8    0
     2    7   83   35    1
     1    0   44   74    3
     0    0    6   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     2   14   25    7    0
     3   12   53   44    1
     0    2   39  107    0
     0    0    0    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   23   48    0    0
     0   18   96   37    0
     0    2   34   63    0
     0    0    1    2    0
[epoch 24] step 2/44: loss=8.1286 
[epoch 24] step 4/44: loss=8.3810 
[epoch 24] step 6/44: loss=7.9636 
[epoch 24] step 8/44: loss=7.9335 
[epoch 24] step 10/44: loss=7.9403 
[epoch 24] step 12/44: loss=8.0352 
[epoch 24] step 14/44: loss=7.9199 
[epoch 24] step 16/44: loss=7.8394 
[epoch 24] step 18/44: loss=7.7495 
[epoch 24] step 20/44: loss=7.7598 
[epoch 24] step 22/44: loss=7.8573 
[epoch 24] step 24/44: loss=7.8503 
[epoch 24] step 26/44: loss=7.9609 
[epoch 24] step 28/44: loss=7.9429 
[epoch 24] step 30/44: loss=7.9190 
[epoch 24] step 32/44: loss=7.8846 
[epoch 24] step 34/44: loss=7.8897 
[epoch 24] step 36/44: loss=7.8717 
[epoch 24] step 38/44: loss=7.8720 
[epoch 24] step 40/44: loss=7.8760 
[epoch 24] step 42/44: loss=7.8489 
[epoch 24] step 44/44: loss=7.8392 
[epoch 24] train_loss(avg per step)=15.6785 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=10.4910 qwk=('0.4809', '0.4940', '0.5180') averageQWK=0.4977 macroEMD=0.3666 tailR0=('0.0185', '0.1333', '0.0000') tailR0avg=0.0506
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     1   12   17   10    0
     1    9   56   59    3
     0    0   33   87    2
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     1   15   23    9    0
     1   12   54   46    0
     1    3   38  106    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   27   37    7    0
     0   23   71   57    0
     0    1   22   76    0
     0    0    0    3    0
[epoch 25] step 2/44: loss=8.0755 
[epoch 25] step 4/44: loss=7.8096 
[epoch 25] step 6/44: loss=7.8694 
[epoch 25] step 8/44: loss=7.9101 
[epoch 25] step 10/44: loss=7.8039 
[epoch 25] step 12/44: loss=7.6884 
[epoch 25] step 14/44: loss=7.7990 
[epoch 25] step 16/44: loss=7.8895 
[epoch 25] step 18/44: loss=7.9140 
[epoch 25] step 20/44: loss=7.9138 
[epoch 25] step 22/44: loss=7.9050 
[epoch 25] step 24/44: loss=7.8931 
[epoch 25] step 26/44: loss=7.9466 
[epoch 25] step 28/44: loss=7.9213 
[epoch 25] step 30/44: loss=7.9771 
[epoch 25] step 32/44: loss=8.0372 
[epoch 25] step 34/44: loss=8.0440 
[epoch 25] step 36/44: loss=7.9934 
[epoch 25] step 38/44: loss=7.9230 
[epoch 25] step 40/44: loss=7.8982 
[epoch 25] step 42/44: loss=7.8998 
[epoch 25] step 44/44: loss=7.8330 
[epoch 25] train_loss(avg per step)=15.6660 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=10.5603 qwk=('0.4848', '0.5099', '0.4706') averageQWK=0.4884 macroEMD=0.3691 tailR0=('0.0185', '0.1833', '0.0000') tailR0avg=0.0673
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     4   11   15   10    0
     3   15   50   57    3
     0    2   33   87    0
     0    0    1   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     1   16   23    8    0
     3   15   51   43    1
     0    5   38  105    0
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   12   57    2    0
     0    6  107   38    0
     0    1   33   65    0
     0    0    1    2    0
[epoch 26] step 2/44: loss=7.2702 
[epoch 26] step 4/44: loss=7.7288 
[epoch 26] step 6/44: loss=7.7632 
[epoch 26] step 8/44: loss=8.0446 
[epoch 26] step 10/44: loss=8.1242 
[epoch 26] step 12/44: loss=8.1907 
[epoch 26] step 14/44: loss=8.1412 
[epoch 26] step 16/44: loss=8.1255 
[epoch 26] step 18/44: loss=8.0402 
[epoch 26] step 20/44: loss=8.0584 
[epoch 26] step 22/44: loss=8.0862 
[epoch 26] step 24/44: loss=8.0143 
[epoch 26] step 26/44: loss=7.9110 
[epoch 26] step 28/44: loss=7.8417 
[epoch 26] step 30/44: loss=7.8882 
[epoch 26] step 32/44: loss=7.8656 
[epoch 26] step 34/44: loss=7.8929 
[epoch 26] step 36/44: loss=7.9406 
[epoch 26] step 38/44: loss=7.9824 
[epoch 26] step 40/44: loss=7.9550 
[epoch 26] step 42/44: loss=7.9450 
[epoch 26] step 44/44: loss=7.9255 
[epoch 26] train_loss(avg per step)=15.8511 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=10.7286 qwk=('0.4305', '0.4634', '0.4765') averageQWK=0.4568 macroEMD=0.3710 tailR0=('0.0556', '0.2667', '0.0000') tailR0avg=0.1074
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     2   11   17   10    0
     3   15   52   52    6
     2    2   37   78    3
     0    0    1   23    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     5   13   20   10    0
     7   13   48   44    1
     4    4   34  106    0
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   38    7    0
     0   35   65   51    0
     0    3   23   73    0
     0    0    1    2    0
[epoch 27] step 2/44: loss=7.4222 
[epoch 27] step 4/44: loss=7.1919 
[epoch 27] step 6/44: loss=7.5028 
[epoch 27] step 8/44: loss=7.6007 
[epoch 27] step 10/44: loss=7.6465 
[epoch 27] step 12/44: loss=7.6110 
[epoch 27] step 14/44: loss=7.6318 
[epoch 27] step 16/44: loss=7.7073 
[epoch 27] step 18/44: loss=7.6696 
[epoch 27] step 20/44: loss=7.7595 
[epoch 27] step 22/44: loss=7.7493 
[epoch 27] step 24/44: loss=7.8292 
[epoch 27] step 26/44: loss=7.8737 
[epoch 27] step 28/44: loss=7.8771 
[epoch 27] step 30/44: loss=7.8897 
[epoch 27] step 32/44: loss=7.8787 
[epoch 27] step 34/44: loss=7.8841 
[epoch 27] step 36/44: loss=7.8692 
[epoch 27] step 38/44: loss=7.8175 
[epoch 27] step 40/44: loss=7.8085 
[epoch 27] step 42/44: loss=7.8143 
[epoch 27] step 44/44: loss=7.8187 
[epoch 27] train_loss(avg per step)=15.6373 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=10.5321 qwk=('0.4696', '0.5100', '0.4900') averageQWK=0.4899 macroEMD=0.3694 tailR0=('0.0370', '0.2667', '0.0000') tailR0avg=0.1012
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     2    9   20    9    0
     1    8   65   49    5
     0    0   39   79    4
     0    0    2   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     1   10   27   10    0
     3    9   56   44    1
     0    1   38  108    1
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   42    5    0
     0   28   78   45    0
     0    2   28   69    0
     0    0    1    2    0
[epoch 28] step 2/44: loss=8.2166 
[epoch 28] step 4/44: loss=8.3249 
[epoch 28] step 6/44: loss=8.2690 
[epoch 28] step 8/44: loss=7.9302 
[epoch 28] step 10/44: loss=7.8375 
[epoch 28] step 12/44: loss=7.8940 
[epoch 28] step 14/44: loss=7.8170 
[epoch 28] step 16/44: loss=7.7846 
[epoch 28] step 18/44: loss=7.7778 
[epoch 28] step 20/44: loss=7.7611 
[epoch 28] step 22/44: loss=7.7893 
[epoch 28] step 24/44: loss=7.8232 
[epoch 28] step 26/44: loss=7.8102 
[epoch 28] step 28/44: loss=7.8023 
[epoch 28] step 30/44: loss=7.8112 
[epoch 28] step 32/44: loss=7.8283 
[epoch 28] step 34/44: loss=7.7999 
[epoch 28] step 36/44: loss=7.8055 
[epoch 28] step 38/44: loss=7.8059 
[epoch 28] step 40/44: loss=7.8087 
[epoch 28] step 42/44: loss=7.8391 
[epoch 28] step 44/44: loss=7.8602 
[epoch 28] train_loss(avg per step)=15.7204 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=10.6873 qwk=('0.4612', '0.4734', '0.4791') averageQWK=0.4712 macroEMD=0.3702 tailR0=('0.0185', '0.2167', '0.0000') tailR0avg=0.0784
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     1   13   15   11    0
     1   18   48   56    5
     0    4   28   89    1
     0    0    1   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     1    9   29    9    0
     2    7   59   44    1
     0    3   42  103    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   18   49    4    0
     0   20   79   52    0
     0    1   25   73    0
     0    0    1    2    0
[epoch 29] step 2/44: loss=7.9597 
[epoch 29] step 4/44: loss=7.8945 
[epoch 29] step 6/44: loss=7.8762 
[epoch 29] step 8/44: loss=7.7911 
[epoch 29] step 10/44: loss=7.6446 
[epoch 29] step 12/44: loss=7.6462 
[epoch 29] step 14/44: loss=7.8598 
[epoch 29] step 16/44: loss=7.9425 
[epoch 29] step 18/44: loss=8.0085 
[epoch 29] step 20/44: loss=7.9221 
[epoch 29] step 22/44: loss=7.8048 
[epoch 29] step 24/44: loss=7.7344 
[epoch 29] step 26/44: loss=7.6760 
[epoch 29] step 28/44: loss=7.6584 
[epoch 29] step 30/44: loss=7.6620 
[epoch 29] step 32/44: loss=7.6752 
[epoch 29] step 34/44: loss=7.7540 
[epoch 29] step 36/44: loss=7.7471 
[epoch 29] step 38/44: loss=7.7676 
[epoch 29] step 40/44: loss=7.8017 
[epoch 29] step 42/44: loss=7.8114 
[epoch 29] step 44/44: loss=7.8224 
[epoch 29] train_loss(avg per step)=15.6449 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=10.6558 qwk=('0.4463', '0.5188', '0.5248') averageQWK=0.4966 macroEMD=0.3700 tailR0=('0.0741', '0.2167', '0.5000') tailR0avg=0.2636
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     1   12   18    9    0
     3   16   64   40    5
     0    4   40   72    6
     0    0    5   18    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     1   14   25    8    0
     3   10   57   42    1
     0    1   43  101    3
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    0    0    0
     0   26   43    2    0
     0   23   84   44    0
     0    2   31   66    0
     0    0    1    2    0
[epoch 30] step 2/44: loss=7.8149 
[epoch 30] step 4/44: loss=8.2315 
[epoch 30] step 6/44: loss=8.1665 
[epoch 30] step 8/44: loss=8.1428 
[epoch 30] step 10/44: loss=7.9765 
[epoch 30] step 12/44: loss=8.0516 
[epoch 30] step 14/44: loss=8.1075 
[epoch 30] step 16/44: loss=8.0893 
[epoch 30] step 18/44: loss=8.1043 
[epoch 30] step 20/44: loss=8.0731 
[epoch 30] step 22/44: loss=8.0005 
[epoch 30] step 24/44: loss=7.9301 
[epoch 30] step 26/44: loss=7.8153 
[epoch 30] step 28/44: loss=7.7293 
[epoch 30] step 30/44: loss=7.7072 
[epoch 30] step 32/44: loss=7.6998 
[epoch 30] step 34/44: loss=7.6697 
[epoch 30] step 36/44: loss=7.7208 
[epoch 30] step 38/44: loss=7.7847 
[epoch 30] step 40/44: loss=7.8350 
[epoch 30] step 42/44: loss=7.8566 
[epoch 30] step 44/44: loss=7.9500 
[epoch 30] train_loss(avg per step)=15.9001 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=10.7738 qwk=('0.4460', '0.4731', '0.5370') averageQWK=0.4854 macroEMD=0.3706 tailR0=('0.0741', '0.1000', '0.5000') tailR0avg=0.2247
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    7   24    9    0
     1    8   68   46    5
     0    0   40   77    5
     0    0    4   19    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0   16   22   10    0
     0   16   52   44    1
     0    5   37  106    0
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    0    0    0
     0   27   41    3    0
     0   28   80   43    0
     0    2   26   71    0
     0    0    1    2    0
[epoch 31] step 2/44: loss=8.3719 
[epoch 31] step 4/44: loss=8.3069 
[epoch 31] step 6/44: loss=8.0846 
[epoch 31] step 8/44: loss=7.6855 
[epoch 31] step 10/44: loss=7.5397 
[epoch 31] step 12/44: loss=7.3279 
[epoch 31] step 14/44: loss=7.3902 
[epoch 31] step 16/44: loss=7.3813 
[epoch 31] step 18/44: loss=7.4161 
[epoch 31] step 20/44: loss=7.4807 
[epoch 31] step 22/44: loss=7.5057 
[epoch 31] step 24/44: loss=7.5320 
[epoch 31] step 26/44: loss=7.5546 
[epoch 31] step 28/44: loss=7.5886 
[epoch 31] step 30/44: loss=7.6431 
[epoch 31] step 32/44: loss=7.6416 
[epoch 31] step 34/44: loss=7.6648 
[epoch 31] step 36/44: loss=7.6688 
[epoch 31] step 38/44: loss=7.6594 
[epoch 31] step 40/44: loss=7.6935 
[epoch 31] step 42/44: loss=7.6959 
[epoch 31] step 44/44: loss=7.7153 
[epoch 31] train_loss(avg per step)=15.4305 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=10.3510 qwk=('0.4247', '0.4944', '0.5225') averageQWK=0.4805 macroEMD=0.3699 tailR0=('0.0556', '0.1000', '0.5000') tailR0avg=0.2185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     1    7   23    9    0
     2    8   72   42    4
     0    1   45   70    6
     0    0    6   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0   15   24    9    0
     0   13   56   43    1
     0    3   38  104    3
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    0    0    0
     0   26   43    2    0
     0   23   85   43    0
     0    2   32   65    0
     0    0    1    2    0
[epoch 32] step 2/44: loss=8.1317 
[epoch 32] step 4/44: loss=8.2351 
[epoch 32] step 6/44: loss=8.1115 
[epoch 32] step 8/44: loss=8.1269 
[epoch 32] step 10/44: loss=8.2919 
[epoch 32] step 12/44: loss=8.2196 
[epoch 32] step 14/44: loss=8.1950 
[epoch 32] step 16/44: loss=8.1173 
[epoch 32] step 18/44: loss=8.0498 
[epoch 32] step 20/44: loss=8.0117 
[epoch 32] step 22/44: loss=7.9595 
[epoch 32] step 24/44: loss=7.9571 
[epoch 32] step 26/44: loss=7.9577 
[epoch 32] step 28/44: loss=7.9154 
[epoch 32] step 30/44: loss=7.8671 
[epoch 32] step 32/44: loss=7.8716 
[epoch 32] step 34/44: loss=7.8679 
[epoch 32] step 36/44: loss=7.8410 
[epoch 32] step 38/44: loss=7.8216 
[epoch 32] step 40/44: loss=7.8798 
[epoch 32] step 42/44: loss=7.8557 
[epoch 32] step 44/44: loss=7.8625 
[epoch 32] train_loss(avg per step)=15.7251 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=10.6283 qwk=('0.4480', '0.5024', '0.5267') averageQWK=0.4924 macroEMD=0.3701 tailR0=('0.0370', '0.2167', '0.5000') tailR0avg=0.2512
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     2   10   17   11    0
     2    9   63   49    5
     1    1   35   80    5
     0    0    2   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     1   13   25    9    0
     2   10   57   43    1
     0    3   39  106    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    0    0    0
     0   24   45    2    0
     0   27   80   44    0
     0    2   27   70    0
     0    0    1    2    0
[epoch 33] step 2/44: loss=7.9103 
[epoch 33] step 4/44: loss=7.8927 
[epoch 33] step 6/44: loss=7.8460 
[epoch 33] step 8/44: loss=7.8671 
[epoch 33] step 10/44: loss=7.9088 
[epoch 33] step 12/44: loss=7.8965 
[epoch 33] step 14/44: loss=7.8929 
[epoch 33] step 16/44: loss=7.8899 
[epoch 33] step 18/44: loss=7.8766 
[epoch 33] step 20/44: loss=7.8879 
[epoch 33] step 22/44: loss=7.9383 
[epoch 33] step 24/44: loss=7.9784 
[epoch 33] step 26/44: loss=7.9538 
[epoch 33] step 28/44: loss=7.9430 
[epoch 33] step 30/44: loss=7.9387 
[epoch 33] step 32/44: loss=7.9415 
[epoch 33] step 34/44: loss=8.0013 
[epoch 33] step 36/44: loss=7.9926 
[epoch 33] step 38/44: loss=7.9680 
[epoch 33] step 40/44: loss=8.0104 
[epoch 33] step 42/44: loss=7.9987 
[epoch 33] step 44/44: loss=7.9826 
[epoch 33] train_loss(avg per step)=15.9652 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=10.8292 qwk=('0.4506', '0.5166', '0.5279') averageQWK=0.4984 macroEMD=0.3707 tailR0=('0.0370', '0.2667', '0.5000') tailR0avg=0.2679
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     2    8   21    9    0
     3    8   73   40    4
     0    0   46   73    3
     0    0    4   21    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     1   12   27    8    0
     3    9   59   41    1
     0    1   46   99    2
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    0    0    0
     0   27   43    1    0
     0   26   87   38    0
     0    2   35   62    0
     0    0    1    2    0
[epoch 34] step 2/44: loss=7.7841 
[epoch 34] step 4/44: loss=7.5000 
[epoch 34] step 6/44: loss=7.3021 
[epoch 34] step 8/44: loss=7.3187 
[epoch 34] step 10/44: loss=7.3074 
[epoch 34] step 12/44: loss=7.3035 
[epoch 34] step 14/44: loss=7.4001 
[epoch 34] step 16/44: loss=7.3949 
[epoch 34] step 18/44: loss=7.5389 
[epoch 34] step 20/44: loss=7.6398 
[epoch 34] step 22/44: loss=7.6596 
[epoch 34] step 24/44: loss=7.7347 
[epoch 34] step 26/44: loss=7.7730 
[epoch 34] step 28/44: loss=7.8210 
[epoch 34] step 30/44: loss=7.8412 
[epoch 34] step 32/44: loss=7.8267 
[epoch 34] step 34/44: loss=7.8315 
[epoch 34] step 36/44: loss=7.8209 
[epoch 34] step 38/44: loss=7.7987 
[epoch 34] step 40/44: loss=7.8048 
[epoch 34] step 42/44: loss=7.8137 
[epoch 34] step 44/44: loss=7.8816 
[epoch 34] train_loss(avg per step)=15.7632 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=10.6048 qwk=('0.4580', '0.4954', '0.5310') averageQWK=0.4948 macroEMD=0.3703 tailR0=('0.0741', '0.1833', '0.5000') tailR0avg=0.2525
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     2    9   20    9    0
     2   10   68   43    5
     1    1   40   75    5
     0    0    3   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1   14   25    8    0
     3   11   56   42    1
     0    3   44   99    2
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    0    0    0
     0   26   42    3    0
     0   29   81   41    0
     0    2   27   70    0
     0    0    1    2    0
[epoch 35] step 2/44: loss=8.8366 
[epoch 35] step 4/44: loss=8.5565 
[epoch 35] step 6/44: loss=8.2551 
[epoch 35] step 8/44: loss=8.0929 
[epoch 35] step 10/44: loss=8.1198 
[epoch 35] step 12/44: loss=8.0683 
[epoch 35] step 14/44: loss=8.0589 
[epoch 35] step 16/44: loss=7.9696 
[epoch 35] step 18/44: loss=7.9365 
[epoch 35] step 20/44: loss=7.9587 
[epoch 35] step 22/44: loss=7.9516 
[epoch 35] step 24/44: loss=7.9123 
[epoch 35] step 26/44: loss=7.8562 
[epoch 35] step 28/44: loss=7.8454 
[epoch 35] step 30/44: loss=7.8331 
[epoch 35] step 32/44: loss=7.8138 
[epoch 35] step 34/44: loss=7.7954 
[epoch 35] step 36/44: loss=7.8242 
[epoch 35] step 38/44: loss=7.8027 
[epoch 35] step 40/44: loss=7.8365 
[epoch 35] step 42/44: loss=7.8412 
[epoch 35] step 44/44: loss=7.8477 
[epoch 35] train_loss(avg per step)=15.6954 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=10.6769 qwk=('0.4611', '0.4614', '0.5286') averageQWK=0.4837 macroEMD=0.3705 tailR0=('0.0370', '0.1000', '0.5000') tailR0avg=0.2123
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     2    8   21    9    0
     3    9   68   44    4
     0    0   39   80    3
     0    0    4   21    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     1   13   24   10    0
     3    9   56   44    1
     0    3   42  102    1
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    0    0    0
     0   24   45    2    0
     0   22   87   42    0
     0    2   29   68    0
     0    0    1    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-1-reassignment-1/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-1-reassignment-1/fold3/metrics.json
Done.
