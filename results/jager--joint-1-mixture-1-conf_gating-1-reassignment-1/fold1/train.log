[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.5408 
[epoch 1] step 4/44: loss=6.0926 
[epoch 1] step 6/44: loss=5.8834 
[epoch 1] step 8/44: loss=5.8741 
[epoch 1] step 10/44: loss=5.9563 
[epoch 1] step 12/44: loss=5.8713 
[epoch 1] step 14/44: loss=5.8778 
[epoch 1] step 16/44: loss=5.9176 
[epoch 1] step 18/44: loss=5.9410 
[epoch 1] step 20/44: loss=5.9431 
[epoch 1] step 22/44: loss=5.9802 
[epoch 1] step 24/44: loss=6.0076 
[epoch 1] step 26/44: loss=6.0043 
[epoch 1] step 28/44: loss=6.0315 
[epoch 1] step 30/44: loss=6.0629 
[epoch 1] step 32/44: loss=6.0779 
[epoch 1] step 34/44: loss=6.1187 
[epoch 1] step 36/44: loss=6.1552 
[epoch 1] step 38/44: loss=6.1709 
[epoch 1] step 40/44: loss=6.2418 
[epoch 1] step 42/44: loss=6.2922 
[epoch 1] step 44/44: loss=6.3013 
[epoch 1] train_loss(avg per step)=12.6026 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=6.7571 qwk=('0.0176', '0.0413', '0.0157') averageQWK=0.0249 macroEMD=0.3903 tailR0=('0.0000', '0.0385', '0.0000') tailR0avg=0.0128
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    0    3    0
     0   38    0    3    0
     0   98    0   24    0
     0  117    0   24    0
     0   16    0    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0   12    0    0
     8    0   31    0    0
    20    0   81    3    0
    24    0  135    4    0
     1    0   14    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    6   46    0    0
     0    7  151    0    0
     0    9  101    0    0
     0    1    2    0    0
[epoch 2] step 2/44: loss=9.4902 
[epoch 2] step 4/44: loss=9.7215 
[epoch 2] step 6/44: loss=9.8090 
[epoch 2] step 8/44: loss=9.8454 
[epoch 2] step 10/44: loss=10.0629 
[epoch 2] step 12/44: loss=10.2105 
[epoch 2] step 14/44: loss=10.2794 
[epoch 2] step 16/44: loss=10.3796 
[epoch 2] step 18/44: loss=10.4514 
[epoch 2] step 20/44: loss=10.5319 
[epoch 2] step 22/44: loss=10.6033 
[epoch 2] step 24/44: loss=10.7201 
[epoch 2] step 26/44: loss=10.8240 
[epoch 2] step 28/44: loss=10.9240 
[epoch 2] step 30/44: loss=10.9823 
[epoch 2] step 32/44: loss=11.0009 
[epoch 2] step 34/44: loss=11.0633 
[epoch 2] step 36/44: loss=11.1248 
[epoch 2] step 38/44: loss=11.2287 
[epoch 2] step 40/44: loss=11.3295 
[epoch 2] step 42/44: loss=11.4401 
[epoch 2] step 44/44: loss=11.5762 
[epoch 2] train_loss(avg per step)=23.1524 lambda[min,max]=[0.500122,1.000000]
[epoch 2] val_loss=12.9426 qwk=('0.2761', '0.2468', '0.0000') averageQWK=0.1743 macroEMD=0.3938 tailR0=('0.2000', '0.0000', '0.0000') tailR0avg=0.0667
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    1    5    0    0
    15    0   26    0    0
    20    0  102    0    0
    11    0  109   21    0
     0    0   18    3    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    1    0
     0    0   37    2    0
     0    0   97    7    0
     0    0  109   54    0
     0    0    6   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    0   52    0    0
     0    0  158    0    0
     0    0  110    0    0
     0    0    3    0    0
[epoch 3] step 2/44: loss=12.6500 
[epoch 3] step 4/44: loss=12.7682 
[epoch 3] step 6/44: loss=12.4469 
[epoch 3] step 8/44: loss=12.5836 
[epoch 3] step 10/44: loss=12.6742 
[epoch 3] step 12/44: loss=12.7422 
[epoch 3] step 14/44: loss=12.7707 
[epoch 3] step 16/44: loss=12.8246 
[epoch 3] step 18/44: loss=12.7556 
[epoch 3] step 20/44: loss=12.7092 
[epoch 3] step 22/44: loss=12.7124 
[epoch 3] step 24/44: loss=12.7724 
[epoch 3] step 26/44: loss=12.8324 
[epoch 3] step 28/44: loss=12.8530 
[epoch 3] step 30/44: loss=12.8435 
[epoch 3] step 32/44: loss=12.8221 
[epoch 3] step 34/44: loss=12.7766 
[epoch 3] step 36/44: loss=12.8207 
[epoch 3] step 38/44: loss=12.7864 
[epoch 3] step 40/44: loss=12.8315 
[epoch 3] step 42/44: loss=12.7862 
[epoch 3] step 44/44: loss=12.8288 
[epoch 3] train_loss(avg per step)=25.6576 lambda[min,max]=[0.525188,1.000000]
[epoch 3] val_loss=14.3433 qwk=('0.1025', '0.5176', '0.0268') averageQWK=0.2156 macroEMD=0.3894 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    0   41    0    0
     0    0  122    0    0
     0    0  121   20    0
     0    0   19    2    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   11    1    1    0
     0   35    3    1    0
     0   55   31   18    0
     0   30   34   99    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    0   52    0    0
     0    0  158    0    0
     0    0  109    1    0
     0    0    3    0    0
[epoch 4] step 2/44: loss=12.1992 
[epoch 4] step 4/44: loss=12.2052 
[epoch 4] step 6/44: loss=12.4041 
[epoch 4] step 8/44: loss=12.6288 
[epoch 4] step 10/44: loss=12.6425 
[epoch 4] step 12/44: loss=12.5952 
[epoch 4] step 14/44: loss=12.4935 
[epoch 4] step 16/44: loss=12.3651 
[epoch 4] step 18/44: loss=12.3172 
[epoch 4] step 20/44: loss=12.2703 
[epoch 4] step 22/44: loss=12.1795 
[epoch 4] step 24/44: loss=12.1974 
[epoch 4] step 26/44: loss=12.2325 
[epoch 4] step 28/44: loss=12.2650 
[epoch 4] step 30/44: loss=12.2050 
[epoch 4] step 32/44: loss=12.1326 
[epoch 4] step 34/44: loss=12.0971 
[epoch 4] step 36/44: loss=12.1725 
[epoch 4] step 38/44: loss=12.1422 
[epoch 4] step 40/44: loss=12.0739 
[epoch 4] step 42/44: loss=11.9836 
[epoch 4] step 44/44: loss=11.9526 
[epoch 4] train_loss(avg per step)=23.9051 lambda[min,max]=[0.512179,1.000000]
[epoch 4] val_loss=13.5399 qwk=('0.3287', '0.1053', '0.2224') averageQWK=0.2188 macroEMD=0.3878 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0    6   35    0    0
     3    1   93   23    2
     7    0   53   78    3
     0    0    8   13    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    9    0
     0    0    4   35    0
     0    0    8   96    0
     0    0    0  163    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    1    0
     0    0   20   32    0
     0    0   27  131    0
     0    0    1  109    0
     0    0    0    3    0
[epoch 5] step 2/44: loss=11.2119 
[epoch 5] step 4/44: loss=11.0525 
[epoch 5] step 6/44: loss=11.1811 
[epoch 5] step 8/44: loss=11.2840 
[epoch 5] step 10/44: loss=11.1579 
[epoch 5] step 12/44: loss=11.1242 
[epoch 5] step 14/44: loss=10.9641 
[epoch 5] step 16/44: loss=10.7918 
[epoch 5] step 18/44: loss=10.7689 
[epoch 5] step 20/44: loss=10.7770 
[epoch 5] step 22/44: loss=10.7766 
[epoch 5] step 24/44: loss=10.9312 
[epoch 5] step 26/44: loss=11.0454 
[epoch 5] step 28/44: loss=11.0749 
[epoch 5] step 30/44: loss=10.9820 
[epoch 5] step 32/44: loss=10.8294 
[epoch 5] step 34/44: loss=10.7269 
[epoch 5] step 36/44: loss=10.6608 
[epoch 5] step 38/44: loss=10.6099 
[epoch 5] step 40/44: loss=10.6242 
[epoch 5] step 42/44: loss=10.6885 
[epoch 5] step 44/44: loss=10.8015 
[epoch 5] train_loss(avg per step)=21.6030 lambda[min,max]=[0.501715,1.000000]
[epoch 5] val_loss=11.9673 qwk=('0.4034', '0.2915', '0.3802') averageQWK=0.3584 macroEMD=0.3839 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    1    0
     0    0   36    5    0
     0    0   66   56    0
     0    0   27  114    0
     0    0    3   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   12    0    0
     0    0   36    3    0
     0    0   88   16    0
     1    0   85   77    0
     0    0    8    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    0   49    3    0
     0    0  128   30    0
     0    0   44   66    0
     0    0    1    2    0
[epoch 6] step 2/44: loss=10.0806 
[epoch 6] step 4/44: loss=9.1202 
[epoch 6] step 6/44: loss=9.3373 
[epoch 6] step 8/44: loss=9.1354 
[epoch 6] step 10/44: loss=8.9318 
[epoch 6] step 12/44: loss=9.1881 
[epoch 6] step 14/44: loss=9.3835 
[epoch 6] step 16/44: loss=9.4410 
[epoch 6] step 18/44: loss=9.4031 
[epoch 6] step 20/44: loss=9.3280 
[epoch 6] step 22/44: loss=9.2749 
[epoch 6] step 24/44: loss=9.2885 
[epoch 6] step 26/44: loss=9.2400 
[epoch 6] step 28/44: loss=9.2620 
[epoch 6] step 30/44: loss=9.3021 
[epoch 6] step 32/44: loss=9.3727 
[epoch 6] step 34/44: loss=9.4017 
[epoch 6] step 36/44: loss=9.3296 
[epoch 6] step 38/44: loss=9.2066 
[epoch 6] step 40/44: loss=9.1437 
[epoch 6] step 42/44: loss=9.1379 
[epoch 6] step 44/44: loss=9.2173 
[epoch 6] train_loss(avg per step)=18.4346 lambda[min,max]=[0.500016,1.000000]
[epoch 6] val_loss=10.4655 qwk=('0.0951', '0.5475', '0.5295') averageQWK=0.3907 macroEMD=0.3759 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    4   37    0    0
     0    1  121    0    0
     0    0  130   11    0
     0    0   21    0    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   12    1    0    0
     0   33    3    3    0
     0   66    7   31    0
     0   24   23  116    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   12    0    0    0
     0   38   11    3    0
     0   58   80   20    0
     0    8   49   53    0
     0    0    1    2    0
[epoch 7] step 2/44: loss=11.2698 
[epoch 7] step 4/44: loss=11.0256 
[epoch 7] step 6/44: loss=10.5773 
[epoch 7] step 8/44: loss=10.4172 
[epoch 7] step 10/44: loss=10.1834 
[epoch 7] step 12/44: loss=10.0815 
[epoch 7] step 14/44: loss=9.9695 
[epoch 7] step 16/44: loss=9.7537 
[epoch 7] step 18/44: loss=9.4919 
[epoch 7] step 20/44: loss=9.3835 
[epoch 7] step 22/44: loss=9.3004 
[epoch 7] step 24/44: loss=9.1741 
[epoch 7] step 26/44: loss=9.0447 
[epoch 7] step 28/44: loss=8.9916 
[epoch 7] step 30/44: loss=8.9965 
[epoch 7] step 32/44: loss=9.0113 
[epoch 7] step 34/44: loss=9.0070 
[epoch 7] step 36/44: loss=8.9464 
[epoch 7] step 38/44: loss=8.9168 
[epoch 7] step 40/44: loss=8.9292 
[epoch 7] step 42/44: loss=8.9321 
[epoch 7] step 44/44: loss=8.9792 
[epoch 7] train_loss(avg per step)=17.9585 lambda[min,max]=[0.500001,1.000000]
[epoch 7] val_loss=10.5544 qwk=('0.4127', '0.3011', '0.4184') averageQWK=0.3774 macroEMD=0.3808 tailR0=('0.2143', '0.0000', '0.0000') tailR0avg=0.0714
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    1    0
     0    1   35    2    3
     0    0   77   33   12
     0    0   34   86   21
     0    0    2   10    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    4    0
     0    0   20   19    0
     0    0   39   65    0
     0    0   13  150    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    0   43    9    0
     0    0  100   58    0
     0    0   17   93    0
     0    0    0    3    0
[epoch 8] step 2/44: loss=8.4694 
[epoch 8] step 4/44: loss=8.7972 
[epoch 8] step 6/44: loss=8.5136 
[epoch 8] step 8/44: loss=8.2365 
[epoch 8] step 10/44: loss=8.1599 
[epoch 8] step 12/44: loss=8.1339 
[epoch 8] step 14/44: loss=8.2918 
[epoch 8] step 16/44: loss=8.4171 
[epoch 8] step 18/44: loss=8.4323 
[epoch 8] step 20/44: loss=8.3038 
[epoch 8] step 22/44: loss=8.3898 
[epoch 8] step 24/44: loss=8.4290 
[epoch 8] step 26/44: loss=8.4628 
[epoch 8] step 28/44: loss=8.3902 
[epoch 8] step 30/44: loss=8.3095 
[epoch 8] step 32/44: loss=8.2198 
[epoch 8] step 34/44: loss=8.2191 
[epoch 8] step 36/44: loss=8.2481 
[epoch 8] step 38/44: loss=8.2351 
[epoch 8] step 40/44: loss=8.2545 
[epoch 8] step 42/44: loss=8.2621 
[epoch 8] step 44/44: loss=8.2224 
[epoch 8] train_loss(avg per step)=16.4448 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=10.0631 qwk=('0.0042', '0.4164', '0.3665') averageQWK=0.2624 macroEMD=0.3760 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    0   41    0    0
     0    0  122    0    0
     0    0  140    1    0
     0    0   21    0    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    1    0
     0    6   33    0    0
     0   12   76   16    0
     0    3   77   83    0
     0    0    5   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    9   41    2    0
     0    6  143    9    0
     0    2   71   37    0
     0    0    1    2    0
[epoch 9] step 2/44: loss=9.4651 
[epoch 9] step 4/44: loss=8.8775 
[epoch 9] step 6/44: loss=8.4140 
[epoch 9] step 8/44: loss=8.0894 
[epoch 9] step 10/44: loss=8.3432 
[epoch 9] step 12/44: loss=8.4726 
[epoch 9] step 14/44: loss=8.3774 
[epoch 9] step 16/44: loss=8.2411 
[epoch 9] step 18/44: loss=8.1372 
[epoch 9] step 20/44: loss=8.0816 
[epoch 9] step 22/44: loss=8.1359 
[epoch 9] step 24/44: loss=8.1363 
[epoch 9] step 26/44: loss=8.1446 
[epoch 9] step 28/44: loss=8.1290 
[epoch 9] step 30/44: loss=8.0545 
[epoch 9] step 32/44: loss=8.0438 
[epoch 9] step 34/44: loss=8.0568 
[epoch 9] step 36/44: loss=8.1442 
[epoch 9] step 38/44: loss=8.1696 
[epoch 9] step 40/44: loss=8.1642 
[epoch 9] step 42/44: loss=8.0710 
[epoch 9] step 44/44: loss=7.9807 
[epoch 9] train_loss(avg per step)=15.9614 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=9.8250 qwk=('0.4802', '0.4396', '0.4911') averageQWK=0.4703 macroEMD=0.3773 tailR0=('0.0000', '0.0769', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   31    9    1    0
     1   50   45   24    2
     1   19   37   82    2
     0    0    8   13    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0   10    1    0
     4    1   33    1    0
     1    1   76   26    0
     2    0   59  102    0
     0    0    4   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   12    0    0    0
     0   31    6   15    0
     0   53   20   85    0
     0    8    5   97    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=7.1295 
[epoch 10] step 4/44: loss=7.2361 
[epoch 10] step 6/44: loss=7.2701 
[epoch 10] step 8/44: loss=7.8472 
[epoch 10] step 10/44: loss=8.1709 
[epoch 10] step 12/44: loss=8.3409 
[epoch 10] step 14/44: loss=8.4260 
[epoch 10] step 16/44: loss=8.3257 
[epoch 10] step 18/44: loss=8.1994 
[epoch 10] step 20/44: loss=8.0541 
[epoch 10] step 22/44: loss=7.9863 
[epoch 10] step 24/44: loss=7.9743 
[epoch 10] step 26/44: loss=7.9679 
[epoch 10] step 28/44: loss=8.0374 
[epoch 10] step 30/44: loss=8.0304 
[epoch 10] step 32/44: loss=8.0511 
[epoch 10] step 34/44: loss=8.1021 
[epoch 10] step 36/44: loss=8.1770 
[epoch 10] step 38/44: loss=8.2166 
[epoch 10] step 40/44: loss=8.2269 
[epoch 10] step 42/44: loss=8.1756 
[epoch 10] step 44/44: loss=8.0370 
[epoch 10] train_loss(avg per step)=16.0739 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=10.1263 qwk=('0.5024', '0.3156', '0.5014') averageQWK=0.4398 macroEMD=0.3802 tailR0=('0.0000', '0.0769', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    2    0
     0   23   10    8    0
     0   39   23   59    1
     0    9   12  120    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    6    5    0
     4    2    7   26    0
     5   10   28   61    0
     2    0   12  149    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   12    0    0    0
     0   26   14   12    0
     0   39   49   70    0
     0    9    9   92    0
     0    0    0    3    0
[epoch 11] step 2/44: loss=5.9457 
[epoch 11] step 4/44: loss=6.1459 
[epoch 11] step 6/44: loss=6.5333 
[epoch 11] step 8/44: loss=6.9989 
[epoch 11] step 10/44: loss=7.5818 
[epoch 11] step 12/44: loss=7.7857 
[epoch 11] step 14/44: loss=7.7800 
[epoch 11] step 16/44: loss=7.6542 
[epoch 11] step 18/44: loss=7.6129 
[epoch 11] step 20/44: loss=7.5760 
[epoch 11] step 22/44: loss=7.5940 
[epoch 11] step 24/44: loss=7.7793 
[epoch 11] step 26/44: loss=7.9929 
[epoch 11] step 28/44: loss=8.1216 
[epoch 11] step 30/44: loss=8.1497 
[epoch 11] step 32/44: loss=8.0661 
[epoch 11] step 34/44: loss=7.9650 
[epoch 11] step 36/44: loss=7.8603 
[epoch 11] step 38/44: loss=7.8160 
[epoch 11] step 40/44: loss=7.8108 
[epoch 11] step 42/44: loss=7.8659 
[epoch 11] step 44/44: loss=8.0037 
[epoch 11] train_loss(avg per step)=16.0074 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=9.6849 qwk=('0.4707', '0.3932', '0.5087') averageQWK=0.4575 macroEMD=0.3724 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    0   40    1    0
     0    0   92   30    0
     0    0   43   98    0
     0    0    3   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    0   31    8    0
     0    0   66   38    0
     0    0   36  127    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    2    0    0
     0   18   29    5    0
     0   22   91   45    0
     0    7   27   76    0
     0    0    0    3    0
[epoch 12] step 2/44: loss=8.9056 
[epoch 12] step 4/44: loss=9.1409 
[epoch 12] step 6/44: loss=8.7366 
[epoch 12] step 8/44: loss=8.2768 
[epoch 12] step 10/44: loss=7.9045 
[epoch 12] step 12/44: loss=7.6949 
[epoch 12] step 14/44: loss=7.6995 
[epoch 12] step 16/44: loss=7.7308 
[epoch 12] step 18/44: loss=7.8386 
[epoch 12] step 20/44: loss=7.9596 
[epoch 12] step 22/44: loss=8.0027 
[epoch 12] step 24/44: loss=8.0669 
[epoch 12] step 26/44: loss=8.1141 
[epoch 12] step 28/44: loss=8.0694 
[epoch 12] step 30/44: loss=8.0405 
[epoch 12] step 32/44: loss=7.9787 
[epoch 12] step 34/44: loss=7.8594 
[epoch 12] step 36/44: loss=7.8371 
[epoch 12] step 38/44: loss=7.8599 
[epoch 12] step 40/44: loss=7.8351 
[epoch 12] step 42/44: loss=7.8317 
[epoch 12] step 44/44: loss=7.9310 
[epoch 12] train_loss(avg per step)=15.8621 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=9.7300 qwk=('0.4160', '0.4285', '0.4473') averageQWK=0.4306 macroEMD=0.3712 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    0   34    7    0
     0    0   74   48    0
     0    0   26  115    0
     0    0    2   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    3   30    6    0
     0    8   57   39    0
     0    0   38  125    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   13   31    8    0
     0   14   96   48    0
     0    4   28   78    0
     0    0    0    3    0
[epoch 13] step 2/44: loss=8.9946 
[epoch 13] step 4/44: loss=8.5328 
[epoch 13] step 6/44: loss=8.3753 
[epoch 13] step 8/44: loss=7.9850 
[epoch 13] step 10/44: loss=7.8276 
[epoch 13] step 12/44: loss=7.7530 
[epoch 13] step 14/44: loss=7.8978 
[epoch 13] step 16/44: loss=7.8986 
[epoch 13] step 18/44: loss=7.9333 
[epoch 13] step 20/44: loss=7.9392 
[epoch 13] step 22/44: loss=7.8862 
[epoch 13] step 24/44: loss=7.8524 
[epoch 13] step 26/44: loss=7.8635 
[epoch 13] step 28/44: loss=7.8851 
[epoch 13] step 30/44: loss=7.8870 
[epoch 13] step 32/44: loss=7.8705 
[epoch 13] step 34/44: loss=7.8618 
[epoch 13] step 36/44: loss=7.8496 
[epoch 13] step 38/44: loss=7.8650 
[epoch 13] step 40/44: loss=7.8734 
[epoch 13] step 42/44: loss=7.8650 
[epoch 13] step 44/44: loss=7.8074 
[epoch 13] train_loss(avg per step)=15.6147 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=9.9015 qwk=('0.4571', '0.4861', '0.2518') averageQWK=0.3983 macroEMD=0.3718 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    0    0
     0    9   31    1    0
     0    4  100   18    0
     0    0   69   72    0
     0    0    5   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    3    0
     0   12   22    5    0
     0   22   51   31    0
     0    2   54  107    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    0   50    2    0
     0    2  150    6    0
     0    1   77   32    0
     0    0    2    1    0
[epoch 14] step 2/44: loss=9.1026 
[epoch 14] step 4/44: loss=8.2505 
[epoch 14] step 6/44: loss=8.3197 
[epoch 14] step 8/44: loss=8.2693 
[epoch 14] step 10/44: loss=8.1063 
[epoch 14] step 12/44: loss=8.0246 
[epoch 14] step 14/44: loss=8.0548 
[epoch 14] step 16/44: loss=8.0055 
[epoch 14] step 18/44: loss=7.8820 
[epoch 14] step 20/44: loss=7.7628 
[epoch 14] step 22/44: loss=7.8186 
[epoch 14] step 24/44: loss=7.9161 
[epoch 14] step 26/44: loss=8.0476 
[epoch 14] step 28/44: loss=8.0889 
[epoch 14] step 30/44: loss=8.0993 
[epoch 14] step 32/44: loss=8.0679 
[epoch 14] step 34/44: loss=8.0545 
[epoch 14] step 36/44: loss=8.0145 
[epoch 14] step 38/44: loss=7.9960 
[epoch 14] step 40/44: loss=7.9859 
[epoch 14] step 42/44: loss=7.9723 
[epoch 14] step 44/44: loss=7.8897 
[epoch 14] train_loss(avg per step)=15.7795 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=10.0921 qwk=('0.5187', '0.4101', '0.4403') averageQWK=0.4564 macroEMD=0.3723 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   18   21    2    0
     0   29   68   25    0
     0    7   42   92    0
     0    0    5   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    1    0
     0    4   35    0    0
     0   12   70   22    0
     0    1   72   90    0
     0    0    4   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    5    0    0
     0   18   32    2    0
     0   24  110   24    0
     0    7   49   54    0
     0    0    1    2    0
[epoch 15] step 2/44: loss=7.6253 
[epoch 15] step 4/44: loss=7.9859 
[epoch 15] step 6/44: loss=7.9597 
[epoch 15] step 8/44: loss=7.9221 
[epoch 15] step 10/44: loss=7.7557 
[epoch 15] step 12/44: loss=7.7643 
[epoch 15] step 14/44: loss=7.6310 
[epoch 15] step 16/44: loss=7.5396 
[epoch 15] step 18/44: loss=7.4918 
[epoch 15] step 20/44: loss=7.5304 
[epoch 15] step 22/44: loss=7.5458 
[epoch 15] step 24/44: loss=7.6549 
[epoch 15] step 26/44: loss=7.7145 
[epoch 15] step 28/44: loss=7.8233 
[epoch 15] step 30/44: loss=7.8418 
[epoch 15] step 32/44: loss=7.8297 
[epoch 15] step 34/44: loss=7.8705 
[epoch 15] step 36/44: loss=7.8575 
[epoch 15] step 38/44: loss=7.8220 
[epoch 15] step 40/44: loss=7.8501 
[epoch 15] step 42/44: loss=7.8637 
[epoch 15] step 44/44: loss=7.7536 
[epoch 15] train_loss(avg per step)=15.5072 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=10.0276 qwk=('0.4419', '0.3815', '0.4234') averageQWK=0.4156 macroEMD=0.3738 tailR0=('0.0476', '0.0000', '0.0000') tailR0avg=0.0159
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    3   34    4    0
     0    0   79   42    1
     0    0   36  102    3
     0    0    4   15    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    2   25   12    0
     0    3   44   57    0
     0    0   22  141    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    0   49    3    0
     0    1  106   51    0
     0    0   29   81    0
     0    0    0    3    0
[epoch 16] step 2/44: loss=8.3287 
[epoch 16] step 4/44: loss=8.2804 
[epoch 16] step 6/44: loss=8.1701 
[epoch 16] step 8/44: loss=7.9757 
[epoch 16] step 10/44: loss=7.8823 
[epoch 16] step 12/44: loss=7.8042 
[epoch 16] step 14/44: loss=7.8305 
[epoch 16] step 16/44: loss=7.8429 
[epoch 16] step 18/44: loss=7.9027 
[epoch 16] step 20/44: loss=7.8604 
[epoch 16] step 22/44: loss=7.9061 
[epoch 16] step 24/44: loss=7.9291 
[epoch 16] step 26/44: loss=7.8725 
[epoch 16] step 28/44: loss=7.9199 
[epoch 16] step 30/44: loss=7.9950 
[epoch 16] step 32/44: loss=8.0293 
[epoch 16] step 34/44: loss=7.9843 
[epoch 16] step 36/44: loss=7.9548 
[epoch 16] step 38/44: loss=7.9485 
[epoch 16] step 40/44: loss=7.9198 
[epoch 16] step 42/44: loss=7.9058 
[epoch 16] step 44/44: loss=7.9746 
[epoch 16] train_loss(avg per step)=15.9493 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=10.0496 qwk=('0.4310', '0.3326', '0.3666') averageQWK=0.3767 macroEMD=0.3732 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     0    4   30    7    0
     0    1   52   69    0
     0    0   21  120    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    6    0
     0    2   23   14    0
     0    1   43   60    0
     0    0   18  145    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    0   50    2    0
     0    0  133   25    0
     0    0   50   60    0
     0    0    0    3    0
[epoch 17] step 2/44: loss=10.0246 
[epoch 17] step 4/44: loss=9.6647 
[epoch 17] step 6/44: loss=9.5268 
[epoch 17] step 8/44: loss=9.0745 
[epoch 17] step 10/44: loss=8.7010 
[epoch 17] step 12/44: loss=8.3337 
[epoch 17] step 14/44: loss=8.0502 
[epoch 17] step 16/44: loss=7.9509 
[epoch 17] step 18/44: loss=7.9048 
[epoch 17] step 20/44: loss=7.8468 
[epoch 17] step 22/44: loss=7.8705 
[epoch 17] step 24/44: loss=7.8784 
[epoch 17] step 26/44: loss=7.9131 
[epoch 17] step 28/44: loss=7.9199 
[epoch 17] step 30/44: loss=7.9094 
[epoch 17] step 32/44: loss=7.9042 
[epoch 17] step 34/44: loss=7.9914 
[epoch 17] step 36/44: loss=8.0343 
[epoch 17] step 38/44: loss=8.0023 
[epoch 17] step 40/44: loss=7.9659 
[epoch 17] step 42/44: loss=7.9296 
[epoch 17] step 44/44: loss=7.8233 
[epoch 17] train_loss(avg per step)=15.6467 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=10.0257 qwk=('0.4637', '0.4192', '0.4534') averageQWK=0.4455 macroEMD=0.3743 tailR0=('0.0000', '0.0385', '0.0000') tailR0avg=0.0128
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    2    0
     0   11   24    6    0
     0   14   60   48    0
     0    1   29  111    0
     0    0    3   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    4    0
     0    5   26    8    0
     0   13   49   42    0
     0    0   36  127    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   18   33    1    0
     0   17  127   14    0
     0    4   56   50    0
     0    0    1    2    0
[epoch 18] step 2/44: loss=6.9244 
[epoch 18] step 4/44: loss=7.7077 
[epoch 18] step 6/44: loss=7.8275 
[epoch 18] step 8/44: loss=7.8934 
[epoch 18] step 10/44: loss=8.0139 
[epoch 18] step 12/44: loss=7.8549 
[epoch 18] step 14/44: loss=7.9350 
[epoch 18] step 16/44: loss=7.9097 
[epoch 18] step 18/44: loss=8.0011 
[epoch 18] step 20/44: loss=8.1220 
[epoch 18] step 22/44: loss=8.0811 
[epoch 18] step 24/44: loss=7.9700 
[epoch 18] step 26/44: loss=7.8228 
[epoch 18] step 28/44: loss=7.7381 
[epoch 18] step 30/44: loss=7.7334 
[epoch 18] step 32/44: loss=7.7633 
[epoch 18] step 34/44: loss=7.8406 
[epoch 18] step 36/44: loss=7.9517 
[epoch 18] step 38/44: loss=8.0181 
[epoch 18] step 40/44: loss=7.9820 
[epoch 18] step 42/44: loss=8.0196 
[epoch 18] step 44/44: loss=7.9938 
[epoch 18] train_loss(avg per step)=15.9875 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=10.2851 qwk=('0.5070', '0.4548', '0.4749') averageQWK=0.4789 macroEMD=0.3706 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    2    0
     1   13   22    5    0
     0   18   63   39    2
     1    2   33   96    9
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    4    0
     0   14   14   11    0
     0   21   34   49    0
     0    6   23  134    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    5    0    0
     0   23   22    7    0
     0   27   70   61    0
     0    8   20   82    0
     0    0    0    3    0
[epoch 19] step 2/44: loss=7.1270 
[epoch 19] step 4/44: loss=7.3212 
[epoch 19] step 6/44: loss=7.4415 
[epoch 19] step 8/44: loss=7.6768 
[epoch 19] step 10/44: loss=7.8818 
[epoch 19] step 12/44: loss=8.0970 
[epoch 19] step 14/44: loss=8.1176 
[epoch 19] step 16/44: loss=7.9855 
[epoch 19] step 18/44: loss=7.9604 
[epoch 19] step 20/44: loss=7.9118 
[epoch 19] step 22/44: loss=7.8935 
[epoch 19] step 24/44: loss=7.8906 
[epoch 19] step 26/44: loss=7.9530 
[epoch 19] step 28/44: loss=7.9374 
[epoch 19] step 30/44: loss=7.9109 
[epoch 19] step 32/44: loss=7.9128 
[epoch 19] step 34/44: loss=7.8995 
[epoch 19] step 36/44: loss=7.8760 
[epoch 19] step 38/44: loss=7.8435 
[epoch 19] step 40/44: loss=7.8540 
[epoch 19] step 42/44: loss=7.8509 
[epoch 19] step 44/44: loss=7.9305 
[epoch 19] train_loss(avg per step)=15.8609 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=10.1316 qwk=('0.4951', '0.4481', '0.4146') averageQWK=0.4526 macroEMD=0.3718 tailR0=('0.1190', '0.0385', '0.0000') tailR0avg=0.0525
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    5   34    2    0
     0    2   95   24    1
     0    0   46   92    3
     0    0    4   12    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    7    3    0
     0    5   25    9    0
     0   13   49   42    0
     0    1   31  131    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    4   44    4    0
     0    9  103   46    0
     0    2   37   71    0
     0    0    0    3    0
[epoch 20] step 2/44: loss=7.8071 
[epoch 20] step 4/44: loss=8.1560 
[epoch 20] step 6/44: loss=8.0360 
[epoch 20] step 8/44: loss=7.8867 
[epoch 20] step 10/44: loss=7.9198 
[epoch 20] step 12/44: loss=8.0096 
[epoch 20] step 14/44: loss=7.9858 
[epoch 20] step 16/44: loss=7.9820 
[epoch 20] step 18/44: loss=8.0203 
[epoch 20] step 20/44: loss=7.9052 
[epoch 20] step 22/44: loss=7.8760 
[epoch 20] step 24/44: loss=7.8328 
[epoch 20] step 26/44: loss=7.8278 
[epoch 20] step 28/44: loss=7.8459 
[epoch 20] step 30/44: loss=7.9330 
[epoch 20] step 32/44: loss=7.9464 
[epoch 20] step 34/44: loss=7.9220 
[epoch 20] step 36/44: loss=7.9200 
[epoch 20] step 38/44: loss=7.8794 
[epoch 20] step 40/44: loss=7.9132 
[epoch 20] step 42/44: loss=7.8939 
[epoch 20] step 44/44: loss=7.7754 
[epoch 20] train_loss(avg per step)=15.5507 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=10.2272 qwk=('0.5058', '0.4318', '0.3893') averageQWK=0.4423 macroEMD=0.3747 tailR0=('0.1190', '0.0000', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   32    2    0
     0    1   90   30    1
     0    0   44   94    3
     0    0    3   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    2    0
     0    6   25    8    0
     0    9   64   31    0
     0    1   52  110    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   13   38    1    0
     0   13  133   12    0
     0    2   71   37    0
     0    0    2    1    0
[epoch 21] step 2/44: loss=7.5132 
[epoch 21] step 4/44: loss=8.1068 
[epoch 21] step 6/44: loss=8.0148 
[epoch 21] step 8/44: loss=7.8546 
[epoch 21] step 10/44: loss=7.9410 
[epoch 21] step 12/44: loss=7.9773 
[epoch 21] step 14/44: loss=7.9579 
[epoch 21] step 16/44: loss=8.0364 
[epoch 21] step 18/44: loss=7.9979 
[epoch 21] step 20/44: loss=8.0265 
[epoch 21] step 22/44: loss=8.0303 
[epoch 21] step 24/44: loss=8.0420 
[epoch 21] step 26/44: loss=8.0387 
[epoch 21] step 28/44: loss=7.9830 
[epoch 21] step 30/44: loss=7.9949 
[epoch 21] step 32/44: loss=7.9948 
[epoch 21] step 34/44: loss=7.9814 
[epoch 21] step 36/44: loss=7.9950 
[epoch 21] step 38/44: loss=7.9891 
[epoch 21] step 40/44: loss=7.9786 
[epoch 21] step 42/44: loss=7.9780 
[epoch 21] step 44/44: loss=8.0497 
[epoch 21] train_loss(avg per step)=16.0994 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=10.3215 qwk=('0.4750', '0.4444', '0.3671') averageQWK=0.4288 macroEMD=0.3746 tailR0=('0.1429', '0.0385', '0.0000') tailR0avg=0.0604
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   30    4    0
     0    2   75   41    4
     0    1   37   93   10
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    7    3    0
     0    2   29    8    0
     0    6   59   39    0
     0    1   32  130    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    2   48    2    0
     0    3  127   28    0
     0    1   56   53    0
     0    0    0    3    0
[epoch 22] step 2/44: loss=8.7453 
[epoch 22] step 4/44: loss=8.3343 
[epoch 22] step 6/44: loss=8.1005 
[epoch 22] step 8/44: loss=7.9972 
[epoch 22] step 10/44: loss=7.9571 
[epoch 22] step 12/44: loss=7.9621 
[epoch 22] step 14/44: loss=8.0018 
[epoch 22] step 16/44: loss=7.8948 
[epoch 22] step 18/44: loss=7.8233 
[epoch 22] step 20/44: loss=7.8050 
[epoch 22] step 22/44: loss=7.8048 
[epoch 22] step 24/44: loss=7.8861 
[epoch 22] step 26/44: loss=7.8758 
[epoch 22] step 28/44: loss=7.8837 
[epoch 22] step 30/44: loss=7.9008 
[epoch 22] step 32/44: loss=7.9541 
[epoch 22] step 34/44: loss=7.9899 
[epoch 22] step 36/44: loss=8.0071 
[epoch 22] step 38/44: loss=8.0033 
[epoch 22] step 40/44: loss=7.9575 
[epoch 22] step 42/44: loss=7.9058 
[epoch 22] step 44/44: loss=7.9880 
[epoch 22] train_loss(avg per step)=15.9760 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=10.2946 qwk=('0.4495', '0.4689', '0.4210') averageQWK=0.4465 macroEMD=0.3728 tailR0=('0.3095', '0.0000', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    9   30    2    0
     3    7   80   24    8
     6    1   40   70   24
     0    0    2    6   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0    9   20   10    0
     0   16   43   45    0
     0    3   24  136    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    3   43    6    0
     0    5  102   51    0
     0    3   27   80    0
     0    0    0    3    0
[epoch 23] step 2/44: loss=7.4556 
[epoch 23] step 4/44: loss=7.6412 
[epoch 23] step 6/44: loss=7.8217 
[epoch 23] step 8/44: loss=7.8754 
[epoch 23] step 10/44: loss=7.9759 
[epoch 23] step 12/44: loss=8.0430 
[epoch 23] step 14/44: loss=8.0863 
[epoch 23] step 16/44: loss=7.9463 
[epoch 23] step 18/44: loss=7.7762 
[epoch 23] step 20/44: loss=7.7418 
[epoch 23] step 22/44: loss=7.7407 
[epoch 23] step 24/44: loss=7.7114 
[epoch 23] step 26/44: loss=7.7876 
[epoch 23] step 28/44: loss=7.8217 
[epoch 23] step 30/44: loss=7.8691 
[epoch 23] step 32/44: loss=7.9025 
[epoch 23] step 34/44: loss=7.9233 
[epoch 23] step 36/44: loss=7.9196 
[epoch 23] step 38/44: loss=7.9255 
[epoch 23] step 40/44: loss=7.9332 
[epoch 23] step 42/44: loss=7.9141 
[epoch 23] step 44/44: loss=7.8949 
[epoch 23] train_loss(avg per step)=15.7898 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=10.1790 qwk=('0.4470', '0.4492', '0.4574') averageQWK=0.4512 macroEMD=0.3753 tailR0=('0.0714', '0.0385', '0.0000') tailR0avg=0.0366
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    6   33    2    0
     0    6   83   32    1
     0    0   46   89    6
     0    0    7   11    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    7    3    0
     1    7   22    9    0
     0   12   43   49    0
     1    1   26  135    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   15   35    2    0
     0   19  105   34    0
     0    7   38   65    0
     0    0    0    3    0
[epoch 24] step 2/44: loss=7.8090 
[epoch 24] step 4/44: loss=7.9206 
[epoch 24] step 6/44: loss=7.9062 
[epoch 24] step 8/44: loss=7.7558 
[epoch 24] step 10/44: loss=7.7622 
[epoch 24] step 12/44: loss=7.7176 
[epoch 24] step 14/44: loss=7.6420 
[epoch 24] step 16/44: loss=7.7327 
[epoch 24] step 18/44: loss=7.7493 
[epoch 24] step 20/44: loss=7.7815 
[epoch 24] step 22/44: loss=7.7460 
[epoch 24] step 24/44: loss=7.7352 
[epoch 24] step 26/44: loss=7.7296 
[epoch 24] step 28/44: loss=7.7658 
[epoch 24] step 30/44: loss=7.7493 
[epoch 24] step 32/44: loss=7.7311 
[epoch 24] step 34/44: loss=7.7604 
[epoch 24] step 36/44: loss=7.7852 
[epoch 24] step 38/44: loss=7.7834 
[epoch 24] step 40/44: loss=7.8116 
[epoch 24] step 42/44: loss=7.8296 
[epoch 24] step 44/44: loss=7.7991 
[epoch 24] train_loss(avg per step)=15.5982 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=10.1719 qwk=('0.5365', '0.5477', '0.4308') averageQWK=0.5050 macroEMD=0.3739 tailR0=('0.1667', '0.0312', '0.0000') tailR0avg=0.0660
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    1    0
     0   13   27    1    0
     0   12   83   26    1
     0    0   52   81    8
     0    0    5    9    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    4    2    0
     0   12   21    6    0
     0   21   51   32    0
     0    1   38  123    1
     0    0    0   15    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    8   42    2    0
     0   10  120   28    0
     0    2   51   57    0
     0    0    0    3    0
[epoch 25] step 2/44: loss=7.1058 
[epoch 25] step 4/44: loss=7.2542 
[epoch 25] step 6/44: loss=7.2802 
[epoch 25] step 8/44: loss=7.6626 
[epoch 25] step 10/44: loss=7.9250 
[epoch 25] step 12/44: loss=7.9295 
[epoch 25] step 14/44: loss=7.9085 
[epoch 25] step 16/44: loss=7.9819 
[epoch 25] step 18/44: loss=8.0017 
[epoch 25] step 20/44: loss=7.9514 
[epoch 25] step 22/44: loss=7.9363 
[epoch 25] step 24/44: loss=7.9325 
[epoch 25] step 26/44: loss=7.9114 
[epoch 25] step 28/44: loss=7.8497 
[epoch 25] step 30/44: loss=7.8619 
[epoch 25] step 32/44: loss=7.8523 
[epoch 25] step 34/44: loss=7.8537 
[epoch 25] step 36/44: loss=7.8498 
[epoch 25] step 38/44: loss=7.8831 
[epoch 25] step 40/44: loss=7.8843 
[epoch 25] step 42/44: loss=7.9061 
[epoch 25] step 44/44: loss=7.8335 
[epoch 25] train_loss(avg per step)=15.6670 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=10.4110 qwk=('0.5739', '0.5272', '0.4912') averageQWK=0.5308 macroEMD=0.3716 tailR0=('0.2167', '0.0000', '0.0000') tailR0avg=0.0722
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    6    0    0
     0   12   29    0    0
     0    9   92   20    1
     0    0   54   72   15
     0    0    5    9    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    2    2    0
     0   15   14   10    0
     0   23   36   45    0
     0    4   26  133    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    5    0    0
     0   24   23    5    0
     0   28   77   53    0
     0    7   26   77    0
     0    0    0    3    0
[epoch 26] step 2/44: loss=7.5499 
[epoch 26] step 4/44: loss=7.8812 
[epoch 26] step 6/44: loss=7.8633 
[epoch 26] step 8/44: loss=7.9563 
[epoch 26] step 10/44: loss=7.9622 
[epoch 26] step 12/44: loss=7.9648 
[epoch 26] step 14/44: loss=8.0434 
[epoch 26] step 16/44: loss=8.0642 
[epoch 26] step 18/44: loss=7.9985 
[epoch 26] step 20/44: loss=7.9441 
[epoch 26] step 22/44: loss=7.9143 
[epoch 26] step 24/44: loss=7.8714 
[epoch 26] step 26/44: loss=7.8580 
[epoch 26] step 28/44: loss=7.8793 
[epoch 26] step 30/44: loss=7.9406 
[epoch 26] step 32/44: loss=7.8865 
[epoch 26] step 34/44: loss=7.8977 
[epoch 26] step 36/44: loss=7.9054 
[epoch 26] step 38/44: loss=7.9039 
[epoch 26] step 40/44: loss=7.9401 
[epoch 26] step 42/44: loss=7.9295 
[epoch 26] step 44/44: loss=7.9748 
[epoch 26] train_loss(avg per step)=15.9497 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=10.3958 qwk=('0.4430', '0.5341', '0.4812') averageQWK=0.4861 macroEMD=0.3731 tailR0=('0.0952', '0.0000', '0.0000') tailR0avg=0.0317
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    7   34    0    0
     0    9   91   21    1
     0    0   65   72    4
     0    0    8    9    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    4    2    0
     0   13   19    7    0
     0   18   49   37    0
     0    3   31  129    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   17   34    1    0
     0   22  105   31    0
     0    5   42   63    0
     0    0    0    3    0
[epoch 27] step 2/44: loss=7.5704 
[epoch 27] step 4/44: loss=7.7085 
[epoch 27] step 6/44: loss=7.5121 
[epoch 27] step 8/44: loss=7.5117 
[epoch 27] step 10/44: loss=7.5971 
[epoch 27] step 12/44: loss=7.8012 
[epoch 27] step 14/44: loss=7.8472 
[epoch 27] step 16/44: loss=7.9837 
[epoch 27] step 18/44: loss=7.9797 
[epoch 27] step 20/44: loss=7.9874 
[epoch 27] step 22/44: loss=7.9834 
[epoch 27] step 24/44: loss=7.9816 
[epoch 27] step 26/44: loss=8.0067 
[epoch 27] step 28/44: loss=7.9928 
[epoch 27] step 30/44: loss=7.9609 
[epoch 27] step 32/44: loss=7.9481 
[epoch 27] step 34/44: loss=7.9004 
[epoch 27] step 36/44: loss=7.8448 
[epoch 27] step 38/44: loss=7.8084 
[epoch 27] step 40/44: loss=7.8193 
[epoch 27] step 42/44: loss=7.8767 
[epoch 27] step 44/44: loss=7.7552 
[epoch 27] train_loss(avg per step)=15.5103 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=10.4169 qwk=('0.4510', '0.5074', '0.4066') averageQWK=0.4550 macroEMD=0.3736 tailR0=('0.0952', '0.0000', '0.0000') tailR0avg=0.0317
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    7   34    0    0
     0    6   93   22    1
     0    0   63   68   10
     0    0    8    9    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    2    0
     0   11   22    6    0
     0   18   49   37    0
     0    1   43  119    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    6   43    3    0
     0    7  122   29    0
     0    2   50   58    0
     0    0    1    2    0
[epoch 28] step 2/44: loss=8.5928 
[epoch 28] step 4/44: loss=8.6096 
[epoch 28] step 6/44: loss=8.7568 
[epoch 28] step 8/44: loss=8.5830 
[epoch 28] step 10/44: loss=8.4972 
[epoch 28] step 12/44: loss=8.3724 
[epoch 28] step 14/44: loss=8.2509 
[epoch 28] step 16/44: loss=8.2744 
[epoch 28] step 18/44: loss=8.1938 
[epoch 28] step 20/44: loss=8.1482 
[epoch 28] step 22/44: loss=8.1237 
[epoch 28] step 24/44: loss=8.0399 
[epoch 28] step 26/44: loss=7.9876 
[epoch 28] step 28/44: loss=8.0273 
[epoch 28] step 30/44: loss=8.0079 
[epoch 28] step 32/44: loss=7.9552 
[epoch 28] step 34/44: loss=7.9243 
[epoch 28] step 36/44: loss=7.9375 
[epoch 28] step 38/44: loss=7.9142 
[epoch 28] step 40/44: loss=7.9275 
[epoch 28] step 42/44: loss=7.9301 
[epoch 28] step 44/44: loss=7.9765 
[epoch 28] train_loss(avg per step)=15.9530 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=10.3761 qwk=('0.4738', '0.5027', '0.4446') averageQWK=0.4737 macroEMD=0.3742 tailR0=('0.0476', '0.0000', '0.0000') tailR0avg=0.0159
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    8   28    5    0
     0    9   67   45    1
     0    0   34  104    3
     0    0    2   17    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    2    0
     0   10   20    9    0
     0   14   51   39    0
     0    0   37  126    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0    9   41    2    0
     0   10  116   32    0
     0    3   45   62    0
     0    0    1    2    0
[epoch 29] step 2/44: loss=8.3141 
[epoch 29] step 4/44: loss=8.1122 
[epoch 29] step 6/44: loss=8.0590 
[epoch 29] step 8/44: loss=8.1515 
[epoch 29] step 10/44: loss=8.1829 
[epoch 29] step 12/44: loss=8.0668 
[epoch 29] step 14/44: loss=8.0161 
[epoch 29] step 16/44: loss=7.8913 
[epoch 29] step 18/44: loss=7.9893 
[epoch 29] step 20/44: loss=8.0467 
[epoch 29] step 22/44: loss=8.0612 
[epoch 29] step 24/44: loss=8.0074 
[epoch 29] step 26/44: loss=8.0827 
[epoch 29] step 28/44: loss=8.1290 
[epoch 29] step 30/44: loss=8.1276 
[epoch 29] step 32/44: loss=8.0801 
[epoch 29] step 34/44: loss=8.0823 
[epoch 29] step 36/44: loss=8.0459 
[epoch 29] step 38/44: loss=8.0325 
[epoch 29] step 40/44: loss=8.0406 
[epoch 29] step 42/44: loss=7.9878 
[epoch 29] step 44/44: loss=8.0500 
[epoch 29] train_loss(avg per step)=16.0999 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=10.5253 qwk=('0.4416', '0.4856', '0.4726') averageQWK=0.4666 macroEMD=0.3753 tailR0=('0.1190', '0.0385', '0.0000') tailR0avg=0.0525
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   32    2    0
     1    5   86   29    1
     1    0   45   87    8
     1    0    5   10    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    8    2    0
     0    9   23    7    0
     0   13   52   39    0
     0    0   39  124    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   10   38    4    0
     0    9  108   41    0
     0    4   32   74    0
     0    0    0    3    0
[epoch 30] step 2/44: loss=7.6987 
[epoch 30] step 4/44: loss=7.7889 
[epoch 30] step 6/44: loss=7.3991 
[epoch 30] step 8/44: loss=7.5968 
[epoch 30] step 10/44: loss=7.4758 
[epoch 30] step 12/44: loss=7.6688 
[epoch 30] step 14/44: loss=7.7232 
[epoch 30] step 16/44: loss=7.6960 
[epoch 30] step 18/44: loss=7.7171 
[epoch 30] step 20/44: loss=7.7252 
[epoch 30] step 22/44: loss=7.7699 
[epoch 30] step 24/44: loss=7.7232 
[epoch 30] step 26/44: loss=7.7346 
[epoch 30] step 28/44: loss=7.7618 
[epoch 30] step 30/44: loss=7.7784 
[epoch 30] step 32/44: loss=7.7986 
[epoch 30] step 34/44: loss=7.7760 
[epoch 30] step 36/44: loss=7.8021 
[epoch 30] step 38/44: loss=7.7855 
[epoch 30] step 40/44: loss=7.8009 
[epoch 30] step 42/44: loss=7.8175 
[epoch 30] step 44/44: loss=7.8315 
[epoch 30] train_loss(avg per step)=15.6629 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=10.2033 qwk=('0.4508', '0.5011', '0.4038') averageQWK=0.4519 macroEMD=0.3749 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    6   33    2    0
     1    3   89   28    1
     2    0   48   83    8
     0    0    5   10    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    2    0
     0    9   22    8    0
     0   14   49   41    0
     0    1   34  128    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    6   45    1    0
     0    5  127   26    0
     0    1   53   56    0
     0    0    1    2    0
[epoch 31] step 2/44: loss=7.9466 
[epoch 31] step 4/44: loss=7.7758 
[epoch 31] step 6/44: loss=8.0612 
[epoch 31] step 8/44: loss=7.9845 
[epoch 31] step 10/44: loss=7.9634 
[epoch 31] step 12/44: loss=7.9191 
[epoch 31] step 14/44: loss=7.9302 
[epoch 31] step 16/44: loss=7.8558 
[epoch 31] step 18/44: loss=7.8174 
[epoch 31] step 20/44: loss=7.7516 
[epoch 31] step 22/44: loss=7.7575 
[epoch 31] step 24/44: loss=7.7360 
[epoch 31] step 26/44: loss=7.7298 
[epoch 31] step 28/44: loss=7.7840 
[epoch 31] step 30/44: loss=7.8326 
[epoch 31] step 32/44: loss=7.8664 
[epoch 31] step 34/44: loss=7.8829 
[epoch 31] step 36/44: loss=7.8751 
[epoch 31] step 38/44: loss=7.8984 
[epoch 31] step 40/44: loss=7.9129 
[epoch 31] step 42/44: loss=7.9101 
[epoch 31] step 44/44: loss=7.8349 
[epoch 31] train_loss(avg per step)=15.6698 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=10.4481 qwk=('0.4389', '0.4819', '0.4373') averageQWK=0.4527 macroEMD=0.3736 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    6   32    3    0
     1    3   89   28    1
     2    0   50   80    9
     0    0    5   10    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0   10   20    9    0
     0   13   42   49    0
     0    0   29  134    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    6   44    2    0
     0    6  112   40    0
     0    3   38   69    0
     0    0    0    3    0
[epoch 32] step 2/44: loss=8.2440 
[epoch 32] step 4/44: loss=8.5185 
[epoch 32] step 6/44: loss=8.2753 
[epoch 32] step 8/44: loss=8.1806 
[epoch 32] step 10/44: loss=8.1116 
[epoch 32] step 12/44: loss=8.0611 
[epoch 32] step 14/44: loss=7.9997 
[epoch 32] step 16/44: loss=8.0072 
[epoch 32] step 18/44: loss=7.9523 
[epoch 32] step 20/44: loss=7.8706 
[epoch 32] step 22/44: loss=7.8351 
[epoch 32] step 24/44: loss=7.8334 
[epoch 32] step 26/44: loss=7.8561 
[epoch 32] step 28/44: loss=7.9368 
[epoch 32] step 30/44: loss=7.9665 
[epoch 32] step 32/44: loss=7.9564 
[epoch 32] step 34/44: loss=7.9500 
[epoch 32] step 36/44: loss=7.9498 
[epoch 32] step 38/44: loss=7.9466 
[epoch 32] step 40/44: loss=7.9642 
[epoch 32] step 42/44: loss=7.9428 
[epoch 32] step 44/44: loss=8.0337 
[epoch 32] train_loss(avg per step)=16.0674 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=10.5145 qwk=('0.4533', '0.5064', '0.4174') averageQWK=0.4590 macroEMD=0.3756 tailR0=('0.1190', '0.0000', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   31    3    0
     1    4   90   26    1
     0    0   54   78    9
     0    0    6   10    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    2    0
     0   12   19    8    0
     0   13   49   42    0
     0    1   33  128    1
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   10   41    1    0
     0   16  117   25    0
     0    6   48   56    0
     0    0    1    2    0
[epoch 33] step 2/44: loss=7.9221 
[epoch 33] step 4/44: loss=7.9203 
[epoch 33] step 6/44: loss=7.7579 
[epoch 33] step 8/44: loss=7.7848 
[epoch 33] step 10/44: loss=7.6896 
[epoch 33] step 12/44: loss=7.7567 
[epoch 33] step 14/44: loss=7.7109 
[epoch 33] step 16/44: loss=7.6966 
[epoch 33] step 18/44: loss=7.7533 
[epoch 33] step 20/44: loss=7.8073 
[epoch 33] step 22/44: loss=7.8024 
[epoch 33] step 24/44: loss=7.8223 
[epoch 33] step 26/44: loss=7.7951 
[epoch 33] step 28/44: loss=7.7945 
[epoch 33] step 30/44: loss=7.7958 
[epoch 33] step 32/44: loss=7.8156 
[epoch 33] step 34/44: loss=7.8033 
[epoch 33] step 36/44: loss=7.8184 
[epoch 33] step 38/44: loss=7.8456 
[epoch 33] step 40/44: loss=7.8479 
[epoch 33] step 42/44: loss=7.9063 
[epoch 33] step 44/44: loss=7.8473 
[epoch 33] train_loss(avg per step)=15.6946 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=10.4097 qwk=('0.4299', '0.5027', '0.4282') averageQWK=0.4536 macroEMD=0.3740 tailR0=('0.1190', '0.0000', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   31    3    0
     1    5   85   30    1
     0    0   51   83    7
     1    0    5   10    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    2    0
     0   11   18   10    0
     0   16   39   49    0
     0    1   25  137    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    9   41    2    0
     0    9  116   33    0
     0    3   46   61    0
     0    0    1    2    0
[epoch 34] step 2/44: loss=8.6412 
[epoch 34] step 4/44: loss=8.2832 
[epoch 34] step 6/44: loss=8.2587 
[epoch 34] step 8/44: loss=8.3864 
[epoch 34] step 10/44: loss=8.2522 
[epoch 34] step 12/44: loss=8.2644 
[epoch 34] step 14/44: loss=8.2174 
[epoch 34] step 16/44: loss=8.1567 
[epoch 34] step 18/44: loss=8.1529 
[epoch 34] step 20/44: loss=8.0964 
[epoch 34] step 22/44: loss=8.0500 
[epoch 34] step 24/44: loss=8.0544 
[epoch 34] step 26/44: loss=8.0870 
[epoch 34] step 28/44: loss=8.0777 
[epoch 34] step 30/44: loss=8.1055 
[epoch 34] step 32/44: loss=8.0951 
[epoch 34] step 34/44: loss=8.0788 
[epoch 34] step 36/44: loss=8.0768 
[epoch 34] step 38/44: loss=8.0755 
[epoch 34] step 40/44: loss=8.0519 
[epoch 34] step 42/44: loss=8.0511 
[epoch 34] step 44/44: loss=8.0724 
[epoch 34] train_loss(avg per step)=16.1448 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=10.6543 qwk=('0.4354', '0.4881', '0.4411') averageQWK=0.4549 macroEMD=0.3754 tailR0=('0.1190', '0.0000', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   31    3    0
     1    4   90   26    1
     0    0   52   82    7
     1    0    5   10    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    2    0
     0   10   20    9    0
     0   14   44   46    0
     0    0   30  132    1
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0    9   41    2    0
     0    9  116   33    0
     0    4   43   63    0
     0    0    1    2    0
[epoch 35] step 2/44: loss=8.2839 
[epoch 35] step 4/44: loss=7.8654 
[epoch 35] step 6/44: loss=7.8560 
[epoch 35] step 8/44: loss=7.7929 
[epoch 35] step 10/44: loss=7.7453 
[epoch 35] step 12/44: loss=7.8067 
[epoch 35] step 14/44: loss=7.7642 
[epoch 35] step 16/44: loss=7.8081 
[epoch 35] step 18/44: loss=7.7987 
[epoch 35] step 20/44: loss=7.7823 
[epoch 35] step 22/44: loss=7.8048 
[epoch 35] step 24/44: loss=7.7991 
[epoch 35] step 26/44: loss=7.7782 
[epoch 35] step 28/44: loss=7.7912 
[epoch 35] step 30/44: loss=7.7818 
[epoch 35] step 32/44: loss=7.7962 
[epoch 35] step 34/44: loss=7.8126 
[epoch 35] step 36/44: loss=7.8087 
[epoch 35] step 38/44: loss=7.7742 
[epoch 35] step 40/44: loss=7.8290 
[epoch 35] step 42/44: loss=7.8449 
[epoch 35] step 44/44: loss=7.8652 
[epoch 35] train_loss(avg per step)=15.7305 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=10.3124 qwk=('0.4354', '0.4891', '0.4169') averageQWK=0.4471 macroEMD=0.3750 tailR0=('0.1190', '0.0000', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   31    3    0
     1    4   90   26    1
     0    0   52   82    7
     1    0    5   10    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    2    0
     0   11   18   10    0
     0   15   39   50    0
     0    1   26  136    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    5   45    2    0
     0    6  118   34    0
     0    3   44   63    0
     0    0    1    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-1-reassignment-1/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-1-reassignment-1/fold1/metrics.json
Done.
