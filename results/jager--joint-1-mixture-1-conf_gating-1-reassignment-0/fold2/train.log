[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=5.8823 
[epoch 1] step 4/44: loss=5.8195 
[epoch 1] step 6/44: loss=5.8749 
[epoch 1] step 8/44: loss=6.0316 
[epoch 1] step 10/44: loss=6.0820 
[epoch 1] step 12/44: loss=6.0666 
[epoch 1] step 14/44: loss=6.1147 
[epoch 1] step 16/44: loss=6.1160 
[epoch 1] step 18/44: loss=6.1276 
[epoch 1] step 20/44: loss=6.1836 
[epoch 1] step 22/44: loss=6.1931 
[epoch 1] step 24/44: loss=6.2552 
[epoch 1] step 26/44: loss=6.2304 
[epoch 1] step 28/44: loss=6.1933 
[epoch 1] step 30/44: loss=6.2099 
[epoch 1] step 32/44: loss=6.1779 
[epoch 1] step 34/44: loss=6.1515 
[epoch 1] step 36/44: loss=6.1389 
[epoch 1] step 38/44: loss=6.0963 
[epoch 1] step 40/44: loss=6.0502 
[epoch 1] step 42/44: loss=5.9918 
[epoch 1] step 44/44: loss=5.9176 
[epoch 1] train_loss(avg per step)=11.8351 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=6.9789 qwk=('-0.0656', '0.0490', '0.1420') averageQWK=0.0418 macroEMD=0.3719 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    6    0
     0   10    0   88    0
     0   10    0  145    0
     0   17    0   42    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    7    0
     6    0   55   21    0
    10    0   60   96    0
    10    0   13   38    0
     0    0    1    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0   22   77    5    0
     0   21  148   11    0
     0    3   26    7    0
     0    0    0    0    0
[epoch 2] step 2/44: loss=4.3836 
[epoch 2] step 4/44: loss=4.1712 
[epoch 2] step 6/44: loss=4.1122 
[epoch 2] step 8/44: loss=3.9745 
[epoch 2] step 10/44: loss=3.8583 
[epoch 2] step 12/44: loss=3.8233 
[epoch 2] step 14/44: loss=3.7249 
[epoch 2] step 16/44: loss=3.6773 
[epoch 2] step 18/44: loss=3.6345 
[epoch 2] step 20/44: loss=3.5883 
[epoch 2] step 22/44: loss=3.5390 
[epoch 2] step 24/44: loss=3.4945 
[epoch 2] step 26/44: loss=3.4585 
[epoch 2] step 28/44: loss=3.4128 
[epoch 2] step 30/44: loss=3.3867 
[epoch 2] step 32/44: loss=3.3604 
[epoch 2] step 34/44: loss=3.3235 
[epoch 2] step 36/44: loss=3.3166 
[epoch 2] step 38/44: loss=3.2889 
[epoch 2] step 40/44: loss=3.2597 
[epoch 2] step 42/44: loss=3.2425 
[epoch 2] step 44/44: loss=3.2159 
[epoch 2] train_loss(avg per step)=6.4318 lambda[min,max]=[0.500399,1.000000]
[epoch 2] val_loss=3.8834 qwk=('0.3514', '0.2243', '0.2228') averageQWK=0.2662 macroEMD=0.3739 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    4    0
     0   55   16   27    0
     0   43   45   67    0
     0    5    9   45    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    5    0
     0    0   61   21    0
     0    0   80   86    0
     0    0   10   51    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0    4   94    6    0
     0    4  147   29    0
     0    0   16   20    0
     0    0    0    0    0
[epoch 3] step 2/44: loss=2.7942 
[epoch 3] step 4/44: loss=2.7500 
[epoch 3] step 6/44: loss=2.7099 
[epoch 3] step 8/44: loss=2.7652 
[epoch 3] step 10/44: loss=2.7401 
[epoch 3] step 12/44: loss=2.7618 
[epoch 3] step 14/44: loss=2.7688 
[epoch 3] step 16/44: loss=2.7015 
[epoch 3] step 18/44: loss=2.7133 
[epoch 3] step 20/44: loss=2.6918 
[epoch 3] step 22/44: loss=2.6843 
[epoch 3] step 24/44: loss=2.6649 
[epoch 3] step 26/44: loss=2.6937 
[epoch 3] step 28/44: loss=2.7019 
[epoch 3] step 30/44: loss=2.7100 
[epoch 3] step 32/44: loss=2.7049 
[epoch 3] step 34/44: loss=2.7095 
[epoch 3] step 36/44: loss=2.6984 
[epoch 3] step 38/44: loss=2.6822 
[epoch 3] step 40/44: loss=2.6812 
[epoch 3] step 42/44: loss=2.6858 
[epoch 3] step 44/44: loss=2.6787 
[epoch 3] train_loss(avg per step)=5.3573 lambda[min,max]=[0.502097,1.000000]
[epoch 3] val_loss=3.8363 qwk=('0.2492', '0.1801', '0.2501') averageQWK=0.2265 macroEMD=0.3690 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    3    4    0
     0    1   86    9    2
     0    1  116   30    8
     0    1   18   38    2
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    4    0
     0    0   75    7    0
     0    0  138   28    0
     0    0   31   30    0
     0    0    1    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   38   65    1    0
     0   37  140    3    0
     0    1   30    5    0
     0    0    0    0    0
[epoch 4] step 2/44: loss=2.6531 
[epoch 4] step 4/44: loss=2.6902 
[epoch 4] step 6/44: loss=2.6378 
[epoch 4] step 8/44: loss=2.5520 
[epoch 4] step 10/44: loss=2.5107 
[epoch 4] step 12/44: loss=2.4705 
[epoch 4] step 14/44: loss=2.4342 
[epoch 4] step 16/44: loss=2.4070 
[epoch 4] step 18/44: loss=2.4128 
[epoch 4] step 20/44: loss=2.4263 
[epoch 4] step 22/44: loss=2.4096 
[epoch 4] step 24/44: loss=2.3950 
[epoch 4] step 26/44: loss=2.3971 
[epoch 4] step 28/44: loss=2.4016 
[epoch 4] step 30/44: loss=2.3760 
[epoch 4] step 32/44: loss=2.3746 
[epoch 4] step 34/44: loss=2.3690 
[epoch 4] step 36/44: loss=2.3755 
[epoch 4] step 38/44: loss=2.3672 
[epoch 4] step 40/44: loss=2.3645 
[epoch 4] step 42/44: loss=2.3515 
[epoch 4] step 44/44: loss=2.3434 
[epoch 4] train_loss(avg per step)=4.6868 lambda[min,max]=[0.511296,1.000000]
[epoch 4] val_loss=4.3593 qwk=('0.2663', '0.2287', '0.2018') averageQWK=0.2323 macroEMD=0.3626 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    4    0
     0   36   21   40    1
     0   26   46   78    5
     0    1    9   49    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    5    0
     0   13   40   29    0
     0   13   59   94    0
     0    0   10   51    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0    1   96    7    0
     0    0  147   33    0
     0    0   17   19    0
     0    0    0    0    0
[epoch 5] step 2/44: loss=1.9167 
[epoch 5] step 4/44: loss=2.0127 
[epoch 5] step 6/44: loss=2.0860 
[epoch 5] step 8/44: loss=2.0884 
[epoch 5] step 10/44: loss=2.1469 
[epoch 5] step 12/44: loss=2.1336 
[epoch 5] step 14/44: loss=2.1468 
[epoch 5] step 16/44: loss=2.1352 
[epoch 5] step 18/44: loss=2.1693 
[epoch 5] step 20/44: loss=2.1293 
[epoch 5] step 22/44: loss=2.1345 
[epoch 5] step 24/44: loss=2.1512 
[epoch 5] step 26/44: loss=2.1624 
[epoch 5] step 28/44: loss=2.1732 
[epoch 5] step 30/44: loss=2.1550 
[epoch 5] step 32/44: loss=2.1538 
[epoch 5] step 34/44: loss=2.1563 
[epoch 5] step 36/44: loss=2.1602 
[epoch 5] step 38/44: loss=2.1592 
[epoch 5] step 40/44: loss=2.1369 
[epoch 5] step 42/44: loss=2.1321 
[epoch 5] step 44/44: loss=2.1352 
[epoch 5] train_loss(avg per step)=4.2704 lambda[min,max]=[0.503468,1.000000]
[epoch 5] val_loss=3.7384 qwk=('0.3491', '0.3152', '0.2750') averageQWK=0.3131 macroEMD=0.3452 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     0   23   66    9    0
     0   13  112   30    0
     0    1   23   35    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    4    0
     0   16   49   17    0
     0   14   87   65    0
     0    1   12   48    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   31   71    2    0
     0   14  164    2    0
     0    0   31    5    0
     0    0    0    0    0
[epoch 6] step 2/44: loss=2.0000 
[epoch 6] step 4/44: loss=1.9657 
[epoch 6] step 6/44: loss=1.9994 
[epoch 6] step 8/44: loss=1.9411 
[epoch 6] step 10/44: loss=1.9319 
[epoch 6] step 12/44: loss=1.9396 
[epoch 6] step 14/44: loss=1.9528 
[epoch 6] step 16/44: loss=1.9615 
[epoch 6] step 18/44: loss=1.9678 
[epoch 6] step 20/44: loss=1.9793 
[epoch 6] step 22/44: loss=1.9841 
[epoch 6] step 24/44: loss=1.9842 
[epoch 6] step 26/44: loss=1.9972 
[epoch 6] step 28/44: loss=1.9891 
[epoch 6] step 30/44: loss=1.9839 
[epoch 6] step 32/44: loss=1.9778 
[epoch 6] step 34/44: loss=1.9917 
[epoch 6] step 36/44: loss=1.9716 
[epoch 6] step 38/44: loss=1.9696 
[epoch 6] step 40/44: loss=1.9585 
[epoch 6] step 42/44: loss=1.9701 
[epoch 6] step 44/44: loss=1.9655 
[epoch 6] train_loss(avg per step)=3.9311 lambda[min,max]=[0.501066,1.000000]
[epoch 6] val_loss=4.3200 qwk=('0.3622', '0.3352', '0.3973') averageQWK=0.3649 macroEMD=0.3320 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    4    0
     0   34   44   20    0
     0   21   75   57    2
     0    1   12   45    1
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    5    0
     0   24   42   16    0
     0   27   69   70    0
     0    1    7   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    2    0
     0   58   31   15    0
     0   44   75   61    0
     0    1    5   30    0
     0    0    0    0    0
[epoch 7] step 2/44: loss=1.9076 
[epoch 7] step 4/44: loss=1.7256 
[epoch 7] step 6/44: loss=1.7843 
[epoch 7] step 8/44: loss=1.8691 
[epoch 7] step 10/44: loss=1.8781 
[epoch 7] step 12/44: loss=1.8536 
[epoch 7] step 14/44: loss=1.8181 
[epoch 7] step 16/44: loss=1.7981 
[epoch 7] step 18/44: loss=1.8098 
[epoch 7] step 20/44: loss=1.8094 
[epoch 7] step 22/44: loss=1.7941 
[epoch 7] step 24/44: loss=1.8055 
[epoch 7] step 26/44: loss=1.7752 
[epoch 7] step 28/44: loss=1.7648 
[epoch 7] step 30/44: loss=1.7671 
[epoch 7] step 32/44: loss=1.7646 
[epoch 7] step 34/44: loss=1.7686 
[epoch 7] step 36/44: loss=1.7602 
[epoch 7] step 38/44: loss=1.7645 
[epoch 7] step 40/44: loss=1.7708 
[epoch 7] step 42/44: loss=1.7632 
[epoch 7] step 44/44: loss=1.7514 
[epoch 7] train_loss(avg per step)=3.5028 lambda[min,max]=[0.500362,1.000000]
[epoch 7] val_loss=4.3352 qwk=('0.2908', '0.3221', '0.3881') averageQWK=0.3337 macroEMD=0.3389 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     0   20   55   22    1
     0   10   80   63    2
     0    1   12   46    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    6    0
     1   26   33   21    1
     0   23   57   86    0
     0    1    6   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   37   59    8    0
     0   22  119   39    0
     0    0   10   26    0
     0    0    0    0    0
[epoch 8] step 2/44: loss=1.4379 
[epoch 8] step 4/44: loss=1.6431 
[epoch 8] step 6/44: loss=1.6636 
[epoch 8] step 8/44: loss=1.6733 
[epoch 8] step 10/44: loss=1.6886 
[epoch 8] step 12/44: loss=1.7083 
[epoch 8] step 14/44: loss=1.7158 
[epoch 8] step 16/44: loss=1.7305 
[epoch 8] step 18/44: loss=1.7841 
[epoch 8] step 20/44: loss=1.8119 
[epoch 8] step 22/44: loss=1.8141 
[epoch 8] step 24/44: loss=1.8085 
[epoch 8] step 26/44: loss=1.8469 
[epoch 8] step 28/44: loss=1.8663 
[epoch 8] step 30/44: loss=1.8414 
[epoch 8] step 32/44: loss=1.8252 
[epoch 8] step 34/44: loss=1.8282 
[epoch 8] step 36/44: loss=1.8325 
[epoch 8] step 38/44: loss=1.8416 
[epoch 8] step 40/44: loss=1.8343 
[epoch 8] step 42/44: loss=1.8275 
[epoch 8] step 44/44: loss=1.8352 
[epoch 8] train_loss(avg per step)=3.6705 lambda[min,max]=[0.500128,1.000000]
[epoch 8] val_loss=5.0572 qwk=('0.3178', '0.2987', '0.2460') averageQWK=0.2875 macroEMD=0.3337 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     0   14   69   15    0
     0    7  104   44    0
     0    1   15   43    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    8    0
     0   43    3   36    0
     0   37   16  113    0
     0    2    0   59    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   26   42   36    0
     0   14   63  103    0
     0    0    2   34    0
     0    0    0    0    0
[epoch 9] step 2/44: loss=1.7506 
[epoch 9] step 4/44: loss=1.8248 
[epoch 9] step 6/44: loss=1.8046 
[epoch 9] step 8/44: loss=1.8213 
[epoch 9] step 10/44: loss=1.7633 
[epoch 9] step 12/44: loss=1.6842 
[epoch 9] step 14/44: loss=1.6738 
[epoch 9] step 16/44: loss=1.6671 
[epoch 9] step 18/44: loss=1.6492 
[epoch 9] step 20/44: loss=1.6468 
[epoch 9] step 22/44: loss=1.6792 
[epoch 9] step 24/44: loss=1.6851 
[epoch 9] step 26/44: loss=1.6606 
[epoch 9] step 28/44: loss=1.6466 
[epoch 9] step 30/44: loss=1.6429 
[epoch 9] step 32/44: loss=1.6368 
[epoch 9] step 34/44: loss=1.6235 
[epoch 9] step 36/44: loss=1.6279 
[epoch 9] step 38/44: loss=1.6215 
[epoch 9] step 40/44: loss=1.6124 
[epoch 9] step 42/44: loss=1.6067 
[epoch 9] step 44/44: loss=1.6043 
[epoch 9] train_loss(avg per step)=3.2086 lambda[min,max]=[0.500414,1.000000]
[epoch 9] val_loss=4.7774 qwk=('0.2926', '0.3426', '0.3314') averageQWK=0.3222 macroEMD=0.3325 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     0   30   35   33    0
     0   17   58   80    0
     0    1    8   50    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    6    0
     1   39   14   28    0
     0   29   34  103    0
     0    2    2   57    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   31   60   13    0
     0   20  103   57    0
     0    0    8   28    0
     0    0    0    0    0
[epoch 10] step 2/44: loss=1.4273 
[epoch 10] step 4/44: loss=1.4313 
[epoch 10] step 6/44: loss=1.4358 
[epoch 10] step 8/44: loss=1.4356 
[epoch 10] step 10/44: loss=1.4214 
[epoch 10] step 12/44: loss=1.4115 
[epoch 10] step 14/44: loss=1.3992 
[epoch 10] step 16/44: loss=1.3904 
[epoch 10] step 18/44: loss=1.3884 
[epoch 10] step 20/44: loss=1.4074 
[epoch 10] step 22/44: loss=1.4108 
[epoch 10] step 24/44: loss=1.4336 
[epoch 10] step 26/44: loss=1.4496 
[epoch 10] step 28/44: loss=1.4639 
[epoch 10] step 30/44: loss=1.4601 
[epoch 10] step 32/44: loss=1.4697 
[epoch 10] step 34/44: loss=1.4849 
[epoch 10] step 36/44: loss=1.4814 
[epoch 10] step 38/44: loss=1.4664 
[epoch 10] step 40/44: loss=1.4609 
[epoch 10] step 42/44: loss=1.4577 
[epoch 10] step 44/44: loss=1.4503 
[epoch 10] train_loss(avg per step)=2.9006 lambda[min,max]=[0.500196,1.000000]
[epoch 10] val_loss=4.5784 qwk=('0.2903', '0.2926', '0.4006') averageQWK=0.3278 macroEMD=0.3261 tailR0=('0.0833', '0.3571', '0.0000') tailR0avg=0.1468
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    3    1
     0   27   51   16    4
     0   13   93   44    5
     0    1   18   36    4
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    5    6    0
     7   11   40   23    1
     5   11   67   82    1
     0    1    9   50    1
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   59   32   13    0
     0   45   78   57    0
     0    0   10   26    0
     0    0    0    0    0
[epoch 11] step 2/44: loss=1.1630 
[epoch 11] step 4/44: loss=1.3053 
[epoch 11] step 6/44: loss=1.3957 
[epoch 11] step 8/44: loss=1.3373 
[epoch 11] step 10/44: loss=1.2527 
[epoch 11] step 12/44: loss=1.2253 
[epoch 11] step 14/44: loss=1.2137 
[epoch 11] step 16/44: loss=1.1953 
[epoch 11] step 18/44: loss=1.2110 
[epoch 11] step 20/44: loss=1.2276 
[epoch 11] step 22/44: loss=1.2415 
[epoch 11] step 24/44: loss=1.2356 
[epoch 11] step 26/44: loss=1.2337 
[epoch 11] step 28/44: loss=1.2433 
[epoch 11] step 30/44: loss=1.2414 
[epoch 11] step 32/44: loss=1.2515 
[epoch 11] step 34/44: loss=1.2487 
[epoch 11] step 36/44: loss=1.2573 
[epoch 11] step 38/44: loss=1.2526 
[epoch 11] step 40/44: loss=1.2498 
[epoch 11] step 42/44: loss=1.2490 
[epoch 11] step 44/44: loss=1.2377 
[epoch 11] train_loss(avg per step)=2.4755 lambda[min,max]=[0.500024,1.000000]
[epoch 11] val_loss=4.2693 qwk=('0.4144', '0.3851', '0.3990') averageQWK=0.3995 macroEMD=0.3132 tailR0=('0.0000', '0.2500', '0.0000') tailR0avg=0.0833
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    3    0
     1   42   45    9    1
     0   30   88   34    3
     0    2   17   37    3
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    3    0
     4   27   47    4    0
     3   21  106   34    2
     0    2   23   35    1
     0    0    1    0    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   45   51    8    0
     0   38  104   38    0
     0    0   12   24    0
     0    0    0    0    0
[epoch 12] step 2/44: loss=1.0341 
[epoch 12] step 4/44: loss=1.1863 
[epoch 12] step 6/44: loss=1.2335 
[epoch 12] step 8/44: loss=1.1492 
[epoch 12] step 10/44: loss=1.2085 
[epoch 12] step 12/44: loss=1.1725 
[epoch 12] step 14/44: loss=1.1593 
[epoch 12] step 16/44: loss=1.1242 
[epoch 12] step 18/44: loss=1.1301 
[epoch 12] step 20/44: loss=1.1234 
[epoch 12] step 22/44: loss=1.1077 
[epoch 12] step 24/44: loss=1.1118 
[epoch 12] step 26/44: loss=1.1066 
[epoch 12] step 28/44: loss=1.0946 
[epoch 12] step 30/44: loss=1.0928 
[epoch 12] step 32/44: loss=1.0854 
[epoch 12] step 34/44: loss=1.0791 
[epoch 12] step 36/44: loss=1.0766 
[epoch 12] step 38/44: loss=1.0666 
[epoch 12] step 40/44: loss=1.0642 
[epoch 12] step 42/44: loss=1.0574 
[epoch 12] step 44/44: loss=1.0504 
[epoch 12] train_loss(avg per step)=2.1009 lambda[min,max]=[0.500006,1.000000]
[epoch 12] val_loss=4.9426 qwk=('0.3360', '0.3845', '0.3837') averageQWK=0.3680 macroEMD=0.3135 tailR0=('0.2500', '0.2857', '0.0000') tailR0avg=0.1786
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    5    0
     0   56   20   14    8
     0   46   58   42    9
     0    4   11   38    6
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    0    6    0
     3   45   19   15    0
     0   59   35   71    1
     0    6    5   49    1
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   55   43    6    0
     0   52   98   30    0
     0    2   12   22    0
     0    0    0    0    0
[epoch 13] step 2/44: loss=0.9826 
[epoch 13] step 4/44: loss=0.8399 
[epoch 13] step 6/44: loss=0.8287 
[epoch 13] step 8/44: loss=0.8604 
[epoch 13] step 10/44: loss=0.8748 
[epoch 13] step 12/44: loss=0.8662 
[epoch 13] step 14/44: loss=0.8471 
[epoch 13] step 16/44: loss=0.8290 
[epoch 13] step 18/44: loss=0.8501 
[epoch 13] step 20/44: loss=0.8403 
[epoch 13] step 22/44: loss=0.8338 
[epoch 13] step 24/44: loss=0.8394 
[epoch 13] step 26/44: loss=0.8469 
[epoch 13] step 28/44: loss=0.8738 
[epoch 13] step 30/44: loss=0.8817 
[epoch 13] step 32/44: loss=0.8777 
[epoch 13] step 34/44: loss=0.8871 
[epoch 13] step 36/44: loss=0.8895 
[epoch 13] step 38/44: loss=0.8991 
[epoch 13] step 40/44: loss=0.9050 
[epoch 13] step 42/44: loss=0.9123 
[epoch 13] step 44/44: loss=0.9071 
[epoch 13] train_loss(avg per step)=1.8143 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=5.5638 qwk=('0.3122', '0.3297', '0.3897') averageQWK=0.3439 macroEMD=0.3106 tailR0=('0.0000', '0.1071', '0.0000') tailR0avg=0.0357
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     6   33   36   16    7
     1   16   64   66    8
     0    2   10   45    2
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    2    6    0
    12   28   12   29    1
     6   23   36   99    2
     0    4    2   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   44   54    6    0
     0   34  122   24    0
     0    0   15   21    0
     0    0    0    0    0
[epoch 14] step 2/44: loss=0.9212 
[epoch 14] step 4/44: loss=0.7611 
[epoch 14] step 6/44: loss=0.7505 
[epoch 14] step 8/44: loss=0.7650 
[epoch 14] step 10/44: loss=0.7795 
[epoch 14] step 12/44: loss=0.7539 
[epoch 14] step 14/44: loss=0.7751 
[epoch 14] step 16/44: loss=0.7828 
[epoch 14] step 18/44: loss=0.7917 
[epoch 14] step 20/44: loss=0.7650 
[epoch 14] step 22/44: loss=0.7576 
[epoch 14] step 24/44: loss=0.7567 
[epoch 14] step 26/44: loss=0.7538 
[epoch 14] step 28/44: loss=0.7547 
[epoch 14] step 30/44: loss=0.7408 
[epoch 14] step 32/44: loss=0.7333 
[epoch 14] step 34/44: loss=0.7497 
[epoch 14] step 36/44: loss=0.7436 
[epoch 14] step 38/44: loss=0.7450 
[epoch 14] step 40/44: loss=0.7457 
[epoch 14] step 42/44: loss=0.7508 
[epoch 14] step 44/44: loss=0.7398 
[epoch 14] train_loss(avg per step)=1.4795 lambda[min,max]=[0.500001,1.000000]
[epoch 14] val_loss=5.9286 qwk=('0.3369', '0.3168', '0.3218') averageQWK=0.3252 macroEMD=0.3113 tailR0=('0.2381', '0.3571', '0.0000') tailR0avg=0.1984
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    1    4    0
     9   32   34   16    7
     2   21   61   62    9
     0    2   11   43    3
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    3    6    0
     9   26   20   25    2
     3   19   52   89    3
     0    4    7   49    1
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   38   58    8    0
     0   27  123   30    0
     0    0   19   17    0
     0    0    0    0    0
[epoch 15] step 2/44: loss=0.6894 
[epoch 15] step 4/44: loss=0.7136 
[epoch 15] step 6/44: loss=0.7478 
[epoch 15] step 8/44: loss=0.6784 
[epoch 15] step 10/44: loss=0.6896 
[epoch 15] step 12/44: loss=0.6842 
[epoch 15] step 14/44: loss=0.6595 
[epoch 15] step 16/44: loss=0.6611 
[epoch 15] step 18/44: loss=0.6561 
[epoch 15] step 20/44: loss=0.6488 
[epoch 15] step 22/44: loss=0.6450 
[epoch 15] step 24/44: loss=0.6405 
[epoch 15] step 26/44: loss=0.6330 
[epoch 15] step 28/44: loss=0.6199 
[epoch 15] step 30/44: loss=0.6157 
[epoch 15] step 32/44: loss=0.6256 
[epoch 15] step 34/44: loss=0.6187 
[epoch 15] step 36/44: loss=0.6074 
[epoch 15] step 38/44: loss=0.6135 
[epoch 15] step 40/44: loss=0.5995 
[epoch 15] step 42/44: loss=0.5987 
[epoch 15] step 44/44: loss=0.5834 
[epoch 15] train_loss(avg per step)=1.1668 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=6.7016 qwk=('0.3073', '0.3491', '0.3616') averageQWK=0.3393 macroEMD=0.3039 tailR0=('0.0714', '0.1429', '0.0000') tailR0avg=0.0714
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    4    0
    18   17   40   16    7
    10   13   64   59    9
     0    2   10   43    4
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    3    1    6    0
    15   28   12   25    2
     7   25   38   93    3
     0    4    4   52    1
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   49   44   11    0
     0   44   86   50    0
     0    0   13   23    0
     0    0    0    0    0
[epoch 16] step 2/44: loss=0.4721 
[epoch 16] step 4/44: loss=0.3473 
[epoch 16] step 6/44: loss=0.3657 
[epoch 16] step 8/44: loss=0.3457 
[epoch 16] step 10/44: loss=0.4000 
[epoch 16] step 12/44: loss=0.4349 
[epoch 16] step 14/44: loss=0.4234 
[epoch 16] step 16/44: loss=0.4321 
[epoch 16] step 18/44: loss=0.4413 
[epoch 16] step 20/44: loss=0.4338 
[epoch 16] step 22/44: loss=0.4186 
[epoch 16] step 24/44: loss=0.4177 
[epoch 16] step 26/44: loss=0.4244 
[epoch 16] step 28/44: loss=0.4331 
[epoch 16] step 30/44: loss=0.4399 
[epoch 16] step 32/44: loss=0.4231 
[epoch 16] step 34/44: loss=0.4194 
[epoch 16] step 36/44: loss=0.4255 
[epoch 16] step 38/44: loss=0.4206 
[epoch 16] step 40/44: loss=0.4317 
[epoch 16] step 42/44: loss=0.4335 
[epoch 16] step 44/44: loss=0.4314 
[epoch 16] train_loss(avg per step)=0.8628 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=6.7536 qwk=('0.3454', '0.3665', '0.3582') averageQWK=0.3567 macroEMD=0.3071 tailR0=('0.3095', '0.3929', '0.0000') tailR0avg=0.2341
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    0    4    0
    28   18   27   15   10
    12    9   62   60   12
     0    1   12   43    3
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    3    2    5    0
    20   25   13   22    2
    17   17   39   86    7
     0    2    5   53    1
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   58   35   11    0
     0   56   78   46    0
     0    2   11   23    0
     0    0    0    0    0
[epoch 17] step 2/44: loss=0.2282 
[epoch 17] step 4/44: loss=0.1714 
[epoch 17] step 6/44: loss=0.2380 
[epoch 17] step 8/44: loss=0.2720 
[epoch 17] step 10/44: loss=0.2581 
[epoch 17] step 12/44: loss=0.2865 
[epoch 17] step 14/44: loss=0.2880 
[epoch 17] step 16/44: loss=0.2605 
[epoch 17] step 18/44: loss=0.2733 
[epoch 17] step 20/44: loss=0.2945 
[epoch 17] step 22/44: loss=0.2825 
[epoch 17] step 24/44: loss=0.2912 
[epoch 17] step 26/44: loss=0.2855 
[epoch 17] step 28/44: loss=0.2919 
[epoch 17] step 30/44: loss=0.2962 
[epoch 17] step 32/44: loss=0.2965 
[epoch 17] step 34/44: loss=0.2991 
[epoch 17] step 36/44: loss=0.2879 
[epoch 17] step 38/44: loss=0.2805 
[epoch 17] step 40/44: loss=0.2904 
[epoch 17] step 42/44: loss=0.2935 
[epoch 17] step 44/44: loss=0.2833 
[epoch 17] train_loss(avg per step)=0.5666 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=8.4303 qwk=('0.2702', '0.3237', '0.3142') averageQWK=0.3027 macroEMD=0.3047 tailR0=('0.0714', '0.3571', '0.0000') tailR0avg=0.1429
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    4    1
    25    8   36   23    6
    12    8   59   67    9
     1    1   10   45    2
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    1    6    0
    18   21   11   30    2
    11   17   37   98    3
     0    4    3   53    1
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    3    0
     0   54   28   22    0
     0   49   63   68    0
     0    0    8   28    0
     0    0    0    0    0
[epoch 18] step 2/44: loss=0.1662 
[epoch 18] step 4/44: loss=0.2064 
[epoch 18] step 6/44: loss=0.2037 
[epoch 18] step 8/44: loss=0.2304 
[epoch 18] step 10/44: loss=0.2462 
[epoch 18] step 12/44: loss=0.2260 
[epoch 18] step 14/44: loss=0.2085 
[epoch 18] step 16/44: loss=0.2170 
[epoch 18] step 18/44: loss=0.2209 
[epoch 18] step 20/44: loss=0.2197 
[epoch 18] step 22/44: loss=0.2242 
[epoch 18] step 24/44: loss=0.2256 
[epoch 18] step 26/44: loss=0.2091 
[epoch 18] step 28/44: loss=0.2004 
[epoch 18] step 30/44: loss=0.2074 
[epoch 18] step 32/44: loss=0.2116 
[epoch 18] step 34/44: loss=0.2039 
[epoch 18] step 36/44: loss=0.1983 
[epoch 18] step 38/44: loss=0.1925 
[epoch 18] step 40/44: loss=0.1949 
[epoch 18] step 42/44: loss=0.1944 
[epoch 18] step 44/44: loss=0.1873 
[epoch 18] train_loss(avg per step)=0.3745 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=8.1739 qwk=('0.2681', '0.3398', '0.3224') averageQWK=0.3101 macroEMD=0.3055 tailR0=('0.1548', '0.3571', '0.0000') tailR0avg=0.1706
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    4    1
    12   18   40   19    9
     4   13   57   71   10
     0    1    9   46    3
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    3    6    0
     9   23   23   27    0
     3   13   51   96    3
     0    1    7   52    1
     0    0    1    0    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    3    0
     0   53   32   19    0
     0   45   62   73    0
     0    0   10   26    0
     0    0    0    0    0
[epoch 19] step 2/44: loss=0.0958 
[epoch 19] step 4/44: loss=0.0872 
[epoch 19] step 6/44: loss=0.0389 
[epoch 19] step 8/44: loss=0.0570 
[epoch 19] step 10/44: loss=0.0476 
[epoch 19] step 12/44: loss=0.0482 
[epoch 19] step 14/44: loss=0.0504 
[epoch 19] step 16/44: loss=0.0577 
[epoch 19] step 18/44: loss=0.0586 
[epoch 19] step 20/44: loss=0.0651 
[epoch 19] step 22/44: loss=0.0625 
[epoch 19] step 24/44: loss=0.0604 
[epoch 19] step 26/44: loss=0.0578 
[epoch 19] step 28/44: loss=0.0595 
[epoch 19] step 30/44: loss=0.0556 
[epoch 19] step 32/44: loss=0.0511 
[epoch 19] step 34/44: loss=0.0469 
[epoch 19] step 36/44: loss=0.0496 
[epoch 19] step 38/44: loss=0.0499 
[epoch 19] step 40/44: loss=0.0539 
[epoch 19] step 42/44: loss=0.0562 
[epoch 19] step 44/44: loss=0.0545 
[epoch 19] train_loss(avg per step)=0.1091 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=8.6846 qwk=('0.2002', '0.2866', '0.3632') averageQWK=0.2833 macroEMD=0.3015 tailR0=('0.2381', '0.3571', '0.0000') tailR0avg=0.1984
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    3    2
     7   11   46   22   12
     3    9   59   65   19
     0    1    9   42    7
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    1    4    6    0
     7   12   30   33    0
     4    8   50  102    2
     0    1    5   54    1
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   44   50   10    0
     0   37  101   42    0
     0    0   13   23    0
     0    0    0    0    0
[epoch 20] step 2/44: loss=-0.0959 
[epoch 20] step 4/44: loss=0.0125 
[epoch 20] step 6/44: loss=-0.0022 
[epoch 20] step 8/44: loss=-0.0202 
[epoch 20] step 10/44: loss=-0.0061 
[epoch 20] step 12/44: loss=-0.0201 
[epoch 20] step 14/44: loss=-0.0242 
[epoch 20] step 16/44: loss=-0.0211 
[epoch 20] step 18/44: loss=-0.0281 
[epoch 20] step 20/44: loss=-0.0166 
[epoch 20] step 22/44: loss=-0.0217 
[epoch 20] step 24/44: loss=-0.0207 
[epoch 20] step 26/44: loss=-0.0151 
[epoch 20] step 28/44: loss=-0.0134 
[epoch 20] step 30/44: loss=-0.0122 
[epoch 20] step 32/44: loss=-0.0113 
[epoch 20] step 34/44: loss=-0.0063 
[epoch 20] step 36/44: loss=0.0007 
[epoch 20] step 38/44: loss=0.0022 
[epoch 20] step 40/44: loss=0.0035 
[epoch 20] step 42/44: loss=0.0101 
[epoch 20] step 44/44: loss=0.0178 
[epoch 20] train_loss(avg per step)=0.0355 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=8.2993 qwk=('0.2901', '0.3389', '0.3389') averageQWK=0.3226 macroEMD=0.2967 tailR0=('0.3929', '0.3571', '0.0000') tailR0avg=0.2500
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    3    2
    23   15   30   19   11
    10   14   56   60   15
     1    0   11   36   11
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    2    5    0
    14   28   20   18    2
     8   29   45   80    4
     0    5   12   41    3
     0    0    1    0    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   60   32   12    0
     0   65   70   45    0
     0    1   12   23    0
     0    0    0    0    0
[epoch 21] step 2/44: loss=0.0006 
[epoch 21] step 4/44: loss=-0.0268 
[epoch 21] step 6/44: loss=-0.0132 
[epoch 21] step 8/44: loss=0.0244 
[epoch 21] step 10/44: loss=-0.0019 
[epoch 21] step 12/44: loss=0.0031 
[epoch 21] step 14/44: loss=-0.0064 
[epoch 21] step 16/44: loss=-0.0259 
[epoch 21] step 18/44: loss=-0.0356 
[epoch 21] step 20/44: loss=-0.0358 
[epoch 21] step 22/44: loss=-0.0450 
[epoch 21] step 24/44: loss=-0.0465 
[epoch 21] step 26/44: loss=-0.0573 
[epoch 21] step 28/44: loss=-0.0522 
[epoch 21] step 30/44: loss=-0.0536 
[epoch 21] step 32/44: loss=-0.0518 
[epoch 21] step 34/44: loss=-0.0523 
[epoch 21] step 36/44: loss=-0.0538 
[epoch 21] step 38/44: loss=-0.0579 
[epoch 21] step 40/44: loss=-0.0589 
[epoch 21] step 42/44: loss=-0.0566 
[epoch 21] step 44/44: loss=-0.0589 
[epoch 21] train_loss(avg per step)=-0.1179 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=8.9820 qwk=('0.2407', '0.2817', '0.3080') averageQWK=0.2768 macroEMD=0.3027 tailR0=('0.2381', '0.3571', '0.0000') tailR0avg=0.1984
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    3    2
    10   15   46   16   11
     4   12   74   51   14
     0    1   14   35    9
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    1    8    0
    10   25   14   31    2
     6   18   37  100    5
     0    3    5   50    3
     0    0    1    0    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   64   26   14    0
     0   71   59   50    0
     0    4   10   21    1
     0    0    0    0    0
[epoch 22] step 2/44: loss=0.0102 
[epoch 22] step 4/44: loss=0.0090 
[epoch 22] step 6/44: loss=-0.0093 
[epoch 22] step 8/44: loss=-0.0308 
[epoch 22] step 10/44: loss=-0.0343 
[epoch 22] step 12/44: loss=-0.0617 
[epoch 22] step 14/44: loss=-0.0782 
[epoch 22] step 16/44: loss=-0.0847 
[epoch 22] step 18/44: loss=-0.0785 
[epoch 22] step 20/44: loss=-0.0706 
[epoch 22] step 22/44: loss=-0.0769 
[epoch 22] step 24/44: loss=-0.0783 
[epoch 22] step 26/44: loss=-0.0847 
[epoch 22] step 28/44: loss=-0.0905 
[epoch 22] step 30/44: loss=-0.0915 
[epoch 22] step 32/44: loss=-0.0911 
[epoch 22] step 34/44: loss=-0.0913 
[epoch 22] step 36/44: loss=-0.0954 
[epoch 22] step 38/44: loss=-0.0945 
[epoch 22] step 40/44: loss=-0.0823 
[epoch 22] step 42/44: loss=-0.0791 
[epoch 22] step 44/44: loss=-0.0703 
[epoch 22] train_loss(avg per step)=-0.1405 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=9.3566 qwk=('0.2873', '0.3369', '0.3235') averageQWK=0.3159 macroEMD=0.2941 tailR0=('0.0714', '0.1071', '0.0000') tailR0avg=0.0595
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    3    2
    16   11   49   15    7
     3   12   73   57   10
     1    0   11   40    7
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    1    6    0
     8   32   17   24    1
     7   18   43   96    2
     0    4    5   51    1
     0    0    1    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   55   37   12    0
     0   68   71   41    0
     0    2   10   24    0
     0    0    0    0    0
[epoch 23] step 2/44: loss=-0.2105 
[epoch 23] step 4/44: loss=-0.1595 
[epoch 23] step 6/44: loss=-0.1824 
[epoch 23] step 8/44: loss=-0.1681 
[epoch 23] step 10/44: loss=-0.1726 
[epoch 23] step 12/44: loss=-0.1812 
[epoch 23] step 14/44: loss=-0.1671 
[epoch 23] step 16/44: loss=-0.1465 
[epoch 23] step 18/44: loss=-0.1423 
[epoch 23] step 20/44: loss=-0.1445 
[epoch 23] step 22/44: loss=-0.1493 
[epoch 23] step 24/44: loss=-0.1515 
[epoch 23] step 26/44: loss=-0.1493 
[epoch 23] step 28/44: loss=-0.1509 
[epoch 23] step 30/44: loss=-0.1490 
[epoch 23] step 32/44: loss=-0.1516 
[epoch 23] step 34/44: loss=-0.1444 
[epoch 23] step 36/44: loss=-0.1419 
[epoch 23] step 38/44: loss=-0.1323 
[epoch 23] step 40/44: loss=-0.1249 
[epoch 23] step 42/44: loss=-0.1261 
[epoch 23] step 44/44: loss=-0.1308 
[epoch 23] train_loss(avg per step)=-0.2617 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=11.5200 qwk=('0.2332', '0.2981', '0.2257') averageQWK=0.2523 macroEMD=0.3061 tailR0=('0.1548', '0.1071', '0.0000') tailR0avg=0.0873
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    4    1
    17    8   43   17   13
     5   12   56   62   20
     1    0   11   38    9
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    1    6    1
     6   25   22   28    1
     5   17   41  100    3
     0    3    3   54    1
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    3    0
     0   34   32   38    0
     0   24   63   93    0
     0    0    6   30    0
     0    0    0    0    0
[epoch 24] step 2/44: loss=-0.1770 
[epoch 24] step 4/44: loss=-0.1398 
[epoch 24] step 6/44: loss=-0.1155 
[epoch 24] step 8/44: loss=-0.1330 
[epoch 24] step 10/44: loss=-0.1368 
[epoch 24] step 12/44: loss=-0.1371 
[epoch 24] step 14/44: loss=-0.1268 
[epoch 24] step 16/44: loss=-0.1383 
[epoch 24] step 18/44: loss=-0.1458 
[epoch 24] step 20/44: loss=-0.1475 
[epoch 24] step 22/44: loss=-0.1528 
[epoch 24] step 24/44: loss=-0.1531 
[epoch 24] step 26/44: loss=-0.1515 
[epoch 24] step 28/44: loss=-0.1464 
[epoch 24] step 30/44: loss=-0.1516 
[epoch 24] step 32/44: loss=-0.1556 
[epoch 24] step 34/44: loss=-0.1525 
[epoch 24] step 36/44: loss=-0.1546 
[epoch 24] step 38/44: loss=-0.1575 
[epoch 24] step 40/44: loss=-0.1590 
[epoch 24] step 42/44: loss=-0.1624 
[epoch 24] step 44/44: loss=-0.1606 
[epoch 24] train_loss(avg per step)=-0.3212 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=9.2970 qwk=('0.2709', '0.3637', '0.3496') averageQWK=0.3281 macroEMD=0.2905 tailR0=('0.0714', '0.1071', '0.0000') tailR0avg=0.0595
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    1    3    1
    11   31   24   20   12
     2   21   50   64   18
     0    3    7   41    8
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    1    6    0
     8   37   17   19    1
     3   32   46   83    2
     0    4    8   48    1
     0    0    1    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   58   36   10    0
     0   61   81   38    0
     0    2   12   22    0
     0    0    0    0    0
[epoch 25] step 2/44: loss=-0.2007 
[epoch 25] step 4/44: loss=-0.1716 
[epoch 25] step 6/44: loss=-0.1458 
[epoch 25] step 8/44: loss=-0.1627 
[epoch 25] step 10/44: loss=-0.1663 
[epoch 25] step 12/44: loss=-0.1700 
[epoch 25] step 14/44: loss=-0.1832 
[epoch 25] step 16/44: loss=-0.1844 
[epoch 25] step 18/44: loss=-0.1871 
[epoch 25] step 20/44: loss=-0.1871 
[epoch 25] step 22/44: loss=-0.1874 
[epoch 25] step 24/44: loss=-0.1908 
[epoch 25] step 26/44: loss=-0.1968 
[epoch 25] step 28/44: loss=-0.2008 
[epoch 25] step 30/44: loss=-0.1993 
[epoch 25] step 32/44: loss=-0.1997 
[epoch 25] step 34/44: loss=-0.1992 
[epoch 25] step 36/44: loss=-0.2003 
[epoch 25] step 38/44: loss=-0.2010 
[epoch 25] step 40/44: loss=-0.2043 
[epoch 25] step 42/44: loss=-0.2058 
[epoch 25] step 44/44: loss=-0.2069 
[epoch 25] train_loss(avg per step)=-0.4138 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=11.0078 qwk=('0.2475', '0.3407', '0.2584') averageQWK=0.2822 macroEMD=0.2970 tailR0=('0.0714', '0.0714', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
    14   12   47   15   10
     7   11   60   62   15
     1    0   11   44    3
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    1    6    0
     7   26   26   22    1
     3   15   59   86    3
     0    3    8   49    1
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    3    0
     0   37   43   24    0
     0   34   74   72    0
     0    0   10   26    0
     0    0    0    0    0
[epoch 26] step 2/44: loss=-0.2576 
[epoch 26] step 4/44: loss=-0.2753 
[epoch 26] step 6/44: loss=-0.2775 
[epoch 26] step 8/44: loss=-0.2616 
[epoch 26] step 10/44: loss=-0.2590 
[epoch 26] step 12/44: loss=-0.2474 
[epoch 26] step 14/44: loss=-0.2422 
[epoch 26] step 16/44: loss=-0.2391 
[epoch 26] step 18/44: loss=-0.2360 
[epoch 26] step 20/44: loss=-0.2339 
[epoch 26] step 22/44: loss=-0.2359 
[epoch 26] step 24/44: loss=-0.2330 
[epoch 26] step 26/44: loss=-0.2354 
[epoch 26] step 28/44: loss=-0.2341 
[epoch 26] step 30/44: loss=-0.2363 
[epoch 26] step 32/44: loss=-0.2359 
[epoch 26] step 34/44: loss=-0.2339 
[epoch 26] step 36/44: loss=-0.2344 
[epoch 26] step 38/44: loss=-0.2332 
[epoch 26] step 40/44: loss=-0.2338 
[epoch 26] step 42/44: loss=-0.2364 
[epoch 26] step 44/44: loss=-0.2396 
[epoch 26] train_loss(avg per step)=-0.4792 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=12.0776 qwk=('0.2290', '0.2931', '0.2768') averageQWK=0.2663 macroEMD=0.3017 tailR0=('0.0714', '0.0714', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    3    2
    15    9   47   14   13
     7   10   62   57   19
     1    0    9   40    9
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    8    0
     5   31   12   33    1
     2   18   38  105    3
     0    3    2   54    2
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    3    0
     0   49   34   20    1
     0   53   60   67    0
     0    1    8   27    0
     0    0    0    0    0
[epoch 27] step 2/44: loss=-0.2574 
[epoch 27] step 4/44: loss=-0.2427 
[epoch 27] step 6/44: loss=-0.2598 
[epoch 27] step 8/44: loss=-0.2553 
[epoch 27] step 10/44: loss=-0.2554 
[epoch 27] step 12/44: loss=-0.2519 
[epoch 27] step 14/44: loss=-0.2523 
[epoch 27] step 16/44: loss=-0.2496 
[epoch 27] step 18/44: loss=-0.2478 
[epoch 27] step 20/44: loss=-0.2506 
[epoch 27] step 22/44: loss=-0.2550 
[epoch 27] step 24/44: loss=-0.2566 
[epoch 27] step 26/44: loss=-0.2552 
[epoch 27] step 28/44: loss=-0.2547 
[epoch 27] step 30/44: loss=-0.2587 
[epoch 27] step 32/44: loss=-0.2605 
[epoch 27] step 34/44: loss=-0.2588 
[epoch 27] step 36/44: loss=-0.2551 
[epoch 27] step 38/44: loss=-0.2505 
[epoch 27] step 40/44: loss=-0.2492 
[epoch 27] step 42/44: loss=-0.2465 
[epoch 27] step 44/44: loss=-0.2420 
[epoch 27] train_loss(avg per step)=-0.4840 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=10.6181 qwk=('0.2740', '0.3367', '0.3193') averageQWK=0.3100 macroEMD=0.2919 tailR0=('0.1548', '0.1071', '0.0000') tailR0avg=0.0873
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    1    3    1
    11   13   50   16    8
     3   15   63   60   14
     0    1   13   39    6
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    2    6    0
     7   23   32   20    0
     3   16   61   83    3
     0    2   15   41    3
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   55   34   15    0
     0   55   68   57    0
     0    2   10   24    0
     0    0    0    0    0
[epoch 28] step 2/44: loss=-0.2488 
[epoch 28] step 4/44: loss=-0.2539 
[epoch 28] step 6/44: loss=-0.2394 
[epoch 28] step 8/44: loss=-0.2482 
[epoch 28] step 10/44: loss=-0.2575 
[epoch 28] step 12/44: loss=-0.2544 
[epoch 28] step 14/44: loss=-0.2603 
[epoch 28] step 16/44: loss=-0.2593 
[epoch 28] step 18/44: loss=-0.2640 
[epoch 28] step 20/44: loss=-0.2644 
[epoch 28] step 22/44: loss=-0.2676 
[epoch 28] step 24/44: loss=-0.2638 
[epoch 28] step 26/44: loss=-0.2630 
[epoch 28] step 28/44: loss=-0.2658 
[epoch 28] step 30/44: loss=-0.2627 
[epoch 28] step 32/44: loss=-0.2644 
[epoch 28] step 34/44: loss=-0.2646 
[epoch 28] step 36/44: loss=-0.2627 
[epoch 28] step 38/44: loss=-0.2633 
[epoch 28] step 40/44: loss=-0.2643 
[epoch 28] step 42/44: loss=-0.2631 
[epoch 28] step 44/44: loss=-0.2625 
[epoch 28] train_loss(avg per step)=-0.5249 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=12.2282 qwk=('0.2256', '0.2849', '0.3009') averageQWK=0.2705 macroEMD=0.2906 tailR0=('0.1548', '0.1071', '0.0000') tailR0avg=0.0873
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    3    2
     4   16   50   19    9
     1   12   66   65   11
     0    1   11   41    6
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    1    8    0
     5   19   27   31    0
     1   14   45  105    1
     0    2    6   51    2
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   49   38   17    0
     0   55   64   61    0
     0    0   12   24    0
     0    0    0    0    0
[epoch 29] step 2/44: loss=-0.2773 
[epoch 29] step 4/44: loss=-0.2878 
[epoch 29] step 6/44: loss=-0.2898 
[epoch 29] step 8/44: loss=-0.2877 
[epoch 29] step 10/44: loss=-0.2840 
[epoch 29] step 12/44: loss=-0.2824 
[epoch 29] step 14/44: loss=-0.2861 
[epoch 29] step 16/44: loss=-0.2798 
[epoch 29] step 18/44: loss=-0.2831 
[epoch 29] step 20/44: loss=-0.2774 
[epoch 29] step 22/44: loss=-0.2744 
[epoch 29] step 24/44: loss=-0.2727 
[epoch 29] step 26/44: loss=-0.2754 
[epoch 29] step 28/44: loss=-0.2736 
[epoch 29] step 30/44: loss=-0.2740 
[epoch 29] step 32/44: loss=-0.2747 
[epoch 29] step 34/44: loss=-0.2758 
[epoch 29] step 36/44: loss=-0.2752 
[epoch 29] step 38/44: loss=-0.2728 
[epoch 29] step 40/44: loss=-0.2706 
[epoch 29] step 42/44: loss=-0.2704 
[epoch 29] step 44/44: loss=-0.2700 
[epoch 29] train_loss(avg per step)=-0.5400 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=11.8632 qwk=('0.2372', '0.3060', '0.3218') averageQWK=0.2884 macroEMD=0.2953 tailR0=('0.3214', '0.1071', '0.0000') tailR0avg=0.1429
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    3    2
    20   16   34   12   16
     9   17   56   48   25
     2    2    8   36   11
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    1    8    0
    12   28   14   27    1
     6   23   38   95    4
     0    4    6   49    2
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   60   30   13    1
     0   62   64   54    0
     0    2   11   22    1
     0    0    0    0    0
[epoch 30] step 2/44: loss=-0.3133 
[epoch 30] step 4/44: loss=-0.2704 
[epoch 30] step 6/44: loss=-0.2690 
[epoch 30] step 8/44: loss=-0.2603 
[epoch 30] step 10/44: loss=-0.2642 
[epoch 30] step 12/44: loss=-0.2725 
[epoch 30] step 14/44: loss=-0.2727 
[epoch 30] step 16/44: loss=-0.2791 
[epoch 30] step 18/44: loss=-0.2795 
[epoch 30] step 20/44: loss=-0.2800 
[epoch 30] step 22/44: loss=-0.2814 
[epoch 30] step 24/44: loss=-0.2836 
[epoch 30] step 26/44: loss=-0.2845 
[epoch 30] step 28/44: loss=-0.2850 
[epoch 30] step 30/44: loss=-0.2816 
[epoch 30] step 32/44: loss=-0.2841 
[epoch 30] step 34/44: loss=-0.2832 
[epoch 30] step 36/44: loss=-0.2851 
[epoch 30] step 38/44: loss=-0.2836 
[epoch 30] step 40/44: loss=-0.2832 
[epoch 30] step 42/44: loss=-0.2834 
[epoch 30] step 44/44: loss=-0.2815 
[epoch 30] train_loss(avg per step)=-0.5630 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=11.9169 qwk=('0.2698', '0.2976', '0.2987') averageQWK=0.2887 macroEMD=0.2979 tailR0=('0.3214', '0.0714', '0.0000') tailR0avg=0.1310
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    3    2
    13   15   45   16    9
     4   14   57   55   25
     0    1   11   38    9
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    8    0
     6   29   20   26    1
     2   21   48   90    5
     0    3    8   47    3
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   47   37   20    0
     0   46   72   62    0
     0    0   11   25    0
     0    0    0    0    0
[epoch 31] step 2/44: loss=-0.3230 
[epoch 31] step 4/44: loss=-0.3284 
[epoch 31] step 6/44: loss=-0.3280 
[epoch 31] step 8/44: loss=-0.3151 
[epoch 31] step 10/44: loss=-0.3133 
[epoch 31] step 12/44: loss=-0.3047 
[epoch 31] step 14/44: loss=-0.3055 
[epoch 31] step 16/44: loss=-0.3103 
[epoch 31] step 18/44: loss=-0.3049 
[epoch 31] step 20/44: loss=-0.3070 
[epoch 31] step 22/44: loss=-0.3037 
[epoch 31] step 24/44: loss=-0.3016 
[epoch 31] step 26/44: loss=-0.3014 
[epoch 31] step 28/44: loss=-0.3015 
[epoch 31] step 30/44: loss=-0.3001 
[epoch 31] step 32/44: loss=-0.2984 
[epoch 31] step 34/44: loss=-0.2986 
[epoch 31] step 36/44: loss=-0.2984 
[epoch 31] step 38/44: loss=-0.2966 
[epoch 31] step 40/44: loss=-0.2980 
[epoch 31] step 42/44: loss=-0.2960 
[epoch 31] step 44/44: loss=-0.2964 
[epoch 31] train_loss(avg per step)=-0.5928 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=11.2477 qwk=('0.2693', '0.3730', '0.3131') averageQWK=0.3185 macroEMD=0.2932 tailR0=('0.1548', '0.3571', '0.0000') tailR0avg=0.1706
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    3    2
    17   16   41   15    9
     8   13   57   57   20
     1    1   10   38    9
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    2    5    0
     8   33   24   16    1
     3   21   59   76    7
     0    5   10   42    4
     0    0    1    0    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   46   40   18    0
     0   48   71   61    0
     0    0    9   27    0
     0    0    0    0    0
[epoch 32] step 2/44: loss=-0.2802 
[epoch 32] step 4/44: loss=-0.2972 
[epoch 32] step 6/44: loss=-0.3059 
[epoch 32] step 8/44: loss=-0.3054 
[epoch 32] step 10/44: loss=-0.3021 
[epoch 32] step 12/44: loss=-0.2930 
[epoch 32] step 14/44: loss=-0.2947 
[epoch 32] step 16/44: loss=-0.2935 
[epoch 32] step 18/44: loss=-0.2920 
[epoch 32] step 20/44: loss=-0.2874 
[epoch 32] step 22/44: loss=-0.2920 
[epoch 32] step 24/44: loss=-0.2941 
[epoch 32] step 26/44: loss=-0.2952 
[epoch 32] step 28/44: loss=-0.2958 
[epoch 32] step 30/44: loss=-0.2983 
[epoch 32] step 32/44: loss=-0.2991 
[epoch 32] step 34/44: loss=-0.3016 
[epoch 32] step 36/44: loss=-0.3032 
[epoch 32] step 38/44: loss=-0.3040 
[epoch 32] step 40/44: loss=-0.3042 
[epoch 32] step 42/44: loss=-0.3046 
[epoch 32] step 44/44: loss=-0.3061 
[epoch 32] train_loss(avg per step)=-0.6122 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=11.5952 qwk=('0.2997', '0.3775', '0.3299') averageQWK=0.3357 macroEMD=0.2867 tailR0=('0.0714', '0.0714', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    4    1
    13   20   42   18    5
     5   21   51   64   14
     0    1    9   44    5
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    1    6    0
     7   33   23   18    1
     2   25   50   85    4
     0    3    6   50    2
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   47   45   12    0
     0   53   73   54    0
     0    0   11   25    0
     0    0    0    0    0
[epoch 33] step 2/44: loss=-0.3144 
[epoch 33] step 4/44: loss=-0.3161 
[epoch 33] step 6/44: loss=-0.3201 
[epoch 33] step 8/44: loss=-0.3101 
[epoch 33] step 10/44: loss=-0.3060 
[epoch 33] step 12/44: loss=-0.3031 
[epoch 33] step 14/44: loss=-0.3055 
[epoch 33] step 16/44: loss=-0.3021 
[epoch 33] step 18/44: loss=-0.3055 
[epoch 33] step 20/44: loss=-0.3092 
[epoch 33] step 22/44: loss=-0.3084 
[epoch 33] step 24/44: loss=-0.3101 
[epoch 33] step 26/44: loss=-0.3107 
[epoch 33] step 28/44: loss=-0.3114 
[epoch 33] step 30/44: loss=-0.3112 
[epoch 33] step 32/44: loss=-0.3089 
[epoch 33] step 34/44: loss=-0.3099 
[epoch 33] step 36/44: loss=-0.3109 
[epoch 33] step 38/44: loss=-0.3109 
[epoch 33] step 40/44: loss=-0.3113 
[epoch 33] step 42/44: loss=-0.3101 
[epoch 33] step 44/44: loss=-0.3105 
[epoch 33] train_loss(avg per step)=-0.6210 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=11.8790 qwk=('0.2830', '0.3690', '0.3280') averageQWK=0.3267 macroEMD=0.2893 tailR0=('0.0714', '0.1071', '0.0000') tailR0avg=0.0595
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    3    2
    16   16   42   16    8
     5   15   57   60   18
     0    1   10   39    9
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    1    6    0
     8   32   20   21    1
     4   20   47   91    4
     0    3    5   52    1
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   48   44   12    0
     0   53   74   53    0
     0    0   12   24    0
     0    0    0    0    0
[epoch 34] step 2/44: loss=-0.3409 
[epoch 34] step 4/44: loss=-0.3300 
[epoch 34] step 6/44: loss=-0.3283 
[epoch 34] step 8/44: loss=-0.3225 
[epoch 34] step 10/44: loss=-0.3252 
[epoch 34] step 12/44: loss=-0.3265 
[epoch 34] step 14/44: loss=-0.3280 
[epoch 34] step 16/44: loss=-0.3283 
[epoch 34] step 18/44: loss=-0.3271 
[epoch 34] step 20/44: loss=-0.3251 
[epoch 34] step 22/44: loss=-0.3268 
[epoch 34] step 24/44: loss=-0.3256 
[epoch 34] step 26/44: loss=-0.3256 
[epoch 34] step 28/44: loss=-0.3241 
[epoch 34] step 30/44: loss=-0.3217 
[epoch 34] step 32/44: loss=-0.3231 
[epoch 34] step 34/44: loss=-0.3220 
[epoch 34] step 36/44: loss=-0.3206 
[epoch 34] step 38/44: loss=-0.3194 
[epoch 34] step 40/44: loss=-0.3189 
[epoch 34] step 42/44: loss=-0.3189 
[epoch 34] step 44/44: loss=-0.3197 
[epoch 34] train_loss(avg per step)=-0.6394 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=11.8230 qwk=('0.2745', '0.3308', '0.3454') averageQWK=0.3169 macroEMD=0.2894 tailR0=('0.0714', '0.0714', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    3    2
    14   17   42   17    8
     5   15   59   59   17
     0    2    8   40    9
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    1    7    0
     7   29   21   24    1
     2   18   52   90    4
     0    3    6   51    1
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   47   46   11    0
     0   48   82   50    0
     0    0   11   25    0
     0    0    0    0    0
[epoch 35] step 2/44: loss=-0.2993 
[epoch 35] step 4/44: loss=-0.3141 
[epoch 35] step 6/44: loss=-0.3168 
[epoch 35] step 8/44: loss=-0.3208 
[epoch 35] step 10/44: loss=-0.3179 
[epoch 35] step 12/44: loss=-0.3137 
[epoch 35] step 14/44: loss=-0.3139 
[epoch 35] step 16/44: loss=-0.3119 
[epoch 35] step 18/44: loss=-0.3119 
[epoch 35] step 20/44: loss=-0.3141 
[epoch 35] step 22/44: loss=-0.3141 
[epoch 35] step 24/44: loss=-0.3142 
[epoch 35] step 26/44: loss=-0.3149 
[epoch 35] step 28/44: loss=-0.3119 
[epoch 35] step 30/44: loss=-0.3118 
[epoch 35] step 32/44: loss=-0.3118 
[epoch 35] step 34/44: loss=-0.3123 
[epoch 35] step 36/44: loss=-0.3130 
[epoch 35] step 38/44: loss=-0.3135 
[epoch 35] step 40/44: loss=-0.3132 
[epoch 35] step 42/44: loss=-0.3136 
[epoch 35] step 44/44: loss=-0.3131 
[epoch 35] train_loss(avg per step)=-0.6262 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=12.0779 qwk=('0.2677', '0.3616', '0.3166') averageQWK=0.3153 macroEMD=0.2922 tailR0=('0.0714', '0.0714', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    3    2
    15   15   42   17    9
     5   15   56   60   19
     0    1    9   40    9
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    1    6    0
     7   35   17   22    1
     3   22   43   94    4
     0    3    7   48    3
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   48   41   15    0
     0   49   74   57    0
     0    1   10   25    0
     0    0    0    0    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-1-reassignment-0/fold2/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-1-reassignment-0/fold2/metrics.json
Done.
