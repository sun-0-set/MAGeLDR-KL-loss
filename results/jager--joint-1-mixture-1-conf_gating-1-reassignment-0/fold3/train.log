[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=5.8772 
[epoch 1] step 4/44: loss=6.0673 
[epoch 1] step 6/44: loss=5.8622 
[epoch 1] step 8/44: loss=5.6811 
[epoch 1] step 10/44: loss=5.8208 
[epoch 1] step 12/44: loss=5.8428 
[epoch 1] step 14/44: loss=5.7950 
[epoch 1] step 16/44: loss=5.8146 
[epoch 1] step 18/44: loss=5.8958 
[epoch 1] step 20/44: loss=5.9482 
[epoch 1] step 22/44: loss=5.9675 
[epoch 1] step 24/44: loss=5.9721 
[epoch 1] step 26/44: loss=5.9961 
[epoch 1] step 28/44: loss=5.9637 
[epoch 1] step 30/44: loss=5.9221 
[epoch 1] step 32/44: loss=5.9096 
[epoch 1] step 34/44: loss=5.8717 
[epoch 1] step 36/44: loss=5.8481 
[epoch 1] step 38/44: loss=5.7800 
[epoch 1] step 40/44: loss=5.7258 
[epoch 1] step 42/44: loss=5.6514 
[epoch 1] step 44/44: loss=5.5680 
[epoch 1] train_loss(avg per step)=11.1359 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=6.2274 qwk=('-0.0340', '0.1260', '0.1088') averageQWK=0.0669 macroEMD=0.3715 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    8    0
     0    4    0   36    0
     0   20    0  108    0
     0   24    0   98    0
     0    1    0   26    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   29   19    0
     6    0   47   60    0
     6    0   52   90    0
     0    0    2    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    3   64    4    0
     0    0  142    9    0
     0    0   84   15    0
     0    0    3    0    0
[epoch 2] step 2/44: loss=4.1516 
[epoch 2] step 4/44: loss=3.9424 
[epoch 2] step 6/44: loss=3.9499 
[epoch 2] step 8/44: loss=3.7619 
[epoch 2] step 10/44: loss=3.8507 
[epoch 2] step 12/44: loss=3.8267 
[epoch 2] step 14/44: loss=3.7588 
[epoch 2] step 16/44: loss=3.6503 
[epoch 2] step 18/44: loss=3.5559 
[epoch 2] step 20/44: loss=3.4944 
[epoch 2] step 22/44: loss=3.4384 
[epoch 2] step 24/44: loss=3.4113 
[epoch 2] step 26/44: loss=3.3720 
[epoch 2] step 28/44: loss=3.3379 
[epoch 2] step 30/44: loss=3.3133 
[epoch 2] step 32/44: loss=3.2974 
[epoch 2] step 34/44: loss=3.2688 
[epoch 2] step 36/44: loss=3.2401 
[epoch 2] step 38/44: loss=3.2208 
[epoch 2] step 40/44: loss=3.1969 
[epoch 2] step 42/44: loss=3.1829 
[epoch 2] step 44/44: loss=3.1688 
[epoch 2] train_loss(avg per step)=6.3376 lambda[min,max]=[0.500452,1.000000]
[epoch 2] val_loss=3.5801 qwk=('0.4695', '0.4120', '0.4917') averageQWK=0.4577 macroEMD=0.3758 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   27   12    1    0
     0   60   42   26    0
     0   22   35   65    0
     0    2    2   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   41    7    0
     0    0   67   46    0
     0    0   38  110    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   63    1    0
     0    1  121   29    0
     0    0   35   64    0
     0    0    0    3    0
[epoch 3] step 2/44: loss=2.9122 
[epoch 3] step 4/44: loss=2.8644 
[epoch 3] step 6/44: loss=2.8908 
[epoch 3] step 8/44: loss=2.7606 
[epoch 3] step 10/44: loss=2.7180 
[epoch 3] step 12/44: loss=2.7016 
[epoch 3] step 14/44: loss=2.7356 
[epoch 3] step 16/44: loss=2.7374 
[epoch 3] step 18/44: loss=2.7114 
[epoch 3] step 20/44: loss=2.6953 
[epoch 3] step 22/44: loss=2.6722 
[epoch 3] step 24/44: loss=2.7198 
[epoch 3] step 26/44: loss=2.6983 
[epoch 3] step 28/44: loss=2.6768 
[epoch 3] step 30/44: loss=2.6703 
[epoch 3] step 32/44: loss=2.6654 
[epoch 3] step 34/44: loss=2.6542 
[epoch 3] step 36/44: loss=2.6341 
[epoch 3] step 38/44: loss=2.6205 
[epoch 3] step 40/44: loss=2.6105 
[epoch 3] step 42/44: loss=2.5961 
[epoch 3] step 44/44: loss=2.5756 
[epoch 3] train_loss(avg per step)=5.1512 lambda[min,max]=[0.510228,1.000000]
[epoch 3] val_loss=4.0699 qwk=('0.2332', '0.4800', '0.1864') averageQWK=0.2999 macroEMD=0.3547 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    0    0
     0    0   40    0    0
     0    0  122    6    0
     0    0   94   28    0
     0    0   14   13    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   34    1   13    0
     0   47    1   65    0
     0   21    1  126    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   69    0    0
     0    0  148    3    0
     0    0   82   17    0
     0    0    2    1    0
[epoch 4] step 2/44: loss=2.6258 
[epoch 4] step 4/44: loss=2.6318 
[epoch 4] step 6/44: loss=2.5417 
[epoch 4] step 8/44: loss=2.4938 
[epoch 4] step 10/44: loss=2.4200 
[epoch 4] step 12/44: loss=2.4688 
[epoch 4] step 14/44: loss=2.4382 
[epoch 4] step 16/44: loss=2.4380 
[epoch 4] step 18/44: loss=2.4356 
[epoch 4] step 20/44: loss=2.4507 
[epoch 4] step 22/44: loss=2.4293 
[epoch 4] step 24/44: loss=2.4275 
[epoch 4] step 26/44: loss=2.4221 
[epoch 4] step 28/44: loss=2.4224 
[epoch 4] step 30/44: loss=2.4072 
[epoch 4] step 32/44: loss=2.4066 
[epoch 4] step 34/44: loss=2.4080 
[epoch 4] step 36/44: loss=2.4029 
[epoch 4] step 38/44: loss=2.3951 
[epoch 4] step 40/44: loss=2.3818 
[epoch 4] step 42/44: loss=2.3720 
[epoch 4] step 44/44: loss=2.3521 
[epoch 4] train_loss(avg per step)=4.7043 lambda[min,max]=[0.508830,1.000000]
[epoch 4] val_loss=3.9433 qwk=('0.2268', '0.4129', '0.2545') averageQWK=0.2981 macroEMD=0.3461 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    0    0
     0    0   40    0    0
     0    0  124    4    0
     0    0   89   33    0
     0    0   17   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    1   37   10    0
     0    0   66   47    0
     0    0   39  109    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   69    0    0
     0    0  147    4    0
     0    0   73   26    0
     0    0    2    1    0
[epoch 5] step 2/44: loss=2.0694 
[epoch 5] step 4/44: loss=2.2118 
[epoch 5] step 6/44: loss=2.2525 
[epoch 5] step 8/44: loss=2.2025 
[epoch 5] step 10/44: loss=2.1924 
[epoch 5] step 12/44: loss=2.1608 
[epoch 5] step 14/44: loss=2.1367 
[epoch 5] step 16/44: loss=2.1330 
[epoch 5] step 18/44: loss=2.1666 
[epoch 5] step 20/44: loss=2.1426 
[epoch 5] step 22/44: loss=2.1386 
[epoch 5] step 24/44: loss=2.1501 
[epoch 5] step 26/44: loss=2.1462 
[epoch 5] step 28/44: loss=2.1343 
[epoch 5] step 30/44: loss=2.1401 
[epoch 5] step 32/44: loss=2.1634 
[epoch 5] step 34/44: loss=2.1653 
[epoch 5] step 36/44: loss=2.1726 
[epoch 5] step 38/44: loss=2.1789 
[epoch 5] step 40/44: loss=2.1616 
[epoch 5] step 42/44: loss=2.1732 
[epoch 5] step 44/44: loss=2.1926 
[epoch 5] train_loss(avg per step)=4.3853 lambda[min,max]=[0.506076,1.000000]
[epoch 5] val_loss=3.8709 qwk=('0.4408', '0.4363', '0.4155') averageQWK=0.4309 macroEMD=0.3368 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    0    0
     0    1   33    6    0
     0    0   71   57    0
     0    0   23   99    0
     0    0    3   24    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5   24   19    0
     0    1   37   75    0
     0    0    8  140    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   10   47   14    0
     0    1   70   80    0
     0    0   12   87    0
     0    0    1    2    0
[epoch 6] step 2/44: loss=2.1368 
[epoch 6] step 4/44: loss=1.9791 
[epoch 6] step 6/44: loss=2.0739 
[epoch 6] step 8/44: loss=2.1955 
[epoch 6] step 10/44: loss=2.2319 
[epoch 6] step 12/44: loss=2.1822 
[epoch 6] step 14/44: loss=2.2052 
[epoch 6] step 16/44: loss=2.1853 
[epoch 6] step 18/44: loss=2.1960 
[epoch 6] step 20/44: loss=2.1801 
[epoch 6] step 22/44: loss=2.1616 
[epoch 6] step 24/44: loss=2.1486 
[epoch 6] step 26/44: loss=2.1319 
[epoch 6] step 28/44: loss=2.1341 
[epoch 6] step 30/44: loss=2.1051 
[epoch 6] step 32/44: loss=2.1011 
[epoch 6] step 34/44: loss=2.1005 
[epoch 6] step 36/44: loss=2.1038 
[epoch 6] step 38/44: loss=2.1052 
[epoch 6] step 40/44: loss=2.1016 
[epoch 6] step 42/44: loss=2.0935 
[epoch 6] step 44/44: loss=2.0939 
[epoch 6] train_loss(avg per step)=4.1878 lambda[min,max]=[0.511194,1.000000]
[epoch 6] val_loss=3.7545 qwk=('0.5222', '0.4932', '0.5257') averageQWK=0.5137 macroEMD=0.3338 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   11   24    5    0
     0    4   92   32    0
     0    0   43   79    0
     0    0    5   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   21   17   10    0
     0   14   57   42    0
     0    8   37  103    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   38   20   13    0
     0   27   55   69    0
     0    1   12   86    0
     0    0    1    2    0
[epoch 7] step 2/44: loss=1.8563 
[epoch 7] step 4/44: loss=1.8161 
[epoch 7] step 6/44: loss=1.8305 
[epoch 7] step 8/44: loss=1.8409 
[epoch 7] step 10/44: loss=1.8453 
[epoch 7] step 12/44: loss=1.8039 
[epoch 7] step 14/44: loss=1.7855 
[epoch 7] step 16/44: loss=1.8005 
[epoch 7] step 18/44: loss=1.8300 
[epoch 7] step 20/44: loss=1.8121 
[epoch 7] step 22/44: loss=1.8229 
[epoch 7] step 24/44: loss=1.8346 
[epoch 7] step 26/44: loss=1.8363 
[epoch 7] step 28/44: loss=1.8380 
[epoch 7] step 30/44: loss=1.8418 
[epoch 7] step 32/44: loss=1.8446 
[epoch 7] step 34/44: loss=1.8487 
[epoch 7] step 36/44: loss=1.8541 
[epoch 7] step 38/44: loss=1.8569 
[epoch 7] step 40/44: loss=1.8583 
[epoch 7] step 42/44: loss=1.8596 
[epoch 7] step 44/44: loss=1.8522 
[epoch 7] train_loss(avg per step)=3.7045 lambda[min,max]=[0.500320,1.000000]
[epoch 7] val_loss=3.8276 qwk=('0.5100', '0.4185', '0.4900') averageQWK=0.4728 macroEMD=0.3276 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    9   27    4    0
     0    6   76   46    0
     0    0   38   84    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6   42    0    0
     0    3  101    9    0
     0    0   96   52    0
     0    0    3    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   10   60    1    0
     0    0  112   39    0
     0    0   35   64    0
     0    0    1    2    0
[epoch 8] step 2/44: loss=1.7120 
[epoch 8] step 4/44: loss=1.6976 
[epoch 8] step 6/44: loss=1.7106 
[epoch 8] step 8/44: loss=1.7159 
[epoch 8] step 10/44: loss=1.6817 
[epoch 8] step 12/44: loss=1.6805 
[epoch 8] step 14/44: loss=1.6922 
[epoch 8] step 16/44: loss=1.6857 
[epoch 8] step 18/44: loss=1.7228 
[epoch 8] step 20/44: loss=1.7307 
[epoch 8] step 22/44: loss=1.7315 
[epoch 8] step 24/44: loss=1.7226 
[epoch 8] step 26/44: loss=1.7363 
[epoch 8] step 28/44: loss=1.7330 
[epoch 8] step 30/44: loss=1.7248 
[epoch 8] step 32/44: loss=1.7304 
[epoch 8] step 34/44: loss=1.7390 
[epoch 8] step 36/44: loss=1.7615 
[epoch 8] step 38/44: loss=1.7702 
[epoch 8] step 40/44: loss=1.7667 
[epoch 8] step 42/44: loss=1.7745 
[epoch 8] step 44/44: loss=1.7805 
[epoch 8] train_loss(avg per step)=3.5611 lambda[min,max]=[0.500955,1.000000]
[epoch 8] val_loss=3.7481 qwk=('0.4570', '0.4478', '0.3804') averageQWK=0.4284 macroEMD=0.3298 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    0    0
     0    4   31    5    0
     0    0   98   30    0
     0    0   50   72    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5   33   10    0
     0    2   78   33    0
     0    0   52   96    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   58    1    0
     0    1  136   14    0
     0    0   64   35    0
     0    0    2    1    0
[epoch 9] step 2/44: loss=1.5206 
[epoch 9] step 4/44: loss=1.6109 
[epoch 9] step 6/44: loss=1.6980 
[epoch 9] step 8/44: loss=1.6829 
[epoch 9] step 10/44: loss=1.7387 
[epoch 9] step 12/44: loss=1.6717 
[epoch 9] step 14/44: loss=1.6480 
[epoch 9] step 16/44: loss=1.6643 
[epoch 9] step 18/44: loss=1.6264 
[epoch 9] step 20/44: loss=1.6168 
[epoch 9] step 22/44: loss=1.6291 
[epoch 9] step 24/44: loss=1.6325 
[epoch 9] step 26/44: loss=1.6342 
[epoch 9] step 28/44: loss=1.6251 
[epoch 9] step 30/44: loss=1.6225 
[epoch 9] step 32/44: loss=1.6126 
[epoch 9] step 34/44: loss=1.5993 
[epoch 9] step 36/44: loss=1.5901 
[epoch 9] step 38/44: loss=1.5856 
[epoch 9] step 40/44: loss=1.5814 
[epoch 9] step 42/44: loss=1.5812 
[epoch 9] step 44/44: loss=1.5808 
[epoch 9] train_loss(avg per step)=3.1617 lambda[min,max]=[0.500566,1.000000]
[epoch 9] val_loss=3.8777 qwk=('0.5628', '0.5615', '0.5771') averageQWK=0.5671 macroEMD=0.3094 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   23   13    4    0
     0   29   76   23    0
     0    3   47   72    0
     0    0    5   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   19   25    4    0
     0   11   79   23    0
     0    3   55   90    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   55   16    0    0
     0   66   59   26    0
     0    6   34   59    0
     0    0    1    2    0
[epoch 10] step 2/44: loss=1.7681 
[epoch 10] step 4/44: loss=1.8640 
[epoch 10] step 6/44: loss=1.7118 
[epoch 10] step 8/44: loss=1.6213 
[epoch 10] step 10/44: loss=1.5486 
[epoch 10] step 12/44: loss=1.5372 
[epoch 10] step 14/44: loss=1.5487 
[epoch 10] step 16/44: loss=1.5076 
[epoch 10] step 18/44: loss=1.4723 
[epoch 10] step 20/44: loss=1.4734 
[epoch 10] step 22/44: loss=1.4617 
[epoch 10] step 24/44: loss=1.4651 
[epoch 10] step 26/44: loss=1.4628 
[epoch 10] step 28/44: loss=1.4546 
[epoch 10] step 30/44: loss=1.4567 
[epoch 10] step 32/44: loss=1.4384 
[epoch 10] step 34/44: loss=1.4216 
[epoch 10] step 36/44: loss=1.4137 
[epoch 10] step 38/44: loss=1.4240 
[epoch 10] step 40/44: loss=1.4140 
[epoch 10] step 42/44: loss=1.4062 
[epoch 10] step 44/44: loss=1.3981 
[epoch 10] train_loss(avg per step)=2.7961 lambda[min,max]=[0.500142,1.000000]
[epoch 10] val_loss=3.7417 qwk=('0.5055', '0.5457', '0.5222') averageQWK=0.5245 macroEMD=0.2958 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   10   27    3    0
     0    7   98   23    0
     0    0   53   69    0
     0    0    7   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   17   27    4    0
     0   12   77   24    0
     0    2   59   87    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   40    0    0
     0   21  117   13    0
     0    1   54   44    0
     0    0    2    1    0
[epoch 11] step 2/44: loss=1.3479 
[epoch 11] step 4/44: loss=1.2900 
[epoch 11] step 6/44: loss=1.2304 
[epoch 11] step 8/44: loss=1.2107 
[epoch 11] step 10/44: loss=1.2064 
[epoch 11] step 12/44: loss=1.2120 
[epoch 11] step 14/44: loss=1.1809 
[epoch 11] step 16/44: loss=1.1800 
[epoch 11] step 18/44: loss=1.1841 
[epoch 11] step 20/44: loss=1.1565 
[epoch 11] step 22/44: loss=1.1613 
[epoch 11] step 24/44: loss=1.1611 
[epoch 11] step 26/44: loss=1.1756 
[epoch 11] step 28/44: loss=1.1707 
[epoch 11] step 30/44: loss=1.1730 
[epoch 11] step 32/44: loss=1.1882 
[epoch 11] step 34/44: loss=1.1794 
[epoch 11] step 36/44: loss=1.1704 
[epoch 11] step 38/44: loss=1.1619 
[epoch 11] step 40/44: loss=1.1687 
[epoch 11] step 42/44: loss=1.1701 
[epoch 11] step 44/44: loss=1.1740 
[epoch 11] train_loss(avg per step)=2.3481 lambda[min,max]=[0.500001,1.000000]
[epoch 11] val_loss=4.2277 qwk=('0.4459', '0.4388', '0.4789') averageQWK=0.4546 macroEMD=0.2923 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    0    0
     0    2   31    7    0
     0    2   76   50    0
     0    0   32   90    0
     0    0    2   25    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    3   31   14    0
     0    2   69   42    0
     0    0   35  113    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   53    6    0
     0    2  103   46    0
     0    0   27   72    0
     0    0    1    2    0
[epoch 12] step 2/44: loss=0.8196 
[epoch 12] step 4/44: loss=0.9434 
[epoch 12] step 6/44: loss=1.0260 
[epoch 12] step 8/44: loss=1.0816 
[epoch 12] step 10/44: loss=1.0842 
[epoch 12] step 12/44: loss=1.1204 
[epoch 12] step 14/44: loss=1.1058 
[epoch 12] step 16/44: loss=1.0854 
[epoch 12] step 18/44: loss=1.0858 
[epoch 12] step 20/44: loss=1.0908 
[epoch 12] step 22/44: loss=1.1005 
[epoch 12] step 24/44: loss=1.0960 
[epoch 12] step 26/44: loss=1.1010 
[epoch 12] step 28/44: loss=1.0978 
[epoch 12] step 30/44: loss=1.1083 
[epoch 12] step 32/44: loss=1.0975 
[epoch 12] step 34/44: loss=1.0870 
[epoch 12] step 36/44: loss=1.0729 
[epoch 12] step 38/44: loss=1.0502 
[epoch 12] step 40/44: loss=1.0519 
[epoch 12] step 42/44: loss=1.0478 
[epoch 12] step 44/44: loss=1.0344 
[epoch 12] train_loss(avg per step)=2.0687 lambda[min,max]=[0.500011,1.000000]
[epoch 12] val_loss=4.6326 qwk=('0.4994', '0.5117', '0.5352') averageQWK=0.5155 macroEMD=0.2766 tailR0=('0.0185', '0.0500', '0.0000') tailR0avg=0.0228
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   14   12   14    0
     0   11   38   79    0
     0    1   12  109    0
     0    0    0   26    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     1   19   12   16    0
     0   18   37   58    0
     0    3   22  123    0
     0    0    0    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   44    5    0
     0    4  102   45    0
     0    0   30   69    0
     0    0    0    3    0
[epoch 13] step 2/44: loss=1.0650 
[epoch 13] step 4/44: loss=0.9370 
[epoch 13] step 6/44: loss=0.9110 
[epoch 13] step 8/44: loss=0.9235 
[epoch 13] step 10/44: loss=0.9062 
[epoch 13] step 12/44: loss=0.9168 
[epoch 13] step 14/44: loss=0.8971 
[epoch 13] step 16/44: loss=0.8685 
[epoch 13] step 18/44: loss=0.8657 
[epoch 13] step 20/44: loss=0.8328 
[epoch 13] step 22/44: loss=0.8413 
[epoch 13] step 24/44: loss=0.8275 
[epoch 13] step 26/44: loss=0.8349 
[epoch 13] step 28/44: loss=0.8436 
[epoch 13] step 30/44: loss=0.8351 
[epoch 13] step 32/44: loss=0.8210 
[epoch 13] step 34/44: loss=0.8200 
[epoch 13] step 36/44: loss=0.8132 
[epoch 13] step 38/44: loss=0.8240 
[epoch 13] step 40/44: loss=0.8309 
[epoch 13] step 42/44: loss=0.8400 
[epoch 13] step 44/44: loss=0.8526 
[epoch 13] train_loss(avg per step)=1.7051 lambda[min,max]=[0.500001,1.000000]
[epoch 13] val_loss=4.1523 qwk=('0.4820', '0.5352', '0.5416') averageQWK=0.5196 macroEMD=0.2831 tailR0=('0.0556', '0.1500', '0.0000') tailR0avg=0.0685
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    9   27    4    0
     0    8   94   26    0
     0    0   60   61    1
     0    0    7   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     1   23   17    7    0
     0   23   65   23    2
     0    6   54   85    3
     0    0    1    6    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   30   41    0    0
     0   17  115   19    0
     0    0   50   49    0
     0    0    2    1    0
[epoch 14] step 2/44: loss=0.7152 
[epoch 14] step 4/44: loss=0.6230 
[epoch 14] step 6/44: loss=0.6747 
[epoch 14] step 8/44: loss=0.7216 
[epoch 14] step 10/44: loss=0.7256 
[epoch 14] step 12/44: loss=0.7342 
[epoch 14] step 14/44: loss=0.7665 
[epoch 14] step 16/44: loss=0.7465 
[epoch 14] step 18/44: loss=0.7460 
[epoch 14] step 20/44: loss=0.7383 
[epoch 14] step 22/44: loss=0.7085 
[epoch 14] step 24/44: loss=0.7152 
[epoch 14] step 26/44: loss=0.7139 
[epoch 14] step 28/44: loss=0.6972 
[epoch 14] step 30/44: loss=0.6953 
[epoch 14] step 32/44: loss=0.6941 
[epoch 14] step 34/44: loss=0.6863 
[epoch 14] step 36/44: loss=0.6814 
[epoch 14] step 38/44: loss=0.7009 
[epoch 14] step 40/44: loss=0.6985 
[epoch 14] step 42/44: loss=0.7103 
[epoch 14] step 44/44: loss=0.6980 
[epoch 14] train_loss(avg per step)=1.3960 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=4.4550 qwk=('0.5151', '0.4702', '0.5222') averageQWK=0.5025 macroEMD=0.2759 tailR0=('0.0185', '0.1833', '0.0000') tailR0avg=0.0673
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0   10   26    4    0
     0    9   86   33    0
     0    0   46   76    0
     0    0    4   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1    6   34    7    0
     0    5   88   19    1
     0    0   62   85    1
     0    0    3    5    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   28   43    0    0
     0   10  119   22    0
     0    1   50   48    0
     0    0    2    1    0
[epoch 15] step 2/44: loss=0.6299 
[epoch 15] step 4/44: loss=0.7024 
[epoch 15] step 6/44: loss=0.6810 
[epoch 15] step 8/44: loss=0.6527 
[epoch 15] step 10/44: loss=0.6274 
[epoch 15] step 12/44: loss=0.6439 
[epoch 15] step 14/44: loss=0.6203 
[epoch 15] step 16/44: loss=0.5881 
[epoch 15] step 18/44: loss=0.5763 
[epoch 15] step 20/44: loss=0.5653 
[epoch 15] step 22/44: loss=0.5769 
[epoch 15] step 24/44: loss=0.5983 
[epoch 15] step 26/44: loss=0.5924 
[epoch 15] step 28/44: loss=0.5938 
[epoch 15] step 30/44: loss=0.6002 
[epoch 15] step 32/44: loss=0.6041 
[epoch 15] step 34/44: loss=0.5965 
[epoch 15] step 36/44: loss=0.5965 
[epoch 15] step 38/44: loss=0.5941 
[epoch 15] step 40/44: loss=0.5903 
[epoch 15] step 42/44: loss=0.5887 
[epoch 15] step 44/44: loss=0.5837 
[epoch 15] train_loss(avg per step)=1.1674 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=4.7680 qwk=('0.5425', '0.5447', '0.4999') averageQWK=0.5291 macroEMD=0.2744 tailR0=('0.1551', '0.2167', '0.0000') tailR0avg=0.1239
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     3    9   25    3    0
     4    7   92   25    0
     0    0   56   65    1
     0    0    5   17    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    0    0    0
     3   19   15   11    0
     4   14   56   39    0
     0    4   35  109    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   33   38    0    0
     0   24  116   11    0
     0    1   61   37    0
     0    0    2    1    0
[epoch 16] step 2/44: loss=0.6667 
[epoch 16] step 4/44: loss=0.5619 
[epoch 16] step 6/44: loss=0.5576 
[epoch 16] step 8/44: loss=0.5482 
[epoch 16] step 10/44: loss=0.5339 
[epoch 16] step 12/44: loss=0.5102 
[epoch 16] step 14/44: loss=0.5391 
[epoch 16] step 16/44: loss=0.5160 
[epoch 16] step 18/44: loss=0.4863 
[epoch 16] step 20/44: loss=0.4896 
[epoch 16] step 22/44: loss=0.4695 
[epoch 16] step 24/44: loss=0.4675 
[epoch 16] step 26/44: loss=0.4637 
[epoch 16] step 28/44: loss=0.4690 
[epoch 16] step 30/44: loss=0.4448 
[epoch 16] step 32/44: loss=0.4367 
[epoch 16] step 34/44: loss=0.4287 
[epoch 16] step 36/44: loss=0.4336 
[epoch 16] step 38/44: loss=0.4323 
[epoch 16] step 40/44: loss=0.4353 
[epoch 16] step 42/44: loss=0.4448 
[epoch 16] step 44/44: loss=0.4463 
[epoch 16] train_loss(avg per step)=0.8926 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=4.8188 qwk=('0.5613', '0.5461', '0.5492') averageQWK=0.5522 macroEMD=0.2672 tailR0=('0.0741', '0.1833', '0.0000') tailR0avg=0.0858
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   14   19    7    0
     2   15   59   51    1
     0    0   31   89    2
     0    0    0   23    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    0    0
     2   22   10   14    0
     2   19   44   48    0
     0    5   24  116    3
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   28   40    2    0
     0    7  106   38    0
     0    1   38   59    1
     0    0    1    2    0
[epoch 17] step 2/44: loss=0.2428 
[epoch 17] step 4/44: loss=0.2880 
[epoch 17] step 6/44: loss=0.3786 
[epoch 17] step 8/44: loss=0.3485 
[epoch 17] step 10/44: loss=0.3428 
[epoch 17] step 12/44: loss=0.3232 
[epoch 17] step 14/44: loss=0.3262 
[epoch 17] step 16/44: loss=0.3359 
[epoch 17] step 18/44: loss=0.3217 
[epoch 17] step 20/44: loss=0.3298 
[epoch 17] step 22/44: loss=0.3277 
[epoch 17] step 24/44: loss=0.3210 
[epoch 17] step 26/44: loss=0.3257 
[epoch 17] step 28/44: loss=0.3122 
[epoch 17] step 30/44: loss=0.3126 
[epoch 17] step 32/44: loss=0.3119 
[epoch 17] step 34/44: loss=0.3034 
[epoch 17] step 36/44: loss=0.3047 
[epoch 17] step 38/44: loss=0.2991 
[epoch 17] step 40/44: loss=0.2907 
[epoch 17] step 42/44: loss=0.2924 
[epoch 17] step 44/44: loss=0.2874 
[epoch 17] train_loss(avg per step)=0.5748 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=5.1220 qwk=('0.5529', '0.5534', '0.4989') averageQWK=0.5350 macroEMD=0.2672 tailR0=('0.1736', '0.2333', '0.0000') tailR0avg=0.1356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0   12   24    4    0
     0   12   76   37    3
     0    0   48   71    3
     0    0    1   20    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     2   12   26    8    0
     2    8   74   29    0
     0    0   48   97    3
     0    0    1    6    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   22   46    2    0
     0    4  122   25    0
     0    0   49   50    0
     0    0    2    1    0
[epoch 18] step 2/44: loss=0.1496 
[epoch 18] step 4/44: loss=0.1975 
[epoch 18] step 6/44: loss=0.2261 
[epoch 18] step 8/44: loss=0.2437 
[epoch 18] step 10/44: loss=0.2472 
[epoch 18] step 12/44: loss=0.2364 
[epoch 18] step 14/44: loss=0.2326 
[epoch 18] step 16/44: loss=0.2146 
[epoch 18] step 18/44: loss=0.2203 
[epoch 18] step 20/44: loss=0.2276 
[epoch 18] step 22/44: loss=0.2181 
[epoch 18] step 24/44: loss=0.2243 
[epoch 18] step 26/44: loss=0.2160 
[epoch 18] step 28/44: loss=0.1976 
[epoch 18] step 30/44: loss=0.1897 
[epoch 18] step 32/44: loss=0.1873 
[epoch 18] step 34/44: loss=0.1892 
[epoch 18] step 36/44: loss=0.1871 
[epoch 18] step 38/44: loss=0.1934 
[epoch 18] step 40/44: loss=0.1930 
[epoch 18] step 42/44: loss=0.1878 
[epoch 18] step 44/44: loss=0.1838 
[epoch 18] train_loss(avg per step)=0.3675 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=5.1982 qwk=('0.5366', '0.5238', '0.5403') averageQWK=0.5336 macroEMD=0.2677 tailR0=('0.1551', '0.2333', '0.0000') tailR0avg=0.1295
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     1    7   29    3    0
     0    6   95   26    1
     0    0   52   68    2
     0    0    4   18    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     2   10   27    9    0
     2    5   80   25    1
     0    0   50   97    1
     0    0    1    6    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   29   39    2    0
     0   16  103   32    0
     0    1   41   56    1
     0    0    1    2    0
[epoch 19] step 2/44: loss=0.1279 
[epoch 19] step 4/44: loss=0.0787 
[epoch 19] step 6/44: loss=0.1182 
[epoch 19] step 8/44: loss=0.1205 
[epoch 19] step 10/44: loss=0.1551 
[epoch 19] step 12/44: loss=0.1584 
[epoch 19] step 14/44: loss=0.1438 
[epoch 19] step 16/44: loss=0.1297 
[epoch 19] step 18/44: loss=0.1237 
[epoch 19] step 20/44: loss=0.1120 
[epoch 19] step 22/44: loss=0.1096 
[epoch 19] step 24/44: loss=0.1086 
[epoch 19] step 26/44: loss=0.1037 
[epoch 19] step 28/44: loss=0.1009 
[epoch 19] step 30/44: loss=0.1015 
[epoch 19] step 32/44: loss=0.0951 
[epoch 19] step 34/44: loss=0.0947 
[epoch 19] step 36/44: loss=0.0963 
[epoch 19] step 38/44: loss=0.0954 
[epoch 19] step 40/44: loss=0.0957 
[epoch 19] step 42/44: loss=0.0915 
[epoch 19] step 44/44: loss=0.0941 
[epoch 19] train_loss(avg per step)=0.1882 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=5.4969 qwk=('0.5661', '0.5414', '0.5448') averageQWK=0.5508 macroEMD=0.2601 tailR0=('0.0741', '0.2333', '0.0000') tailR0avg=0.1025
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   11   25    4    0
     0   11   79   38    0
     0    0   40   82    0
     0    0    2   21    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     1   18   24    5    0
     2   11   72   27    1
     0    3   56   88    1
     0    0    1    6    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   26   43    1    0
     0    7  114   30    0
     0    0   45   54    0
     0    0    1    2    0
[epoch 20] step 2/44: loss=-0.0158 
[epoch 20] step 4/44: loss=0.0271 
[epoch 20] step 6/44: loss=0.0351 
[epoch 20] step 8/44: loss=0.0326 
[epoch 20] step 10/44: loss=0.0102 
[epoch 20] step 12/44: loss=0.0370 
[epoch 20] step 14/44: loss=0.0298 
[epoch 20] step 16/44: loss=0.0087 
[epoch 20] step 18/44: loss=0.0028 
[epoch 20] step 20/44: loss=0.0094 
[epoch 20] step 22/44: loss=0.0096 
[epoch 20] step 24/44: loss=0.0079 
[epoch 20] step 26/44: loss=0.0093 
[epoch 20] step 28/44: loss=0.0072 
[epoch 20] step 30/44: loss=0.0174 
[epoch 20] step 32/44: loss=0.0140 
[epoch 20] step 34/44: loss=0.0155 
[epoch 20] step 36/44: loss=0.0172 
[epoch 20] step 38/44: loss=0.0095 
[epoch 20] step 40/44: loss=0.0093 
[epoch 20] step 42/44: loss=0.0082 
[epoch 20] step 44/44: loss=0.0092 
[epoch 20] train_loss(avg per step)=0.0185 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=6.1965 qwk=('0.5556', '0.4652', '0.4968') averageQWK=0.5059 macroEMD=0.2568 tailR0=('0.0926', '0.1833', '0.0000') tailR0avg=0.0920
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    9   28    3    0
     0    5   86   36    1
     0    0   39   81    2
     0    0    3   19    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1   11   31    5    0
     0    7   87   18    1
     0    1   74   72    1
     0    0    3    5    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   23   46    1    0
     0   10  116   25    0
     0    1   48   50    0
     0    0    2    1    0
[epoch 21] step 2/44: loss=-0.0628 
[epoch 21] step 4/44: loss=-0.0711 
[epoch 21] step 6/44: loss=-0.0622 
[epoch 21] step 8/44: loss=-0.0389 
[epoch 21] step 10/44: loss=-0.0389 
[epoch 21] step 12/44: loss=-0.0425 
[epoch 21] step 14/44: loss=-0.0416 
[epoch 21] step 16/44: loss=-0.0547 
[epoch 21] step 18/44: loss=-0.0505 
[epoch 21] step 20/44: loss=-0.0481 
[epoch 21] step 22/44: loss=-0.0453 
[epoch 21] step 24/44: loss=-0.0375 
[epoch 21] step 26/44: loss=-0.0362 
[epoch 21] step 28/44: loss=-0.0403 
[epoch 21] step 30/44: loss=-0.0432 
[epoch 21] step 32/44: loss=-0.0357 
[epoch 21] step 34/44: loss=-0.0337 
[epoch 21] step 36/44: loss=-0.0338 
[epoch 21] step 38/44: loss=-0.0347 
[epoch 21] step 40/44: loss=-0.0359 
[epoch 21] step 42/44: loss=-0.0342 
[epoch 21] step 44/44: loss=-0.0398 
[epoch 21] train_loss(avg per step)=-0.0795 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=6.2088 qwk=('0.5651', '0.4940', '0.4753') averageQWK=0.5115 macroEMD=0.2621 tailR0=('0.1551', '0.2333', '0.0000') tailR0avg=0.1295
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     1    7   27    5    0
     0    7   79   41    1
     0    0   33   87    2
     0    0    1   21    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1   14   22   11    0
     1    8   65   38    1
     0    3   42  100    3
     0    0    1    6    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   19   50    1    0
     0    3  126   22    0
     0    0   56   43    0
     0    0    1    2    0
[epoch 22] step 2/44: loss=-0.1241 
[epoch 22] step 4/44: loss=-0.1505 
[epoch 22] step 6/44: loss=-0.1392 
[epoch 22] step 8/44: loss=-0.0968 
[epoch 22] step 10/44: loss=-0.0998 
[epoch 22] step 12/44: loss=-0.1091 
[epoch 22] step 14/44: loss=-0.1046 
[epoch 22] step 16/44: loss=-0.1034 
[epoch 22] step 18/44: loss=-0.0839 
[epoch 22] step 20/44: loss=-0.0795 
[epoch 22] step 22/44: loss=-0.0739 
[epoch 22] step 24/44: loss=-0.0658 
[epoch 22] step 26/44: loss=-0.0519 
[epoch 22] step 28/44: loss=-0.0422 
[epoch 22] step 30/44: loss=-0.0450 
[epoch 22] step 32/44: loss=-0.0423 
[epoch 22] step 34/44: loss=-0.0432 
[epoch 22] step 36/44: loss=-0.0473 
[epoch 22] step 38/44: loss=-0.0469 
[epoch 22] step 40/44: loss=-0.0497 
[epoch 22] step 42/44: loss=-0.0533 
[epoch 22] step 44/44: loss=-0.0550 
[epoch 22] train_loss(avg per step)=-0.1100 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=5.7789 qwk=('0.5048', '0.5324', '0.5268') averageQWK=0.5213 macroEMD=0.2616 tailR0=('0.2176', '0.2333', '0.0000') tailR0avg=0.1503
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    1    0    0
     3    8   26    3    0
     5   10   83   27    3
     2    0   53   64    3
     0    0    5   17    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     2   15   23    8    0
     2    9   68   34    0
     0    3   47   96    2
     0    0    1    6    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   31   38    1    0
     0   19  109   23    0
     0    2   46   51    0
     0    0    2    1    0
[epoch 23] step 2/44: loss=-0.1322 
[epoch 23] step 4/44: loss=-0.1701 
[epoch 23] step 6/44: loss=-0.1434 
[epoch 23] step 8/44: loss=-0.1091 
[epoch 23] step 10/44: loss=-0.1039 
[epoch 23] step 12/44: loss=-0.0928 
[epoch 23] step 14/44: loss=-0.0959 
[epoch 23] step 16/44: loss=-0.1041 
[epoch 23] step 18/44: loss=-0.1116 
[epoch 23] step 20/44: loss=-0.1065 
[epoch 23] step 22/44: loss=-0.1023 
[epoch 23] step 24/44: loss=-0.1075 
[epoch 23] step 26/44: loss=-0.1106 
[epoch 23] step 28/44: loss=-0.1071 
[epoch 23] step 30/44: loss=-0.1069 
[epoch 23] step 32/44: loss=-0.1101 
[epoch 23] step 34/44: loss=-0.1114 
[epoch 23] step 36/44: loss=-0.1129 
[epoch 23] step 38/44: loss=-0.1135 
[epoch 23] step 40/44: loss=-0.1081 
[epoch 23] step 42/44: loss=-0.1076 
[epoch 23] step 44/44: loss=-0.1083 
[epoch 23] train_loss(avg per step)=-0.2165 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=6.6324 qwk=('0.5277', '0.4880', '0.4773') averageQWK=0.4977 macroEMD=0.2564 tailR0=('0.0926', '0.1833', '0.0000') tailR0avg=0.0920
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    1    0
     1    9   23    7    0
     1    8   59   60    0
     0    0   24   97    1
     0    0    1   21    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1    9   27   11    0
     0    9   72   32    0
     0    1   47   99    1
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   20   46    4    0
     0    3  113   35    0
     0    0   46   53    0
     0    0    1    2    0
[epoch 24] step 2/44: loss=-0.1848 
[epoch 24] step 4/44: loss=-0.1742 
[epoch 24] step 6/44: loss=-0.1703 
[epoch 24] step 8/44: loss=-0.1583 
[epoch 24] step 10/44: loss=-0.1509 
[epoch 24] step 12/44: loss=-0.1631 
[epoch 24] step 14/44: loss=-0.1594 
[epoch 24] step 16/44: loss=-0.1682 
[epoch 24] step 18/44: loss=-0.1607 
[epoch 24] step 20/44: loss=-0.1557 
[epoch 24] step 22/44: loss=-0.1530 
[epoch 24] step 24/44: loss=-0.1483 
[epoch 24] step 26/44: loss=-0.1450 
[epoch 24] step 28/44: loss=-0.1499 
[epoch 24] step 30/44: loss=-0.1515 
[epoch 24] step 32/44: loss=-0.1573 
[epoch 24] step 34/44: loss=-0.1613 
[epoch 24] step 36/44: loss=-0.1588 
[epoch 24] step 38/44: loss=-0.1573 
[epoch 24] step 40/44: loss=-0.1602 
[epoch 24] step 42/44: loss=-0.1590 
[epoch 24] step 44/44: loss=-0.1583 
[epoch 24] train_loss(avg per step)=-0.3167 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=6.8430 qwk=('0.5300', '0.4529', '0.4916') averageQWK=0.4915 macroEMD=0.2547 tailR0=('0.0926', '0.1333', '0.0000') tailR0avg=0.0753
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0   10   27    3    0
     0    7   82   37    2
     0    0   46   73    3
     0    0    3   19    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1   15   29    3    0
     2   11   90   10    0
     0    2   87   58    1
     0    0    4    5    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   30   40    1    0
     0   25  105   21    0
     0    1   53   45    0
     0    0    2    1    0
[epoch 25] step 2/44: loss=-0.1832 
[epoch 25] step 4/44: loss=-0.1945 
[epoch 25] step 6/44: loss=-0.1750 
[epoch 25] step 8/44: loss=-0.1812 
[epoch 25] step 10/44: loss=-0.1650 
[epoch 25] step 12/44: loss=-0.1493 
[epoch 25] step 14/44: loss=-0.1477 
[epoch 25] step 16/44: loss=-0.1610 
[epoch 25] step 18/44: loss=-0.1673 
[epoch 25] step 20/44: loss=-0.1660 
[epoch 25] step 22/44: loss=-0.1697 
[epoch 25] step 24/44: loss=-0.1674 
[epoch 25] step 26/44: loss=-0.1698 
[epoch 25] step 28/44: loss=-0.1722 
[epoch 25] step 30/44: loss=-0.1797 
[epoch 25] step 32/44: loss=-0.1824 
[epoch 25] step 34/44: loss=-0.1866 
[epoch 25] step 36/44: loss=-0.1894 
[epoch 25] step 38/44: loss=-0.1905 
[epoch 25] step 40/44: loss=-0.1870 
[epoch 25] step 42/44: loss=-0.1882 
[epoch 25] step 44/44: loss=-0.1861 
[epoch 25] train_loss(avg per step)=-0.3721 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=6.7561 qwk=('0.5345', '0.5314', '0.5208') averageQWK=0.5289 macroEMD=0.2516 tailR0=('0.2176', '0.2833', '0.0000') tailR0avg=0.1670
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    0    0
     2    7   27    4    0
     3    6   80   36    3
     1    0   38   78    5
     0    0    2   20    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     1   20   18    8    1
     3   11   67   28    4
     0    3   45   95    5
     0    0    0    6    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   26   43    1    0
     0   12  113   26    0
     0    0   48   51    0
     0    0    2    1    0
[epoch 26] step 2/44: loss=-0.2042 
[epoch 26] step 4/44: loss=-0.1954 
[epoch 26] step 6/44: loss=-0.2261 
[epoch 26] step 8/44: loss=-0.2205 
[epoch 26] step 10/44: loss=-0.2099 
[epoch 26] step 12/44: loss=-0.2200 
[epoch 26] step 14/44: loss=-0.2275 
[epoch 26] step 16/44: loss=-0.2255 
[epoch 26] step 18/44: loss=-0.2254 
[epoch 26] step 20/44: loss=-0.2215 
[epoch 26] step 22/44: loss=-0.2183 
[epoch 26] step 24/44: loss=-0.2242 
[epoch 26] step 26/44: loss=-0.2249 
[epoch 26] step 28/44: loss=-0.2188 
[epoch 26] step 30/44: loss=-0.2193 
[epoch 26] step 32/44: loss=-0.2219 
[epoch 26] step 34/44: loss=-0.2252 
[epoch 26] step 36/44: loss=-0.2262 
[epoch 26] step 38/44: loss=-0.2252 
[epoch 26] step 40/44: loss=-0.2261 
[epoch 26] step 42/44: loss=-0.2221 
[epoch 26] step 44/44: loss=-0.2240 
[epoch 26] train_loss(avg per step)=-0.4481 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=6.7937 qwk=('0.5067', '0.4815', '0.5236') averageQWK=0.5039 macroEMD=0.2527 tailR0=('0.1111', '0.2333', '0.0000') tailR0avg=0.1148
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     1   11   21    6    1
     3   11   59   51    4
     2    1   25   91    3
     0    0    1   20    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     3    8   30    6    1
     3    7   76   24    3
     0    1   57   86    4
     0    0    1    6    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   28   39    3    0
     0   22   93   36    0
     0    1   38   60    0
     0    0    1    2    0
[epoch 27] step 2/44: loss=-0.2482 
[epoch 27] step 4/44: loss=-0.2550 
[epoch 27] step 6/44: loss=-0.2493 
[epoch 27] step 8/44: loss=-0.2139 
[epoch 27] step 10/44: loss=-0.2147 
[epoch 27] step 12/44: loss=-0.2177 
[epoch 27] step 14/44: loss=-0.2260 
[epoch 27] step 16/44: loss=-0.2294 
[epoch 27] step 18/44: loss=-0.2293 
[epoch 27] step 20/44: loss=-0.2333 
[epoch 27] step 22/44: loss=-0.2302 
[epoch 27] step 24/44: loss=-0.2334 
[epoch 27] step 26/44: loss=-0.2346 
[epoch 27] step 28/44: loss=-0.2380 
[epoch 27] step 30/44: loss=-0.2341 
[epoch 27] step 32/44: loss=-0.2351 
[epoch 27] step 34/44: loss=-0.2365 
[epoch 27] step 36/44: loss=-0.2372 
[epoch 27] step 38/44: loss=-0.2395 
[epoch 27] step 40/44: loss=-0.2402 
[epoch 27] step 42/44: loss=-0.2395 
[epoch 27] step 44/44: loss=-0.2343 
[epoch 27] train_loss(avg per step)=-0.4687 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=7.2467 qwk=('0.5282', '0.5238', '0.4931') averageQWK=0.5150 macroEMD=0.2492 tailR0=('0.1366', '0.1333', '0.0000') tailR0avg=0.0900
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     1   11   23    5    0
     2   14   73   38    1
     2    0   42   76    2
     0    0    2   21    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     2   20   17    9    0
     3   17   59   34    0
     0    6   40  102    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   34   36    1    0
     0   33  101   17    0
     0    2   54   43    0
     0    0    2    1    0
[epoch 28] step 2/44: loss=-0.2185 
[epoch 28] step 4/44: loss=-0.2459 
[epoch 28] step 6/44: loss=-0.2355 
[epoch 28] step 8/44: loss=-0.2496 
[epoch 28] step 10/44: loss=-0.2507 
[epoch 28] step 12/44: loss=-0.2429 
[epoch 28] step 14/44: loss=-0.2371 
[epoch 28] step 16/44: loss=-0.2421 
[epoch 28] step 18/44: loss=-0.2488 
[epoch 28] step 20/44: loss=-0.2468 
[epoch 28] step 22/44: loss=-0.2491 
[epoch 28] step 24/44: loss=-0.2489 
[epoch 28] step 26/44: loss=-0.2495 
[epoch 28] step 28/44: loss=-0.2472 
[epoch 28] step 30/44: loss=-0.2462 
[epoch 28] step 32/44: loss=-0.2478 
[epoch 28] step 34/44: loss=-0.2500 
[epoch 28] step 36/44: loss=-0.2493 
[epoch 28] step 38/44: loss=-0.2517 
[epoch 28] step 40/44: loss=-0.2535 
[epoch 28] step 42/44: loss=-0.2552 
[epoch 28] step 44/44: loss=-0.2546 
[epoch 28] train_loss(avg per step)=-0.5092 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=7.5857 qwk=('0.5358', '0.4695', '0.5037') averageQWK=0.5030 macroEMD=0.2507 tailR0=('0.1551', '0.1833', '0.0000') tailR0avg=0.1128
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     1    7   24    8    0
     3    4   63   57    1
     0    0   20   99    3
     0    0    1   21    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1    7   28   12    0
     3    9   60   41    0
     0    1   41  103    3
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   19   48    3    0
     0    5  112   34    0
     0    0   41   58    0
     0    0    1    2    0
[epoch 29] step 2/44: loss=-0.2770 
[epoch 29] step 4/44: loss=-0.2461 
[epoch 29] step 6/44: loss=-0.2433 
[epoch 29] step 8/44: loss=-0.2480 
[epoch 29] step 10/44: loss=-0.2324 
[epoch 29] step 12/44: loss=-0.2325 
[epoch 29] step 14/44: loss=-0.2392 
[epoch 29] step 16/44: loss=-0.2482 
[epoch 29] step 18/44: loss=-0.2466 
[epoch 29] step 20/44: loss=-0.2507 
[epoch 29] step 22/44: loss=-0.2545 
[epoch 29] step 24/44: loss=-0.2525 
[epoch 29] step 26/44: loss=-0.2539 
[epoch 29] step 28/44: loss=-0.2552 
[epoch 29] step 30/44: loss=-0.2594 
[epoch 29] step 32/44: loss=-0.2588 
[epoch 29] step 34/44: loss=-0.2590 
[epoch 29] step 36/44: loss=-0.2562 
[epoch 29] step 38/44: loss=-0.2542 
[epoch 29] step 40/44: loss=-0.2532 
[epoch 29] step 42/44: loss=-0.2501 
[epoch 29] step 44/44: loss=-0.2520 
[epoch 29] train_loss(avg per step)=-0.5040 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=7.6629 qwk=('0.5317', '0.4842', '0.4932') averageQWK=0.5030 macroEMD=0.2497 tailR0=('0.2431', '0.1333', '0.0000') tailR0avg=0.1255
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    3    0    0
     2    5   26    7    0
     2    4   71   51    0
     0    0   30   91    1
     0    0    2   22    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1   11   25   11    0
     3    9   69   32    0
     0    2   46  100    0
     0    0    0    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   45    4    0
     0    5  106   40    0
     0    1   38   60    0
     0    0    1    2    0
[epoch 30] step 2/44: loss=-0.3141 
[epoch 30] step 4/44: loss=-0.3132 
[epoch 30] step 6/44: loss=-0.3145 
[epoch 30] step 8/44: loss=-0.3128 
[epoch 30] step 10/44: loss=-0.2993 
[epoch 30] step 12/44: loss=-0.2976 
[epoch 30] step 14/44: loss=-0.2979 
[epoch 30] step 16/44: loss=-0.2951 
[epoch 30] step 18/44: loss=-0.2960 
[epoch 30] step 20/44: loss=-0.2951 
[epoch 30] step 22/44: loss=-0.2949 
[epoch 30] step 24/44: loss=-0.2956 
[epoch 30] step 26/44: loss=-0.2954 
[epoch 30] step 28/44: loss=-0.2955 
[epoch 30] step 30/44: loss=-0.2962 
[epoch 30] step 32/44: loss=-0.2925 
[epoch 30] step 34/44: loss=-0.2935 
[epoch 30] step 36/44: loss=-0.2900 
[epoch 30] step 38/44: loss=-0.2911 
[epoch 30] step 40/44: loss=-0.2877 
[epoch 30] step 42/44: loss=-0.2880 
[epoch 30] step 44/44: loss=-0.2881 
[epoch 30] train_loss(avg per step)=-0.5762 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=7.1568 qwk=('0.5118', '0.4743', '0.5098') averageQWK=0.4986 macroEMD=0.2512 tailR0=('0.1921', '0.2333', '0.0000') tailR0avg=0.1418
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     1    8   26    5    0
     2    5   78   39    4
     0    0   47   71    4
     0    0    2   18    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1   10   28    9    0
     3    8   76   26    0
     0    1   61   84    2
     0    0    1    6    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   26   43    1    0
     0   17  106   28    0
     0    2   45   52    0
     0    0    1    2    0
[epoch 31] step 2/44: loss=-0.3054 
[epoch 31] step 4/44: loss=-0.3045 
[epoch 31] step 6/44: loss=-0.3078 
[epoch 31] step 8/44: loss=-0.3012 
[epoch 31] step 10/44: loss=-0.2910 
[epoch 31] step 12/44: loss=-0.2936 
[epoch 31] step 14/44: loss=-0.2952 
[epoch 31] step 16/44: loss=-0.2923 
[epoch 31] step 18/44: loss=-0.2909 
[epoch 31] step 20/44: loss=-0.2907 
[epoch 31] step 22/44: loss=-0.2910 
[epoch 31] step 24/44: loss=-0.2893 
[epoch 31] step 26/44: loss=-0.2855 
[epoch 31] step 28/44: loss=-0.2864 
[epoch 31] step 30/44: loss=-0.2870 
[epoch 31] step 32/44: loss=-0.2901 
[epoch 31] step 34/44: loss=-0.2910 
[epoch 31] step 36/44: loss=-0.2905 
[epoch 31] step 38/44: loss=-0.2917 
[epoch 31] step 40/44: loss=-0.2915 
[epoch 31] step 42/44: loss=-0.2919 
[epoch 31] step 44/44: loss=-0.2934 
[epoch 31] train_loss(avg per step)=-0.5869 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=7.5551 qwk=('0.5213', '0.4841', '0.5046') averageQWK=0.5034 macroEMD=0.2474 tailR0=('0.1366', '0.1833', '0.0000') tailR0avg=0.1066
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1   10   24    5    0
     3    9   69   45    2
     1    0   37   83    1
     0    0    2   21    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1   11   29    7    0
     3    8   80   22    0
     0    2   62   84    0
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   29   41    1    0
     0   20  106   25    0
     0    2   46   51    0
     0    0    2    1    0
[epoch 32] step 2/44: loss=-0.3306 
[epoch 32] step 4/44: loss=-0.3356 
[epoch 32] step 6/44: loss=-0.3261 
[epoch 32] step 8/44: loss=-0.3207 
[epoch 32] step 10/44: loss=-0.3226 
[epoch 32] step 12/44: loss=-0.3172 
[epoch 32] step 14/44: loss=-0.3104 
[epoch 32] step 16/44: loss=-0.3018 
[epoch 32] step 18/44: loss=-0.2927 
[epoch 32] step 20/44: loss=-0.2946 
[epoch 32] step 22/44: loss=-0.2978 
[epoch 32] step 24/44: loss=-0.2967 
[epoch 32] step 26/44: loss=-0.2964 
[epoch 32] step 28/44: loss=-0.2956 
[epoch 32] step 30/44: loss=-0.2960 
[epoch 32] step 32/44: loss=-0.2980 
[epoch 32] step 34/44: loss=-0.2977 
[epoch 32] step 36/44: loss=-0.2978 
[epoch 32] step 38/44: loss=-0.2984 
[epoch 32] step 40/44: loss=-0.2997 
[epoch 32] step 42/44: loss=-0.3000 
[epoch 32] step 44/44: loss=-0.2981 
[epoch 32] train_loss(avg per step)=-0.5963 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=7.3248 qwk=('0.5174', '0.4882', '0.5192') averageQWK=0.5083 macroEMD=0.2499 tailR0=('0.1736', '0.2333', '0.0000') tailR0avg=0.1356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     1    9   25    5    0
     3    7   71   44    3
     1    0   36   81    4
     0    0    2   19    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1   12   26    9    0
     3    9   74   27    0
     0    2   56   88    2
     0    0    1    6    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   27   42    2    0
     0   15  103   33    0
     0    2   39   58    0
     0    0    1    2    0
[epoch 33] step 2/44: loss=-0.3167 
[epoch 33] step 4/44: loss=-0.3085 
[epoch 33] step 6/44: loss=-0.3112 
[epoch 33] step 8/44: loss=-0.3109 
[epoch 33] step 10/44: loss=-0.3127 
[epoch 33] step 12/44: loss=-0.3144 
[epoch 33] step 14/44: loss=-0.3100 
[epoch 33] step 16/44: loss=-0.3131 
[epoch 33] step 18/44: loss=-0.3149 
[epoch 33] step 20/44: loss=-0.3172 
[epoch 33] step 22/44: loss=-0.3113 
[epoch 33] step 24/44: loss=-0.3085 
[epoch 33] step 26/44: loss=-0.3090 
[epoch 33] step 28/44: loss=-0.3085 
[epoch 33] step 30/44: loss=-0.3094 
[epoch 33] step 32/44: loss=-0.3072 
[epoch 33] step 34/44: loss=-0.3083 
[epoch 33] step 36/44: loss=-0.3087 
[epoch 33] step 38/44: loss=-0.3100 
[epoch 33] step 40/44: loss=-0.3102 
[epoch 33] step 42/44: loss=-0.3109 
[epoch 33] step 44/44: loss=-0.3092 
[epoch 33] train_loss(avg per step)=-0.6184 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=7.6510 qwk=('0.5178', '0.5184', '0.4991') averageQWK=0.5117 macroEMD=0.2485 tailR0=('0.1551', '0.2333', '0.0000') tailR0avg=0.1295
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     1    9   24    6    0
     3    7   71   45    2
     1    0   33   86    2
     0    0    2   20    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     1   14   26    7    0
     2   11   77   23    0
     0    2   61   83    2
     0    0    1    6    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   25   41    4    0
     0   12   99   40    0
     0    2   37   60    0
     0    0    1    2    0
[epoch 34] step 2/44: loss=-0.3067 
[epoch 34] step 4/44: loss=-0.2943 
[epoch 34] step 6/44: loss=-0.2988 
[epoch 34] step 8/44: loss=-0.3053 
[epoch 34] step 10/44: loss=-0.3050 
[epoch 34] step 12/44: loss=-0.3080 
[epoch 34] step 14/44: loss=-0.3075 
[epoch 34] step 16/44: loss=-0.3113 
[epoch 34] step 18/44: loss=-0.3133 
[epoch 34] step 20/44: loss=-0.3139 
[epoch 34] step 22/44: loss=-0.3161 
[epoch 34] step 24/44: loss=-0.3144 
[epoch 34] step 26/44: loss=-0.3127 
[epoch 34] step 28/44: loss=-0.3140 
[epoch 34] step 30/44: loss=-0.3138 
[epoch 34] step 32/44: loss=-0.3133 
[epoch 34] step 34/44: loss=-0.3145 
[epoch 34] step 36/44: loss=-0.3155 
[epoch 34] step 38/44: loss=-0.3161 
[epoch 34] step 40/44: loss=-0.3152 
[epoch 34] step 42/44: loss=-0.3160 
[epoch 34] step 44/44: loss=-0.3170 
[epoch 34] train_loss(avg per step)=-0.6341 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=8.0192 qwk=('0.5511', '0.5069', '0.5082') averageQWK=0.5221 macroEMD=0.2464 tailR0=('0.1551', '0.2333', '0.0000') tailR0avg=0.1295
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     1    8   25    6    0
     2    6   65   55    0
     0    0   26   96    0
     0    0    1   21    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1   16   19   12    0
     2   13   61   37    0
     0    3   42  101    2
     0    0    0    7    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   45    2    0
     0    7  111   33    0
     0    2   38   59    0
     0    0    2    1    0
[epoch 35] step 2/44: loss=-0.3159 
[epoch 35] step 4/44: loss=-0.3279 
[epoch 35] step 6/44: loss=-0.3121 
[epoch 35] step 8/44: loss=-0.3169 
[epoch 35] step 10/44: loss=-0.3217 
[epoch 35] step 12/44: loss=-0.3192 
[epoch 35] step 14/44: loss=-0.3213 
[epoch 35] step 16/44: loss=-0.3226 
[epoch 35] step 18/44: loss=-0.3206 
[epoch 35] step 20/44: loss=-0.3210 
[epoch 35] step 22/44: loss=-0.3217 
[epoch 35] step 24/44: loss=-0.3220 
[epoch 35] step 26/44: loss=-0.3205 
[epoch 35] step 28/44: loss=-0.3203 
[epoch 35] step 30/44: loss=-0.3194 
[epoch 35] step 32/44: loss=-0.3174 
[epoch 35] step 34/44: loss=-0.3184 
[epoch 35] step 36/44: loss=-0.3180 
[epoch 35] step 38/44: loss=-0.3179 
[epoch 35] step 40/44: loss=-0.3192 
[epoch 35] step 42/44: loss=-0.3178 
[epoch 35] step 44/44: loss=-0.3186 
[epoch 35] train_loss(avg per step)=-0.6371 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=7.8375 qwk=('0.5341', '0.5223', '0.5112') averageQWK=0.5225 macroEMD=0.2452 tailR0=('0.1551', '0.2333', '0.0000') tailR0avg=0.1295
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     1    9   25    5    0
     3    7   71   46    1
     1    0   31   88    2
     0    0    2   20    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     1   17   21    9    0
     2   13   72   26    0
     0    3   54   89    2
     0    0    1    6    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   27   42    2    0
     0   14  107   30    0
     0    2   40   57    0
     0    0    2    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-1-reassignment-0/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-1-reassignment-0/fold3/metrics.json
Done.
