[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=5.4961 
[epoch 1] step 4/44: loss=5.6466 
[epoch 1] step 6/44: loss=5.6108 
[epoch 1] step 8/44: loss=5.6773 
[epoch 1] step 10/44: loss=5.7540 
[epoch 1] step 12/44: loss=5.7317 
[epoch 1] step 14/44: loss=5.7243 
[epoch 1] step 16/44: loss=5.7444 
[epoch 1] step 18/44: loss=5.7735 
[epoch 1] step 20/44: loss=5.6962 
[epoch 1] step 22/44: loss=5.7024 
[epoch 1] step 24/44: loss=5.6868 
[epoch 1] step 26/44: loss=5.7188 
[epoch 1] step 28/44: loss=5.6862 
[epoch 1] step 30/44: loss=5.6961 
[epoch 1] step 32/44: loss=5.6516 
[epoch 1] step 34/44: loss=5.6537 
[epoch 1] step 36/44: loss=5.6446 
[epoch 1] step 38/44: loss=5.6408 
[epoch 1] step 40/44: loss=5.6330 
[epoch 1] step 42/44: loss=5.6010 
[epoch 1] step 44/44: loss=5.5284 
[epoch 1] train_loss(avg per step)=11.0569 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=9.1258 qwk=('-0.0082', '0.1016', '-0.0106') averageQWK=0.0276 macroEMD=0.3892 tailR0=('0.0000', '0.1667', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   14    0    1    0
     0   68    0   10    0
     0  145    0   17    0
     0   60    0    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    4    0    0
     7    0    9    0    0
    28    0   38    0    0
    44    0  161    0    0
     2    0   28    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    1   28    0    0
     0    1  110    0    0
     0    6  175    0    0
     0    0    1    0    0
[epoch 2] step 2/44: loss=4.3583 
[epoch 2] step 4/44: loss=4.2844 
[epoch 2] step 6/44: loss=4.1967 
[epoch 2] step 8/44: loss=4.0566 
[epoch 2] step 10/44: loss=3.8568 
[epoch 2] step 12/44: loss=3.8988 
[epoch 2] step 14/44: loss=3.9182 
[epoch 2] step 16/44: loss=3.8457 
[epoch 2] step 18/44: loss=3.7924 
[epoch 2] step 20/44: loss=3.7189 
[epoch 2] step 22/44: loss=3.6866 
[epoch 2] step 24/44: loss=3.6606 
[epoch 2] step 26/44: loss=3.6000 
[epoch 2] step 28/44: loss=3.5762 
[epoch 2] step 30/44: loss=3.5435 
[epoch 2] step 32/44: loss=3.5137 
[epoch 2] step 34/44: loss=3.5012 
[epoch 2] step 36/44: loss=3.4758 
[epoch 2] step 38/44: loss=3.4492 
[epoch 2] step 40/44: loss=3.4226 
[epoch 2] step 42/44: loss=3.3905 
[epoch 2] step 44/44: loss=3.3605 
[epoch 2] train_loss(avg per step)=6.7210 lambda[min,max]=[0.500252,1.000000]
[epoch 2] val_loss=4.4769 qwk=('0.0277', '0.0416', '0.1100') averageQWK=0.0598 macroEMD=0.3826 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    0   15    0    0
     0    0   77    1    0
     0    0  154    8    0
     0    0   64    0    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   14    2    0
     0    0   53   13    0
     0    0  154   51    0
     0    0   25    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    0   29    0    0
     0    1   99   11    0
     0    0  149   32    0
     0    0    1    0    0
[epoch 3] step 2/44: loss=3.3673 
[epoch 3] step 4/44: loss=3.0451 
[epoch 3] step 6/44: loss=2.9682 
[epoch 3] step 8/44: loss=2.9410 
[epoch 3] step 10/44: loss=2.9564 
[epoch 3] step 12/44: loss=2.8955 
[epoch 3] step 14/44: loss=2.8634 
[epoch 3] step 16/44: loss=2.8179 
[epoch 3] step 18/44: loss=2.7870 
[epoch 3] step 20/44: loss=2.7732 
[epoch 3] step 22/44: loss=2.7421 
[epoch 3] step 24/44: loss=2.7231 
[epoch 3] step 26/44: loss=2.6843 
[epoch 3] step 28/44: loss=2.6741 
[epoch 3] step 30/44: loss=2.6615 
[epoch 3] step 32/44: loss=2.6386 
[epoch 3] step 34/44: loss=2.6162 
[epoch 3] step 36/44: loss=2.6113 
[epoch 3] step 38/44: loss=2.5879 
[epoch 3] step 40/44: loss=2.5939 
[epoch 3] step 42/44: loss=2.5892 
[epoch 3] step 44/44: loss=2.5938 
[epoch 3] train_loss(avg per step)=5.1875 lambda[min,max]=[0.502260,1.000000]
[epoch 3] val_loss=6.3273 qwk=('0.1176', '0.0406', '0.1661') averageQWK=0.1081 macroEMD=0.3763 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   13    1    1    0
     0   54   19    5    0
     0   60   72   30    0
     0   21   39    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   16    0    0
     0    0   61    5    0
     0    0  184   21    0
     0    0   28    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24    5    0    0
     0   49   61    1    0
     0   53  116   12    0
     0    0    1    0    0
[epoch 4] step 2/44: loss=2.9717 
[epoch 4] step 4/44: loss=2.7207 
[epoch 4] step 6/44: loss=2.6339 
[epoch 4] step 8/44: loss=2.6006 
[epoch 4] step 10/44: loss=2.5759 
[epoch 4] step 12/44: loss=2.5703 
[epoch 4] step 14/44: loss=2.5638 
[epoch 4] step 16/44: loss=2.5243 
[epoch 4] step 18/44: loss=2.4694 
[epoch 4] step 20/44: loss=2.4635 
[epoch 4] step 22/44: loss=2.4660 
[epoch 4] step 24/44: loss=2.4678 
[epoch 4] step 26/44: loss=2.4752 
[epoch 4] step 28/44: loss=2.4823 
[epoch 4] step 30/44: loss=2.4497 
[epoch 4] step 32/44: loss=2.4490 
[epoch 4] step 34/44: loss=2.4289 
[epoch 4] step 36/44: loss=2.4165 
[epoch 4] step 38/44: loss=2.4067 
[epoch 4] step 40/44: loss=2.3930 
[epoch 4] step 42/44: loss=2.3855 
[epoch 4] step 44/44: loss=2.3809 
[epoch 4] train_loss(avg per step)=4.7619 lambda[min,max]=[0.507336,1.000000]
[epoch 4] val_loss=4.3341 qwk=('0.1908', '0.3766', '0.3095') averageQWK=0.2923 macroEMD=0.3600 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0    6    8    1    0
     0   11   52   15    0
     0    5   96   61    0
     0    4   41   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    6    3    0
     0    7   32   27    0
     0   12   68  125    0
     0    1    3   26    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   23    6    0    0
     0   38   55   18    0
     0   35   80   66    0
     0    0    0    1    0
[epoch 5] step 2/44: loss=2.0857 
[epoch 5] step 4/44: loss=2.3202 
[epoch 5] step 6/44: loss=2.3475 
[epoch 5] step 8/44: loss=2.2964 
[epoch 5] step 10/44: loss=2.3231 
[epoch 5] step 12/44: loss=2.3152 
[epoch 5] step 14/44: loss=2.2819 
[epoch 5] step 16/44: loss=2.2339 
[epoch 5] step 18/44: loss=2.2284 
[epoch 5] step 20/44: loss=2.2218 
[epoch 5] step 22/44: loss=2.2290 
[epoch 5] step 24/44: loss=2.2180 
[epoch 5] step 26/44: loss=2.2141 
[epoch 5] step 28/44: loss=2.1841 
[epoch 5] step 30/44: loss=2.1726 
[epoch 5] step 32/44: loss=2.1554 
[epoch 5] step 34/44: loss=2.1443 
[epoch 5] step 36/44: loss=2.1397 
[epoch 5] step 38/44: loss=2.1237 
[epoch 5] step 40/44: loss=2.1228 
[epoch 5] step 42/44: loss=2.1174 
[epoch 5] step 44/44: loss=2.1078 
[epoch 5] train_loss(avg per step)=4.2156 lambda[min,max]=[0.502271,1.000000]
[epoch 5] val_loss=4.2114 qwk=('0.2085', '0.2804', '0.1639') averageQWK=0.2176 macroEMD=0.3511 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    0   15    0    0
     0    0   52   26    0
     0    0   67   95    0
     0    0   33   31    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    3   12    1    0
     0    4   41   21    0
     0    3  106   96    0
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   27    0    0
     0    1  105    5    0
     0    0  148   33    0
     0    0    1    0    0
[epoch 6] step 2/44: loss=1.9901 
[epoch 6] step 4/44: loss=2.0435 
[epoch 6] step 6/44: loss=2.0121 
[epoch 6] step 8/44: loss=2.0109 
[epoch 6] step 10/44: loss=2.0348 
[epoch 6] step 12/44: loss=2.0405 
[epoch 6] step 14/44: loss=2.0372 
[epoch 6] step 16/44: loss=2.0408 
[epoch 6] step 18/44: loss=2.0539 
[epoch 6] step 20/44: loss=2.0446 
[epoch 6] step 22/44: loss=2.0222 
[epoch 6] step 24/44: loss=2.0380 
[epoch 6] step 26/44: loss=2.0380 
[epoch 6] step 28/44: loss=2.0454 
[epoch 6] step 30/44: loss=2.0353 
[epoch 6] step 32/44: loss=2.0414 
[epoch 6] step 34/44: loss=2.0175 
[epoch 6] step 36/44: loss=2.0133 
[epoch 6] step 38/44: loss=1.9917 
[epoch 6] step 40/44: loss=1.9790 
[epoch 6] step 42/44: loss=1.9708 
[epoch 6] step 44/44: loss=1.9506 
[epoch 6] train_loss(avg per step)=3.9013 lambda[min,max]=[0.509384,1.000000]
[epoch 6] val_loss=5.2852 qwk=('0.1502', '0.2618', '0.3248') averageQWK=0.2456 macroEMD=0.3453 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   11    0    0
     0    7   64    7    0
     0    0  124   38    0
     0    2   50   12    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   11    3    2    0
     0   21   33   12    0
     0   24  122   59    0
     0    2   14   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20    9    0    0
     0   24   81    6    0
     0   13  129   39    0
     0    0    1    0    0
[epoch 7] step 2/44: loss=1.9471 
[epoch 7] step 4/44: loss=1.9104 
[epoch 7] step 6/44: loss=1.9138 
[epoch 7] step 8/44: loss=1.9212 
[epoch 7] step 10/44: loss=1.8488 
[epoch 7] step 12/44: loss=1.8720 
[epoch 7] step 14/44: loss=1.9162 
[epoch 7] step 16/44: loss=1.9444 
[epoch 7] step 18/44: loss=1.9373 
[epoch 7] step 20/44: loss=1.9467 
[epoch 7] step 22/44: loss=1.9547 
[epoch 7] step 24/44: loss=1.9680 
[epoch 7] step 26/44: loss=1.9503 
[epoch 7] step 28/44: loss=1.9440 
[epoch 7] step 30/44: loss=1.9573 
[epoch 7] step 32/44: loss=1.9474 
[epoch 7] step 34/44: loss=1.9371 
[epoch 7] step 36/44: loss=1.9209 
[epoch 7] step 38/44: loss=1.9128 
[epoch 7] step 40/44: loss=1.9067 
[epoch 7] step 42/44: loss=1.8960 
[epoch 7] step 44/44: loss=1.8891 
[epoch 7] train_loss(avg per step)=3.7782 lambda[min,max]=[0.501713,1.000000]
[epoch 7] val_loss=4.6560 qwk=('0.1876', '0.1043', '0.2007') averageQWK=0.1642 macroEMD=0.3387 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4    9    2    0
     0    3   52   23    0
     0    0   90   72    0
     0    1   35   28    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   15    1    0
     0    0   59    7    0
     0    0  161   44    0
     0    0   22    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    4   25    0    0
     0    3  102    6    0
     0    0  148   33    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=1.6385 
[epoch 8] step 4/44: loss=1.6938 
[epoch 8] step 6/44: loss=1.7744 
[epoch 8] step 8/44: loss=1.7572 
[epoch 8] step 10/44: loss=1.7025 
[epoch 8] step 12/44: loss=1.6959 
[epoch 8] step 14/44: loss=1.6741 
[epoch 8] step 16/44: loss=1.6660 
[epoch 8] step 18/44: loss=1.6502 
[epoch 8] step 20/44: loss=1.6818 
[epoch 8] step 22/44: loss=1.6543 
[epoch 8] step 24/44: loss=1.6558 
[epoch 8] step 26/44: loss=1.6381 
[epoch 8] step 28/44: loss=1.6348 
[epoch 8] step 30/44: loss=1.6271 
[epoch 8] step 32/44: loss=1.6315 
[epoch 8] step 34/44: loss=1.6124 
[epoch 8] step 36/44: loss=1.5982 
[epoch 8] step 38/44: loss=1.6063 
[epoch 8] step 40/44: loss=1.6139 
[epoch 8] step 42/44: loss=1.6122 
[epoch 8] step 44/44: loss=1.6124 
[epoch 8] train_loss(avg per step)=3.2249 lambda[min,max]=[0.501559,1.000000]
[epoch 8] val_loss=4.5625 qwk=('0.1956', '0.2512', '0.3185') averageQWK=0.2551 macroEMD=0.3297 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    5   10    0    0
     0    7   55   16    0
     0    1  108   53    0
     0    1   40   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6    8    2    0
     0   11   37   18    0
     0    7  127   71    0
     0    1   15   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   13   16    0    0
     0    8   93   10    0
     0    4  129   48    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=1.6235 
[epoch 9] step 4/44: loss=1.6876 
[epoch 9] step 6/44: loss=1.6045 
[epoch 9] step 8/44: loss=1.5554 
[epoch 9] step 10/44: loss=1.5582 
[epoch 9] step 12/44: loss=1.5420 
[epoch 9] step 14/44: loss=1.5470 
[epoch 9] step 16/44: loss=1.5148 
[epoch 9] step 18/44: loss=1.4902 
[epoch 9] step 20/44: loss=1.4924 
[epoch 9] step 22/44: loss=1.4753 
[epoch 9] step 24/44: loss=1.4663 
[epoch 9] step 26/44: loss=1.4628 
[epoch 9] step 28/44: loss=1.4526 
[epoch 9] step 30/44: loss=1.4413 
[epoch 9] step 32/44: loss=1.4413 
[epoch 9] step 34/44: loss=1.4487 
[epoch 9] step 36/44: loss=1.4442 
[epoch 9] step 38/44: loss=1.4395 
[epoch 9] step 40/44: loss=1.4353 
[epoch 9] step 42/44: loss=1.4427 
[epoch 9] step 44/44: loss=1.4396 
[epoch 9] train_loss(avg per step)=2.8793 lambda[min,max]=[0.500049,1.000000]
[epoch 9] val_loss=4.7759 qwk=('0.1960', '0.2122', '0.2602') averageQWK=0.2228 macroEMD=0.3260 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    2   56   20    0
     0    2   81   79    0
     0    0   38   26    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    2   13    1    0
     0    5   49   12    0
     0    1  147   57    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   10   19    0    0
     0    4  103    4    0
     0    2  143   36    0
     0    0    1    0    0
[epoch 10] step 2/44: loss=1.2806 
[epoch 10] step 4/44: loss=1.4718 
[epoch 10] step 6/44: loss=1.4112 
[epoch 10] step 8/44: loss=1.4018 
[epoch 10] step 10/44: loss=1.3517 
[epoch 10] step 12/44: loss=1.3522 
[epoch 10] step 14/44: loss=1.3446 
[epoch 10] step 16/44: loss=1.3099 
[epoch 10] step 18/44: loss=1.2974 
[epoch 10] step 20/44: loss=1.2981 
[epoch 10] step 22/44: loss=1.2895 
[epoch 10] step 24/44: loss=1.3137 
[epoch 10] step 26/44: loss=1.3277 
[epoch 10] step 28/44: loss=1.3171 
[epoch 10] step 30/44: loss=1.3138 
[epoch 10] step 32/44: loss=1.3187 
[epoch 10] step 34/44: loss=1.3295 
[epoch 10] step 36/44: loss=1.3235 
[epoch 10] step 38/44: loss=1.3067 
[epoch 10] step 40/44: loss=1.3074 
[epoch 10] step 42/44: loss=1.2939 
[epoch 10] step 44/44: loss=1.2855 
[epoch 10] train_loss(avg per step)=2.5711 lambda[min,max]=[0.500051,1.000000]
[epoch 10] val_loss=6.5841 qwk=('0.1979', '0.2301', '0.2505') averageQWK=0.2262 macroEMD=0.3094 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    6    1    0
     0   14   53   11    0
     0    8  102   52    0
     0    5   39   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    9    6    1    0
     0   12   43   11    0
     0   13  142   50    0
     0    2   15   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   16   13    0    0
     0   15   96    0    0
     0    8  153   20    0
     0    0    1    0    0
[epoch 11] step 2/44: loss=1.1477 
[epoch 11] step 4/44: loss=1.1486 
[epoch 11] step 6/44: loss=1.1663 
[epoch 11] step 8/44: loss=1.1624 
[epoch 11] step 10/44: loss=1.2015 
[epoch 11] step 12/44: loss=1.2266 
[epoch 11] step 14/44: loss=1.2027 
[epoch 11] step 16/44: loss=1.1992 
[epoch 11] step 18/44: loss=1.1897 
[epoch 11] step 20/44: loss=1.1683 
[epoch 11] step 22/44: loss=1.1936 
[epoch 11] step 24/44: loss=1.1684 
[epoch 11] step 26/44: loss=1.1707 
[epoch 11] step 28/44: loss=1.1992 
[epoch 11] step 30/44: loss=1.1927 
[epoch 11] step 32/44: loss=1.1974 
[epoch 11] step 34/44: loss=1.2109 
[epoch 11] step 36/44: loss=1.2139 
[epoch 11] step 38/44: loss=1.2053 
[epoch 11] step 40/44: loss=1.1971 
[epoch 11] step 42/44: loss=1.1916 
[epoch 11] step 44/44: loss=1.1990 
[epoch 11] train_loss(avg per step)=2.3980 lambda[min,max]=[0.500009,1.000000]
[epoch 11] val_loss=5.5626 qwk=('0.2064', '0.2396', '0.3719') averageQWK=0.2726 macroEMD=0.3103 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    7    0    0
     0   13   58    7    0
     0    5  116   41    0
     0    3   44   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   11    3    2    0
     0   17   37   12    0
     0   21  129   55    0
     0    3   13   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   12    0    0
     0   25   78    8    0
     0   14  106   61    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=1.3657 
[epoch 12] step 4/44: loss=1.3267 
[epoch 12] step 6/44: loss=1.2406 
[epoch 12] step 8/44: loss=1.1947 
[epoch 12] step 10/44: loss=1.0992 
[epoch 12] step 12/44: loss=1.0988 
[epoch 12] step 14/44: loss=1.0914 
[epoch 12] step 16/44: loss=1.0672 
[epoch 12] step 18/44: loss=1.0695 
[epoch 12] step 20/44: loss=1.0700 
[epoch 12] step 22/44: loss=1.0704 
[epoch 12] step 24/44: loss=1.0429 
[epoch 12] step 26/44: loss=1.0496 
[epoch 12] step 28/44: loss=1.0366 
[epoch 12] step 30/44: loss=1.0367 
[epoch 12] step 32/44: loss=1.0289 
[epoch 12] step 34/44: loss=1.0250 
[epoch 12] step 36/44: loss=1.0120 
[epoch 12] step 38/44: loss=1.0017 
[epoch 12] step 40/44: loss=1.0102 
[epoch 12] step 42/44: loss=1.0192 
[epoch 12] step 44/44: loss=1.0283 
[epoch 12] train_loss(avg per step)=2.0565 lambda[min,max]=[0.500016,1.000000]
[epoch 12] val_loss=7.0192 qwk=('0.1050', '0.1983', '0.2595') averageQWK=0.1876 macroEMD=0.3107 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    6    1    0
     0   18   52    8    0
     0   20  106   36    0
     0   10   46    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   10    5    1    0
     0   17   40    9    0
     0   26  136   43    0
     0    4   17    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   17   12    0    0
     0   22   86    3    0
     0   12  143   26    0
     0    0    1    0    0
[epoch 13] step 2/44: loss=1.0172 
[epoch 13] step 4/44: loss=0.8616 
[epoch 13] step 6/44: loss=0.8655 
[epoch 13] step 8/44: loss=0.9720 
[epoch 13] step 10/44: loss=1.0005 
[epoch 13] step 12/44: loss=1.0212 
[epoch 13] step 14/44: loss=1.0317 
[epoch 13] step 16/44: loss=1.0449 
[epoch 13] step 18/44: loss=1.0651 
[epoch 13] step 20/44: loss=1.0714 
[epoch 13] step 22/44: loss=1.0800 
[epoch 13] step 24/44: loss=1.0661 
[epoch 13] step 26/44: loss=1.0563 
[epoch 13] step 28/44: loss=1.0304 
[epoch 13] step 30/44: loss=1.0372 
[epoch 13] step 32/44: loss=1.0041 
[epoch 13] step 34/44: loss=0.9865 
[epoch 13] step 36/44: loss=0.9784 
[epoch 13] step 38/44: loss=0.9826 
[epoch 13] step 40/44: loss=0.9680 
[epoch 13] step 42/44: loss=0.9638 
[epoch 13] step 44/44: loss=0.9688 
[epoch 13] train_loss(avg per step)=1.9376 lambda[min,max]=[0.500005,1.000000]
[epoch 13] val_loss=5.4514 qwk=('0.2205', '0.3260', '0.2888') averageQWK=0.2784 macroEMD=0.3092 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    7   55   16    0
     0    5   90   66    1
     0    3   32   29    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    8    5    3    0
     0   11   26   29    0
     0   11   78  116    0
     0    2    5   23    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   18   11    0    0
     0   21   85    5    0
     0   14  129   38    0
     0    0    1    0    0
[epoch 14] step 2/44: loss=0.7745 
[epoch 14] step 4/44: loss=0.8192 
[epoch 14] step 6/44: loss=0.8109 
[epoch 14] step 8/44: loss=0.8363 
[epoch 14] step 10/44: loss=0.8003 
[epoch 14] step 12/44: loss=0.7908 
[epoch 14] step 14/44: loss=0.8050 
[epoch 14] step 16/44: loss=0.8018 
[epoch 14] step 18/44: loss=0.8114 
[epoch 14] step 20/44: loss=0.8341 
[epoch 14] step 22/44: loss=0.8572 
[epoch 14] step 24/44: loss=0.8500 
[epoch 14] step 26/44: loss=0.8437 
[epoch 14] step 28/44: loss=0.8247 
[epoch 14] step 30/44: loss=0.8186 
[epoch 14] step 32/44: loss=0.8069 
[epoch 14] step 34/44: loss=0.7969 
[epoch 14] step 36/44: loss=0.7909 
[epoch 14] step 38/44: loss=0.7952 
[epoch 14] step 40/44: loss=0.7903 
[epoch 14] step 42/44: loss=0.7875 
[epoch 14] step 44/44: loss=0.7791 
[epoch 14] train_loss(avg per step)=1.5581 lambda[min,max]=[0.500008,1.000000]
[epoch 14] val_loss=6.4345 qwk=('0.1847', '0.1573', '0.2802') averageQWK=0.2074 macroEMD=0.3101 tailR0=('0.0234', '0.0167', '0.0000') tailR0avg=0.0134
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    5   52   20    1
     0    3   92   61    6
     0    0   40   21    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    3   12    1    0
     0    6   51    9    0
     0    2  161   39    3
     0    0   24    5    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   12   17    0    0
     0   10   95    6    0
     0    6  136   39    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=0.8790 
[epoch 15] step 4/44: loss=0.7318 
[epoch 15] step 6/44: loss=0.7422 
[epoch 15] step 8/44: loss=0.6775 
[epoch 15] step 10/44: loss=0.6975 
[epoch 15] step 12/44: loss=0.7068 
[epoch 15] step 14/44: loss=0.7541 
[epoch 15] step 16/44: loss=0.7338 
[epoch 15] step 18/44: loss=0.7093 
[epoch 15] step 20/44: loss=0.6961 
[epoch 15] step 22/44: loss=0.6965 
[epoch 15] step 24/44: loss=0.6859 
[epoch 15] step 26/44: loss=0.6715 
[epoch 15] step 28/44: loss=0.6743 
[epoch 15] step 30/44: loss=0.6676 
[epoch 15] step 32/44: loss=0.6640 
[epoch 15] step 34/44: loss=0.6586 
[epoch 15] step 36/44: loss=0.6541 
[epoch 15] step 38/44: loss=0.6549 
[epoch 15] step 40/44: loss=0.6599 
[epoch 15] step 42/44: loss=0.6622 
[epoch 15] step 44/44: loss=0.6691 
[epoch 15] train_loss(avg per step)=1.3382 lambda[min,max]=[0.500002,1.000000]
[epoch 15] val_loss=6.5893 qwk=('0.2217', '0.1881', '0.2487') averageQWK=0.2195 macroEMD=0.3056 tailR0=('0.0156', '0.0167', '0.0000') tailR0avg=0.0108
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    5    9    1    0
     0    9   57   12    0
     0    5  101   51    5
     0    2   36   24    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    8    5    3    0
     0   10   35   21    0
     0    8  136   58    3
     0    1   18   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   20    9    0    0
     0   32   66   13    0
     0   32  102   47    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=0.6076 
[epoch 16] step 4/44: loss=0.6492 
[epoch 16] step 6/44: loss=0.6121 
[epoch 16] step 8/44: loss=0.5884 
[epoch 16] step 10/44: loss=0.5807 
[epoch 16] step 12/44: loss=0.5395 
[epoch 16] step 14/44: loss=0.5860 
[epoch 16] step 16/44: loss=0.5955 
[epoch 16] step 18/44: loss=0.5687 
[epoch 16] step 20/44: loss=0.5543 
[epoch 16] step 22/44: loss=0.5562 
[epoch 16] step 24/44: loss=0.5645 
[epoch 16] step 26/44: loss=0.5673 
[epoch 16] step 28/44: loss=0.5610 
[epoch 16] step 30/44: loss=0.5644 
[epoch 16] step 32/44: loss=0.5717 
[epoch 16] step 34/44: loss=0.5718 
[epoch 16] step 36/44: loss=0.5730 
[epoch 16] step 38/44: loss=0.5681 
[epoch 16] step 40/44: loss=0.5720 
[epoch 16] step 42/44: loss=0.5742 
[epoch 16] step 44/44: loss=0.5733 
[epoch 16] train_loss(avg per step)=1.1465 lambda[min,max]=[0.500001,1.000000]
[epoch 16] val_loss=6.6728 qwk=('0.1613', '0.2036', '0.2886') averageQWK=0.2179 macroEMD=0.3008 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4    9    2    0
     0   12   47   19    0
     0   10  101   50    1
     0    3   38   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    9    4    3    0
     0   14   34   18    0
     0   14  134   57    0
     0    2   17   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   14   15    0    0
     0   21   83    7    0
     0   14  121   46    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=0.4343 
[epoch 17] step 4/44: loss=0.4251 
[epoch 17] step 6/44: loss=0.4571 
[epoch 17] step 8/44: loss=0.4258 
[epoch 17] step 10/44: loss=0.4253 
[epoch 17] step 12/44: loss=0.4221 
[epoch 17] step 14/44: loss=0.4075 
[epoch 17] step 16/44: loss=0.4097 
[epoch 17] step 18/44: loss=0.4080 
[epoch 17] step 20/44: loss=0.4039 
[epoch 17] step 22/44: loss=0.3928 
[epoch 17] step 24/44: loss=0.3883 
[epoch 17] step 26/44: loss=0.3894 
[epoch 17] step 28/44: loss=0.3888 
[epoch 17] step 30/44: loss=0.3797 
[epoch 17] step 32/44: loss=0.3752 
[epoch 17] step 34/44: loss=0.3918 
[epoch 17] step 36/44: loss=0.3902 
[epoch 17] step 38/44: loss=0.3923 
[epoch 17] step 40/44: loss=0.4062 
[epoch 17] step 42/44: loss=0.4095 
[epoch 17] step 44/44: loss=0.4199 
[epoch 17] train_loss(avg per step)=0.8397 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=7.6027 qwk=('0.1659', '0.2077', '0.2328') averageQWK=0.2021 macroEMD=0.3033 tailR0=('0.0391', '0.0167', '0.0000') tailR0avg=0.0186
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     1    4   63    8    2
     0    3  116   35    8
     0    1   45   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    8    6    2    0
     0   11   46    9    0
     0    6  154   41    4
     0    0   24    5    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1    5   23    0    0
     0    4  102    5    0
     0    2  144   35    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=0.2519 
[epoch 18] step 4/44: loss=0.2532 
[epoch 18] step 6/44: loss=0.2785 
[epoch 18] step 8/44: loss=0.2947 
[epoch 18] step 10/44: loss=0.3163 
[epoch 18] step 12/44: loss=0.3153 
[epoch 18] step 14/44: loss=0.2994 
[epoch 18] step 16/44: loss=0.2969 
[epoch 18] step 18/44: loss=0.2842 
[epoch 18] step 20/44: loss=0.2826 
[epoch 18] step 22/44: loss=0.2899 
[epoch 18] step 24/44: loss=0.2848 
[epoch 18] step 26/44: loss=0.2802 
[epoch 18] step 28/44: loss=0.2860 
[epoch 18] step 30/44: loss=0.2899 
[epoch 18] step 32/44: loss=0.2906 
[epoch 18] step 34/44: loss=0.2803 
[epoch 18] step 36/44: loss=0.2720 
[epoch 18] step 38/44: loss=0.2746 
[epoch 18] step 40/44: loss=0.2753 
[epoch 18] step 42/44: loss=0.2817 
[epoch 18] step 44/44: loss=0.2912 
[epoch 18] train_loss(avg per step)=0.5824 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=7.3637 qwk=('0.2302', '0.2718', '0.2504') averageQWK=0.2508 macroEMD=0.2940 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7    7    1    0
     0   12   55   11    0
     0    7  103   47    5
     0    4   34   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    9    6    1    0
     0   10   42   14    0
     0    7  125   73    0
     0    0   19   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1    7   21    0    0
     0    5  101    5    0
     0    4  140   37    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=0.1767 
[epoch 19] step 4/44: loss=0.1391 
[epoch 19] step 6/44: loss=0.1420 
[epoch 19] step 8/44: loss=0.1436 
[epoch 19] step 10/44: loss=0.1556 
[epoch 19] step 12/44: loss=0.1682 
[epoch 19] step 14/44: loss=0.1769 
[epoch 19] step 16/44: loss=0.1740 
[epoch 19] step 18/44: loss=0.1842 
[epoch 19] step 20/44: loss=0.1864 
[epoch 19] step 22/44: loss=0.1939 
[epoch 19] step 24/44: loss=0.1831 
[epoch 19] step 26/44: loss=0.1843 
[epoch 19] step 28/44: loss=0.1779 
[epoch 19] step 30/44: loss=0.1804 
[epoch 19] step 32/44: loss=0.1806 
[epoch 19] step 34/44: loss=0.1796 
[epoch 19] step 36/44: loss=0.1840 
[epoch 19] step 38/44: loss=0.1820 
[epoch 19] step 40/44: loss=0.1866 
[epoch 19] step 42/44: loss=0.1907 
[epoch 19] step 44/44: loss=0.1870 
[epoch 19] train_loss(avg per step)=0.3740 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=7.9378 qwk=('0.1497', '0.1597', '0.3091') averageQWK=0.2062 macroEMD=0.2927 tailR0=('0.0469', '0.0667', '0.0000') tailR0avg=0.0378
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   10    2    0
     0    5   58   12    3
     0    3  112   35   12
     0    2   42   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    4    9    3    0
     0    8   43   13    2
     0    4  149   46    6
     0    1   21    4    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1    9   19    0    0
     1    8   92   10    0
     0    3  129   49    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=-0.0295 
[epoch 20] step 4/44: loss=-0.0133 
[epoch 20] step 6/44: loss=0.0460 
[epoch 20] step 8/44: loss=0.0616 
[epoch 20] step 10/44: loss=0.0629 
[epoch 20] step 12/44: loss=0.0510 
[epoch 20] step 14/44: loss=0.0577 
[epoch 20] step 16/44: loss=0.0502 
[epoch 20] step 18/44: loss=0.0583 
[epoch 20] step 20/44: loss=0.0777 
[epoch 20] step 22/44: loss=0.0827 
[epoch 20] step 24/44: loss=0.0878 
[epoch 20] step 26/44: loss=0.0935 
[epoch 20] step 28/44: loss=0.0989 
[epoch 20] step 30/44: loss=0.1041 
[epoch 20] step 32/44: loss=0.1086 
[epoch 20] step 34/44: loss=0.1018 
[epoch 20] step 36/44: loss=0.1055 
[epoch 20] step 38/44: loss=0.1133 
[epoch 20] step 40/44: loss=0.1091 
[epoch 20] step 42/44: loss=0.1062 
[epoch 20] step 44/44: loss=0.1024 
[epoch 20] train_loss(avg per step)=0.2047 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=9.3985 qwk=('0.1902', '0.2136', '0.2436') averageQWK=0.2158 macroEMD=0.2938 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    7    7    1    0
     0    6   65    7    0
     0    6  115   41    0
     0    2   41   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    9    6    1    0
     0   12   42   12    0
     0   18  133   54    0
     0    2   18   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     2   14   13    0    0
     0   23   84    4    0
     0   20  132   29    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=0.1243 
[epoch 21] step 4/44: loss=0.1553 
[epoch 21] step 6/44: loss=0.1204 
[epoch 21] step 8/44: loss=0.0939 
[epoch 21] step 10/44: loss=0.0606 
[epoch 21] step 12/44: loss=0.0887 
[epoch 21] step 14/44: loss=0.0848 
[epoch 21] step 16/44: loss=0.0741 
[epoch 21] step 18/44: loss=0.0656 
[epoch 21] step 20/44: loss=0.0538 
[epoch 21] step 22/44: loss=0.0508 
[epoch 21] step 24/44: loss=0.0456 
[epoch 21] step 26/44: loss=0.0386 
[epoch 21] step 28/44: loss=0.0363 
[epoch 21] step 30/44: loss=0.0295 
[epoch 21] step 32/44: loss=0.0260 
[epoch 21] step 34/44: loss=0.0188 
[epoch 21] step 36/44: loss=0.0209 
[epoch 21] step 38/44: loss=0.0222 
[epoch 21] step 40/44: loss=0.0202 
[epoch 21] step 42/44: loss=0.0183 
[epoch 21] step 44/44: loss=0.0260 
[epoch 21] train_loss(avg per step)=0.0519 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=8.7005 qwk=('0.2141', '0.2084', '0.3427') averageQWK=0.2551 macroEMD=0.2861 tailR0=('0.0156', '0.1000', '0.0000') tailR0avg=0.0385
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    5    2    0
     0   18   34   25    1
     0   14   73   67    8
     0    7   26   29    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    8    6    2    0
     0    8   48    9    1
     1    4  155   43    2
     0    0   23    6    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1   17   11    0    0
     0   22   79   10    0
     1   13  110   57    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=-0.0459 
[epoch 22] step 4/44: loss=-0.0310 
[epoch 22] step 6/44: loss=-0.0255 
[epoch 22] step 8/44: loss=-0.0392 
[epoch 22] step 10/44: loss=-0.0328 
[epoch 22] step 12/44: loss=-0.0140 
[epoch 22] step 14/44: loss=-0.0125 
[epoch 22] step 16/44: loss=-0.0202 
[epoch 22] step 18/44: loss=-0.0200 
[epoch 22] step 20/44: loss=-0.0069 
[epoch 22] step 22/44: loss=-0.0011 
[epoch 22] step 24/44: loss=0.0167 
[epoch 22] step 26/44: loss=0.0279 
[epoch 22] step 28/44: loss=0.0250 
[epoch 22] step 30/44: loss=0.0153 
[epoch 22] step 32/44: loss=0.0118 
[epoch 22] step 34/44: loss=0.0091 
[epoch 22] step 36/44: loss=0.0038 
[epoch 22] step 38/44: loss=0.0006 
[epoch 22] step 40/44: loss=-0.0002 
[epoch 22] step 42/44: loss=-0.0058 
[epoch 22] step 44/44: loss=-0.0123 
[epoch 22] train_loss(avg per step)=-0.0246 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=9.1686 qwk=('0.2352', '0.2213', '0.3200') averageQWK=0.2588 macroEMD=0.2802 tailR0=('0.0078', '0.0167', '0.0000') tailR0avg=0.0082
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    7    6    2    0
     0   11   36   31    0
     0    6   63   88    5
     0    3   28   32    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    8    7    1    0
     0    8   47   10    1
     0    3  152   45    5
     0    0   21    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1   16   12    0    0
     0   14   91    6    0
     0   10  129   42    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=-0.0054 
[epoch 23] step 4/44: loss=-0.0449 
[epoch 23] step 6/44: loss=-0.0766 
[epoch 23] step 8/44: loss=-0.0860 
[epoch 23] step 10/44: loss=-0.0736 
[epoch 23] step 12/44: loss=-0.0613 
[epoch 23] step 14/44: loss=-0.0579 
[epoch 23] step 16/44: loss=-0.0625 
[epoch 23] step 18/44: loss=-0.0722 
[epoch 23] step 20/44: loss=-0.0730 
[epoch 23] step 22/44: loss=-0.0810 
[epoch 23] step 24/44: loss=-0.0810 
[epoch 23] step 26/44: loss=-0.0855 
[epoch 23] step 28/44: loss=-0.0936 
[epoch 23] step 30/44: loss=-0.0946 
[epoch 23] step 32/44: loss=-0.1023 
[epoch 23] step 34/44: loss=-0.1018 
[epoch 23] step 36/44: loss=-0.1037 
[epoch 23] step 38/44: loss=-0.1001 
[epoch 23] step 40/44: loss=-0.0945 
[epoch 23] step 42/44: loss=-0.0955 
[epoch 23] step 44/44: loss=-0.0960 
[epoch 23] train_loss(avg per step)=-0.1921 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=8.8136 qwk=('0.2393', '0.1697', '0.3120') averageQWK=0.2403 macroEMD=0.2833 tailR0=('0.0156', '0.0833', '0.0000') tailR0avg=0.0330
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    7    2    0
     0   12   29   36    1
     0   11   52   92    7
     0    4   22   36    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    4    0    0
     0    2   11    3    0
     0    4   45   17    0
     0    0  137   67    1
     0    0   19   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1   12   16    0    0
     0   10   96    5    0
     0    5  135   41    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=-0.0761 
[epoch 24] step 4/44: loss=-0.0807 
[epoch 24] step 6/44: loss=-0.0981 
[epoch 24] step 8/44: loss=-0.0986 
[epoch 24] step 10/44: loss=-0.0975 
[epoch 24] step 12/44: loss=-0.0972 
[epoch 24] step 14/44: loss=-0.1075 
[epoch 24] step 16/44: loss=-0.1026 
[epoch 24] step 18/44: loss=-0.1149 
[epoch 24] step 20/44: loss=-0.1192 
[epoch 24] step 22/44: loss=-0.1225 
[epoch 24] step 24/44: loss=-0.1132 
[epoch 24] step 26/44: loss=-0.1205 
[epoch 24] step 28/44: loss=-0.1152 
[epoch 24] step 30/44: loss=-0.1089 
[epoch 24] step 32/44: loss=-0.1092 
[epoch 24] step 34/44: loss=-0.1133 
[epoch 24] step 36/44: loss=-0.1140 
[epoch 24] step 38/44: loss=-0.1138 
[epoch 24] step 40/44: loss=-0.1137 
[epoch 24] step 42/44: loss=-0.1182 
[epoch 24] step 44/44: loss=-0.1196 
[epoch 24] train_loss(avg per step)=-0.2392 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=9.8073 qwk=('0.2059', '0.2187', '0.3253') averageQWK=0.2500 macroEMD=0.2813 tailR0=('0.0156', '0.0833', '0.0000') tailR0avg=0.0330
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     1    5    8    1    0
     1   13   52   12    0
     0    9  108   41    4
     0    3   38   21    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    7    6    3    0
     0    8   41   17    0
     0    7  136   61    1
     0    0   19   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   16   12    0    0
     0   20   85    6    0
     0   17  115   49    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=-0.1504 
[epoch 25] step 4/44: loss=-0.1181 
[epoch 25] step 6/44: loss=-0.1147 
[epoch 25] step 8/44: loss=-0.1208 
[epoch 25] step 10/44: loss=-0.1438 
[epoch 25] step 12/44: loss=-0.1551 
[epoch 25] step 14/44: loss=-0.1411 
[epoch 25] step 16/44: loss=-0.1534 
[epoch 25] step 18/44: loss=-0.1597 
[epoch 25] step 20/44: loss=-0.1588 
[epoch 25] step 22/44: loss=-0.1548 
[epoch 25] step 24/44: loss=-0.1583 
[epoch 25] step 26/44: loss=-0.1562 
[epoch 25] step 28/44: loss=-0.1613 
[epoch 25] step 30/44: loss=-0.1611 
[epoch 25] step 32/44: loss=-0.1543 
[epoch 25] step 34/44: loss=-0.1584 
[epoch 25] step 36/44: loss=-0.1585 
[epoch 25] step 38/44: loss=-0.1605 
[epoch 25] step 40/44: loss=-0.1619 
[epoch 25] step 42/44: loss=-0.1654 
[epoch 25] step 44/44: loss=-0.1638 
[epoch 25] train_loss(avg per step)=-0.3275 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=10.1100 qwk=('0.1794', '0.2463', '0.2504') averageQWK=0.2254 macroEMD=0.2856 tailR0=('0.0312', '0.0333', '0.0000') tailR0avg=0.0215
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     1    4    8    2    0
     1    6   48   20    3
     1    5   93   54    9
     0    3   34   23    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   10    5    1    0
     0    9   44   12    1
     0    8  138   55    4
     0    1   21    6    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     2    4   23    0    0
     0    6  101    4    0
     0    3  141   37    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=-0.2668 
[epoch 26] step 4/44: loss=-0.2274 
[epoch 26] step 6/44: loss=-0.2230 
[epoch 26] step 8/44: loss=-0.2225 
[epoch 26] step 10/44: loss=-0.2267 
[epoch 26] step 12/44: loss=-0.2300 
[epoch 26] step 14/44: loss=-0.2304 
[epoch 26] step 16/44: loss=-0.2301 
[epoch 26] step 18/44: loss=-0.2240 
[epoch 26] step 20/44: loss=-0.2245 
[epoch 26] step 22/44: loss=-0.2272 
[epoch 26] step 24/44: loss=-0.2272 
[epoch 26] step 26/44: loss=-0.2178 
[epoch 26] step 28/44: loss=-0.2149 
[epoch 26] step 30/44: loss=-0.2126 
[epoch 26] step 32/44: loss=-0.2135 
[epoch 26] step 34/44: loss=-0.2146 
[epoch 26] step 36/44: loss=-0.2136 
[epoch 26] step 38/44: loss=-0.2121 
[epoch 26] step 40/44: loss=-0.2147 
[epoch 26] step 42/44: loss=-0.2111 
[epoch 26] step 44/44: loss=-0.2102 
[epoch 26] train_loss(avg per step)=-0.4203 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=10.5774 qwk=('0.1398', '0.2528', '0.2987') averageQWK=0.2304 macroEMD=0.2850 tailR0=('0.0391', '0.0833', '0.0000') tailR0avg=0.0408
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     1    5    8    1    0
     1   11   57    7    2
     0    9  119   25    9
     0    3   52    4    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    8    6    2    0
     0   12   37   17    0
     0   13  120   72    0
     0    1   17   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     3    3   23    0    0
     0    5  100    6    0
     1    1  129   50    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=-0.0631 
[epoch 27] step 4/44: loss=-0.1258 
[epoch 27] step 6/44: loss=-0.1290 
[epoch 27] step 8/44: loss=-0.1536 
[epoch 27] step 10/44: loss=-0.1692 
[epoch 27] step 12/44: loss=-0.1697 
[epoch 27] step 14/44: loss=-0.1770 
[epoch 27] step 16/44: loss=-0.1846 
[epoch 27] step 18/44: loss=-0.1804 
[epoch 27] step 20/44: loss=-0.1783 
[epoch 27] step 22/44: loss=-0.1857 
[epoch 27] step 24/44: loss=-0.1920 
[epoch 27] step 26/44: loss=-0.1966 
[epoch 27] step 28/44: loss=-0.2008 
[epoch 27] step 30/44: loss=-0.1972 
[epoch 27] step 32/44: loss=-0.1987 
[epoch 27] step 34/44: loss=-0.1988 
[epoch 27] step 36/44: loss=-0.2005 
[epoch 27] step 38/44: loss=-0.2024 
[epoch 27] step 40/44: loss=-0.2025 
[epoch 27] step 42/44: loss=-0.2068 
[epoch 27] step 44/44: loss=-0.2065 
[epoch 27] train_loss(avg per step)=-0.4130 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=10.1603 qwk=('0.1769', '0.2186', '0.3076') averageQWK=0.2344 macroEMD=0.2828 tailR0=('0.0156', '0.1000', '0.0000') tailR0avg=0.0385
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4    9    2    0
     1    6   46   24    1
     0    9   84   65    4
     0    3   31   28    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    3    0    0
     0    3   10    3    0
     1    7   42   16    0
     0    1  141   61    2
     0    0   17   12    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1   13   15    0    0
     1   11   90    9    0
     1    9  120   51    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=-0.2573 
[epoch 28] step 4/44: loss=-0.2485 
[epoch 28] step 6/44: loss=-0.2421 
[epoch 28] step 8/44: loss=-0.2381 
[epoch 28] step 10/44: loss=-0.2320 
[epoch 28] step 12/44: loss=-0.2431 
[epoch 28] step 14/44: loss=-0.2478 
[epoch 28] step 16/44: loss=-0.2483 
[epoch 28] step 18/44: loss=-0.2503 
[epoch 28] step 20/44: loss=-0.2524 
[epoch 28] step 22/44: loss=-0.2515 
[epoch 28] step 24/44: loss=-0.2479 
[epoch 28] step 26/44: loss=-0.2520 
[epoch 28] step 28/44: loss=-0.2535 
[epoch 28] step 30/44: loss=-0.2543 
[epoch 28] step 32/44: loss=-0.2527 
[epoch 28] step 34/44: loss=-0.2490 
[epoch 28] step 36/44: loss=-0.2496 
[epoch 28] step 38/44: loss=-0.2501 
[epoch 28] step 40/44: loss=-0.2507 
[epoch 28] step 42/44: loss=-0.2530 
[epoch 28] step 44/44: loss=-0.2511 
[epoch 28] train_loss(avg per step)=-0.5023 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=10.1131 qwk=('0.1593', '0.2133', '0.3392') averageQWK=0.2373 macroEMD=0.2820 tailR0=('0.0156', '0.0833', '0.0000') tailR0avg=0.0330
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4    9    2    0
     0   10   44   23    1
     0    5   95   57    5
     0    3   36   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    3    0    0
     0    3   10    3    0
     0    7   43   16    0
     0    4  129   72    0
     0    1   15   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     2    4   23    0    0
     0    3   97   11    0
     0    1  117   63    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=-0.2815 
[epoch 29] step 4/44: loss=-0.2771 
[epoch 29] step 6/44: loss=-0.2794 
[epoch 29] step 8/44: loss=-0.2845 
[epoch 29] step 10/44: loss=-0.2771 
[epoch 29] step 12/44: loss=-0.2786 
[epoch 29] step 14/44: loss=-0.2836 
[epoch 29] step 16/44: loss=-0.2878 
[epoch 29] step 18/44: loss=-0.2882 
[epoch 29] step 20/44: loss=-0.2815 
[epoch 29] step 22/44: loss=-0.2808 
[epoch 29] step 24/44: loss=-0.2803 
[epoch 29] step 26/44: loss=-0.2815 
[epoch 29] step 28/44: loss=-0.2804 
[epoch 29] step 30/44: loss=-0.2792 
[epoch 29] step 32/44: loss=-0.2759 
[epoch 29] step 34/44: loss=-0.2778 
[epoch 29] step 36/44: loss=-0.2763 
[epoch 29] step 38/44: loss=-0.2721 
[epoch 29] step 40/44: loss=-0.2689 
[epoch 29] step 42/44: loss=-0.2716 
[epoch 29] step 44/44: loss=-0.2738 
[epoch 29] train_loss(avg per step)=-0.5476 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=11.0347 qwk=('0.2112', '0.1889', '0.3092') averageQWK=0.2364 macroEMD=0.2804 tailR0=('0.0078', '0.0167', '0.0000') tailR0avg=0.0082
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4    9    2    0
     1   10   40   27    0
     0    9   75   77    1
     0    3   27   33    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    7    7    2    0
     0    9   45   12    0
     0    3  151   47    4
     0    1   22    6    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     2    6   21    0    0
     0    6   98    7    0
     0    5  123   53    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=-0.2505 
[epoch 30] step 4/44: loss=-0.2855 
[epoch 30] step 6/44: loss=-0.2657 
[epoch 30] step 8/44: loss=-0.2770 
[epoch 30] step 10/44: loss=-0.2827 
[epoch 30] step 12/44: loss=-0.2843 
[epoch 30] step 14/44: loss=-0.2846 
[epoch 30] step 16/44: loss=-0.2807 
[epoch 30] step 18/44: loss=-0.2817 
[epoch 30] step 20/44: loss=-0.2790 
[epoch 30] step 22/44: loss=-0.2772 
[epoch 30] step 24/44: loss=-0.2811 
[epoch 30] step 26/44: loss=-0.2820 
[epoch 30] step 28/44: loss=-0.2842 
[epoch 30] step 30/44: loss=-0.2827 
[epoch 30] step 32/44: loss=-0.2851 
[epoch 30] step 34/44: loss=-0.2872 
[epoch 30] step 36/44: loss=-0.2847 
[epoch 30] step 38/44: loss=-0.2825 
[epoch 30] step 40/44: loss=-0.2834 
[epoch 30] step 42/44: loss=-0.2812 
[epoch 30] step 44/44: loss=-0.2809 
[epoch 30] train_loss(avg per step)=-0.5618 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=11.9545 qwk=('0.1814', '0.1988', '0.2603') averageQWK=0.2135 macroEMD=0.2814 tailR0=('0.0000', '0.0833', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4    9    2    0
     1    7   46   24    0
     0    7   86   69    0
     0    2   33   29    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    3    0    0
     0    3   11    2    0
     0    9   43   14    0
     0    3  141   61    0
     0    0   20   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1   10   18    0    0
     0   12   95    4    0
     0    7  138   36    0
     0    0    1    0    0
[epoch 31] step 2/44: loss=-0.3075 
[epoch 31] step 4/44: loss=-0.3096 
[epoch 31] step 6/44: loss=-0.2831 
[epoch 31] step 8/44: loss=-0.2981 
[epoch 31] step 10/44: loss=-0.3022 
[epoch 31] step 12/44: loss=-0.2953 
[epoch 31] step 14/44: loss=-0.2924 
[epoch 31] step 16/44: loss=-0.2909 
[epoch 31] step 18/44: loss=-0.2935 
[epoch 31] step 20/44: loss=-0.2951 
[epoch 31] step 22/44: loss=-0.2920 
[epoch 31] step 24/44: loss=-0.2929 
[epoch 31] step 26/44: loss=-0.2942 
[epoch 31] step 28/44: loss=-0.2947 
[epoch 31] step 30/44: loss=-0.2944 
[epoch 31] step 32/44: loss=-0.2939 
[epoch 31] step 34/44: loss=-0.2929 
[epoch 31] step 36/44: loss=-0.2945 
[epoch 31] step 38/44: loss=-0.2950 
[epoch 31] step 40/44: loss=-0.2960 
[epoch 31] step 42/44: loss=-0.2973 
[epoch 31] step 44/44: loss=-0.2987 
[epoch 31] train_loss(avg per step)=-0.5974 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=11.0315 qwk=('0.1879', '0.2491', '0.3000') averageQWK=0.2457 macroEMD=0.2815 tailR0=('0.0000', '0.0833', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   10    2    0
     1    7   41   29    0
     0    6   75   80    1
     0    3   28   33    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    7    7    2    0
     0    9   39   18    0
     0    6  128   71    0
     0    0   20   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     3    6   20    0    0
     0    8   96    7    0
     0    5  130   46    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=-0.3157 
[epoch 32] step 4/44: loss=-0.3044 
[epoch 32] step 6/44: loss=-0.3055 
[epoch 32] step 8/44: loss=-0.3118 
[epoch 32] step 10/44: loss=-0.3118 
[epoch 32] step 12/44: loss=-0.3074 
[epoch 32] step 14/44: loss=-0.2997 
[epoch 32] step 16/44: loss=-0.2983 
[epoch 32] step 18/44: loss=-0.2935 
[epoch 32] step 20/44: loss=-0.2900 
[epoch 32] step 22/44: loss=-0.2911 
[epoch 32] step 24/44: loss=-0.2913 
[epoch 32] step 26/44: loss=-0.2918 
[epoch 32] step 28/44: loss=-0.2923 
[epoch 32] step 30/44: loss=-0.2946 
[epoch 32] step 32/44: loss=-0.2936 
[epoch 32] step 34/44: loss=-0.2954 
[epoch 32] step 36/44: loss=-0.2969 
[epoch 32] step 38/44: loss=-0.2965 
[epoch 32] step 40/44: loss=-0.2970 
[epoch 32] step 42/44: loss=-0.2973 
[epoch 32] step 44/44: loss=-0.2982 
[epoch 32] train_loss(avg per step)=-0.5963 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=10.7829 qwk=('0.2123', '0.1839', '0.2993') averageQWK=0.2318 macroEMD=0.2811 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4    9    2    0
     1   10   38   28    1
     0    9   64   86    3
     0    3   27   33    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    3    0    0
     0    3   11    2    0
     0    7   42   16    1
     0    2  136   66    1
     0    0   21    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     2    5   22    0    0
     0    6   96    9    0
     0    4  124   53    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=-0.2583 
[epoch 33] step 4/44: loss=-0.2853 
[epoch 33] step 6/44: loss=-0.2816 
[epoch 33] step 8/44: loss=-0.2846 
[epoch 33] step 10/44: loss=-0.2858 
[epoch 33] step 12/44: loss=-0.2846 
[epoch 33] step 14/44: loss=-0.2888 
[epoch 33] step 16/44: loss=-0.2853 
[epoch 33] step 18/44: loss=-0.2868 
[epoch 33] step 20/44: loss=-0.2854 
[epoch 33] step 22/44: loss=-0.2894 
[epoch 33] step 24/44: loss=-0.2905 
[epoch 33] step 26/44: loss=-0.2940 
[epoch 33] step 28/44: loss=-0.2907 
[epoch 33] step 30/44: loss=-0.2915 
[epoch 33] step 32/44: loss=-0.2940 
[epoch 33] step 34/44: loss=-0.2958 
[epoch 33] step 36/44: loss=-0.2963 
[epoch 33] step 38/44: loss=-0.2985 
[epoch 33] step 40/44: loss=-0.2987 
[epoch 33] step 42/44: loss=-0.3000 
[epoch 33] step 44/44: loss=-0.3013 
[epoch 33] train_loss(avg per step)=-0.6027 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=12.5226 qwk=('0.1876', '0.1858', '0.2428') averageQWK=0.2054 macroEMD=0.2830 tailR0=('0.0000', '0.0833', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    2   11    2    0
     1    5   47   25    0
     0    5   80   77    0
     0    2   30   32    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    3    0    0
     0    3   11    2    0
     0    7   45   14    0
     0    1  147   56    1
     0    0   21    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     2    4   23    0    0
     0    4  103    4    0
     0    1  144   36    0
     0    0    1    0    0
[epoch 34] step 2/44: loss=-0.3228 
[epoch 34] step 4/44: loss=-0.3313 
[epoch 34] step 6/44: loss=-0.3231 
[epoch 34] step 8/44: loss=-0.3218 
[epoch 34] step 10/44: loss=-0.3158 
[epoch 34] step 12/44: loss=-0.3166 
[epoch 34] step 14/44: loss=-0.3163 
[epoch 34] step 16/44: loss=-0.3115 
[epoch 34] step 18/44: loss=-0.3109 
[epoch 34] step 20/44: loss=-0.3137 
[epoch 34] step 22/44: loss=-0.3124 
[epoch 34] step 24/44: loss=-0.3105 
[epoch 34] step 26/44: loss=-0.3123 
[epoch 34] step 28/44: loss=-0.3139 
[epoch 34] step 30/44: loss=-0.3126 
[epoch 34] step 32/44: loss=-0.3125 
[epoch 34] step 34/44: loss=-0.3114 
[epoch 34] step 36/44: loss=-0.3130 
[epoch 34] step 38/44: loss=-0.3139 
[epoch 34] step 40/44: loss=-0.3114 
[epoch 34] step 42/44: loss=-0.3112 
[epoch 34] step 44/44: loss=-0.3122 
[epoch 34] train_loss(avg per step)=-0.6244 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=11.6144 qwk=('0.1846', '0.2215', '0.2994') averageQWK=0.2352 macroEMD=0.2785 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4    9    2    0
     1    6   46   25    0
     0    6   85   69    2
     0    2   33   28    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    3   11    2    0
     0    8   41   17    0
     0    3  132   69    1
     0    0   19   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     2    7   20    0    0
     0    6   97    8    0
     0    3  132   46    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=-0.3395 
[epoch 35] step 4/44: loss=-0.3166 
[epoch 35] step 6/44: loss=-0.3203 
[epoch 35] step 8/44: loss=-0.3217 
[epoch 35] step 10/44: loss=-0.3230 
[epoch 35] step 12/44: loss=-0.3218 
[epoch 35] step 14/44: loss=-0.3178 
[epoch 35] step 16/44: loss=-0.3190 
[epoch 35] step 18/44: loss=-0.3193 
[epoch 35] step 20/44: loss=-0.3199 
[epoch 35] step 22/44: loss=-0.3176 
[epoch 35] step 24/44: loss=-0.3179 
[epoch 35] step 26/44: loss=-0.3166 
[epoch 35] step 28/44: loss=-0.3159 
[epoch 35] step 30/44: loss=-0.3154 
[epoch 35] step 32/44: loss=-0.3158 
[epoch 35] step 34/44: loss=-0.3164 
[epoch 35] step 36/44: loss=-0.3178 
[epoch 35] step 38/44: loss=-0.3153 
[epoch 35] step 40/44: loss=-0.3158 
[epoch 35] step 42/44: loss=-0.3164 
[epoch 35] step 44/44: loss=-0.3166 
[epoch 35] train_loss(avg per step)=-0.6332 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=11.5621 qwk=('0.1989', '0.2402', '0.2809') averageQWK=0.2400 macroEMD=0.2776 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4    9    2    0
     1    6   46   25    0
     0    6   83   73    0
     0    2   30   32    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    6    8    2    0
     0    9   40   17    0
     0    3  129   73    0
     0    0   19   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     2    6   21    0    0
     0    5   98    8    0
     0    3  134   44    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-1-reassignment-0/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-1-reassignment-0/fold0/metrics.json
Done.
