[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.5410 
[epoch 1] step 4/44: loss=6.0936 
[epoch 1] step 6/44: loss=5.8863 
[epoch 1] step 8/44: loss=5.8780 
[epoch 1] step 10/44: loss=5.9617 
[epoch 1] step 12/44: loss=5.8784 
[epoch 1] step 14/44: loss=5.8853 
[epoch 1] step 16/44: loss=5.9228 
[epoch 1] step 18/44: loss=5.9414 
[epoch 1] step 20/44: loss=5.9353 
[epoch 1] step 22/44: loss=5.9585 
[epoch 1] step 24/44: loss=5.9718 
[epoch 1] step 26/44: loss=5.9479 
[epoch 1] step 28/44: loss=5.9468 
[epoch 1] step 30/44: loss=5.9422 
[epoch 1] step 32/44: loss=5.9131 
[epoch 1] step 34/44: loss=5.8946 
[epoch 1] step 36/44: loss=5.8732 
[epoch 1] step 38/44: loss=5.8196 
[epoch 1] step 40/44: loss=5.7994 
[epoch 1] step 42/44: loss=5.7514 
[epoch 1] step 44/44: loss=5.6762 
[epoch 1] train_loss(avg per step)=11.3523 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=5.5652 qwk=('-0.0257', '0.1015', '0.0536') averageQWK=0.0431 macroEMD=0.3828 tailR0=('0.0000', '0.0385', '0.0000') tailR0avg=0.0128
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    8    0
     0   15    0   26    0
     0   45    0   77    0
     0   48    0   93    0
     0    9    0   12    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0   12    0    0
     6    0   29    4    0
    13    0   76   15    0
    15    0  118   30    0
     0    0   12    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    3   49    0    0
     0    4  154    0    0
     0    2  108    0    0
     0    0    3    0    0
[epoch 2] step 2/44: loss=4.2479 
[epoch 2] step 4/44: loss=4.2401 
[epoch 2] step 6/44: loss=4.2144 
[epoch 2] step 8/44: loss=4.0848 
[epoch 2] step 10/44: loss=4.0092 
[epoch 2] step 12/44: loss=3.9622 
[epoch 2] step 14/44: loss=3.8795 
[epoch 2] step 16/44: loss=3.8013 
[epoch 2] step 18/44: loss=3.7443 
[epoch 2] step 20/44: loss=3.6417 
[epoch 2] step 22/44: loss=3.5748 
[epoch 2] step 24/44: loss=3.5470 
[epoch 2] step 26/44: loss=3.4991 
[epoch 2] step 28/44: loss=3.4740 
[epoch 2] step 30/44: loss=3.4363 
[epoch 2] step 32/44: loss=3.3963 
[epoch 2] step 34/44: loss=3.3484 
[epoch 2] step 36/44: loss=3.3157 
[epoch 2] step 38/44: loss=3.3008 
[epoch 2] step 40/44: loss=3.2749 
[epoch 2] step 42/44: loss=3.2490 
[epoch 2] step 44/44: loss=3.2083 
[epoch 2] train_loss(avg per step)=6.4167 lambda[min,max]=[0.500005,1.000000]
[epoch 2] val_loss=3.7818 qwk=('0.4744', '0.1094', '0.1827') averageQWK=0.2555 macroEMD=0.3780 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    3   34    4    0
     1    2   62   57    0
     0    0   22  119    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    0    0
     0    0   39    0    0
     0    0  102    2    0
     0    0  146   17    0
     0    0   11    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    0   52    0    0
     0    0  156    2    0
     0    0   89   21    0
     0    0    1    2    0
[epoch 3] step 2/44: loss=2.4539 
[epoch 3] step 4/44: loss=2.6631 
[epoch 3] step 6/44: loss=2.6732 
[epoch 3] step 8/44: loss=2.7165 
[epoch 3] step 10/44: loss=2.7318 
[epoch 3] step 12/44: loss=2.7219 
[epoch 3] step 14/44: loss=2.7601 
[epoch 3] step 16/44: loss=2.7533 
[epoch 3] step 18/44: loss=2.7615 
[epoch 3] step 20/44: loss=2.7482 
[epoch 3] step 22/44: loss=2.7314 
[epoch 3] step 24/44: loss=2.7255 
[epoch 3] step 26/44: loss=2.7219 
[epoch 3] step 28/44: loss=2.7075 
[epoch 3] step 30/44: loss=2.7271 
[epoch 3] step 32/44: loss=2.7026 
[epoch 3] step 34/44: loss=2.6765 
[epoch 3] step 36/44: loss=2.6656 
[epoch 3] step 38/44: loss=2.6391 
[epoch 3] step 40/44: loss=2.6492 
[epoch 3] step 42/44: loss=2.6454 
[epoch 3] step 44/44: loss=2.6188 
[epoch 3] train_loss(avg per step)=5.2376 lambda[min,max]=[0.508885,1.000000]
[epoch 3] val_loss=4.0025 qwk=('0.4797', '0.1720', '0.2036') averageQWK=0.2851 macroEMD=0.3672 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    0    0
     0    7   33    1    0
     0    4   99   19    0
     0    0   55   86    0
     0    0    6   15    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    0    0
     0    3   36    0    0
     0    3   99    2    0
     0    0  131   32    0
     0    0   13    3    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    4   48    0    0
     0    4  154    0    0
     0    1   87   22    0
     0    0    3    0    0
[epoch 4] step 2/44: loss=2.7634 
[epoch 4] step 4/44: loss=2.6165 
[epoch 4] step 6/44: loss=2.5800 
[epoch 4] step 8/44: loss=2.6266 
[epoch 4] step 10/44: loss=2.6337 
[epoch 4] step 12/44: loss=2.6075 
[epoch 4] step 14/44: loss=2.6153 
[epoch 4] step 16/44: loss=2.6114 
[epoch 4] step 18/44: loss=2.5529 
[epoch 4] step 20/44: loss=2.5424 
[epoch 4] step 22/44: loss=2.5186 
[epoch 4] step 24/44: loss=2.5064 
[epoch 4] step 26/44: loss=2.5010 
[epoch 4] step 28/44: loss=2.5055 
[epoch 4] step 30/44: loss=2.5045 
[epoch 4] step 32/44: loss=2.4968 
[epoch 4] step 34/44: loss=2.4925 
[epoch 4] step 36/44: loss=2.4967 
[epoch 4] step 38/44: loss=2.4860 
[epoch 4] step 40/44: loss=2.4903 
[epoch 4] step 42/44: loss=2.4638 
[epoch 4] step 44/44: loss=2.4546 
[epoch 4] train_loss(avg per step)=4.9092 lambda[min,max]=[0.513913,1.000000]
[epoch 4] val_loss=4.2596 qwk=('0.4080', '0.4791', '0.4002') averageQWK=0.4291 macroEMD=0.3439 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    1   30   10    0
     0    0   47   75    0
     0    0   13  128    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    1    0
     0    0   36    3    0
     0    0   71   33    0
     0    0   33  130    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   14   20   18    0
     0   19   31  108    0
     0    3    3  104    0
     0    0    0    3    0
[epoch 5] step 2/44: loss=2.2067 
[epoch 5] step 4/44: loss=2.2280 
[epoch 5] step 6/44: loss=2.2118 
[epoch 5] step 8/44: loss=2.2620 
[epoch 5] step 10/44: loss=2.2334 
[epoch 5] step 12/44: loss=2.2203 
[epoch 5] step 14/44: loss=2.2185 
[epoch 5] step 16/44: loss=2.2153 
[epoch 5] step 18/44: loss=2.2053 
[epoch 5] step 20/44: loss=2.1563 
[epoch 5] step 22/44: loss=2.1722 
[epoch 5] step 24/44: loss=2.1898 
[epoch 5] step 26/44: loss=2.1909 
[epoch 5] step 28/44: loss=2.1982 
[epoch 5] step 30/44: loss=2.2084 
[epoch 5] step 32/44: loss=2.2084 
[epoch 5] step 34/44: loss=2.1880 
[epoch 5] step 36/44: loss=2.1933 
[epoch 5] step 38/44: loss=2.1837 
[epoch 5] step 40/44: loss=2.1828 
[epoch 5] step 42/44: loss=2.1760 
[epoch 5] step 44/44: loss=2.1927 
[epoch 5] train_loss(avg per step)=4.3853 lambda[min,max]=[0.502617,1.000000]
[epoch 5] val_loss=3.8793 qwk=('0.3858', '0.4414', '0.4667') averageQWK=0.4313 macroEMD=0.3460 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    6   21   14    0
     0    1   36   85    0
     0    0    8  133    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    1    0
     0    1   33    5    0
     0    1   65   38    0
     0    0   35  128    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   48    2    0
     0    5  116   37    0
     0    0   28   82    0
     0    0    0    3    0
[epoch 6] step 2/44: loss=2.2273 
[epoch 6] step 4/44: loss=2.1068 
[epoch 6] step 6/44: loss=2.1402 
[epoch 6] step 8/44: loss=2.0922 
[epoch 6] step 10/44: loss=2.0703 
[epoch 6] step 12/44: loss=2.0759 
[epoch 6] step 14/44: loss=2.0778 
[epoch 6] step 16/44: loss=2.0615 
[epoch 6] step 18/44: loss=2.0443 
[epoch 6] step 20/44: loss=2.0381 
[epoch 6] step 22/44: loss=2.0567 
[epoch 6] step 24/44: loss=2.0387 
[epoch 6] step 26/44: loss=2.0028 
[epoch 6] step 28/44: loss=2.0048 
[epoch 6] step 30/44: loss=1.9794 
[epoch 6] step 32/44: loss=1.9729 
[epoch 6] step 34/44: loss=1.9759 
[epoch 6] step 36/44: loss=1.9753 
[epoch 6] step 38/44: loss=1.9692 
[epoch 6] step 40/44: loss=1.9787 
[epoch 6] step 42/44: loss=1.9867 
[epoch 6] step 44/44: loss=1.9802 
[epoch 6] train_loss(avg per step)=3.9603 lambda[min,max]=[0.500489,1.000000]
[epoch 6] val_loss=4.4325 qwk=('0.5636', '0.5380', '0.3614') averageQWK=0.4877 macroEMD=0.3447 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    1    0    0
     0   31    9    1    0
     0   53   44   25    0
     0   15   33   93    0
     0    1    2   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    2    1    0
     0   24   13    2    0
     0   40   35   29    0
     0   16   37  110    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   11    1    0    0
     0   32   20    0    0
     0   48  110    0    0
     0    8   96    6    0
     0    0    3    0    0
[epoch 7] step 2/44: loss=2.4752 
[epoch 7] step 4/44: loss=2.4900 
[epoch 7] step 6/44: loss=2.3248 
[epoch 7] step 8/44: loss=2.2265 
[epoch 7] step 10/44: loss=2.2318 
[epoch 7] step 12/44: loss=2.1617 
[epoch 7] step 14/44: loss=2.1061 
[epoch 7] step 16/44: loss=2.0917 
[epoch 7] step 18/44: loss=2.0952 
[epoch 7] step 20/44: loss=2.1127 
[epoch 7] step 22/44: loss=2.0722 
[epoch 7] step 24/44: loss=2.0655 
[epoch 7] step 26/44: loss=2.0597 
[epoch 7] step 28/44: loss=2.0346 
[epoch 7] step 30/44: loss=2.0344 
[epoch 7] step 32/44: loss=2.0201 
[epoch 7] step 34/44: loss=2.0153 
[epoch 7] step 36/44: loss=2.0036 
[epoch 7] step 38/44: loss=1.9817 
[epoch 7] step 40/44: loss=1.9696 
[epoch 7] step 42/44: loss=1.9590 
[epoch 7] step 44/44: loss=1.9574 
[epoch 7] train_loss(avg per step)=3.9149 lambda[min,max]=[0.503721,1.000000]
[epoch 7] val_loss=4.6941 qwk=('0.4777', '0.2114', '0.3208') averageQWK=0.3366 macroEMD=0.3315 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    4   32    5    0
     0    0   65   57    0
     0    0   20  121    0
     0    0    2   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    6    0
     0    4    5   30    0
     0    6   14   84    0
     0    1    9  153    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    1    0
     0   11   14   27    0
     0   17   25  116    0
     0    4    3  103    0
     0    0    0    3    0
[epoch 8] step 2/44: loss=1.4671 
[epoch 8] step 4/44: loss=1.8283 
[epoch 8] step 6/44: loss=1.7899 
[epoch 8] step 8/44: loss=1.7336 
[epoch 8] step 10/44: loss=1.7284 
[epoch 8] step 12/44: loss=1.7580 
[epoch 8] step 14/44: loss=1.7577 
[epoch 8] step 16/44: loss=1.7637 
[epoch 8] step 18/44: loss=1.7586 
[epoch 8] step 20/44: loss=1.7559 
[epoch 8] step 22/44: loss=1.7584 
[epoch 8] step 24/44: loss=1.7650 
[epoch 8] step 26/44: loss=1.7738 
[epoch 8] step 28/44: loss=1.7729 
[epoch 8] step 30/44: loss=1.7781 
[epoch 8] step 32/44: loss=1.7802 
[epoch 8] step 34/44: loss=1.7890 
[epoch 8] step 36/44: loss=1.7806 
[epoch 8] step 38/44: loss=1.7730 
[epoch 8] step 40/44: loss=1.7701 
[epoch 8] step 42/44: loss=1.7763 
[epoch 8] step 44/44: loss=1.7869 
[epoch 8] train_loss(avg per step)=3.5737 lambda[min,max]=[0.500341,1.000000]
[epoch 8] val_loss=3.8185 qwk=('0.5322', '0.4938', '0.4883') averageQWK=0.5048 macroEMD=0.3255 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   18   22    1    0
     0   23   65   34    0
     0    6   39   96    0
     0    0    4   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    1    0
     0   15   23    1    0
     0   19   62   23    0
     0    9   51  103    0
     0    1    1   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    3    0    0
     0   24   28    0    0
     0   35  106   17    0
     0    7   53   50    0
     0    0    1    2    0
[epoch 9] step 2/44: loss=1.9318 
[epoch 9] step 4/44: loss=1.8341 
[epoch 9] step 6/44: loss=1.7106 
[epoch 9] step 8/44: loss=1.7704 
[epoch 9] step 10/44: loss=1.6881 
[epoch 9] step 12/44: loss=1.6526 
[epoch 9] step 14/44: loss=1.6487 
[epoch 9] step 16/44: loss=1.6790 
[epoch 9] step 18/44: loss=1.7076 
[epoch 9] step 20/44: loss=1.6912 
[epoch 9] step 22/44: loss=1.6738 
[epoch 9] step 24/44: loss=1.6589 
[epoch 9] step 26/44: loss=1.6409 
[epoch 9] step 28/44: loss=1.6423 
[epoch 9] step 30/44: loss=1.6340 
[epoch 9] step 32/44: loss=1.6241 
[epoch 9] step 34/44: loss=1.6010 
[epoch 9] step 36/44: loss=1.5945 
[epoch 9] step 38/44: loss=1.5907 
[epoch 9] step 40/44: loss=1.5974 
[epoch 9] step 42/44: loss=1.6117 
[epoch 9] step 44/44: loss=1.6062 
[epoch 9] train_loss(avg per step)=3.2125 lambda[min,max]=[0.500027,1.000000]
[epoch 9] val_loss=4.8368 qwk=('0.2917', '0.2331', '0.3618') averageQWK=0.2955 macroEMD=0.3298 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    4    0
     0    4   17   20    0
     0    1   26   95    0
     0    0    6  135    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    6    0
     0    3    9   27    0
     0    3   24   77    0
     0    1    7  155    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   36   15    0
     0    4   65   89    0
     0    0   10  100    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=1.5129 
[epoch 10] step 4/44: loss=1.5067 
[epoch 10] step 6/44: loss=1.5268 
[epoch 10] step 8/44: loss=1.5740 
[epoch 10] step 10/44: loss=1.5456 
[epoch 10] step 12/44: loss=1.5219 
[epoch 10] step 14/44: loss=1.5403 
[epoch 10] step 16/44: loss=1.5484 
[epoch 10] step 18/44: loss=1.5243 
[epoch 10] step 20/44: loss=1.5157 
[epoch 10] step 22/44: loss=1.4742 
[epoch 10] step 24/44: loss=1.4392 
[epoch 10] step 26/44: loss=1.4258 
[epoch 10] step 28/44: loss=1.4086 
[epoch 10] step 30/44: loss=1.4049 
[epoch 10] step 32/44: loss=1.4012 
[epoch 10] step 34/44: loss=1.3916 
[epoch 10] step 36/44: loss=1.3878 
[epoch 10] step 38/44: loss=1.3976 
[epoch 10] step 40/44: loss=1.3994 
[epoch 10] step 42/44: loss=1.4035 
[epoch 10] step 44/44: loss=1.4058 
[epoch 10] train_loss(avg per step)=2.8116 lambda[min,max]=[0.500023,1.000000]
[epoch 10] val_loss=4.5323 qwk=('0.4213', '0.3216', '0.4073') averageQWK=0.3834 macroEMD=0.3207 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    3    0
     0    4   30    7    0
     0    1   54   67    0
     0    0   16  125    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    4    0
     0    4   15   20    0
     0    2   30   72    0
     0    0   14  149    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    2   39   11    0
     0    5   76   77    0
     0    0   13   97    0
     0    0    0    3    0
[epoch 11] step 2/44: loss=1.6159 
[epoch 11] step 4/44: loss=1.4196 
[epoch 11] step 6/44: loss=1.3395 
[epoch 11] step 8/44: loss=1.3695 
[epoch 11] step 10/44: loss=1.3556 
[epoch 11] step 12/44: loss=1.3326 
[epoch 11] step 14/44: loss=1.3309 
[epoch 11] step 16/44: loss=1.3223 
[epoch 11] step 18/44: loss=1.3518 
[epoch 11] step 20/44: loss=1.3424 
[epoch 11] step 22/44: loss=1.3414 
[epoch 11] step 24/44: loss=1.3522 
[epoch 11] step 26/44: loss=1.3567 
[epoch 11] step 28/44: loss=1.3482 
[epoch 11] step 30/44: loss=1.3577 
[epoch 11] step 32/44: loss=1.3586 
[epoch 11] step 34/44: loss=1.3587 
[epoch 11] step 36/44: loss=1.3500 
[epoch 11] step 38/44: loss=1.3400 
[epoch 11] step 40/44: loss=1.3285 
[epoch 11] step 42/44: loss=1.3212 
[epoch 11] step 44/44: loss=1.2833 
[epoch 11] train_loss(avg per step)=2.5666 lambda[min,max]=[0.500006,1.000000]
[epoch 11] val_loss=4.4089 qwk=('0.4171', '0.4637', '0.4458') averageQWK=0.4422 macroEMD=0.3173 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    3    0
     0    3   31    7    0
     0    2   47   73    0
     0    0   14  127    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    1    0
     0    1   34    4    0
     0    3   62   39    0
     0    0   33  130    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   48    2    0
     0    2  108   48    0
     0    0   29   81    0
     0    0    0    3    0
[epoch 12] step 2/44: loss=1.0722 
[epoch 12] step 4/44: loss=1.1827 
[epoch 12] step 6/44: loss=1.1463 
[epoch 12] step 8/44: loss=1.1934 
[epoch 12] step 10/44: loss=1.1920 
[epoch 12] step 12/44: loss=1.1583 
[epoch 12] step 14/44: loss=1.1377 
[epoch 12] step 16/44: loss=1.1266 
[epoch 12] step 18/44: loss=1.1379 
[epoch 12] step 20/44: loss=1.1481 
[epoch 12] step 22/44: loss=1.1496 
[epoch 12] step 24/44: loss=1.1389 
[epoch 12] step 26/44: loss=1.1595 
[epoch 12] step 28/44: loss=1.1745 
[epoch 12] step 30/44: loss=1.1669 
[epoch 12] step 32/44: loss=1.1689 
[epoch 12] step 34/44: loss=1.1752 
[epoch 12] step 36/44: loss=1.1726 
[epoch 12] step 38/44: loss=1.1732 
[epoch 12] step 40/44: loss=1.1682 
[epoch 12] step 42/44: loss=1.1659 
[epoch 12] step 44/44: loss=1.1393 
[epoch 12] train_loss(avg per step)=2.2786 lambda[min,max]=[0.500007,1.000000]
[epoch 12] val_loss=4.3093 qwk=('0.4767', '0.4658', '0.4269') averageQWK=0.4565 macroEMD=0.3021 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    5   31    5    0
     0    3   62   57    0
     0    0   23  118    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    6   28    5    0
     0   11   49   44    0
     0    1   34  128    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    8   44    0    0
     0    9  131   18    0
     0    2   52   56    0
     0    0    1    2    0
[epoch 13] step 2/44: loss=1.0518 
[epoch 13] step 4/44: loss=1.0517 
[epoch 13] step 6/44: loss=1.0225 
[epoch 13] step 8/44: loss=1.0658 
[epoch 13] step 10/44: loss=1.0634 
[epoch 13] step 12/44: loss=1.0482 
[epoch 13] step 14/44: loss=1.0603 
[epoch 13] step 16/44: loss=1.0843 
[epoch 13] step 18/44: loss=1.0470 
[epoch 13] step 20/44: loss=1.0354 
[epoch 13] step 22/44: loss=1.0300 
[epoch 13] step 24/44: loss=1.0281 
[epoch 13] step 26/44: loss=1.0368 
[epoch 13] step 28/44: loss=1.0371 
[epoch 13] step 30/44: loss=1.0303 
[epoch 13] step 32/44: loss=1.0277 
[epoch 13] step 34/44: loss=1.0278 
[epoch 13] step 36/44: loss=1.0202 
[epoch 13] step 38/44: loss=1.0109 
[epoch 13] step 40/44: loss=1.0177 
[epoch 13] step 42/44: loss=1.0121 
[epoch 13] step 44/44: loss=1.0148 
[epoch 13] train_loss(avg per step)=2.0296 lambda[min,max]=[0.500001,1.000000]
[epoch 13] val_loss=5.1357 qwk=('0.4718', '0.4369', '0.1844') averageQWK=0.3644 macroEMD=0.3046 tailR0=('0.0476', '0.0000', '0.0000') tailR0avg=0.0159
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    5   34    2    0
     0    2   78   42    0
     0    0   39  102    0
     0    0    3   16    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    1    0
     0    3   33    3    0
     0    3   68   33    0
     0    0   47  116    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   50    0    0
     0    1  154    3    0
     0    0   89   21    0
     0    0    3    0    0
[epoch 14] step 2/44: loss=1.1284 
[epoch 14] step 4/44: loss=1.1822 
[epoch 14] step 6/44: loss=1.1232 
[epoch 14] step 8/44: loss=1.0316 
[epoch 14] step 10/44: loss=1.0203 
[epoch 14] step 12/44: loss=1.0040 
[epoch 14] step 14/44: loss=1.0132 
[epoch 14] step 16/44: loss=1.0161 
[epoch 14] step 18/44: loss=0.9890 
[epoch 14] step 20/44: loss=0.9557 
[epoch 14] step 22/44: loss=0.9226 
[epoch 14] step 24/44: loss=0.9204 
[epoch 14] step 26/44: loss=0.9256 
[epoch 14] step 28/44: loss=0.9157 
[epoch 14] step 30/44: loss=0.9017 
[epoch 14] step 32/44: loss=0.8990 
[epoch 14] step 34/44: loss=0.8991 
[epoch 14] step 36/44: loss=0.9064 
[epoch 14] step 38/44: loss=0.9032 
[epoch 14] step 40/44: loss=0.8952 
[epoch 14] step 42/44: loss=0.8876 
[epoch 14] step 44/44: loss=0.8784 
[epoch 14] train_loss(avg per step)=1.7569 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=5.1087 qwk=('0.4575', '0.3984', '0.4392') averageQWK=0.4317 macroEMD=0.3009 tailR0=('0.0238', '0.0000', '0.0000') tailR0avg=0.0079
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    3    0
     0    6   27    8    0
     0    3   52   67    0
     0    0   13  128    0
     0    0    0   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    2    0
     0    2   28    9    0
     0    3   55   46    0
     0    0   33  130    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    4   43    5    0
     0    9  112   37    0
     0    0   33   77    0
     0    0    0    3    0
[epoch 15] step 2/44: loss=0.7910 
[epoch 15] step 4/44: loss=0.7297 
[epoch 15] step 6/44: loss=0.7592 
[epoch 15] step 8/44: loss=0.8072 
[epoch 15] step 10/44: loss=0.8670 
[epoch 15] step 12/44: loss=0.8793 
[epoch 15] step 14/44: loss=0.8881 
[epoch 15] step 16/44: loss=0.8569 
[epoch 15] step 18/44: loss=0.8532 
[epoch 15] step 20/44: loss=0.8346 
[epoch 15] step 22/44: loss=0.8635 
[epoch 15] step 24/44: loss=0.8695 
[epoch 15] step 26/44: loss=0.8505 
[epoch 15] step 28/44: loss=0.8410 
[epoch 15] step 30/44: loss=0.8259 
[epoch 15] step 32/44: loss=0.8171 
[epoch 15] step 34/44: loss=0.8059 
[epoch 15] step 36/44: loss=0.7965 
[epoch 15] step 38/44: loss=0.7882 
[epoch 15] step 40/44: loss=0.7841 
[epoch 15] step 42/44: loss=0.7693 
[epoch 15] step 44/44: loss=0.7576 
[epoch 15] train_loss(avg per step)=1.5152 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=4.8044 qwk=('0.4799', '0.4433', '0.3638') averageQWK=0.4290 macroEMD=0.3045 tailR0=('0.0238', '0.0312', '0.0000') tailR0avg=0.0184
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    3    0
     0    4   33    4    0
     0    2   70   50    0
     0    0   22  116    3
     0    0    0   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    2    0
     0    4   26    9    0
     0    6   50   48    0
     0    0   30  129    4
     0    0    0   15    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   49    1    0
     0    5  128   25    0
     0    1   54   55    0
     0    0    0    3    0
[epoch 16] step 2/44: loss=0.7198 
[epoch 16] step 4/44: loss=0.7336 
[epoch 16] step 6/44: loss=0.7757 
[epoch 16] step 8/44: loss=0.7465 
[epoch 16] step 10/44: loss=0.7192 
[epoch 16] step 12/44: loss=0.7281 
[epoch 16] step 14/44: loss=0.6954 
[epoch 16] step 16/44: loss=0.6976 
[epoch 16] step 18/44: loss=0.6881 
[epoch 16] step 20/44: loss=0.7004 
[epoch 16] step 22/44: loss=0.6975 
[epoch 16] step 24/44: loss=0.6675 
[epoch 16] step 26/44: loss=0.6727 
[epoch 16] step 28/44: loss=0.6575 
[epoch 16] step 30/44: loss=0.6747 
[epoch 16] step 32/44: loss=0.6725 
[epoch 16] step 34/44: loss=0.6722 
[epoch 16] step 36/44: loss=0.6543 
[epoch 16] step 38/44: loss=0.6451 
[epoch 16] step 40/44: loss=0.6455 
[epoch 16] step 42/44: loss=0.6449 
[epoch 16] step 44/44: loss=0.6152 
[epoch 16] train_loss(avg per step)=1.2304 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=5.3034 qwk=('0.4619', '0.4265', '0.4219') averageQWK=0.4368 macroEMD=0.2942 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    3    0
     0    5   31    5    0
     0    5   65   52    0
     0    0   21  116    4
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    3   30    6    0
     0    4   59   40    1
     0    1   34  126    2
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    5   42    5    0
     0    8  100   50    0
     0    2   26   81    1
     0    0    0    3    0
[epoch 17] step 2/44: loss=0.4926 
[epoch 17] step 4/44: loss=0.4639 
[epoch 17] step 6/44: loss=0.4444 
[epoch 17] step 8/44: loss=0.4550 
[epoch 17] step 10/44: loss=0.4816 
[epoch 17] step 12/44: loss=0.4979 
[epoch 17] step 14/44: loss=0.5058 
[epoch 17] step 16/44: loss=0.5161 
[epoch 17] step 18/44: loss=0.5149 
[epoch 17] step 20/44: loss=0.5110 
[epoch 17] step 22/44: loss=0.4993 
[epoch 17] step 24/44: loss=0.4910 
[epoch 17] step 26/44: loss=0.4784 
[epoch 17] step 28/44: loss=0.4730 
[epoch 17] step 30/44: loss=0.4652 
[epoch 17] step 32/44: loss=0.4645 
[epoch 17] step 34/44: loss=0.4564 
[epoch 17] step 36/44: loss=0.4547 
[epoch 17] step 38/44: loss=0.4615 
[epoch 17] step 40/44: loss=0.4608 
[epoch 17] step 42/44: loss=0.4561 
[epoch 17] step 44/44: loss=0.4392 
[epoch 17] train_loss(avg per step)=0.8783 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=5.2969 qwk=('0.5430', '0.4111', '0.3709') averageQWK=0.4417 macroEMD=0.2907 tailR0=('0.1667', '0.0625', '0.0000') tailR0avg=0.0764
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   32    2    0
     0    5   76   41    0
     0    0   34   97   10
     0    0    1   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    3   32    4    0
     0    5   78   21    0
     0    0   63   96    4
     0    0    3   11    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    4   47    1    0
     0    6  136   16    0
     0    1   58   51    0
     0    0    0    3    0
[epoch 18] step 2/44: loss=0.4157 
[epoch 18] step 4/44: loss=0.4082 
[epoch 18] step 6/44: loss=0.4584 
[epoch 18] step 8/44: loss=0.4742 
[epoch 18] step 10/44: loss=0.4286 
[epoch 18] step 12/44: loss=0.4461 
[epoch 18] step 14/44: loss=0.4291 
[epoch 18] step 16/44: loss=0.4289 
[epoch 18] step 18/44: loss=0.4382 
[epoch 18] step 20/44: loss=0.4326 
[epoch 18] step 22/44: loss=0.4300 
[epoch 18] step 24/44: loss=0.4191 
[epoch 18] step 26/44: loss=0.4197 
[epoch 18] step 28/44: loss=0.4081 
[epoch 18] step 30/44: loss=0.3934 
[epoch 18] step 32/44: loss=0.3869 
[epoch 18] step 34/44: loss=0.3754 
[epoch 18] step 36/44: loss=0.3731 
[epoch 18] step 38/44: loss=0.3716 
[epoch 18] step 40/44: loss=0.3748 
[epoch 18] step 42/44: loss=0.3678 
[epoch 18] step 44/44: loss=0.3560 
[epoch 18] train_loss(avg per step)=0.7119 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=5.5744 qwk=('0.5420', '0.4898', '0.4527') averageQWK=0.4948 macroEMD=0.2768 tailR0=('0.0238', '0.0000', '0.0000') tailR0avg=0.0079
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0   10   26    5    0
     0    7   66   49    0
     0    0   20  115    6
     0    0    0   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    4    2    0
     0   14   18    7    0
     0   20   46   38    0
     0    7   32  123    1
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0   11   39    2    0
     1   15  104   38    0
     0    3   38   69    0
     0    0    0    3    0
[epoch 19] step 2/44: loss=0.2892 
[epoch 19] step 4/44: loss=0.2558 
[epoch 19] step 6/44: loss=0.3289 
[epoch 19] step 8/44: loss=0.3475 
[epoch 19] step 10/44: loss=0.3383 
[epoch 19] step 12/44: loss=0.3298 
[epoch 19] step 14/44: loss=0.3315 
[epoch 19] step 16/44: loss=0.3425 
[epoch 19] step 18/44: loss=0.3194 
[epoch 19] step 20/44: loss=0.3280 
[epoch 19] step 22/44: loss=0.3251 
[epoch 19] step 24/44: loss=0.3421 
[epoch 19] step 26/44: loss=0.3415 
[epoch 19] step 28/44: loss=0.3371 
[epoch 19] step 30/44: loss=0.3286 
[epoch 19] step 32/44: loss=0.3286 
[epoch 19] step 34/44: loss=0.3333 
[epoch 19] step 36/44: loss=0.3283 
[epoch 19] step 38/44: loss=0.3289 
[epoch 19] step 40/44: loss=0.3326 
[epoch 19] step 42/44: loss=0.3294 
[epoch 19] step 44/44: loss=0.3426 
[epoch 19] train_loss(avg per step)=0.6852 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=5.6444 qwk=('0.5239', '0.5001', '0.3989') averageQWK=0.4743 macroEMD=0.2847 tailR0=('0.2643', '0.0625', '0.1667') tailR0avg=0.1645
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     0    5   33    3    0
     0    4   77   38    3
     0    0   34   92   15
     0    0    2   10    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    4    2    0
     0    8   22    9    0
     0    9   42   53    0
     0    3   23  132    5
     0    0    0   14    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    7   42    3    0
     0   10  126   22    0
     0    3   50   55    2
     0    0    1    1    1
[epoch 20] step 2/44: loss=0.1185 
[epoch 20] step 4/44: loss=0.1250 
[epoch 20] step 6/44: loss=0.1402 
[epoch 20] step 8/44: loss=0.1261 
[epoch 20] step 10/44: loss=0.1233 
[epoch 20] step 12/44: loss=0.1443 
[epoch 20] step 14/44: loss=0.1550 
[epoch 20] step 16/44: loss=0.1455 
[epoch 20] step 18/44: loss=0.1313 
[epoch 20] step 20/44: loss=0.1261 
[epoch 20] step 22/44: loss=0.1273 
[epoch 20] step 24/44: loss=0.1428 
[epoch 20] step 26/44: loss=0.1350 
[epoch 20] step 28/44: loss=0.1334 
[epoch 20] step 30/44: loss=0.1290 
[epoch 20] step 32/44: loss=0.1303 
[epoch 20] step 34/44: loss=0.1293 
[epoch 20] step 36/44: loss=0.1317 
[epoch 20] step 38/44: loss=0.1352 
[epoch 20] step 40/44: loss=0.1328 
[epoch 20] step 42/44: loss=0.1323 
[epoch 20] step 44/44: loss=0.1258 
[epoch 20] train_loss(avg per step)=0.2515 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=6.0372 qwk=('0.5269', '0.4572', '0.4511') averageQWK=0.4784 macroEMD=0.2756 tailR0=('0.1690', '0.0000', '0.0000') tailR0avg=0.0563
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    1    0
     0    9   27    5    0
     0    5   64   51    2
     0    0   25  105   11
     0    0    1   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    4    2    0
     0   12   17   10    0
     0   19   36   48    1
     0    8   21  132    2
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    6   43    3    0
     0   10  116   32    0
     0    1   38   71    0
     0    0    0    3    0
[epoch 21] step 2/44: loss=0.0222 
[epoch 21] step 4/44: loss=0.0394 
[epoch 21] step 6/44: loss=0.0301 
[epoch 21] step 8/44: loss=0.0298 
[epoch 21] step 10/44: loss=0.0467 
[epoch 21] step 12/44: loss=0.0585 
[epoch 21] step 14/44: loss=0.0605 
[epoch 21] step 16/44: loss=0.0468 
[epoch 21] step 18/44: loss=0.0625 
[epoch 21] step 20/44: loss=0.0762 
[epoch 21] step 22/44: loss=0.0703 
[epoch 21] step 24/44: loss=0.0652 
[epoch 21] step 26/44: loss=0.0551 
[epoch 21] step 28/44: loss=0.0432 
[epoch 21] step 30/44: loss=0.0417 
[epoch 21] step 32/44: loss=0.0447 
[epoch 21] step 34/44: loss=0.0421 
[epoch 21] step 36/44: loss=0.0399 
[epoch 21] step 38/44: loss=0.0391 
[epoch 21] step 40/44: loss=0.0400 
[epoch 21] step 42/44: loss=0.0351 
[epoch 21] step 44/44: loss=0.0292 
[epoch 21] train_loss(avg per step)=0.0584 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=6.4692 qwk=('0.5209', '0.4258', '0.3929') averageQWK=0.4466 macroEMD=0.2794 tailR0=('0.1690', '0.0312', '0.0000') tailR0avg=0.0668
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     1    8   26    6    0
     0    5   58   58    1
     0    0   19  113    9
     0    0    1   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    4   29    6    0
     0    5   63   35    1
     0    2   41  117    3
     0    0    3   12    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    8   42    2    0
     0    9  131   18    0
     0    1   58   51    0
     0    0    0    3    0
[epoch 22] step 2/44: loss=-0.0530 
[epoch 22] step 4/44: loss=-0.0845 
[epoch 22] step 6/44: loss=-0.0590 
[epoch 22] step 8/44: loss=-0.0601 
[epoch 22] step 10/44: loss=-0.0313 
[epoch 22] step 12/44: loss=-0.0309 
[epoch 22] step 14/44: loss=-0.0340 
[epoch 22] step 16/44: loss=-0.0349 
[epoch 22] step 18/44: loss=-0.0456 
[epoch 22] step 20/44: loss=-0.0460 
[epoch 22] step 22/44: loss=-0.0450 
[epoch 22] step 24/44: loss=-0.0470 
[epoch 22] step 26/44: loss=-0.0491 
[epoch 22] step 28/44: loss=-0.0454 
[epoch 22] step 30/44: loss=-0.0456 
[epoch 22] step 32/44: loss=-0.0483 
[epoch 22] step 34/44: loss=-0.0416 
[epoch 22] step 36/44: loss=-0.0441 
[epoch 22] step 38/44: loss=-0.0372 
[epoch 22] step 40/44: loss=-0.0366 
[epoch 22] step 42/44: loss=-0.0322 
[epoch 22] step 44/44: loss=-0.0144 
[epoch 22] train_loss(avg per step)=-0.0288 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=7.2256 qwk=('0.4944', '0.4499', '0.4273') averageQWK=0.4572 macroEMD=0.2746 tailR0=('0.1190', '0.0000', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0   10   27    4    0
     0    7   65   48    2
     0    0   38   94    9
     0    0    2   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    3    2    0
     0   12   13   14    0
     0   16   30   57    1
     0    8   16  136    3
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   12   35    5    0
     1   16   86   54    1
     0    4   33   71    2
     0    0    0    3    0
[epoch 23] step 2/44: loss=0.0610 
[epoch 23] step 4/44: loss=0.1382 
[epoch 23] step 6/44: loss=0.1420 
[epoch 23] step 8/44: loss=0.0980 
[epoch 23] step 10/44: loss=0.0658 
[epoch 23] step 12/44: loss=0.0281 
[epoch 23] step 14/44: loss=0.0166 
[epoch 23] step 16/44: loss=-0.0052 
[epoch 23] step 18/44: loss=-0.0265 
[epoch 23] step 20/44: loss=-0.0422 
[epoch 23] step 22/44: loss=-0.0367 
[epoch 23] step 24/44: loss=-0.0192 
[epoch 23] step 26/44: loss=-0.0065 
[epoch 23] step 28/44: loss=-0.0083 
[epoch 23] step 30/44: loss=-0.0110 
[epoch 23] step 32/44: loss=-0.0239 
[epoch 23] step 34/44: loss=-0.0253 
[epoch 23] step 36/44: loss=-0.0342 
[epoch 23] step 38/44: loss=-0.0389 
[epoch 23] step 40/44: loss=-0.0425 
[epoch 23] step 42/44: loss=-0.0391 
[epoch 23] step 44/44: loss=-0.0468 
[epoch 23] train_loss(avg per step)=-0.0936 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=6.9551 qwk=('0.4939', '0.4827', '0.3916') averageQWK=0.4561 macroEMD=0.2763 tailR0=('0.2405', '0.0938', '0.0000') tailR0avg=0.1114
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     0    7   33    1    0
     0    4   78   39    1
     0    0   47   84   10
     0    0    5    8    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    2    0
     0    9   24    6    0
     0    8   55   40    1
     0    4   34  122    3
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    0   47    5    0
     0    3  106   49    0
     0    0   31   78    1
     0    0    0    3    0
[epoch 24] step 2/44: loss=-0.1808 
[epoch 24] step 4/44: loss=-0.1167 
[epoch 24] step 6/44: loss=-0.1229 
[epoch 24] step 8/44: loss=-0.1302 
[epoch 24] step 10/44: loss=-0.1411 
[epoch 24] step 12/44: loss=-0.1436 
[epoch 24] step 14/44: loss=-0.1450 
[epoch 24] step 16/44: loss=-0.1340 
[epoch 24] step 18/44: loss=-0.1122 
[epoch 24] step 20/44: loss=-0.1009 
[epoch 24] step 22/44: loss=-0.1029 
[epoch 24] step 24/44: loss=-0.1035 
[epoch 24] step 26/44: loss=-0.1055 
[epoch 24] step 28/44: loss=-0.1098 
[epoch 24] step 30/44: loss=-0.1117 
[epoch 24] step 32/44: loss=-0.1092 
[epoch 24] step 34/44: loss=-0.1161 
[epoch 24] step 36/44: loss=-0.1185 
[epoch 24] step 38/44: loss=-0.1237 
[epoch 24] step 40/44: loss=-0.1192 
[epoch 24] step 42/44: loss=-0.1186 
[epoch 24] step 44/44: loss=-0.1234 
[epoch 24] train_loss(avg per step)=-0.2468 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=7.4133 qwk=('0.5090', '0.4598', '0.4206') averageQWK=0.4631 macroEMD=0.2744 tailR0=('0.1929', '0.0938', '0.0000') tailR0avg=0.0955
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     1    6   30    4    0
     0    4   62   54    2
     0    0   26   98   17
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    2    0
     0    5   28    6    0
     1    3   64   35    1
     0    0   39  120    4
     0    0    2   11    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    6   43    3    0
     1    6  107   43    1
     0    1   37   71    1
     0    0    0    3    0
[epoch 25] step 2/44: loss=-0.0285 
[epoch 25] step 4/44: loss=-0.0887 
[epoch 25] step 6/44: loss=-0.1030 
[epoch 25] step 8/44: loss=-0.1282 
[epoch 25] step 10/44: loss=-0.1476 
[epoch 25] step 12/44: loss=-0.1528 
[epoch 25] step 14/44: loss=-0.1512 
[epoch 25] step 16/44: loss=-0.1525 
[epoch 25] step 18/44: loss=-0.1567 
[epoch 25] step 20/44: loss=-0.1630 
[epoch 25] step 22/44: loss=-0.1552 
[epoch 25] step 24/44: loss=-0.1587 
[epoch 25] step 26/44: loss=-0.1617 
[epoch 25] step 28/44: loss=-0.1618 
[epoch 25] step 30/44: loss=-0.1638 
[epoch 25] step 32/44: loss=-0.1675 
[epoch 25] step 34/44: loss=-0.1689 
[epoch 25] step 36/44: loss=-0.1698 
[epoch 25] step 38/44: loss=-0.1663 
[epoch 25] step 40/44: loss=-0.1691 
[epoch 25] step 42/44: loss=-0.1683 
[epoch 25] step 44/44: loss=-0.1472 
[epoch 25] train_loss(avg per step)=-0.2944 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=7.7873 qwk=('0.5039', '0.4633', '0.3933') averageQWK=0.4535 macroEMD=0.2720 tailR0=('0.0976', '0.0938', '0.0000') tailR0avg=0.0638
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    4   31    4    0
     0    3   71   47    1
     0    0   29  106    6
     0    0    1   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    5   30    4    0
     1    3   70   29    1
     0    0   48  113    2
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    5   45    2    0
     1    5  131   21    0
     0    0   53   57    0
     0    0    0    3    0
[epoch 26] step 2/44: loss=-0.2041 
[epoch 26] step 4/44: loss=-0.2057 
[epoch 26] step 6/44: loss=-0.1985 
[epoch 26] step 8/44: loss=-0.1964 
[epoch 26] step 10/44: loss=-0.1979 
[epoch 26] step 12/44: loss=-0.1884 
[epoch 26] step 14/44: loss=-0.1684 
[epoch 26] step 16/44: loss=-0.1590 
[epoch 26] step 18/44: loss=-0.1701 
[epoch 26] step 20/44: loss=-0.1687 
[epoch 26] step 22/44: loss=-0.1728 
[epoch 26] step 24/44: loss=-0.1771 
[epoch 26] step 26/44: loss=-0.1785 
[epoch 26] step 28/44: loss=-0.1745 
[epoch 26] step 30/44: loss=-0.1788 
[epoch 26] step 32/44: loss=-0.1775 
[epoch 26] step 34/44: loss=-0.1815 
[epoch 26] step 36/44: loss=-0.1876 
[epoch 26] step 38/44: loss=-0.1873 
[epoch 26] step 40/44: loss=-0.1894 
[epoch 26] step 42/44: loss=-0.1940 
[epoch 26] step 44/44: loss=-0.1965 
[epoch 26] train_loss(avg per step)=-0.3930 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=8.4697 qwk=('0.4750', '0.4467', '0.3559') averageQWK=0.4258 macroEMD=0.2735 tailR0=('0.0976', '0.0312', '0.0000') tailR0avg=0.0430
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    2   33    4    0
     0    1   67   53    1
     0    0   29  105    7
     0    0    2   17    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    2    0
     0    6   24    9    0
     0    5   58   40    1
     0    2   29  130    2
     0    0    3   12    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    0   48    4    0
     0    4  121   33    0
     0    0   48   62    0
     0    0    0    3    0
[epoch 27] step 2/44: loss=-0.2449 
[epoch 27] step 4/44: loss=-0.1866 
[epoch 27] step 6/44: loss=-0.1900 
[epoch 27] step 8/44: loss=-0.2200 
[epoch 27] step 10/44: loss=-0.2341 
[epoch 27] step 12/44: loss=-0.2415 
[epoch 27] step 14/44: loss=-0.2350 
[epoch 27] step 16/44: loss=-0.2258 
[epoch 27] step 18/44: loss=-0.2259 
[epoch 27] step 20/44: loss=-0.2208 
[epoch 27] step 22/44: loss=-0.2236 
[epoch 27] step 24/44: loss=-0.2180 
[epoch 27] step 26/44: loss=-0.2106 
[epoch 27] step 28/44: loss=-0.2122 
[epoch 27] step 30/44: loss=-0.2141 
[epoch 27] step 32/44: loss=-0.2156 
[epoch 27] step 34/44: loss=-0.2156 
[epoch 27] step 36/44: loss=-0.2160 
[epoch 27] step 38/44: loss=-0.2108 
[epoch 27] step 40/44: loss=-0.2096 
[epoch 27] step 42/44: loss=-0.2127 
[epoch 27] step 44/44: loss=-0.2151 
[epoch 27] train_loss(avg per step)=-0.4302 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=8.0008 qwk=('0.5070', '0.4391', '0.4383') averageQWK=0.4615 macroEMD=0.2752 tailR0=('0.1690', '0.0625', '0.0000') tailR0avg=0.0772
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    4   31    4    0
     0    3   65   52    2
     0    0   28  100   13
     0    0    1   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     0    8   21   10    0
     0    8   47   48    1
     0    4   25  128    6
     0    0    1   13    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    8   42    2    0
     0    6  113   39    0
     0    1   38   71    0
     0    0    0    3    0
[epoch 28] step 2/44: loss=-0.2600 
[epoch 28] step 4/44: loss=-0.2798 
[epoch 28] step 6/44: loss=-0.2694 
[epoch 28] step 8/44: loss=-0.2600 
[epoch 28] step 10/44: loss=-0.2546 
[epoch 28] step 12/44: loss=-0.2540 
[epoch 28] step 14/44: loss=-0.2552 
[epoch 28] step 16/44: loss=-0.2474 
[epoch 28] step 18/44: loss=-0.2424 
[epoch 28] step 20/44: loss=-0.2402 
[epoch 28] step 22/44: loss=-0.2428 
[epoch 28] step 24/44: loss=-0.2384 
[epoch 28] step 26/44: loss=-0.2393 
[epoch 28] step 28/44: loss=-0.2373 
[epoch 28] step 30/44: loss=-0.2399 
[epoch 28] step 32/44: loss=-0.2371 
[epoch 28] step 34/44: loss=-0.2361 
[epoch 28] step 36/44: loss=-0.2383 
[epoch 28] step 38/44: loss=-0.2373 
[epoch 28] step 40/44: loss=-0.2355 
[epoch 28] step 42/44: loss=-0.2371 
[epoch 28] step 44/44: loss=-0.2398 
[epoch 28] train_loss(avg per step)=-0.4797 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=8.7508 qwk=('0.5033', '0.4211', '0.4151') averageQWK=0.4465 macroEMD=0.2744 tailR0=('0.1929', '0.0312', '0.0000') tailR0avg=0.0747
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     2    3   30    6    0
     0    2   58   60    2
     0    0   17  112   12
     0    0    0   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    4   24   11    0
     0    4   57   42    1
     0    1   26  132    4
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    3   47    2    0
     0    3  120   35    0
     0    0   42   68    0
     0    0    0    3    0
[epoch 29] step 2/44: loss=-0.2897 
[epoch 29] step 4/44: loss=-0.2824 
[epoch 29] step 6/44: loss=-0.2679 
[epoch 29] step 8/44: loss=-0.2666 
[epoch 29] step 10/44: loss=-0.2659 
[epoch 29] step 12/44: loss=-0.2621 
[epoch 29] step 14/44: loss=-0.2521 
[epoch 29] step 16/44: loss=-0.2565 
[epoch 29] step 18/44: loss=-0.2578 
[epoch 29] step 20/44: loss=-0.2550 
[epoch 29] step 22/44: loss=-0.2533 
[epoch 29] step 24/44: loss=-0.2568 
[epoch 29] step 26/44: loss=-0.2513 
[epoch 29] step 28/44: loss=-0.2545 
[epoch 29] step 30/44: loss=-0.2500 
[epoch 29] step 32/44: loss=-0.2500 
[epoch 29] step 34/44: loss=-0.2504 
[epoch 29] step 36/44: loss=-0.2520 
[epoch 29] step 38/44: loss=-0.2527 
[epoch 29] step 40/44: loss=-0.2552 
[epoch 29] step 42/44: loss=-0.2530 
[epoch 29] step 44/44: loss=-0.2561 
[epoch 29] train_loss(avg per step)=-0.5121 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=8.1983 qwk=('0.5036', '0.4517', '0.3968') averageQWK=0.4507 macroEMD=0.2683 tailR0=('0.1214', '0.0312', '0.0000') tailR0avg=0.0509
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    4   31    4    0
     0    5   74   43    0
     0    0   31  101    9
     0    0    3   15    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0   10   21    8    0
     0    8   58   37    1
     0    5   33  121    4
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    8   42    2    0
     0    7  113   38    0
     0    1   45   64    0
     0    0    0    3    0
[epoch 30] step 2/44: loss=-0.3300 
[epoch 30] step 4/44: loss=-0.2974 
[epoch 30] step 6/44: loss=-0.2951 
[epoch 30] step 8/44: loss=-0.2815 
[epoch 30] step 10/44: loss=-0.2737 
[epoch 30] step 12/44: loss=-0.2756 
[epoch 30] step 14/44: loss=-0.2677 
[epoch 30] step 16/44: loss=-0.2658 
[epoch 30] step 18/44: loss=-0.2636 
[epoch 30] step 20/44: loss=-0.2642 
[epoch 30] step 22/44: loss=-0.2669 
[epoch 30] step 24/44: loss=-0.2668 
[epoch 30] step 26/44: loss=-0.2655 
[epoch 30] step 28/44: loss=-0.2677 
[epoch 30] step 30/44: loss=-0.2706 
[epoch 30] step 32/44: loss=-0.2722 
[epoch 30] step 34/44: loss=-0.2735 
[epoch 30] step 36/44: loss=-0.2755 
[epoch 30] step 38/44: loss=-0.2753 
[epoch 30] step 40/44: loss=-0.2759 
[epoch 30] step 42/44: loss=-0.2758 
[epoch 30] step 44/44: loss=-0.2778 
[epoch 30] train_loss(avg per step)=-0.5557 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=8.8371 qwk=('0.4786', '0.4357', '0.3985') averageQWK=0.4376 macroEMD=0.2737 tailR0=('0.1452', '0.0000', '0.0000') tailR0avg=0.0484
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     2    4   30    5    0
     0    2   59   60    1
     0    0   26  105   10
     0    0    1   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    5   25    9    0
     0    4   56   43    1
     0    1   29  130    3
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    0   48    4    0
     0    4  125   29    0
     0    0   41   68    1
     0    0    0    3    0
[epoch 31] step 2/44: loss=-0.2919 
[epoch 31] step 4/44: loss=-0.3020 
[epoch 31] step 6/44: loss=-0.3106 
[epoch 31] step 8/44: loss=-0.3005 
[epoch 31] step 10/44: loss=-0.2961 
[epoch 31] step 12/44: loss=-0.2843 
[epoch 31] step 14/44: loss=-0.2781 
[epoch 31] step 16/44: loss=-0.2786 
[epoch 31] step 18/44: loss=-0.2766 
[epoch 31] step 20/44: loss=-0.2810 
[epoch 31] step 22/44: loss=-0.2812 
[epoch 31] step 24/44: loss=-0.2805 
[epoch 31] step 26/44: loss=-0.2803 
[epoch 31] step 28/44: loss=-0.2822 
[epoch 31] step 30/44: loss=-0.2840 
[epoch 31] step 32/44: loss=-0.2837 
[epoch 31] step 34/44: loss=-0.2843 
[epoch 31] step 36/44: loss=-0.2848 
[epoch 31] step 38/44: loss=-0.2866 
[epoch 31] step 40/44: loss=-0.2885 
[epoch 31] step 42/44: loss=-0.2907 
[epoch 31] step 44/44: loss=-0.2916 
[epoch 31] train_loss(avg per step)=-0.5831 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=8.2559 qwk=('0.5243', '0.4707', '0.3784') averageQWK=0.4578 macroEMD=0.2715 tailR0=('0.1929', '0.0938', '0.0000') tailR0avg=0.0955
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    5   30    4    0
     0    4   69   46    3
     0    0   27   99   15
     0    0    1   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    2    0
     0    6   26    7    0
     0    5   63   35    1
     0    2   40  117    4
     0    0    2   11    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    5   45    2    0
     0    7  121   30    0
     0    0   51   59    0
     0    0    1    2    0
[epoch 32] step 2/44: loss=-0.2742 
[epoch 32] step 4/44: loss=-0.2883 
[epoch 32] step 6/44: loss=-0.2801 
[epoch 32] step 8/44: loss=-0.2791 
[epoch 32] step 10/44: loss=-0.2764 
[epoch 32] step 12/44: loss=-0.2755 
[epoch 32] step 14/44: loss=-0.2798 
[epoch 32] step 16/44: loss=-0.2771 
[epoch 32] step 18/44: loss=-0.2813 
[epoch 32] step 20/44: loss=-0.2869 
[epoch 32] step 22/44: loss=-0.2892 
[epoch 32] step 24/44: loss=-0.2901 
[epoch 32] step 26/44: loss=-0.2911 
[epoch 32] step 28/44: loss=-0.2945 
[epoch 32] step 30/44: loss=-0.2949 
[epoch 32] step 32/44: loss=-0.2934 
[epoch 32] step 34/44: loss=-0.2912 
[epoch 32] step 36/44: loss=-0.2901 
[epoch 32] step 38/44: loss=-0.2877 
[epoch 32] step 40/44: loss=-0.2899 
[epoch 32] step 42/44: loss=-0.2908 
[epoch 32] step 44/44: loss=-0.2908 
[epoch 32] train_loss(avg per step)=-0.5815 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=8.7465 qwk=('0.5183', '0.4763', '0.3906') averageQWK=0.4617 macroEMD=0.2704 tailR0=('0.1929', '0.0938', '0.0000') tailR0avg=0.0955
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    4   31    4    0
     0    3   71   46    2
     0    0   30  100   11
     0    0    1   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    2    0
     0    6   26    7    0
     0    5   62   36    1
     0    1   40  118    4
     0    0    2   11    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    3   47    2    0
     0    5  122   31    0
     0    0   46   64    0
     0    0    1    2    0
[epoch 33] step 2/44: loss=-0.2891 
[epoch 33] step 4/44: loss=-0.3000 
[epoch 33] step 6/44: loss=-0.3039 
[epoch 33] step 8/44: loss=-0.3085 
[epoch 33] step 10/44: loss=-0.3059 
[epoch 33] step 12/44: loss=-0.2918 
[epoch 33] step 14/44: loss=-0.2910 
[epoch 33] step 16/44: loss=-0.2885 
[epoch 33] step 18/44: loss=-0.2936 
[epoch 33] step 20/44: loss=-0.2921 
[epoch 33] step 22/44: loss=-0.2918 
[epoch 33] step 24/44: loss=-0.2931 
[epoch 33] step 26/44: loss=-0.2962 
[epoch 33] step 28/44: loss=-0.2949 
[epoch 33] step 30/44: loss=-0.2966 
[epoch 33] step 32/44: loss=-0.2977 
[epoch 33] step 34/44: loss=-0.2982 
[epoch 33] step 36/44: loss=-0.2978 
[epoch 33] step 38/44: loss=-0.2971 
[epoch 33] step 40/44: loss=-0.2977 
[epoch 33] step 42/44: loss=-0.2984 
[epoch 33] step 44/44: loss=-0.3002 
[epoch 33] train_loss(avg per step)=-0.6004 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=9.0005 qwk=('0.5128', '0.4719', '0.3822') averageQWK=0.4557 macroEMD=0.2682 tailR0=('0.1929', '0.0625', '0.0000') tailR0avg=0.0851
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    4   31    4    0
     0    4   65   51    2
     0    0   28  103   10
     0    0    1   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    2    0
     0    8   23    8    0
     0    7   58   38    1
     0    3   33  124    3
     0    0    2   12    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    5   45    2    0
     0    6  128   24    0
     0    1   50   59    0
     0    0    1    2    0
[epoch 34] step 2/44: loss=-0.3086 
[epoch 34] step 4/44: loss=-0.3187 
[epoch 34] step 6/44: loss=-0.3102 
[epoch 34] step 8/44: loss=-0.3064 
[epoch 34] step 10/44: loss=-0.3112 
[epoch 34] step 12/44: loss=-0.3095 
[epoch 34] step 14/44: loss=-0.3034 
[epoch 34] step 16/44: loss=-0.3038 
[epoch 34] step 18/44: loss=-0.3043 
[epoch 34] step 20/44: loss=-0.3065 
[epoch 34] step 22/44: loss=-0.3087 
[epoch 34] step 24/44: loss=-0.3093 
[epoch 34] step 26/44: loss=-0.3109 
[epoch 34] step 28/44: loss=-0.3121 
[epoch 34] step 30/44: loss=-0.3111 
[epoch 34] step 32/44: loss=-0.3117 
[epoch 34] step 34/44: loss=-0.3123 
[epoch 34] step 36/44: loss=-0.3132 
[epoch 34] step 38/44: loss=-0.3135 
[epoch 34] step 40/44: loss=-0.3140 
[epoch 34] step 42/44: loss=-0.3133 
[epoch 34] step 44/44: loss=-0.3132 
[epoch 34] train_loss(avg per step)=-0.6264 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=9.1617 qwk=('0.5007', '0.4570', '0.3848') averageQWK=0.4475 macroEMD=0.2681 tailR0=('0.1929', '0.0312', '0.0000') tailR0avg=0.0747
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     2    4   31    4    0
     0    4   62   54    2
     0    0   26  105   10
     0    0    1   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    2    0
     0    6   23   10    0
     0    7   52   44    1
     0    3   26  131    3
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    5   45    2    0
     0    7  114   37    0
     0    2   40   67    1
     0    0    1    2    0
[epoch 35] step 2/44: loss=-0.3233 
[epoch 35] step 4/44: loss=-0.3107 
[epoch 35] step 6/44: loss=-0.3077 
[epoch 35] step 8/44: loss=-0.3042 
[epoch 35] step 10/44: loss=-0.3029 
[epoch 35] step 12/44: loss=-0.3067 
[epoch 35] step 14/44: loss=-0.3106 
[epoch 35] step 16/44: loss=-0.3087 
[epoch 35] step 18/44: loss=-0.3064 
[epoch 35] step 20/44: loss=-0.3074 
[epoch 35] step 22/44: loss=-0.3106 
[epoch 35] step 24/44: loss=-0.3104 
[epoch 35] step 26/44: loss=-0.3117 
[epoch 35] step 28/44: loss=-0.3118 
[epoch 35] step 30/44: loss=-0.3118 
[epoch 35] step 32/44: loss=-0.3125 
[epoch 35] step 34/44: loss=-0.3136 
[epoch 35] step 36/44: loss=-0.3127 
[epoch 35] step 38/44: loss=-0.3127 
[epoch 35] step 40/44: loss=-0.3130 
[epoch 35] step 42/44: loss=-0.3126 
[epoch 35] step 44/44: loss=-0.3121 
[epoch 35] train_loss(avg per step)=-0.6242 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=9.0355 qwk=('0.4999', '0.4616', '0.3901') averageQWK=0.4505 macroEMD=0.2678 tailR0=('0.1929', '0.0312', '0.0000') tailR0avg=0.0747
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    4   31    4    0
     0    4   67   48    3
     0    0   30  101   10
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    2    0
     0    7   24    8    0
     0    7   54   42    1
     0    3   30  127    3
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    5   45    2    0
     0    7  117   34    0
     0    2   42   66    0
     0    0    1    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-1-reassignment-0/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-1-reassignment-0/fold1/metrics.json
Done.
