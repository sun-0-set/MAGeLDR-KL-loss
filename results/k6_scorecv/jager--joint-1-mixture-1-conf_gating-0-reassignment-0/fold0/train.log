[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=8.0302 
[epoch 1] step 4/44: loss=7.5851 
[epoch 1] step 6/44: loss=7.4362 
[epoch 1] step 8/44: loss=7.3188 
[epoch 1] step 10/44: loss=7.2154 
[epoch 1] step 12/44: loss=7.1857 
[epoch 1] step 14/44: loss=7.1780 
[epoch 1] step 16/44: loss=7.1840 
[epoch 1] step 18/44: loss=7.2435 
[epoch 1] step 20/44: loss=7.2126 
[epoch 1] step 22/44: loss=7.2041 
[epoch 1] step 24/44: loss=7.2229 
[epoch 1] step 26/44: loss=7.1678 
[epoch 1] step 28/44: loss=7.1079 
[epoch 1] step 30/44: loss=7.0822 
[epoch 1] step 32/44: loss=7.0828 
[epoch 1] step 34/44: loss=7.0462 
[epoch 1] step 36/44: loss=7.0128 
[epoch 1] step 38/44: loss=6.9683 
[epoch 1] step 40/44: loss=6.8951 
[epoch 1] step 42/44: loss=6.8012 
[epoch 1] step 44/44: loss=6.7904 
[epoch 1] train_loss(avg per step)=13.5809 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=8.5735 qwk=('0.1912', '0.1642', '0.0752') averageQWK=0.1435 macroEMD=0.3769 tailR0=('0.0000', '0.1111', '0.0000') tailR0avg=0.0370
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    4    0
     0   23    0   32    0
     0   51    0   74    0
     0   37    0   79    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    6    1    0
    19    0   26    7    0
    37    0   44   40    0
    32    0   37   65    0
     1    0    4    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   10   57    2    0
     0    9  137    5    0
     0    7   87    7    0
     0    1    1    0    0
[epoch 2] step 2/44: loss=5.1702 
[epoch 2] step 4/44: loss=4.9398 
[epoch 2] step 6/44: loss=5.0823 
[epoch 2] step 8/44: loss=4.9510 
[epoch 2] step 10/44: loss=4.9126 
[epoch 2] step 12/44: loss=4.8170 
[epoch 2] step 14/44: loss=4.7354 
[epoch 2] step 16/44: loss=4.6262 
[epoch 2] step 18/44: loss=4.5317 
[epoch 2] step 20/44: loss=4.4286 
[epoch 2] step 22/44: loss=4.3264 
[epoch 2] step 24/44: loss=4.2325 
[epoch 2] step 26/44: loss=4.1453 
[epoch 2] step 28/44: loss=4.0864 
[epoch 2] step 30/44: loss=4.0305 
[epoch 2] step 32/44: loss=3.9761 
[epoch 2] step 34/44: loss=3.9232 
[epoch 2] step 36/44: loss=3.8575 
[epoch 2] step 38/44: loss=3.8244 
[epoch 2] step 40/44: loss=3.7944 
[epoch 2] step 42/44: loss=3.7642 
[epoch 2] step 44/44: loss=3.7386 
[epoch 2] train_loss(avg per step)=7.4771 lambda[min,max]=[0.520754,1.000000]
[epoch 2] val_loss=4.1946 qwk=('0.1850', '0.4418', '0.4880') averageQWK=0.3716 macroEMD=0.3815 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    0    0
     0   51    4    0    0
     0  103   18    4    0
     0   68   25   23    0
     0   13    6    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   47    5    0
     0    0   72   49    0
     0    0   19  115    0
     0    0    3    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   31   38    0    0
     0   21  120   10    0
     0    2   65   34    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=2.9504 
[epoch 3] step 4/44: loss=2.9908 
[epoch 3] step 6/44: loss=3.0031 
[epoch 3] step 8/44: loss=2.9517 
[epoch 3] step 10/44: loss=2.9465 
[epoch 3] step 12/44: loss=2.9030 
[epoch 3] step 14/44: loss=2.9033 
[epoch 3] step 16/44: loss=2.9101 
[epoch 3] step 18/44: loss=2.9072 
[epoch 3] step 20/44: loss=2.8860 
[epoch 3] step 22/44: loss=2.8915 
[epoch 3] step 24/44: loss=2.8929 
[epoch 3] step 26/44: loss=2.8823 
[epoch 3] step 28/44: loss=2.8648 
[epoch 3] step 30/44: loss=2.8419 
[epoch 3] step 32/44: loss=2.8463 
[epoch 3] step 34/44: loss=2.8244 
[epoch 3] step 36/44: loss=2.8152 
[epoch 3] step 38/44: loss=2.8149 
[epoch 3] step 40/44: loss=2.7877 
[epoch 3] step 42/44: loss=2.7651 
[epoch 3] step 44/44: loss=2.7562 
[epoch 3] train_loss(avg per step)=5.5124 lambda[min,max]=[0.506732,1.000000]
[epoch 3] val_loss=3.9252 qwk=('0.4309', '0.5203', '0.4552') averageQWK=0.4688 macroEMD=0.3556 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    0
     0    6   48    1    0
     0    1  106   18    0
     0    0   44   72    0
     0    0   11   12    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   15   25   12    0
     0    8   49   64    0
     0    0    8  126    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    1   67    1    0
     0    0  134   17    0
     0    0   37   64    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=2.4252 
[epoch 4] step 4/44: loss=2.1976 
[epoch 4] step 6/44: loss=2.3608 
[epoch 4] step 8/44: loss=2.4623 
[epoch 4] step 10/44: loss=2.4054 
[epoch 4] step 12/44: loss=2.4229 
[epoch 4] step 14/44: loss=2.4202 
[epoch 4] step 16/44: loss=2.4043 
[epoch 4] step 18/44: loss=2.4920 
[epoch 4] step 20/44: loss=2.5046 
[epoch 4] step 22/44: loss=2.5054 
[epoch 4] step 24/44: loss=2.5057 
[epoch 4] step 26/44: loss=2.5111 
[epoch 4] step 28/44: loss=2.5072 
[epoch 4] step 30/44: loss=2.4908 
[epoch 4] step 32/44: loss=2.4870 
[epoch 4] step 34/44: loss=2.4912 
[epoch 4] step 36/44: loss=2.4813 
[epoch 4] step 38/44: loss=2.4805 
[epoch 4] step 40/44: loss=2.4699 
[epoch 4] step 42/44: loss=2.4641 
[epoch 4] step 44/44: loss=2.4621 
[epoch 4] train_loss(avg per step)=4.9242 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=3.9182 qwk=('0.5963', '0.2485', '0.6658') averageQWK=0.5035 macroEMD=0.3509 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   42   13    0    0
     0   40   73   12    0
     0    3   43   70    0
     0    1   10   12    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    0
     0    2   50    0    0
     0    0  120    1    0
     0    0   95   39    0
     0    0   10    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   34   35    0    0
     0   12  119   20    0
     0    0   31   70    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=2.4453 
[epoch 5] step 4/44: loss=2.2754 
[epoch 5] step 6/44: loss=2.2241 
[epoch 5] step 8/44: loss=2.2463 
[epoch 5] step 10/44: loss=2.2598 
[epoch 5] step 12/44: loss=2.2151 
[epoch 5] step 14/44: loss=2.2005 
[epoch 5] step 16/44: loss=2.1769 
[epoch 5] step 18/44: loss=2.1786 
[epoch 5] step 20/44: loss=2.1835 
[epoch 5] step 22/44: loss=2.1836 
[epoch 5] step 24/44: loss=2.1793 
[epoch 5] step 26/44: loss=2.1657 
[epoch 5] step 28/44: loss=2.1731 
[epoch 5] step 30/44: loss=2.1690 
[epoch 5] step 32/44: loss=2.1611 
[epoch 5] step 34/44: loss=2.1635 
[epoch 5] step 36/44: loss=2.1661 
[epoch 5] step 38/44: loss=2.1632 
[epoch 5] step 40/44: loss=2.1671 
[epoch 5] step 42/44: loss=2.1593 
[epoch 5] step 44/44: loss=2.1627 
[epoch 5] train_loss(avg per step)=4.3254 lambda[min,max]=[0.541574,1.000000]
[epoch 5] val_loss=3.6615 qwk=('0.5929', '0.6627', '0.4241') averageQWK=0.5599 macroEMD=0.3357 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   25   29    1    0
     0   12  100   13    0
     0    0   36   80    0
     0    0   10   13    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   27   24    1    0
     0   20   80   21    0
     0    1   31  102    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   12   57    0    0
     0    3  148    0    0
     0    0   67   34    0
     0    0    1    1    0
[epoch 6] step 2/44: loss=1.9546 
[epoch 6] step 4/44: loss=1.9553 
[epoch 6] step 6/44: loss=1.9942 
[epoch 6] step 8/44: loss=1.9942 
[epoch 6] step 10/44: loss=2.0058 
[epoch 6] step 12/44: loss=1.9976 
[epoch 6] step 14/44: loss=2.0161 
[epoch 6] step 16/44: loss=1.9964 
[epoch 6] step 18/44: loss=1.9999 
[epoch 6] step 20/44: loss=2.0117 
[epoch 6] step 22/44: loss=2.0069 
[epoch 6] step 24/44: loss=1.9990 
[epoch 6] step 26/44: loss=2.0231 
[epoch 6] step 28/44: loss=2.0118 
[epoch 6] step 30/44: loss=2.0095 
[epoch 6] step 32/44: loss=2.0076 
[epoch 6] step 34/44: loss=2.0204 
[epoch 6] step 36/44: loss=2.0151 
[epoch 6] step 38/44: loss=2.0041 
[epoch 6] step 40/44: loss=1.9919 
[epoch 6] step 42/44: loss=1.9988 
[epoch 6] step 44/44: loss=1.9994 
[epoch 6] train_loss(avg per step)=3.9988 lambda[min,max]=[0.513362,1.000000]
[epoch 6] val_loss=3.5280 qwk=('0.6318', '0.6361', '0.6869') averageQWK=0.6516 macroEMD=0.3225 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   26   26    3    0
     0   10   78   37    0
     0    0   20   96    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   21   27    4    0
     0   11   76   34    0
     0    0   16  118    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   47   20    2    0
     0   29   79   43    0
     0    1    9   91    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=1.8273 
[epoch 7] step 4/44: loss=1.8606 
[epoch 7] step 6/44: loss=1.8677 
[epoch 7] step 8/44: loss=1.8737 
[epoch 7] step 10/44: loss=1.9011 
[epoch 7] step 12/44: loss=1.9045 
[epoch 7] step 14/44: loss=1.9001 
[epoch 7] step 16/44: loss=1.8988 
[epoch 7] step 18/44: loss=1.9124 
[epoch 7] step 20/44: loss=1.9128 
[epoch 7] step 22/44: loss=1.8937 
[epoch 7] step 24/44: loss=1.8890 
[epoch 7] step 26/44: loss=1.8758 
[epoch 7] step 28/44: loss=1.8627 
[epoch 7] step 30/44: loss=1.8581 
[epoch 7] step 32/44: loss=1.8567 
[epoch 7] step 34/44: loss=1.8534 
[epoch 7] step 36/44: loss=1.8511 
[epoch 7] step 38/44: loss=1.8435 
[epoch 7] step 40/44: loss=1.8361 
[epoch 7] step 42/44: loss=1.8224 
[epoch 7] step 44/44: loss=1.8274 
[epoch 7] train_loss(avg per step)=3.6549 lambda[min,max]=[0.502005,1.000000]
[epoch 7] val_loss=3.6718 qwk=('0.6487', '0.6169', '0.6728') averageQWK=0.6461 macroEMD=0.3058 tailR0=('0.0000', '0.0556', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   41   14    0    0
     0   39   72   14    0
     0    1   39   76    0
     0    0    5   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     1   28   22    1    0
     0   21   87   13    0
     0    0   52   82    0
     0    0    4    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   55   14    0    0
     0   48   85   18    0
     0    3   29   69    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=1.7186 
[epoch 8] step 4/44: loss=1.6011 
[epoch 8] step 6/44: loss=1.5536 
[epoch 8] step 8/44: loss=1.6518 
[epoch 8] step 10/44: loss=1.7435 
[epoch 8] step 12/44: loss=1.7775 
[epoch 8] step 14/44: loss=1.7779 
[epoch 8] step 16/44: loss=1.7757 
[epoch 8] step 18/44: loss=1.7814 
[epoch 8] step 20/44: loss=1.7759 
[epoch 8] step 22/44: loss=1.7888 
[epoch 8] step 24/44: loss=1.7964 
[epoch 8] step 26/44: loss=1.7877 
[epoch 8] step 28/44: loss=1.7862 
[epoch 8] step 30/44: loss=1.7751 
[epoch 8] step 32/44: loss=1.7776 
[epoch 8] step 34/44: loss=1.7612 
[epoch 8] step 36/44: loss=1.7478 
[epoch 8] step 38/44: loss=1.7294 
[epoch 8] step 40/44: loss=1.7178 
[epoch 8] step 42/44: loss=1.7118 
[epoch 8] step 44/44: loss=1.7210 
[epoch 8] train_loss(avg per step)=3.4421 lambda[min,max]=[0.500239,1.000000]
[epoch 8] val_loss=3.5337 qwk=('0.6238', '0.6976', '0.6891') averageQWK=0.6702 macroEMD=0.2971 tailR0=('0.0000', '0.0556', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   36   18    1    0
     0   26   88   11    0
     0    0   38   78    0
     0    1    7   15    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    0    0
     0   39   12    1    0
     1   30   71   19    0
     0    2   26  106    0
     0    1    1   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   46   22    1    0
     0   29   96   26    0
     0    2   20   79    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=1.4149 
[epoch 9] step 4/44: loss=1.4205 
[epoch 9] step 6/44: loss=1.4237 
[epoch 9] step 8/44: loss=1.4489 
[epoch 9] step 10/44: loss=1.5225 
[epoch 9] step 12/44: loss=1.5197 
[epoch 9] step 14/44: loss=1.5258 
[epoch 9] step 16/44: loss=1.5329 
[epoch 9] step 18/44: loss=1.5649 
[epoch 9] step 20/44: loss=1.5824 
[epoch 9] step 22/44: loss=1.5955 
[epoch 9] step 24/44: loss=1.6016 
[epoch 9] step 26/44: loss=1.6044 
[epoch 9] step 28/44: loss=1.5913 
[epoch 9] step 30/44: loss=1.5939 
[epoch 9] step 32/44: loss=1.5917 
[epoch 9] step 34/44: loss=1.5876 
[epoch 9] step 36/44: loss=1.5807 
[epoch 9] step 38/44: loss=1.5849 
[epoch 9] step 40/44: loss=1.5770 
[epoch 9] step 42/44: loss=1.5756 
[epoch 9] step 44/44: loss=1.5674 
[epoch 9] train_loss(avg per step)=3.1347 lambda[min,max]=[0.500065,1.000000]
[epoch 9] val_loss=3.5517 qwk=('0.6110', '0.6691', '0.6883') averageQWK=0.6562 macroEMD=0.2847 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   27   27    1    0
     0   16   95   14    0
     0    0   35   81    0
     0    0    6   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   41    9    2    0
     0   36   67   18    0
     0    5   30   99    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   47   22    0    0
     0   28  102   21    0
     0    1   30   70    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=1.2976 
[epoch 10] step 4/44: loss=1.3053 
[epoch 10] step 6/44: loss=1.2914 
[epoch 10] step 8/44: loss=1.2477 
[epoch 10] step 10/44: loss=1.2656 
[epoch 10] step 12/44: loss=1.2769 
[epoch 10] step 14/44: loss=1.2909 
[epoch 10] step 16/44: loss=1.3064 
[epoch 10] step 18/44: loss=1.3246 
[epoch 10] step 20/44: loss=1.3406 
[epoch 10] step 22/44: loss=1.3413 
[epoch 10] step 24/44: loss=1.3446 
[epoch 10] step 26/44: loss=1.3508 
[epoch 10] step 28/44: loss=1.3450 
[epoch 10] step 30/44: loss=1.3512 
[epoch 10] step 32/44: loss=1.3424 
[epoch 10] step 34/44: loss=1.3432 
[epoch 10] step 36/44: loss=1.3272 
[epoch 10] step 38/44: loss=1.3313 
[epoch 10] step 40/44: loss=1.3386 
[epoch 10] step 42/44: loss=1.3360 
[epoch 10] step 44/44: loss=1.3395 
[epoch 10] train_loss(avg per step)=2.6789 lambda[min,max]=[0.500081,1.000000]
[epoch 10] val_loss=3.6864 qwk=('0.6423', '0.6660', '0.6526') averageQWK=0.6536 macroEMD=0.2895 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   29   24    1    1
     0   18   89   17    1
     0    0   27   83    6
     0    0    6   11    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   41    8    3    0
     0   46   48   27    0
     0    6   14  114    0
     0    1    0   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   39   28    2    0
     0   29   83   39    0
     0    2   14   85    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=1.1116 
[epoch 11] step 4/44: loss=1.1620 
[epoch 11] step 6/44: loss=1.0983 
[epoch 11] step 8/44: loss=1.0649 
[epoch 11] step 10/44: loss=1.0756 
[epoch 11] step 12/44: loss=1.0703 
[epoch 11] step 14/44: loss=1.0997 
[epoch 11] step 16/44: loss=1.1260 
[epoch 11] step 18/44: loss=1.1317 
[epoch 11] step 20/44: loss=1.1555 
[epoch 11] step 22/44: loss=1.1412 
[epoch 11] step 24/44: loss=1.1295 
[epoch 11] step 26/44: loss=1.1351 
[epoch 11] step 28/44: loss=1.1405 
[epoch 11] step 30/44: loss=1.1446 
[epoch 11] step 32/44: loss=1.1299 
[epoch 11] step 34/44: loss=1.1346 
[epoch 11] step 36/44: loss=1.1338 
[epoch 11] step 38/44: loss=1.1174 
[epoch 11] step 40/44: loss=1.1100 
[epoch 11] step 42/44: loss=1.1155 
[epoch 11] step 44/44: loss=1.1232 
[epoch 11] train_loss(avg per step)=2.2464 lambda[min,max]=[0.500007,1.000000]
[epoch 11] val_loss=4.1325 qwk=('0.6761', '0.6435', '0.6278') averageQWK=0.6492 macroEMD=0.2753 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     1   38   14    2    0
     0   35   74   16    0
     0    2   30   82    2
     0    0    3   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   41    9    2    0
     0   59   37   25    0
     0   10   10  114    0
     0    1    0   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   56   13    0    0
     0   63   73   15    0
     0    6   30   65    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=1.4147 
[epoch 12] step 4/44: loss=1.3477 
[epoch 12] step 6/44: loss=1.2142 
[epoch 12] step 8/44: loss=1.1603 
[epoch 12] step 10/44: loss=1.1667 
[epoch 12] step 12/44: loss=1.1325 
[epoch 12] step 14/44: loss=1.1329 
[epoch 12] step 16/44: loss=1.1629 
[epoch 12] step 18/44: loss=1.1679 
[epoch 12] step 20/44: loss=1.1469 
[epoch 12] step 22/44: loss=1.1438 
[epoch 12] step 24/44: loss=1.1454 
[epoch 12] step 26/44: loss=1.1242 
[epoch 12] step 28/44: loss=1.1224 
[epoch 12] step 30/44: loss=1.1126 
[epoch 12] step 32/44: loss=1.1084 
[epoch 12] step 34/44: loss=1.1054 
[epoch 12] step 36/44: loss=1.1079 
[epoch 12] step 38/44: loss=1.1048 
[epoch 12] step 40/44: loss=1.0871 
[epoch 12] step 42/44: loss=1.0790 
[epoch 12] step 44/44: loss=1.0750 
[epoch 12] train_loss(avg per step)=2.1500 lambda[min,max]=[0.500005,1.000000]
[epoch 12] val_loss=4.2794 qwk=('0.6189', '0.6103', '0.6053') averageQWK=0.6115 macroEMD=0.2728 tailR0=('0.0435', '0.0972', '0.1000') tailR0avg=0.0802
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0   26   22    6    1
     0   13   70   42    0
     0    0   12  103    1
     0    0    1   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   23   23    5    1
     0   15   56   50    0
     0    1   13  115    5
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     1   29   35    4    0
     1   14   77   59    0
     0    0   10   91    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.9854 
[epoch 13] step 4/44: loss=0.9089 
[epoch 13] step 6/44: loss=0.8210 
[epoch 13] step 8/44: loss=0.8386 
[epoch 13] step 10/44: loss=0.8579 
[epoch 13] step 12/44: loss=0.8140 
[epoch 13] step 14/44: loss=0.8171 
[epoch 13] step 16/44: loss=0.8329 
[epoch 13] step 18/44: loss=0.8511 
[epoch 13] step 20/44: loss=0.8589 
[epoch 13] step 22/44: loss=0.8565 
[epoch 13] step 24/44: loss=0.8560 
[epoch 13] step 26/44: loss=0.8676 
[epoch 13] step 28/44: loss=0.8720 
[epoch 13] step 30/44: loss=0.8868 
[epoch 13] step 32/44: loss=0.9113 
[epoch 13] step 34/44: loss=0.9138 
[epoch 13] step 36/44: loss=0.9126 
[epoch 13] step 38/44: loss=0.9159 
[epoch 13] step 40/44: loss=0.9091 
[epoch 13] step 42/44: loss=0.8972 
[epoch 13] step 44/44: loss=0.9003 
[epoch 13] train_loss(avg per step)=1.8006 lambda[min,max]=[0.500004,1.000000]
[epoch 13] val_loss=4.0358 qwk=('0.6533', '0.6145', '0.6087') averageQWK=0.6255 macroEMD=0.2657 tailR0=('0.1425', '0.0556', '0.1000') tailR0avg=0.0994
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    1    0
     0   28   24    3    0
     0   12   72   41    0
     0    0   16   99    1
     0    0    2   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    0    0
     0   14   34    4    0
     0    6   85   30    0
     0    0   20  113    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    3    0    0
     0   18   51    0    0
     0    2  131   18    0
     0    0   32   69    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.7465 
[epoch 14] step 4/44: loss=0.6289 
[epoch 14] step 6/44: loss=0.6971 
[epoch 14] step 8/44: loss=0.6851 
[epoch 14] step 10/44: loss=0.7306 
[epoch 14] step 12/44: loss=0.6953 
[epoch 14] step 14/44: loss=0.7175 
[epoch 14] step 16/44: loss=0.7190 
[epoch 14] step 18/44: loss=0.7288 
[epoch 14] step 20/44: loss=0.7174 
[epoch 14] step 22/44: loss=0.7084 
[epoch 14] step 24/44: loss=0.6996 
[epoch 14] step 26/44: loss=0.6964 
[epoch 14] step 28/44: loss=0.6856 
[epoch 14] step 30/44: loss=0.6922 
[epoch 14] step 32/44: loss=0.7033 
[epoch 14] step 34/44: loss=0.6914 
[epoch 14] step 36/44: loss=0.6888 
[epoch 14] step 38/44: loss=0.6876 
[epoch 14] step 40/44: loss=0.6862 
[epoch 14] step 42/44: loss=0.7060 
[epoch 14] step 44/44: loss=0.7141 
[epoch 14] train_loss(avg per step)=1.4283 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=4.0237 qwk=('0.6561', '0.6335', '0.6450') averageQWK=0.6449 macroEMD=0.2566 tailR0=('0.1304', '0.0417', '0.1000') tailR0avg=0.0907
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   31   22    1    1
     0   16   85   22    2
     0    0   27   82    7
     0    0    4   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   23   27    2    0
     0   14   86   21    0
     0    1   34   98    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   38   31    0    0
     0   25  117    9    0
     0    1   42   57    1
     0    0    0    2    0
[epoch 15] step 2/44: loss=0.8203 
[epoch 15] step 4/44: loss=0.7053 
[epoch 15] step 6/44: loss=0.6099 
[epoch 15] step 8/44: loss=0.5785 
[epoch 15] step 10/44: loss=0.5565 
[epoch 15] step 12/44: loss=0.5389 
[epoch 15] step 14/44: loss=0.5614 
[epoch 15] step 16/44: loss=0.5638 
[epoch 15] step 18/44: loss=0.5675 
[epoch 15] step 20/44: loss=0.5463 
[epoch 15] step 22/44: loss=0.5625 
[epoch 15] step 24/44: loss=0.5442 
[epoch 15] step 26/44: loss=0.5556 
[epoch 15] step 28/44: loss=0.5475 
[epoch 15] step 30/44: loss=0.5405 
[epoch 15] step 32/44: loss=0.5457 
[epoch 15] step 34/44: loss=0.5409 
[epoch 15] step 36/44: loss=0.5440 
[epoch 15] step 38/44: loss=0.5604 
[epoch 15] step 40/44: loss=0.5608 
[epoch 15] step 42/44: loss=0.5509 
[epoch 15] step 44/44: loss=0.5480 
[epoch 15] train_loss(avg per step)=1.0961 lambda[min,max]=[0.500001,1.000000]
[epoch 15] val_loss=4.2426 qwk=('0.6402', '0.6033', '0.6185') averageQWK=0.6207 macroEMD=0.2591 tailR0=('0.1522', '0.1389', '0.1000') tailR0avg=0.1304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   22   32    1    0
     0   15   88   20    2
     0    0   31   82    3
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     2   17   31    1    1
     1   15   86   19    0
     0    1   36   90    7
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     2   27   39    1    0
     0   25  101   25    0
     0    1   29   71    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=0.4420 
[epoch 16] step 4/44: loss=0.4537 
[epoch 16] step 6/44: loss=0.4361 
[epoch 16] step 8/44: loss=0.4047 
[epoch 16] step 10/44: loss=0.3929 
[epoch 16] step 12/44: loss=0.3912 
[epoch 16] step 14/44: loss=0.4070 
[epoch 16] step 16/44: loss=0.3799 
[epoch 16] step 18/44: loss=0.3711 
[epoch 16] step 20/44: loss=0.3538 
[epoch 16] step 22/44: loss=0.3636 
[epoch 16] step 24/44: loss=0.3960 
[epoch 16] step 26/44: loss=0.3956 
[epoch 16] step 28/44: loss=0.3889 
[epoch 16] step 30/44: loss=0.3921 
[epoch 16] step 32/44: loss=0.3894 
[epoch 16] step 34/44: loss=0.3917 
[epoch 16] step 36/44: loss=0.4051 
[epoch 16] step 38/44: loss=0.4057 
[epoch 16] step 40/44: loss=0.3976 
[epoch 16] step 42/44: loss=0.3988 
[epoch 16] step 44/44: loss=0.4142 
[epoch 16] train_loss(avg per step)=0.8283 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=4.4992 qwk=('0.6088', '0.6488', '0.6053') averageQWK=0.6210 macroEMD=0.2626 tailR0=('0.2850', '0.1389', '0.1000') tailR0avg=0.1746
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    4    0    1
     4   13   35    3    0
     2    4   82   33    4
     0    0   18   86   12
     0    0    2   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     0   23   24    5    0
     0   17   73   31    0
     0    1   19  108    6
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     5   16   46    2    0
     0    7  118   26    0
     0    0   26   75    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=0.3739 
[epoch 17] step 4/44: loss=0.3921 
[epoch 17] step 6/44: loss=0.3813 
[epoch 17] step 8/44: loss=0.3402 
[epoch 17] step 10/44: loss=0.3268 
[epoch 17] step 12/44: loss=0.3031 
[epoch 17] step 14/44: loss=0.2927 
[epoch 17] step 16/44: loss=0.2663 
[epoch 17] step 18/44: loss=0.2725 
[epoch 17] step 20/44: loss=0.2763 
[epoch 17] step 22/44: loss=0.2714 
[epoch 17] step 24/44: loss=0.2653 
[epoch 17] step 26/44: loss=0.2702 
[epoch 17] step 28/44: loss=0.2742 
[epoch 17] step 30/44: loss=0.2800 
[epoch 17] step 32/44: loss=0.2783 
[epoch 17] step 34/44: loss=0.2843 
[epoch 17] step 36/44: loss=0.2853 
[epoch 17] step 38/44: loss=0.2863 
[epoch 17] step 40/44: loss=0.2830 
[epoch 17] step 42/44: loss=0.2914 
[epoch 17] step 44/44: loss=0.2872 
[epoch 17] train_loss(avg per step)=0.5745 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=4.6275 qwk=('0.6457', '0.6188', '0.6080') averageQWK=0.6241 macroEMD=0.2564 tailR0=('0.0990', '0.0972', '0.1000') tailR0avg=0.0988
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   21   31    2    0
     1   12   86   25    1
     0    0   19   96    1
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    0    0
     1   26   20    5    0
     0   19   70   32    0
     0    0   27  106    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   32   37    0    0
     0   26  111   14    0
     0    2   39   60    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=0.3313 
[epoch 18] step 4/44: loss=0.2634 
[epoch 18] step 6/44: loss=0.2827 
[epoch 18] step 8/44: loss=0.2985 
[epoch 18] step 10/44: loss=0.2952 
[epoch 18] step 12/44: loss=0.2781 
[epoch 18] step 14/44: loss=0.2624 
[epoch 18] step 16/44: loss=0.2629 
[epoch 18] step 18/44: loss=0.2317 
[epoch 18] step 20/44: loss=0.2243 
[epoch 18] step 22/44: loss=0.2177 
[epoch 18] step 24/44: loss=0.2237 
[epoch 18] step 26/44: loss=0.2172 
[epoch 18] step 28/44: loss=0.2087 
[epoch 18] step 30/44: loss=0.2035 
[epoch 18] step 32/44: loss=0.2069 
[epoch 18] step 34/44: loss=0.2011 
[epoch 18] step 36/44: loss=0.2021 
[epoch 18] step 38/44: loss=0.2018 
[epoch 18] step 40/44: loss=0.2064 
[epoch 18] step 42/44: loss=0.1967 
[epoch 18] step 44/44: loss=0.2058 
[epoch 18] train_loss(avg per step)=0.4116 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=5.1235 qwk=('0.6062', '0.6130', '0.6094') averageQWK=0.6096 macroEMD=0.2548 tailR0=('0.2198', '0.1389', '0.1000') tailR0avg=0.1529
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
     2   20   31    2    0
     1   14   92   15    3
     0    0   40   74    2
     0    0    4   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     1   23   24    3    1
     1   13   78   29    0
     0    2   25  105    2
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     2   24   43    0    0
     0   17  126    8    0
     0    0   45   56    0
     0    0    0    2    0
[epoch 19] step 2/44: loss=0.0011 
[epoch 19] step 4/44: loss=0.0499 
[epoch 19] step 6/44: loss=0.0323 
[epoch 19] step 8/44: loss=0.0216 
[epoch 19] step 10/44: loss=0.0476 
[epoch 19] step 12/44: loss=0.0548 
[epoch 19] step 14/44: loss=0.0738 
[epoch 19] step 16/44: loss=0.0526 
[epoch 19] step 18/44: loss=0.0710 
[epoch 19] step 20/44: loss=0.0707 
[epoch 19] step 22/44: loss=0.0875 
[epoch 19] step 24/44: loss=0.0924 
[epoch 19] step 26/44: loss=0.0911 
[epoch 19] step 28/44: loss=0.0946 
[epoch 19] step 30/44: loss=0.1100 
[epoch 19] step 32/44: loss=0.1119 
[epoch 19] step 34/44: loss=0.1079 
[epoch 19] step 36/44: loss=0.1048 
[epoch 19] step 38/44: loss=0.0986 
[epoch 19] step 40/44: loss=0.0946 
[epoch 19] step 42/44: loss=0.0908 
[epoch 19] step 44/44: loss=0.0869 
[epoch 19] train_loss(avg per step)=0.1738 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=4.9204 qwk=('0.6732', '0.6262', '0.5984') averageQWK=0.6326 macroEMD=0.2514 tailR0=('0.2512', '0.1389', '0.1000') tailR0avg=0.1634
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     2   28   23    1    1
     1   19   76   26    3
     0    0   16   92    8
     0    0    3   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     0   32   14    4    2
     0   24   68   28    1
     0    3   21  102    8
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   22   46    0    0
     0   15  118   17    1
     0    0   36   65    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=-0.0048 
[epoch 20] step 4/44: loss=-0.0356 
[epoch 20] step 6/44: loss=-0.0182 
[epoch 20] step 8/44: loss=-0.0234 
[epoch 20] step 10/44: loss=-0.0232 
[epoch 20] step 12/44: loss=-0.0224 
[epoch 20] step 14/44: loss=-0.0321 
[epoch 20] step 16/44: loss=-0.0380 
[epoch 20] step 18/44: loss=-0.0381 
[epoch 20] step 20/44: loss=-0.0305 
[epoch 20] step 22/44: loss=-0.0302 
[epoch 20] step 24/44: loss=-0.0348 
[epoch 20] step 26/44: loss=-0.0277 
[epoch 20] step 28/44: loss=-0.0234 
[epoch 20] step 30/44: loss=-0.0188 
[epoch 20] step 32/44: loss=-0.0178 
[epoch 20] step 34/44: loss=-0.0211 
[epoch 20] step 36/44: loss=-0.0176 
[epoch 20] step 38/44: loss=-0.0187 
[epoch 20] step 40/44: loss=-0.0172 
[epoch 20] step 42/44: loss=-0.0161 
[epoch 20] step 44/44: loss=-0.0157 
[epoch 20] train_loss(avg per step)=-0.0314 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=5.5157 qwk=('0.5921', '0.6126', '0.6319') averageQWK=0.6122 macroEMD=0.2500 tailR0=('0.1860', '0.1389', '0.1000') tailR0avg=0.1416
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   14   37    3    0
     0    7   89   26    3
     0    0   29   83    4
     0    0    4   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     1   24   23    3    1
     0   13   75   32    1
     0    2   20  110    2
     0    1    0    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     2   25   41    1    0
     0   16  108   27    0
     0    0   29   72    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=-0.0654 
[epoch 21] step 4/44: loss=-0.0378 
[epoch 21] step 6/44: loss=-0.0203 
[epoch 21] step 8/44: loss=-0.0282 
[epoch 21] step 10/44: loss=-0.0361 
[epoch 21] step 12/44: loss=-0.0414 
[epoch 21] step 14/44: loss=-0.0456 
[epoch 21] step 16/44: loss=-0.0592 
[epoch 21] step 18/44: loss=-0.0557 
[epoch 21] step 20/44: loss=-0.0599 
[epoch 21] step 22/44: loss=-0.0656 
[epoch 21] step 24/44: loss=-0.0594 
[epoch 21] step 26/44: loss=-0.0457 
[epoch 21] step 28/44: loss=-0.0516 
[epoch 21] step 30/44: loss=-0.0590 
[epoch 21] step 32/44: loss=-0.0619 
[epoch 21] step 34/44: loss=-0.0665 
[epoch 21] step 36/44: loss=-0.0582 
[epoch 21] step 38/44: loss=-0.0499 
[epoch 21] step 40/44: loss=-0.0491 
[epoch 21] step 42/44: loss=-0.0469 
[epoch 21] step 44/44: loss=-0.0468 
[epoch 21] train_loss(avg per step)=-0.0936 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=5.4562 qwk=('0.6019', '0.6100', '0.5692') averageQWK=0.5937 macroEMD=0.2501 tailR0=('0.0990', '0.0833', '0.1000') tailR0avg=0.0941
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   15   36    3    0
     0    8   86   28    3
     0    0   21   92    3
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    0    0
     0   24   26    1    1
     0    8   88   24    1
     0    1   33   99    1
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   21   47    1    0
     0   12  111   27    1
     0    0   35   66    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=-0.1179 
[epoch 22] step 4/44: loss=-0.1647 
[epoch 22] step 6/44: loss=-0.1713 
[epoch 22] step 8/44: loss=-0.1506 
[epoch 22] step 10/44: loss=-0.1488 
[epoch 22] step 12/44: loss=-0.1321 
[epoch 22] step 14/44: loss=-0.1291 
[epoch 22] step 16/44: loss=-0.1353 
[epoch 22] step 18/44: loss=-0.1479 
[epoch 22] step 20/44: loss=-0.1502 
[epoch 22] step 22/44: loss=-0.1461 
[epoch 22] step 24/44: loss=-0.1421 
[epoch 22] step 26/44: loss=-0.1372 
[epoch 22] step 28/44: loss=-0.1371 
[epoch 22] step 30/44: loss=-0.1379 
[epoch 22] step 32/44: loss=-0.1377 
[epoch 22] step 34/44: loss=-0.1401 
[epoch 22] step 36/44: loss=-0.1411 
[epoch 22] step 38/44: loss=-0.1381 
[epoch 22] step 40/44: loss=-0.1333 
[epoch 22] step 42/44: loss=-0.1347 
[epoch 22] step 44/44: loss=-0.1348 
[epoch 22] train_loss(avg per step)=-0.2696 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=5.6284 qwk=('0.6480', '0.6337', '0.6077') averageQWK=0.6298 macroEMD=0.2437 tailR0=('0.2174', '0.1389', '0.1000') tailR0avg=0.1521
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   32   21    0    1
     2   17   88   14    4
     0    0   34   69   13
     0    1    3    9   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   25   23    2    1
     1   12   92   15    1
     0    2   36   93    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     3   34   31    1    0
     0   30  106   15    0
     0    3   38   60    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=-0.1643 
[epoch 23] step 4/44: loss=-0.1821 
[epoch 23] step 6/44: loss=-0.1675 
[epoch 23] step 8/44: loss=-0.1906 
[epoch 23] step 10/44: loss=-0.1793 
[epoch 23] step 12/44: loss=-0.1917 
[epoch 23] step 14/44: loss=-0.1792 
[epoch 23] step 16/44: loss=-0.1737 
[epoch 23] step 18/44: loss=-0.1761 
[epoch 23] step 20/44: loss=-0.1681 
[epoch 23] step 22/44: loss=-0.1708 
[epoch 23] step 24/44: loss=-0.1651 
[epoch 23] step 26/44: loss=-0.1648 
[epoch 23] step 28/44: loss=-0.1547 
[epoch 23] step 30/44: loss=-0.1565 
[epoch 23] step 32/44: loss=-0.1610 
[epoch 23] step 34/44: loss=-0.1638 
[epoch 23] step 36/44: loss=-0.1567 
[epoch 23] step 38/44: loss=-0.1533 
[epoch 23] step 40/44: loss=-0.1566 
[epoch 23] step 42/44: loss=-0.1600 
[epoch 23] step 44/44: loss=-0.1581 
[epoch 23] train_loss(avg per step)=-0.3162 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=5.7580 qwk=('0.6399', '0.6422', '0.6335') averageQWK=0.6385 macroEMD=0.2389 tailR0=('0.1643', '0.1389', '0.1000') tailR0avg=0.1344
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     2   23   27    3    0
     1   12   79   30    3
     0    0   22   90    4
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     2   23   23    4    0
     1   13   80   26    1
     0    1   25  108    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     2   28   38    1    0
     0   16  117   18    0
     0    0   34   67    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=-0.2805 
[epoch 24] step 4/44: loss=-0.2268 
[epoch 24] step 6/44: loss=-0.2329 
[epoch 24] step 8/44: loss=-0.2197 
[epoch 24] step 10/44: loss=-0.2299 
[epoch 24] step 12/44: loss=-0.2216 
[epoch 24] step 14/44: loss=-0.2294 
[epoch 24] step 16/44: loss=-0.2301 
[epoch 24] step 18/44: loss=-0.2284 
[epoch 24] step 20/44: loss=-0.2271 
[epoch 24] step 22/44: loss=-0.2137 
[epoch 24] step 24/44: loss=-0.2079 
[epoch 24] step 26/44: loss=-0.2117 
[epoch 24] step 28/44: loss=-0.2056 
[epoch 24] step 30/44: loss=-0.1993 
[epoch 24] step 32/44: loss=-0.2006 
[epoch 24] step 34/44: loss=-0.2030 
[epoch 24] step 36/44: loss=-0.1983 
[epoch 24] step 38/44: loss=-0.1993 
[epoch 24] step 40/44: loss=-0.2004 
[epoch 24] step 42/44: loss=-0.1981 
[epoch 24] step 44/44: loss=-0.1916 
[epoch 24] train_loss(avg per step)=-0.3832 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=6.3886 qwk=('0.6631', '0.6255', '0.6172') averageQWK=0.6353 macroEMD=0.2390 tailR0=('0.2512', '0.1389', '0.1000') tailR0avg=0.1634
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     1   28   24    1    1
     0   16   85   22    2
     0    0   31   78    7
     0    0    3   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    0    0
     0   19   30    3    0
     0    9   88   24    0
     0    0   32  102    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    3    0    0
     1   23   45    0    0
     0   12  116   23    0
     0    0   30   71    0
     0    0    0    2    0
[epoch 25] step 2/44: loss=-0.2592 
[epoch 25] step 4/44: loss=-0.2365 
[epoch 25] step 6/44: loss=-0.2350 
[epoch 25] step 8/44: loss=-0.2197 
[epoch 25] step 10/44: loss=-0.2210 
[epoch 25] step 12/44: loss=-0.2233 
[epoch 25] step 14/44: loss=-0.2334 
[epoch 25] step 16/44: loss=-0.2345 
[epoch 25] step 18/44: loss=-0.2273 
[epoch 25] step 20/44: loss=-0.2233 
[epoch 25] step 22/44: loss=-0.2201 
[epoch 25] step 24/44: loss=-0.2190 
[epoch 25] step 26/44: loss=-0.2185 
[epoch 25] step 28/44: loss=-0.2208 
[epoch 25] step 30/44: loss=-0.2245 
[epoch 25] step 32/44: loss=-0.2207 
[epoch 25] step 34/44: loss=-0.2193 
[epoch 25] step 36/44: loss=-0.2219 
[epoch 25] step 38/44: loss=-0.2227 
[epoch 25] step 40/44: loss=-0.2181 
[epoch 25] step 42/44: loss=-0.2196 
[epoch 25] step 44/44: loss=-0.2208 
[epoch 25] train_loss(avg per step)=-0.4416 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=6.4669 qwk=('0.6350', '0.6192', '0.5865') averageQWK=0.6136 macroEMD=0.2403 tailR0=('0.1957', '0.1389', '0.1000') tailR0avg=0.1448
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   26   26    2    1
     1   13   79   27    5
     0    0   18   89    9
     0    0    3   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   22   26    3    1
     1   13   68   37    2
     0    1   18  112    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    3    0    0
     4   15   48    2    0
     1    6  116   28    0
     0    0   27   74    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=-0.2902 
[epoch 26] step 4/44: loss=-0.2697 
[epoch 26] step 6/44: loss=-0.2650 
[epoch 26] step 8/44: loss=-0.2435 
[epoch 26] step 10/44: loss=-0.2465 
[epoch 26] step 12/44: loss=-0.2462 
[epoch 26] step 14/44: loss=-0.2491 
[epoch 26] step 16/44: loss=-0.2507 
[epoch 26] step 18/44: loss=-0.2476 
[epoch 26] step 20/44: loss=-0.2481 
[epoch 26] step 22/44: loss=-0.2471 
[epoch 26] step 24/44: loss=-0.2388 
[epoch 26] step 26/44: loss=-0.2422 
[epoch 26] step 28/44: loss=-0.2452 
[epoch 26] step 30/44: loss=-0.2485 
[epoch 26] step 32/44: loss=-0.2413 
[epoch 26] step 34/44: loss=-0.2453 
[epoch 26] step 36/44: loss=-0.2484 
[epoch 26] step 38/44: loss=-0.2484 
[epoch 26] step 40/44: loss=-0.2474 
[epoch 26] step 42/44: loss=-0.2477 
[epoch 26] step 44/44: loss=-0.2482 
[epoch 26] train_loss(avg per step)=-0.4964 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=6.6446 qwk=('0.6013', '0.6242', '0.5915') averageQWK=0.6057 macroEMD=0.2387 tailR0=('0.2729', '0.1389', '0.1000') tailR0avg=0.1706
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    1    1
     0   19   33    2    1
     2   10   83   25    5
     0    0   18   90    8
     0    0    3   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    1    0
     0   24   24    3    1
     0   18   66   36    1
     0    0   21  111    2
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   19   49    0    0
     0    8  124   19    0
     0    0   38   63    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=-0.2622 
[epoch 27] step 4/44: loss=-0.2616 
[epoch 27] step 6/44: loss=-0.2715 
[epoch 27] step 8/44: loss=-0.2772 
[epoch 27] step 10/44: loss=-0.2743 
[epoch 27] step 12/44: loss=-0.2764 
[epoch 27] step 14/44: loss=-0.2741 
[epoch 27] step 16/44: loss=-0.2731 
[epoch 27] step 18/44: loss=-0.2664 
[epoch 27] step 20/44: loss=-0.2673 
[epoch 27] step 22/44: loss=-0.2685 
[epoch 27] step 24/44: loss=-0.2660 
[epoch 27] step 26/44: loss=-0.2684 
[epoch 27] step 28/44: loss=-0.2697 
[epoch 27] step 30/44: loss=-0.2706 
[epoch 27] step 32/44: loss=-0.2624 
[epoch 27] step 34/44: loss=-0.2580 
[epoch 27] step 36/44: loss=-0.2565 
[epoch 27] step 38/44: loss=-0.2590 
[epoch 27] step 40/44: loss=-0.2589 
[epoch 27] step 42/44: loss=-0.2561 
[epoch 27] step 44/44: loss=-0.2540 
[epoch 27] train_loss(avg per step)=-0.5080 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=6.9954 qwk=('0.6038', '0.6093', '0.6169') averageQWK=0.6100 macroEMD=0.2401 tailR0=('0.3188', '0.1389', '0.1000') tailR0avg=0.1859
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    1    4    0    1
     7    8   37    3    0
     2    5   84   30    4
     0    0   18   92    6
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     0   21   25    5    1
     0    9   78   32    2
     0    1   19  110    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   27   39    2    0
     0   18   97   36    0
     0    1   21   77    2
     0    0    0    2    0
[epoch 28] step 2/44: loss=-0.2216 
[epoch 28] step 4/44: loss=-0.2462 
[epoch 28] step 6/44: loss=-0.2639 
[epoch 28] step 8/44: loss=-0.2655 
[epoch 28] step 10/44: loss=-0.2596 
[epoch 28] step 12/44: loss=-0.2640 
[epoch 28] step 14/44: loss=-0.2676 
[epoch 28] step 16/44: loss=-0.2741 
[epoch 28] step 18/44: loss=-0.2708 
[epoch 28] step 20/44: loss=-0.2724 
[epoch 28] step 22/44: loss=-0.2757 
[epoch 28] step 24/44: loss=-0.2766 
[epoch 28] step 26/44: loss=-0.2793 
[epoch 28] step 28/44: loss=-0.2796 
[epoch 28] step 30/44: loss=-0.2821 
[epoch 28] step 32/44: loss=-0.2834 
[epoch 28] step 34/44: loss=-0.2813 
[epoch 28] step 36/44: loss=-0.2836 
[epoch 28] step 38/44: loss=-0.2816 
[epoch 28] step 40/44: loss=-0.2838 
[epoch 28] step 42/44: loss=-0.2817 
[epoch 28] step 44/44: loss=-0.2835 
[epoch 28] train_loss(avg per step)=-0.5669 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=6.7136 qwk=('0.6684', '0.6508', '0.6013') averageQWK=0.6401 macroEMD=0.2303 tailR0=('0.1522', '0.1389', '0.1000') tailR0avg=0.1304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   29   24    2    0
     1   12   81   29    2
     0    0   19   90    7
     0    0    4   12    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   21   28    2    0
     0   13   86   21    1
     0    0   34   98    2
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     1   23   44    1    0
     0   16  111   24    0
     0    0   35   66    0
     0    0    0    2    0
[epoch 29] step 2/44: loss=-0.2815 
[epoch 29] step 4/44: loss=-0.2966 
[epoch 29] step 6/44: loss=-0.2961 
[epoch 29] step 8/44: loss=-0.2976 
[epoch 29] step 10/44: loss=-0.2916 
[epoch 29] step 12/44: loss=-0.2958 
[epoch 29] step 14/44: loss=-0.2974 
[epoch 29] step 16/44: loss=-0.2966 
[epoch 29] step 18/44: loss=-0.2945 
[epoch 29] step 20/44: loss=-0.2982 
[epoch 29] step 22/44: loss=-0.2978 
[epoch 29] step 24/44: loss=-0.2989 
[epoch 29] step 26/44: loss=-0.2985 
[epoch 29] step 28/44: loss=-0.2990 
[epoch 29] step 30/44: loss=-0.2965 
[epoch 29] step 32/44: loss=-0.2947 
[epoch 29] step 34/44: loss=-0.2965 
[epoch 29] step 36/44: loss=-0.2959 
[epoch 29] step 38/44: loss=-0.2927 
[epoch 29] step 40/44: loss=-0.2922 
[epoch 29] step 42/44: loss=-0.2926 
[epoch 29] step 44/44: loss=-0.2923 
[epoch 29] train_loss(avg per step)=-0.5847 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=6.6808 qwk=('0.6522', '0.6298', '0.6314') averageQWK=0.6378 macroEMD=0.2314 tailR0=('0.3623', '0.1389', '0.1000') tailR0avg=0.2004
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    4    0    0
     3   23   26    2    1
     2   11   85   22    5
     0    1   20   82   13
     0    0    3   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     0   28   21    1    2
     1   16   85   18    1
     0    3   30   98    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     2   22   44    1    0
     0   11  111   29    0
     0    0   27   74    0
     0    0    0    2    0
[epoch 30] step 2/44: loss=-0.2829 
[epoch 30] step 4/44: loss=-0.2839 
[epoch 30] step 6/44: loss=-0.2979 
[epoch 30] step 8/44: loss=-0.2977 
[epoch 30] step 10/44: loss=-0.2927 
[epoch 30] step 12/44: loss=-0.2923 
[epoch 30] step 14/44: loss=-0.2916 
[epoch 30] step 16/44: loss=-0.2972 
[epoch 30] step 18/44: loss=-0.3013 
[epoch 30] step 20/44: loss=-0.2997 
[epoch 30] step 22/44: loss=-0.2982 
[epoch 30] step 24/44: loss=-0.2964 
[epoch 30] step 26/44: loss=-0.2984 
[epoch 30] step 28/44: loss=-0.2995 
[epoch 30] step 30/44: loss=-0.2966 
[epoch 30] step 32/44: loss=-0.2983 
[epoch 30] step 34/44: loss=-0.2972 
[epoch 30] step 36/44: loss=-0.2986 
[epoch 30] step 38/44: loss=-0.2992 
[epoch 30] step 40/44: loss=-0.3002 
[epoch 30] step 42/44: loss=-0.2993 
[epoch 30] step 44/44: loss=-0.3008 
[epoch 30] train_loss(avg per step)=-0.6016 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=7.1017 qwk=('0.6164', '0.6177', '0.6050') averageQWK=0.6130 macroEMD=0.2375 tailR0=('0.3068', '0.1389', '0.1000') tailR0avg=0.1819
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
     1   16   35    1    2
     0    6   93   21    5
     0    0   24   82   10
     0    0    3   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    0    0
     0   18   31    3    0
     0   12   80   27    2
     0    0   25  105    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     2   20   46    1    0
     0   11  111   29    0
     0    0   29   72    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=-0.3269 
[epoch 31] step 4/44: loss=-0.3226 
[epoch 31] step 6/44: loss=-0.3213 
[epoch 31] step 8/44: loss=-0.3206 
[epoch 31] step 10/44: loss=-0.3234 
[epoch 31] step 12/44: loss=-0.3228 
[epoch 31] step 14/44: loss=-0.3221 
[epoch 31] step 16/44: loss=-0.3187 
[epoch 31] step 18/44: loss=-0.3178 
[epoch 31] step 20/44: loss=-0.3162 
[epoch 31] step 22/44: loss=-0.3174 
[epoch 31] step 24/44: loss=-0.3192 
[epoch 31] step 26/44: loss=-0.3204 
[epoch 31] step 28/44: loss=-0.3190 
[epoch 31] step 30/44: loss=-0.3191 
[epoch 31] step 32/44: loss=-0.3167 
[epoch 31] step 34/44: loss=-0.3166 
[epoch 31] step 36/44: loss=-0.3158 
[epoch 31] step 38/44: loss=-0.3170 
[epoch 31] step 40/44: loss=-0.3163 
[epoch 31] step 42/44: loss=-0.3162 
[epoch 31] step 44/44: loss=-0.3169 
[epoch 31] train_loss(avg per step)=-0.6338 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=7.4897 qwk=('0.6156', '0.6128', '0.6131') averageQWK=0.6138 macroEMD=0.2345 tailR0=('0.2512', '0.1389', '0.1000') tailR0avg=0.1634
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   19   32    1    2
     0    8   91   21    5
     0    0   23   83   10
     0    0    4   10    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    0    0
     1   21   24    6    0
     0   15   67   38    1
     0    2   13  116    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   24   44    1    0
     0   13  113   25    0
     0    0   30   71    0
     0    0    0    2    0
[epoch 32] step 2/44: loss=-0.3157 
[epoch 32] step 4/44: loss=-0.3200 
[epoch 32] step 6/44: loss=-0.3212 
[epoch 32] step 8/44: loss=-0.3156 
[epoch 32] step 10/44: loss=-0.3126 
[epoch 32] step 12/44: loss=-0.3103 
[epoch 32] step 14/44: loss=-0.3129 
[epoch 32] step 16/44: loss=-0.3105 
[epoch 32] step 18/44: loss=-0.3135 
[epoch 32] step 20/44: loss=-0.3130 
[epoch 32] step 22/44: loss=-0.3146 
[epoch 32] step 24/44: loss=-0.3149 
[epoch 32] step 26/44: loss=-0.3139 
[epoch 32] step 28/44: loss=-0.3117 
[epoch 32] step 30/44: loss=-0.3102 
[epoch 32] step 32/44: loss=-0.3089 
[epoch 32] step 34/44: loss=-0.3100 
[epoch 32] step 36/44: loss=-0.3097 
[epoch 32] step 38/44: loss=-0.3110 
[epoch 32] step 40/44: loss=-0.3113 
[epoch 32] step 42/44: loss=-0.3124 
[epoch 32] step 44/44: loss=-0.3136 
[epoch 32] train_loss(avg per step)=-0.6272 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=7.3530 qwk=('0.6174', '0.6303', '0.6126') averageQWK=0.6201 macroEMD=0.2335 tailR0=('0.3285', '0.1389', '0.1000') tailR0avg=0.1891
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
     1   18   32    2    2
     1    5   90   24    5
     0    0   22   83   11
     0    0    3   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     1   21   26    3    1
     0   12   77   31    1
     0    0   23  107    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   22   45    1    0
     0   10  115   26    0
     0    0   30   70    1
     0    0    0    2    0
[epoch 33] step 2/44: loss=-0.3334 
[epoch 33] step 4/44: loss=-0.3206 
[epoch 33] step 6/44: loss=-0.3223 
[epoch 33] step 8/44: loss=-0.3155 
[epoch 33] step 10/44: loss=-0.3128 
[epoch 33] step 12/44: loss=-0.3131 
[epoch 33] step 14/44: loss=-0.3133 
[epoch 33] step 16/44: loss=-0.3130 
[epoch 33] step 18/44: loss=-0.3156 
[epoch 33] step 20/44: loss=-0.3169 
[epoch 33] step 22/44: loss=-0.3157 
[epoch 33] step 24/44: loss=-0.3166 
[epoch 33] step 26/44: loss=-0.3180 
[epoch 33] step 28/44: loss=-0.3177 
[epoch 33] step 30/44: loss=-0.3181 
[epoch 33] step 32/44: loss=-0.3190 
[epoch 33] step 34/44: loss=-0.3190 
[epoch 33] step 36/44: loss=-0.3203 
[epoch 33] step 38/44: loss=-0.3197 
[epoch 33] step 40/44: loss=-0.3189 
[epoch 33] step 42/44: loss=-0.3186 
[epoch 33] step 44/44: loss=-0.3193 
[epoch 33] train_loss(avg per step)=-0.6385 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=7.2350 qwk=('0.6326', '0.6379', '0.6307') averageQWK=0.6338 macroEMD=0.2293 tailR0=('0.2295', '0.1389', '0.1000') tailR0avg=0.1561
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     1   23   27    2    2
     0   11   83   26    5
     0    0   17   90    9
     0    0    2   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   23   26    3    0
     0   15   78   26    2
     0    2   24  104    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     2   22   44    1    0
     0   10  112   29    0
     0    0   25   76    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=-0.3358 
[epoch 34] step 4/44: loss=-0.3384 
[epoch 34] step 6/44: loss=-0.3338 
[epoch 34] step 8/44: loss=-0.3257 
[epoch 34] step 10/44: loss=-0.3170 
[epoch 34] step 12/44: loss=-0.3174 
[epoch 34] step 14/44: loss=-0.3157 
[epoch 34] step 16/44: loss=-0.3193 
[epoch 34] step 18/44: loss=-0.3214 
[epoch 34] step 20/44: loss=-0.3198 
[epoch 34] step 22/44: loss=-0.3212 
[epoch 34] step 24/44: loss=-0.3230 
[epoch 34] step 26/44: loss=-0.3245 
[epoch 34] step 28/44: loss=-0.3254 
[epoch 34] step 30/44: loss=-0.3264 
[epoch 34] step 32/44: loss=-0.3267 
[epoch 34] step 34/44: loss=-0.3252 
[epoch 34] step 36/44: loss=-0.3257 
[epoch 34] step 38/44: loss=-0.3259 
[epoch 34] step 40/44: loss=-0.3252 
[epoch 34] step 42/44: loss=-0.3259 
[epoch 34] step 44/44: loss=-0.3250 
[epoch 34] train_loss(avg per step)=-0.6500 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=7.0832 qwk=('0.6254', '0.6347', '0.6110') averageQWK=0.6237 macroEMD=0.2279 tailR0=('0.2850', '0.1389', '0.1000') tailR0avg=0.1746
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
     2   21   29    1    2
     1   12   86   21    5
     0    0   23   82   11
     0    0    3   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     0   22   27    3    0
     1   14   79   26    1
     0    1   25  105    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     2   25   41    1    0
     0   17  112   22    0
     0    0   34   67    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=-0.3263 
[epoch 35] step 4/44: loss=-0.3294 
[epoch 35] step 6/44: loss=-0.3323 
[epoch 35] step 8/44: loss=-0.3293 
[epoch 35] step 10/44: loss=-0.3271 
[epoch 35] step 12/44: loss=-0.3284 
[epoch 35] step 14/44: loss=-0.3265 
[epoch 35] step 16/44: loss=-0.3268 
[epoch 35] step 18/44: loss=-0.3273 
[epoch 35] step 20/44: loss=-0.3287 
[epoch 35] step 22/44: loss=-0.3294 
[epoch 35] step 24/44: loss=-0.3298 
[epoch 35] step 26/44: loss=-0.3297 
[epoch 35] step 28/44: loss=-0.3299 
[epoch 35] step 30/44: loss=-0.3310 
[epoch 35] step 32/44: loss=-0.3305 
[epoch 35] step 34/44: loss=-0.3302 
[epoch 35] step 36/44: loss=-0.3291 
[epoch 35] step 38/44: loss=-0.3295 
[epoch 35] step 40/44: loss=-0.3287 
[epoch 35] step 42/44: loss=-0.3290 
[epoch 35] step 44/44: loss=-0.3283 
[epoch 35] train_loss(avg per step)=-0.6565 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=7.0189 qwk=('0.6365', '0.6357', '0.6218') averageQWK=0.6313 macroEMD=0.2260 tailR0=('0.2850', '0.1389', '0.1000') tailR0avg=0.1746
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     1   26   24    2    2
     1   13   84   22    5
     0    0   23   84    9
     0    0    3   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     0   23   26    3    0
     1   14   79   26    1
     0    1   26  104    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     2   28   38    1    0
     0   17  113   21    0
     0    0   35   66    0
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-0-reassignment-0/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-0-reassignment-0/fold0/metrics.json
Done.
