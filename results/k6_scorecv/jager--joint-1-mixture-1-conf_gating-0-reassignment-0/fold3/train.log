[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=7.4959 
[epoch 1] step 4/44: loss=7.6159 
[epoch 1] step 6/44: loss=7.5460 
[epoch 1] step 8/44: loss=7.4098 
[epoch 1] step 10/44: loss=7.2338 
[epoch 1] step 12/44: loss=7.1576 
[epoch 1] step 14/44: loss=7.1826 
[epoch 1] step 16/44: loss=7.1627 
[epoch 1] step 18/44: loss=7.1437 
[epoch 1] step 20/44: loss=7.0838 
[epoch 1] step 22/44: loss=7.0882 
[epoch 1] step 24/44: loss=7.1096 
[epoch 1] step 26/44: loss=7.0976 
[epoch 1] step 28/44: loss=7.0594 
[epoch 1] step 30/44: loss=7.0535 
[epoch 1] step 32/44: loss=7.0648 
[epoch 1] step 34/44: loss=7.0520 
[epoch 1] step 36/44: loss=7.0282 
[epoch 1] step 38/44: loss=6.9866 
[epoch 1] step 40/44: loss=6.9412 
[epoch 1] step 42/44: loss=6.8875 
[epoch 1] step 44/44: loss=6.8102 
[epoch 1] train_loss(avg per step)=13.6203 lambda[min,max]=[0.525900,1.000000]
[epoch 1] val_loss=8.3634 qwk=('0.0296', '0.0692', '0.1304') averageQWK=0.0764 macroEMD=0.3891 tailR0=('0.0000', '0.1000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   47    0    8    0
     0   98    0   28    0
     0   90    0   26    0
     0   18    1    3    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    8    0    0
    16    0   37    0    0
    42    0   74    3    0
    33    0   95    6    0
     0    0   12    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0   12   57    0    0
     0   10  138    3    0
     0    3   96    1    2
     0    0    1    0    0
[epoch 2] step 2/44: loss=5.1875 
[epoch 2] step 4/44: loss=5.1437 
[epoch 2] step 6/44: loss=5.0532 
[epoch 2] step 8/44: loss=4.9364 
[epoch 2] step 10/44: loss=4.8837 
[epoch 2] step 12/44: loss=4.8528 
[epoch 2] step 14/44: loss=4.8510 
[epoch 2] step 16/44: loss=4.7352 
[epoch 2] step 18/44: loss=4.6384 
[epoch 2] step 20/44: loss=4.5543 
[epoch 2] step 22/44: loss=4.4399 
[epoch 2] step 24/44: loss=4.3216 
[epoch 2] step 26/44: loss=4.2190 
[epoch 2] step 28/44: loss=4.1326 
[epoch 2] step 30/44: loss=4.0704 
[epoch 2] step 32/44: loss=4.0093 
[epoch 2] step 34/44: loss=3.9704 
[epoch 2] step 36/44: loss=3.9398 
[epoch 2] step 38/44: loss=3.9104 
[epoch 2] step 40/44: loss=3.8744 
[epoch 2] step 42/44: loss=3.8309 
[epoch 2] step 44/44: loss=3.7839 
[epoch 2] train_loss(avg per step)=7.5678 lambda[min,max]=[0.508278,1.000000]
[epoch 2] val_loss=4.4414 qwk=('0.4274', '0.2177', '0.3043') averageQWK=0.3165 macroEMD=0.3740 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0    9   35   11    0
     0    7   71   48    0
     0    1   28   87    0
     0    0    6   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    3    0
     0    0   22   31    0
     0    0   20   99    0
     0    0    6  128    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    1   65    3    0
     0    0  118   33    0
     0    0   55   47    0
     0    0    0    1    0
[epoch 3] step 2/44: loss=3.0843 
[epoch 3] step 4/44: loss=2.9671 
[epoch 3] step 6/44: loss=2.9898 
[epoch 3] step 8/44: loss=3.0449 
[epoch 3] step 10/44: loss=3.0893 
[epoch 3] step 12/44: loss=3.0207 
[epoch 3] step 14/44: loss=2.9805 
[epoch 3] step 16/44: loss=2.9825 
[epoch 3] step 18/44: loss=2.9873 
[epoch 3] step 20/44: loss=2.9708 
[epoch 3] step 22/44: loss=2.9487 
[epoch 3] step 24/44: loss=2.9381 
[epoch 3] step 26/44: loss=2.9120 
[epoch 3] step 28/44: loss=2.9017 
[epoch 3] step 30/44: loss=2.8788 
[epoch 3] step 32/44: loss=2.8686 
[epoch 3] step 34/44: loss=2.8437 
[epoch 3] step 36/44: loss=2.8221 
[epoch 3] step 38/44: loss=2.8129 
[epoch 3] step 40/44: loss=2.8004 
[epoch 3] step 42/44: loss=2.7805 
[epoch 3] step 44/44: loss=2.7808 
[epoch 3] train_loss(avg per step)=5.5616 lambda[min,max]=[0.539068,1.000000]
[epoch 3] val_loss=4.0414 qwk=('0.5801', '0.4608', '0.5337') averageQWK=0.5249 macroEMD=0.3519 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   29   21    5    0
     0   40   54   32    0
     0    5   23   88    0
     0    1    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    0   51    2    0
     0    0   97   22    0
     0    0   42   92    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   20   46    3    0
     0    9  103   39    0
     0    0   34   68    0
     0    0    0    1    0
[epoch 4] step 2/44: loss=2.5651 
[epoch 4] step 4/44: loss=2.4879 
[epoch 4] step 6/44: loss=2.4779 
[epoch 4] step 8/44: loss=2.4457 
[epoch 4] step 10/44: loss=2.3998 
[epoch 4] step 12/44: loss=2.4373 
[epoch 4] step 14/44: loss=2.3975 
[epoch 4] step 16/44: loss=2.4102 
[epoch 4] step 18/44: loss=2.3974 
[epoch 4] step 20/44: loss=2.4036 
[epoch 4] step 22/44: loss=2.3810 
[epoch 4] step 24/44: loss=2.3738 
[epoch 4] step 26/44: loss=2.3621 
[epoch 4] step 28/44: loss=2.3791 
[epoch 4] step 30/44: loss=2.3576 
[epoch 4] step 32/44: loss=2.3696 
[epoch 4] step 34/44: loss=2.3515 
[epoch 4] step 36/44: loss=2.3605 
[epoch 4] step 38/44: loss=2.3594 
[epoch 4] step 40/44: loss=2.3681 
[epoch 4] step 42/44: loss=2.3752 
[epoch 4] step 44/44: loss=2.3555 
[epoch 4] train_loss(avg per step)=4.7110 lambda[min,max]=[0.525172,1.000000]
[epoch 4] val_loss=3.9439 qwk=('0.5969', '0.4591', '0.5325') averageQWK=0.5295 macroEMD=0.3490 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   34   18    3    0
     0   40   63   23    0
     0    4   31   81    0
     0    1    2   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    4   48    1    0
     0    1  104   14    0
     0    0   58   76    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   30   38    1    0
     0   24  107   20    0
     0    5   41   56    0
     0    0    0    1    0
[epoch 5] step 2/44: loss=2.1123 
[epoch 5] step 4/44: loss=2.1829 
[epoch 5] step 6/44: loss=2.1585 
[epoch 5] step 8/44: loss=2.1256 
[epoch 5] step 10/44: loss=2.1470 
[epoch 5] step 12/44: loss=2.1304 
[epoch 5] step 14/44: loss=2.1362 
[epoch 5] step 16/44: loss=2.1314 
[epoch 5] step 18/44: loss=2.1525 
[epoch 5] step 20/44: loss=2.1320 
[epoch 5] step 22/44: loss=2.1288 
[epoch 5] step 24/44: loss=2.1358 
[epoch 5] step 26/44: loss=2.1164 
[epoch 5] step 28/44: loss=2.1275 
[epoch 5] step 30/44: loss=2.1072 
[epoch 5] step 32/44: loss=2.1080 
[epoch 5] step 34/44: loss=2.1012 
[epoch 5] step 36/44: loss=2.0972 
[epoch 5] step 38/44: loss=2.1067 
[epoch 5] step 40/44: loss=2.1038 
[epoch 5] step 42/44: loss=2.0815 
[epoch 5] step 44/44: loss=2.0739 
[epoch 5] train_loss(avg per step)=4.1479 lambda[min,max]=[0.502498,1.000000]
[epoch 5] val_loss=4.4186 qwk=('0.6059', '0.5422', '0.3028') averageQWK=0.4837 macroEMD=0.3342 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   33   17    5    0
     0   43   63   20    0
     0    3   31   82    0
     0    1    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   21   32    0    0
     0   16   92   11    0
     0    4   66   64    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   22   47    0    0
     0   10  141    0    0
     0    2   91    9    0
     0    0    1    0    0
[epoch 6] step 2/44: loss=2.3723 
[epoch 6] step 4/44: loss=2.2896 
[epoch 6] step 6/44: loss=2.3059 
[epoch 6] step 8/44: loss=2.1402 
[epoch 6] step 10/44: loss=2.1896 
[epoch 6] step 12/44: loss=2.1552 
[epoch 6] step 14/44: loss=2.1216 
[epoch 6] step 16/44: loss=2.1330 
[epoch 6] step 18/44: loss=2.1202 
[epoch 6] step 20/44: loss=2.1142 
[epoch 6] step 22/44: loss=2.0969 
[epoch 6] step 24/44: loss=2.0782 
[epoch 6] step 26/44: loss=2.0506 
[epoch 6] step 28/44: loss=2.0522 
[epoch 6] step 30/44: loss=2.0584 
[epoch 6] step 32/44: loss=2.0568 
[epoch 6] step 34/44: loss=2.0450 
[epoch 6] step 36/44: loss=2.0470 
[epoch 6] step 38/44: loss=2.0438 
[epoch 6] step 40/44: loss=2.0427 
[epoch 6] step 42/44: loss=2.0430 
[epoch 6] step 44/44: loss=2.0341 
[epoch 6] train_loss(avg per step)=4.0682 lambda[min,max]=[0.505140,1.000000]
[epoch 6] val_loss=4.0720 qwk=('0.4997', '0.4671', '0.5349') averageQWK=0.5005 macroEMD=0.3282 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   11   29   15    0
     0    4   59   63    0
     0    0    8  108    0
     0    0    0   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    2    0
     0   10   25   18    0
     0    1   53   65    0
     0    0    7  127    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   29   31    9    0
     0   14   75   62    0
     0    3   15   84    0
     0    0    0    1    0
[epoch 7] step 2/44: loss=1.9828 
[epoch 7] step 4/44: loss=1.9699 
[epoch 7] step 6/44: loss=1.9601 
[epoch 7] step 8/44: loss=1.9440 
[epoch 7] step 10/44: loss=1.9699 
[epoch 7] step 12/44: loss=1.9512 
[epoch 7] step 14/44: loss=1.9185 
[epoch 7] step 16/44: loss=1.8944 
[epoch 7] step 18/44: loss=1.8777 
[epoch 7] step 20/44: loss=1.8697 
[epoch 7] step 22/44: loss=1.8584 
[epoch 7] step 24/44: loss=1.8737 
[epoch 7] step 26/44: loss=1.8722 
[epoch 7] step 28/44: loss=1.8666 
[epoch 7] step 30/44: loss=1.8744 
[epoch 7] step 32/44: loss=1.8727 
[epoch 7] step 34/44: loss=1.8740 
[epoch 7] step 36/44: loss=1.8744 
[epoch 7] step 38/44: loss=1.8786 
[epoch 7] step 40/44: loss=1.8749 
[epoch 7] step 42/44: loss=1.8693 
[epoch 7] step 44/44: loss=1.8587 
[epoch 7] train_loss(avg per step)=3.7174 lambda[min,max]=[0.507553,1.000000]
[epoch 7] val_loss=3.7556 qwk=('0.6286', '0.6061', '0.6093') averageQWK=0.6147 macroEMD=0.3166 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   18   31    6    0
     0    7   96   23    0
     0    0   27   89    0
     0    0    1   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   29   13   11    0
     0   23   47   49    0
     0    4    6  124    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   42   25    2    0
     0   33   95   23    0
     0    4   28   70    0
     0    0    1    0    0
[epoch 8] step 2/44: loss=1.5758 
[epoch 8] step 4/44: loss=1.6327 
[epoch 8] step 6/44: loss=1.5690 
[epoch 8] step 8/44: loss=1.6286 
[epoch 8] step 10/44: loss=1.6390 
[epoch 8] step 12/44: loss=1.6790 
[epoch 8] step 14/44: loss=1.7057 
[epoch 8] step 16/44: loss=1.6977 
[epoch 8] step 18/44: loss=1.7054 
[epoch 8] step 20/44: loss=1.6969 
[epoch 8] step 22/44: loss=1.6988 
[epoch 8] step 24/44: loss=1.7080 
[epoch 8] step 26/44: loss=1.7055 
[epoch 8] step 28/44: loss=1.7092 
[epoch 8] step 30/44: loss=1.7013 
[epoch 8] step 32/44: loss=1.6965 
[epoch 8] step 34/44: loss=1.6900 
[epoch 8] step 36/44: loss=1.6745 
[epoch 8] step 38/44: loss=1.6741 
[epoch 8] step 40/44: loss=1.6791 
[epoch 8] step 42/44: loss=1.6744 
[epoch 8] step 44/44: loss=1.6802 
[epoch 8] train_loss(avg per step)=3.3605 lambda[min,max]=[0.500751,1.000000]
[epoch 8] val_loss=4.2863 qwk=('0.5845', '0.6104', '0.5705') averageQWK=0.5885 macroEMD=0.3124 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   35   19    1    0
     0   33   82   11    0
     0    3   58   55    0
     0    0    6   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    1    0    0
     0   38   13    2    0
     0   35   72   12    0
     0   12   39   83    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   55   13    1    0
     0   70   66   15    0
     0    8   36   58    0
     0    0    1    0    0
[epoch 9] step 2/44: loss=1.9638 
[epoch 9] step 4/44: loss=2.0067 
[epoch 9] step 6/44: loss=1.8744 
[epoch 9] step 8/44: loss=1.8657 
[epoch 9] step 10/44: loss=1.8390 
[epoch 9] step 12/44: loss=1.7668 
[epoch 9] step 14/44: loss=1.7325 
[epoch 9] step 16/44: loss=1.7031 
[epoch 9] step 18/44: loss=1.6839 
[epoch 9] step 20/44: loss=1.6812 
[epoch 9] step 22/44: loss=1.6802 
[epoch 9] step 24/44: loss=1.6622 
[epoch 9] step 26/44: loss=1.6593 
[epoch 9] step 28/44: loss=1.6508 
[epoch 9] step 30/44: loss=1.6363 
[epoch 9] step 32/44: loss=1.6397 
[epoch 9] step 34/44: loss=1.6211 
[epoch 9] step 36/44: loss=1.6123 
[epoch 9] step 38/44: loss=1.6096 
[epoch 9] step 40/44: loss=1.6046 
[epoch 9] step 42/44: loss=1.6059 
[epoch 9] step 44/44: loss=1.6082 
[epoch 9] train_loss(avg per step)=3.2164 lambda[min,max]=[0.500044,1.000000]
[epoch 9] val_loss=4.4519 qwk=('0.5052', '0.5596', '0.5011') averageQWK=0.5220 macroEMD=0.2943 tailR0=('0.0000', '0.0500', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   11   32   12    0
     0    4   65   57    0
     0    0   17   99    0
     0    0    1   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    2    0
     0   13   27   13    0
     0    4   64   51    0
     0    0    8  126    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   16   43   10    0
     0    7   78   66    0
     0    0   14   88    0
     0    0    0    1    0
[epoch 10] step 2/44: loss=1.5226 
[epoch 10] step 4/44: loss=1.5643 
[epoch 10] step 6/44: loss=1.5979 
[epoch 10] step 8/44: loss=1.5957 
[epoch 10] step 10/44: loss=1.5509 
[epoch 10] step 12/44: loss=1.5493 
[epoch 10] step 14/44: loss=1.5486 
[epoch 10] step 16/44: loss=1.5479 
[epoch 10] step 18/44: loss=1.5423 
[epoch 10] step 20/44: loss=1.5364 
[epoch 10] step 22/44: loss=1.5157 
[epoch 10] step 24/44: loss=1.5219 
[epoch 10] step 26/44: loss=1.4988 
[epoch 10] step 28/44: loss=1.4852 
[epoch 10] step 30/44: loss=1.4795 
[epoch 10] step 32/44: loss=1.4716 
[epoch 10] step 34/44: loss=1.4657 
[epoch 10] step 36/44: loss=1.4460 
[epoch 10] step 38/44: loss=1.4351 
[epoch 10] step 40/44: loss=1.4310 
[epoch 10] step 42/44: loss=1.4253 
[epoch 10] step 44/44: loss=1.4232 
[epoch 10] train_loss(avg per step)=2.8463 lambda[min,max]=[0.500066,1.000000]
[epoch 10] val_loss=4.1480 qwk=('0.6155', '0.6071', '0.5345') averageQWK=0.5857 macroEMD=0.2886 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   17   32    6    0
     0    4   90   32    0
     0    0   25   91    0
     0    0    1   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    2    0
     0   26   17   10    0
     0   23   53   43    0
     0    3    7  124    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   17   52    0    0
     0    6  127   18    0
     0    1   46   55    0
     0    0    0    1    0
[epoch 11] step 2/44: loss=1.4790 
[epoch 11] step 4/44: loss=1.4253 
[epoch 11] step 6/44: loss=1.2779 
[epoch 11] step 8/44: loss=1.2600 
[epoch 11] step 10/44: loss=1.3011 
[epoch 11] step 12/44: loss=1.2811 
[epoch 11] step 14/44: loss=1.2661 
[epoch 11] step 16/44: loss=1.2469 
[epoch 11] step 18/44: loss=1.2181 
[epoch 11] step 20/44: loss=1.2191 
[epoch 11] step 22/44: loss=1.2200 
[epoch 11] step 24/44: loss=1.2193 
[epoch 11] step 26/44: loss=1.2276 
[epoch 11] step 28/44: loss=1.2355 
[epoch 11] step 30/44: loss=1.2407 
[epoch 11] step 32/44: loss=1.2191 
[epoch 11] step 34/44: loss=1.2189 
[epoch 11] step 36/44: loss=1.2184 
[epoch 11] step 38/44: loss=1.2108 
[epoch 11] step 40/44: loss=1.2163 
[epoch 11] step 42/44: loss=1.2137 
[epoch 11] step 44/44: loss=1.2194 
[epoch 11] train_loss(avg per step)=2.4387 lambda[min,max]=[0.500015,1.000000]
[epoch 11] val_loss=4.2146 qwk=('0.5945', '0.5728', '0.5566') averageQWK=0.5746 macroEMD=0.2836 tailR0=('0.0909', '0.0000', '0.0000') tailR0avg=0.0303
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   12   38    5    0
     0    2   91   31    2
     0    0   25   90    1
     0    0    1   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    2    0
     0   14   30    9    0
     0    6   73   40    0
     0    0   13  121    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   19   49    1    0
     0    8  122   21    0
     0    1   37   64    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=1.1158 
[epoch 12] step 4/44: loss=1.1685 
[epoch 12] step 6/44: loss=1.2087 
[epoch 12] step 8/44: loss=1.1699 
[epoch 12] step 10/44: loss=1.1004 
[epoch 12] step 12/44: loss=1.0854 
[epoch 12] step 14/44: loss=1.0852 
[epoch 12] step 16/44: loss=1.0802 
[epoch 12] step 18/44: loss=1.0842 
[epoch 12] step 20/44: loss=1.0671 
[epoch 12] step 22/44: loss=1.0661 
[epoch 12] step 24/44: loss=1.0575 
[epoch 12] step 26/44: loss=1.0600 
[epoch 12] step 28/44: loss=1.0463 
[epoch 12] step 30/44: loss=1.0592 
[epoch 12] step 32/44: loss=1.0552 
[epoch 12] step 34/44: loss=1.0439 
[epoch 12] step 36/44: loss=1.0418 
[epoch 12] step 38/44: loss=1.0442 
[epoch 12] step 40/44: loss=1.0323 
[epoch 12] step 42/44: loss=1.0281 
[epoch 12] step 44/44: loss=1.0345 
[epoch 12] train_loss(avg per step)=2.0690 lambda[min,max]=[0.500008,1.000000]
[epoch 12] val_loss=4.5521 qwk=('0.6041', '0.6089', '0.5642') averageQWK=0.5924 macroEMD=0.2693 tailR0=('0.0455', '0.0000', '0.0000') tailR0avg=0.0152
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   17   32    6    0
     0    5   83   37    1
     0    0   22   93    1
     0    0    1   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   15   31    7    0
     0    6   79   34    0
     0    0   18  116    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   19   48    2    0
     0    7  101   43    0
     0    0   29   73    0
     0    0    0    1    0
[epoch 13] step 2/44: loss=0.8934 
[epoch 13] step 4/44: loss=0.8901 
[epoch 13] step 6/44: loss=0.8650 
[epoch 13] step 8/44: loss=0.9127 
[epoch 13] step 10/44: loss=0.9263 
[epoch 13] step 12/44: loss=0.9465 
[epoch 13] step 14/44: loss=0.9522 
[epoch 13] step 16/44: loss=0.9332 
[epoch 13] step 18/44: loss=0.9394 
[epoch 13] step 20/44: loss=0.9278 
[epoch 13] step 22/44: loss=0.9073 
[epoch 13] step 24/44: loss=0.9147 
[epoch 13] step 26/44: loss=0.9233 
[epoch 13] step 28/44: loss=0.9256 
[epoch 13] step 30/44: loss=0.9163 
[epoch 13] step 32/44: loss=0.9015 
[epoch 13] step 34/44: loss=0.8813 
[epoch 13] step 36/44: loss=0.8798 
[epoch 13] step 38/44: loss=0.8775 
[epoch 13] step 40/44: loss=0.8732 
[epoch 13] step 42/44: loss=0.8849 
[epoch 13] step 44/44: loss=0.8806 
[epoch 13] train_loss(avg per step)=1.7611 lambda[min,max]=[0.500004,1.000000]
[epoch 13] val_loss=4.3926 qwk=('0.6447', '0.5899', '0.5764') averageQWK=0.6036 macroEMD=0.2725 tailR0=('0.0909', '0.0833', '0.0000') tailR0avg=0.0581
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     3   17   31    4    0
     0   11   92   22    1
     0    0   29   82    5
     0    0    1   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    2    0
     0   20   25    8    0
     0   12   75   31    1
     0    2   23  109    0
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   37   32    0    0
     0   32  100   19    0
     0    3   43   56    0
     0    0    0    1    0
[epoch 14] step 2/44: loss=0.7615 
[epoch 14] step 4/44: loss=0.7927 
[epoch 14] step 6/44: loss=0.7871 
[epoch 14] step 8/44: loss=0.7414 
[epoch 14] step 10/44: loss=0.7786 
[epoch 14] step 12/44: loss=0.8001 
[epoch 14] step 14/44: loss=0.7986 
[epoch 14] step 16/44: loss=0.8193 
[epoch 14] step 18/44: loss=0.8230 
[epoch 14] step 20/44: loss=0.8102 
[epoch 14] step 22/44: loss=0.7972 
[epoch 14] step 24/44: loss=0.7890 
[epoch 14] step 26/44: loss=0.8017 
[epoch 14] step 28/44: loss=0.8157 
[epoch 14] step 30/44: loss=0.8174 
[epoch 14] step 32/44: loss=0.8214 
[epoch 14] step 34/44: loss=0.8124 
[epoch 14] step 36/44: loss=0.8105 
[epoch 14] step 38/44: loss=0.8163 
[epoch 14] step 40/44: loss=0.8065 
[epoch 14] step 42/44: loss=0.8123 
[epoch 14] step 44/44: loss=0.8032 
[epoch 14] train_loss(avg per step)=1.6064 lambda[min,max]=[0.500001,1.000000]
[epoch 14] val_loss=4.6097 qwk=('0.6541', '0.6413', '0.5858') averageQWK=0.6271 macroEMD=0.2625 tailR0=('0.0909', '0.0917', '0.0000') tailR0avg=0.0609
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     4   22   26    3    0
     1   13   87   23    2
     0    1   30   82    3
     0    0    1   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     4   20   24    5    0
     0   19   70   29    1
     0    1   21  112    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   37   27    5    0
     0   32   82   37    0
     0    2   25   75    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=0.7735 
[epoch 15] step 4/44: loss=0.6574 
[epoch 15] step 6/44: loss=0.6306 
[epoch 15] step 8/44: loss=0.5805 
[epoch 15] step 10/44: loss=0.6078 
[epoch 15] step 12/44: loss=0.6159 
[epoch 15] step 14/44: loss=0.6309 
[epoch 15] step 16/44: loss=0.6293 
[epoch 15] step 18/44: loss=0.6219 
[epoch 15] step 20/44: loss=0.6384 
[epoch 15] step 22/44: loss=0.6341 
[epoch 15] step 24/44: loss=0.6422 
[epoch 15] step 26/44: loss=0.6669 
[epoch 15] step 28/44: loss=0.6818 
[epoch 15] step 30/44: loss=0.6828 
[epoch 15] step 32/44: loss=0.6969 
[epoch 15] step 34/44: loss=0.7021 
[epoch 15] step 36/44: loss=0.7024 
[epoch 15] step 38/44: loss=0.6968 
[epoch 15] step 40/44: loss=0.7021 
[epoch 15] step 42/44: loss=0.7044 
[epoch 15] step 44/44: loss=0.6964 
[epoch 15] train_loss(avg per step)=1.3928 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=4.6691 qwk=('0.6447', '0.5987', '0.5854') averageQWK=0.6096 macroEMD=0.2692 tailR0=('0.2702', '0.1833', '0.0000') tailR0avg=0.1512
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     6   11   36    2    0
     0    6  101   15    4
     0    1   32   74    9
     0    0    1   14    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    2    0    0
     3   13   31    6    0
     1   11   81   25    1
     1    2   29   99    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   32    2    0
     0   27   98   26    0
     0    2   36   64    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=0.5752 
[epoch 16] step 4/44: loss=0.5727 
[epoch 16] step 6/44: loss=0.5934 
[epoch 16] step 8/44: loss=0.6120 
[epoch 16] step 10/44: loss=0.5405 
[epoch 16] step 12/44: loss=0.5141 
[epoch 16] step 14/44: loss=0.5305 
[epoch 16] step 16/44: loss=0.5159 
[epoch 16] step 18/44: loss=0.4880 
[epoch 16] step 20/44: loss=0.4712 
[epoch 16] step 22/44: loss=0.4733 
[epoch 16] step 24/44: loss=0.4782 
[epoch 16] step 26/44: loss=0.4629 
[epoch 16] step 28/44: loss=0.4646 
[epoch 16] step 30/44: loss=0.4733 
[epoch 16] step 32/44: loss=0.4714 
[epoch 16] step 34/44: loss=0.4769 
[epoch 16] step 36/44: loss=0.4830 
[epoch 16] step 38/44: loss=0.4900 
[epoch 16] step 40/44: loss=0.4896 
[epoch 16] step 42/44: loss=0.4936 
[epoch 16] step 44/44: loss=0.4877 
[epoch 16] train_loss(avg per step)=0.9753 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=5.2501 qwk=('0.6503', '0.6081', '0.5748') averageQWK=0.6111 macroEMD=0.2575 tailR0=('0.1364', '0.0417', '0.0000') tailR0avg=0.0593
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     3   26   22    4    0
     1   17   85   20    3
     0    2   30   73   11
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   20   29    4    0
     0   18   76   24    1
     0    4   29   98    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   36   29    4    0
     0   28   72   51    0
     0    3   21   78    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=0.5548 
[epoch 17] step 4/44: loss=0.4941 
[epoch 17] step 6/44: loss=0.4721 
[epoch 17] step 8/44: loss=0.4092 
[epoch 17] step 10/44: loss=0.4002 
[epoch 17] step 12/44: loss=0.3775 
[epoch 17] step 14/44: loss=0.3749 
[epoch 17] step 16/44: loss=0.3796 
[epoch 17] step 18/44: loss=0.3813 
[epoch 17] step 20/44: loss=0.3721 
[epoch 17] step 22/44: loss=0.3825 
[epoch 17] step 24/44: loss=0.3736 
[epoch 17] step 26/44: loss=0.3718 
[epoch 17] step 28/44: loss=0.3664 
[epoch 17] step 30/44: loss=0.3659 
[epoch 17] step 32/44: loss=0.3673 
[epoch 17] step 34/44: loss=0.3676 
[epoch 17] step 36/44: loss=0.3645 
[epoch 17] step 38/44: loss=0.3680 
[epoch 17] step 40/44: loss=0.3690 
[epoch 17] step 42/44: loss=0.3656 
[epoch 17] step 44/44: loss=0.3645 
[epoch 17] train_loss(avg per step)=0.7289 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=5.2064 qwk=('0.6623', '0.6089', '0.5786') averageQWK=0.6166 macroEMD=0.2537 tailR0=('0.0682', '0.0417', '0.0000') tailR0avg=0.0366
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     3   27   21    4    0
     0   16   84   24    2
     0    1   28   86    1
     0    0    1   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   18   30    5    0
     0   13   76   29    1
     0    3   25  104    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   34    0    0
     0   27  105   19    0
     0    2   45   55    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=0.0523 
[epoch 18] step 4/44: loss=0.1258 
[epoch 18] step 6/44: loss=0.1641 
[epoch 18] step 8/44: loss=0.2201 
[epoch 18] step 10/44: loss=0.2301 
[epoch 18] step 12/44: loss=0.2633 
[epoch 18] step 14/44: loss=0.2623 
[epoch 18] step 16/44: loss=0.2547 
[epoch 18] step 18/44: loss=0.2568 
[epoch 18] step 20/44: loss=0.2574 
[epoch 18] step 22/44: loss=0.2589 
[epoch 18] step 24/44: loss=0.2478 
[epoch 18] step 26/44: loss=0.2529 
[epoch 18] step 28/44: loss=0.2633 
[epoch 18] step 30/44: loss=0.2650 
[epoch 18] step 32/44: loss=0.2587 
[epoch 18] step 34/44: loss=0.2567 
[epoch 18] step 36/44: loss=0.2597 
[epoch 18] step 38/44: loss=0.2562 
[epoch 18] step 40/44: loss=0.2528 
[epoch 18] step 42/44: loss=0.2523 
[epoch 18] step 44/44: loss=0.2636 
[epoch 18] train_loss(avg per step)=0.5271 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=5.3722 qwk=('0.6498', '0.5833', '0.5632') averageQWK=0.5988 macroEMD=0.2587 tailR0=('0.1364', '0.1917', '0.1000') tailR0avg=0.1427
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     5   14   35    1    0
     1    8   94   20    3
     0    0   32   77    7
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    3    1    0
     5   11   32    5    0
     0   11   81   26    1
     0    3   32   95    4
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     1   22   44    2    0
     0   12  113   26    0
     0    2   36   64    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=0.1447 
[epoch 19] step 4/44: loss=0.1888 
[epoch 19] step 6/44: loss=0.1526 
[epoch 19] step 8/44: loss=0.1313 
[epoch 19] step 10/44: loss=0.1309 
[epoch 19] step 12/44: loss=0.1291 
[epoch 19] step 14/44: loss=0.1293 
[epoch 19] step 16/44: loss=0.1201 
[epoch 19] step 18/44: loss=0.1093 
[epoch 19] step 20/44: loss=0.1177 
[epoch 19] step 22/44: loss=0.1094 
[epoch 19] step 24/44: loss=0.1022 
[epoch 19] step 26/44: loss=0.1055 
[epoch 19] step 28/44: loss=0.1029 
[epoch 19] step 30/44: loss=0.0933 
[epoch 19] step 32/44: loss=0.1000 
[epoch 19] step 34/44: loss=0.1019 
[epoch 19] step 36/44: loss=0.1081 
[epoch 19] step 38/44: loss=0.1149 
[epoch 19] step 40/44: loss=0.1195 
[epoch 19] step 42/44: loss=0.1231 
[epoch 19] step 44/44: loss=0.1204 
[epoch 19] train_loss(avg per step)=0.2408 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=6.1667 qwk=('0.6310', '0.5784', '0.5883') averageQWK=0.5992 macroEMD=0.2489 tailR0=('0.2500', '0.0417', '0.1000') tailR0avg=0.1306
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     4   22   23    5    1
     1   13   83   24    5
     0    2   24   79   11
     0    0    1   10   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    2    0
     2   22   19   10    0
     0   19   58   41    1
     0    4   15  114    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   32   35    2    0
     0   23   95   33    0
     0    3   29   70    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=0.1955 
[epoch 20] step 4/44: loss=0.1139 
[epoch 20] step 6/44: loss=0.1073 
[epoch 20] step 8/44: loss=0.0654 
[epoch 20] step 10/44: loss=0.0761 
[epoch 20] step 12/44: loss=0.0826 
[epoch 20] step 14/44: loss=0.0809 
[epoch 20] step 16/44: loss=0.0793 
[epoch 20] step 18/44: loss=0.0929 
[epoch 20] step 20/44: loss=0.0847 
[epoch 20] step 22/44: loss=0.0790 
[epoch 20] step 24/44: loss=0.0750 
[epoch 20] step 26/44: loss=0.0971 
[epoch 20] step 28/44: loss=0.0918 
[epoch 20] step 30/44: loss=0.0935 
[epoch 20] step 32/44: loss=0.0945 
[epoch 20] step 34/44: loss=0.0947 
[epoch 20] step 36/44: loss=0.1017 
[epoch 20] step 38/44: loss=0.0969 
[epoch 20] step 40/44: loss=0.0965 
[epoch 20] step 42/44: loss=0.0922 
[epoch 20] step 44/44: loss=0.0897 
[epoch 20] train_loss(avg per step)=0.1793 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=6.5715 qwk=('0.5932', '0.5591', '0.5800') averageQWK=0.5774 macroEMD=0.2491 tailR0=('0.1364', '0.0000', '0.1000') tailR0avg=0.0788
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     3   12   36    4    0
     0    4   87   31    4
     0    0   27   81    8
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    2    0
     0   15   29    9    0
     0   11   62   45    1
     0    2   12  119    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     1   27   38    3    0
     0   18   94   39    0
     0    2   27   73    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=-0.0467 
[epoch 21] step 4/44: loss=0.0043 
[epoch 21] step 6/44: loss=0.0287 
[epoch 21] step 8/44: loss=0.0222 
[epoch 21] step 10/44: loss=0.0010 
[epoch 21] step 12/44: loss=0.0145 
[epoch 21] step 14/44: loss=0.0137 
[epoch 21] step 16/44: loss=0.0170 
[epoch 21] step 18/44: loss=0.0071 
[epoch 21] step 20/44: loss=0.0058 
[epoch 21] step 22/44: loss=0.0032 
[epoch 21] step 24/44: loss=0.0034 
[epoch 21] step 26/44: loss=0.0024 
[epoch 21] step 28/44: loss=-0.0066 
[epoch 21] step 30/44: loss=-0.0109 
[epoch 21] step 32/44: loss=-0.0207 
[epoch 21] step 34/44: loss=-0.0187 
[epoch 21] step 36/44: loss=-0.0137 
[epoch 21] step 38/44: loss=-0.0159 
[epoch 21] step 40/44: loss=-0.0126 
[epoch 21] step 42/44: loss=-0.0115 
[epoch 21] step 44/44: loss=-0.0055 
[epoch 21] train_loss(avg per step)=-0.0110 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=6.8250 qwk=('0.5486', '0.5493', '0.5834') averageQWK=0.5604 macroEMD=0.2522 tailR0=('0.0682', '0.0000', '0.0000') tailR0avg=0.0227
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     2   11   38    4    0
     0    4   92   26    4
     0    0   26   86    4
     0    0    1   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    2    0
     0   23   20   10    0
     0   21   61   36    1
     0    8   13  112    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   23   43    3    0
     0   12   97   42    0
     0    1   20   80    1
     0    0    0    1    0
[epoch 22] step 2/44: loss=-0.0298 
[epoch 22] step 4/44: loss=0.0230 
[epoch 22] step 6/44: loss=0.0154 
[epoch 22] step 8/44: loss=-0.0178 
[epoch 22] step 10/44: loss=-0.0236 
[epoch 22] step 12/44: loss=-0.0132 
[epoch 22] step 14/44: loss=-0.0052 
[epoch 22] step 16/44: loss=-0.0153 
[epoch 22] step 18/44: loss=-0.0260 
[epoch 22] step 20/44: loss=-0.0370 
[epoch 22] step 22/44: loss=-0.0561 
[epoch 22] step 24/44: loss=-0.0564 
[epoch 22] step 26/44: loss=-0.0536 
[epoch 22] step 28/44: loss=-0.0567 
[epoch 22] step 30/44: loss=-0.0630 
[epoch 22] step 32/44: loss=-0.0606 
[epoch 22] step 34/44: loss=-0.0450 
[epoch 22] step 36/44: loss=-0.0460 
[epoch 22] step 38/44: loss=-0.0499 
[epoch 22] step 40/44: loss=-0.0499 
[epoch 22] step 42/44: loss=-0.0480 
[epoch 22] step 44/44: loss=-0.0321 
[epoch 22] train_loss(avg per step)=-0.0641 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=6.9602 qwk=('0.6450', '0.5503', '0.5432') averageQWK=0.5795 macroEMD=0.2471 tailR0=('0.2348', '0.0833', '0.1000') tailR0avg=0.1394
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    1    1    0
     5   16   30    4    0
     0    7   92   25    2
     0    0   28   84    4
     0    0    2   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    2    0
     0   23   20   10    0
     0   22   57   39    1
     0    8   14  110    2
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     2   17   46    4    0
     0    9  114   28    0
     0    2   33   67    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=-0.0976 
[epoch 23] step 4/44: loss=-0.1200 
[epoch 23] step 6/44: loss=-0.1143 
[epoch 23] step 8/44: loss=-0.1158 
[epoch 23] step 10/44: loss=-0.1136 
[epoch 23] step 12/44: loss=-0.1274 
[epoch 23] step 14/44: loss=-0.1165 
[epoch 23] step 16/44: loss=-0.1179 
[epoch 23] step 18/44: loss=-0.1186 
[epoch 23] step 20/44: loss=-0.1183 
[epoch 23] step 22/44: loss=-0.1279 
[epoch 23] step 24/44: loss=-0.1312 
[epoch 23] step 26/44: loss=-0.1351 
[epoch 23] step 28/44: loss=-0.1316 
[epoch 23] step 30/44: loss=-0.1285 
[epoch 23] step 32/44: loss=-0.1267 
[epoch 23] step 34/44: loss=-0.1309 
[epoch 23] step 36/44: loss=-0.1335 
[epoch 23] step 38/44: loss=-0.1316 
[epoch 23] step 40/44: loss=-0.1305 
[epoch 23] step 42/44: loss=-0.1303 
[epoch 23] step 44/44: loss=-0.1368 
[epoch 23] train_loss(avg per step)=-0.2736 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=6.9995 qwk=('0.6463', '0.5699', '0.5819') averageQWK=0.5994 macroEMD=0.2459 tailR0=('0.2576', '0.0000', '0.1000') tailR0avg=0.1192
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    2    1    0
     3   20   29    3    0
     0    7   94   22    3
     0    1   30   82    3
     0    0    1   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     3   15   26    9    0
     0    8   78   32    1
     0    3   21  109    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     2   25   42    0    0
     0   17  112   22    0
     0    2   40   60    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=-0.2763 
[epoch 24] step 4/44: loss=-0.2457 
[epoch 24] step 6/44: loss=-0.2216 
[epoch 24] step 8/44: loss=-0.2254 
[epoch 24] step 10/44: loss=-0.2134 
[epoch 24] step 12/44: loss=-0.2217 
[epoch 24] step 14/44: loss=-0.2207 
[epoch 24] step 16/44: loss=-0.2161 
[epoch 24] step 18/44: loss=-0.2174 
[epoch 24] step 20/44: loss=-0.2142 
[epoch 24] step 22/44: loss=-0.2157 
[epoch 24] step 24/44: loss=-0.2103 
[epoch 24] step 26/44: loss=-0.2038 
[epoch 24] step 28/44: loss=-0.2051 
[epoch 24] step 30/44: loss=-0.2037 
[epoch 24] step 32/44: loss=-0.1932 
[epoch 24] step 34/44: loss=-0.1905 
[epoch 24] step 36/44: loss=-0.1887 
[epoch 24] step 38/44: loss=-0.1876 
[epoch 24] step 40/44: loss=-0.1890 
[epoch 24] step 42/44: loss=-0.1888 
[epoch 24] step 44/44: loss=-0.1829 
[epoch 24] train_loss(avg per step)=-0.3657 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=7.3457 qwk=('0.6167', '0.5448', '0.5809') averageQWK=0.5808 macroEMD=0.2426 tailR0=('0.1591', '0.0833', '0.1000') tailR0avg=0.1141
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     3   17   31    4    0
     0    6   94   21    5
     0    0   30   76   10
     0    0    1   14    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    2    0
     3   14   27    9    0
     0   14   69   35    1
     0    6   19  106    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     2   24   42    1    0
     0   15  112   24    0
     0    2   37   63    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=-0.1313 
[epoch 25] step 4/44: loss=-0.1805 
[epoch 25] step 6/44: loss=-0.1757 
[epoch 25] step 8/44: loss=-0.1854 
[epoch 25] step 10/44: loss=-0.1704 
[epoch 25] step 12/44: loss=-0.1863 
[epoch 25] step 14/44: loss=-0.1865 
[epoch 25] step 16/44: loss=-0.1774 
[epoch 25] step 18/44: loss=-0.1761 
[epoch 25] step 20/44: loss=-0.1840 
[epoch 25] step 22/44: loss=-0.1855 
[epoch 25] step 24/44: loss=-0.1909 
[epoch 25] step 26/44: loss=-0.1874 
[epoch 25] step 28/44: loss=-0.1802 
[epoch 25] step 30/44: loss=-0.1792 
[epoch 25] step 32/44: loss=-0.1789 
[epoch 25] step 34/44: loss=-0.1747 
[epoch 25] step 36/44: loss=-0.1771 
[epoch 25] step 38/44: loss=-0.1694 
[epoch 25] step 40/44: loss=-0.1706 
[epoch 25] step 42/44: loss=-0.1707 
[epoch 25] step 44/44: loss=-0.1697 
[epoch 25] train_loss(avg per step)=-0.3395 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=7.3430 qwk=('0.6293', '0.5735', '0.5809') averageQWK=0.5946 macroEMD=0.2359 tailR0=('0.1364', '0.0833', '0.1000') tailR0avg=0.1066
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     4   25   22    4    0
     2   20   74   25    5
     0    3   24   81    8
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     2   18   28    5    0
     0   13   78   27    1
     0    5   35   93    1
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   33   35    1    0
     0   26  101   24    0
     0    2   40   60    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=-0.1883 
[epoch 26] step 4/44: loss=-0.1976 
[epoch 26] step 6/44: loss=-0.2109 
[epoch 26] step 8/44: loss=-0.2321 
[epoch 26] step 10/44: loss=-0.2282 
[epoch 26] step 12/44: loss=-0.2319 
[epoch 26] step 14/44: loss=-0.2267 
[epoch 26] step 16/44: loss=-0.2293 
[epoch 26] step 18/44: loss=-0.2315 
[epoch 26] step 20/44: loss=-0.2264 
[epoch 26] step 22/44: loss=-0.2226 
[epoch 26] step 24/44: loss=-0.2281 
[epoch 26] step 26/44: loss=-0.2324 
[epoch 26] step 28/44: loss=-0.2296 
[epoch 26] step 30/44: loss=-0.2251 
[epoch 26] step 32/44: loss=-0.2235 
[epoch 26] step 34/44: loss=-0.2227 
[epoch 26] step 36/44: loss=-0.2205 
[epoch 26] step 38/44: loss=-0.2153 
[epoch 26] step 40/44: loss=-0.2181 
[epoch 26] step 42/44: loss=-0.2200 
[epoch 26] step 44/44: loss=-0.2176 
[epoch 26] train_loss(avg per step)=-0.4351 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=7.6648 qwk=('0.6449', '0.6007', '0.5051') averageQWK=0.5835 macroEMD=0.2393 tailR0=('0.0682', '0.0833', '0.1000') tailR0avg=0.0838
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     4   23   26    2    0
     1   13   86   22    4
     0    2   27   81    6
     0    0    1   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   24   23    6    0
     0   16   77   25    1
     0    6   28   96    4
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     2   12   51    4    0
     0    9  114   28    0
     0    1   39   62    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=-0.1953 
[epoch 27] step 4/44: loss=-0.1943 
[epoch 27] step 6/44: loss=-0.2053 
[epoch 27] step 8/44: loss=-0.1885 
[epoch 27] step 10/44: loss=-0.1905 
[epoch 27] step 12/44: loss=-0.1866 
[epoch 27] step 14/44: loss=-0.1867 
[epoch 27] step 16/44: loss=-0.1946 
[epoch 27] step 18/44: loss=-0.1904 
[epoch 27] step 20/44: loss=-0.1835 
[epoch 27] step 22/44: loss=-0.1765 
[epoch 27] step 24/44: loss=-0.1830 
[epoch 27] step 26/44: loss=-0.1866 
[epoch 27] step 28/44: loss=-0.1930 
[epoch 27] step 30/44: loss=-0.1906 
[epoch 27] step 32/44: loss=-0.1850 
[epoch 27] step 34/44: loss=-0.1874 
[epoch 27] step 36/44: loss=-0.1861 
[epoch 27] step 38/44: loss=-0.1887 
[epoch 27] step 40/44: loss=-0.1929 
[epoch 27] step 42/44: loss=-0.1917 
[epoch 27] step 44/44: loss=-0.1956 
[epoch 27] train_loss(avg per step)=-0.3913 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=8.3022 qwk=('0.6001', '0.5654', '0.4804') averageQWK=0.5486 macroEMD=0.2411 tailR0=('0.0682', '0.0833', '0.1000') tailR0avg=0.0838
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     4   18   27    6    0
     0    6   73   45    2
     0    0   19   93    4
     0    0    1   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     3   13   31    6    0
     0   12   81   25    1
     0    5   31   94    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     2   11   50    6    0
     0    6  112   33    0
     0    2   36   64    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=-0.1385 
[epoch 28] step 4/44: loss=-0.2156 
[epoch 28] step 6/44: loss=-0.2099 
[epoch 28] step 8/44: loss=-0.2124 
[epoch 28] step 10/44: loss=-0.1998 
[epoch 28] step 12/44: loss=-0.2000 
[epoch 28] step 14/44: loss=-0.1962 
[epoch 28] step 16/44: loss=-0.1985 
[epoch 28] step 18/44: loss=-0.2119 
[epoch 28] step 20/44: loss=-0.2221 
[epoch 28] step 22/44: loss=-0.2224 
[epoch 28] step 24/44: loss=-0.2217 
[epoch 28] step 26/44: loss=-0.2271 
[epoch 28] step 28/44: loss=-0.2313 
[epoch 28] step 30/44: loss=-0.2349 
[epoch 28] step 32/44: loss=-0.2363 
[epoch 28] step 34/44: loss=-0.2306 
[epoch 28] step 36/44: loss=-0.2295 
[epoch 28] step 38/44: loss=-0.2293 
[epoch 28] step 40/44: loss=-0.2290 
[epoch 28] step 42/44: loss=-0.2305 
[epoch 28] step 44/44: loss=-0.2347 
[epoch 28] train_loss(avg per step)=-0.4693 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=8.3251 qwk=('0.6075', '0.5641', '0.5369') averageQWK=0.5695 macroEMD=0.2396 tailR0=('0.0682', '0.0833', '0.1000') tailR0avg=0.0838
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     3   18   29    5    0
     0    5   84   35    2
     0    0   24   87    5
     0    0    1   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    2    0
     3   15   26    9    0
     0   11   72   35    1
     0    5   17  109    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     2   13   51    3    0
     0    6  113   32    0
     0    1   34   67    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=-0.2757 
[epoch 29] step 4/44: loss=-0.2765 
[epoch 29] step 6/44: loss=-0.2782 
[epoch 29] step 8/44: loss=-0.2824 
[epoch 29] step 10/44: loss=-0.2783 
[epoch 29] step 12/44: loss=-0.2849 
[epoch 29] step 14/44: loss=-0.2753 
[epoch 29] step 16/44: loss=-0.2679 
[epoch 29] step 18/44: loss=-0.2730 
[epoch 29] step 20/44: loss=-0.2661 
[epoch 29] step 22/44: loss=-0.2706 
[epoch 29] step 24/44: loss=-0.2709 
[epoch 29] step 26/44: loss=-0.2711 
[epoch 29] step 28/44: loss=-0.2699 
[epoch 29] step 30/44: loss=-0.2697 
[epoch 29] step 32/44: loss=-0.2711 
[epoch 29] step 34/44: loss=-0.2687 
[epoch 29] step 36/44: loss=-0.2710 
[epoch 29] step 38/44: loss=-0.2681 
[epoch 29] step 40/44: loss=-0.2682 
[epoch 29] step 42/44: loss=-0.2673 
[epoch 29] step 44/44: loss=-0.2702 
[epoch 29] train_loss(avg per step)=-0.5404 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=8.3938 qwk=('0.6259', '0.5730', '0.5573') averageQWK=0.5854 macroEMD=0.2372 tailR0=('0.1919', '0.0417', '0.1000') tailR0avg=0.1112
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     4   17   29    5    0
     0    5   88   30    3
     0    0   25   84    7
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     2   12   32    7    0
     0    8   79   31    1
     0    3   24  107    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     2   16   49    2    0
     0   10  109   32    0
     0    1   33   68    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=-0.2630 
[epoch 30] step 4/44: loss=-0.2333 
[epoch 30] step 6/44: loss=-0.2487 
[epoch 30] step 8/44: loss=-0.2550 
[epoch 30] step 10/44: loss=-0.2644 
[epoch 30] step 12/44: loss=-0.2671 
[epoch 30] step 14/44: loss=-0.2704 
[epoch 30] step 16/44: loss=-0.2757 
[epoch 30] step 18/44: loss=-0.2736 
[epoch 30] step 20/44: loss=-0.2755 
[epoch 30] step 22/44: loss=-0.2774 
[epoch 30] step 24/44: loss=-0.2728 
[epoch 30] step 26/44: loss=-0.2729 
[epoch 30] step 28/44: loss=-0.2750 
[epoch 30] step 30/44: loss=-0.2755 
[epoch 30] step 32/44: loss=-0.2765 
[epoch 30] step 34/44: loss=-0.2746 
[epoch 30] step 36/44: loss=-0.2757 
[epoch 30] step 38/44: loss=-0.2769 
[epoch 30] step 40/44: loss=-0.2773 
[epoch 30] step 42/44: loss=-0.2769 
[epoch 30] step 44/44: loss=-0.2763 
[epoch 30] train_loss(avg per step)=-0.5525 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=8.4305 qwk=('0.6183', '0.5670', '0.5602') averageQWK=0.5819 macroEMD=0.2371 tailR0=('0.1818', '0.0833', '0.1000') tailR0avg=0.1217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     4   17   29    4    1
     0    8   85   28    5
     0    0   24   77   15
     0    0    1   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     1   13   32    7    0
     0   10   77   31    1
     0    4   24  103    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     1   23   43    2    0
     0   16  106   29    0
     0    2   35   65    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=-0.2370 
[epoch 31] step 4/44: loss=-0.2396 
[epoch 31] step 6/44: loss=-0.2590 
[epoch 31] step 8/44: loss=-0.2753 
[epoch 31] step 10/44: loss=-0.2808 
[epoch 31] step 12/44: loss=-0.2844 
[epoch 31] step 14/44: loss=-0.2867 
[epoch 31] step 16/44: loss=-0.2909 
[epoch 31] step 18/44: loss=-0.2894 
[epoch 31] step 20/44: loss=-0.2922 
[epoch 31] step 22/44: loss=-0.2898 
[epoch 31] step 24/44: loss=-0.2904 
[epoch 31] step 26/44: loss=-0.2908 
[epoch 31] step 28/44: loss=-0.2940 
[epoch 31] step 30/44: loss=-0.2953 
[epoch 31] step 32/44: loss=-0.2974 
[epoch 31] step 34/44: loss=-0.2950 
[epoch 31] step 36/44: loss=-0.2961 
[epoch 31] step 38/44: loss=-0.2971 
[epoch 31] step 40/44: loss=-0.2970 
[epoch 31] step 42/44: loss=-0.2955 
[epoch 31] step 44/44: loss=-0.2960 
[epoch 31] train_loss(avg per step)=-0.5921 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=8.4342 qwk=('0.6268', '0.5734', '0.5850') averageQWK=0.5950 macroEMD=0.2328 tailR0=('0.1465', '0.0833', '0.1000') tailR0avg=0.1099
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     4   19   29    2    1
     0    6   97   20    3
     0    1   29   79    7
     0    0    1   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     3   14   28    8    0
     0   10   78   30    1
     0    3   28  100    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     1   26   41    1    0
     0   16  110   25    0
     0    2   36   64    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=-0.3228 
[epoch 32] step 4/44: loss=-0.3037 
[epoch 32] step 6/44: loss=-0.3024 
[epoch 32] step 8/44: loss=-0.2908 
[epoch 32] step 10/44: loss=-0.2954 
[epoch 32] step 12/44: loss=-0.2935 
[epoch 32] step 14/44: loss=-0.2936 
[epoch 32] step 16/44: loss=-0.2959 
[epoch 32] step 18/44: loss=-0.2936 
[epoch 32] step 20/44: loss=-0.2932 
[epoch 32] step 22/44: loss=-0.2924 
[epoch 32] step 24/44: loss=-0.2938 
[epoch 32] step 26/44: loss=-0.2974 
[epoch 32] step 28/44: loss=-0.2983 
[epoch 32] step 30/44: loss=-0.2958 
[epoch 32] step 32/44: loss=-0.2954 
[epoch 32] step 34/44: loss=-0.2951 
[epoch 32] step 36/44: loss=-0.2962 
[epoch 32] step 38/44: loss=-0.2962 
[epoch 32] step 40/44: loss=-0.2956 
[epoch 32] step 42/44: loss=-0.2965 
[epoch 32] step 44/44: loss=-0.2940 
[epoch 32] train_loss(avg per step)=-0.5881 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=8.4943 qwk=('0.6067', '0.5521', '0.5535') averageQWK=0.5708 macroEMD=0.2338 tailR0=('0.1364', '0.0833', '0.1000') tailR0avg=0.1066
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     3   19   29    3    1
     0    5   97   20    4
     0    1   29   78    8
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   16   28    9    0
     0   11   75   32    1
     0    4   26  101    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     1   22   44    2    0
     0   15  105   31    0
     0    2   35   65    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=-0.3015 
[epoch 33] step 4/44: loss=-0.3118 
[epoch 33] step 6/44: loss=-0.3158 
[epoch 33] step 8/44: loss=-0.3178 
[epoch 33] step 10/44: loss=-0.3177 
[epoch 33] step 12/44: loss=-0.3115 
[epoch 33] step 14/44: loss=-0.3124 
[epoch 33] step 16/44: loss=-0.3148 
[epoch 33] step 18/44: loss=-0.3122 
[epoch 33] step 20/44: loss=-0.3121 
[epoch 33] step 22/44: loss=-0.3138 
[epoch 33] step 24/44: loss=-0.3159 
[epoch 33] step 26/44: loss=-0.3133 
[epoch 33] step 28/44: loss=-0.3116 
[epoch 33] step 30/44: loss=-0.3112 
[epoch 33] step 32/44: loss=-0.3128 
[epoch 33] step 34/44: loss=-0.3096 
[epoch 33] step 36/44: loss=-0.3105 
[epoch 33] step 38/44: loss=-0.3105 
[epoch 33] step 40/44: loss=-0.3113 
[epoch 33] step 42/44: loss=-0.3113 
[epoch 33] step 44/44: loss=-0.3113 
[epoch 33] train_loss(avg per step)=-0.6226 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=8.5171 qwk=('0.6350', '0.5893', '0.5468') averageQWK=0.5904 macroEMD=0.2316 tailR0=('0.1364', '0.0833', '0.1000') tailR0avg=0.1066
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     3   21   26    5    0
     0    8   88   27    3
     0    1   24   83    8
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     1   19   25    8    0
     0   13   77   28    1
     0    3   26  102    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     1   20   46    2    0
     0   13  109   29    0
     0    2   36   64    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=-0.3101 
[epoch 34] step 4/44: loss=-0.3146 
[epoch 34] step 6/44: loss=-0.3183 
[epoch 34] step 8/44: loss=-0.3223 
[epoch 34] step 10/44: loss=-0.3181 
[epoch 34] step 12/44: loss=-0.3220 
[epoch 34] step 14/44: loss=-0.3215 
[epoch 34] step 16/44: loss=-0.3218 
[epoch 34] step 18/44: loss=-0.3233 
[epoch 34] step 20/44: loss=-0.3216 
[epoch 34] step 22/44: loss=-0.3231 
[epoch 34] step 24/44: loss=-0.3212 
[epoch 34] step 26/44: loss=-0.3212 
[epoch 34] step 28/44: loss=-0.3223 
[epoch 34] step 30/44: loss=-0.3218 
[epoch 34] step 32/44: loss=-0.3204 
[epoch 34] step 34/44: loss=-0.3207 
[epoch 34] step 36/44: loss=-0.3217 
[epoch 34] step 38/44: loss=-0.3215 
[epoch 34] step 40/44: loss=-0.3212 
[epoch 34] step 42/44: loss=-0.3218 
[epoch 34] step 44/44: loss=-0.3217 
[epoch 34] train_loss(avg per step)=-0.6433 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=8.4528 qwk=('0.6374', '0.5902', '0.5503') averageQWK=0.5926 macroEMD=0.2299 tailR0=('0.1364', '0.0833', '0.1000') tailR0avg=0.1066
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     2   22   27    4    0
     0    8   90   24    4
     0    1   25   84    6
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     1   18   28    6    0
     0   13   77   28    1
     0    4   26  101    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   23   44    2    0
     0   18  110   23    0
     0    2   38   62    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=-0.3158 
[epoch 35] step 4/44: loss=-0.3152 
[epoch 35] step 6/44: loss=-0.2994 
[epoch 35] step 8/44: loss=-0.3067 
[epoch 35] step 10/44: loss=-0.3125 
[epoch 35] step 12/44: loss=-0.3129 
[epoch 35] step 14/44: loss=-0.3160 
[epoch 35] step 16/44: loss=-0.3171 
[epoch 35] step 18/44: loss=-0.3164 
[epoch 35] step 20/44: loss=-0.3164 
[epoch 35] step 22/44: loss=-0.3176 
[epoch 35] step 24/44: loss=-0.3151 
[epoch 35] step 26/44: loss=-0.3151 
[epoch 35] step 28/44: loss=-0.3167 
[epoch 35] step 30/44: loss=-0.3175 
[epoch 35] step 32/44: loss=-0.3178 
[epoch 35] step 34/44: loss=-0.3179 
[epoch 35] step 36/44: loss=-0.3174 
[epoch 35] step 38/44: loss=-0.3176 
[epoch 35] step 40/44: loss=-0.3169 
[epoch 35] step 42/44: loss=-0.3170 
[epoch 35] step 44/44: loss=-0.3178 
[epoch 35] train_loss(avg per step)=-0.6355 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=8.4832 qwk=('0.6323', '0.5876', '0.5543') averageQWK=0.5914 macroEMD=0.2302 tailR0=('0.1364', '0.0833', '0.1000') tailR0avg=0.1066
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     3   22   26    3    1
     0    8   90   24    4
     0    1   25   82    8
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     1   19   27    6    0
     0   14   76   28    1
     0    5   25  101    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     1   22   44    2    0
     0   17  105   29    0
     0    2   35   65    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-0-reassignment-0/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-0-reassignment-0/fold3/metrics.json
Done.
