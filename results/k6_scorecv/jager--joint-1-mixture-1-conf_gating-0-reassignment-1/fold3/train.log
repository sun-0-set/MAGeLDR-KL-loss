[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=20.1026 
[epoch 1] step 4/44: loss=20.0645 
[epoch 1] step 6/44: loss=20.0487 
[epoch 1] step 8/44: loss=19.7659 
[epoch 1] step 10/44: loss=19.4478 
[epoch 1] step 12/44: loss=19.3064 
[epoch 1] step 14/44: loss=19.3980 
[epoch 1] step 16/44: loss=19.3871 
[epoch 1] step 18/44: loss=19.3071 
[epoch 1] step 20/44: loss=19.2774 
[epoch 1] step 22/44: loss=19.2416 
[epoch 1] step 24/44: loss=19.2799 
[epoch 1] step 26/44: loss=19.2912 
[epoch 1] step 28/44: loss=19.2883 
[epoch 1] step 30/44: loss=19.2886 
[epoch 1] step 32/44: loss=19.2341 
[epoch 1] step 34/44: loss=19.1665 
[epoch 1] step 36/44: loss=19.0890 
[epoch 1] step 38/44: loss=19.0222 
[epoch 1] step 40/44: loss=18.9357 
[epoch 1] step 42/44: loss=18.8551 
[epoch 1] step 44/44: loss=18.8088 
[epoch 1] train_loss(avg per step)=37.6176 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=29.5420 qwk=('0.0099', '0.0372', '0.0761') averageQWK=0.0411 macroEMD=0.3988 tailR0=('0.0227', '0.0500', '0.0000') tailR0avg=0.0242
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    0    0
     0   53    0    2    0
     0  121    0    5    0
     0  114    0    2    0
     0   20    0    1    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    9    0    0
    16    0   37    0    0
    41    0   77    1    0
    31    0  102    1    0
     2    0   10    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    8   61    0    0
     0    4  147    0    0
     0    1  101    0    0
     0    0    1    0    0
[epoch 2] step 2/44: loss=17.5629 
[epoch 2] step 4/44: loss=17.4764 
[epoch 2] step 6/44: loss=17.4642 
[epoch 2] step 8/44: loss=17.2591 
[epoch 2] step 10/44: loss=17.0202 
[epoch 2] step 12/44: loss=16.8658 
[epoch 2] step 14/44: loss=16.5591 
[epoch 2] step 16/44: loss=16.3170 
[epoch 2] step 18/44: loss=16.3040 
[epoch 2] step 20/44: loss=16.1841 
[epoch 2] step 22/44: loss=16.0281 
[epoch 2] step 24/44: loss=15.8000 
[epoch 2] step 26/44: loss=15.6631 
[epoch 2] step 28/44: loss=15.5469 
[epoch 2] step 30/44: loss=15.4292 
[epoch 2] step 32/44: loss=15.2201 
[epoch 2] step 34/44: loss=15.0634 
[epoch 2] step 36/44: loss=14.9634 
[epoch 2] step 38/44: loss=14.7997 
[epoch 2] step 40/44: loss=14.7455 
[epoch 2] step 42/44: loss=14.6512 
[epoch 2] step 44/44: loss=14.5795 
[epoch 2] train_loss(avg per step)=29.1590 lambda[min,max]=[0.517414,1.000000]
[epoch 2] val_loss=18.9558 qwk=('0.4691', '0.3469', '0.1457') averageQWK=0.3205 macroEMD=0.3908 tailR0=('0.4672', '0.0000', '0.0000') tailR0avg=0.1557
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     8    0    0    1    0
    24    4   12   14    1
    25    4   32   61    4
     5    0   17   93    1
     0    0    4   17    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    2    0
     0    0   39   14    0
     0    0   51   68    0
     0    0   18  116    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0   11   58    0    0
     0    3  147    1    0
     0    0   98    4    0
     0    0    1    0    0
[epoch 3] step 2/44: loss=13.0783 
[epoch 3] step 4/44: loss=12.5194 
[epoch 3] step 6/44: loss=12.3572 
[epoch 3] step 8/44: loss=12.5360 
[epoch 3] step 10/44: loss=12.6362 
[epoch 3] step 12/44: loss=12.7643 
[epoch 3] step 14/44: loss=12.7511 
[epoch 3] step 16/44: loss=12.7029 
[epoch 3] step 18/44: loss=12.5831 
[epoch 3] step 20/44: loss=12.6226 
[epoch 3] step 22/44: loss=12.6337 
[epoch 3] step 24/44: loss=12.6828 
[epoch 3] step 26/44: loss=12.6383 
[epoch 3] step 28/44: loss=12.5866 
[epoch 3] step 30/44: loss=12.6232 
[epoch 3] step 32/44: loss=12.5940 
[epoch 3] step 34/44: loss=12.5742 
[epoch 3] step 36/44: loss=12.5545 
[epoch 3] step 38/44: loss=12.4503 
[epoch 3] step 40/44: loss=12.4379 
[epoch 3] step 42/44: loss=12.3787 
[epoch 3] step 44/44: loss=12.3421 
[epoch 3] train_loss(avg per step)=24.6843 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=22.9999 qwk=('0.4097', '0.4145', '0.2442') averageQWK=0.3561 macroEMD=0.3864 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   49    6    0
     0    0   83   43    0
     0    0   33   83    0
     0    0    3   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    0   51    2    0
     0    0   95   24    0
     0    0   53   81    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    0   68    1    0
     0    0  144    7    0
     0    0   70   32    0
     0    0    1    0    0
[epoch 4] step 2/44: loss=12.3333 
[epoch 4] step 4/44: loss=12.0466 
[epoch 4] step 6/44: loss=12.0453 
[epoch 4] step 8/44: loss=11.9457 
[epoch 4] step 10/44: loss=11.9202 
[epoch 4] step 12/44: loss=11.9674 
[epoch 4] step 14/44: loss=11.9530 
[epoch 4] step 16/44: loss=11.8393 
[epoch 4] step 18/44: loss=11.6889 
[epoch 4] step 20/44: loss=11.7624 
[epoch 4] step 22/44: loss=11.8213 
[epoch 4] step 24/44: loss=11.7354 
[epoch 4] step 26/44: loss=11.6364 
[epoch 4] step 28/44: loss=11.6368 
[epoch 4] step 30/44: loss=11.5852 
[epoch 4] step 32/44: loss=11.6167 
[epoch 4] step 34/44: loss=11.6580 
[epoch 4] step 36/44: loss=11.5930 
[epoch 4] step 38/44: loss=11.5808 
[epoch 4] step 40/44: loss=11.5083 
[epoch 4] step 42/44: loss=11.4156 
[epoch 4] step 44/44: loss=11.3064 
[epoch 4] train_loss(avg per step)=22.6128 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=25.6404 qwk=('0.4087', '0.2881', '0.4448') averageQWK=0.3806 macroEMD=0.3785 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    0    2    0
     0   26    0   29    0
     0   26    0  100    0
     0    4    0  112    0
     0    0    0   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    0   28   25    0
     0    0   26   93    0
     0    0    6  128    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0    3   64    2    0
     0    0  110   41    0
     0    0   33   69    0
     0    0    0    1    0
[epoch 5] step 2/44: loss=12.9652 
[epoch 5] step 4/44: loss=12.2898 
[epoch 5] step 6/44: loss=12.1973 
[epoch 5] step 8/44: loss=11.9823 
[epoch 5] step 10/44: loss=11.4400 
[epoch 5] step 12/44: loss=11.1355 
[epoch 5] step 14/44: loss=11.0574 
[epoch 5] step 16/44: loss=10.9449 
[epoch 5] step 18/44: loss=11.0105 
[epoch 5] step 20/44: loss=10.9573 
[epoch 5] step 22/44: loss=10.9459 
[epoch 5] step 24/44: loss=10.8066 
[epoch 5] step 26/44: loss=10.6247 
[epoch 5] step 28/44: loss=10.5514 
[epoch 5] step 30/44: loss=10.4378 
[epoch 5] step 32/44: loss=10.3383 
[epoch 5] step 34/44: loss=10.3305 
[epoch 5] step 36/44: loss=10.3139 
[epoch 5] step 38/44: loss=10.2943 
[epoch 5] step 40/44: loss=10.2758 
[epoch 5] step 42/44: loss=10.2236 
[epoch 5] step 44/44: loss=10.1635 
[epoch 5] train_loss(avg per step)=20.3270 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=14.5666 qwk=('0.2464', '0.5024', '0.5299') averageQWK=0.4262 macroEMD=0.3802 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     2   42    9    2    0
    11   58   47   10    0
    26   15   30   45    0
     3    1    3   15    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    0    0
     0    7   44    2    0
     0    1  100   18    0
     0    0   52   82    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   26   34    9    0
     0   18   75   58    0
     0    1   19   82    0
     0    0    0    1    0
[epoch 6] step 2/44: loss=9.9369 
[epoch 6] step 4/44: loss=9.3604 
[epoch 6] step 6/44: loss=9.4494 
[epoch 6] step 8/44: loss=9.1814 
[epoch 6] step 10/44: loss=9.1663 
[epoch 6] step 12/44: loss=8.8297 
[epoch 6] step 14/44: loss=8.9470 
[epoch 6] step 16/44: loss=9.0652 
[epoch 6] step 18/44: loss=9.2694 
[epoch 6] step 20/44: loss=9.2978 
[epoch 6] step 22/44: loss=9.2460 
[epoch 6] step 24/44: loss=9.0921 
[epoch 6] step 26/44: loss=8.9416 
[epoch 6] step 28/44: loss=8.9076 
[epoch 6] step 30/44: loss=8.9121 
[epoch 6] step 32/44: loss=9.0096 
[epoch 6] step 34/44: loss=9.0814 
[epoch 6] step 36/44: loss=9.0739 
[epoch 6] step 38/44: loss=9.0247 
[epoch 6] step 40/44: loss=8.9597 
[epoch 6] step 42/44: loss=8.9084 
[epoch 6] step 44/44: loss=8.9568 
[epoch 6] train_loss(avg per step)=17.9136 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=19.4724 qwk=('0.3966', '0.3250', '0.3901') averageQWK=0.3705 macroEMD=0.3749 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    1   37   17    0
     0    0   67   59    0
     0    0   10  106    0
     0    0    0   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    2    0
     0    0   31   22    0
     0    0   42   77    0
     0    0    6  128    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   10   39   20    0
     0    2   70   79    0
     0    0   12   90    0
     0    0    0    1    0
[epoch 7] step 2/44: loss=11.1437 
[epoch 7] step 4/44: loss=10.5623 
[epoch 7] step 6/44: loss=9.8601 
[epoch 7] step 8/44: loss=9.5389 
[epoch 7] step 10/44: loss=9.0813 
[epoch 7] step 12/44: loss=8.7692 
[epoch 7] step 14/44: loss=8.8594 
[epoch 7] step 16/44: loss=9.0380 
[epoch 7] step 18/44: loss=9.1533 
[epoch 7] step 20/44: loss=9.2262 
[epoch 7] step 22/44: loss=9.1629 
[epoch 7] step 24/44: loss=9.0804 
[epoch 7] step 26/44: loss=9.0499 
[epoch 7] step 28/44: loss=8.8837 
[epoch 7] step 30/44: loss=8.8056 
[epoch 7] step 32/44: loss=8.7856 
[epoch 7] step 34/44: loss=8.8442 
[epoch 7] step 36/44: loss=8.8658 
[epoch 7] step 38/44: loss=8.9064 
[epoch 7] step 40/44: loss=8.8704 
[epoch 7] step 42/44: loss=8.7941 
[epoch 7] step 44/44: loss=8.7397 
[epoch 7] train_loss(avg per step)=17.4795 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=12.5574 qwk=('0.5658', '0.5804', '0.4247') averageQWK=0.5236 macroEMD=0.3714 tailR0=('0.0556', '0.0000', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    0    0
     1   27   22    2    3
     0   31   74   20    1
     0    2   34   76    4
     0    0    5   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    1    0
     0   38    3   12    0
     0   40   29   50    0
     0    9    2  123    0
     0    1    0   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     0   28   21   20    0
     0   17   44   90    0
     0    3    8   91    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=8.5016 
[epoch 8] step 4/44: loss=8.7602 
[epoch 8] step 6/44: loss=9.0083 
[epoch 8] step 8/44: loss=9.2559 
[epoch 8] step 10/44: loss=9.2904 
[epoch 8] step 12/44: loss=9.1475 
[epoch 8] step 14/44: loss=9.0178 
[epoch 8] step 16/44: loss=8.8063 
[epoch 8] step 18/44: loss=8.6882 
[epoch 8] step 20/44: loss=8.5213 
[epoch 8] step 22/44: loss=8.4339 
[epoch 8] step 24/44: loss=8.4628 
[epoch 8] step 26/44: loss=8.4651 
[epoch 8] step 28/44: loss=8.4699 
[epoch 8] step 30/44: loss=8.4581 
[epoch 8] step 32/44: loss=8.4427 
[epoch 8] step 34/44: loss=8.4070 
[epoch 8] step 36/44: loss=8.3967 
[epoch 8] step 38/44: loss=8.4038 
[epoch 8] step 40/44: loss=8.4714 
[epoch 8] step 42/44: loss=8.5304 
[epoch 8] step 44/44: loss=8.5445 
[epoch 8] train_loss(avg per step)=17.0890 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=10.6844 qwk=('0.4278', '0.4204', '0.5151') averageQWK=0.4544 macroEMD=0.3760 tailR0=('0.0227', '0.0000', '0.0000') tailR0avg=0.0076
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    0    1
     0   31    3   15    6
     0   33   22   57   14
     0    3    8   97    8
     0    0    0   21    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    3   34   16    0
     0    0   63   56    0
     0    0   10  124    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   11   55    3    0
     0    4   98   49    0
     0    1   23   78    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=7.5090 
[epoch 9] step 4/44: loss=6.8872 
[epoch 9] step 6/44: loss=6.9606 
[epoch 9] step 8/44: loss=7.0097 
[epoch 9] step 10/44: loss=7.3498 
[epoch 9] step 12/44: loss=7.6838 
[epoch 9] step 14/44: loss=7.8114 
[epoch 9] step 16/44: loss=7.9023 
[epoch 9] step 18/44: loss=8.0462 
[epoch 9] step 20/44: loss=8.0897 
[epoch 9] step 22/44: loss=8.0819 
[epoch 9] step 24/44: loss=7.9749 
[epoch 9] step 26/44: loss=8.0129 
[epoch 9] step 28/44: loss=8.0202 
[epoch 9] step 30/44: loss=8.0886 
[epoch 9] step 32/44: loss=8.0820 
[epoch 9] step 34/44: loss=8.0906 
[epoch 9] step 36/44: loss=8.0139 
[epoch 9] step 38/44: loss=8.0404 
[epoch 9] step 40/44: loss=8.0299 
[epoch 9] step 42/44: loss=8.0589 
[epoch 9] step 44/44: loss=8.0991 
[epoch 9] train_loss(avg per step)=16.1983 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=11.3314 qwk=('0.5848', '0.6093', '0.5852') averageQWK=0.5931 macroEMD=0.3679 tailR0=('0.1364', '0.0000', '0.0000') tailR0avg=0.0455
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     2   27   21    1    4
     0   18   84   14   10
     0    1   28   77   10
     0    0    2   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   23   24    6    0
     0   14   62   43    0
     0    4   10  120    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   42   21    6    0
     0   34   68   49    0
     0    4   19   79    0
     0    0    0    1    0
[epoch 10] step 2/44: loss=7.7882 
[epoch 10] step 4/44: loss=7.5316 
[epoch 10] step 6/44: loss=7.2821 
[epoch 10] step 8/44: loss=7.5397 
[epoch 10] step 10/44: loss=7.7341 
[epoch 10] step 12/44: loss=7.7375 
[epoch 10] step 14/44: loss=7.6429 
[epoch 10] step 16/44: loss=7.6970 
[epoch 10] step 18/44: loss=7.7452 
[epoch 10] step 20/44: loss=7.8397 
[epoch 10] step 22/44: loss=7.9648 
[epoch 10] step 24/44: loss=8.0307 
[epoch 10] step 26/44: loss=8.0045 
[epoch 10] step 28/44: loss=7.9614 
[epoch 10] step 30/44: loss=7.9967 
[epoch 10] step 32/44: loss=8.0465 
[epoch 10] step 34/44: loss=8.0164 
[epoch 10] step 36/44: loss=8.0009 
[epoch 10] step 38/44: loss=7.9646 
[epoch 10] step 40/44: loss=7.9305 
[epoch 10] step 42/44: loss=7.9034 
[epoch 10] step 44/44: loss=7.9067 
[epoch 10] train_loss(avg per step)=15.8134 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=13.4046 qwk=('0.5299', '0.4340', '0.5060') averageQWK=0.4900 macroEMD=0.3686 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     4   19   18   14    0
     0   12   49   65    0
     0    2   10  104    0
     0    0    0   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    2    0
     0    5   32   16    0
     0    3   55   61    0
     0    0    8  126    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   12   53    4    0
     0    3  109   39    0
     0    0   29   73    0
     0    0    0    1    0
[epoch 11] step 2/44: loss=8.6011 
[epoch 11] step 4/44: loss=8.5637 
[epoch 11] step 6/44: loss=8.3348 
[epoch 11] step 8/44: loss=8.1602 
[epoch 11] step 10/44: loss=7.9624 
[epoch 11] step 12/44: loss=7.9366 
[epoch 11] step 14/44: loss=8.0378 
[epoch 11] step 16/44: loss=8.1379 
[epoch 11] step 18/44: loss=8.1838 
[epoch 11] step 20/44: loss=8.2268 
[epoch 11] step 22/44: loss=8.1705 
[epoch 11] step 24/44: loss=8.1068 
[epoch 11] step 26/44: loss=8.0218 
[epoch 11] step 28/44: loss=7.9956 
[epoch 11] step 30/44: loss=7.9478 
[epoch 11] step 32/44: loss=7.9645 
[epoch 11] step 34/44: loss=7.9743 
[epoch 11] step 36/44: loss=7.9502 
[epoch 11] step 38/44: loss=7.9021 
[epoch 11] step 40/44: loss=7.8905 
[epoch 11] step 42/44: loss=7.8877 
[epoch 11] step 44/44: loss=7.8558 
[epoch 11] train_loss(avg per step)=15.7117 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=18.9577 qwk=('0.4681', '0.6232', '0.4352') averageQWK=0.5088 macroEMD=0.3649 tailR0=('0.0682', '0.0000', '0.0000') tailR0avg=0.0227
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   12   41    2    0
     0    3  114    7    2
     0    0   62   54    0
     0    0   10    9    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   16   34    3    0
     0    5   88   26    0
     0    0   28  106    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   15   53    1    0
     0    6  136    9    0
     0    0   60   42    0
     0    0    1    0    0
[epoch 12] step 2/44: loss=9.7981 
[epoch 12] step 4/44: loss=9.9563 
[epoch 12] step 6/44: loss=9.5624 
[epoch 12] step 8/44: loss=9.0216 
[epoch 12] step 10/44: loss=8.6036 
[epoch 12] step 12/44: loss=8.3820 
[epoch 12] step 14/44: loss=8.3015 
[epoch 12] step 16/44: loss=8.3413 
[epoch 12] step 18/44: loss=8.3926 
[epoch 12] step 20/44: loss=8.3437 
[epoch 12] step 22/44: loss=8.2417 
[epoch 12] step 24/44: loss=8.1923 
[epoch 12] step 26/44: loss=8.1867 
[epoch 12] step 28/44: loss=8.1698 
[epoch 12] step 30/44: loss=8.2080 
[epoch 12] step 32/44: loss=8.2459 
[epoch 12] step 34/44: loss=8.2675 
[epoch 12] step 36/44: loss=8.2039 
[epoch 12] step 38/44: loss=8.1307 
[epoch 12] step 40/44: loss=8.1073 
[epoch 12] step 42/44: loss=8.0841 
[epoch 12] step 44/44: loss=8.0714 
[epoch 12] train_loss(avg per step)=16.1428 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=14.7508 qwk=('0.4736', '0.3981', '0.5609') averageQWK=0.4776 macroEMD=0.3695 tailR0=('0.0682', '0.0000', '0.0000') tailR0avg=0.0227
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0    4   48    3    0
     0    1  113   10    2
     0    0   47   68    1
     0    0    7   12    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     1    1   49    2    0
     0    0  108   11    0
     0    0   58   76    0
     0    0    6    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   34   33    2    0
     0   23  105   23    0
     0    2   39   61    0
     0    0    1    0    0
[epoch 13] step 2/44: loss=8.6448 
[epoch 13] step 4/44: loss=8.5212 
[epoch 13] step 6/44: loss=8.6611 
[epoch 13] step 8/44: loss=8.4490 
[epoch 13] step 10/44: loss=8.0332 
[epoch 13] step 12/44: loss=7.7953 
[epoch 13] step 14/44: loss=7.7144 
[epoch 13] step 16/44: loss=7.6034 
[epoch 13] step 18/44: loss=7.6112 
[epoch 13] step 20/44: loss=7.7038 
[epoch 13] step 22/44: loss=7.8655 
[epoch 13] step 24/44: loss=7.9525 
[epoch 13] step 26/44: loss=7.9625 
[epoch 13] step 28/44: loss=7.9574 
[epoch 13] step 30/44: loss=7.9329 
[epoch 13] step 32/44: loss=7.9206 
[epoch 13] step 34/44: loss=7.9064 
[epoch 13] step 36/44: loss=7.9155 
[epoch 13] step 38/44: loss=7.9665 
[epoch 13] step 40/44: loss=8.0297 
[epoch 13] step 42/44: loss=8.0386 
[epoch 13] step 44/44: loss=8.0020 
[epoch 13] train_loss(avg per step)=16.0040 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=9.6465 qwk=('0.5532', '0.5450', '0.5312') averageQWK=0.5431 macroEMD=0.3709 tailR0=('0.3359', '0.0000', '0.0000') tailR0avg=0.1120
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    1    3    1    0
     9   10   21   14    1
     1    5   60   57    3
     0    0   12   99    5
     0    0    1   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    2    0
     0   22   16   15    0
     0   12   45   62    0
     0    3    4  127    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   32    6    0
     0   22   73   56    0
     0    4   21   77    0
     0    0    0    1    0
[epoch 14] step 2/44: loss=6.8617 
[epoch 14] step 4/44: loss=6.7437 
[epoch 14] step 6/44: loss=6.8179 
[epoch 14] step 8/44: loss=7.2128 
[epoch 14] step 10/44: loss=7.4517 
[epoch 14] step 12/44: loss=7.7248 
[epoch 14] step 14/44: loss=7.8952 
[epoch 14] step 16/44: loss=8.0214 
[epoch 14] step 18/44: loss=7.9943 
[epoch 14] step 20/44: loss=7.9200 
[epoch 14] step 22/44: loss=7.8375 
[epoch 14] step 24/44: loss=7.7822 
[epoch 14] step 26/44: loss=7.7972 
[epoch 14] step 28/44: loss=7.8724 
[epoch 14] step 30/44: loss=7.9463 
[epoch 14] step 32/44: loss=8.0218 
[epoch 14] step 34/44: loss=8.0211 
[epoch 14] step 36/44: loss=8.0068 
[epoch 14] step 38/44: loss=7.9897 
[epoch 14] step 40/44: loss=7.9563 
[epoch 14] step 42/44: loss=7.8998 
[epoch 14] step 44/44: loss=7.8504 
[epoch 14] train_loss(avg per step)=15.7008 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=11.8142 qwk=('0.5905', '0.5596', '0.5613') averageQWK=0.5705 macroEMD=0.3671 tailR0=('0.1136', '0.0000', '0.0000') tailR0avg=0.0379
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     2   23   27    3    0
     0   14   96   13    3
     0    1   41   69    5
     0    0    6   11    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   24   27    2    0
     0   10   94   15    0
     0    3   57   74    0
     0    0    5    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   51   18    0    0
     0   54   84   13    0
     0    8   43   51    0
     0    0    1    0    0
[epoch 15] step 2/44: loss=7.5361 
[epoch 15] step 4/44: loss=7.2172 
[epoch 15] step 6/44: loss=7.2770 
[epoch 15] step 8/44: loss=7.6359 
[epoch 15] step 10/44: loss=7.6638 
[epoch 15] step 12/44: loss=7.7563 
[epoch 15] step 14/44: loss=7.7477 
[epoch 15] step 16/44: loss=7.7066 
[epoch 15] step 18/44: loss=7.8141 
[epoch 15] step 20/44: loss=7.8599 
[epoch 15] step 22/44: loss=7.8556 
[epoch 15] step 24/44: loss=7.9032 
[epoch 15] step 26/44: loss=7.8639 
[epoch 15] step 28/44: loss=7.8320 
[epoch 15] step 30/44: loss=7.8252 
[epoch 15] step 32/44: loss=7.7608 
[epoch 15] step 34/44: loss=7.7212 
[epoch 15] step 36/44: loss=7.7572 
[epoch 15] step 38/44: loss=7.7907 
[epoch 15] step 40/44: loss=7.7858 
[epoch 15] step 42/44: loss=7.7677 
[epoch 15] step 44/44: loss=7.7529 
[epoch 15] train_loss(avg per step)=15.5058 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=10.9534 qwk=('0.6303', '0.5172', '0.6191') averageQWK=0.5889 macroEMD=0.3684 tailR0=('0.2247', '0.0500', '0.0000') tailR0avg=0.0916
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    0    0
     5   21   26    2    1
     2   13   88   20    3
     0    2   31   77    6
     0    0    3   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     6    1   43    3    0
     0    0   97   22    0
     0    0   39   95    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   35   32    2    0
     0   19  104   28    0
     0    2   32   68    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=7.1126 
[epoch 16] step 4/44: loss=7.3170 
[epoch 16] step 6/44: loss=7.7554 
[epoch 16] step 8/44: loss=7.8479 
[epoch 16] step 10/44: loss=7.9864 
[epoch 16] step 12/44: loss=8.2385 
[epoch 16] step 14/44: loss=8.2270 
[epoch 16] step 16/44: loss=8.1618 
[epoch 16] step 18/44: loss=8.0626 
[epoch 16] step 20/44: loss=7.9578 
[epoch 16] step 22/44: loss=7.8853 
[epoch 16] step 24/44: loss=7.8998 
[epoch 16] step 26/44: loss=7.9225 
[epoch 16] step 28/44: loss=7.9555 
[epoch 16] step 30/44: loss=7.9116 
[epoch 16] step 32/44: loss=7.8547 
[epoch 16] step 34/44: loss=7.8482 
[epoch 16] step 36/44: loss=7.9048 
[epoch 16] step 38/44: loss=7.9274 
[epoch 16] step 40/44: loss=7.9113 
[epoch 16] step 42/44: loss=7.8741 
[epoch 16] step 44/44: loss=7.8286 
[epoch 16] train_loss(avg per step)=15.6572 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=11.1720 qwk=('0.6612', '0.6458', '0.5680') averageQWK=0.6250 macroEMD=0.3636 tailR0=('0.3712', '0.1833', '0.0000') tailR0avg=0.1848
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    2    0    0
     8   17   26    4    0
     3   14   73   33    3
     0    1   23   86    6
     0    0    1   12    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    1    0
     4   15   30    4    0
     0   10   72   36    1
     0    1   17  114    2
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   32   29    8    0
     0   21   69   61    0
     0    1   17   84    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=6.8173 
[epoch 17] step 4/44: loss=7.6518 
[epoch 17] step 6/44: loss=7.9768 
[epoch 17] step 8/44: loss=8.2831 
[epoch 17] step 10/44: loss=8.1813 
[epoch 17] step 12/44: loss=8.2107 
[epoch 17] step 14/44: loss=8.0518 
[epoch 17] step 16/44: loss=7.9012 
[epoch 17] step 18/44: loss=7.7858 
[epoch 17] step 20/44: loss=7.7237 
[epoch 17] step 22/44: loss=7.7749 
[epoch 17] step 24/44: loss=7.8329 
[epoch 17] step 26/44: loss=7.8783 
[epoch 17] step 28/44: loss=7.9899 
[epoch 17] step 30/44: loss=7.9825 
[epoch 17] step 32/44: loss=7.9168 
[epoch 17] step 34/44: loss=7.8978 
[epoch 17] step 36/44: loss=7.8629 
[epoch 17] step 38/44: loss=7.8729 
[epoch 17] step 40/44: loss=7.8869 
[epoch 17] step 42/44: loss=7.8918 
[epoch 17] step 44/44: loss=7.8603 
[epoch 17] train_loss(avg per step)=15.7206 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=14.7434 qwk=('0.5593', '0.5789', '0.5848') averageQWK=0.5743 macroEMD=0.3664 tailR0=('0.1692', '0.0000', '0.0000') tailR0avg=0.0564
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     2    7   43    3    0
     0    2  106   15    3
     0    0   34   78    4
     0    0    5   12    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   17   32    4    0
     0    6   78   35    0
     0    1   28  105    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   41   26    2    0
     0   28  100   23    0
     0    3   41   58    0
     0    0    1    0    0
[epoch 18] step 2/44: loss=8.4425 
[epoch 18] step 4/44: loss=8.3756 
[epoch 18] step 6/44: loss=7.8089 
[epoch 18] step 8/44: loss=7.7885 
[epoch 18] step 10/44: loss=7.7410 
[epoch 18] step 12/44: loss=7.7021 
[epoch 18] step 14/44: loss=7.8087 
[epoch 18] step 16/44: loss=8.0297 
[epoch 18] step 18/44: loss=8.1608 
[epoch 18] step 20/44: loss=8.1504 
[epoch 18] step 22/44: loss=8.0984 
[epoch 18] step 24/44: loss=8.0333 
[epoch 18] step 26/44: loss=7.9146 
[epoch 18] step 28/44: loss=7.9192 
[epoch 18] step 30/44: loss=7.9326 
[epoch 18] step 32/44: loss=7.9263 
[epoch 18] step 34/44: loss=7.9231 
[epoch 18] step 36/44: loss=7.9188 
[epoch 18] step 38/44: loss=7.9422 
[epoch 18] step 40/44: loss=7.9173 
[epoch 18] step 42/44: loss=7.9516 
[epoch 18] step 44/44: loss=7.9852 
[epoch 18] train_loss(avg per step)=15.9704 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=12.5362 qwk=('0.6044', '0.6178', '0.5947') averageQWK=0.6056 macroEMD=0.3654 tailR0=('0.2146', '0.0917', '0.0000') tailR0avg=0.1021
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   12   40    3    0
     0    7   97   19    3
     0    1   26   84    5
     0    0    3   12    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     2   17   26    8    0
     0    7   74   38    0
     0    1   16  116    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   35   32    2    0
     0   20   99   32    0
     0    2   36   64    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=8.1631 
[epoch 19] step 4/44: loss=7.5500 
[epoch 19] step 6/44: loss=7.3633 
[epoch 19] step 8/44: loss=7.1992 
[epoch 19] step 10/44: loss=7.2905 
[epoch 19] step 12/44: loss=7.3762 
[epoch 19] step 14/44: loss=7.6471 
[epoch 19] step 16/44: loss=7.8046 
[epoch 19] step 18/44: loss=7.9296 
[epoch 19] step 20/44: loss=7.9704 
[epoch 19] step 22/44: loss=8.0187 
[epoch 19] step 24/44: loss=7.9788 
[epoch 19] step 26/44: loss=7.9679 
[epoch 19] step 28/44: loss=7.9738 
[epoch 19] step 30/44: loss=7.9229 
[epoch 19] step 32/44: loss=7.9323 
[epoch 19] step 34/44: loss=7.8842 
[epoch 19] step 36/44: loss=7.8645 
[epoch 19] step 38/44: loss=7.8522 
[epoch 19] step 40/44: loss=7.7987 
[epoch 19] step 42/44: loss=7.7908 
[epoch 19] step 44/44: loss=7.8079 
[epoch 19] train_loss(avg per step)=15.6158 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=15.2026 qwk=('0.6089', '0.5931', '0.5570') averageQWK=0.5863 macroEMD=0.3628 tailR0=('0.1919', '0.0917', '0.0000') tailR0avg=0.0945
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   14   37    3    0
     0    4  100   19    3
     0    1   28   80    7
     0    0    3   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     1   14   28   10    0
     0    7   73   38    1
     0    1   12  121    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   31   36    2    0
     0   15  119   17    0
     0    3   47   52    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=9.2673 
[epoch 20] step 4/44: loss=9.0105 
[epoch 20] step 6/44: loss=8.8445 
[epoch 20] step 8/44: loss=8.5681 
[epoch 20] step 10/44: loss=8.2991 
[epoch 20] step 12/44: loss=8.1311 
[epoch 20] step 14/44: loss=7.9322 
[epoch 20] step 16/44: loss=7.8163 
[epoch 20] step 18/44: loss=7.9344 
[epoch 20] step 20/44: loss=7.9613 
[epoch 20] step 22/44: loss=7.9773 
[epoch 20] step 24/44: loss=7.9630 
[epoch 20] step 26/44: loss=8.0036 
[epoch 20] step 28/44: loss=7.9677 
[epoch 20] step 30/44: loss=7.9482 
[epoch 20] step 32/44: loss=7.9287 
[epoch 20] step 34/44: loss=7.9000 
[epoch 20] step 36/44: loss=7.9120 
[epoch 20] step 38/44: loss=7.8995 
[epoch 20] step 40/44: loss=7.8984 
[epoch 20] step 42/44: loss=7.9225 
[epoch 20] step 44/44: loss=7.9736 
[epoch 20] train_loss(avg per step)=15.9471 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=12.3277 qwk=('0.6217', '0.6203', '0.5837') averageQWK=0.6086 macroEMD=0.3626 tailR0=('0.3939', '0.1333', '0.1000') tailR0avg=0.2091
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    2    0    0
     7   18   27    2    1
     5   13   85   19    4
     0    3   28   69   16
     0    0    5    7   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    1    1    0
     3   28   15    7    0
     0   17   61   39    2
     1    4   14  114    1
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   47   19    3    0
     1   40   76   34    0
     0    6   30   66    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=8.4146 
[epoch 21] step 4/44: loss=8.1933 
[epoch 21] step 6/44: loss=8.2053 
[epoch 21] step 8/44: loss=8.1307 
[epoch 21] step 10/44: loss=7.9204 
[epoch 21] step 12/44: loss=7.7549 
[epoch 21] step 14/44: loss=7.6468 
[epoch 21] step 16/44: loss=7.7065 
[epoch 21] step 18/44: loss=7.8100 
[epoch 21] step 20/44: loss=7.8620 
[epoch 21] step 22/44: loss=7.9152 
[epoch 21] step 24/44: loss=7.9652 
[epoch 21] step 26/44: loss=7.9225 
[epoch 21] step 28/44: loss=7.8927 
[epoch 21] step 30/44: loss=7.8504 
[epoch 21] step 32/44: loss=7.8327 
[epoch 21] step 34/44: loss=7.8537 
[epoch 21] step 36/44: loss=7.8420 
[epoch 21] step 38/44: loss=7.9391 
[epoch 21] step 40/44: loss=7.9451 
[epoch 21] step 42/44: loss=7.9946 
[epoch 21] step 44/44: loss=7.9917 
[epoch 21] train_loss(avg per step)=15.9833 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=10.1647 qwk=('0.6373', '0.6070', '0.5936') averageQWK=0.6126 macroEMD=0.3668 tailR0=('0.3813', '0.0833', '0.1000') tailR0avg=0.1882
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    4    1    0    0
     5   18   26    6    0
     4   12   69   38    3
     0    2   17   90    7
     0    0    2   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     2   21   21    9    0
     0   13   64   41    1
     0    2   10  120    2
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   34   30    5    0
     0   25   84   42    0
     0    1   27   74    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=7.2269 
[epoch 22] step 4/44: loss=6.9656 
[epoch 22] step 6/44: loss=6.7435 
[epoch 22] step 8/44: loss=6.8716 
[epoch 22] step 10/44: loss=7.0732 
[epoch 22] step 12/44: loss=7.1880 
[epoch 22] step 14/44: loss=7.3559 
[epoch 22] step 16/44: loss=7.5243 
[epoch 22] step 18/44: loss=7.5537 
[epoch 22] step 20/44: loss=7.5906 
[epoch 22] step 22/44: loss=7.6599 
[epoch 22] step 24/44: loss=7.7334 
[epoch 22] step 26/44: loss=7.7461 
[epoch 22] step 28/44: loss=7.7238 
[epoch 22] step 30/44: loss=7.7279 
[epoch 22] step 32/44: loss=7.7198 
[epoch 22] step 34/44: loss=7.7061 
[epoch 22] step 36/44: loss=7.6809 
[epoch 22] step 38/44: loss=7.7114 
[epoch 22] step 40/44: loss=7.6759 
[epoch 22] step 42/44: loss=7.7103 
[epoch 22] step 44/44: loss=7.7867 
[epoch 22] train_loss(avg per step)=15.5734 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=14.7108 qwk=('0.6335', '0.5648', '0.5716') averageQWK=0.5900 macroEMD=0.3619 tailR0=('0.1919', '0.1250', '0.1000') tailR0avg=0.1390
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     2   22   28    3    0
     1   11   88   23    3
     0    2   24   87    3
     0    0    3   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     1   17   30    5    0
     0    9   81   27    2
     0    4   29   97    4
     0    0    2    7    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   26   41    2    0
     0   20  108   23    0
     0    2   38   62    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=8.4628 
[epoch 23] step 4/44: loss=8.2045 
[epoch 23] step 6/44: loss=8.0723 
[epoch 23] step 8/44: loss=7.9990 
[epoch 23] step 10/44: loss=7.7872 
[epoch 23] step 12/44: loss=7.6974 
[epoch 23] step 14/44: loss=7.8484 
[epoch 23] step 16/44: loss=7.8410 
[epoch 23] step 18/44: loss=7.8922 
[epoch 23] step 20/44: loss=7.8893 
[epoch 23] step 22/44: loss=7.9390 
[epoch 23] step 24/44: loss=7.9170 
[epoch 23] step 26/44: loss=7.8969 
[epoch 23] step 28/44: loss=7.8309 
[epoch 23] step 30/44: loss=7.7948 
[epoch 23] step 32/44: loss=7.7464 
[epoch 23] step 34/44: loss=7.7426 
[epoch 23] step 36/44: loss=7.7426 
[epoch 23] step 38/44: loss=7.7721 
[epoch 23] step 40/44: loss=7.8180 
[epoch 23] step 42/44: loss=7.8665 
[epoch 23] step 44/44: loss=7.8985 
[epoch 23] train_loss(avg per step)=15.7970 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=13.1730 qwk=('0.6401', '0.6001', '0.6161') averageQWK=0.6187 macroEMD=0.3600 tailR0=('0.3712', '0.0833', '0.1000') tailR0avg=0.1848
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    5    1    0    0
     2   26   22    3    2
     2   17   69   34    4
     0    3   17   85   11
     0    0    2   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     1   25   17   10    0
     0   23   56   39    1
     0    4    9  115    6
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   35   31    3    0
     0   21   97   33    0
     0    1   32   69    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=8.2255 
[epoch 24] step 4/44: loss=8.4178 
[epoch 24] step 6/44: loss=8.7003 
[epoch 24] step 8/44: loss=8.4771 
[epoch 24] step 10/44: loss=8.2124 
[epoch 24] step 12/44: loss=8.0681 
[epoch 24] step 14/44: loss=7.9351 
[epoch 24] step 16/44: loss=7.8789 
[epoch 24] step 18/44: loss=7.8734 
[epoch 24] step 20/44: loss=7.9311 
[epoch 24] step 22/44: loss=7.9461 
[epoch 24] step 24/44: loss=7.8986 
[epoch 24] step 26/44: loss=7.8596 
[epoch 24] step 28/44: loss=7.9445 
[epoch 24] step 30/44: loss=7.9620 
[epoch 24] step 32/44: loss=7.9486 
[epoch 24] step 34/44: loss=7.9523 
[epoch 24] step 36/44: loss=7.9426 
[epoch 24] step 38/44: loss=7.9378 
[epoch 24] step 40/44: loss=7.9331 
[epoch 24] step 42/44: loss=7.9256 
[epoch 24] step 44/44: loss=7.8700 
[epoch 24] train_loss(avg per step)=15.7399 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=11.8775 qwk=('0.6352', '0.5760', '0.6086') averageQWK=0.6066 macroEMD=0.3656 tailR0=('0.2475', '0.0917', '0.0000') tailR0avg=0.1130
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    0    0
     2   19   31    3    0
     0   12   94   17    3
     0    2   33   77    4
     0    0    3   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     2   18   23   10    0
     0   15   64   39    1
     0    4   16  113    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   33   33    3    0
     0   19  105   27    0
     0    1   34   67    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=7.4350 
[epoch 25] step 4/44: loss=7.7098 
[epoch 25] step 6/44: loss=7.6315 
[epoch 25] step 8/44: loss=7.7389 
[epoch 25] step 10/44: loss=7.8122 
[epoch 25] step 12/44: loss=7.8953 
[epoch 25] step 14/44: loss=7.8385 
[epoch 25] step 16/44: loss=7.7470 
[epoch 25] step 18/44: loss=7.7164 
[epoch 25] step 20/44: loss=7.7595 
[epoch 25] step 22/44: loss=7.7423 
[epoch 25] step 24/44: loss=7.7128 
[epoch 25] step 26/44: loss=7.7460 
[epoch 25] step 28/44: loss=7.8540 
[epoch 25] step 30/44: loss=7.8833 
[epoch 25] step 32/44: loss=7.9510 
[epoch 25] step 34/44: loss=7.9822 
[epoch 25] step 36/44: loss=8.0000 
[epoch 25] step 38/44: loss=7.9819 
[epoch 25] step 40/44: loss=7.9258 
[epoch 25] step 42/44: loss=7.8859 
[epoch 25] step 44/44: loss=7.8163 
[epoch 25] train_loss(avg per step)=15.6327 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=11.4021 qwk=('0.6148', '0.5738', '0.5925') averageQWK=0.5937 macroEMD=0.3642 tailR0=('0.3157', '0.0833', '0.1000') tailR0avg=0.1663
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     3   12   36    4    0
     2    6   83   30    5
     0    0   23   83   10
     0    0    2   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     3   15   27    8    0
     0   10   68   40    1
     0    3   17  110    4
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   26   41    2    0
     0   17  103   31    0
     0    1   33   68    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=7.6962 
[epoch 26] step 4/44: loss=7.8788 
[epoch 26] step 6/44: loss=8.0953 
[epoch 26] step 8/44: loss=8.1709 
[epoch 26] step 10/44: loss=8.4000 
[epoch 26] step 12/44: loss=8.4663 
[epoch 26] step 14/44: loss=8.3060 
[epoch 26] step 16/44: loss=8.3374 
[epoch 26] step 18/44: loss=8.2156 
[epoch 26] step 20/44: loss=8.1387 
[epoch 26] step 22/44: loss=8.0652 
[epoch 26] step 24/44: loss=7.9643 
[epoch 26] step 26/44: loss=7.9672 
[epoch 26] step 28/44: loss=7.9715 
[epoch 26] step 30/44: loss=7.8794 
[epoch 26] step 32/44: loss=7.8998 
[epoch 26] step 34/44: loss=7.9684 
[epoch 26] step 36/44: loss=7.9997 
[epoch 26] step 38/44: loss=8.0330 
[epoch 26] step 40/44: loss=8.0329 
[epoch 26] step 42/44: loss=8.0273 
[epoch 26] step 44/44: loss=7.9645 
[epoch 26] train_loss(avg per step)=15.9289 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=10.2474 qwk=('0.6383', '0.5993', '0.6057') averageQWK=0.6144 macroEMD=0.3649 tailR0=('0.3712', '0.1833', '0.1000') tailR0avg=0.2182
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    2    0    0
     3   23   24    5    0
     3   16   67   35    5
     0    2   18   87    9
     0    0    2   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    1    0
     9   10   27    7    0
     1    4   76   37    1
     0    1   23  108    2
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   37   31    1    0
     0   26  102   23    0
     0    2   41   59    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=7.4199 
[epoch 27] step 4/44: loss=7.4126 
[epoch 27] step 6/44: loss=7.3043 
[epoch 27] step 8/44: loss=7.4653 
[epoch 27] step 10/44: loss=7.5137 
[epoch 27] step 12/44: loss=7.6124 
[epoch 27] step 14/44: loss=7.7110 
[epoch 27] step 16/44: loss=7.7561 
[epoch 27] step 18/44: loss=7.8084 
[epoch 27] step 20/44: loss=7.8237 
[epoch 27] step 22/44: loss=7.8024 
[epoch 27] step 24/44: loss=7.8224 
[epoch 27] step 26/44: loss=7.8459 
[epoch 27] step 28/44: loss=7.8773 
[epoch 27] step 30/44: loss=7.9078 
[epoch 27] step 32/44: loss=7.9649 
[epoch 27] step 34/44: loss=8.0146 
[epoch 27] step 36/44: loss=7.9798 
[epoch 27] step 38/44: loss=7.9665 
[epoch 27] step 40/44: loss=7.9277 
[epoch 27] step 42/44: loss=7.8535 
[epoch 27] step 44/44: loss=7.8527 
[epoch 27] train_loss(avg per step)=15.7053 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=12.7426 qwk=('0.6114', '0.5917', '0.5919') averageQWK=0.5984 macroEMD=0.3656 tailR0=('0.3157', '0.0833', '0.0000') tailR0avg=0.1330
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     2   17   33    2    1
     2   11   91   18    4
     0    2   29   74   11
     0    0    4    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     1   20   23    9    0
     0   14   60   44    1
     0    3   10  121    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   33   35    1    0
     0   21  106   24    0
     0    2   40   60    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=8.2114 
[epoch 28] step 4/44: loss=8.4781 
[epoch 28] step 6/44: loss=8.5810 
[epoch 28] step 8/44: loss=8.2404 
[epoch 28] step 10/44: loss=8.0254 
[epoch 28] step 12/44: loss=8.0799 
[epoch 28] step 14/44: loss=8.0359 
[epoch 28] step 16/44: loss=7.9864 
[epoch 28] step 18/44: loss=7.9760 
[epoch 28] step 20/44: loss=7.9489 
[epoch 28] step 22/44: loss=7.9450 
[epoch 28] step 24/44: loss=7.9482 
[epoch 28] step 26/44: loss=7.9905 
[epoch 28] step 28/44: loss=7.9428 
[epoch 28] step 30/44: loss=7.8915 
[epoch 28] step 32/44: loss=7.8806 
[epoch 28] step 34/44: loss=7.9581 
[epoch 28] step 36/44: loss=7.9621 
[epoch 28] step 38/44: loss=7.9931 
[epoch 28] step 40/44: loss=7.9790 
[epoch 28] step 42/44: loss=7.9935 
[epoch 28] step 44/44: loss=7.9532 
[epoch 28] train_loss(avg per step)=15.9064 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=10.9706 qwk=('0.6015', '0.6254', '0.6115') averageQWK=0.6128 macroEMD=0.3657 tailR0=('0.3384', '0.0833', '0.1000') tailR0avg=0.1739
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     2   17   33    2    1
     2   12   87   21    4
     0    2   24   76   14
     1    0    3    8   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     2   31   12    8    0
     0   29   55   34    1
     0    7   11  112    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   40   26    3    0
     0   30   86   35    0
     0    2   31   69    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=7.6798 
[epoch 29] step 4/44: loss=7.8449 
[epoch 29] step 6/44: loss=7.9071 
[epoch 29] step 8/44: loss=7.8636 
[epoch 29] step 10/44: loss=7.8833 
[epoch 29] step 12/44: loss=7.9505 
[epoch 29] step 14/44: loss=8.0305 
[epoch 29] step 16/44: loss=7.9779 
[epoch 29] step 18/44: loss=7.9805 
[epoch 29] step 20/44: loss=7.8793 
[epoch 29] step 22/44: loss=7.8273 
[epoch 29] step 24/44: loss=7.8273 
[epoch 29] step 26/44: loss=7.7654 
[epoch 29] step 28/44: loss=7.7244 
[epoch 29] step 30/44: loss=7.7127 
[epoch 29] step 32/44: loss=7.7492 
[epoch 29] step 34/44: loss=7.7877 
[epoch 29] step 36/44: loss=7.8310 
[epoch 29] step 38/44: loss=7.8980 
[epoch 29] step 40/44: loss=7.9327 
[epoch 29] step 42/44: loss=7.9550 
[epoch 29] step 44/44: loss=7.9152 
[epoch 29] train_loss(avg per step)=15.8304 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=12.2155 qwk=('0.6217', '0.6200', '0.5909') averageQWK=0.6109 macroEMD=0.3642 tailR0=('0.3030', '0.1333', '0.0000') tailR0avg=0.1455
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    5    1    0    0
     3   22   25    5    0
     4   19   78   22    3
     0    5   22   86    3
     0    0    3   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    1    0
     2   21   25    5    0
     0   16   69   33    1
     0    3   18  112    1
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   34   34    1    0
     0   23  109   19    0
     0    2   43   57    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=7.8139 
[epoch 30] step 4/44: loss=7.7220 
[epoch 30] step 6/44: loss=7.6651 
[epoch 30] step 8/44: loss=7.5408 
[epoch 30] step 10/44: loss=7.5491 
[epoch 30] step 12/44: loss=7.6310 
[epoch 30] step 14/44: loss=7.6627 
[epoch 30] step 16/44: loss=7.7264 
[epoch 30] step 18/44: loss=7.8254 
[epoch 30] step 20/44: loss=7.8910 
[epoch 30] step 22/44: loss=7.9310 
[epoch 30] step 24/44: loss=7.9310 
[epoch 30] step 26/44: loss=7.9998 
[epoch 30] step 28/44: loss=8.0262 
[epoch 30] step 30/44: loss=7.9936 
[epoch 30] step 32/44: loss=8.0155 
[epoch 30] step 34/44: loss=8.0191 
[epoch 30] step 36/44: loss=7.9913 
[epoch 30] step 38/44: loss=7.9662 
[epoch 30] step 40/44: loss=7.9263 
[epoch 30] step 42/44: loss=7.9123 
[epoch 30] step 44/44: loss=7.8765 
[epoch 30] train_loss(avg per step)=15.7529 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=10.6106 qwk=('0.6153', '0.5998', '0.5882') averageQWK=0.6011 macroEMD=0.3642 tailR0=('0.3384', '0.1750', '0.0000') tailR0avg=0.1711
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    0    0
     2   23   23    7    0
     4   22   59   36    5
     0    3   14   85   14
     0    0    2   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    1    0
     6   14   23   10    0
     0    8   69   41    1
     0    2   13  113    6
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   28   39    2    0
     0   17  106   28    0
     0    1   36   65    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=6.6023 
[epoch 31] step 4/44: loss=7.1596 
[epoch 31] step 6/44: loss=7.3020 
[epoch 31] step 8/44: loss=7.3149 
[epoch 31] step 10/44: loss=7.4706 
[epoch 31] step 12/44: loss=7.6642 
[epoch 31] step 14/44: loss=7.7968 
[epoch 31] step 16/44: loss=7.7898 
[epoch 31] step 18/44: loss=7.7455 
[epoch 31] step 20/44: loss=7.7914 
[epoch 31] step 22/44: loss=7.8462 
[epoch 31] step 24/44: loss=7.9219 
[epoch 31] step 26/44: loss=7.9766 
[epoch 31] step 28/44: loss=7.9285 
[epoch 31] step 30/44: loss=7.9267 
[epoch 31] step 32/44: loss=7.9081 
[epoch 31] step 34/44: loss=7.8579 
[epoch 31] step 36/44: loss=7.8379 
[epoch 31] step 38/44: loss=7.8183 
[epoch 31] step 40/44: loss=7.8219 
[epoch 31] step 42/44: loss=7.8206 
[epoch 31] step 44/44: loss=7.8626 
[epoch 31] train_loss(avg per step)=15.7252 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=12.5823 qwk=('0.6114', '0.5897', '0.6129') averageQWK=0.6047 macroEMD=0.3646 tailR0=('0.3157', '0.0833', '0.0000') tailR0avg=0.1330
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     2   16   32    5    0
     2    8   90   23    3
     0    2   26   78   10
     0    0    3   10    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     1   16   30    6    0
     0   11   71   36    1
     0    2   19  110    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   39   28    2    0
     0   25   99   27    0
     0    2   36   64    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=8.3459 
[epoch 32] step 4/44: loss=7.9067 
[epoch 32] step 6/44: loss=8.2260 
[epoch 32] step 8/44: loss=8.2071 
[epoch 32] step 10/44: loss=8.1941 
[epoch 32] step 12/44: loss=8.2569 
[epoch 32] step 14/44: loss=8.2269 
[epoch 32] step 16/44: loss=8.2276 
[epoch 32] step 18/44: loss=8.1556 
[epoch 32] step 20/44: loss=8.1289 
[epoch 32] step 22/44: loss=8.0668 
[epoch 32] step 24/44: loss=8.0174 
[epoch 32] step 26/44: loss=7.9967 
[epoch 32] step 28/44: loss=7.9821 
[epoch 32] step 30/44: loss=7.9153 
[epoch 32] step 32/44: loss=7.8842 
[epoch 32] step 34/44: loss=7.8556 
[epoch 32] step 36/44: loss=7.8478 
[epoch 32] step 38/44: loss=7.8644 
[epoch 32] step 40/44: loss=7.8294 
[epoch 32] step 42/44: loss=7.8689 
[epoch 32] step 44/44: loss=7.8863 
[epoch 32] train_loss(avg per step)=15.7725 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=11.8577 qwk=('0.6378', '0.5954', '0.5880') averageQWK=0.6071 macroEMD=0.3638 tailR0=('0.2601', '0.0833', '0.0000') tailR0avg=0.1145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    0    0
     1   23   26    5    0
     1   22   73   27    3
     0    4   17   85   10
     0    0    2   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     1   16   30    6    0
     0   12   75   31    1
     0    1   23  107    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   29   39    1    0
     0   17  112   22    0
     0    1   42   59    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=7.5391 
[epoch 33] step 4/44: loss=7.6933 
[epoch 33] step 6/44: loss=7.8597 
[epoch 33] step 8/44: loss=8.1137 
[epoch 33] step 10/44: loss=8.2236 
[epoch 33] step 12/44: loss=8.1787 
[epoch 33] step 14/44: loss=8.1146 
[epoch 33] step 16/44: loss=8.1502 
[epoch 33] step 18/44: loss=8.1383 
[epoch 33] step 20/44: loss=8.1183 
[epoch 33] step 22/44: loss=8.0634 
[epoch 33] step 24/44: loss=8.0631 
[epoch 33] step 26/44: loss=8.1337 
[epoch 33] step 28/44: loss=8.1138 
[epoch 33] step 30/44: loss=8.1086 
[epoch 33] step 32/44: loss=8.1228 
[epoch 33] step 34/44: loss=8.0786 
[epoch 33] step 36/44: loss=8.0555 
[epoch 33] step 38/44: loss=8.1159 
[epoch 33] step 40/44: loss=8.0997 
[epoch 33] step 42/44: loss=8.0978 
[epoch 33] step 44/44: loss=8.1025 
[epoch 33] train_loss(avg per step)=16.2050 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=10.9359 qwk=('0.6332', '0.6020', '0.5949') averageQWK=0.6101 macroEMD=0.3664 tailR0=('0.3384', '0.0833', '0.0000') tailR0avg=0.1406
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    0    0
     2   20   29    4    0
     2   20   79   22    3
     0    4   25   76   11
     0    0    2   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     3   18   26    6    0
     0   14   70   34    1
     0    2   21  108    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   32   36    1    0
     0   21  110   20    0
     0    1   43   58    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=7.6502 
[epoch 34] step 4/44: loss=7.4608 
[epoch 34] step 6/44: loss=7.6792 
[epoch 34] step 8/44: loss=7.6623 
[epoch 34] step 10/44: loss=7.7515 
[epoch 34] step 12/44: loss=7.7123 
[epoch 34] step 14/44: loss=7.6497 
[epoch 34] step 16/44: loss=7.7362 
[epoch 34] step 18/44: loss=7.7325 
[epoch 34] step 20/44: loss=7.7352 
[epoch 34] step 22/44: loss=7.7193 
[epoch 34] step 24/44: loss=7.7176 
[epoch 34] step 26/44: loss=7.7289 
[epoch 34] step 28/44: loss=7.7451 
[epoch 34] step 30/44: loss=7.7076 
[epoch 34] step 32/44: loss=7.7215 
[epoch 34] step 34/44: loss=7.7417 
[epoch 34] step 36/44: loss=7.7626 
[epoch 34] step 38/44: loss=7.7728 
[epoch 34] step 40/44: loss=7.7879 
[epoch 34] step 42/44: loss=7.7738 
[epoch 34] step 44/44: loss=7.7784 
[epoch 34] train_loss(avg per step)=15.5568 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=11.6832 qwk=('0.6255', '0.5973', '0.6075') averageQWK=0.6101 macroEMD=0.3653 tailR0=('0.3384', '0.0833', '0.0000') tailR0avg=0.1406
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     2   16   33    4    0
     1   11   90   20    4
     0    2   27   74   13
     0    0    2   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     2   18   25    8    0
     0   12   72   34    1
     0    2   17  112    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   35   33    1    0
     0   25  103   23    0
     0    1   40   61    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=8.1181 
[epoch 35] step 4/44: loss=8.3059 
[epoch 35] step 6/44: loss=8.0474 
[epoch 35] step 8/44: loss=7.9460 
[epoch 35] step 10/44: loss=7.9851 
[epoch 35] step 12/44: loss=7.8860 
[epoch 35] step 14/44: loss=7.9487 
[epoch 35] step 16/44: loss=7.9862 
[epoch 35] step 18/44: loss=8.0421 
[epoch 35] step 20/44: loss=7.9780 
[epoch 35] step 22/44: loss=8.0030 
[epoch 35] step 24/44: loss=7.9974 
[epoch 35] step 26/44: loss=8.0346 
[epoch 35] step 28/44: loss=8.0266 
[epoch 35] step 30/44: loss=8.0192 
[epoch 35] step 32/44: loss=7.9837 
[epoch 35] step 34/44: loss=7.9522 
[epoch 35] step 36/44: loss=7.9138 
[epoch 35] step 38/44: loss=7.9160 
[epoch 35] step 40/44: loss=7.8972 
[epoch 35] step 42/44: loss=7.9192 
[epoch 35] step 44/44: loss=7.9417 
[epoch 35] train_loss(avg per step)=15.8835 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=11.6384 qwk=('0.6228', '0.5918', '0.6043') averageQWK=0.6063 macroEMD=0.3651 tailR0=('0.3384', '0.0833', '0.0000') tailR0avg=0.1406
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     2   18   30    5    0
     2   15   79   26    4
     0    4   18   82   12
     0    0    2   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     2   18   24    9    0
     0   12   71   35    1
     0    2   16  113    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   32   36    1    0
     0   19  109   23    0
     0    1   40   61    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-0-reassignment-1/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-0-reassignment-1/fold3/metrics.json
Done.
