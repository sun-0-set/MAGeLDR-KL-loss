[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.4113 
[epoch 1] step 4/44: loss=6.0940 
[epoch 1] step 6/44: loss=5.7573 
[epoch 1] step 8/44: loss=5.8407 
[epoch 1] step 10/44: loss=5.8594 
[epoch 1] step 12/44: loss=5.8655 
[epoch 1] step 14/44: loss=5.8722 
[epoch 1] step 16/44: loss=5.9353 
[epoch 1] step 18/44: loss=5.9133 
[epoch 1] step 20/44: loss=5.9508 
[epoch 1] step 22/44: loss=5.9287 
[epoch 1] step 24/44: loss=5.9600 
[epoch 1] step 26/44: loss=5.9713 
[epoch 1] step 28/44: loss=5.9649 
[epoch 1] step 30/44: loss=5.9694 
[epoch 1] step 32/44: loss=5.9623 
[epoch 1] step 34/44: loss=5.9821 
[epoch 1] step 36/44: loss=5.9263 
[epoch 1] step 38/44: loss=5.8626 
[epoch 1] step 40/44: loss=5.7914 
[epoch 1] step 42/44: loss=5.7484 
[epoch 1] step 44/44: loss=5.6565 
[epoch 1] train_loss(avg per step)=11.3130 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=5.5547 qwk=('0.1526', '0.2053', '0.0130') averageQWK=0.1236 macroEMD=0.3712 tailR0=('0.0000', '0.2222', '0.0000') tailR0avg=0.0741
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    5    0
     0   18    0   37    0
     0   30    0   95    0
     0   22    0   94    0
     0    3    0   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    0    4    1    0
    15    0   37    1    0
    23    0   87   12    0
    18    0   84   31    0
     0    0   10    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    2   67    0    0
     0    1  151    0    0
     0    1  100    0    0
     0    0    2    0    0
[epoch 2] step 2/44: loss=4.0497 
[epoch 2] step 4/44: loss=4.1140 
[epoch 2] step 6/44: loss=4.0914 
[epoch 2] step 8/44: loss=4.0025 
[epoch 2] step 10/44: loss=3.9210 
[epoch 2] step 12/44: loss=3.9441 
[epoch 2] step 14/44: loss=3.8966 
[epoch 2] step 16/44: loss=3.9053 
[epoch 2] step 18/44: loss=3.8921 
[epoch 2] step 20/44: loss=3.8216 
[epoch 2] step 22/44: loss=3.7173 
[epoch 2] step 24/44: loss=3.6371 
[epoch 2] step 26/44: loss=3.5529 
[epoch 2] step 28/44: loss=3.5070 
[epoch 2] step 30/44: loss=3.4595 
[epoch 2] step 32/44: loss=3.4191 
[epoch 2] step 34/44: loss=3.3920 
[epoch 2] step 36/44: loss=3.3663 
[epoch 2] step 38/44: loss=3.3293 
[epoch 2] step 40/44: loss=3.3085 
[epoch 2] step 42/44: loss=3.2890 
[epoch 2] step 44/44: loss=3.2747 
[epoch 2] train_loss(avg per step)=6.5493 lambda[min,max]=[0.500463,1.000000]
[epoch 2] val_loss=4.0350 qwk=('0.3584', '0.1679', '0.2620') averageQWK=0.2628 macroEMD=0.3811 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    1    0
     0   31   12   12    0
     0   36   43   46    0
     0   17   12   87    0
     0    5    4   14    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    4    0
     0    0   15   38    0
     0    0   16  106    0
     0    0    0  133    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0    2   39   28    0
     0    0   45  107    0
     0    0    7   94    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=2.7403 
[epoch 3] step 4/44: loss=2.6889 
[epoch 3] step 6/44: loss=2.7237 
[epoch 3] step 8/44: loss=2.6827 
[epoch 3] step 10/44: loss=2.7482 
[epoch 3] step 12/44: loss=2.7406 
[epoch 3] step 14/44: loss=2.7468 
[epoch 3] step 16/44: loss=2.7422 
[epoch 3] step 18/44: loss=2.7404 
[epoch 3] step 20/44: loss=2.7313 
[epoch 3] step 22/44: loss=2.7390 
[epoch 3] step 24/44: loss=2.7437 
[epoch 3] step 26/44: loss=2.7448 
[epoch 3] step 28/44: loss=2.7290 
[epoch 3] step 30/44: loss=2.7425 
[epoch 3] step 32/44: loss=2.7496 
[epoch 3] step 34/44: loss=2.7368 
[epoch 3] step 36/44: loss=2.7248 
[epoch 3] step 38/44: loss=2.7097 
[epoch 3] step 40/44: loss=2.7064 
[epoch 3] step 42/44: loss=2.6834 
[epoch 3] step 44/44: loss=2.6963 
[epoch 3] train_loss(avg per step)=5.3927 lambda[min,max]=[0.500214,1.000000]
[epoch 3] val_loss=3.9289 qwk=('0.3709', '0.0673', '0.3972') averageQWK=0.2785 macroEMD=0.3672 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     0   10   45    0    0
     0    7  113    5    0
     0    0   73   43    0
     0    0   14    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    1   52    0    0
     0    1  120    1    0
     0    0  122   11    0
     0    0   12    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   22   47    0    0
     0   19  125    8    0
     0    0   77   24    0
     0    0    2    0    0
[epoch 4] step 2/44: loss=3.1263 
[epoch 4] step 4/44: loss=2.7354 
[epoch 4] step 6/44: loss=2.7042 
[epoch 4] step 8/44: loss=2.6612 
[epoch 4] step 10/44: loss=2.6423 
[epoch 4] step 12/44: loss=2.6202 
[epoch 4] step 14/44: loss=2.6097 
[epoch 4] step 16/44: loss=2.5856 
[epoch 4] step 18/44: loss=2.5421 
[epoch 4] step 20/44: loss=2.5531 
[epoch 4] step 22/44: loss=2.5401 
[epoch 4] step 24/44: loss=2.5066 
[epoch 4] step 26/44: loss=2.4938 
[epoch 4] step 28/44: loss=2.4743 
[epoch 4] step 30/44: loss=2.4996 
[epoch 4] step 32/44: loss=2.5229 
[epoch 4] step 34/44: loss=2.5135 
[epoch 4] step 36/44: loss=2.5008 
[epoch 4] step 38/44: loss=2.5073 
[epoch 4] step 40/44: loss=2.5024 
[epoch 4] step 42/44: loss=2.4965 
[epoch 4] step 44/44: loss=2.4806 
[epoch 4] train_loss(avg per step)=4.9612 lambda[min,max]=[0.504312,1.000000]
[epoch 4] val_loss=4.0644 qwk=('0.4324', '0.4899', '0.4509') averageQWK=0.4577 macroEMD=0.3498 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    3   42   10    0
     0    4   63   58    0
     0    0   15  101    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0    5   36   12    0
     0    6   59   57    0
     0    0    8  125    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   19   32   18    0
     0    9   48   95    0
     0    0    5   96    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=2.3410 
[epoch 5] step 4/44: loss=2.1960 
[epoch 5] step 6/44: loss=2.2212 
[epoch 5] step 8/44: loss=2.2215 
[epoch 5] step 10/44: loss=2.2122 
[epoch 5] step 12/44: loss=2.2647 
[epoch 5] step 14/44: loss=2.2536 
[epoch 5] step 16/44: loss=2.2103 
[epoch 5] step 18/44: loss=2.2354 
[epoch 5] step 20/44: loss=2.2299 
[epoch 5] step 22/44: loss=2.2156 
[epoch 5] step 24/44: loss=2.2093 
[epoch 5] step 26/44: loss=2.2015 
[epoch 5] step 28/44: loss=2.1753 
[epoch 5] step 30/44: loss=2.1825 
[epoch 5] step 32/44: loss=2.1896 
[epoch 5] step 34/44: loss=2.1972 
[epoch 5] step 36/44: loss=2.1931 
[epoch 5] step 38/44: loss=2.1959 
[epoch 5] step 40/44: loss=2.1713 
[epoch 5] step 42/44: loss=2.1694 
[epoch 5] step 44/44: loss=2.1597 
[epoch 5] train_loss(avg per step)=4.3194 lambda[min,max]=[0.504734,1.000000]
[epoch 5] val_loss=3.7206 qwk=('0.5626', '0.5271', '0.4316') averageQWK=0.5071 macroEMD=0.3374 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   17   32    6    0
     0   10   67   48    0
     0    0   17   99    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   15   26   12    0
     0   12   58   52    0
     0    0   15  118    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0    4   65    0    0
     0    3  124   25    0
     0    0   43   58    0
     0    0    1    1    0
[epoch 6] step 2/44: loss=1.8781 
[epoch 6] step 4/44: loss=1.9936 
[epoch 6] step 6/44: loss=2.0690 
[epoch 6] step 8/44: loss=2.0812 
[epoch 6] step 10/44: loss=2.0933 
[epoch 6] step 12/44: loss=2.1056 
[epoch 6] step 14/44: loss=2.0867 
[epoch 6] step 16/44: loss=2.0783 
[epoch 6] step 18/44: loss=2.1092 
[epoch 6] step 20/44: loss=2.1225 
[epoch 6] step 22/44: loss=2.1089 
[epoch 6] step 24/44: loss=2.1067 
[epoch 6] step 26/44: loss=2.1077 
[epoch 6] step 28/44: loss=2.0822 
[epoch 6] step 30/44: loss=2.0817 
[epoch 6] step 32/44: loss=2.0682 
[epoch 6] step 34/44: loss=2.0554 
[epoch 6] step 36/44: loss=2.0552 
[epoch 6] step 38/44: loss=2.0475 
[epoch 6] step 40/44: loss=2.0400 
[epoch 6] step 42/44: loss=2.0425 
[epoch 6] step 44/44: loss=2.0367 
[epoch 6] train_loss(avg per step)=4.0733 lambda[min,max]=[0.521428,1.000000]
[epoch 6] val_loss=3.4672 qwk=('0.5599', '0.4969', '0.5235') averageQWK=0.5268 macroEMD=0.3321 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   13   39    3    0
     0    7   89   29    0
     0    0   30   86    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   19   31    3    0
     1   14   91   16    0
     0    0   62   71    0
     0    0    5    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   27   42    0    0
     0   15  120   17    0
     0    0   55   46    0
     0    0    2    0    0
[epoch 7] step 2/44: loss=1.7208 
[epoch 7] step 4/44: loss=1.6906 
[epoch 7] step 6/44: loss=1.6816 
[epoch 7] step 8/44: loss=1.6797 
[epoch 7] step 10/44: loss=1.7236 
[epoch 7] step 12/44: loss=1.7350 
[epoch 7] step 14/44: loss=1.7846 
[epoch 7] step 16/44: loss=1.7881 
[epoch 7] step 18/44: loss=1.7989 
[epoch 7] step 20/44: loss=1.7937 
[epoch 7] step 22/44: loss=1.7922 
[epoch 7] step 24/44: loss=1.7861 
[epoch 7] step 26/44: loss=1.7909 
[epoch 7] step 28/44: loss=1.7879 
[epoch 7] step 30/44: loss=1.8024 
[epoch 7] step 32/44: loss=1.7955 
[epoch 7] step 34/44: loss=1.7826 
[epoch 7] step 36/44: loss=1.7745 
[epoch 7] step 38/44: loss=1.7894 
[epoch 7] step 40/44: loss=1.7984 
[epoch 7] step 42/44: loss=1.8061 
[epoch 7] step 44/44: loss=1.8054 
[epoch 7] train_loss(avg per step)=3.6107 lambda[min,max]=[0.504032,1.000000]
[epoch 7] val_loss=3.7777 qwk=('0.5075', '0.5094', '0.4677') averageQWK=0.4949 macroEMD=0.3301 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    2   49    4    0
     0    2   73   50    0
     0    0   13  103    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0    8   34   11    0
     0    0   69   53    0
     0    0    9  124    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    5   64    0    0
     0    2  112   38    0
     0    0   30   71    0
     0    0    1    1    0
[epoch 8] step 2/44: loss=1.6954 
[epoch 8] step 4/44: loss=1.6684 
[epoch 8] step 6/44: loss=1.7109 
[epoch 8] step 8/44: loss=1.7667 
[epoch 8] step 10/44: loss=1.7473 
[epoch 8] step 12/44: loss=1.7552 
[epoch 8] step 14/44: loss=1.7620 
[epoch 8] step 16/44: loss=1.7695 
[epoch 8] step 18/44: loss=1.7409 
[epoch 8] step 20/44: loss=1.7147 
[epoch 8] step 22/44: loss=1.7062 
[epoch 8] step 24/44: loss=1.6950 
[epoch 8] step 26/44: loss=1.7149 
[epoch 8] step 28/44: loss=1.6838 
[epoch 8] step 30/44: loss=1.6860 
[epoch 8] step 32/44: loss=1.6835 
[epoch 8] step 34/44: loss=1.6798 
[epoch 8] step 36/44: loss=1.6733 
[epoch 8] step 38/44: loss=1.6600 
[epoch 8] step 40/44: loss=1.6736 
[epoch 8] step 42/44: loss=1.7012 
[epoch 8] step 44/44: loss=1.7026 
[epoch 8] train_loss(avg per step)=3.4053 lambda[min,max]=[0.500673,1.000000]
[epoch 8] val_loss=3.4653 qwk=('0.4768', '0.6335', '0.5467') averageQWK=0.5524 macroEMD=0.3160 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   12   43    0    0
     0    8  104   13    0
     0    0   54   62    0
     0    0   11   12    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   29   18    6    0
     0   22   72   28    0
     0    2   34   97    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   24   43    2    0
     0   11  107   34    0
     0    0   34   67    0
     0    0    2    0    0
[epoch 9] step 2/44: loss=1.6791 
[epoch 9] step 4/44: loss=1.6262 
[epoch 9] step 6/44: loss=1.6853 
[epoch 9] step 8/44: loss=1.6935 
[epoch 9] step 10/44: loss=1.6177 
[epoch 9] step 12/44: loss=1.6206 
[epoch 9] step 14/44: loss=1.6446 
[epoch 9] step 16/44: loss=1.6575 
[epoch 9] step 18/44: loss=1.6538 
[epoch 9] step 20/44: loss=1.6219 
[epoch 9] step 22/44: loss=1.6194 
[epoch 9] step 24/44: loss=1.6147 
[epoch 9] step 26/44: loss=1.5957 
[epoch 9] step 28/44: loss=1.5898 
[epoch 9] step 30/44: loss=1.5776 
[epoch 9] step 32/44: loss=1.5768 
[epoch 9] step 34/44: loss=1.5651 
[epoch 9] step 36/44: loss=1.5511 
[epoch 9] step 38/44: loss=1.5487 
[epoch 9] step 40/44: loss=1.5545 
[epoch 9] step 42/44: loss=1.5460 
[epoch 9] step 44/44: loss=1.5415 
[epoch 9] train_loss(avg per step)=3.0830 lambda[min,max]=[0.500028,1.000000]
[epoch 9] val_loss=3.9551 qwk=('0.5780', '0.5729', '0.5329') averageQWK=0.5613 macroEMD=0.3184 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   29   26    0    0
     0   17   95   13    0
     0    1   53   62    0
     0    0    7   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    0    0
     0   44    5    4    0
     0   74   22   26    0
     0   18   14  101    0
     0    1    1   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   53   16    0    0
     0   53   84   15    0
     0    6   56   39    0
     0    0    2    0    0
[epoch 10] step 2/44: loss=1.8801 
[epoch 10] step 4/44: loss=1.7867 
[epoch 10] step 6/44: loss=1.6953 
[epoch 10] step 8/44: loss=1.6382 
[epoch 10] step 10/44: loss=1.6398 
[epoch 10] step 12/44: loss=1.5843 
[epoch 10] step 14/44: loss=1.5323 
[epoch 10] step 16/44: loss=1.5141 
[epoch 10] step 18/44: loss=1.5207 
[epoch 10] step 20/44: loss=1.5209 
[epoch 10] step 22/44: loss=1.5023 
[epoch 10] step 24/44: loss=1.4852 
[epoch 10] step 26/44: loss=1.4673 
[epoch 10] step 28/44: loss=1.4684 
[epoch 10] step 30/44: loss=1.4668 
[epoch 10] step 32/44: loss=1.4649 
[epoch 10] step 34/44: loss=1.4509 
[epoch 10] step 36/44: loss=1.4382 
[epoch 10] step 38/44: loss=1.4414 
[epoch 10] step 40/44: loss=1.4374 
[epoch 10] step 42/44: loss=1.4250 
[epoch 10] step 44/44: loss=1.4156 
[epoch 10] train_loss(avg per step)=2.8313 lambda[min,max]=[0.500044,1.000000]
[epoch 10] val_loss=3.7511 qwk=('0.4971', '0.5695', '0.4944') averageQWK=0.5203 macroEMD=0.3035 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    1    0
     0    6   48    1    0
     0    4   95   26    0
     0    0   41   73    2
     0    0    4   18    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     1   14   29    9    0
     0    9   75   38    0
     0    0   19  114    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   14   54    1    0
     0    5  122   25    0
     0    0   42   59    0
     0    0    1    1    0
[epoch 11] step 2/44: loss=1.1001 
[epoch 11] step 4/44: loss=1.1297 
[epoch 11] step 6/44: loss=1.1509 
[epoch 11] step 8/44: loss=1.1830 
[epoch 11] step 10/44: loss=1.2153 
[epoch 11] step 12/44: loss=1.2053 
[epoch 11] step 14/44: loss=1.1992 
[epoch 11] step 16/44: loss=1.1932 
[epoch 11] step 18/44: loss=1.1699 
[epoch 11] step 20/44: loss=1.1785 
[epoch 11] step 22/44: loss=1.1979 
[epoch 11] step 24/44: loss=1.2004 
[epoch 11] step 26/44: loss=1.2163 
[epoch 11] step 28/44: loss=1.2355 
[epoch 11] step 30/44: loss=1.2296 
[epoch 11] step 32/44: loss=1.2188 
[epoch 11] step 34/44: loss=1.2198 
[epoch 11] step 36/44: loss=1.2181 
[epoch 11] step 38/44: loss=1.2223 
[epoch 11] step 40/44: loss=1.2062 
[epoch 11] step 42/44: loss=1.1986 
[epoch 11] step 44/44: loss=1.2100 
[epoch 11] train_loss(avg per step)=2.4200 lambda[min,max]=[0.500006,1.000000]
[epoch 11] val_loss=3.7279 qwk=('0.5957', '0.5981', '0.5835') averageQWK=0.5924 macroEMD=0.2930 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   18   36    1    0
     0   10   83   32    0
     0    0   32   84    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   26   22    5    0
     0   20   73   29    0
     0    1   34   97    1
     0    0    3    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   37   32    0    0
     0   21  103   28    0
     0    1   42   58    0
     0    0    2    0    0
[epoch 12] step 2/44: loss=0.9901 
[epoch 12] step 4/44: loss=1.0458 
[epoch 12] step 6/44: loss=1.0451 
[epoch 12] step 8/44: loss=0.9972 
[epoch 12] step 10/44: loss=1.0642 
[epoch 12] step 12/44: loss=1.0908 
[epoch 12] step 14/44: loss=1.0710 
[epoch 12] step 16/44: loss=1.0517 
[epoch 12] step 18/44: loss=1.0551 
[epoch 12] step 20/44: loss=1.0562 
[epoch 12] step 22/44: loss=1.0401 
[epoch 12] step 24/44: loss=1.0438 
[epoch 12] step 26/44: loss=1.0360 
[epoch 12] step 28/44: loss=1.0310 
[epoch 12] step 30/44: loss=1.0223 
[epoch 12] step 32/44: loss=1.0225 
[epoch 12] step 34/44: loss=1.0245 
[epoch 12] step 36/44: loss=1.0227 
[epoch 12] step 38/44: loss=1.0290 
[epoch 12] step 40/44: loss=1.0291 
[epoch 12] step 42/44: loss=1.0286 
[epoch 12] step 44/44: loss=1.0480 
[epoch 12] train_loss(avg per step)=2.0960 lambda[min,max]=[0.500001,1.000000]
[epoch 12] val_loss=3.8723 qwk=('0.5846', '0.5706', '0.5262') averageQWK=0.5605 macroEMD=0.2993 tailR0=('0.1804', '0.0417', '0.0000') tailR0avg=0.0740
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    1    0
     1   11   40    3    0
     0    6   86   32    1
     0    0   29   78    9
     0    0    3   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     1   15   31    6    0
     1    6   81   32    2
     0    0   25  104    4
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   23   46    0    0
     0    9  124   19    0
     0    0   46   55    0
     0    0    2    0    0
[epoch 13] step 2/44: loss=0.8501 
[epoch 13] step 4/44: loss=0.8626 
[epoch 13] step 6/44: loss=0.8679 
[epoch 13] step 8/44: loss=0.8669 
[epoch 13] step 10/44: loss=0.8491 
[epoch 13] step 12/44: loss=0.8471 
[epoch 13] step 14/44: loss=0.8509 
[epoch 13] step 16/44: loss=0.9171 
[epoch 13] step 18/44: loss=0.9379 
[epoch 13] step 20/44: loss=0.9608 
[epoch 13] step 22/44: loss=0.9471 
[epoch 13] step 24/44: loss=0.9518 
[epoch 13] step 26/44: loss=0.9457 
[epoch 13] step 28/44: loss=0.9452 
[epoch 13] step 30/44: loss=0.9463 
[epoch 13] step 32/44: loss=0.9409 
[epoch 13] step 34/44: loss=0.9381 
[epoch 13] step 36/44: loss=0.9387 
[epoch 13] step 38/44: loss=0.9384 
[epoch 13] step 40/44: loss=0.9350 
[epoch 13] step 42/44: loss=0.9388 
[epoch 13] step 44/44: loss=0.9470 
[epoch 13] train_loss(avg per step)=1.8941 lambda[min,max]=[0.500002,1.000000]
[epoch 13] val_loss=4.0448 qwk=('0.5654', '0.6072', '0.5269') averageQWK=0.5665 macroEMD=0.2834 tailR0=('0.0870', '0.1250', '0.0000') tailR0avg=0.0707
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   14   40    1    0
     0    9   96   20    0
     0    0   44   68    4
     0    0    4   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     1   18   29    5    0
     1   13   83   23    2
     0    0   35   95    3
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   23   46    0    0
     0   11  110   31    0
     0    0   45   56    0
     0    0    1    1    0
[epoch 14] step 2/44: loss=0.9308 
[epoch 14] step 4/44: loss=0.8491 
[epoch 14] step 6/44: loss=0.8622 
[epoch 14] step 8/44: loss=0.8275 
[epoch 14] step 10/44: loss=0.8377 
[epoch 14] step 12/44: loss=0.8409 
[epoch 14] step 14/44: loss=0.8248 
[epoch 14] step 16/44: loss=0.8101 
[epoch 14] step 18/44: loss=0.7874 
[epoch 14] step 20/44: loss=0.7865 
[epoch 14] step 22/44: loss=0.7681 
[epoch 14] step 24/44: loss=0.7515 
[epoch 14] step 26/44: loss=0.7549 
[epoch 14] step 28/44: loss=0.7517 
[epoch 14] step 30/44: loss=0.7408 
[epoch 14] step 32/44: loss=0.7441 
[epoch 14] step 34/44: loss=0.7432 
[epoch 14] step 36/44: loss=0.7465 
[epoch 14] step 38/44: loss=0.7591 
[epoch 14] step 40/44: loss=0.7586 
[epoch 14] step 42/44: loss=0.7520 
[epoch 14] step 44/44: loss=0.7432 
[epoch 14] train_loss(avg per step)=1.4865 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=4.7569 qwk=('0.5564', '0.5912', '0.4966') averageQWK=0.5480 macroEMD=0.2800 tailR0=('0.1739', '0.0417', '0.0000') tailR0avg=0.0719
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   14   39    2    0
     0    9   88   25    3
     0    0   43   59   14
     0    0    5   10    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     1   22   21    9    0
     2   13   69   35    3
     0    1   20  108    4
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   20   49    0    0
     0   10  124   18    0
     0    0   49   52    0
     0    0    2    0    0
[epoch 15] step 2/44: loss=0.6703 
[epoch 15] step 4/44: loss=0.6188 
[epoch 15] step 6/44: loss=0.6465 
[epoch 15] step 8/44: loss=0.5979 
[epoch 15] step 10/44: loss=0.6086 
[epoch 15] step 12/44: loss=0.6024 
[epoch 15] step 14/44: loss=0.5853 
[epoch 15] step 16/44: loss=0.5693 
[epoch 15] step 18/44: loss=0.5832 
[epoch 15] step 20/44: loss=0.5836 
[epoch 15] step 22/44: loss=0.5818 
[epoch 15] step 24/44: loss=0.5769 
[epoch 15] step 26/44: loss=0.5889 
[epoch 15] step 28/44: loss=0.5935 
[epoch 15] step 30/44: loss=0.5852 
[epoch 15] step 32/44: loss=0.6024 
[epoch 15] step 34/44: loss=0.6032 
[epoch 15] step 36/44: loss=0.6052 
[epoch 15] step 38/44: loss=0.6113 
[epoch 15] step 40/44: loss=0.6084 
[epoch 15] step 42/44: loss=0.6089 
[epoch 15] step 44/44: loss=0.6015 
[epoch 15] train_loss(avg per step)=1.2031 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=4.6507 qwk=('0.6076', '0.5140', '0.4842') averageQWK=0.5353 macroEMD=0.2800 tailR0=('0.2674', '0.0972', '0.0000') tailR0avg=0.1215
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     2   15   37    1    0
     0    9   89   22    5
     0    0   41   65   10
     0    0    3   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   17   32    3    0
     3    4   96   14    5
     0    0   52   71   10
     0    0    5    6    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   28   41    0    0
     0   17  117   18    0
     0    0   61   40    0
     0    0    2    0    0
[epoch 16] step 2/44: loss=0.8195 
[epoch 16] step 4/44: loss=0.6292 
[epoch 16] step 6/44: loss=0.5746 
[epoch 16] step 8/44: loss=0.5388 
[epoch 16] step 10/44: loss=0.5266 
[epoch 16] step 12/44: loss=0.5444 
[epoch 16] step 14/44: loss=0.5427 
[epoch 16] step 16/44: loss=0.5139 
[epoch 16] step 18/44: loss=0.5162 
[epoch 16] step 20/44: loss=0.5096 
[epoch 16] step 22/44: loss=0.5164 
[epoch 16] step 24/44: loss=0.5136 
[epoch 16] step 26/44: loss=0.4979 
[epoch 16] step 28/44: loss=0.4859 
[epoch 16] step 30/44: loss=0.4829 
[epoch 16] step 32/44: loss=0.4857 
[epoch 16] step 34/44: loss=0.4769 
[epoch 16] step 36/44: loss=0.4774 
[epoch 16] step 38/44: loss=0.4724 
[epoch 16] step 40/44: loss=0.4762 
[epoch 16] step 42/44: loss=0.4764 
[epoch 16] step 44/44: loss=0.4755 
[epoch 16] train_loss(avg per step)=0.9511 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=5.3610 qwk=('0.5628', '0.5159', '0.4452') averageQWK=0.5080 macroEMD=0.2769 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     0   11   39    5    0
     0    4   76   42    3
     0    0   22   86    8
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     1   11   35    6    0
     3    1   77   38    3
     0    0   21  109    3
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   16   53    0    0
     0    7  120   25    0
     0    0   53   48    0
     0    0    2    0    0
[epoch 17] step 2/44: loss=0.3886 
[epoch 17] step 4/44: loss=0.3850 
[epoch 17] step 6/44: loss=0.3779 
[epoch 17] step 8/44: loss=0.3921 
[epoch 17] step 10/44: loss=0.3572 
[epoch 17] step 12/44: loss=0.3575 
[epoch 17] step 14/44: loss=0.3345 
[epoch 17] step 16/44: loss=0.3301 
[epoch 17] step 18/44: loss=0.3285 
[epoch 17] step 20/44: loss=0.3322 
[epoch 17] step 22/44: loss=0.3308 
[epoch 17] step 24/44: loss=0.3221 
[epoch 17] step 26/44: loss=0.3134 
[epoch 17] step 28/44: loss=0.3127 
[epoch 17] step 30/44: loss=0.3103 
[epoch 17] step 32/44: loss=0.3180 
[epoch 17] step 34/44: loss=0.3231 
[epoch 17] step 36/44: loss=0.3237 
[epoch 17] step 38/44: loss=0.3209 
[epoch 17] step 40/44: loss=0.3242 
[epoch 17] step 42/44: loss=0.3288 
[epoch 17] step 44/44: loss=0.3348 
[epoch 17] train_loss(avg per step)=0.6696 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=5.0429 qwk=('0.6410', '0.6249', '0.5860') averageQWK=0.6173 macroEMD=0.2561 tailR0=('0.2391', '0.1667', '0.0000') tailR0avg=0.1353
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     1   24   26    4    0
     0   17   59   47    2
     0    1   19   86   10
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     1   23   23    6    0
     2   17   71   28    4
     0    2   20  105    6
     0    0    2    6    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   27   41    1    0
     0   14  103   35    0
     0    0   33   68    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=0.3352 
[epoch 18] step 4/44: loss=0.2969 
[epoch 18] step 6/44: loss=0.3142 
[epoch 18] step 8/44: loss=0.3109 
[epoch 18] step 10/44: loss=0.2869 
[epoch 18] step 12/44: loss=0.2754 
[epoch 18] step 14/44: loss=0.2673 
[epoch 18] step 16/44: loss=0.2735 
[epoch 18] step 18/44: loss=0.2711 
[epoch 18] step 20/44: loss=0.2726 
[epoch 18] step 22/44: loss=0.2768 
[epoch 18] step 24/44: loss=0.2775 
[epoch 18] step 26/44: loss=0.2779 
[epoch 18] step 28/44: loss=0.2689 
[epoch 18] step 30/44: loss=0.2629 
[epoch 18] step 32/44: loss=0.2650 
[epoch 18] step 34/44: loss=0.2665 
[epoch 18] step 36/44: loss=0.2583 
[epoch 18] step 38/44: loss=0.2567 
[epoch 18] step 40/44: loss=0.2585 
[epoch 18] step 42/44: loss=0.2564 
[epoch 18] step 44/44: loss=0.2444 
[epoch 18] train_loss(avg per step)=0.4888 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=5.5466 qwk=('0.5994', '0.6104', '0.5212') averageQWK=0.5770 macroEMD=0.2589 tailR0=('0.1957', '0.0417', '0.0000') tailR0avg=0.0791
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   18   33    4    0
     0   10   74   36    5
     0    0   27   76   13
     0    0    2   12    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   20   27    6    0
     1   10   78   31    2
     0    1   19  109    4
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   21   48    0    0
     0   14  108   30    0
     0    0   41   60    0
     0    0    1    1    0
[epoch 19] step 2/44: loss=0.0276 
[epoch 19] step 4/44: loss=0.0551 
[epoch 19] step 6/44: loss=0.0135 
[epoch 19] step 8/44: loss=0.0450 
[epoch 19] step 10/44: loss=0.0539 
[epoch 19] step 12/44: loss=0.0554 
[epoch 19] step 14/44: loss=0.0857 
[epoch 19] step 16/44: loss=0.1002 
[epoch 19] step 18/44: loss=0.0990 
[epoch 19] step 20/44: loss=0.1042 
[epoch 19] step 22/44: loss=0.1042 
[epoch 19] step 24/44: loss=0.1031 
[epoch 19] step 26/44: loss=0.1158 
[epoch 19] step 28/44: loss=0.1232 
[epoch 19] step 30/44: loss=0.1433 
[epoch 19] step 32/44: loss=0.1425 
[epoch 19] step 34/44: loss=0.1430 
[epoch 19] step 36/44: loss=0.1431 
[epoch 19] step 38/44: loss=0.1364 
[epoch 19] step 40/44: loss=0.1221 
[epoch 19] step 42/44: loss=0.1245 
[epoch 19] step 44/44: loss=0.1263 
[epoch 19] train_loss(avg per step)=0.2527 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=5.7411 qwk=('0.5723', '0.6005', '0.5663') averageQWK=0.5797 macroEMD=0.2599 tailR0=('0.1739', '0.1667', '0.0000') tailR0avg=0.1135
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   13   37    5    0
     0    4   81   35    5
     0    0   26   82    8
     0    0    1   14    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   15   31    7    0
     2   10   72   35    3
     0    0   17  109    7
     0    0    0    8    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   24   45    0    0
     0   13   99   40    0
     0    0   32   69    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=0.0069 
[epoch 20] step 4/44: loss=0.0551 
[epoch 20] step 6/44: loss=0.0728 
[epoch 20] step 8/44: loss=0.0583 
[epoch 20] step 10/44: loss=0.0477 
[epoch 20] step 12/44: loss=0.0317 
[epoch 20] step 14/44: loss=0.0491 
[epoch 20] step 16/44: loss=0.0459 
[epoch 20] step 18/44: loss=0.0418 
[epoch 20] step 20/44: loss=0.0273 
[epoch 20] step 22/44: loss=0.0314 
[epoch 20] step 24/44: loss=0.0394 
[epoch 20] step 26/44: loss=0.0295 
[epoch 20] step 28/44: loss=0.0330 
[epoch 20] step 30/44: loss=0.0263 
[epoch 20] step 32/44: loss=0.0262 
[epoch 20] step 34/44: loss=0.0353 
[epoch 20] step 36/44: loss=0.0342 
[epoch 20] step 38/44: loss=0.0303 
[epoch 20] step 40/44: loss=0.0350 
[epoch 20] step 42/44: loss=0.0518 
[epoch 20] step 44/44: loss=0.0558 
[epoch 20] train_loss(avg per step)=0.1116 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=5.5819 qwk=('0.6273', '0.6110', '0.5226') averageQWK=0.5870 macroEMD=0.2582 tailR0=('0.4391', '0.0417', '0.0000') tailR0avg=0.1603
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    3    2    1    0
     1   14   38    2    0
     0    9   85   28    3
     0    0   33   71   12
     0    0    4    8   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   25   22    6    0
     1   18   69   32    2
     0    2   22  104    5
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   31   38    0    0
     0   17  114   21    0
     0    1   52   48    0
     0    0    2    0    0
[epoch 21] step 2/44: loss=-0.1102 
[epoch 21] step 4/44: loss=-0.0923 
[epoch 21] step 6/44: loss=-0.0225 
[epoch 21] step 8/44: loss=-0.0073 
[epoch 21] step 10/44: loss=-0.0071 
[epoch 21] step 12/44: loss=0.0150 
[epoch 21] step 14/44: loss=0.0167 
[epoch 21] step 16/44: loss=0.0296 
[epoch 21] step 18/44: loss=0.0268 
[epoch 21] step 20/44: loss=0.0201 
[epoch 21] step 22/44: loss=0.0076 
[epoch 21] step 24/44: loss=0.0226 
[epoch 21] step 26/44: loss=0.0293 
[epoch 21] step 28/44: loss=0.0294 
[epoch 21] step 30/44: loss=0.0175 
[epoch 21] step 32/44: loss=0.0091 
[epoch 21] step 34/44: loss=0.0082 
[epoch 21] step 36/44: loss=0.0070 
[epoch 21] step 38/44: loss=0.0114 
[epoch 21] step 40/44: loss=0.0086 
[epoch 21] step 42/44: loss=0.0076 
[epoch 21] step 44/44: loss=0.0024 
[epoch 21] train_loss(avg per step)=0.0047 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=6.0561 qwk=('0.6044', '0.5364', '0.5398') averageQWK=0.5602 macroEMD=0.2555 tailR0=('0.3239', '0.0833', '0.0000') tailR0avg=0.1357
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    4    1    0
     2    9   42    2    0
     1    2   83   35    4
     0    0   26   82    8
     0    0    1   14    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     1   14   30    8    0
     3    7   66   43    3
     0    0   19  109    5
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   28   41    0    0
     0   20  107   25    0
     0    1   42   58    0
     0    0    2    0    0
[epoch 22] step 2/44: loss=-0.1994 
[epoch 22] step 4/44: loss=-0.1199 
[epoch 22] step 6/44: loss=-0.0996 
[epoch 22] step 8/44: loss=-0.1058 
[epoch 22] step 10/44: loss=-0.1134 
[epoch 22] step 12/44: loss=-0.0924 
[epoch 22] step 14/44: loss=-0.0809 
[epoch 22] step 16/44: loss=-0.0656 
[epoch 22] step 18/44: loss=-0.0754 
[epoch 22] step 20/44: loss=-0.0843 
[epoch 22] step 22/44: loss=-0.0791 
[epoch 22] step 24/44: loss=-0.0826 
[epoch 22] step 26/44: loss=-0.0834 
[epoch 22] step 28/44: loss=-0.0816 
[epoch 22] step 30/44: loss=-0.0796 
[epoch 22] step 32/44: loss=-0.0757 
[epoch 22] step 34/44: loss=-0.0782 
[epoch 22] step 36/44: loss=-0.0800 
[epoch 22] step 38/44: loss=-0.0781 
[epoch 22] step 40/44: loss=-0.0807 
[epoch 22] step 42/44: loss=-0.0813 
[epoch 22] step 44/44: loss=-0.0794 
[epoch 22] train_loss(avg per step)=-0.1589 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=6.6284 qwk=('0.5798', '0.5578', '0.4617') averageQWK=0.5331 macroEMD=0.2581 tailR0=('0.2239', '0.0833', '0.0000') tailR0avg=0.1024
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    1    0
     1   13   36    5    0
     0    6   75   41    3
     0    0   24   82   10
     0    0    1   14    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   16   30    6    0
     2    9   78   28    5
     0    1   27   96    9
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   15   54    0    0
     0    7  121   24    0
     0    0   49   52    0
     0    0    2    0    0
[epoch 23] step 2/44: loss=-0.0901 
[epoch 23] step 4/44: loss=-0.0782 
[epoch 23] step 6/44: loss=-0.0927 
[epoch 23] step 8/44: loss=-0.0974 
[epoch 23] step 10/44: loss=-0.1148 
[epoch 23] step 12/44: loss=-0.1149 
[epoch 23] step 14/44: loss=-0.1178 
[epoch 23] step 16/44: loss=-0.1256 
[epoch 23] step 18/44: loss=-0.1265 
[epoch 23] step 20/44: loss=-0.1260 
[epoch 23] step 22/44: loss=-0.1210 
[epoch 23] step 24/44: loss=-0.1244 
[epoch 23] step 26/44: loss=-0.1275 
[epoch 23] step 28/44: loss=-0.1356 
[epoch 23] step 30/44: loss=-0.1371 
[epoch 23] step 32/44: loss=-0.1380 
[epoch 23] step 34/44: loss=-0.1337 
[epoch 23] step 36/44: loss=-0.1301 
[epoch 23] step 38/44: loss=-0.1266 
[epoch 23] step 40/44: loss=-0.1269 
[epoch 23] step 42/44: loss=-0.1274 
[epoch 23] step 44/44: loss=-0.1310 
[epoch 23] train_loss(avg per step)=-0.2619 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=6.6407 qwk=('0.5829', '0.5710', '0.5080') averageQWK=0.5540 macroEMD=0.2542 tailR0=('0.2457', '0.0417', '0.0000') tailR0avg=0.0958
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    1    0
     2    9   43    1    0
     0    3   88   31    3
     0    0   32   75    9
     0    0    2   12    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     1   18   27    7    0
     1    8   75   37    1
     0    1   22  108    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   26   43    0    0
     0   12  116   24    0
     0    1   50   50    0
     0    0    2    0    0
[epoch 24] step 2/44: loss=-0.1429 
[epoch 24] step 4/44: loss=-0.1689 
[epoch 24] step 6/44: loss=-0.1635 
[epoch 24] step 8/44: loss=-0.1759 
[epoch 24] step 10/44: loss=-0.1818 
[epoch 24] step 12/44: loss=-0.1585 
[epoch 24] step 14/44: loss=-0.1704 
[epoch 24] step 16/44: loss=-0.1800 
[epoch 24] step 18/44: loss=-0.1840 
[epoch 24] step 20/44: loss=-0.1918 
[epoch 24] step 22/44: loss=-0.1881 
[epoch 24] step 24/44: loss=-0.1896 
[epoch 24] step 26/44: loss=-0.1813 
[epoch 24] step 28/44: loss=-0.1815 
[epoch 24] step 30/44: loss=-0.1836 
[epoch 24] step 32/44: loss=-0.1866 
[epoch 24] step 34/44: loss=-0.1890 
[epoch 24] step 36/44: loss=-0.1865 
[epoch 24] step 38/44: loss=-0.1900 
[epoch 24] step 40/44: loss=-0.1889 
[epoch 24] step 42/44: loss=-0.1900 
[epoch 24] step 44/44: loss=-0.1907 
[epoch 24] train_loss(avg per step)=-0.3814 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=6.7770 qwk=('0.6198', '0.5600', '0.5255') averageQWK=0.5684 macroEMD=0.2488 tailR0=('0.2739', '0.0833', '0.0000') tailR0avg=0.1191
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    1    0
     3   13   36    3    0
     1    8   84   28    4
     0    1   28   76   11
     0    0    1   14    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   23   24    6    0
     1   14   70   33    4
     0    2   23  101    7
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   32   37    0    0
     0   17  113   22    0
     0    2   47   51    1
     0    0    2    0    0
[epoch 25] step 2/44: loss=-0.1766 
[epoch 25] step 4/44: loss=-0.1863 
[epoch 25] step 6/44: loss=-0.2150 
[epoch 25] step 8/44: loss=-0.2178 
[epoch 25] step 10/44: loss=-0.2061 
[epoch 25] step 12/44: loss=-0.2029 
[epoch 25] step 14/44: loss=-0.1937 
[epoch 25] step 16/44: loss=-0.1967 
[epoch 25] step 18/44: loss=-0.1949 
[epoch 25] step 20/44: loss=-0.1986 
[epoch 25] step 22/44: loss=-0.2030 
[epoch 25] step 24/44: loss=-0.2022 
[epoch 25] step 26/44: loss=-0.2075 
[epoch 25] step 28/44: loss=-0.2089 
[epoch 25] step 30/44: loss=-0.2049 
[epoch 25] step 32/44: loss=-0.2103 
[epoch 25] step 34/44: loss=-0.2106 
[epoch 25] step 36/44: loss=-0.2090 
[epoch 25] step 38/44: loss=-0.2027 
[epoch 25] step 40/44: loss=-0.2046 
[epoch 25] step 42/44: loss=-0.2041 
[epoch 25] step 44/44: loss=-0.2058 
[epoch 25] train_loss(avg per step)=-0.4117 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=6.8610 qwk=('0.5982', '0.5407', '0.5886') averageQWK=0.5759 macroEMD=0.2493 tailR0=('0.3239', '0.0417', '0.0000') tailR0avg=0.1219
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    2    1    0
     2   14   35    4    0
     1    8   80   32    4
     0    2   28   78    8
     0    0    2   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   16   32    5    0
     2    9   76   32    3
     0    2   24  104    3
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   40   29    0    0
     0   28   97   27    0
     0    3   36   62    0
     0    0    2    0    0
[epoch 26] step 2/44: loss=-0.2018 
[epoch 26] step 4/44: loss=-0.2259 
[epoch 26] step 6/44: loss=-0.2315 
[epoch 26] step 8/44: loss=-0.2358 
[epoch 26] step 10/44: loss=-0.2265 
[epoch 26] step 12/44: loss=-0.2345 
[epoch 26] step 14/44: loss=-0.2400 
[epoch 26] step 16/44: loss=-0.2391 
[epoch 26] step 18/44: loss=-0.2345 
[epoch 26] step 20/44: loss=-0.2212 
[epoch 26] step 22/44: loss=-0.2172 
[epoch 26] step 24/44: loss=-0.2188 
[epoch 26] step 26/44: loss=-0.2150 
[epoch 26] step 28/44: loss=-0.2113 
[epoch 26] step 30/44: loss=-0.2121 
[epoch 26] step 32/44: loss=-0.2130 
[epoch 26] step 34/44: loss=-0.2164 
[epoch 26] step 36/44: loss=-0.2190 
[epoch 26] step 38/44: loss=-0.2178 
[epoch 26] step 40/44: loss=-0.2176 
[epoch 26] step 42/44: loss=-0.2157 
[epoch 26] step 44/44: loss=-0.2168 
[epoch 26] train_loss(avg per step)=-0.4336 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=6.8643 qwk=('0.6408', '0.5731', '0.5920') averageQWK=0.6020 macroEMD=0.2462 tailR0=('0.3543', '0.0833', '0.0000') tailR0avg=0.1459
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     3   19   30    3    0
     0   12   74   32    7
     0    1   24   73   18
     0    0    1    8   14
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   25   22    6    0
     1   18   68   31    4
     0    2   21  103    7
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   38   31    0    0
     0   20  102   30    0
     0    2   35   63    1
     0    0    2    0    0
[epoch 27] step 2/44: loss=-0.2523 
[epoch 27] step 4/44: loss=-0.1745 
[epoch 27] step 6/44: loss=-0.2067 
[epoch 27] step 8/44: loss=-0.2253 
[epoch 27] step 10/44: loss=-0.2338 
[epoch 27] step 12/44: loss=-0.2261 
[epoch 27] step 14/44: loss=-0.2247 
[epoch 27] step 16/44: loss=-0.2173 
[epoch 27] step 18/44: loss=-0.2278 
[epoch 27] step 20/44: loss=-0.2346 
[epoch 27] step 22/44: loss=-0.2335 
[epoch 27] step 24/44: loss=-0.2348 
[epoch 27] step 26/44: loss=-0.2374 
[epoch 27] step 28/44: loss=-0.2396 
[epoch 27] step 30/44: loss=-0.2384 
[epoch 27] step 32/44: loss=-0.2404 
[epoch 27] step 34/44: loss=-0.2420 
[epoch 27] step 36/44: loss=-0.2435 
[epoch 27] step 38/44: loss=-0.2455 
[epoch 27] step 40/44: loss=-0.2489 
[epoch 27] step 42/44: loss=-0.2508 
[epoch 27] step 44/44: loss=-0.2512 
[epoch 27] train_loss(avg per step)=-0.5024 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=6.9364 qwk=('0.6294', '0.6085', '0.5043') averageQWK=0.5807 macroEMD=0.2509 tailR0=('0.4043', '0.0417', '0.0000') tailR0avg=0.1487
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    1    0
     2   13   39    1    0
     1    5   92   22    5
     0    0   37   62   17
     0    0    3    6   14
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   24   23    6    0
     1   16   75   27    3
     0    2   26   99    6
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   27   42    0    0
     0   16  113   22    1
     0    1   50   50    0
     0    0    2    0    0
[epoch 28] step 2/44: loss=-0.2900 
[epoch 28] step 4/44: loss=-0.2715 
[epoch 28] step 6/44: loss=-0.2760 
[epoch 28] step 8/44: loss=-0.2761 
[epoch 28] step 10/44: loss=-0.2852 
[epoch 28] step 12/44: loss=-0.2824 
[epoch 28] step 14/44: loss=-0.2803 
[epoch 28] step 16/44: loss=-0.2828 
[epoch 28] step 18/44: loss=-0.2709 
[epoch 28] step 20/44: loss=-0.2710 
[epoch 28] step 22/44: loss=-0.2694 
[epoch 28] step 24/44: loss=-0.2687 
[epoch 28] step 26/44: loss=-0.2660 
[epoch 28] step 28/44: loss=-0.2693 
[epoch 28] step 30/44: loss=-0.2691 
[epoch 28] step 32/44: loss=-0.2706 
[epoch 28] step 34/44: loss=-0.2717 
[epoch 28] step 36/44: loss=-0.2716 
[epoch 28] step 38/44: loss=-0.2679 
[epoch 28] step 40/44: loss=-0.2659 
[epoch 28] step 42/44: loss=-0.2677 
[epoch 28] step 44/44: loss=-0.2649 
[epoch 28] train_loss(avg per step)=-0.5298 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=7.4878 qwk=('0.6353', '0.5661', '0.5292') averageQWK=0.5768 macroEMD=0.2437 tailR0=('0.2457', '0.0417', '0.0000') tailR0avg=0.0958
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     2   18   33    2    0
     0   12   72   36    5
     0    0   24   83    9
     0    0    1   13    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   17   31    5    0
     2    7   90   21    2
     0    1   30   98    4
     0    0    3    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   20   49    0    0
     0   13  115   24    0
     0    0   41   60    0
     0    0    1    1    0
[epoch 29] step 2/44: loss=-0.2428 
[epoch 29] step 4/44: loss=-0.2107 
[epoch 29] step 6/44: loss=-0.2146 
[epoch 29] step 8/44: loss=-0.2129 
[epoch 29] step 10/44: loss=-0.2254 
[epoch 29] step 12/44: loss=-0.2342 
[epoch 29] step 14/44: loss=-0.2442 
[epoch 29] step 16/44: loss=-0.2411 
[epoch 29] step 18/44: loss=-0.2397 
[epoch 29] step 20/44: loss=-0.2377 
[epoch 29] step 22/44: loss=-0.2406 
[epoch 29] step 24/44: loss=-0.2410 
[epoch 29] step 26/44: loss=-0.2419 
[epoch 29] step 28/44: loss=-0.2406 
[epoch 29] step 30/44: loss=-0.2399 
[epoch 29] step 32/44: loss=-0.2428 
[epoch 29] step 34/44: loss=-0.2462 
[epoch 29] step 36/44: loss=-0.2494 
[epoch 29] step 38/44: loss=-0.2520 
[epoch 29] step 40/44: loss=-0.2486 
[epoch 29] step 42/44: loss=-0.2486 
[epoch 29] step 44/44: loss=-0.2478 
[epoch 29] train_loss(avg per step)=-0.4955 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=7.4631 qwk=('0.6438', '0.5965', '0.5500') averageQWK=0.5968 macroEMD=0.2442 tailR0=('0.3391', '0.0833', '0.0000') tailR0avg=0.1408
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    1    0
     2   15   36    2    0
     0   10   82   29    4
     0    0   27   79   10
     0    0    2   10   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   19   28    6    0
     1   16   72   31    2
     0    1   25  103    4
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   27   42    0    0
     0   15  111   26    0
     0    0   40   61    0
     0    0    2    0    0
[epoch 30] step 2/44: loss=-0.2899 
[epoch 30] step 4/44: loss=-0.2939 
[epoch 30] step 6/44: loss=-0.2885 
[epoch 30] step 8/44: loss=-0.2959 
[epoch 30] step 10/44: loss=-0.2982 
[epoch 30] step 12/44: loss=-0.2977 
[epoch 30] step 14/44: loss=-0.2910 
[epoch 30] step 16/44: loss=-0.2942 
[epoch 30] step 18/44: loss=-0.2944 
[epoch 30] step 20/44: loss=-0.2886 
[epoch 30] step 22/44: loss=-0.2852 
[epoch 30] step 24/44: loss=-0.2885 
[epoch 30] step 26/44: loss=-0.2901 
[epoch 30] step 28/44: loss=-0.2886 
[epoch 30] step 30/44: loss=-0.2880 
[epoch 30] step 32/44: loss=-0.2894 
[epoch 30] step 34/44: loss=-0.2902 
[epoch 30] step 36/44: loss=-0.2915 
[epoch 30] step 38/44: loss=-0.2937 
[epoch 30] step 40/44: loss=-0.2900 
[epoch 30] step 42/44: loss=-0.2904 
[epoch 30] step 44/44: loss=-0.2908 
[epoch 30] train_loss(avg per step)=-0.5816 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=7.8540 qwk=('0.6255', '0.5760', '0.5479') averageQWK=0.5831 macroEMD=0.2462 tailR0=('0.3174', '0.1250', '0.0000') tailR0avg=0.1475
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    1    0
     2   13   37    3    0
     0    7   81   33    4
     0    0   26   80   10
     0    0    1   12   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   20   28    5    0
     2    9   74   31    6
     0    1   23   99   10
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   29   40    0    0
     0   16  111   25    0
     0    1   40   60    0
     0    0    2    0    0
[epoch 31] step 2/44: loss=-0.2747 
[epoch 31] step 4/44: loss=-0.2825 
[epoch 31] step 6/44: loss=-0.2966 
[epoch 31] step 8/44: loss=-0.2917 
[epoch 31] step 10/44: loss=-0.2942 
[epoch 31] step 12/44: loss=-0.2922 
[epoch 31] step 14/44: loss=-0.2961 
[epoch 31] step 16/44: loss=-0.2950 
[epoch 31] step 18/44: loss=-0.2951 
[epoch 31] step 20/44: loss=-0.2985 
[epoch 31] step 22/44: loss=-0.3022 
[epoch 31] step 24/44: loss=-0.3000 
[epoch 31] step 26/44: loss=-0.2937 
[epoch 31] step 28/44: loss=-0.2885 
[epoch 31] step 30/44: loss=-0.2903 
[epoch 31] step 32/44: loss=-0.2898 
[epoch 31] step 34/44: loss=-0.2910 
[epoch 31] step 36/44: loss=-0.2917 
[epoch 31] step 38/44: loss=-0.2913 
[epoch 31] step 40/44: loss=-0.2930 
[epoch 31] step 42/44: loss=-0.2940 
[epoch 31] step 44/44: loss=-0.2959 
[epoch 31] train_loss(avg per step)=-0.5918 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=7.8900 qwk=('0.6092', '0.5820', '0.5737') averageQWK=0.5883 macroEMD=0.2442 tailR0=('0.2891', '0.0417', '0.0000') tailR0avg=0.1103
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    1    0
     2   13   38    2    0
     1    6   83   31    4
     0    0   29   75   12
     0    0    2   10   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   20   27    6    0
     2   12   69   35    4
     0    1   22  103    7
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   29   40    0    0
     0   19   97   36    0
     0    1   30   70    0
     0    0    1    1    0
[epoch 32] step 2/44: loss=-0.3135 
[epoch 32] step 4/44: loss=-0.2657 
[epoch 32] step 6/44: loss=-0.2736 
[epoch 32] step 8/44: loss=-0.2878 
[epoch 32] step 10/44: loss=-0.2930 
[epoch 32] step 12/44: loss=-0.2909 
[epoch 32] step 14/44: loss=-0.2923 
[epoch 32] step 16/44: loss=-0.2950 
[epoch 32] step 18/44: loss=-0.2970 
[epoch 32] step 20/44: loss=-0.2960 
[epoch 32] step 22/44: loss=-0.2978 
[epoch 32] step 24/44: loss=-0.2989 
[epoch 32] step 26/44: loss=-0.3005 
[epoch 32] step 28/44: loss=-0.3027 
[epoch 32] step 30/44: loss=-0.3028 
[epoch 32] step 32/44: loss=-0.3026 
[epoch 32] step 34/44: loss=-0.3031 
[epoch 32] step 36/44: loss=-0.3032 
[epoch 32] step 38/44: loss=-0.3049 
[epoch 32] step 40/44: loss=-0.3041 
[epoch 32] step 42/44: loss=-0.3058 
[epoch 32] step 44/44: loss=-0.3068 
[epoch 32] train_loss(avg per step)=-0.6135 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=8.0072 qwk=('0.6074', '0.5679', '0.5545') averageQWK=0.5766 macroEMD=0.2454 tailR0=('0.2891', '0.0417', '0.0000') tailR0avg=0.1103
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    1    0
     2   13   37    3    0
     2    6   81   31    5
     0    0   29   74   13
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   22   24    7    0
     1   16   63   38    4
     0    1   20  105    7
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   29   40    0    0
     0   16  111   25    0
     0    0   44   56    1
     0    0    2    0    0
[epoch 33] step 2/44: loss=-0.3359 
[epoch 33] step 4/44: loss=-0.3347 
[epoch 33] step 6/44: loss=-0.3363 
[epoch 33] step 8/44: loss=-0.3269 
[epoch 33] step 10/44: loss=-0.3273 
[epoch 33] step 12/44: loss=-0.3241 
[epoch 33] step 14/44: loss=-0.3215 
[epoch 33] step 16/44: loss=-0.3223 
[epoch 33] step 18/44: loss=-0.3222 
[epoch 33] step 20/44: loss=-0.3220 
[epoch 33] step 22/44: loss=-0.3189 
[epoch 33] step 24/44: loss=-0.3191 
[epoch 33] step 26/44: loss=-0.3183 
[epoch 33] step 28/44: loss=-0.3139 
[epoch 33] step 30/44: loss=-0.3145 
[epoch 33] step 32/44: loss=-0.3151 
[epoch 33] step 34/44: loss=-0.3164 
[epoch 33] step 36/44: loss=-0.3151 
[epoch 33] step 38/44: loss=-0.3157 
[epoch 33] step 40/44: loss=-0.3165 
[epoch 33] step 42/44: loss=-0.3174 
[epoch 33] step 44/44: loss=-0.3180 
[epoch 33] train_loss(avg per step)=-0.6361 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=8.0445 qwk=('0.6072', '0.5569', '0.5540') averageQWK=0.5727 macroEMD=0.2453 tailR0=('0.2891', '0.0417', '0.0000') tailR0avg=0.1103
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    1    0
     2   13   37    3    0
     1    8   78   32    6
     0    0   27   76   13
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   16   32    5    0
     1    7   85   25    4
     0    1   26   99    7
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   32   37    0    0
     0   19  104   29    0
     0    1   39   61    0
     0    0    2    0    0
[epoch 34] step 2/44: loss=-0.3029 
[epoch 34] step 4/44: loss=-0.3160 
[epoch 34] step 6/44: loss=-0.3236 
[epoch 34] step 8/44: loss=-0.3218 
[epoch 34] step 10/44: loss=-0.3209 
[epoch 34] step 12/44: loss=-0.3215 
[epoch 34] step 14/44: loss=-0.3191 
[epoch 34] step 16/44: loss=-0.3217 
[epoch 34] step 18/44: loss=-0.3212 
[epoch 34] step 20/44: loss=-0.3227 
[epoch 34] step 22/44: loss=-0.3214 
[epoch 34] step 24/44: loss=-0.3208 
[epoch 34] step 26/44: loss=-0.3201 
[epoch 34] step 28/44: loss=-0.3201 
[epoch 34] step 30/44: loss=-0.3182 
[epoch 34] step 32/44: loss=-0.3187 
[epoch 34] step 34/44: loss=-0.3193 
[epoch 34] step 36/44: loss=-0.3192 
[epoch 34] step 38/44: loss=-0.3181 
[epoch 34] step 40/44: loss=-0.3163 
[epoch 34] step 42/44: loss=-0.3157 
[epoch 34] step 44/44: loss=-0.3155 
[epoch 34] train_loss(avg per step)=-0.6310 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=8.3086 qwk=('0.6240', '0.5653', '0.5237') averageQWK=0.5710 macroEMD=0.2452 tailR0=('0.4391', '0.0417', '0.0000') tailR0avg=0.1603
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    1    4    1    0
     3   12   37    3    0
     1    3   85   31    5
     0    0   28   77   11
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   18   28    7    0
     0    9   75   35    3
     0    1   23  104    5
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   23   46    0    0
     0   12  115   25    0
     0    0   43   58    0
     0    0    2    0    0
[epoch 35] step 2/44: loss=-0.3122 
[epoch 35] step 4/44: loss=-0.3226 
[epoch 35] step 6/44: loss=-0.3179 
[epoch 35] step 8/44: loss=-0.3124 
[epoch 35] step 10/44: loss=-0.3131 
[epoch 35] step 12/44: loss=-0.3176 
[epoch 35] step 14/44: loss=-0.3155 
[epoch 35] step 16/44: loss=-0.3156 
[epoch 35] step 18/44: loss=-0.3176 
[epoch 35] step 20/44: loss=-0.3177 
[epoch 35] step 22/44: loss=-0.3197 
[epoch 35] step 24/44: loss=-0.3195 
[epoch 35] step 26/44: loss=-0.3167 
[epoch 35] step 28/44: loss=-0.3169 
[epoch 35] step 30/44: loss=-0.3181 
[epoch 35] step 32/44: loss=-0.3193 
[epoch 35] step 34/44: loss=-0.3177 
[epoch 35] step 36/44: loss=-0.3182 
[epoch 35] step 38/44: loss=-0.3179 
[epoch 35] step 40/44: loss=-0.3186 
[epoch 35] step 42/44: loss=-0.3174 
[epoch 35] step 44/44: loss=-0.3178 
[epoch 35] train_loss(avg per step)=-0.6357 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=8.1806 qwk=('0.6241', '0.5739', '0.5365') averageQWK=0.5782 macroEMD=0.2441 tailR0=('0.3391', '0.0417', '0.0000') tailR0avg=0.1269
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    1    0
     2   13   37    3    0
     1    6   81   32    5
     0    0   28   77   11
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   17   31    5    0
     1    7   81   30    3
     0    1   23  104    5
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   28   41    0    0
     0   17  110   25    0
     0    0   44   57    0
     0    0    2    0    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-1-reassignment-0/fold5/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-1-reassignment-0/fold5/metrics.json
Done.
