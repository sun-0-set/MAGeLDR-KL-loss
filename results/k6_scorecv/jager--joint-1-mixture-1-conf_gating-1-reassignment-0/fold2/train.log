[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.4642 
[epoch 1] step 4/44: loss=6.1462 
[epoch 1] step 6/44: loss=6.1207 
[epoch 1] step 8/44: loss=6.1151 
[epoch 1] step 10/44: loss=6.0310 
[epoch 1] step 12/44: loss=5.9745 
[epoch 1] step 14/44: loss=5.9971 
[epoch 1] step 16/44: loss=5.9101 
[epoch 1] step 18/44: loss=5.8598 
[epoch 1] step 20/44: loss=5.8739 
[epoch 1] step 22/44: loss=5.8359 
[epoch 1] step 24/44: loss=5.8652 
[epoch 1] step 26/44: loss=5.8117 
[epoch 1] step 28/44: loss=5.7991 
[epoch 1] step 30/44: loss=5.8098 
[epoch 1] step 32/44: loss=5.8143 
[epoch 1] step 34/44: loss=5.7938 
[epoch 1] step 36/44: loss=5.7786 
[epoch 1] step 38/44: loss=5.7422 
[epoch 1] step 40/44: loss=5.7141 
[epoch 1] step 42/44: loss=5.6758 
[epoch 1] step 44/44: loss=5.6332 
[epoch 1] train_loss(avg per step)=11.2664 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=6.6154 qwk=('0.0979', '0.1118', '0.1728') averageQWK=0.1275 macroEMD=0.3766 tailR0=('0.0000', '0.0556', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    6    0
     0   18    0   36    0
     0   51    0   74    0
     0   36    0   80    0
     0    3    0   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    1    0
    19    0   28    6    0
    35    0   55   31    0
    40    0   38   55    0
     1    0    3    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0   15   53    1    0
     0   20  123    8    0
     0   10   75   16    0
     0    0    1    1    0
[epoch 2] step 2/44: loss=4.3361 
[epoch 2] step 4/44: loss=4.2005 
[epoch 2] step 6/44: loss=4.1293 
[epoch 2] step 8/44: loss=4.0787 
[epoch 2] step 10/44: loss=3.9960 
[epoch 2] step 12/44: loss=3.9106 
[epoch 2] step 14/44: loss=3.8509 
[epoch 2] step 16/44: loss=3.7576 
[epoch 2] step 18/44: loss=3.6907 
[epoch 2] step 20/44: loss=3.6300 
[epoch 2] step 22/44: loss=3.5599 
[epoch 2] step 24/44: loss=3.5165 
[epoch 2] step 26/44: loss=3.4728 
[epoch 2] step 28/44: loss=3.4344 
[epoch 2] step 30/44: loss=3.4013 
[epoch 2] step 32/44: loss=3.3611 
[epoch 2] step 34/44: loss=3.3202 
[epoch 2] step 36/44: loss=3.3050 
[epoch 2] step 38/44: loss=3.2816 
[epoch 2] step 40/44: loss=3.2610 
[epoch 2] step 42/44: loss=3.2479 
[epoch 2] step 44/44: loss=3.2130 
[epoch 2] train_loss(avg per step)=6.4261 lambda[min,max]=[0.500887,1.000000]
[epoch 2] val_loss=3.7476 qwk=('0.2699', '0.3986', '0.3940') averageQWK=0.3542 macroEMD=0.3800 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   33   21    0    0
     0   48   70    7    0
     0   22   62   32    0
     0   11    4    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   48    5    0
     0    0   97   24    0
     0    0   51   82    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    4   64    1    0
     0    0  133   18    0
     0    0   51   50    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=2.6973 
[epoch 3] step 4/44: loss=2.8434 
[epoch 3] step 6/44: loss=2.7958 
[epoch 3] step 8/44: loss=2.7688 
[epoch 3] step 10/44: loss=2.7423 
[epoch 3] step 12/44: loss=2.7240 
[epoch 3] step 14/44: loss=2.7092 
[epoch 3] step 16/44: loss=2.7027 
[epoch 3] step 18/44: loss=2.7417 
[epoch 3] step 20/44: loss=2.7312 
[epoch 3] step 22/44: loss=2.7445 
[epoch 3] step 24/44: loss=2.7236 
[epoch 3] step 26/44: loss=2.7078 
[epoch 3] step 28/44: loss=2.7107 
[epoch 3] step 30/44: loss=2.7050 
[epoch 3] step 32/44: loss=2.7081 
[epoch 3] step 34/44: loss=2.6946 
[epoch 3] step 36/44: loss=2.6853 
[epoch 3] step 38/44: loss=2.6752 
[epoch 3] step 40/44: loss=2.6619 
[epoch 3] step 42/44: loss=2.6547 
[epoch 3] step 44/44: loss=2.6438 
[epoch 3] train_loss(avg per step)=5.2877 lambda[min,max]=[0.517232,1.000000]
[epoch 3] val_loss=4.1624 qwk=('0.2087', '0.4236', '0.4949') averageQWK=0.3757 macroEMD=0.3672 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    4   50    0    0
     0    2  122    1    0
     0    0   91   25    0
     0    0   17    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   36   17    0    0
     0   48   68    5    0
     0   19   71   43    0
     0    0    4    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   52   17    0    0
     0   59   88    4    0
     0    7   65   29    0
     0    0    2    0    0
[epoch 4] step 2/44: loss=2.8405 
[epoch 4] step 4/44: loss=2.7258 
[epoch 4] step 6/44: loss=2.5727 
[epoch 4] step 8/44: loss=2.5905 
[epoch 4] step 10/44: loss=2.6661 
[epoch 4] step 12/44: loss=2.6817 
[epoch 4] step 14/44: loss=2.6639 
[epoch 4] step 16/44: loss=2.6608 
[epoch 4] step 18/44: loss=2.6652 
[epoch 4] step 20/44: loss=2.6609 
[epoch 4] step 22/44: loss=2.6456 
[epoch 4] step 24/44: loss=2.6582 
[epoch 4] step 26/44: loss=2.6352 
[epoch 4] step 28/44: loss=2.6063 
[epoch 4] step 30/44: loss=2.5926 
[epoch 4] step 32/44: loss=2.5900 
[epoch 4] step 34/44: loss=2.5740 
[epoch 4] step 36/44: loss=2.5699 
[epoch 4] step 38/44: loss=2.5408 
[epoch 4] step 40/44: loss=2.5420 
[epoch 4] step 42/44: loss=2.5387 
[epoch 4] step 44/44: loss=2.5344 
[epoch 4] train_loss(avg per step)=5.0688 lambda[min,max]=[0.521717,1.000000]
[epoch 4] val_loss=3.5007 qwk=('0.4376', '0.4802', '0.4739') averageQWK=0.4639 macroEMD=0.3481 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    0    0
     0    4   50    0    0
     0    2  109   14    0
     0    0   51   65    0
     0    0    9   14    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   50    3    0
     0    0  101   20    0
     0    0   39   94    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0    5   62    2    0
     0    2  129   20    0
     0    0   37   64    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=2.1221 
[epoch 5] step 4/44: loss=2.2175 
[epoch 5] step 6/44: loss=2.2019 
[epoch 5] step 8/44: loss=2.1603 
[epoch 5] step 10/44: loss=2.1710 
[epoch 5] step 12/44: loss=2.1901 
[epoch 5] step 14/44: loss=2.2058 
[epoch 5] step 16/44: loss=2.2374 
[epoch 5] step 18/44: loss=2.2623 
[epoch 5] step 20/44: loss=2.2374 
[epoch 5] step 22/44: loss=2.2288 
[epoch 5] step 24/44: loss=2.2499 
[epoch 5] step 26/44: loss=2.2261 
[epoch 5] step 28/44: loss=2.2282 
[epoch 5] step 30/44: loss=2.2257 
[epoch 5] step 32/44: loss=2.2186 
[epoch 5] step 34/44: loss=2.2212 
[epoch 5] step 36/44: loss=2.2282 
[epoch 5] step 38/44: loss=2.2222 
[epoch 5] step 40/44: loss=2.2268 
[epoch 5] step 42/44: loss=2.2236 
[epoch 5] step 44/44: loss=2.2065 
[epoch 5] train_loss(avg per step)=4.4129 lambda[min,max]=[0.507636,1.000000]
[epoch 5] val_loss=3.4730 qwk=('0.5708', '0.6016', '0.5214') averageQWK=0.5646 macroEMD=0.3359 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   13   34    7    0
     0   10   65   50    0
     0    0   15  101    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   19   30    4    0
     0   21   69   31    0
     0    0   35   98    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   14   55    0    0
     0    2  131   18    0
     0    0   42   59    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=1.9317 
[epoch 6] step 4/44: loss=1.8576 
[epoch 6] step 6/44: loss=1.9184 
[epoch 6] step 8/44: loss=1.9311 
[epoch 6] step 10/44: loss=1.9475 
[epoch 6] step 12/44: loss=1.9288 
[epoch 6] step 14/44: loss=1.9078 
[epoch 6] step 16/44: loss=1.9148 
[epoch 6] step 18/44: loss=1.9265 
[epoch 6] step 20/44: loss=1.9468 
[epoch 6] step 22/44: loss=1.9429 
[epoch 6] step 24/44: loss=1.9574 
[epoch 6] step 26/44: loss=1.9515 
[epoch 6] step 28/44: loss=1.9508 
[epoch 6] step 30/44: loss=1.9390 
[epoch 6] step 32/44: loss=1.9453 
[epoch 6] step 34/44: loss=1.9549 
[epoch 6] step 36/44: loss=1.9468 
[epoch 6] step 38/44: loss=1.9619 
[epoch 6] step 40/44: loss=1.9605 
[epoch 6] step 42/44: loss=1.9700 
[epoch 6] step 44/44: loss=1.9888 
[epoch 6] train_loss(avg per step)=3.9777 lambda[min,max]=[0.508203,1.000000]
[epoch 6] val_loss=3.3592 qwk=('0.5578', '0.5465', '0.5596') averageQWK=0.5546 macroEMD=0.3315 tailR0=('0.0000', '0.0556', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0    9   43    2    0
     0    9   90   26    0
     0    0   33   83    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    0    0
     3    1   46    3    0
     0    1   96   24    0
     0    0   36   97    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   20   49    0    0
     0    2  136   13    0
     0    0   43   58    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=1.6280 
[epoch 7] step 4/44: loss=1.8037 
[epoch 7] step 6/44: loss=1.9035 
[epoch 7] step 8/44: loss=1.8679 
[epoch 7] step 10/44: loss=1.8540 
[epoch 7] step 12/44: loss=1.9054 
[epoch 7] step 14/44: loss=1.9145 
[epoch 7] step 16/44: loss=1.9328 
[epoch 7] step 18/44: loss=1.9291 
[epoch 7] step 20/44: loss=1.9267 
[epoch 7] step 22/44: loss=1.9165 
[epoch 7] step 24/44: loss=1.9113 
[epoch 7] step 26/44: loss=1.8966 
[epoch 7] step 28/44: loss=1.8863 
[epoch 7] step 30/44: loss=1.8952 
[epoch 7] step 32/44: loss=1.8886 
[epoch 7] step 34/44: loss=1.8860 
[epoch 7] step 36/44: loss=1.8765 
[epoch 7] step 38/44: loss=1.8675 
[epoch 7] step 40/44: loss=1.8774 
[epoch 7] step 42/44: loss=1.8637 
[epoch 7] step 44/44: loss=1.8603 
[epoch 7] train_loss(avg per step)=3.7205 lambda[min,max]=[0.500283,1.000000]
[epoch 7] val_loss=3.6443 qwk=('0.6107', '0.4779', '0.5309') averageQWK=0.5398 macroEMD=0.3243 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    1    0    0
     0   26   28    0    0
     0   27   87   11    0
     0    0   52   64    0
     0    1    4   17    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   14   39    0    0
     0   17  100    4    0
     0    0   78   55    0
     0    0    5    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   36   33    0    0
     0   17  131    3    0
     0    1   66   34    0
     0    0    2    0    0
[epoch 8] step 2/44: loss=1.9857 
[epoch 8] step 4/44: loss=1.9341 
[epoch 8] step 6/44: loss=1.8484 
[epoch 8] step 8/44: loss=1.8446 
[epoch 8] step 10/44: loss=1.7880 
[epoch 8] step 12/44: loss=1.7638 
[epoch 8] step 14/44: loss=1.7469 
[epoch 8] step 16/44: loss=1.7128 
[epoch 8] step 18/44: loss=1.6809 
[epoch 8] step 20/44: loss=1.6582 
[epoch 8] step 22/44: loss=1.6473 
[epoch 8] step 24/44: loss=1.6399 
[epoch 8] step 26/44: loss=1.6369 
[epoch 8] step 28/44: loss=1.6383 
[epoch 8] step 30/44: loss=1.6567 
[epoch 8] step 32/44: loss=1.6547 
[epoch 8] step 34/44: loss=1.6650 
[epoch 8] step 36/44: loss=1.6678 
[epoch 8] step 38/44: loss=1.6660 
[epoch 8] step 40/44: loss=1.6571 
[epoch 8] step 42/44: loss=1.6599 
[epoch 8] step 44/44: loss=1.6558 
[epoch 8] train_loss(avg per step)=3.3116 lambda[min,max]=[0.500095,1.000000]
[epoch 8] val_loss=3.5723 qwk=('0.5735', '0.5705', '0.5591') averageQWK=0.5677 macroEMD=0.3075 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0    8   46    0    0
     0    7   88   30    0
     0    0   29   87    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   21   18   14    0
     0   28   36   57    0
     0    1    9  123    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   34   35    0    0
     0   18  128    5    0
     0    1   59   41    0
     0    0    2    0    0
[epoch 9] step 2/44: loss=1.5808 
[epoch 9] step 4/44: loss=1.4980 
[epoch 9] step 6/44: loss=1.4950 
[epoch 9] step 8/44: loss=1.5431 
[epoch 9] step 10/44: loss=1.5716 
[epoch 9] step 12/44: loss=1.5085 
[epoch 9] step 14/44: loss=1.4879 
[epoch 9] step 16/44: loss=1.4684 
[epoch 9] step 18/44: loss=1.4747 
[epoch 9] step 20/44: loss=1.4919 
[epoch 9] step 22/44: loss=1.5020 
[epoch 9] step 24/44: loss=1.4898 
[epoch 9] step 26/44: loss=1.4859 
[epoch 9] step 28/44: loss=1.4751 
[epoch 9] step 30/44: loss=1.4841 
[epoch 9] step 32/44: loss=1.4823 
[epoch 9] step 34/44: loss=1.4933 
[epoch 9] step 36/44: loss=1.4917 
[epoch 9] step 38/44: loss=1.4965 
[epoch 9] step 40/44: loss=1.4851 
[epoch 9] step 42/44: loss=1.4949 
[epoch 9] step 44/44: loss=1.5045 
[epoch 9] train_loss(avg per step)=3.0091 lambda[min,max]=[0.500026,1.000000]
[epoch 9] val_loss=3.4732 qwk=('0.6478', '0.6248', '0.6018') averageQWK=0.6248 macroEMD=0.2949 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    0    0    0
     0   23   31    0    0
     0   24   83   18    0
     0    0   38   78    0
     0    0    4   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   21   31    1    0
     0   24   78   19    0
     0    2   44   87    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   43   26    0    0
     0   29  100   22    0
     0    4   40   57    0
     0    0    1    1    0
[epoch 10] step 2/44: loss=1.4082 
[epoch 10] step 4/44: loss=1.4148 
[epoch 10] step 6/44: loss=1.4569 
[epoch 10] step 8/44: loss=1.4338 
[epoch 10] step 10/44: loss=1.4493 
[epoch 10] step 12/44: loss=1.4406 
[epoch 10] step 14/44: loss=1.4511 
[epoch 10] step 16/44: loss=1.4529 
[epoch 10] step 18/44: loss=1.4226 
[epoch 10] step 20/44: loss=1.4094 
[epoch 10] step 22/44: loss=1.4015 
[epoch 10] step 24/44: loss=1.3740 
[epoch 10] step 26/44: loss=1.3617 
[epoch 10] step 28/44: loss=1.3446 
[epoch 10] step 30/44: loss=1.3411 
[epoch 10] step 32/44: loss=1.3316 
[epoch 10] step 34/44: loss=1.3224 
[epoch 10] step 36/44: loss=1.3291 
[epoch 10] step 38/44: loss=1.3277 
[epoch 10] step 40/44: loss=1.3270 
[epoch 10] step 42/44: loss=1.3322 
[epoch 10] step 44/44: loss=1.3268 
[epoch 10] train_loss(avg per step)=2.6536 lambda[min,max]=[0.500008,1.000000]
[epoch 10] val_loss=3.7982 qwk=('0.6138', '0.4912', '0.5853') averageQWK=0.5635 macroEMD=0.3015 tailR0=('0.1957', '0.0833', '0.0000') tailR0avg=0.0930
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   17   37    0    0
     0   17   95   12    1
     0    0   50   61    5
     0    0    6    8    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     2   15   35    1    0
     1   15  101    4    0
     0    0   81   49    3
     0    0    5    5    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   42   27    0    0
     0   34  109    8    0
     0    3   51   47    0
     0    0    1    1    0
[epoch 11] step 2/44: loss=1.5512 
[epoch 11] step 4/44: loss=1.4027 
[epoch 11] step 6/44: loss=1.3190 
[epoch 11] step 8/44: loss=1.3084 
[epoch 11] step 10/44: loss=1.2793 
[epoch 11] step 12/44: loss=1.2619 
[epoch 11] step 14/44: loss=1.3342 
[epoch 11] step 16/44: loss=1.2992 
[epoch 11] step 18/44: loss=1.2648 
[epoch 11] step 20/44: loss=1.2458 
[epoch 11] step 22/44: loss=1.2757 
[epoch 11] step 24/44: loss=1.2894 
[epoch 11] step 26/44: loss=1.2872 
[epoch 11] step 28/44: loss=1.2781 
[epoch 11] step 30/44: loss=1.2664 
[epoch 11] step 32/44: loss=1.2683 
[epoch 11] step 34/44: loss=1.2649 
[epoch 11] step 36/44: loss=1.2605 
[epoch 11] step 38/44: loss=1.2629 
[epoch 11] step 40/44: loss=1.2672 
[epoch 11] step 42/44: loss=1.2486 
[epoch 11] step 44/44: loss=1.2512 
[epoch 11] train_loss(avg per step)=2.5024 lambda[min,max]=[0.500006,1.000000]
[epoch 11] val_loss=3.5925 qwk=('0.5857', '0.5748', '0.6176') averageQWK=0.5927 macroEMD=0.2885 tailR0=('0.0717', '0.0000', '0.0000') tailR0avg=0.0239
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    6    0    0
     0    8   44    2    0
     0    6   93   25    1
     0    0   25   90    1
     0    0    2   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   15   30    8    0
     0   12   66   43    0
     0    1   18  114    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   32   36    1    0
     0   15  108   28    0
     0    1   28   72    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=1.1184 
[epoch 12] step 4/44: loss=1.1016 
[epoch 12] step 6/44: loss=1.1157 
[epoch 12] step 8/44: loss=1.1050 
[epoch 12] step 10/44: loss=1.0926 
[epoch 12] step 12/44: loss=1.0262 
[epoch 12] step 14/44: loss=1.0205 
[epoch 12] step 16/44: loss=1.0331 
[epoch 12] step 18/44: loss=1.0376 
[epoch 12] step 20/44: loss=1.0308 
[epoch 12] step 22/44: loss=1.0366 
[epoch 12] step 24/44: loss=1.0408 
[epoch 12] step 26/44: loss=1.0144 
[epoch 12] step 28/44: loss=1.0023 
[epoch 12] step 30/44: loss=1.0002 
[epoch 12] step 32/44: loss=0.9872 
[epoch 12] step 34/44: loss=0.9844 
[epoch 12] step 36/44: loss=0.9913 
[epoch 12] step 38/44: loss=0.9911 
[epoch 12] step 40/44: loss=0.9922 
[epoch 12] step 42/44: loss=0.9886 
[epoch 12] step 44/44: loss=0.9917 
[epoch 12] train_loss(avg per step)=1.9835 lambda[min,max]=[0.500003,1.000000]
[epoch 12] val_loss=3.8478 qwk=('0.6108', '0.5590', '0.6283') averageQWK=0.5994 macroEMD=0.2808 tailR0=('0.1957', '0.0000', '0.1000') tailR0avg=0.0986
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   12   41    1    0
     0   11   85   24    5
     0    0   34   75    7
     0    0    3   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   16   29    8    0
     0   14   64   42    1
     0    1   23  103    6
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   32   36    1    0
     1   20   93   37    0
     0    1   26   74    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.9045 
[epoch 13] step 4/44: loss=0.8229 
[epoch 13] step 6/44: loss=0.8227 
[epoch 13] step 8/44: loss=0.8578 
[epoch 13] step 10/44: loss=0.8764 
[epoch 13] step 12/44: loss=0.9150 
[epoch 13] step 14/44: loss=0.9559 
[epoch 13] step 16/44: loss=0.9559 
[epoch 13] step 18/44: loss=0.9519 
[epoch 13] step 20/44: loss=0.9345 
[epoch 13] step 22/44: loss=0.9335 
[epoch 13] step 24/44: loss=0.9354 
[epoch 13] step 26/44: loss=0.9417 
[epoch 13] step 28/44: loss=0.9577 
[epoch 13] step 30/44: loss=0.9555 
[epoch 13] step 32/44: loss=0.9546 
[epoch 13] step 34/44: loss=0.9688 
[epoch 13] step 36/44: loss=0.9572 
[epoch 13] step 38/44: loss=0.9477 
[epoch 13] step 40/44: loss=0.9499 
[epoch 13] step 42/44: loss=0.9442 
[epoch 13] step 44/44: loss=0.9420 
[epoch 13] train_loss(avg per step)=1.8839 lambda[min,max]=[0.500005,1.000000]
[epoch 13] val_loss=3.7562 qwk=('0.6575', '0.6036', '0.6078') averageQWK=0.6230 macroEMD=0.2720 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   18   36    0    0
     0   14   91   20    0
     0    0   34   81    1
     0    0    1   19    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   18   30    5    0
     0   23   71   27    0
     0    1   33   98    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   41   28    0    0
     0   29  112   10    0
     0    1   51   49    0
     0    0    1    1    0
[epoch 14] step 2/44: loss=0.8663 
[epoch 14] step 4/44: loss=0.8848 
[epoch 14] step 6/44: loss=0.8616 
[epoch 14] step 8/44: loss=0.8354 
[epoch 14] step 10/44: loss=0.8452 
[epoch 14] step 12/44: loss=0.8559 
[epoch 14] step 14/44: loss=0.8852 
[epoch 14] step 16/44: loss=0.9051 
[epoch 14] step 18/44: loss=0.8829 
[epoch 14] step 20/44: loss=0.8589 
[epoch 14] step 22/44: loss=0.8314 
[epoch 14] step 24/44: loss=0.8406 
[epoch 14] step 26/44: loss=0.8548 
[epoch 14] step 28/44: loss=0.8362 
[epoch 14] step 30/44: loss=0.8212 
[epoch 14] step 32/44: loss=0.8105 
[epoch 14] step 34/44: loss=0.7943 
[epoch 14] step 36/44: loss=0.7824 
[epoch 14] step 38/44: loss=0.7836 
[epoch 14] step 40/44: loss=0.7748 
[epoch 14] step 42/44: loss=0.7699 
[epoch 14] step 44/44: loss=0.7667 
[epoch 14] train_loss(avg per step)=1.5334 lambda[min,max]=[0.500001,1.000000]
[epoch 14] val_loss=4.2709 qwk=('0.6568', '0.5384', '0.6447') averageQWK=0.6133 macroEMD=0.2653 tailR0=('0.1304', '0.0833', '0.0000') tailR0avg=0.0713
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   17   34    3    0
     0   13   69   42    1
     0    0   18   97    1
     0    0    0   17    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     2    6   43    2    0
     0    5   97   19    0
     0    0   54   72    7
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   34   35    0    0
     0   17  104   30    0
     0    1   31   69    0
     0    0    0    2    0
[epoch 15] step 2/44: loss=0.9393 
[epoch 15] step 4/44: loss=0.8561 
[epoch 15] step 6/44: loss=0.7899 
[epoch 15] step 8/44: loss=0.7617 
[epoch 15] step 10/44: loss=0.7929 
[epoch 15] step 12/44: loss=0.7868 
[epoch 15] step 14/44: loss=0.7707 
[epoch 15] step 16/44: loss=0.7284 
[epoch 15] step 18/44: loss=0.7314 
[epoch 15] step 20/44: loss=0.7180 
[epoch 15] step 22/44: loss=0.7283 
[epoch 15] step 24/44: loss=0.7205 
[epoch 15] step 26/44: loss=0.6930 
[epoch 15] step 28/44: loss=0.6836 
[epoch 15] step 30/44: loss=0.6747 
[epoch 15] step 32/44: loss=0.6812 
[epoch 15] step 34/44: loss=0.6702 
[epoch 15] step 36/44: loss=0.6747 
[epoch 15] step 38/44: loss=0.6725 
[epoch 15] step 40/44: loss=0.6666 
[epoch 15] step 42/44: loss=0.6477 
[epoch 15] step 44/44: loss=0.6468 
[epoch 15] train_loss(avg per step)=1.2935 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=4.5488 qwk=('0.5838', '0.5779', '0.5748') averageQWK=0.5788 macroEMD=0.2632 tailR0=('0.2674', '0.0417', '0.0000') tailR0avg=0.1030
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    4    0    0
     0    8   44    1    1
     0    8   82   29    6
     0    0   29   72   15
     0    0    2   11   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     4   10   30    9    0
     1    8   73   39    0
     0    0   22  106    5
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   22   47    0    0
     1    6  120   24    0
     0    1   36   64    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=0.5863 
[epoch 16] step 4/44: loss=0.5746 
[epoch 16] step 6/44: loss=0.5884 
[epoch 16] step 8/44: loss=0.5695 
[epoch 16] step 10/44: loss=0.5322 
[epoch 16] step 12/44: loss=0.5110 
[epoch 16] step 14/44: loss=0.4849 
[epoch 16] step 16/44: loss=0.4841 
[epoch 16] step 18/44: loss=0.4646 
[epoch 16] step 20/44: loss=0.4448 
[epoch 16] step 22/44: loss=0.4533 
[epoch 16] step 24/44: loss=0.4508 
[epoch 16] step 26/44: loss=0.4444 
[epoch 16] step 28/44: loss=0.4436 
[epoch 16] step 30/44: loss=0.4421 
[epoch 16] step 32/44: loss=0.4490 
[epoch 16] step 34/44: loss=0.4542 
[epoch 16] step 36/44: loss=0.4521 
[epoch 16] step 38/44: loss=0.4624 
[epoch 16] step 40/44: loss=0.4567 
[epoch 16] step 42/44: loss=0.4630 
[epoch 16] step 44/44: loss=0.4579 
[epoch 16] train_loss(avg per step)=0.9157 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=4.5015 qwk=('0.6303', '0.5766', '0.6418') averageQWK=0.6162 macroEMD=0.2584 tailR0=('0.3174', '0.0833', '0.0000') tailR0avg=0.1336
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    4    0    0
     0   13   38    3    0
     0   10   78   35    2
     0    0   28   84    4
     0    0    1   12   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     4   12   30    7    0
     0   11   70   39    1
     0    1   30   98    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   34    0    0
     0   17  111   23    0
     0    1   34   66    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=0.2957 
[epoch 17] step 4/44: loss=0.3283 
[epoch 17] step 6/44: loss=0.3324 
[epoch 17] step 8/44: loss=0.3689 
[epoch 17] step 10/44: loss=0.3617 
[epoch 17] step 12/44: loss=0.3963 
[epoch 17] step 14/44: loss=0.3945 
[epoch 17] step 16/44: loss=0.3858 
[epoch 17] step 18/44: loss=0.3947 
[epoch 17] step 20/44: loss=0.4029 
[epoch 17] step 22/44: loss=0.3963 
[epoch 17] step 24/44: loss=0.3924 
[epoch 17] step 26/44: loss=0.3857 
[epoch 17] step 28/44: loss=0.3669 
[epoch 17] step 30/44: loss=0.3607 
[epoch 17] step 32/44: loss=0.3540 
[epoch 17] step 34/44: loss=0.3460 
[epoch 17] step 36/44: loss=0.3263 
[epoch 17] step 38/44: loss=0.3239 
[epoch 17] step 40/44: loss=0.3205 
[epoch 17] step 42/44: loss=0.3152 
[epoch 17] step 44/44: loss=0.3109 
[epoch 17] train_loss(avg per step)=0.6219 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=4.8459 qwk=('0.6220', '0.5714', '0.5957') averageQWK=0.5964 macroEMD=0.2546 tailR0=('0.3826', '0.0833', '0.0000') tailR0avg=0.1553
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    4    0    0
     0   16   37    0    1
     0   13   93   11    8
     0    0   39   58   19
     0    0    2    8   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     4   15   28    5    1
     0   20   67   32    2
     0    2   32   92    7
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   25   42    2    0
     0    7  121   23    0
     0    1   27   73    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=0.2366 
[epoch 18] step 4/44: loss=0.2925 
[epoch 18] step 6/44: loss=0.2734 
[epoch 18] step 8/44: loss=0.2990 
[epoch 18] step 10/44: loss=0.2640 
[epoch 18] step 12/44: loss=0.2408 
[epoch 18] step 14/44: loss=0.2313 
[epoch 18] step 16/44: loss=0.2380 
[epoch 18] step 18/44: loss=0.2472 
[epoch 18] step 20/44: loss=0.2512 
[epoch 18] step 22/44: loss=0.2504 
[epoch 18] step 24/44: loss=0.2495 
[epoch 18] step 26/44: loss=0.2486 
[epoch 18] step 28/44: loss=0.2489 
[epoch 18] step 30/44: loss=0.2600 
[epoch 18] step 32/44: loss=0.2553 
[epoch 18] step 34/44: loss=0.2528 
[epoch 18] step 36/44: loss=0.2505 
[epoch 18] step 38/44: loss=0.2483 
[epoch 18] step 40/44: loss=0.2482 
[epoch 18] step 42/44: loss=0.2471 
[epoch 18] step 44/44: loss=0.2393 
[epoch 18] train_loss(avg per step)=0.4786 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=5.2006 qwk=('0.6370', '0.5586', '0.6585') averageQWK=0.6180 macroEMD=0.2497 tailR0=('0.3391', '0.0972', '0.2000') tailR0avg=0.2121
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    3    0    0
     0   15   37    2    0
     0   12   67   40    6
     0    0   20   84   12
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     3    9   32    8    1
     0    7   71   42    1
     0    0   25  104    4
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   34   32    3    0
     1   12  107   31    0
     0    1   24   76    0
     0    0    0    2    0
[epoch 19] step 2/44: loss=0.1349 
[epoch 19] step 4/44: loss=0.2313 
[epoch 19] step 6/44: loss=0.2602 
[epoch 19] step 8/44: loss=0.2205 
[epoch 19] step 10/44: loss=0.1729 
[epoch 19] step 12/44: loss=0.1610 
[epoch 19] step 14/44: loss=0.1554 
[epoch 19] step 16/44: loss=0.1519 
[epoch 19] step 18/44: loss=0.1360 
[epoch 19] step 20/44: loss=0.1358 
[epoch 19] step 22/44: loss=0.1280 
[epoch 19] step 24/44: loss=0.1263 
[epoch 19] step 26/44: loss=0.1405 
[epoch 19] step 28/44: loss=0.1342 
[epoch 19] step 30/44: loss=0.1279 
[epoch 19] step 32/44: loss=0.1359 
[epoch 19] step 34/44: loss=0.1308 
[epoch 19] step 36/44: loss=0.1239 
[epoch 19] step 38/44: loss=0.1184 
[epoch 19] step 40/44: loss=0.1116 
[epoch 19] step 42/44: loss=0.1030 
[epoch 19] step 44/44: loss=0.1014 
[epoch 19] train_loss(avg per step)=0.2028 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=5.1321 qwk=('0.6647', '0.5852', '0.6317') averageQWK=0.6272 macroEMD=0.2400 tailR0=('0.1587', '0.1389', '0.0000') tailR0avg=0.0992
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    8    1    0    0
     0   23   31    0    0
     0   19   85   21    0
     0    0   37   79    0
     0    1    2   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    0    0
     2   15   33    3    0
     0   22   80   19    0
     0    3   43   83    4
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   43   26    0    0
     0   30  106   15    0
     0    2   41   58    0
     0    0    1    1    0
[epoch 20] step 2/44: loss=0.0870 
[epoch 20] step 4/44: loss=0.0421 
[epoch 20] step 6/44: loss=0.0077 
[epoch 20] step 8/44: loss=0.0175 
[epoch 20] step 10/44: loss=0.0634 
[epoch 20] step 12/44: loss=0.0603 
[epoch 20] step 14/44: loss=0.0489 
[epoch 20] step 16/44: loss=0.0523 
[epoch 20] step 18/44: loss=0.0557 
[epoch 20] step 20/44: loss=0.0709 
[epoch 20] step 22/44: loss=0.0685 
[epoch 20] step 24/44: loss=0.0606 
[epoch 20] step 26/44: loss=0.0595 
[epoch 20] step 28/44: loss=0.0496 
[epoch 20] step 30/44: loss=0.0511 
[epoch 20] step 32/44: loss=0.0483 
[epoch 20] step 34/44: loss=0.0498 
[epoch 20] step 36/44: loss=0.0530 
[epoch 20] step 38/44: loss=0.0508 
[epoch 20] step 40/44: loss=0.0510 
[epoch 20] step 42/44: loss=0.0459 
[epoch 20] step 44/44: loss=0.0349 
[epoch 20] train_loss(avg per step)=0.0697 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=5.6093 qwk=('0.6318', '0.5651', '0.6121') averageQWK=0.6030 macroEMD=0.2403 tailR0=('0.0870', '0.0833', '0.0000') tailR0avg=0.0568
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    1    0    0
     0   22   29    3    0
     0   27   60   37    1
     0    0   23   87    6
     0    1    1   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     1   16   30    5    1
     0   15   77   28    1
     0    1   34   94    4
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   29   40    0    0
     0   11  122   18    0
     0    1   35   65    0
     0    0    1    1    0
[epoch 21] step 2/44: loss=0.1121 
[epoch 21] step 4/44: loss=0.0198 
[epoch 21] step 6/44: loss=-0.0046 
[epoch 21] step 8/44: loss=-0.0143 
[epoch 21] step 10/44: loss=-0.0518 
[epoch 21] step 12/44: loss=-0.0631 
[epoch 21] step 14/44: loss=-0.0644 
[epoch 21] step 16/44: loss=-0.0727 
[epoch 21] step 18/44: loss=-0.0608 
[epoch 21] step 20/44: loss=-0.0580 
[epoch 21] step 22/44: loss=-0.0621 
[epoch 21] step 24/44: loss=-0.0602 
[epoch 21] step 26/44: loss=-0.0615 
[epoch 21] step 28/44: loss=-0.0543 
[epoch 21] step 30/44: loss=-0.0566 
[epoch 21] step 32/44: loss=-0.0534 
[epoch 21] step 34/44: loss=-0.0518 
[epoch 21] step 36/44: loss=-0.0521 
[epoch 21] step 38/44: loss=-0.0456 
[epoch 21] step 40/44: loss=-0.0522 
[epoch 21] step 42/44: loss=-0.0503 
[epoch 21] step 44/44: loss=-0.0518 
[epoch 21] train_loss(avg per step)=-0.1037 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=6.1010 qwk=('0.5768', '0.5344', '0.6471') averageQWK=0.5861 macroEMD=0.2462 tailR0=('0.3239', '0.0417', '0.0000') tailR0avg=0.1219
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    5    0    0
     0    9   42    2    1
     0    7   87   27    4
     0    0   32   74   10
     0    0    3   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     3    8   33    8    1
     0    8   71   41    1
     0    0   27  103    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   40   28    1    0
     1   18   95   37    0
     0    1   26   74    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=-0.1369 
[epoch 22] step 4/44: loss=-0.1368 
[epoch 22] step 6/44: loss=-0.1007 
[epoch 22] step 8/44: loss=-0.0958 
[epoch 22] step 10/44: loss=-0.0692 
[epoch 22] step 12/44: loss=-0.0737 
[epoch 22] step 14/44: loss=-0.0729 
[epoch 22] step 16/44: loss=-0.0896 
[epoch 22] step 18/44: loss=-0.1020 
[epoch 22] step 20/44: loss=-0.1071 
[epoch 22] step 22/44: loss=-0.0945 
[epoch 22] step 24/44: loss=-0.0869 
[epoch 22] step 26/44: loss=-0.0934 
[epoch 22] step 28/44: loss=-0.0930 
[epoch 22] step 30/44: loss=-0.0996 
[epoch 22] step 32/44: loss=-0.1011 
[epoch 22] step 34/44: loss=-0.1016 
[epoch 22] step 36/44: loss=-0.0948 
[epoch 22] step 38/44: loss=-0.0955 
[epoch 22] step 40/44: loss=-0.0983 
[epoch 22] step 42/44: loss=-0.0999 
[epoch 22] step 44/44: loss=-0.1023 
[epoch 22] train_loss(avg per step)=-0.2046 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=6.5106 qwk=('0.5851', '0.5278', '0.6542') averageQWK=0.5891 macroEMD=0.2426 tailR0=('0.3674', '0.0417', '0.0000') tailR0avg=0.1364
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    5    0    0
     1   10   40    2    1
     1    7   80   30    7
     0    0   30   76   10
     0    0    1   12   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1    9   34    8    1
     0    8   73   39    1
     0    0   28  102    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   34   35    0    0
     0   13  105   33    0
     0    1   26   74    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=-0.2048 
[epoch 23] step 4/44: loss=-0.1667 
[epoch 23] step 6/44: loss=-0.1597 
[epoch 23] step 8/44: loss=-0.1457 
[epoch 23] step 10/44: loss=-0.1366 
[epoch 23] step 12/44: loss=-0.1413 
[epoch 23] step 14/44: loss=-0.1521 
[epoch 23] step 16/44: loss=-0.1463 
[epoch 23] step 18/44: loss=-0.1548 
[epoch 23] step 20/44: loss=-0.1629 
[epoch 23] step 22/44: loss=-0.1520 
[epoch 23] step 24/44: loss=-0.1511 
[epoch 23] step 26/44: loss=-0.1501 
[epoch 23] step 28/44: loss=-0.1524 
[epoch 23] step 30/44: loss=-0.1523 
[epoch 23] step 32/44: loss=-0.1527 
[epoch 23] step 34/44: loss=-0.1465 
[epoch 23] step 36/44: loss=-0.1468 
[epoch 23] step 38/44: loss=-0.1463 
[epoch 23] step 40/44: loss=-0.1473 
[epoch 23] step 42/44: loss=-0.1451 
[epoch 23] step 44/44: loss=-0.1397 
[epoch 23] train_loss(avg per step)=-0.2795 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=6.2177 qwk=('0.6472', '0.5419', '0.6324') averageQWK=0.6072 macroEMD=0.2404 tailR0=('0.3391', '0.0833', '0.0000') tailR0avg=0.1408
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    2    0    0
     2   19   30    2    1
     2   18   70   30    5
     0    0   25   83    8
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   15   35    2    1
     0   16   84   19    2
     0    0   49   78    6
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   35    2    0
     0   12  108   31    0
     0    0   30   71    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=-0.2047 
[epoch 24] step 4/44: loss=-0.1997 
[epoch 24] step 6/44: loss=-0.1671 
[epoch 24] step 8/44: loss=-0.1804 
[epoch 24] step 10/44: loss=-0.1743 
[epoch 24] step 12/44: loss=-0.1876 
[epoch 24] step 14/44: loss=-0.1992 
[epoch 24] step 16/44: loss=-0.1956 
[epoch 24] step 18/44: loss=-0.2033 
[epoch 24] step 20/44: loss=-0.1953 
[epoch 24] step 22/44: loss=-0.1954 
[epoch 24] step 24/44: loss=-0.1943 
[epoch 24] step 26/44: loss=-0.1919 
[epoch 24] step 28/44: loss=-0.1914 
[epoch 24] step 30/44: loss=-0.1914 
[epoch 24] step 32/44: loss=-0.1897 
[epoch 24] step 34/44: loss=-0.1831 
[epoch 24] step 36/44: loss=-0.1835 
[epoch 24] step 38/44: loss=-0.1791 
[epoch 24] step 40/44: loss=-0.1806 
[epoch 24] step 42/44: loss=-0.1834 
[epoch 24] step 44/44: loss=-0.1850 
[epoch 24] train_loss(avg per step)=-0.3699 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=6.6401 qwk=('0.5931', '0.5352', '0.6397') averageQWK=0.5893 macroEMD=0.2390 tailR0=('0.2174', '0.0833', '0.1000') tailR0avg=0.1336
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   16   36    1    1
     0   16   79   23    7
     0    0   30   75   11
     0    1    2   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0    9   40    4    0
     0    9   85   27    0
     0    0   44   88    1
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   35   33    1    0
     1   14  107   29    0
     0    1   33   67    0
     0    0    0    2    0
[epoch 25] step 2/44: loss=-0.2038 
[epoch 25] step 4/44: loss=-0.1853 
[epoch 25] step 6/44: loss=-0.1867 
[epoch 25] step 8/44: loss=-0.2004 
[epoch 25] step 10/44: loss=-0.2102 
[epoch 25] step 12/44: loss=-0.2187 
[epoch 25] step 14/44: loss=-0.2218 
[epoch 25] step 16/44: loss=-0.2193 
[epoch 25] step 18/44: loss=-0.2201 
[epoch 25] step 20/44: loss=-0.2208 
[epoch 25] step 22/44: loss=-0.2193 
[epoch 25] step 24/44: loss=-0.2179 
[epoch 25] step 26/44: loss=-0.2147 
[epoch 25] step 28/44: loss=-0.2146 
[epoch 25] step 30/44: loss=-0.2167 
[epoch 25] step 32/44: loss=-0.2179 
[epoch 25] step 34/44: loss=-0.2174 
[epoch 25] step 36/44: loss=-0.2165 
[epoch 25] step 38/44: loss=-0.2163 
[epoch 25] step 40/44: loss=-0.2146 
[epoch 25] step 42/44: loss=-0.2141 
[epoch 25] step 44/44: loss=-0.2109 
[epoch 25] train_loss(avg per step)=-0.4217 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=6.8237 qwk=('0.6317', '0.5952', '0.6401') averageQWK=0.6223 macroEMD=0.2359 tailR0=('0.2391', '0.1389', '0.0000') tailR0avg=0.1260
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   18   35    1    0
     0   17   73   30    5
     0    0   30   76   10
     0    0    2   10   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     4   13   28    8    0
     0   16   61   43    1
     0    0   23  107    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   37   30    2    0
     0   15  106   30    0
     0    1   27   73    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=-0.3037 
[epoch 26] step 4/44: loss=-0.3033 
[epoch 26] step 6/44: loss=-0.2901 
[epoch 26] step 8/44: loss=-0.2508 
[epoch 26] step 10/44: loss=-0.2517 
[epoch 26] step 12/44: loss=-0.2501 
[epoch 26] step 14/44: loss=-0.2549 
[epoch 26] step 16/44: loss=-0.2559 
[epoch 26] step 18/44: loss=-0.2529 
[epoch 26] step 20/44: loss=-0.2492 
[epoch 26] step 22/44: loss=-0.2505 
[epoch 26] step 24/44: loss=-0.2513 
[epoch 26] step 26/44: loss=-0.2538 
[epoch 26] step 28/44: loss=-0.2531 
[epoch 26] step 30/44: loss=-0.2496 
[epoch 26] step 32/44: loss=-0.2474 
[epoch 26] step 34/44: loss=-0.2402 
[epoch 26] step 36/44: loss=-0.2353 
[epoch 26] step 38/44: loss=-0.2372 
[epoch 26] step 40/44: loss=-0.2340 
[epoch 26] step 42/44: loss=-0.2359 
[epoch 26] step 44/44: loss=-0.2381 
[epoch 26] train_loss(avg per step)=-0.4761 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=6.8135 qwk=('0.6311', '0.5806', '0.6484') averageQWK=0.6201 macroEMD=0.2315 tailR0=('0.2174', '0.0833', '0.0000') tailR0avg=0.1002
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    0    0    0
     0   28   24    1    1
     0   35   55   26    9
     0    0   27   71   18
     0    1    1   11   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     2   10   38    3    0
     0   16   79   26    0
     0    0   41   89    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   37   30    2    0
     0   17  105   29    0
     0    1   27   73    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=-0.2007 
[epoch 27] step 4/44: loss=-0.2264 
[epoch 27] step 6/44: loss=-0.1959 
[epoch 27] step 8/44: loss=-0.2069 
[epoch 27] step 10/44: loss=-0.2207 
[epoch 27] step 12/44: loss=-0.2224 
[epoch 27] step 14/44: loss=-0.2294 
[epoch 27] step 16/44: loss=-0.2277 
[epoch 27] step 18/44: loss=-0.2364 
[epoch 27] step 20/44: loss=-0.2449 
[epoch 27] step 22/44: loss=-0.2492 
[epoch 27] step 24/44: loss=-0.2524 
[epoch 27] step 26/44: loss=-0.2528 
[epoch 27] step 28/44: loss=-0.2517 
[epoch 27] step 30/44: loss=-0.2540 
[epoch 27] step 32/44: loss=-0.2550 
[epoch 27] step 34/44: loss=-0.2547 
[epoch 27] step 36/44: loss=-0.2529 
[epoch 27] step 38/44: loss=-0.2521 
[epoch 27] step 40/44: loss=-0.2504 
[epoch 27] step 42/44: loss=-0.2493 
[epoch 27] step 44/44: loss=-0.2537 
[epoch 27] train_loss(avg per step)=-0.5073 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=7.1706 qwk=('0.6310', '0.5578', '0.6392') averageQWK=0.6094 macroEMD=0.2337 tailR0=('0.4174', '0.1389', '0.0000') tailR0avg=0.1854
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    3    3    0    0
     2   17   33    1    1
     2   16   70   31    6
     0    0   26   80   10
     0    0    2   11   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   10   36    6    0
     0   10   75   36    0
     0    0   34   96    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   33   36    0    0
     0   16  114   21    0
     0    0   37   64    0
     0    0    0    2    0
[epoch 28] step 2/44: loss=-0.2977 
[epoch 28] step 4/44: loss=-0.2933 
[epoch 28] step 6/44: loss=-0.2755 
[epoch 28] step 8/44: loss=-0.2757 
[epoch 28] step 10/44: loss=-0.2786 
[epoch 28] step 12/44: loss=-0.2751 
[epoch 28] step 14/44: loss=-0.2746 
[epoch 28] step 16/44: loss=-0.2719 
[epoch 28] step 18/44: loss=-0.2639 
[epoch 28] step 20/44: loss=-0.2605 
[epoch 28] step 22/44: loss=-0.2671 
[epoch 28] step 24/44: loss=-0.2703 
[epoch 28] step 26/44: loss=-0.2699 
[epoch 28] step 28/44: loss=-0.2698 
[epoch 28] step 30/44: loss=-0.2674 
[epoch 28] step 32/44: loss=-0.2697 
[epoch 28] step 34/44: loss=-0.2706 
[epoch 28] step 36/44: loss=-0.2690 
[epoch 28] step 38/44: loss=-0.2683 
[epoch 28] step 40/44: loss=-0.2659 
[epoch 28] step 42/44: loss=-0.2634 
[epoch 28] step 44/44: loss=-0.2649 
[epoch 28] train_loss(avg per step)=-0.5298 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=7.3593 qwk=('0.6526', '0.5680', '0.6644') averageQWK=0.6284 macroEMD=0.2245 tailR0=('0.3457', '0.0833', '0.0000') tailR0avg=0.1430
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    5    2    0    0
     3   16   33    1    1
     0   18   72   31    4
     0    0   24   82   10
     0    0    2   12    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     4   12   30    7    0
     0   19   65   36    1
     0    0   30   99    4
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   39   29    1    0
     0   16  100   35    0
     0    0   27   74    0
     0    0    0    2    0
[epoch 29] step 2/44: loss=-0.2979 
[epoch 29] step 4/44: loss=-0.3130 
[epoch 29] step 6/44: loss=-0.3053 
[epoch 29] step 8/44: loss=-0.3096 
[epoch 29] step 10/44: loss=-0.3054 
[epoch 29] step 12/44: loss=-0.3046 
[epoch 29] step 14/44: loss=-0.3047 
[epoch 29] step 16/44: loss=-0.3048 
[epoch 29] step 18/44: loss=-0.3060 
[epoch 29] step 20/44: loss=-0.3036 
[epoch 29] step 22/44: loss=-0.3040 
[epoch 29] step 24/44: loss=-0.2959 
[epoch 29] step 26/44: loss=-0.2928 
[epoch 29] step 28/44: loss=-0.2903 
[epoch 29] step 30/44: loss=-0.2923 
[epoch 29] step 32/44: loss=-0.2923 
[epoch 29] step 34/44: loss=-0.2915 
[epoch 29] step 36/44: loss=-0.2909 
[epoch 29] step 38/44: loss=-0.2900 
[epoch 29] step 40/44: loss=-0.2903 
[epoch 29] step 42/44: loss=-0.2908 
[epoch 29] step 44/44: loss=-0.2901 
[epoch 29] train_loss(avg per step)=-0.5801 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=7.5500 qwk=('0.6030', '0.5737', '0.6105') averageQWK=0.5957 macroEMD=0.2298 tailR0=('0.3043', '0.1389', '0.0000') tailR0avg=0.1477
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   15   37    1    1
     0   14   79   20   12
     0    0   28   62   26
     0    0    2    7   14
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     4   12   29    7    1
     0   16   69   35    1
     0    0   29  100    4
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   26   42    1    0
     0   11  121   19    0
     0    0   35   66    0
     0    0    0    2    0
[epoch 30] step 2/44: loss=-0.3071 
[epoch 30] step 4/44: loss=-0.2924 
[epoch 30] step 6/44: loss=-0.3002 
[epoch 30] step 8/44: loss=-0.2942 
[epoch 30] step 10/44: loss=-0.3018 
[epoch 30] step 12/44: loss=-0.2902 
[epoch 30] step 14/44: loss=-0.2903 
[epoch 30] step 16/44: loss=-0.2932 
[epoch 30] step 18/44: loss=-0.2900 
[epoch 30] step 20/44: loss=-0.2889 
[epoch 30] step 22/44: loss=-0.2918 
[epoch 30] step 24/44: loss=-0.2894 
[epoch 30] step 26/44: loss=-0.2893 
[epoch 30] step 28/44: loss=-0.2885 
[epoch 30] step 30/44: loss=-0.2909 
[epoch 30] step 32/44: loss=-0.2916 
[epoch 30] step 34/44: loss=-0.2921 
[epoch 30] step 36/44: loss=-0.2929 
[epoch 30] step 38/44: loss=-0.2891 
[epoch 30] step 40/44: loss=-0.2912 
[epoch 30] step 42/44: loss=-0.2922 
[epoch 30] step 44/44: loss=-0.2936 
[epoch 30] train_loss(avg per step)=-0.5872 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=7.4248 qwk=('0.6486', '0.5885', '0.6428') averageQWK=0.6266 macroEMD=0.2296 tailR0=('0.3391', '0.1389', '0.0000') tailR0avg=0.1593
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    2    0    0
     1   18   33    1    1
     0   18   70   32    5
     0    0   26   79   11
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     3   11   35    3    1
     0    7   83   30    1
     0    0   36   92    5
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   35    2    0
     0   15  107   29    0
     0    0   27   74    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=-0.2783 
[epoch 31] step 4/44: loss=-0.2916 
[epoch 31] step 6/44: loss=-0.3045 
[epoch 31] step 8/44: loss=-0.3058 
[epoch 31] step 10/44: loss=-0.3105 
[epoch 31] step 12/44: loss=-0.3134 
[epoch 31] step 14/44: loss=-0.3104 
[epoch 31] step 16/44: loss=-0.3115 
[epoch 31] step 18/44: loss=-0.3139 
[epoch 31] step 20/44: loss=-0.3128 
[epoch 31] step 22/44: loss=-0.3122 
[epoch 31] step 24/44: loss=-0.3128 
[epoch 31] step 26/44: loss=-0.3144 
[epoch 31] step 28/44: loss=-0.3138 
[epoch 31] step 30/44: loss=-0.3153 
[epoch 31] step 32/44: loss=-0.3131 
[epoch 31] step 34/44: loss=-0.3137 
[epoch 31] step 36/44: loss=-0.3104 
[epoch 31] step 38/44: loss=-0.3079 
[epoch 31] step 40/44: loss=-0.3072 
[epoch 31] step 42/44: loss=-0.3049 
[epoch 31] step 44/44: loss=-0.3037 
[epoch 31] train_loss(avg per step)=-0.6073 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=7.7350 qwk=('0.6606', '0.5852', '0.6614') averageQWK=0.6357 macroEMD=0.2235 tailR0=('0.4391', '0.0972', '0.0000') tailR0avg=0.1788
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    4    2    0    0
     2   18   32    2    0
     0   16   61   42    6
     0    0   21   88    7
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     4   12   29    7    1
     0   16   62   42    1
     0    0   21  109    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   33    1    0
     0   15  110   26    0
     0    0   29   72    0
     0    0    0    2    0
[epoch 32] step 2/44: loss=-0.3111 
[epoch 32] step 4/44: loss=-0.3054 
[epoch 32] step 6/44: loss=-0.3103 
[epoch 32] step 8/44: loss=-0.3093 
[epoch 32] step 10/44: loss=-0.3090 
[epoch 32] step 12/44: loss=-0.3116 
[epoch 32] step 14/44: loss=-0.3042 
[epoch 32] step 16/44: loss=-0.3092 
[epoch 32] step 18/44: loss=-0.3073 
[epoch 32] step 20/44: loss=-0.3077 
[epoch 32] step 22/44: loss=-0.3054 
[epoch 32] step 24/44: loss=-0.3077 
[epoch 32] step 26/44: loss=-0.3089 
[epoch 32] step 28/44: loss=-0.3098 
[epoch 32] step 30/44: loss=-0.3114 
[epoch 32] step 32/44: loss=-0.3125 
[epoch 32] step 34/44: loss=-0.3137 
[epoch 32] step 36/44: loss=-0.3124 
[epoch 32] step 38/44: loss=-0.3128 
[epoch 32] step 40/44: loss=-0.3128 
[epoch 32] step 42/44: loss=-0.3130 
[epoch 32] step 44/44: loss=-0.3137 
[epoch 32] train_loss(avg per step)=-0.6273 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=7.4995 qwk=('0.6173', '0.5484', '0.6739') averageQWK=0.6132 macroEMD=0.2256 tailR0=('0.2891', '0.0000', '0.0000') tailR0avg=0.0964
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    3    0    0
     0   21   31    1    1
     0   24   69   22   10
     0    0   27   75   14
     0    0    2   10   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   11   35    5    1
     0   14   73   34    0
     0    0   33   97    3
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   42   26    1    0
     0   23  104   24    0
     0    1   30   70    0
     0    0    0    2    0
[epoch 33] step 2/44: loss=-0.3197 
[epoch 33] step 4/44: loss=-0.3289 
[epoch 33] step 6/44: loss=-0.3306 
[epoch 33] step 8/44: loss=-0.3256 
[epoch 33] step 10/44: loss=-0.3150 
[epoch 33] step 12/44: loss=-0.3132 
[epoch 33] step 14/44: loss=-0.3125 
[epoch 33] step 16/44: loss=-0.3082 
[epoch 33] step 18/44: loss=-0.3089 
[epoch 33] step 20/44: loss=-0.3080 
[epoch 33] step 22/44: loss=-0.3075 
[epoch 33] step 24/44: loss=-0.3087 
[epoch 33] step 26/44: loss=-0.3098 
[epoch 33] step 28/44: loss=-0.3073 
[epoch 33] step 30/44: loss=-0.3089 
[epoch 33] step 32/44: loss=-0.3106 
[epoch 33] step 34/44: loss=-0.3109 
[epoch 33] step 36/44: loss=-0.3113 
[epoch 33] step 38/44: loss=-0.3101 
[epoch 33] step 40/44: loss=-0.3110 
[epoch 33] step 42/44: loss=-0.3101 
[epoch 33] step 44/44: loss=-0.3106 
[epoch 33] train_loss(avg per step)=-0.6212 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=7.7365 qwk=('0.6103', '0.5281', '0.6339') averageQWK=0.5908 macroEMD=0.2324 tailR0=('0.2891', '0.0417', '0.0000') tailR0avg=0.1103
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    4    0    0
     0   13   39    1    1
     0    9   86   23    7
     0    0   28   75   13
     0    0    2   10   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     1    8   39    4    1
     0    5   84   32    0
     0    0   37   94    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   36    1    0
     0   14  112   25    0
     0    1   31   69    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=-0.3138 
[epoch 34] step 4/44: loss=-0.3096 
[epoch 34] step 6/44: loss=-0.3110 
[epoch 34] step 8/44: loss=-0.3174 
[epoch 34] step 10/44: loss=-0.3163 
[epoch 34] step 12/44: loss=-0.3195 
[epoch 34] step 14/44: loss=-0.3198 
[epoch 34] step 16/44: loss=-0.3163 
[epoch 34] step 18/44: loss=-0.3181 
[epoch 34] step 20/44: loss=-0.3190 
[epoch 34] step 22/44: loss=-0.3200 
[epoch 34] step 24/44: loss=-0.3192 
[epoch 34] step 26/44: loss=-0.3195 
[epoch 34] step 28/44: loss=-0.3197 
[epoch 34] step 30/44: loss=-0.3174 
[epoch 34] step 32/44: loss=-0.3160 
[epoch 34] step 34/44: loss=-0.3168 
[epoch 34] step 36/44: loss=-0.3177 
[epoch 34] step 38/44: loss=-0.3182 
[epoch 34] step 40/44: loss=-0.3188 
[epoch 34] step 42/44: loss=-0.3173 
[epoch 34] step 44/44: loss=-0.3183 
[epoch 34] train_loss(avg per step)=-0.6366 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=7.4443 qwk=('0.6568', '0.5878', '0.6634') averageQWK=0.6360 macroEMD=0.2247 tailR0=('0.3891', '0.1389', '0.1000') tailR0avg=0.2093
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    3    0    0
     1   21   30    2    0
     1   20   76   22    6
     0    0   28   78   10
     0    0    2   10   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    0    0
     4   13   31    4    1
     0   20   70   31    0
     0    1   36   93    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   36   32    1    0
     0   15  114   22    0
     0    1   33   67    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=-0.3319 
[epoch 35] step 4/44: loss=-0.3176 
[epoch 35] step 6/44: loss=-0.3117 
[epoch 35] step 8/44: loss=-0.3199 
[epoch 35] step 10/44: loss=-0.3230 
[epoch 35] step 12/44: loss=-0.3200 
[epoch 35] step 14/44: loss=-0.3224 
[epoch 35] step 16/44: loss=-0.3223 
[epoch 35] step 18/44: loss=-0.3222 
[epoch 35] step 20/44: loss=-0.3206 
[epoch 35] step 22/44: loss=-0.3228 
[epoch 35] step 24/44: loss=-0.3214 
[epoch 35] step 26/44: loss=-0.3226 
[epoch 35] step 28/44: loss=-0.3226 
[epoch 35] step 30/44: loss=-0.3210 
[epoch 35] step 32/44: loss=-0.3188 
[epoch 35] step 34/44: loss=-0.3193 
[epoch 35] step 36/44: loss=-0.3194 
[epoch 35] step 38/44: loss=-0.3203 
[epoch 35] step 40/44: loss=-0.3209 
[epoch 35] step 42/44: loss=-0.3216 
[epoch 35] step 44/44: loss=-0.3220 
[epoch 35] train_loss(avg per step)=-0.6440 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=7.5528 qwk=('0.6221', '0.5595', '0.6511') averageQWK=0.6109 macroEMD=0.2269 tailR0=('0.2891', '0.0833', '0.0000') tailR0avg=0.1242
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    4    0    0
     0   18   34    1    1
     0   16   76   27    6
     0    0   27   77   12
     0    0    2   10   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     3   11   34    4    1
     0   13   75   33    0
     0    0   37   93    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   38   30    1    0
     0   16  108   27    0
     0    1   31   69    0
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-1-reassignment-0/fold2/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-1-reassignment-0/fold2/metrics.json
Done.
