[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.5768 
[epoch 1] step 4/44: loss=6.1931 
[epoch 1] step 6/44: loss=6.0733 
[epoch 1] step 8/44: loss=5.9616 
[epoch 1] step 10/44: loss=5.8711 
[epoch 1] step 12/44: loss=5.8563 
[epoch 1] step 14/44: loss=5.8777 
[epoch 1] step 16/44: loss=5.9082 
[epoch 1] step 18/44: loss=5.9740 
[epoch 1] step 20/44: loss=5.9494 
[epoch 1] step 22/44: loss=5.9458 
[epoch 1] step 24/44: loss=5.9730 
[epoch 1] step 26/44: loss=5.9377 
[epoch 1] step 28/44: loss=5.8854 
[epoch 1] step 30/44: loss=5.8713 
[epoch 1] step 32/44: loss=5.8862 
[epoch 1] step 34/44: loss=5.8681 
[epoch 1] step 36/44: loss=5.8382 
[epoch 1] step 38/44: loss=5.8046 
[epoch 1] step 40/44: loss=5.7437 
[epoch 1] step 42/44: loss=5.6852 
[epoch 1] step 44/44: loss=5.6746 
[epoch 1] train_loss(avg per step)=11.3492 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=5.8253 qwk=('0.1520', '0.2295', '0.1885') averageQWK=0.1900 macroEMD=0.3710 tailR0=('0.0000', '0.1111', '0.0000') tailR0avg=0.0370
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    6    0
     0   18    1   36    0
     0   33    0   92    0
     0   26    0   90    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    6    1    0
    14    0   19   19    0
    27    0   24   70    0
    15    0   21   98    0
     1    0    2    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0    4   60    5    0
     0    6  132   13    0
     0    1   74   26    0
     0    0    2    0    0
[epoch 2] step 2/44: loss=4.4665 
[epoch 2] step 4/44: loss=4.1459 
[epoch 2] step 6/44: loss=4.1924 
[epoch 2] step 8/44: loss=4.1291 
[epoch 2] step 10/44: loss=4.0901 
[epoch 2] step 12/44: loss=4.0547 
[epoch 2] step 14/44: loss=3.9975 
[epoch 2] step 16/44: loss=3.8972 
[epoch 2] step 18/44: loss=3.8202 
[epoch 2] step 20/44: loss=3.7361 
[epoch 2] step 22/44: loss=3.6634 
[epoch 2] step 24/44: loss=3.5949 
[epoch 2] step 26/44: loss=3.5358 
[epoch 2] step 28/44: loss=3.4986 
[epoch 2] step 30/44: loss=3.4716 
[epoch 2] step 32/44: loss=3.4365 
[epoch 2] step 34/44: loss=3.4110 
[epoch 2] step 36/44: loss=3.3610 
[epoch 2] step 38/44: loss=3.3442 
[epoch 2] step 40/44: loss=3.3279 
[epoch 2] step 42/44: loss=3.3156 
[epoch 2] step 44/44: loss=3.3149 
[epoch 2] train_loss(avg per step)=6.6299 lambda[min,max]=[0.501602,1.000000]
[epoch 2] val_loss=3.8557 qwk=('0.3200', '0.2966', '0.3473') averageQWK=0.3213 macroEMD=0.3813 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    0    0
     0   50    4    1    0
     0   82   18   25    0
     0   47   12   57    0
     0   11    2   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    0   30   22    0
     0    0   27   94    0
     0    0    2  132    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0    6   45   18    0
     0    2   60   89    0
     0    1    8   92    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=2.7187 
[epoch 3] step 4/44: loss=2.8348 
[epoch 3] step 6/44: loss=2.8988 
[epoch 3] step 8/44: loss=2.8371 
[epoch 3] step 10/44: loss=2.8164 
[epoch 3] step 12/44: loss=2.7871 
[epoch 3] step 14/44: loss=2.7830 
[epoch 3] step 16/44: loss=2.7770 
[epoch 3] step 18/44: loss=2.7921 
[epoch 3] step 20/44: loss=2.7682 
[epoch 3] step 22/44: loss=2.7901 
[epoch 3] step 24/44: loss=2.7950 
[epoch 3] step 26/44: loss=2.7922 
[epoch 3] step 28/44: loss=2.7900 
[epoch 3] step 30/44: loss=2.7692 
[epoch 3] step 32/44: loss=2.7566 
[epoch 3] step 34/44: loss=2.7431 
[epoch 3] step 36/44: loss=2.7374 
[epoch 3] step 38/44: loss=2.7363 
[epoch 3] step 40/44: loss=2.7101 
[epoch 3] step 42/44: loss=2.6959 
[epoch 3] step 44/44: loss=2.6933 
[epoch 3] train_loss(avg per step)=5.3866 lambda[min,max]=[0.523803,1.000000]
[epoch 3] val_loss=3.3711 qwk=('0.4557', '0.6360', '0.5505') averageQWK=0.5474 macroEMD=0.3594 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    0
     0    4   49    2    0
     0    1  104   20    0
     0    0   35   81    0
     0    1    7   15    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   35   16    1    0
     0   29   68   24    0
     0    6   23  105    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   15   52    2    0
     0    4  126   21    0
     0    1   31   69    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=2.4502 
[epoch 4] step 4/44: loss=2.2077 
[epoch 4] step 6/44: loss=2.3793 
[epoch 4] step 8/44: loss=2.4436 
[epoch 4] step 10/44: loss=2.4017 
[epoch 4] step 12/44: loss=2.4787 
[epoch 4] step 14/44: loss=2.4685 
[epoch 4] step 16/44: loss=2.4780 
[epoch 4] step 18/44: loss=2.5173 
[epoch 4] step 20/44: loss=2.4971 
[epoch 4] step 22/44: loss=2.5051 
[epoch 4] step 24/44: loss=2.5167 
[epoch 4] step 26/44: loss=2.5104 
[epoch 4] step 28/44: loss=2.5123 
[epoch 4] step 30/44: loss=2.4822 
[epoch 4] step 32/44: loss=2.4625 
[epoch 4] step 34/44: loss=2.4713 
[epoch 4] step 36/44: loss=2.4641 
[epoch 4] step 38/44: loss=2.4648 
[epoch 4] step 40/44: loss=2.4522 
[epoch 4] step 42/44: loss=2.4430 
[epoch 4] step 44/44: loss=2.4360 
[epoch 4] train_loss(avg per step)=4.8720 lambda[min,max]=[0.506506,1.000000]
[epoch 4] val_loss=3.2704 qwk=('0.5542', '0.5287', '0.5451') averageQWK=0.5427 macroEMD=0.3471 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   25   29    1    0
     0   10  102   13    0
     0    0   49   67    0
     0    0    8   15    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    0
     0    8   43    1    0
     0    2  102   17    0
     0    0   44   90    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   11   57    1    0
     0    5  127   19    0
     0    0   33   68    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=2.2782 
[epoch 5] step 4/44: loss=2.1432 
[epoch 5] step 6/44: loss=2.1337 
[epoch 5] step 8/44: loss=2.1708 
[epoch 5] step 10/44: loss=2.1788 
[epoch 5] step 12/44: loss=2.1661 
[epoch 5] step 14/44: loss=2.1566 
[epoch 5] step 16/44: loss=2.1362 
[epoch 5] step 18/44: loss=2.1404 
[epoch 5] step 20/44: loss=2.1590 
[epoch 5] step 22/44: loss=2.1498 
[epoch 5] step 24/44: loss=2.1439 
[epoch 5] step 26/44: loss=2.1392 
[epoch 5] step 28/44: loss=2.1499 
[epoch 5] step 30/44: loss=2.1463 
[epoch 5] step 32/44: loss=2.1357 
[epoch 5] step 34/44: loss=2.1351 
[epoch 5] step 36/44: loss=2.1359 
[epoch 5] step 38/44: loss=2.1296 
[epoch 5] step 40/44: loss=2.1300 
[epoch 5] step 42/44: loss=2.1274 
[epoch 5] step 44/44: loss=2.1279 
[epoch 5] train_loss(avg per step)=4.2558 lambda[min,max]=[0.503348,1.000000]
[epoch 5] val_loss=3.3708 qwk=('0.4023', '0.6486', '0.5239') averageQWK=0.5249 macroEMD=0.3363 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    0
     0    9   45    1    0
     0    1  113   11    0
     0    0   58   58    0
     0    0   12   11    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   39   10    3    0
     0   45   46   30    0
     0    6   14  114    0
     0    1    0   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   22   47    0    0
     0    7  138    6    0
     0    0   54   47    0
     0    0    1    1    0
[epoch 6] step 2/44: loss=1.9476 
[epoch 6] step 4/44: loss=1.8638 
[epoch 6] step 6/44: loss=1.9019 
[epoch 6] step 8/44: loss=1.9176 
[epoch 6] step 10/44: loss=1.9393 
[epoch 6] step 12/44: loss=1.9243 
[epoch 6] step 14/44: loss=1.9733 
[epoch 6] step 16/44: loss=1.9680 
[epoch 6] step 18/44: loss=1.9754 
[epoch 6] step 20/44: loss=1.9786 
[epoch 6] step 22/44: loss=1.9755 
[epoch 6] step 24/44: loss=1.9752 
[epoch 6] step 26/44: loss=1.9983 
[epoch 6] step 28/44: loss=1.9856 
[epoch 6] step 30/44: loss=1.9764 
[epoch 6] step 32/44: loss=1.9712 
[epoch 6] step 34/44: loss=1.9867 
[epoch 6] step 36/44: loss=1.9784 
[epoch 6] step 38/44: loss=1.9703 
[epoch 6] step 40/44: loss=1.9570 
[epoch 6] step 42/44: loss=1.9650 
[epoch 6] step 44/44: loss=1.9653 
[epoch 6] train_loss(avg per step)=3.9306 lambda[min,max]=[0.501854,1.000000]
[epoch 6] val_loss=3.1956 qwk=('0.5610', '0.5762', '0.6629') averageQWK=0.6000 macroEMD=0.3176 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   17   34    4    0
     0    3   87   35    0
     0    0   19   97    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   21   21   10    0
     0   11   55   55    0
     0    1    8  125    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   36   32    1    0
     0   21  102   28    0
     0    2   17   82    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=1.8022 
[epoch 7] step 4/44: loss=1.8031 
[epoch 7] step 6/44: loss=1.8327 
[epoch 7] step 8/44: loss=1.8389 
[epoch 7] step 10/44: loss=1.8489 
[epoch 7] step 12/44: loss=1.8496 
[epoch 7] step 14/44: loss=1.8558 
[epoch 7] step 16/44: loss=1.8543 
[epoch 7] step 18/44: loss=1.8687 
[epoch 7] step 20/44: loss=1.8641 
[epoch 7] step 22/44: loss=1.8429 
[epoch 7] step 24/44: loss=1.8504 
[epoch 7] step 26/44: loss=1.8404 
[epoch 7] step 28/44: loss=1.8289 
[epoch 7] step 30/44: loss=1.8318 
[epoch 7] step 32/44: loss=1.8286 
[epoch 7] step 34/44: loss=1.8279 
[epoch 7] step 36/44: loss=1.8348 
[epoch 7] step 38/44: loss=1.8310 
[epoch 7] step 40/44: loss=1.8259 
[epoch 7] step 42/44: loss=1.8171 
[epoch 7] step 44/44: loss=1.8073 
[epoch 7] train_loss(avg per step)=3.6146 lambda[min,max]=[0.500184,1.000000]
[epoch 7] val_loss=3.1956 qwk=('0.6119', '0.5562', '0.6594') averageQWK=0.6092 macroEMD=0.3105 tailR0=('0.0000', '0.0556', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   33   21    0    1
     0   27   83   15    0
     0    1   41   72    2
     0    0    6   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    0    0
     1    9   41    1    0
     0    3  108   10    0
     0    0   49   85    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   42   27    0    0
     0   26  108   17    0
     0    2   33   66    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=1.6254 
[epoch 8] step 4/44: loss=1.5312 
[epoch 8] step 6/44: loss=1.4984 
[epoch 8] step 8/44: loss=1.6318 
[epoch 8] step 10/44: loss=1.6936 
[epoch 8] step 12/44: loss=1.7201 
[epoch 8] step 14/44: loss=1.7229 
[epoch 8] step 16/44: loss=1.7110 
[epoch 8] step 18/44: loss=1.6982 
[epoch 8] step 20/44: loss=1.6998 
[epoch 8] step 22/44: loss=1.7201 
[epoch 8] step 24/44: loss=1.7172 
[epoch 8] step 26/44: loss=1.7134 
[epoch 8] step 28/44: loss=1.7126 
[epoch 8] step 30/44: loss=1.7088 
[epoch 8] step 32/44: loss=1.7138 
[epoch 8] step 34/44: loss=1.7035 
[epoch 8] step 36/44: loss=1.6827 
[epoch 8] step 38/44: loss=1.6710 
[epoch 8] step 40/44: loss=1.6578 
[epoch 8] step 42/44: loss=1.6564 
[epoch 8] step 44/44: loss=1.6714 
[epoch 8] train_loss(avg per step)=3.3427 lambda[min,max]=[0.500108,1.000000]
[epoch 8] val_loss=3.1597 qwk=('0.6455', '0.6908', '0.6446') averageQWK=0.6603 macroEMD=0.2952 tailR0=('0.0000', '0.0556', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   22   32    1    0
     0   15   88   22    0
     0    0   22   94    0
     0    0    4   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    0    0
     7   23   20    2    0
     5   15   77   24    0
     0    0   23  111    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   24   44    1    0
     0    9  113   29    0
     0    0   20   81    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=1.2764 
[epoch 9] step 4/44: loss=1.4169 
[epoch 9] step 6/44: loss=1.4330 
[epoch 9] step 8/44: loss=1.4752 
[epoch 9] step 10/44: loss=1.5497 
[epoch 9] step 12/44: loss=1.5305 
[epoch 9] step 14/44: loss=1.5132 
[epoch 9] step 16/44: loss=1.5106 
[epoch 9] step 18/44: loss=1.5230 
[epoch 9] step 20/44: loss=1.5339 
[epoch 9] step 22/44: loss=1.5398 
[epoch 9] step 24/44: loss=1.5383 
[epoch 9] step 26/44: loss=1.5382 
[epoch 9] step 28/44: loss=1.5240 
[epoch 9] step 30/44: loss=1.5286 
[epoch 9] step 32/44: loss=1.5461 
[epoch 9] step 34/44: loss=1.5447 
[epoch 9] step 36/44: loss=1.5388 
[epoch 9] step 38/44: loss=1.5528 
[epoch 9] step 40/44: loss=1.5532 
[epoch 9] step 42/44: loss=1.5523 
[epoch 9] step 44/44: loss=1.5440 
[epoch 9] train_loss(avg per step)=3.0881 lambda[min,max]=[0.500084,1.000000]
[epoch 9] val_loss=3.1806 qwk=('0.5558', '0.6747', '0.6229') averageQWK=0.6178 macroEMD=0.2970 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   19   35    1    0
     0   10  101   13    1
     0    0   39   72    5
     0    0    9   12    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   34   16    2    0
     0   24   72   25    0
     0    3   22  109    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   32   37    0    0
     0   16  119   16    0
     0    0   40   61    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=1.2507 
[epoch 10] step 4/44: loss=1.3086 
[epoch 10] step 6/44: loss=1.3445 
[epoch 10] step 8/44: loss=1.3073 
[epoch 10] step 10/44: loss=1.3138 
[epoch 10] step 12/44: loss=1.3351 
[epoch 10] step 14/44: loss=1.3528 
[epoch 10] step 16/44: loss=1.3590 
[epoch 10] step 18/44: loss=1.3688 
[epoch 10] step 20/44: loss=1.3483 
[epoch 10] step 22/44: loss=1.3497 
[epoch 10] step 24/44: loss=1.3560 
[epoch 10] step 26/44: loss=1.3620 
[epoch 10] step 28/44: loss=1.3551 
[epoch 10] step 30/44: loss=1.3597 
[epoch 10] step 32/44: loss=1.3484 
[epoch 10] step 34/44: loss=1.3522 
[epoch 10] step 36/44: loss=1.3448 
[epoch 10] step 38/44: loss=1.3431 
[epoch 10] step 40/44: loss=1.3523 
[epoch 10] step 42/44: loss=1.3568 
[epoch 10] step 44/44: loss=1.3600 
[epoch 10] train_loss(avg per step)=2.7200 lambda[min,max]=[0.500004,1.000000]
[epoch 10] val_loss=3.6283 qwk=('0.5530', '0.6571', '0.6064') averageQWK=0.6055 macroEMD=0.2909 tailR0=('0.1739', '0.0000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   19   36    0    0
     0   13  104    5    3
     0    0   56   53    7
     0    0    9    6    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   35   15    2    0
     0   28   80   13    0
     0    2   43   85    4
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   50   18    1    0
     0   47   92   12    0
     0    4   42   55    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=1.3697 
[epoch 11] step 4/44: loss=1.3359 
[epoch 11] step 6/44: loss=1.2355 
[epoch 11] step 8/44: loss=1.2045 
[epoch 11] step 10/44: loss=1.1871 
[epoch 11] step 12/44: loss=1.1688 
[epoch 11] step 14/44: loss=1.1897 
[epoch 11] step 16/44: loss=1.2083 
[epoch 11] step 18/44: loss=1.2028 
[epoch 11] step 20/44: loss=1.2340 
[epoch 11] step 22/44: loss=1.2209 
[epoch 11] step 24/44: loss=1.2141 
[epoch 11] step 26/44: loss=1.2226 
[epoch 11] step 28/44: loss=1.2164 
[epoch 11] step 30/44: loss=1.2143 
[epoch 11] step 32/44: loss=1.2158 
[epoch 11] step 34/44: loss=1.2171 
[epoch 11] step 36/44: loss=1.2182 
[epoch 11] step 38/44: loss=1.2028 
[epoch 11] step 40/44: loss=1.1945 
[epoch 11] step 42/44: loss=1.2018 
[epoch 11] step 44/44: loss=1.2279 
[epoch 11] train_loss(avg per step)=2.4559 lambda[min,max]=[0.500073,1.000000]
[epoch 11] val_loss=3.6317 qwk=('0.5608', '0.6465', '0.6016') averageQWK=0.6029 macroEMD=0.2897 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    2    0
     0   18   30    6    1
     0    7   73   45    0
     0    0   10  105    1
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   27   18    7    0
     0   20   54   47    0
     0    0    9  125    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     0   24   42    3    0
     0   16   93   42    0
     0    0   14   87    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=1.3569 
[epoch 12] step 4/44: loss=1.2902 
[epoch 12] step 6/44: loss=1.2576 
[epoch 12] step 8/44: loss=1.1932 
[epoch 12] step 10/44: loss=1.1942 
[epoch 12] step 12/44: loss=1.1690 
[epoch 12] step 14/44: loss=1.1594 
[epoch 12] step 16/44: loss=1.1326 
[epoch 12] step 18/44: loss=1.1267 
[epoch 12] step 20/44: loss=1.1181 
[epoch 12] step 22/44: loss=1.1137 
[epoch 12] step 24/44: loss=1.1159 
[epoch 12] step 26/44: loss=1.0989 
[epoch 12] step 28/44: loss=1.1026 
[epoch 12] step 30/44: loss=1.0920 
[epoch 12] step 32/44: loss=1.0879 
[epoch 12] step 34/44: loss=1.0940 
[epoch 12] step 36/44: loss=1.0984 
[epoch 12] step 38/44: loss=1.0981 
[epoch 12] step 40/44: loss=1.0872 
[epoch 12] step 42/44: loss=1.0762 
[epoch 12] step 44/44: loss=1.0802 
[epoch 12] train_loss(avg per step)=2.1605 lambda[min,max]=[0.500005,1.000000]
[epoch 12] val_loss=3.6668 qwk=('0.6051', '0.6285', '0.5913') averageQWK=0.6083 macroEMD=0.2853 tailR0=('0.1522', '0.2222', '0.1000') tailR0avg=0.1581
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   14   37    3    1
     0    6   91   25    3
     0    0   20   92    4
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     0   22   26    2    2
     0   11   81   28    1
     0    0   22   95   17
     0    0    1    7    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     0   23   43    3    0
     0   12   91   48    0
     0    0   16   85    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.9802 
[epoch 13] step 4/44: loss=0.9282 
[epoch 13] step 6/44: loss=0.8590 
[epoch 13] step 8/44: loss=0.8812 
[epoch 13] step 10/44: loss=0.8936 
[epoch 13] step 12/44: loss=0.8559 
[epoch 13] step 14/44: loss=0.8725 
[epoch 13] step 16/44: loss=0.8525 
[epoch 13] step 18/44: loss=0.8588 
[epoch 13] step 20/44: loss=0.8643 
[epoch 13] step 22/44: loss=0.8690 
[epoch 13] step 24/44: loss=0.8743 
[epoch 13] step 26/44: loss=0.8637 
[epoch 13] step 28/44: loss=0.8536 
[epoch 13] step 30/44: loss=0.8676 
[epoch 13] step 32/44: loss=0.8833 
[epoch 13] step 34/44: loss=0.8795 
[epoch 13] step 36/44: loss=0.8614 
[epoch 13] step 38/44: loss=0.8643 
[epoch 13] step 40/44: loss=0.8557 
[epoch 13] step 42/44: loss=0.8431 
[epoch 13] step 44/44: loss=0.8445 
[epoch 13] train_loss(avg per step)=1.6890 lambda[min,max]=[0.500004,1.000000]
[epoch 13] val_loss=3.5650 qwk=('0.6258', '0.6478', '0.6133') averageQWK=0.6290 macroEMD=0.2716 tailR0=('0.2077', '0.0417', '0.1000') tailR0avg=0.1165
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     1   18   33    3    0
     1    8  101   12    3
     0    0   31   75   10
     0    0    5   11    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   27   22    3    0
     0   22   78   21    0
     0    1   29  102    2
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    3    0    0
     1   22   45    1    0
     0    8  119   24    0
     0    0   29   72    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.5359 
[epoch 14] step 4/44: loss=0.5259 
[epoch 14] step 6/44: loss=0.6560 
[epoch 14] step 8/44: loss=0.6352 
[epoch 14] step 10/44: loss=0.7002 
[epoch 14] step 12/44: loss=0.7030 
[epoch 14] step 14/44: loss=0.7091 
[epoch 14] step 16/44: loss=0.7204 
[epoch 14] step 18/44: loss=0.7439 
[epoch 14] step 20/44: loss=0.7521 
[epoch 14] step 22/44: loss=0.7363 
[epoch 14] step 24/44: loss=0.7190 
[epoch 14] step 26/44: loss=0.7074 
[epoch 14] step 28/44: loss=0.7053 
[epoch 14] step 30/44: loss=0.7043 
[epoch 14] step 32/44: loss=0.7203 
[epoch 14] step 34/44: loss=0.7171 
[epoch 14] step 36/44: loss=0.7198 
[epoch 14] step 38/44: loss=0.7126 
[epoch 14] step 40/44: loss=0.7075 
[epoch 14] step 42/44: loss=0.7162 
[epoch 14] step 44/44: loss=0.7216 
[epoch 14] train_loss(avg per step)=1.4433 lambda[min,max]=[0.500001,1.000000]
[epoch 14] val_loss=3.7739 qwk=('0.6263', '0.6658', '0.6119') averageQWK=0.6346 macroEMD=0.2627 tailR0=('0.0990', '0.0556', '0.0000') tailR0avg=0.0515
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     2   30   20    2    1
     1   22   83   18    1
     0    1   29   84    2
     0    0    5   16    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     2   23   24    3    0
     0   17   78   26    0
     0    0   25  109    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   33   36    0    0
     0   24  114   13    0
     0    0   42   59    0
     0    0    0    2    0
[epoch 15] step 2/44: loss=0.8620 
[epoch 15] step 4/44: loss=0.7836 
[epoch 15] step 6/44: loss=0.6739 
[epoch 15] step 8/44: loss=0.6292 
[epoch 15] step 10/44: loss=0.5897 
[epoch 15] step 12/44: loss=0.5806 
[epoch 15] step 14/44: loss=0.6177 
[epoch 15] step 16/44: loss=0.6229 
[epoch 15] step 18/44: loss=0.6283 
[epoch 15] step 20/44: loss=0.6034 
[epoch 15] step 22/44: loss=0.5969 
[epoch 15] step 24/44: loss=0.5833 
[epoch 15] step 26/44: loss=0.5918 
[epoch 15] step 28/44: loss=0.5798 
[epoch 15] step 30/44: loss=0.5725 
[epoch 15] step 32/44: loss=0.5717 
[epoch 15] step 34/44: loss=0.5707 
[epoch 15] step 36/44: loss=0.5709 
[epoch 15] step 38/44: loss=0.5754 
[epoch 15] step 40/44: loss=0.5637 
[epoch 15] step 42/44: loss=0.5560 
[epoch 15] step 44/44: loss=0.5563 
[epoch 15] train_loss(avg per step)=1.1126 lambda[min,max]=[0.500001,1.000000]
[epoch 15] val_loss=3.9374 qwk=('0.5661', '0.6364', '0.5852') averageQWK=0.5959 macroEMD=0.2708 tailR0=('0.2198', '0.1806', '0.1000') tailR0avg=0.1668
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    4    1    0
     2   15   33    4    1
     1   10   81   29    4
     0    0   21   90    5
     0    0    5   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     1   23   24    3    1
     0   16   78   27    0
     0    1   29   98    6
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   28   40    1    0
     0   17  115   17    2
     0    0   40   60    1
     0    0    0    2    0
[epoch 16] step 2/44: loss=0.4536 
[epoch 16] step 4/44: loss=0.4597 
[epoch 16] step 6/44: loss=0.4280 
[epoch 16] step 8/44: loss=0.4130 
[epoch 16] step 10/44: loss=0.4236 
[epoch 16] step 12/44: loss=0.4305 
[epoch 16] step 14/44: loss=0.4215 
[epoch 16] step 16/44: loss=0.3891 
[epoch 16] step 18/44: loss=0.3939 
[epoch 16] step 20/44: loss=0.3832 
[epoch 16] step 22/44: loss=0.3812 
[epoch 16] step 24/44: loss=0.3993 
[epoch 16] step 26/44: loss=0.3887 
[epoch 16] step 28/44: loss=0.3854 
[epoch 16] step 30/44: loss=0.3939 
[epoch 16] step 32/44: loss=0.3882 
[epoch 16] step 34/44: loss=0.3939 
[epoch 16] step 36/44: loss=0.4055 
[epoch 16] step 38/44: loss=0.4046 
[epoch 16] step 40/44: loss=0.3954 
[epoch 16] step 42/44: loss=0.3947 
[epoch 16] step 44/44: loss=0.4032 
[epoch 16] train_loss(avg per step)=0.8064 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=4.6823 qwk=('0.6252', '0.6542', '0.5628') averageQWK=0.6141 macroEMD=0.2642 tailR0=('0.3961', '0.1389', '0.1000') tailR0avg=0.2117
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    0    4    1    0
    11    5   34    5    0
     3    3   84   32    3
     0    0   18   91    7
     0    0    2   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     1   29   17    4    1
     0   21   55   45    0
     0    1   14  112    7
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    3    0    0
     3   11   54    1    0
     0    2  121   28    0
     0    0   32   69    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=0.5538 
[epoch 17] step 4/44: loss=0.5162 
[epoch 17] step 6/44: loss=0.4669 
[epoch 17] step 8/44: loss=0.4083 
[epoch 17] step 10/44: loss=0.3782 
[epoch 17] step 12/44: loss=0.3504 
[epoch 17] step 14/44: loss=0.3644 
[epoch 17] step 16/44: loss=0.3448 
[epoch 17] step 18/44: loss=0.3403 
[epoch 17] step 20/44: loss=0.3181 
[epoch 17] step 22/44: loss=0.3076 
[epoch 17] step 24/44: loss=0.2907 
[epoch 17] step 26/44: loss=0.2896 
[epoch 17] step 28/44: loss=0.2885 
[epoch 17] step 30/44: loss=0.2951 
[epoch 17] step 32/44: loss=0.2887 
[epoch 17] step 34/44: loss=0.2871 
[epoch 17] step 36/44: loss=0.2862 
[epoch 17] step 38/44: loss=0.2851 
[epoch 17] step 40/44: loss=0.2759 
[epoch 17] step 42/44: loss=0.2822 
[epoch 17] step 44/44: loss=0.2772 
[epoch 17] train_loss(avg per step)=0.5544 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=4.3437 qwk=('0.6508', '0.6403', '0.6152') averageQWK=0.6354 macroEMD=0.2550 tailR0=('0.2077', '0.1528', '0.1000') tailR0avg=0.1535
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     1   31   21    2    0
     1   18   82   22    2
     0    2   29   79    6
     0    0    4   12    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     4   27   17    3    1
     1   29   60   31    0
     0    2   23  106    3
     0    1    0   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   29   38    2    0
     0   20  108   23    0
     0    0   31   70    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=0.2345 
[epoch 18] step 4/44: loss=0.1646 
[epoch 18] step 6/44: loss=0.1851 
[epoch 18] step 8/44: loss=0.1781 
[epoch 18] step 10/44: loss=0.1682 
[epoch 18] step 12/44: loss=0.1534 
[epoch 18] step 14/44: loss=0.1558 
[epoch 18] step 16/44: loss=0.1673 
[epoch 18] step 18/44: loss=0.1403 
[epoch 18] step 20/44: loss=0.1424 
[epoch 18] step 22/44: loss=0.1392 
[epoch 18] step 24/44: loss=0.1416 
[epoch 18] step 26/44: loss=0.1478 
[epoch 18] step 28/44: loss=0.1402 
[epoch 18] step 30/44: loss=0.1404 
[epoch 18] step 32/44: loss=0.1398 
[epoch 18] step 34/44: loss=0.1366 
[epoch 18] step 36/44: loss=0.1406 
[epoch 18] step 38/44: loss=0.1381 
[epoch 18] step 40/44: loss=0.1408 
[epoch 18] step 42/44: loss=0.1388 
[epoch 18] step 44/44: loss=0.1511 
[epoch 18] train_loss(avg per step)=0.3023 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=4.7281 qwk=('0.5979', '0.6149', '0.5999') averageQWK=0.6042 macroEMD=0.2541 tailR0=('0.3188', '0.1528', '0.1000') tailR0avg=0.1905
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    5    1    0
     8   12   30    4    1
     4    7   86   24    4
     0    1   16   88   11
     0    0    4   12    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     3   23   19    6    1
     0   25   56   40    0
     0    2   13  115    4
     0    1    0   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   26   42    1    0
     0   17  122   11    1
     0    0   39   61    1
     0    0    0    2    0
[epoch 19] step 2/44: loss=-0.0897 
[epoch 19] step 4/44: loss=-0.0073 
[epoch 19] step 6/44: loss=-0.0212 
[epoch 19] step 8/44: loss=-0.0230 
[epoch 19] step 10/44: loss=0.0297 
[epoch 19] step 12/44: loss=0.0215 
[epoch 19] step 14/44: loss=0.0376 
[epoch 19] step 16/44: loss=0.0302 
[epoch 19] step 18/44: loss=0.0483 
[epoch 19] step 20/44: loss=0.0490 
[epoch 19] step 22/44: loss=0.0497 
[epoch 19] step 24/44: loss=0.0671 
[epoch 19] step 26/44: loss=0.0686 
[epoch 19] step 28/44: loss=0.0662 
[epoch 19] step 30/44: loss=0.0611 
[epoch 19] step 32/44: loss=0.0570 
[epoch 19] step 34/44: loss=0.0585 
[epoch 19] step 36/44: loss=0.0541 
[epoch 19] step 38/44: loss=0.0479 
[epoch 19] step 40/44: loss=0.0408 
[epoch 19] step 42/44: loss=0.0409 
[epoch 19] step 44/44: loss=0.0387 
[epoch 19] train_loss(avg per step)=0.0773 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=4.9055 qwk=('0.6165', '0.6398', '0.5828') averageQWK=0.6130 macroEMD=0.2536 tailR0=('0.2512', '0.1528', '0.1000') tailR0avg=0.1680
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     1   25   24    4    1
     1   12   81   25    6
     0    1   20   86    9
     0    0    4   10    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
     2   22   25    2    1
     1   20   69   31    0
     0    0   23  106    5
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   26   42    1    0
     0   16  112   21    2
     0    0   37   62    2
     0    0    0    2    0
[epoch 20] step 2/44: loss=-0.0032 
[epoch 20] step 4/44: loss=-0.0448 
[epoch 20] step 6/44: loss=-0.0621 
[epoch 20] step 8/44: loss=-0.0626 
[epoch 20] step 10/44: loss=-0.0448 
[epoch 20] step 12/44: loss=-0.0383 
[epoch 20] step 14/44: loss=-0.0495 
[epoch 20] step 16/44: loss=-0.0542 
[epoch 20] step 18/44: loss=-0.0475 
[epoch 20] step 20/44: loss=-0.0374 
[epoch 20] step 22/44: loss=-0.0402 
[epoch 20] step 24/44: loss=-0.0399 
[epoch 20] step 26/44: loss=-0.0380 
[epoch 20] step 28/44: loss=-0.0365 
[epoch 20] step 30/44: loss=-0.0343 
[epoch 20] step 32/44: loss=-0.0345 
[epoch 20] step 34/44: loss=-0.0362 
[epoch 20] step 36/44: loss=-0.0375 
[epoch 20] step 38/44: loss=-0.0336 
[epoch 20] step 40/44: loss=-0.0305 
[epoch 20] step 42/44: loss=-0.0320 
[epoch 20] step 44/44: loss=-0.0343 
[epoch 20] train_loss(avg per step)=-0.0687 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=5.0053 qwk=('0.6031', '0.6349', '0.5989') averageQWK=0.6123 macroEMD=0.2478 tailR0=('0.2415', '0.1528', '0.1000') tailR0avg=0.1648
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    1    0
     3   21   26    4    1
     2   10   85   25    3
     0    0   27   83    6
     0    0    4   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     2   24   24    1    1
     0   21   74   26    0
     0    2   28   98    6
     0    1    0   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   29   37    2    0
     0   18  106   26    1
     0    1   31   69    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=-0.1779 
[epoch 21] step 4/44: loss=-0.1054 
[epoch 21] step 6/44: loss=-0.0946 
[epoch 21] step 8/44: loss=-0.0909 
[epoch 21] step 10/44: loss=-0.1035 
[epoch 21] step 12/44: loss=-0.0934 
[epoch 21] step 14/44: loss=-0.1071 
[epoch 21] step 16/44: loss=-0.1152 
[epoch 21] step 18/44: loss=-0.1093 
[epoch 21] step 20/44: loss=-0.1076 
[epoch 21] step 22/44: loss=-0.1036 
[epoch 21] step 24/44: loss=-0.0767 
[epoch 21] step 26/44: loss=-0.0761 
[epoch 21] step 28/44: loss=-0.0862 
[epoch 21] step 30/44: loss=-0.0898 
[epoch 21] step 32/44: loss=-0.0924 
[epoch 21] step 34/44: loss=-0.0957 
[epoch 21] step 36/44: loss=-0.0969 
[epoch 21] step 38/44: loss=-0.0985 
[epoch 21] step 40/44: loss=-0.1033 
[epoch 21] step 42/44: loss=-0.1042 
[epoch 21] step 44/44: loss=-0.1068 
[epoch 21] train_loss(avg per step)=-0.2136 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=5.8989 qwk=('0.5921', '0.6152', '0.5805') averageQWK=0.5960 macroEMD=0.2593 tailR0=('0.3068', '0.1806', '0.1000') tailR0avg=0.1958
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    7    0    0
     2   12   37    4    0
     2    4   92   23    4
     0    0   24   80   12
     0    0    4   10    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   26   23    2    1
     0   25   71   24    1
     0    2   23  103    6
     0    1    2    6    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   14   54    1    0
     0    4  117   30    0
     0    0   28   73    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=-0.0645 
[epoch 22] step 4/44: loss=-0.0692 
[epoch 22] step 6/44: loss=-0.0788 
[epoch 22] step 8/44: loss=-0.0794 
[epoch 22] step 10/44: loss=-0.0893 
[epoch 22] step 12/44: loss=-0.1006 
[epoch 22] step 14/44: loss=-0.1145 
[epoch 22] step 16/44: loss=-0.1175 
[epoch 22] step 18/44: loss=-0.1281 
[epoch 22] step 20/44: loss=-0.1311 
[epoch 22] step 22/44: loss=-0.1239 
[epoch 22] step 24/44: loss=-0.1250 
[epoch 22] step 26/44: loss=-0.1313 
[epoch 22] step 28/44: loss=-0.1315 
[epoch 22] step 30/44: loss=-0.1257 
[epoch 22] step 32/44: loss=-0.1272 
[epoch 22] step 34/44: loss=-0.1320 
[epoch 22] step 36/44: loss=-0.1353 
[epoch 22] step 38/44: loss=-0.1351 
[epoch 22] step 40/44: loss=-0.1343 
[epoch 22] step 42/44: loss=-0.1371 
[epoch 22] step 44/44: loss=-0.1355 
[epoch 22] train_loss(avg per step)=-0.2709 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=5.6083 qwk=('0.6030', '0.6024', '0.5770') averageQWK=0.5942 macroEMD=0.2508 tailR0=('0.2633', '0.0972', '0.1000') tailR0avg=0.1535
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    1    0
     3   17   31    4    0
     1    7   88   25    4
     0    0   27   85    4
     0    0    6   10    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   19   27    5    1
     0   16   60   45    0
     0    0   14  117    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   18   48    2    0
     0    7  120   23    1
     0    0   33   68    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=-0.2780 
[epoch 23] step 4/44: loss=-0.2358 
[epoch 23] step 6/44: loss=-0.2401 
[epoch 23] step 8/44: loss=-0.2317 
[epoch 23] step 10/44: loss=-0.2186 
[epoch 23] step 12/44: loss=-0.2260 
[epoch 23] step 14/44: loss=-0.2099 
[epoch 23] step 16/44: loss=-0.2068 
[epoch 23] step 18/44: loss=-0.2128 
[epoch 23] step 20/44: loss=-0.2005 
[epoch 23] step 22/44: loss=-0.1880 
[epoch 23] step 24/44: loss=-0.1898 
[epoch 23] step 26/44: loss=-0.1904 
[epoch 23] step 28/44: loss=-0.1896 
[epoch 23] step 30/44: loss=-0.1857 
[epoch 23] step 32/44: loss=-0.1855 
[epoch 23] step 34/44: loss=-0.1861 
[epoch 23] step 36/44: loss=-0.1856 
[epoch 23] step 38/44: loss=-0.1814 
[epoch 23] step 40/44: loss=-0.1813 
[epoch 23] step 42/44: loss=-0.1808 
[epoch 23] step 44/44: loss=-0.1786 
[epoch 23] train_loss(avg per step)=-0.3572 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=5.8775 qwk=('0.6109', '0.6502', '0.5684') averageQWK=0.6098 macroEMD=0.2462 tailR0=('0.2077', '0.0972', '0.1000') tailR0avg=0.1350
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     3   22   25    4    1
     3   10   80   26    6
     0    0   18   90    8
     0    0    4   12    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   24   23    3    1
     0   16   68   37    0
     0    0   15  115    4
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   20   46    2    0
     0   17  117   16    1
     0    0   37   63    1
     0    0    0    2    0
[epoch 24] step 2/44: loss=-0.2906 
[epoch 24] step 4/44: loss=-0.2658 
[epoch 24] step 6/44: loss=-0.2709 
[epoch 24] step 8/44: loss=-0.2616 
[epoch 24] step 10/44: loss=-0.2592 
[epoch 24] step 12/44: loss=-0.2428 
[epoch 24] step 14/44: loss=-0.2370 
[epoch 24] step 16/44: loss=-0.2383 
[epoch 24] step 18/44: loss=-0.2357 
[epoch 24] step 20/44: loss=-0.2333 
[epoch 24] step 22/44: loss=-0.2283 
[epoch 24] step 24/44: loss=-0.2334 
[epoch 24] step 26/44: loss=-0.2353 
[epoch 24] step 28/44: loss=-0.2302 
[epoch 24] step 30/44: loss=-0.2274 
[epoch 24] step 32/44: loss=-0.2281 
[epoch 24] step 34/44: loss=-0.2272 
[epoch 24] step 36/44: loss=-0.2247 
[epoch 24] step 38/44: loss=-0.2272 
[epoch 24] step 40/44: loss=-0.2278 
[epoch 24] step 42/44: loss=-0.2287 
[epoch 24] step 44/44: loss=-0.2245 
[epoch 24] train_loss(avg per step)=-0.4491 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=6.0691 qwk=('0.6134', '0.6090', '0.5825') averageQWK=0.6016 macroEMD=0.2399 tailR0=('0.2729', '0.1389', '0.1000') tailR0avg=0.1706
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    0    0
     1   31   18    4    1
     1   22   70   24    8
     0    1   23   78   14
     0    2    2    9   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   29   17    5    1
     0   30   63   28    0
     0    2   24  102    6
     0    1    0    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     2   20   45    2    0
     0   17   98   36    0
     0    0   27   74    0
     0    0    0    2    0
[epoch 25] step 2/44: loss=-0.2922 
[epoch 25] step 4/44: loss=-0.2473 
[epoch 25] step 6/44: loss=-0.2230 
[epoch 25] step 8/44: loss=-0.2160 
[epoch 25] step 10/44: loss=-0.2224 
[epoch 25] step 12/44: loss=-0.2372 
[epoch 25] step 14/44: loss=-0.2375 
[epoch 25] step 16/44: loss=-0.2345 
[epoch 25] step 18/44: loss=-0.2383 
[epoch 25] step 20/44: loss=-0.2409 
[epoch 25] step 22/44: loss=-0.2479 
[epoch 25] step 24/44: loss=-0.2450 
[epoch 25] step 26/44: loss=-0.2455 
[epoch 25] step 28/44: loss=-0.2474 
[epoch 25] step 30/44: loss=-0.2497 
[epoch 25] step 32/44: loss=-0.2455 
[epoch 25] step 34/44: loss=-0.2430 
[epoch 25] step 36/44: loss=-0.2458 
[epoch 25] step 38/44: loss=-0.2485 
[epoch 25] step 40/44: loss=-0.2479 
[epoch 25] step 42/44: loss=-0.2489 
[epoch 25] step 44/44: loss=-0.2481 
[epoch 25] train_loss(avg per step)=-0.4962 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=6.5539 qwk=('0.5906', '0.6309', '0.5662') averageQWK=0.5959 macroEMD=0.2437 tailR0=('0.3068', '0.1389', '0.1000') tailR0avg=0.1819
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    4    1    0
     1   17   33    3    1
     0   10   82   24    9
     0    0   20   82   14
     0    0    3   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     1   26   21    3    1
     0   26   55   39    1
     0    1   15  112    6
     0    1    0    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   17   50    2    0
     0    6  128   17    0
     0    0   38   63    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=-0.2946 
[epoch 26] step 4/44: loss=-0.3006 
[epoch 26] step 6/44: loss=-0.2898 
[epoch 26] step 8/44: loss=-0.2835 
[epoch 26] step 10/44: loss=-0.2768 
[epoch 26] step 12/44: loss=-0.2761 
[epoch 26] step 14/44: loss=-0.2697 
[epoch 26] step 16/44: loss=-0.2648 
[epoch 26] step 18/44: loss=-0.2590 
[epoch 26] step 20/44: loss=-0.2530 
[epoch 26] step 22/44: loss=-0.2505 
[epoch 26] step 24/44: loss=-0.2534 
[epoch 26] step 26/44: loss=-0.2523 
[epoch 26] step 28/44: loss=-0.2544 
[epoch 26] step 30/44: loss=-0.2551 
[epoch 26] step 32/44: loss=-0.2514 
[epoch 26] step 34/44: loss=-0.2532 
[epoch 26] step 36/44: loss=-0.2548 
[epoch 26] step 38/44: loss=-0.2544 
[epoch 26] step 40/44: loss=-0.2564 
[epoch 26] step 42/44: loss=-0.2570 
[epoch 26] step 44/44: loss=-0.2587 
[epoch 26] train_loss(avg per step)=-0.5173 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=6.7477 qwk=('0.5953', '0.6218', '0.5521') averageQWK=0.5897 macroEMD=0.2415 tailR0=('0.2633', '0.0972', '0.1000') tailR0avg=0.1535
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    4    1    0
     2   19   28    5    1
     0    8   81   30    6
     0    0   18   90    8
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   21   24    5    1
     0   18   60   43    0
     0    0   12  120    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   17   50    2    0
     0    6  130   15    0
     0    0   42   59    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=-0.3129 
[epoch 27] step 4/44: loss=-0.2964 
[epoch 27] step 6/44: loss=-0.2655 
[epoch 27] step 8/44: loss=-0.2665 
[epoch 27] step 10/44: loss=-0.2744 
[epoch 27] step 12/44: loss=-0.2820 
[epoch 27] step 14/44: loss=-0.2814 
[epoch 27] step 16/44: loss=-0.2785 
[epoch 27] step 18/44: loss=-0.2819 
[epoch 27] step 20/44: loss=-0.2800 
[epoch 27] step 22/44: loss=-0.2831 
[epoch 27] step 24/44: loss=-0.2847 
[epoch 27] step 26/44: loss=-0.2848 
[epoch 27] step 28/44: loss=-0.2815 
[epoch 27] step 30/44: loss=-0.2810 
[epoch 27] step 32/44: loss=-0.2770 
[epoch 27] step 34/44: loss=-0.2775 
[epoch 27] step 36/44: loss=-0.2739 
[epoch 27] step 38/44: loss=-0.2736 
[epoch 27] step 40/44: loss=-0.2711 
[epoch 27] step 42/44: loss=-0.2647 
[epoch 27] step 44/44: loss=-0.2670 
[epoch 27] train_loss(avg per step)=-0.5341 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=6.6568 qwk=('0.5794', '0.6415', '0.5733') averageQWK=0.5980 macroEMD=0.2430 tailR0=('0.2415', '0.0556', '0.1000') tailR0avg=0.1324
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    1    2    0
     5   13   30    6    1
     1    7   74   36    7
     0    0   12   97    7
     0    0    3   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     0   30   18    3    1
     0   25   53   43    0
     0    1   12  119    2
     0    1    1   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     0   22   45    2    0
     0   16   93   42    0
     0    0   23   78    0
     0    0    0    2    0
[epoch 28] step 2/44: loss=-0.2122 
[epoch 28] step 4/44: loss=-0.2485 
[epoch 28] step 6/44: loss=-0.2634 
[epoch 28] step 8/44: loss=-0.2649 
[epoch 28] step 10/44: loss=-0.2475 
[epoch 28] step 12/44: loss=-0.2475 
[epoch 28] step 14/44: loss=-0.2540 
[epoch 28] step 16/44: loss=-0.2529 
[epoch 28] step 18/44: loss=-0.2554 
[epoch 28] step 20/44: loss=-0.2545 
[epoch 28] step 22/44: loss=-0.2556 
[epoch 28] step 24/44: loss=-0.2521 
[epoch 28] step 26/44: loss=-0.2548 
[epoch 28] step 28/44: loss=-0.2556 
[epoch 28] step 30/44: loss=-0.2529 
[epoch 28] step 32/44: loss=-0.2505 
[epoch 28] step 34/44: loss=-0.2530 
[epoch 28] step 36/44: loss=-0.2549 
[epoch 28] step 38/44: loss=-0.2568 
[epoch 28] step 40/44: loss=-0.2555 
[epoch 28] step 42/44: loss=-0.2578 
[epoch 28] step 44/44: loss=-0.2568 
[epoch 28] train_loss(avg per step)=-0.5136 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=6.5575 qwk=('0.6650', '0.6308', '0.5686') averageQWK=0.6215 macroEMD=0.2352 tailR0=('0.2198', '0.0972', '0.1000') tailR0avg=0.1390
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     5   24   24    2    0
     2   11   85   24    3
     0    0   25   88    3
     0    0    4   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     0   29   21    1    1
     0   28   74   19    0
     0    2   31   98    3
     0    1    1    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   22   47    0    0
     0   17  126    8    0
     0    0   47   54    0
     0    0    0    2    0
[epoch 29] step 2/44: loss=-0.2827 
[epoch 29] step 4/44: loss=-0.2425 
[epoch 29] step 6/44: loss=-0.2566 
[epoch 29] step 8/44: loss=-0.2726 
[epoch 29] step 10/44: loss=-0.2665 
[epoch 29] step 12/44: loss=-0.2777 
[epoch 29] step 14/44: loss=-0.2810 
[epoch 29] step 16/44: loss=-0.2832 
[epoch 29] step 18/44: loss=-0.2830 
[epoch 29] step 20/44: loss=-0.2849 
[epoch 29] step 22/44: loss=-0.2827 
[epoch 29] step 24/44: loss=-0.2835 
[epoch 29] step 26/44: loss=-0.2824 
[epoch 29] step 28/44: loss=-0.2810 
[epoch 29] step 30/44: loss=-0.2813 
[epoch 29] step 32/44: loss=-0.2823 
[epoch 29] step 34/44: loss=-0.2858 
[epoch 29] step 36/44: loss=-0.2873 
[epoch 29] step 38/44: loss=-0.2873 
[epoch 29] step 40/44: loss=-0.2865 
[epoch 29] step 42/44: loss=-0.2874 
[epoch 29] step 44/44: loss=-0.2889 
[epoch 29] train_loss(avg per step)=-0.5779 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=7.1913 qwk=('0.5352', '0.6174', '0.5659') averageQWK=0.5729 macroEMD=0.2452 tailR0=('0.2198', '0.0972', '0.1000') tailR0avg=0.1390
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    4    2    0
     2   10   36    6    1
     1    7   72   40    5
     0    0   11  100    5
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   27   20    4    1
     0   24   59   38    0
     0    1   17  113    3
     0    1    0   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     1   16   50    2    0
     0    5  109   37    0
     0    0   26   75    0
     0    0    0    2    0
[epoch 30] step 2/44: loss=-0.3008 
[epoch 30] step 4/44: loss=-0.3154 
[epoch 30] step 6/44: loss=-0.3202 
[epoch 30] step 8/44: loss=-0.3039 
[epoch 30] step 10/44: loss=-0.3056 
[epoch 30] step 12/44: loss=-0.3070 
[epoch 30] step 14/44: loss=-0.3069 
[epoch 30] step 16/44: loss=-0.3068 
[epoch 30] step 18/44: loss=-0.3100 
[epoch 30] step 20/44: loss=-0.3109 
[epoch 30] step 22/44: loss=-0.3118 
[epoch 30] step 24/44: loss=-0.3110 
[epoch 30] step 26/44: loss=-0.3097 
[epoch 30] step 28/44: loss=-0.3084 
[epoch 30] step 30/44: loss=-0.3084 
[epoch 30] step 32/44: loss=-0.3090 
[epoch 30] step 34/44: loss=-0.3080 
[epoch 30] step 36/44: loss=-0.3064 
[epoch 30] step 38/44: loss=-0.3053 
[epoch 30] step 40/44: loss=-0.3065 
[epoch 30] step 42/44: loss=-0.3065 
[epoch 30] step 44/44: loss=-0.3027 
[epoch 30] train_loss(avg per step)=-0.6054 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=6.8387 qwk=('0.5917', '0.6420', '0.5779') averageQWK=0.6039 macroEMD=0.2415 tailR0=('0.2633', '0.1389', '0.1000') tailR0avg=0.1674
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    1    0
     3   14   34    3    1
     1    8   86   23    7
     0    0   23   86    7
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     3   23   21    4    1
     1   17   66   36    1
     0    0   15  115    4
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   20   46    2    0
     0   10  117   23    1
     0    0   34   66    1
     0    0    0    2    0
[epoch 31] step 2/44: loss=-0.3329 
[epoch 31] step 4/44: loss=-0.3342 
[epoch 31] step 6/44: loss=-0.3352 
[epoch 31] step 8/44: loss=-0.3328 
[epoch 31] step 10/44: loss=-0.3288 
[epoch 31] step 12/44: loss=-0.3262 
[epoch 31] step 14/44: loss=-0.3236 
[epoch 31] step 16/44: loss=-0.3175 
[epoch 31] step 18/44: loss=-0.3186 
[epoch 31] step 20/44: loss=-0.3190 
[epoch 31] step 22/44: loss=-0.3190 
[epoch 31] step 24/44: loss=-0.3184 
[epoch 31] step 26/44: loss=-0.3171 
[epoch 31] step 28/44: loss=-0.3178 
[epoch 31] step 30/44: loss=-0.3187 
[epoch 31] step 32/44: loss=-0.3181 
[epoch 31] step 34/44: loss=-0.3185 
[epoch 31] step 36/44: loss=-0.3183 
[epoch 31] step 38/44: loss=-0.3193 
[epoch 31] step 40/44: loss=-0.3185 
[epoch 31] step 42/44: loss=-0.3169 
[epoch 31] step 44/44: loss=-0.3176 
[epoch 31] train_loss(avg per step)=-0.6351 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=6.8471 qwk=('0.6192', '0.6280', '0.5998') averageQWK=0.6156 macroEMD=0.2383 tailR0=('0.2633', '0.1389', '0.1000') tailR0avg=0.1674
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    1    0
     2   22   27    3    1
     1   10   80   28    6
     0    0   22   87    7
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     2   16   30    3    1
     0   13   74   34    0
     0    0   19  110    5
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   27   39    2    0
     0   23   96   31    1
     0    0   27   74    0
     0    0    0    2    0
[epoch 32] step 2/44: loss=-0.3261 
[epoch 32] step 4/44: loss=-0.3239 
[epoch 32] step 6/44: loss=-0.3087 
[epoch 32] step 8/44: loss=-0.3099 
[epoch 32] step 10/44: loss=-0.3086 
[epoch 32] step 12/44: loss=-0.3139 
[epoch 32] step 14/44: loss=-0.3134 
[epoch 32] step 16/44: loss=-0.3145 
[epoch 32] step 18/44: loss=-0.3168 
[epoch 32] step 20/44: loss=-0.3160 
[epoch 32] step 22/44: loss=-0.3179 
[epoch 32] step 24/44: loss=-0.3191 
[epoch 32] step 26/44: loss=-0.3193 
[epoch 32] step 28/44: loss=-0.3192 
[epoch 32] step 30/44: loss=-0.3188 
[epoch 32] step 32/44: loss=-0.3158 
[epoch 32] step 34/44: loss=-0.3158 
[epoch 32] step 36/44: loss=-0.3150 
[epoch 32] step 38/44: loss=-0.3154 
[epoch 32] step 40/44: loss=-0.3154 
[epoch 32] step 42/44: loss=-0.3162 
[epoch 32] step 44/44: loss=-0.3168 
[epoch 32] train_loss(avg per step)=-0.6336 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=7.2248 qwk=('0.5701', '0.6285', '0.5603') averageQWK=0.5863 macroEMD=0.2413 tailR0=('0.2295', '0.1389', '0.1000') tailR0avg=0.1561
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     1   12   38    3    1
     0    7   86   26    6
     0    0   25   84    7
     0    0    3   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     1   16   32    2    1
     0   13   83   25    0
     0    0   23  107    4
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   20   47    2    0
     0   12  121   18    0
     0    0   40   61    0
     0    0    0    2    0
[epoch 33] step 2/44: loss=-0.2812 
[epoch 33] step 4/44: loss=-0.2938 
[epoch 33] step 6/44: loss=-0.2899 
[epoch 33] step 8/44: loss=-0.2982 
[epoch 33] step 10/44: loss=-0.2976 
[epoch 33] step 12/44: loss=-0.3032 
[epoch 33] step 14/44: loss=-0.3029 
[epoch 33] step 16/44: loss=-0.3068 
[epoch 33] step 18/44: loss=-0.3085 
[epoch 33] step 20/44: loss=-0.3118 
[epoch 33] step 22/44: loss=-0.3123 
[epoch 33] step 24/44: loss=-0.3138 
[epoch 33] step 26/44: loss=-0.3137 
[epoch 33] step 28/44: loss=-0.3145 
[epoch 33] step 30/44: loss=-0.3144 
[epoch 33] step 32/44: loss=-0.3146 
[epoch 33] step 34/44: loss=-0.3156 
[epoch 33] step 36/44: loss=-0.3163 
[epoch 33] step 38/44: loss=-0.3158 
[epoch 33] step 40/44: loss=-0.3154 
[epoch 33] step 42/44: loss=-0.3159 
[epoch 33] step 44/44: loss=-0.3166 
[epoch 33] train_loss(avg per step)=-0.6332 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=6.9573 qwk=('0.6028', '0.6386', '0.6063') averageQWK=0.6159 macroEMD=0.2362 tailR0=('0.2633', '0.0972', '0.1000') tailR0avg=0.1535
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     3   19   29    3    1
     3   13   79   24    6
     0    0   26   83    7
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     2   26   20    3    1
     1   22   70   28    0
     0    2   16  113    3
     0    1    0   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   25   41    2    0
     0   18  108   25    0
     0    0   30   71    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=-0.3294 
[epoch 34] step 4/44: loss=-0.3348 
[epoch 34] step 6/44: loss=-0.3294 
[epoch 34] step 8/44: loss=-0.3265 
[epoch 34] step 10/44: loss=-0.3256 
[epoch 34] step 12/44: loss=-0.3253 
[epoch 34] step 14/44: loss=-0.3265 
[epoch 34] step 16/44: loss=-0.3284 
[epoch 34] step 18/44: loss=-0.3250 
[epoch 34] step 20/44: loss=-0.3238 
[epoch 34] step 22/44: loss=-0.3184 
[epoch 34] step 24/44: loss=-0.3178 
[epoch 34] step 26/44: loss=-0.3180 
[epoch 34] step 28/44: loss=-0.3184 
[epoch 34] step 30/44: loss=-0.3197 
[epoch 34] step 32/44: loss=-0.3197 
[epoch 34] step 34/44: loss=-0.3207 
[epoch 34] step 36/44: loss=-0.3205 
[epoch 34] step 38/44: loss=-0.3205 
[epoch 34] step 40/44: loss=-0.3213 
[epoch 34] step 42/44: loss=-0.3199 
[epoch 34] step 44/44: loss=-0.3168 
[epoch 34] train_loss(avg per step)=-0.6336 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=6.9629 qwk=('0.6148', '0.6572', '0.5997') averageQWK=0.6239 macroEMD=0.2342 tailR0=('0.2633', '0.1806', '0.1000') tailR0avg=0.1813
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    1    0
     1   26   24    3    1
     1   15   78   25    6
     0    1   25   84    6
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   25   23    2    1
     0   21   77   23    0
     0    2   21  106    5
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   24   42    2    0
     0   17  109   25    0
     0    0   31   70    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=-0.3344 
[epoch 35] step 4/44: loss=-0.3276 
[epoch 35] step 6/44: loss=-0.3305 
[epoch 35] step 8/44: loss=-0.3251 
[epoch 35] step 10/44: loss=-0.3232 
[epoch 35] step 12/44: loss=-0.3236 
[epoch 35] step 14/44: loss=-0.3190 
[epoch 35] step 16/44: loss=-0.3203 
[epoch 35] step 18/44: loss=-0.3215 
[epoch 35] step 20/44: loss=-0.3217 
[epoch 35] step 22/44: loss=-0.3218 
[epoch 35] step 24/44: loss=-0.3226 
[epoch 35] step 26/44: loss=-0.3233 
[epoch 35] step 28/44: loss=-0.3243 
[epoch 35] step 30/44: loss=-0.3256 
[epoch 35] step 32/44: loss=-0.3262 
[epoch 35] step 34/44: loss=-0.3267 
[epoch 35] step 36/44: loss=-0.3266 
[epoch 35] step 38/44: loss=-0.3272 
[epoch 35] step 40/44: loss=-0.3273 
[epoch 35] step 42/44: loss=-0.3279 
[epoch 35] step 44/44: loss=-0.3278 
[epoch 35] train_loss(avg per step)=-0.6556 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=7.0758 qwk=('0.5923', '0.6462', '0.5884') averageQWK=0.6090 macroEMD=0.2356 tailR0=('0.2633', '0.1806', '0.1000') tailR0avg=0.1813
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    1    0
     2   20   29    3    1
     2   12   79   25    7
     0    0   25   83    8
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   25   22    3    1
     0   24   72   25    0
     0    2   20  105    7
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   24   42    2    0
     0   16  110   24    1
     0    0   33   67    1
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-1-reassignment-0/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-1-reassignment-0/fold0/metrics.json
Done.
