[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.5226 
[epoch 1] step 4/44: loss=0.5243 
[epoch 1] step 6/44: loss=0.5168 
[epoch 1] step 8/44: loss=0.5221 
[epoch 1] step 10/44: loss=0.5211 
[epoch 1] step 12/44: loss=0.5254 
[epoch 1] step 14/44: loss=0.5278 
[epoch 1] step 16/44: loss=0.5282 
[epoch 1] step 18/44: loss=0.5286 
[epoch 1] step 20/44: loss=0.5326 
[epoch 1] step 22/44: loss=0.5360 
[epoch 1] step 24/44: loss=0.5394 
[epoch 1] step 26/44: loss=0.5432 
[epoch 1] step 28/44: loss=0.5470 
[epoch 1] step 30/44: loss=0.5511 
[epoch 1] step 32/44: loss=0.5554 
[epoch 1] step 34/44: loss=0.5602 
[epoch 1] step 36/44: loss=0.5639 
[epoch 1] step 38/44: loss=0.5655 
[epoch 1] step 40/44: loss=0.5681 
[epoch 1] step 42/44: loss=0.5718 
[epoch 1] step 44/44: loss=0.5750 
[epoch 1] train_loss(avg per step)=1.1500 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=0.9882 qwk=('0.0735', '0.0270', '0.1054') averageQWK=0.0686 macroEMD=0.3823 tailR0=('0.0000', '0.0000', '0.2500') tailR0avg=0.0833
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    9    0
     0   29    2   24    0
     0   61    6   58    0
     0   40   13   63    0
     0    3    8   12    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
    21    0   32    0    0
    53    0   69    0    0
    42    0   91    0    0
     2    0   10    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0   22   41    1    5
     0   39   95    2   16
     0   28   51    8   15
     0    1    0    0    1
[epoch 2] step 2/44: loss=0.5827 
[epoch 2] step 4/44: loss=0.5870 
[epoch 2] step 6/44: loss=0.5895 
[epoch 2] step 8/44: loss=0.5924 
[epoch 2] step 10/44: loss=0.5888 
[epoch 2] step 12/44: loss=0.5913 
[epoch 2] step 14/44: loss=0.5903 
[epoch 2] step 16/44: loss=0.5957 
[epoch 2] step 18/44: loss=0.5964 
[epoch 2] step 20/44: loss=0.5939 
[epoch 2] step 22/44: loss=0.5921 
[epoch 2] step 24/44: loss=0.5906 
[epoch 2] step 26/44: loss=0.5918 
[epoch 2] step 28/44: loss=0.5951 
[epoch 2] step 30/44: loss=0.5960 
[epoch 2] step 32/44: loss=0.5977 
[epoch 2] step 34/44: loss=0.5984 
[epoch 2] step 36/44: loss=0.5985 
[epoch 2] step 38/44: loss=0.6008 
[epoch 2] step 40/44: loss=0.5992 
[epoch 2] step 42/44: loss=0.5984 
[epoch 2] step 44/44: loss=0.5979 
[epoch 2] train_loss(avg per step)=1.1958 lambda[min,max]=[0.503863,1.000000]
[epoch 2] val_loss=1.1596 qwk=('0.2071', '0.1841', '0.3750') averageQWK=0.2554 macroEMD=0.3313 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    5    0
     0    0   26   29    0
     0    0   23  102    0
     0    0    8  108    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    4    0
     0    0   20   33    0
     0    0   10  112    0
     0    0    2  131    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    0   63    6    0
     0    0  116   36    0
     0    0   37   65    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=0.5958 
[epoch 3] step 4/44: loss=0.5830 
[epoch 3] step 6/44: loss=0.5786 
[epoch 3] step 8/44: loss=0.5840 
[epoch 3] step 10/44: loss=0.5920 
[epoch 3] step 12/44: loss=0.5854 
[epoch 3] step 14/44: loss=0.5794 
[epoch 3] step 16/44: loss=0.5782 
[epoch 3] step 18/44: loss=0.5765 
[epoch 3] step 20/44: loss=0.5739 
[epoch 3] step 22/44: loss=0.5681 
[epoch 3] step 24/44: loss=0.5610 
[epoch 3] step 26/44: loss=0.5621 
[epoch 3] step 28/44: loss=0.5580 
[epoch 3] step 30/44: loss=0.5570 
[epoch 3] step 32/44: loss=0.5562 
[epoch 3] step 34/44: loss=0.5528 
[epoch 3] step 36/44: loss=0.5490 
[epoch 3] step 38/44: loss=0.5492 
[epoch 3] step 40/44: loss=0.5495 
[epoch 3] step 42/44: loss=0.5474 
[epoch 3] step 44/44: loss=0.5435 
[epoch 3] train_loss(avg per step)=1.0870 lambda[min,max]=[0.504128,1.000000]
[epoch 3] val_loss=1.0913 qwk=('0.2993', '0.2309', '0.2655') averageQWK=0.2652 macroEMD=0.2952 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    0    0
     0    1   53    1    0
     0    0  117    8    0
     0    0   72   44    0
     0    0   14    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   52    1    0
     0    0  116    6    0
     0    0   95   38    0
     0    0    7    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0   11   58    0    0
     0    8  143    1    0
     0    0   84   18    0
     0    0    2    0    0
[epoch 4] step 2/44: loss=0.5585 
[epoch 4] step 4/44: loss=0.5431 
[epoch 4] step 6/44: loss=0.5310 
[epoch 4] step 8/44: loss=0.5532 
[epoch 4] step 10/44: loss=0.5509 
[epoch 4] step 12/44: loss=0.5457 
[epoch 4] step 14/44: loss=0.5492 
[epoch 4] step 16/44: loss=0.5495 
[epoch 4] step 18/44: loss=0.5444 
[epoch 4] step 20/44: loss=0.5430 
[epoch 4] step 22/44: loss=0.5408 
[epoch 4] step 24/44: loss=0.5390 
[epoch 4] step 26/44: loss=0.5378 
[epoch 4] step 28/44: loss=0.5378 
[epoch 4] step 30/44: loss=0.5362 
[epoch 4] step 32/44: loss=0.5391 
[epoch 4] step 34/44: loss=0.5414 
[epoch 4] step 36/44: loss=0.5438 
[epoch 4] step 38/44: loss=0.5406 
[epoch 4] step 40/44: loss=0.5397 
[epoch 4] step 42/44: loss=0.5396 
[epoch 4] step 44/44: loss=0.5399 
[epoch 4] train_loss(avg per step)=1.0799 lambda[min,max]=[0.495805,1.000000]
[epoch 4] val_loss=1.1302 qwk=('0.3717', '0.2873', '0.4720') averageQWK=0.3770 macroEMD=0.2876 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0    9   45    1    0
     0   10  107    8    0
     0    1   67   48    0
     0    0   17    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    0
     0    3   48    2    0
     0    2  113    7    0
     0    0   88   45    0
     0    0    7    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   35   34    0    0
     0   31  118    3    0
     0    0   78   24    0
     0    0    1    1    0
[epoch 5] step 2/44: loss=0.4778 
[epoch 5] step 4/44: loss=0.4843 
[epoch 5] step 6/44: loss=0.4983 
[epoch 5] step 8/44: loss=0.4874 
[epoch 5] step 10/44: loss=0.4865 
[epoch 5] step 12/44: loss=0.4890 
[epoch 5] step 14/44: loss=0.4903 
[epoch 5] step 16/44: loss=0.4919 
[epoch 5] step 18/44: loss=0.4991 
[epoch 5] step 20/44: loss=0.4991 
[epoch 5] step 22/44: loss=0.4938 
[epoch 5] step 24/44: loss=0.4986 
[epoch 5] step 26/44: loss=0.5023 
[epoch 5] step 28/44: loss=0.5024 
[epoch 5] step 30/44: loss=0.5020 
[epoch 5] step 32/44: loss=0.4986 
[epoch 5] step 34/44: loss=0.5001 
[epoch 5] step 36/44: loss=0.5001 
[epoch 5] step 38/44: loss=0.4997 
[epoch 5] step 40/44: loss=0.4979 
[epoch 5] step 42/44: loss=0.4959 
[epoch 5] step 44/44: loss=0.4920 
[epoch 5] train_loss(avg per step)=0.9839 lambda[min,max]=[0.500105,1.000000]
[epoch 5] val_loss=0.9663 qwk=('0.5251', '0.5765', '0.5510') averageQWK=0.5509 macroEMD=0.2445 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0    5   48    2    0
     0    4  107   14    0
     0    0   44   72    0
     0    0    4   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   13   37    3    0
     0    5  102   15    0
     0    0   50   83    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   23   45    1    0
     0   14  116   22    0
     0    0   45   57    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=0.4149 
[epoch 6] step 4/44: loss=0.4487 
[epoch 6] step 6/44: loss=0.4495 
[epoch 6] step 8/44: loss=0.4542 
[epoch 6] step 10/44: loss=0.4598 
[epoch 6] step 12/44: loss=0.4647 
[epoch 6] step 14/44: loss=0.4662 
[epoch 6] step 16/44: loss=0.4620 
[epoch 6] step 18/44: loss=0.4563 
[epoch 6] step 20/44: loss=0.4529 
[epoch 6] step 22/44: loss=0.4579 
[epoch 6] step 24/44: loss=0.4560 
[epoch 6] step 26/44: loss=0.4553 
[epoch 6] step 28/44: loss=0.4503 
[epoch 6] step 30/44: loss=0.4492 
[epoch 6] step 32/44: loss=0.4519 
[epoch 6] step 34/44: loss=0.4476 
[epoch 6] step 36/44: loss=0.4471 
[epoch 6] step 38/44: loss=0.4465 
[epoch 6] step 40/44: loss=0.4495 
[epoch 6] step 42/44: loss=0.4494 
[epoch 6] step 44/44: loss=0.4489 
[epoch 6] train_loss(avg per step)=0.8979 lambda[min,max]=[0.500005,1.000000]
[epoch 6] val_loss=0.9786 qwk=('0.6262', '0.6400', '0.6504') averageQWK=0.6388 macroEMD=0.2293 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    1    0    0
     0   32   21    2    0
     0   41   52   32    0
     0    4   26   86    0
     0    1    0   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   18   33    2    0
     0   12   91   19    0
     0    1   34   98    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   44   24    1    0
     0   41   81   30    0
     0    2   24   76    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=0.3888 
[epoch 7] step 4/44: loss=0.3962 
[epoch 7] step 6/44: loss=0.3959 
[epoch 7] step 8/44: loss=0.3865 
[epoch 7] step 10/44: loss=0.3946 
[epoch 7] step 12/44: loss=0.3865 
[epoch 7] step 14/44: loss=0.3911 
[epoch 7] step 16/44: loss=0.3912 
[epoch 7] step 18/44: loss=0.3966 
[epoch 7] step 20/44: loss=0.3959 
[epoch 7] step 22/44: loss=0.3962 
[epoch 7] step 24/44: loss=0.3981 
[epoch 7] step 26/44: loss=0.3966 
[epoch 7] step 28/44: loss=0.4004 
[epoch 7] step 30/44: loss=0.3975 
[epoch 7] step 32/44: loss=0.3936 
[epoch 7] step 34/44: loss=0.3902 
[epoch 7] step 36/44: loss=0.3893 
[epoch 7] step 38/44: loss=0.3907 
[epoch 7] step 40/44: loss=0.3913 
[epoch 7] step 42/44: loss=0.3925 
[epoch 7] step 44/44: loss=0.3911 
[epoch 7] train_loss(avg per step)=0.7823 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=0.9334 qwk=('0.5934', '0.6680', '0.5654') averageQWK=0.6089 macroEMD=0.2295 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   18   35    2    0
     0   10   93   22    0
     0    1   39   75    1
     0    0    4   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   23   28    2    0
     0   13   89   20    0
     0    1   36   96    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   42   27    0    0
     0   29  114    9    0
     0    2   60   40    0
     0    0    1    1    0
[epoch 8] step 2/44: loss=0.3603 
[epoch 8] step 4/44: loss=0.3380 
[epoch 8] step 6/44: loss=0.3450 
[epoch 8] step 8/44: loss=0.3384 
[epoch 8] step 10/44: loss=0.3336 
[epoch 8] step 12/44: loss=0.3466 
[epoch 8] step 14/44: loss=0.3437 
[epoch 8] step 16/44: loss=0.3407 
[epoch 8] step 18/44: loss=0.3414 
[epoch 8] step 20/44: loss=0.3436 
[epoch 8] step 22/44: loss=0.3408 
[epoch 8] step 24/44: loss=0.3428 
[epoch 8] step 26/44: loss=0.3456 
[epoch 8] step 28/44: loss=0.3503 
[epoch 8] step 30/44: loss=0.3528 
[epoch 8] step 32/44: loss=0.3520 
[epoch 8] step 34/44: loss=0.3516 
[epoch 8] step 36/44: loss=0.3493 
[epoch 8] step 38/44: loss=0.3485 
[epoch 8] step 40/44: loss=0.3469 
[epoch 8] step 42/44: loss=0.3458 
[epoch 8] step 44/44: loss=0.3489 
[epoch 8] train_loss(avg per step)=0.6978 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=0.9517 qwk=('0.5897', '0.6025', '0.6225') averageQWK=0.6049 macroEMD=0.2182 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   19   29    7    0
     0   12   65   48    0
     0    1   13  102    0
     0    1    0   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   20   26    7    0
     0    8   68   46    0
     0    0   16  117    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   40   24    5    0
     0   22   75   55    0
     0    2   12   88    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=0.3673 
[epoch 9] step 4/44: loss=0.3382 
[epoch 9] step 6/44: loss=0.3398 
[epoch 9] step 8/44: loss=0.3535 
[epoch 9] step 10/44: loss=0.3425 
[epoch 9] step 12/44: loss=0.3384 
[epoch 9] step 14/44: loss=0.3421 
[epoch 9] step 16/44: loss=0.3362 
[epoch 9] step 18/44: loss=0.3352 
[epoch 9] step 20/44: loss=0.3299 
[epoch 9] step 22/44: loss=0.3288 
[epoch 9] step 24/44: loss=0.3256 
[epoch 9] step 26/44: loss=0.3249 
[epoch 9] step 28/44: loss=0.3233 
[epoch 9] step 30/44: loss=0.3230 
[epoch 9] step 32/44: loss=0.3206 
[epoch 9] step 34/44: loss=0.3169 
[epoch 9] step 36/44: loss=0.3126 
[epoch 9] step 38/44: loss=0.3122 
[epoch 9] step 40/44: loss=0.3118 
[epoch 9] step 42/44: loss=0.3114 
[epoch 9] step 44/44: loss=0.3072 
[epoch 9] train_loss(avg per step)=0.6144 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=0.9396 qwk=('0.5955', '0.6424', '0.5846') averageQWK=0.6075 macroEMD=0.2214 tailR0=('0.0870', '0.0000', '0.0000') tailR0avg=0.0290
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   22   30    3    0
     0   15   82   26    2
     0    1   38   68    9
     0    1    2   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   28   22    3    0
     0   17   83   22    0
     0    2   33   98    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   36   32    1    0
     0   21  112   19    0
     0    1   45   56    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=0.2480 
[epoch 10] step 4/44: loss=0.2512 
[epoch 10] step 6/44: loss=0.2497 
[epoch 10] step 8/44: loss=0.2565 
[epoch 10] step 10/44: loss=0.2650 
[epoch 10] step 12/44: loss=0.2610 
[epoch 10] step 14/44: loss=0.2595 
[epoch 10] step 16/44: loss=0.2548 
[epoch 10] step 18/44: loss=0.2549 
[epoch 10] step 20/44: loss=0.2521 
[epoch 10] step 22/44: loss=0.2534 
[epoch 10] step 24/44: loss=0.2515 
[epoch 10] step 26/44: loss=0.2524 
[epoch 10] step 28/44: loss=0.2542 
[epoch 10] step 30/44: loss=0.2536 
[epoch 10] step 32/44: loss=0.2537 
[epoch 10] step 34/44: loss=0.2536 
[epoch 10] step 36/44: loss=0.2518 
[epoch 10] step 38/44: loss=0.2549 
[epoch 10] step 40/44: loss=0.2557 
[epoch 10] step 42/44: loss=0.2535 
[epoch 10] step 44/44: loss=0.2563 
[epoch 10] train_loss(avg per step)=0.5126 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=0.9428 qwk=('0.5358', '0.5946', '0.5275') averageQWK=0.5527 macroEMD=0.2248 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   13   38    4    0
     0    5   89   30    1
     0    1   38   73    4
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   15   33    5    0
     0    6   74   42    0
     0    1   20  112    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   34   34    1    0
     0   25  113   14    0
     0    0   60   42    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.1387 
[epoch 11] step 4/44: loss=0.1904 
[epoch 11] step 6/44: loss=0.2328 
[epoch 11] step 8/44: loss=0.2240 
[epoch 11] step 10/44: loss=0.2269 
[epoch 11] step 12/44: loss=0.2200 
[epoch 11] step 14/44: loss=0.2191 
[epoch 11] step 16/44: loss=0.2253 
[epoch 11] step 18/44: loss=0.2222 
[epoch 11] step 20/44: loss=0.2213 
[epoch 11] step 22/44: loss=0.2225 
[epoch 11] step 24/44: loss=0.2220 
[epoch 11] step 26/44: loss=0.2211 
[epoch 11] step 28/44: loss=0.2188 
[epoch 11] step 30/44: loss=0.2212 
[epoch 11] step 32/44: loss=0.2193 
[epoch 11] step 34/44: loss=0.2189 
[epoch 11] step 36/44: loss=0.2196 
[epoch 11] step 38/44: loss=0.2213 
[epoch 11] step 40/44: loss=0.2206 
[epoch 11] step 42/44: loss=0.2190 
[epoch 11] step 44/44: loss=0.2200 
[epoch 11] train_loss(avg per step)=0.4399 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=0.9918 qwk=('0.5465', '0.6068', '0.5675') averageQWK=0.5736 macroEMD=0.2296 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   26   26    3    0
     0   22   84   19    0
     0    1   54   61    0
     0    1    5   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   27   24    2    0
     0   16   92   14    0
     0    2   51   80    0
     0    0    3    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   48   21    0    0
     0   35  109    8    0
     0    2   62   38    0
     0    0    2    0    0
[epoch 12] step 2/44: loss=0.2669 
[epoch 12] step 4/44: loss=0.2477 
[epoch 12] step 6/44: loss=0.2231 
[epoch 12] step 8/44: loss=0.2077 
[epoch 12] step 10/44: loss=0.1938 
[epoch 12] step 12/44: loss=0.1977 
[epoch 12] step 14/44: loss=0.1960 
[epoch 12] step 16/44: loss=0.1958 
[epoch 12] step 18/44: loss=0.1986 
[epoch 12] step 20/44: loss=0.1951 
[epoch 12] step 22/44: loss=0.1948 
[epoch 12] step 24/44: loss=0.1955 
[epoch 12] step 26/44: loss=0.1941 
[epoch 12] step 28/44: loss=0.1938 
[epoch 12] step 30/44: loss=0.1930 
[epoch 12] step 32/44: loss=0.1970 
[epoch 12] step 34/44: loss=0.1928 
[epoch 12] step 36/44: loss=0.1921 
[epoch 12] step 38/44: loss=0.1952 
[epoch 12] step 40/44: loss=0.1953 
[epoch 12] step 42/44: loss=0.1896 
[epoch 12] step 44/44: loss=0.1854 
[epoch 12] train_loss(avg per step)=0.3709 lambda[min,max]=[0.498905,1.000000]
[epoch 12] val_loss=0.9991 qwk=('0.5477', '0.5714', '0.5598') averageQWK=0.5596 macroEMD=0.2206 tailR0=('0.1739', '0.0000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     0   15   34    6    0
     0    5   75   40    5
     0    1   24   81   10
     0    0    2   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0   15   30    8    0
     0    4   62   56    0
     0    1    8  124    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   29   38    2    0
     0   17   91   44    0
     0    1   31   70    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.2079 
[epoch 13] step 4/44: loss=0.2258 
[epoch 13] step 6/44: loss=0.2089 
[epoch 13] step 8/44: loss=0.2069 
[epoch 13] step 10/44: loss=0.1884 
[epoch 13] step 12/44: loss=0.1859 
[epoch 13] step 14/44: loss=0.1821 
[epoch 13] step 16/44: loss=0.1765 
[epoch 13] step 18/44: loss=0.1726 
[epoch 13] step 20/44: loss=0.1714 
[epoch 13] step 22/44: loss=0.1705 
[epoch 13] step 24/44: loss=0.1702 
[epoch 13] step 26/44: loss=0.1651 
[epoch 13] step 28/44: loss=0.1613 
[epoch 13] step 30/44: loss=0.1601 
[epoch 13] step 32/44: loss=0.1574 
[epoch 13] step 34/44: loss=0.1549 
[epoch 13] step 36/44: loss=0.1530 
[epoch 13] step 38/44: loss=0.1538 
[epoch 13] step 40/44: loss=0.1590 
[epoch 13] step 42/44: loss=0.1585 
[epoch 13] step 44/44: loss=0.1588 
[epoch 13] train_loss(avg per step)=0.3176 lambda[min,max]=[0.499216,1.000000]
[epoch 13] val_loss=0.9634 qwk=('0.5424', '0.6192', '0.6290') averageQWK=0.5969 macroEMD=0.2115 tailR0=('0.1957', '0.0000', '0.0000') tailR0avg=0.0652
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   20   32    3    0
     0   13   93   15    4
     0    1   54   54    7
     0    1    6    7    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   23   24    6    0
     0   12   71   39    0
     0    3   17  113    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   39   29    1    0
     0   19   99   34    0
     0    2   27   73    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.1633 
[epoch 14] step 4/44: loss=0.1441 
[epoch 14] step 6/44: loss=0.1451 
[epoch 14] step 8/44: loss=0.1442 
[epoch 14] step 10/44: loss=0.1480 
[epoch 14] step 12/44: loss=0.1436 
[epoch 14] step 14/44: loss=0.1401 
[epoch 14] step 16/44: loss=0.1367 
[epoch 14] step 18/44: loss=0.1365 
[epoch 14] step 20/44: loss=0.1307 
[epoch 14] step 22/44: loss=0.1325 
[epoch 14] step 24/44: loss=0.1282 
[epoch 14] step 26/44: loss=0.1283 
[epoch 14] step 28/44: loss=0.1274 
[epoch 14] step 30/44: loss=0.1267 
[epoch 14] step 32/44: loss=0.1276 
[epoch 14] step 34/44: loss=0.1263 
[epoch 14] step 36/44: loss=0.1255 
[epoch 14] step 38/44: loss=0.1250 
[epoch 14] step 40/44: loss=0.1265 
[epoch 14] step 42/44: loss=0.1260 
[epoch 14] step 44/44: loss=0.1248 
[epoch 14] train_loss(avg per step)=0.2497 lambda[min,max]=[0.494104,1.000000]
[epoch 14] val_loss=1.0545 qwk=('0.4298', '0.6153', '0.5261') averageQWK=0.5237 macroEMD=0.2317 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   20   34    1    0
     0    8  109    6    2
     0    1   76   35    4
     0    1   12    8    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   26   23    4    0
     0    9   93   20    0
     0    3   40   90    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   44   25    0    0
     0   27  118    7    0
     0    2   68   32    0
     0    0    2    0    0
[epoch 15] step 2/44: loss=0.1786 
[epoch 15] step 4/44: loss=0.1549 
[epoch 15] step 6/44: loss=0.1495 
[epoch 15] step 8/44: loss=0.1351 
[epoch 15] step 10/44: loss=0.1304 
[epoch 15] step 12/44: loss=0.1244 
[epoch 15] step 14/44: loss=0.1165 
[epoch 15] step 16/44: loss=0.1104 
[epoch 15] step 18/44: loss=0.1098 
[epoch 15] step 20/44: loss=0.1081 
[epoch 15] step 22/44: loss=0.1056 
[epoch 15] step 24/44: loss=0.1022 
[epoch 15] step 26/44: loss=0.1054 
[epoch 15] step 28/44: loss=0.1009 
[epoch 15] step 30/44: loss=0.0972 
[epoch 15] step 32/44: loss=0.0959 
[epoch 15] step 34/44: loss=0.0946 
[epoch 15] step 36/44: loss=0.0917 
[epoch 15] step 38/44: loss=0.0910 
[epoch 15] step 40/44: loss=0.0905 
[epoch 15] step 42/44: loss=0.0900 
[epoch 15] step 44/44: loss=0.0871 
[epoch 15] train_loss(avg per step)=0.1743 lambda[min,max]=[0.498762,1.000000]
[epoch 15] val_loss=1.0687 qwk=('0.4705', '0.6072', '0.6175') averageQWK=0.5651 macroEMD=0.2177 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   26   28    1    0
     0   20  101    1    3
     0    1   80   27    8
     0    1   14    2    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    0    2    0
     0   33   14    6    0
     0   27   65   30    0
     0    5   23  105    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   49   19    1    0
     0   34  101   17    0
     0    2   49   51    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=0.1260 
[epoch 16] step 4/44: loss=0.1352 
[epoch 16] step 6/44: loss=0.1145 
[epoch 16] step 8/44: loss=0.0992 
[epoch 16] step 10/44: loss=0.0925 
[epoch 16] step 12/44: loss=0.0892 
[epoch 16] step 14/44: loss=0.0921 
[epoch 16] step 16/44: loss=0.0885 
[epoch 16] step 18/44: loss=0.0826 
[epoch 16] step 20/44: loss=0.0770 
[epoch 16] step 22/44: loss=0.0794 
[epoch 16] step 24/44: loss=0.0796 
[epoch 16] step 26/44: loss=0.0790 
[epoch 16] step 28/44: loss=0.0793 
[epoch 16] step 30/44: loss=0.0753 
[epoch 16] step 32/44: loss=0.0722 
[epoch 16] step 34/44: loss=0.0693 
[epoch 16] step 36/44: loss=0.0677 
[epoch 16] step 38/44: loss=0.0652 
[epoch 16] step 40/44: loss=0.0643 
[epoch 16] step 42/44: loss=0.0638 
[epoch 16] step 44/44: loss=0.0622 
[epoch 16] train_loss(avg per step)=0.1244 lambda[min,max]=[0.498879,1.000000]
[epoch 16] val_loss=1.0462 qwk=('0.5166', '0.6040', '0.5779') averageQWK=0.5662 macroEMD=0.2161 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   21   32    2    0
     0   13   93   17    2
     0    1   55   55    5
     0    1    9    8    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    0    2    0
     0   26   21    6    0
     0   18   64   40    0
     0    3   17  113    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   37   32    0    0
     0   19  118   15    0
     0    1   55   46    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=0.0417 
[epoch 17] step 4/44: loss=0.0277 
[epoch 17] step 6/44: loss=0.0329 
[epoch 17] step 8/44: loss=0.0355 
[epoch 17] step 10/44: loss=0.0357 
[epoch 17] step 12/44: loss=0.0378 
[epoch 17] step 14/44: loss=0.0363 
[epoch 17] step 16/44: loss=0.0369 
[epoch 17] step 18/44: loss=0.0372 
[epoch 17] step 20/44: loss=0.0369 
[epoch 17] step 22/44: loss=0.0344 
[epoch 17] step 24/44: loss=0.0318 
[epoch 17] step 26/44: loss=0.0317 
[epoch 17] step 28/44: loss=0.0304 
[epoch 17] step 30/44: loss=0.0335 
[epoch 17] step 32/44: loss=0.0337 
[epoch 17] step 34/44: loss=0.0322 
[epoch 17] step 36/44: loss=0.0319 
[epoch 17] step 38/44: loss=0.0322 
[epoch 17] step 40/44: loss=0.0345 
[epoch 17] step 42/44: loss=0.0345 
[epoch 17] step 44/44: loss=0.0318 
[epoch 17] train_loss(avg per step)=0.0637 lambda[min,max]=[0.431048,1.000000]
[epoch 17] val_loss=1.0584 qwk=('0.5530', '0.5961', '0.4887') averageQWK=0.5459 macroEMD=0.2164 tailR0=('0.0217', '0.0972', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   16   35    4    0
     0    6   84   35    0
     0    1   32   83    0
     0    0    2   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    1    2    0
     0   21   25    7    0
     0    7   78   37    0
     0    1   23  109    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   21   47    1    0
     0    8  125   19    0
     0    1   54   47    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=0.0334 
[epoch 18] step 4/44: loss=0.0368 
[epoch 18] step 6/44: loss=0.0335 
[epoch 18] step 8/44: loss=0.0392 
[epoch 18] step 10/44: loss=0.0302 
[epoch 18] step 12/44: loss=0.0217 
[epoch 18] step 14/44: loss=0.0228 
[epoch 18] step 16/44: loss=0.0212 
[epoch 18] step 18/44: loss=0.0259 
[epoch 18] step 20/44: loss=0.0240 
[epoch 18] step 22/44: loss=0.0218 
[epoch 18] step 24/44: loss=0.0199 
[epoch 18] step 26/44: loss=0.0172 
[epoch 18] step 28/44: loss=0.0167 
[epoch 18] step 30/44: loss=0.0146 
[epoch 18] step 32/44: loss=0.0129 
[epoch 18] step 34/44: loss=0.0139 
[epoch 18] step 36/44: loss=0.0143 
[epoch 18] step 38/44: loss=0.0152 
[epoch 18] step 40/44: loss=0.0153 
[epoch 18] step 42/44: loss=0.0165 
[epoch 18] step 44/44: loss=0.0185 
[epoch 18] train_loss(avg per step)=0.0369 lambda[min,max]=[0.404933,1.000000]
[epoch 18] val_loss=1.0691 qwk=('0.5512', '0.5692', '0.5491') averageQWK=0.5565 macroEMD=0.2110 tailR0=('0.0217', '0.0972', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   24   24    7    0
     0   11   88   26    0
     0    1   37   77    1
     0    1    4   17    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    0    0
     0   21   29    3    0
     0    9  102   11    0
     0    2   58   73    0
     0    0    4    7    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   34   35    0    0
     0   14  122   16    0
     0    1   57   44    0
     0    0    0    2    0
[epoch 19] step 2/44: loss=0.0190 
[epoch 19] step 4/44: loss=0.0056 
[epoch 19] step 6/44: loss=0.0109 
[epoch 19] step 8/44: loss=0.0107 
[epoch 19] step 10/44: loss=0.0153 
[epoch 19] step 12/44: loss=0.0124 
[epoch 19] step 14/44: loss=0.0139 
[epoch 19] step 16/44: loss=0.0157 
[epoch 19] step 18/44: loss=0.0123 
[epoch 19] step 20/44: loss=0.0143 
[epoch 19] step 22/44: loss=0.0114 
[epoch 19] step 24/44: loss=0.0088 
[epoch 19] step 26/44: loss=0.0085 
[epoch 19] step 28/44: loss=0.0094 
[epoch 19] step 30/44: loss=0.0093 
[epoch 19] step 32/44: loss=0.0092 
[epoch 19] step 34/44: loss=0.0069 
[epoch 19] step 36/44: loss=0.0056 
[epoch 19] step 38/44: loss=0.0053 
[epoch 19] step 40/44: loss=0.0027 
[epoch 19] step 42/44: loss=0.0032 
[epoch 19] step 44/44: loss=0.0010 
[epoch 19] train_loss(avg per step)=0.0020 lambda[min,max]=[0.399421,1.000000]
[epoch 19] val_loss=1.0828 qwk=('0.5155', '0.6065', '0.5807') averageQWK=0.5676 macroEMD=0.2098 tailR0=('0.1652', '0.1528', '0.0000') tailR0avg=0.1060
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    1    0
     1   22   29    3    0
     0   14   93   18    0
     0    1   59   54    2
     0    1    8   11    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    1    0
     0   20   29    4    0
     0    9   84   29    0
     0    2   33   98    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   37   32    0    0
     0   23  109   20    0
     0    1   53   48    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=-0.0300 
[epoch 20] step 4/44: loss=-0.0251 
[epoch 20] step 6/44: loss=-0.0189 
[epoch 20] step 8/44: loss=-0.0126 
[epoch 20] step 10/44: loss=-0.0187 
[epoch 20] step 12/44: loss=-0.0208 
[epoch 20] step 14/44: loss=-0.0225 
[epoch 20] step 16/44: loss=-0.0234 
[epoch 20] step 18/44: loss=-0.0246 
[epoch 20] step 20/44: loss=-0.0239 
[epoch 20] step 22/44: loss=-0.0237 
[epoch 20] step 24/44: loss=-0.0234 
[epoch 20] step 26/44: loss=-0.0236 
[epoch 20] step 28/44: loss=-0.0228 
[epoch 20] step 30/44: loss=-0.0229 
[epoch 20] step 32/44: loss=-0.0218 
[epoch 20] step 34/44: loss=-0.0215 
[epoch 20] step 36/44: loss=-0.0234 
[epoch 20] step 38/44: loss=-0.0229 
[epoch 20] step 40/44: loss=-0.0222 
[epoch 20] step 42/44: loss=-0.0224 
[epoch 20] step 44/44: loss=-0.0231 
[epoch 20] train_loss(avg per step)=-0.0462 lambda[min,max]=[0.437291,1.000000]
[epoch 20] val_loss=1.1106 qwk=('0.5162', '0.5827', '0.5259') averageQWK=0.5416 macroEMD=0.2101 tailR0=('0.1152', '0.1528', '0.0000') tailR0avg=0.0893
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    5    0    0
     0   12   40    3    0
     0    9   89   25    2
     0    1   40   69    6
     0    0    7   13    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    1    0
     0   12   36    5    0
     0    6   84   31    1
     0    0   31  102    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   25   42    2    0
     0    8  123   21    0
     0    1   48   53    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=-0.0472 
[epoch 21] step 4/44: loss=-0.0339 
[epoch 21] step 6/44: loss=-0.0298 
[epoch 21] step 8/44: loss=-0.0308 
[epoch 21] step 10/44: loss=-0.0289 
[epoch 21] step 12/44: loss=-0.0280 
[epoch 21] step 14/44: loss=-0.0290 
[epoch 21] step 16/44: loss=-0.0316 
[epoch 21] step 18/44: loss=-0.0325 
[epoch 21] step 20/44: loss=-0.0335 
[epoch 21] step 22/44: loss=-0.0332 
[epoch 21] step 24/44: loss=-0.0331 
[epoch 21] step 26/44: loss=-0.0322 
[epoch 21] step 28/44: loss=-0.0322 
[epoch 21] step 30/44: loss=-0.0326 
[epoch 21] step 32/44: loss=-0.0336 
[epoch 21] step 34/44: loss=-0.0330 
[epoch 21] step 36/44: loss=-0.0325 
[epoch 21] step 38/44: loss=-0.0321 
[epoch 21] step 40/44: loss=-0.0321 
[epoch 21] step 42/44: loss=-0.0330 
[epoch 21] step 44/44: loss=-0.0325 
[epoch 21] train_loss(avg per step)=-0.0649 lambda[min,max]=[0.450426,1.000000]
[epoch 21] val_loss=1.0996 qwk=('0.5887', '0.6048', '0.5854') averageQWK=0.5930 macroEMD=0.2035 tailR0=('0.1652', '0.1528', '0.0000') tailR0avg=0.1060
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    1    0
     1   22   27    5    0
     0   16   76   32    1
     0    1   31   80    4
     0    1    2   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    1    0
     0   23   24    6    0
     0   10   91   21    0
     0    2   38   92    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   36   33    0    0
     0   17  117   18    0
     0    1   54   47    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=-0.0155 
[epoch 22] step 4/44: loss=-0.0310 
[epoch 22] step 6/44: loss=-0.0373 
[epoch 22] step 8/44: loss=-0.0391 
[epoch 22] step 10/44: loss=-0.0419 
[epoch 22] step 12/44: loss=-0.0414 
[epoch 22] step 14/44: loss=-0.0433 
[epoch 22] step 16/44: loss=-0.0439 
[epoch 22] step 18/44: loss=-0.0461 
[epoch 22] step 20/44: loss=-0.0463 
[epoch 22] step 22/44: loss=-0.0483 
[epoch 22] step 24/44: loss=-0.0478 
[epoch 22] step 26/44: loss=-0.0462 
[epoch 22] step 28/44: loss=-0.0477 
[epoch 22] step 30/44: loss=-0.0486 
[epoch 22] step 32/44: loss=-0.0485 
[epoch 22] step 34/44: loss=-0.0493 
[epoch 22] step 36/44: loss=-0.0495 
[epoch 22] step 38/44: loss=-0.0505 
[epoch 22] step 40/44: loss=-0.0502 
[epoch 22] step 42/44: loss=-0.0501 
[epoch 22] step 44/44: loss=-0.0477 
[epoch 22] train_loss(avg per step)=-0.0954 lambda[min,max]=[0.356606,1.000000]
[epoch 22] val_loss=1.1392 qwk=('0.4765', '0.5860', '0.5067') averageQWK=0.5230 macroEMD=0.2117 tailR0=('0.0717', '0.0972', '0.1250') tailR0avg=0.0980
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    1    0
     0   12   39    4    0
     0    6   93   25    1
     0    1   43   68    4
     0    0    7   15    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     0   14   34    5    0
     0    8   84   30    0
     0    1   30  102    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     0   21   46    2    0
     0   10  119   23    0
     0    1   48   53    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=-0.0632 
[epoch 23] step 4/44: loss=-0.0584 
[epoch 23] step 6/44: loss=-0.0592 
[epoch 23] step 8/44: loss=-0.0643 
[epoch 23] step 10/44: loss=-0.0623 
[epoch 23] step 12/44: loss=-0.0625 
[epoch 23] step 14/44: loss=-0.0592 
[epoch 23] step 16/44: loss=-0.0601 
[epoch 23] step 18/44: loss=-0.0610 
[epoch 23] step 20/44: loss=-0.0589 
[epoch 23] step 22/44: loss=-0.0583 
[epoch 23] step 24/44: loss=-0.0582 
[epoch 23] step 26/44: loss=-0.0585 
[epoch 23] step 28/44: loss=-0.0593 
[epoch 23] step 30/44: loss=-0.0603 
[epoch 23] step 32/44: loss=-0.0595 
[epoch 23] step 34/44: loss=-0.0586 
[epoch 23] step 36/44: loss=-0.0597 
[epoch 23] step 38/44: loss=-0.0593 
[epoch 23] step 40/44: loss=-0.0599 
[epoch 23] step 42/44: loss=-0.0596 
[epoch 23] step 44/44: loss=-0.0599 
[epoch 23] train_loss(avg per step)=-0.1197 lambda[min,max]=[0.350753,1.000000]
[epoch 23] val_loss=1.1746 qwk=('0.4996', '0.5933', '0.5234') averageQWK=0.5387 macroEMD=0.2084 tailR0=('0.0935', '0.0972', '0.0000') tailR0avg=0.0636
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    1    0
     0   13   40    2    0
     0    6   91   27    1
     0    1   44   69    2
     0    0    6   15    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     0   16   32    5    0
     0    9   85   28    0
     0    0   37   96    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   32   37    0    0
     0   23  117   12    0
     0    1   62   39    0
     0    0    1    1    0
[epoch 24] step 2/44: loss=-0.0723 
[epoch 24] step 4/44: loss=-0.0748 
[epoch 24] step 6/44: loss=-0.0774 
[epoch 24] step 8/44: loss=-0.0729 
[epoch 24] step 10/44: loss=-0.0754 
[epoch 24] step 12/44: loss=-0.0756 
[epoch 24] step 14/44: loss=-0.0741 
[epoch 24] step 16/44: loss=-0.0737 
[epoch 24] step 18/44: loss=-0.0755 
[epoch 24] step 20/44: loss=-0.0745 
[epoch 24] step 22/44: loss=-0.0721 
[epoch 24] step 24/44: loss=-0.0718 
[epoch 24] step 26/44: loss=-0.0713 
[epoch 24] step 28/44: loss=-0.0699 
[epoch 24] step 30/44: loss=-0.0699 
[epoch 24] step 32/44: loss=-0.0702 
[epoch 24] step 34/44: loss=-0.0697 
[epoch 24] step 36/44: loss=-0.0692 
[epoch 24] step 38/44: loss=-0.0686 
[epoch 24] step 40/44: loss=-0.0681 
[epoch 24] step 42/44: loss=-0.0682 
[epoch 24] step 44/44: loss=-0.0696 
[epoch 24] train_loss(avg per step)=-0.1392 lambda[min,max]=[0.352440,1.000000]
[epoch 24] val_loss=1.1690 qwk=('0.5066', '0.6051', '0.5657') averageQWK=0.5591 macroEMD=0.2059 tailR0=('0.0935', '0.0556', '0.1250') tailR0avg=0.0913
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    1    0
     2   12   38    3    0
     0    5   90   29    1
     0    1   41   72    2
     0    0    6   15    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    1    0
     0   17   31    5    0
     0    5   81   36    0
     0    0   29  103    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    0    0
     0   26   42    1    0
     0   17  110   25    0
     0    1   44   57    0
     0    0    0    2    0
[epoch 25] step 2/44: loss=-0.0845 
[epoch 25] step 4/44: loss=-0.0788 
[epoch 25] step 6/44: loss=-0.0788 
[epoch 25] step 8/44: loss=-0.0722 
[epoch 25] step 10/44: loss=-0.0732 
[epoch 25] step 12/44: loss=-0.0743 
[epoch 25] step 14/44: loss=-0.0730 
[epoch 25] step 16/44: loss=-0.0716 
[epoch 25] step 18/44: loss=-0.0714 
[epoch 25] step 20/44: loss=-0.0708 
[epoch 25] step 22/44: loss=-0.0702 
[epoch 25] step 24/44: loss=-0.0704 
[epoch 25] step 26/44: loss=-0.0719 
[epoch 25] step 28/44: loss=-0.0724 
[epoch 25] step 30/44: loss=-0.0715 
[epoch 25] step 32/44: loss=-0.0719 
[epoch 25] step 34/44: loss=-0.0718 
[epoch 25] step 36/44: loss=-0.0723 
[epoch 25] step 38/44: loss=-0.0722 
[epoch 25] step 40/44: loss=-0.0726 
[epoch 25] step 42/44: loss=-0.0729 
[epoch 25] step 44/44: loss=-0.0731 
[epoch 25] train_loss(avg per step)=-0.1463 lambda[min,max]=[0.413032,1.000000]
[epoch 25] val_loss=1.1713 qwk=('0.5357', '0.5984', '0.5937') averageQWK=0.5759 macroEMD=0.1977 tailR0=('0.1217', '0.0556', '0.1250') tailR0avg=0.1008
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    1    0
     1   17   33    4    0
     0   11   84   30    0
     0    1   34   77    4
     0    1    5   16    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    1    0
     0   21   26    6    0
     0   10   78   34    0
     0    1   31  100    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    0    0
     0   39   28    2    0
     0   30   94   28    0
     0    1   43   58    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=-0.0763 
[epoch 26] step 4/44: loss=-0.0788 
[epoch 26] step 6/44: loss=-0.0806 
[epoch 26] step 8/44: loss=-0.0796 
[epoch 26] step 10/44: loss=-0.0781 
[epoch 26] step 12/44: loss=-0.0808 
[epoch 26] step 14/44: loss=-0.0811 
[epoch 26] step 16/44: loss=-0.0828 
[epoch 26] step 18/44: loss=-0.0838 
[epoch 26] step 20/44: loss=-0.0825 
[epoch 26] step 22/44: loss=-0.0827 
[epoch 26] step 24/44: loss=-0.0805 
[epoch 26] step 26/44: loss=-0.0804 
[epoch 26] step 28/44: loss=-0.0812 
[epoch 26] step 30/44: loss=-0.0810 
[epoch 26] step 32/44: loss=-0.0797 
[epoch 26] step 34/44: loss=-0.0800 
[epoch 26] step 36/44: loss=-0.0796 
[epoch 26] step 38/44: loss=-0.0792 
[epoch 26] step 40/44: loss=-0.0790 
[epoch 26] step 42/44: loss=-0.0785 
[epoch 26] step 44/44: loss=-0.0794 
[epoch 26] train_loss(avg per step)=-0.1588 lambda[min,max]=[0.434334,1.000000]
[epoch 26] val_loss=1.1987 qwk=('0.5114', '0.6118', '0.5909') averageQWK=0.5714 macroEMD=0.2049 tailR0=('0.1217', '0.1528', '0.1250') tailR0avg=0.1332
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    1    0
     3   16   34    2    0
     0    8   91   26    0
     0    1   50   63    2
     0    1    6   15    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    0    0
     1   20   28    4    0
     0   11   86   25    0
     0    1   45   86    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    0    0
     1   31   37    0    0
     0   15  117   20    0
     0    1   50   51    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=-0.0896 
[epoch 27] step 4/44: loss=-0.0818 
[epoch 27] step 6/44: loss=-0.0822 
[epoch 27] step 8/44: loss=-0.0857 
[epoch 27] step 10/44: loss=-0.0854 
[epoch 27] step 12/44: loss=-0.0875 
[epoch 27] step 14/44: loss=-0.0876 
[epoch 27] step 16/44: loss=-0.0888 
[epoch 27] step 18/44: loss=-0.0870 
[epoch 27] step 20/44: loss=-0.0855 
[epoch 27] step 22/44: loss=-0.0852 
[epoch 27] step 24/44: loss=-0.0841 
[epoch 27] step 26/44: loss=-0.0833 
[epoch 27] step 28/44: loss=-0.0831 
[epoch 27] step 30/44: loss=-0.0836 
[epoch 27] step 32/44: loss=-0.0843 
[epoch 27] step 34/44: loss=-0.0841 
[epoch 27] step 36/44: loss=-0.0846 
[epoch 27] step 38/44: loss=-0.0840 
[epoch 27] step 40/44: loss=-0.0835 
[epoch 27] step 42/44: loss=-0.0836 
[epoch 27] step 44/44: loss=-0.0843 
[epoch 27] train_loss(avg per step)=-0.1686 lambda[min,max]=[0.387080,1.000000]
[epoch 27] val_loss=1.2157 qwk=('0.4715', '0.5794', '0.5735') averageQWK=0.5415 macroEMD=0.2015 tailR0=('0.1870', '0.0972', '0.1250') tailR0avg=0.1364
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    1    0
     1   15   37    2    0
     0   12   87   24    2
     0    1   53   56    6
     0    1    8   10    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    0    2    0
     0   22   25    6    0
     0   13   71   38    0
     0    2   30  101    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    0    0
     0   29   40    0    0
     0   18  111   23    0
     0    1   48   53    0
     0    0    0    2    0
[epoch 28] step 2/44: loss=-0.0928 
[epoch 28] step 4/44: loss=-0.0899 
[epoch 28] step 6/44: loss=-0.0859 
[epoch 28] step 8/44: loss=-0.0827 
[epoch 28] step 10/44: loss=-0.0843 
[epoch 28] step 12/44: loss=-0.0843 
[epoch 28] step 14/44: loss=-0.0853 
[epoch 28] step 16/44: loss=-0.0863 
[epoch 28] step 18/44: loss=-0.0867 
[epoch 28] step 20/44: loss=-0.0846 
[epoch 28] step 22/44: loss=-0.0848 
[epoch 28] step 24/44: loss=-0.0850 
[epoch 28] step 26/44: loss=-0.0859 
[epoch 28] step 28/44: loss=-0.0867 
[epoch 28] step 30/44: loss=-0.0871 
[epoch 28] step 32/44: loss=-0.0877 
[epoch 28] step 34/44: loss=-0.0881 
[epoch 28] step 36/44: loss=-0.0884 
[epoch 28] step 38/44: loss=-0.0888 
[epoch 28] step 40/44: loss=-0.0887 
[epoch 28] step 42/44: loss=-0.0886 
[epoch 28] step 44/44: loss=-0.0888 
[epoch 28] train_loss(avg per step)=-0.1777 lambda[min,max]=[0.440699,1.000000]
[epoch 28] val_loss=1.2282 qwk=('0.4772', '0.6107', '0.5719') averageQWK=0.5533 macroEMD=0.2053 tailR0=('0.1652', '0.0972', '0.1250') tailR0avg=0.1291
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    1    0
     3   14   36    2    0
     0    7  102   15    1
     0    1   60   53    2
     0    0   10   10    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    0    2    0
     0   26   22    5    0
     0   17   68   37    0
     0    2   26  105    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    0    0
     0   34   35    0    0
     0   20  119   13    0
     0    1   58   43    0
     0    0    0    2    0
[epoch 29] step 2/44: loss=-0.1004 
[epoch 29] step 4/44: loss=-0.1012 
[epoch 29] step 6/44: loss=-0.1019 
[epoch 29] step 8/44: loss=-0.1017 
[epoch 29] step 10/44: loss=-0.1005 
[epoch 29] step 12/44: loss=-0.0965 
[epoch 29] step 14/44: loss=-0.0960 
[epoch 29] step 16/44: loss=-0.0955 
[epoch 29] step 18/44: loss=-0.0944 
[epoch 29] step 20/44: loss=-0.0923 
[epoch 29] step 22/44: loss=-0.0909 
[epoch 29] step 24/44: loss=-0.0917 
[epoch 29] step 26/44: loss=-0.0914 
[epoch 29] step 28/44: loss=-0.0919 
[epoch 29] step 30/44: loss=-0.0924 
[epoch 29] step 32/44: loss=-0.0929 
[epoch 29] step 34/44: loss=-0.0931 
[epoch 29] step 36/44: loss=-0.0930 
[epoch 29] step 38/44: loss=-0.0929 
[epoch 29] step 40/44: loss=-0.0928 
[epoch 29] step 42/44: loss=-0.0929 
[epoch 29] step 44/44: loss=-0.0927 
[epoch 29] train_loss(avg per step)=-0.1854 lambda[min,max]=[0.396750,1.000000]
[epoch 29] val_loss=1.2127 qwk=('0.5273', '0.6084', '0.5563') averageQWK=0.5640 macroEMD=0.2031 tailR0=('0.1370', '0.0972', '0.1250') tailR0avg=0.1197
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    1    0
     0   19   33    3    0
     0   11   86   27    1
     0    1   41   69    5
     0    1    7   11    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    1    0
     0   20   28    5    0
     0    8   83   31    0
     0    0   36   96    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    0    0
     0   27   42    0    0
     0   13  119   20    0
     0    1   53   48    0
     0    0    0    2    0
[epoch 30] step 2/44: loss=-0.0955 
[epoch 30] step 4/44: loss=-0.0950 
[epoch 30] step 6/44: loss=-0.0941 
[epoch 30] step 8/44: loss=-0.0956 
[epoch 30] step 10/44: loss=-0.0956 
[epoch 30] step 12/44: loss=-0.0957 
[epoch 30] step 14/44: loss=-0.0956 
[epoch 30] step 16/44: loss=-0.0931 
[epoch 30] step 18/44: loss=-0.0933 
[epoch 30] step 20/44: loss=-0.0925 
[epoch 30] step 22/44: loss=-0.0930 
[epoch 30] step 24/44: loss=-0.0930 
[epoch 30] step 26/44: loss=-0.0932 
[epoch 30] step 28/44: loss=-0.0940 
[epoch 30] step 30/44: loss=-0.0936 
[epoch 30] step 32/44: loss=-0.0943 
[epoch 30] step 34/44: loss=-0.0946 
[epoch 30] step 36/44: loss=-0.0950 
[epoch 30] step 38/44: loss=-0.0954 
[epoch 30] step 40/44: loss=-0.0955 
[epoch 30] step 42/44: loss=-0.0953 
[epoch 30] step 44/44: loss=-0.0955 
[epoch 30] train_loss(avg per step)=-0.1910 lambda[min,max]=[0.415327,1.000000]
[epoch 30] val_loss=1.2299 qwk=('0.4743', '0.5947', '0.5848') averageQWK=0.5513 macroEMD=0.2021 tailR0=('0.0935', '0.0556', '0.1250') tailR0avg=0.0913
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    1    0
     1   15   37    2    0
     0    9   89   26    1
     0    1   47   65    3
     0    1    9   11    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    0    2    0
     0   24   24    5    0
     0   14   69   39    0
     0    2   27  104    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    0    0
     1   30   38    0    0
     0   16  114   22    0
     0    1   49   52    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=-0.0995 
[epoch 31] step 4/44: loss=-0.1009 
[epoch 31] step 6/44: loss=-0.0997 
[epoch 31] step 8/44: loss=-0.0967 
[epoch 31] step 10/44: loss=-0.0968 
[epoch 31] step 12/44: loss=-0.0983 
[epoch 31] step 14/44: loss=-0.0991 
[epoch 31] step 16/44: loss=-0.0997 
[epoch 31] step 18/44: loss=-0.0998 
[epoch 31] step 20/44: loss=-0.0997 
[epoch 31] step 22/44: loss=-0.0993 
[epoch 31] step 24/44: loss=-0.0997 
[epoch 31] step 26/44: loss=-0.0997 
[epoch 31] step 28/44: loss=-0.1001 
[epoch 31] step 30/44: loss=-0.0996 
[epoch 31] step 32/44: loss=-0.0998 
[epoch 31] step 34/44: loss=-0.0997 
[epoch 31] step 36/44: loss=-0.0993 
[epoch 31] step 38/44: loss=-0.0995 
[epoch 31] step 40/44: loss=-0.0996 
[epoch 31] step 42/44: loss=-0.0991 
[epoch 31] step 44/44: loss=-0.0992 
[epoch 31] train_loss(avg per step)=-0.1984 lambda[min,max]=[0.365601,1.000000]
[epoch 31] val_loss=1.2205 qwk=('0.5290', '0.5993', '0.5719') averageQWK=0.5667 macroEMD=0.1993 tailR0=('0.1152', '0.0972', '0.1250') tailR0avg=0.1125
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     2   17   34    2    0
     0   11   87   26    1
     0    1   43   67    5
     0    1    8   11    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    0    2    0
     0   21   27    5    0
     0    8   78   36    0
     0    1   30  101    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    0    0
     0   27   42    0    0
     0   13  116   23    0
     0    1   48   53    0
     0    0    0    2    0
[epoch 32] step 2/44: loss=-0.0934 
[epoch 32] step 4/44: loss=-0.0961 
[epoch 32] step 6/44: loss=-0.0961 
[epoch 32] step 8/44: loss=-0.0964 
[epoch 32] step 10/44: loss=-0.0979 
[epoch 32] step 12/44: loss=-0.0982 
[epoch 32] step 14/44: loss=-0.0983 
[epoch 32] step 16/44: loss=-0.0983 
[epoch 32] step 18/44: loss=-0.0988 
[epoch 32] step 20/44: loss=-0.0998 
[epoch 32] step 22/44: loss=-0.1000 
[epoch 32] step 24/44: loss=-0.0999 
[epoch 32] step 26/44: loss=-0.1002 
[epoch 32] step 28/44: loss=-0.1003 
[epoch 32] step 30/44: loss=-0.1003 
[epoch 32] step 32/44: loss=-0.1003 
[epoch 32] step 34/44: loss=-0.1006 
[epoch 32] step 36/44: loss=-0.1006 
[epoch 32] step 38/44: loss=-0.1006 
[epoch 32] step 40/44: loss=-0.1004 
[epoch 32] step 42/44: loss=-0.1003 
[epoch 32] step 44/44: loss=-0.1006 
[epoch 32] train_loss(avg per step)=-0.2012 lambda[min,max]=[0.403296,1.000000]
[epoch 32] val_loss=1.2353 qwk=('0.5066', '0.6088', '0.5762') averageQWK=0.5639 macroEMD=0.2013 tailR0=('0.0935', '0.0556', '0.1250') tailR0avg=0.0913
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    1    0
     0   15   38    2    0
     0    7   87   30    1
     0    1   40   72    3
     0    0    7   14    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    0    2    0
     0   22   25    6    0
     0    8   75   39    0
     0    1   22  110    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    0    0
     1   26   42    0    0
     0   11  118   23    0
     0    1   48   53    0
     0    0    0    2    0
[epoch 33] step 2/44: loss=-0.0975 
[epoch 33] step 4/44: loss=-0.0968 
[epoch 33] step 6/44: loss=-0.0953 
[epoch 33] step 8/44: loss=-0.0969 
[epoch 33] step 10/44: loss=-0.0986 
[epoch 33] step 12/44: loss=-0.0991 
[epoch 33] step 14/44: loss=-0.1000 
[epoch 33] step 16/44: loss=-0.1001 
[epoch 33] step 18/44: loss=-0.1002 
[epoch 33] step 20/44: loss=-0.1003 
[epoch 33] step 22/44: loss=-0.1007 
[epoch 33] step 24/44: loss=-0.1006 
[epoch 33] step 26/44: loss=-0.1010 
[epoch 33] step 28/44: loss=-0.1010 
[epoch 33] step 30/44: loss=-0.1009 
[epoch 33] step 32/44: loss=-0.1015 
[epoch 33] step 34/44: loss=-0.1017 
[epoch 33] step 36/44: loss=-0.1019 
[epoch 33] step 38/44: loss=-0.1018 
[epoch 33] step 40/44: loss=-0.1016 
[epoch 33] step 42/44: loss=-0.1017 
[epoch 33] step 44/44: loss=-0.1019 
[epoch 33] train_loss(avg per step)=-0.2037 lambda[min,max]=[0.375748,1.000000]
[epoch 33] val_loss=1.2285 qwk=('0.4659', '0.6064', '0.5771') averageQWK=0.5498 macroEMD=0.2002 tailR0=('0.1152', '0.0972', '0.1250') tailR0avg=0.1125
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    1    0
     0   16   37    2    0
     0    9   94   21    1
     0    1   54   58    3
     0    1    9   10    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     0   19   29    5    0
     0    7   83   32    0
     0    0   32  101    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    0    0
     0   31   38    0    0
     0   19  110   23    0
     0    1   49   52    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=-0.1037 
[epoch 34] step 4/44: loss=-0.1058 
[epoch 34] step 6/44: loss=-0.1061 
[epoch 34] step 8/44: loss=-0.1060 
[epoch 34] step 10/44: loss=-0.1056 
[epoch 34] step 12/44: loss=-0.1060 
[epoch 34] step 14/44: loss=-0.1057 
[epoch 34] step 16/44: loss=-0.1048 
[epoch 34] step 18/44: loss=-0.1046 
[epoch 34] step 20/44: loss=-0.1045 
[epoch 34] step 22/44: loss=-0.1044 
[epoch 34] step 24/44: loss=-0.1043 
[epoch 34] step 26/44: loss=-0.1043 
[epoch 34] step 28/44: loss=-0.1048 
[epoch 34] step 30/44: loss=-0.1039 
[epoch 34] step 32/44: loss=-0.1038 
[epoch 34] step 34/44: loss=-0.1038 
[epoch 34] step 36/44: loss=-0.1035 
[epoch 34] step 38/44: loss=-0.1032 
[epoch 34] step 40/44: loss=-0.1030 
[epoch 34] step 42/44: loss=-0.1030 
[epoch 34] step 44/44: loss=-0.1032 
[epoch 34] train_loss(avg per step)=-0.2064 lambda[min,max]=[0.469563,1.000000]
[epoch 34] val_loss=1.2312 qwk=('0.4824', '0.6124', '0.5776') averageQWK=0.5575 macroEMD=0.1994 tailR0=('0.1152', '0.0972', '0.1250') tailR0avg=0.1125
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    1    0
     0   19   34    2    0
     0   11   88   25    1
     0    1   50   62    3
     0    1    9   10    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    1    0
     0   22   26    5    0
     0    9   82   31    0
     0    1   34   98    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    0    0
     1   28   40    0    0
     0   12  118   22    0
     0    1   50   51    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=-0.1013 
[epoch 35] step 4/44: loss=-0.1060 
[epoch 35] step 6/44: loss=-0.1034 
[epoch 35] step 8/44: loss=-0.1045 
[epoch 35] step 10/44: loss=-0.1040 
[epoch 35] step 12/44: loss=-0.1036 
[epoch 35] step 14/44: loss=-0.1034 
[epoch 35] step 16/44: loss=-0.1030 
[epoch 35] step 18/44: loss=-0.1032 
[epoch 35] step 20/44: loss=-0.1026 
[epoch 35] step 22/44: loss=-0.1030 
[epoch 35] step 24/44: loss=-0.1022 
[epoch 35] step 26/44: loss=-0.1025 
[epoch 35] step 28/44: loss=-0.1022 
[epoch 35] step 30/44: loss=-0.1024 
[epoch 35] step 32/44: loss=-0.1017 
[epoch 35] step 34/44: loss=-0.1021 
[epoch 35] step 36/44: loss=-0.1022 
[epoch 35] step 38/44: loss=-0.1023 
[epoch 35] step 40/44: loss=-0.1025 
[epoch 35] step 42/44: loss=-0.1028 
[epoch 35] step 44/44: loss=-0.1028 
[epoch 35] train_loss(avg per step)=-0.2057 lambda[min,max]=[0.415331,1.000000]
[epoch 35] val_loss=1.2291 qwk=('0.4821', '0.6170', '0.5793') averageQWK=0.5594 macroEMD=0.1983 tailR0=('0.1370', '0.0972', '0.1250') tailR0avg=0.1197
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    1    0
     0   17   36    2    0
     0    8   93   23    1
     0    1   51   60    4
     0    1    9    9    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    1    0
     0   23   25    5    0
     0   10   79   33    0
     0    2   29  102    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    0    0
     1   28   40    0    0
     0   15  114   23    0
     0    1   48   53    0
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-1-reassignment-0/fold4/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-1-reassignment-0/fold4/metrics.json
Done.
