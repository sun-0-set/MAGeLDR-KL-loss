[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.9760 
[epoch 1] step 4/44: loss=0.9584 
[epoch 1] step 6/44: loss=0.9516 
[epoch 1] step 8/44: loss=0.9427 
[epoch 1] step 10/44: loss=0.9366 
[epoch 1] step 12/44: loss=0.9359 
[epoch 1] step 14/44: loss=0.9350 
[epoch 1] step 16/44: loss=0.9363 
[epoch 1] step 18/44: loss=0.9390 
[epoch 1] step 20/44: loss=0.9367 
[epoch 1] step 22/44: loss=0.9358 
[epoch 1] step 24/44: loss=0.9373 
[epoch 1] step 26/44: loss=0.9332 
[epoch 1] step 28/44: loss=0.9297 
[epoch 1] step 30/44: loss=0.9275 
[epoch 1] step 32/44: loss=0.9268 
[epoch 1] step 34/44: loss=0.9239 
[epoch 1] step 36/44: loss=0.9203 
[epoch 1] step 38/44: loss=0.9154 
[epoch 1] step 40/44: loss=0.9103 
[epoch 1] step 42/44: loss=0.9047 
[epoch 1] step 44/44: loss=0.9010 
[epoch 1] val_loss=1.4973 qwk=('0.1059', '0.1876', '0.1619') averageQWK=0.1518 macroEMD=0.3663 tailR0=('0.0000', '0.1111', '0.2500') tailR0avg=0.1204
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    4    0
     0   18    0   37    0
     0   36    1   88    0
     0   35    6   75    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    6    1    0
    19    0   23   10    0
    34    0   36   51    0
    26    0   38   70    0
     1    0    3    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    1
     0   30   38    0    1
     0   43  102    2    4
     0   25   66    5    5
     0    0    1    0    1
[epoch 2] step 2/44: loss=0.7901 
[epoch 2] step 4/44: loss=0.7642 
[epoch 2] step 6/44: loss=0.7560 
[epoch 2] step 8/44: loss=0.7417 
[epoch 2] step 10/44: loss=0.7319 
[epoch 2] step 12/44: loss=0.7173 
[epoch 2] step 14/44: loss=0.7096 
[epoch 2] step 16/44: loss=0.7007 
[epoch 2] step 18/44: loss=0.6921 
[epoch 2] step 20/44: loss=0.6877 
[epoch 2] step 22/44: loss=0.6837 
[epoch 2] step 24/44: loss=0.6774 
[epoch 2] step 26/44: loss=0.6707 
[epoch 2] step 28/44: loss=0.6679 
[epoch 2] step 30/44: loss=0.6647 
[epoch 2] step 32/44: loss=0.6612 
[epoch 2] step 34/44: loss=0.6576 
[epoch 2] step 36/44: loss=0.6541 
[epoch 2] step 38/44: loss=0.6535 
[epoch 2] step 40/44: loss=0.6540 
[epoch 2] step 42/44: loss=0.6504 
[epoch 2] step 44/44: loss=0.6469 
[epoch 2] val_loss=1.1459 qwk=('0.3076', '0.4588', '0.4474') averageQWK=0.4046 macroEMD=0.3098 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   53    2    0
     0    0  109   16    0
     0    0   64   52    0
     0    0   11   12    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   47    5    0
     0    0   84   37    0
     0    0   24  110    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   45   24    0    0
     0   40  107    4    0
     0    4   79   18    0
     0    0    1    1    0
[epoch 3] step 2/44: loss=0.5994 
[epoch 3] step 4/44: loss=0.5698 
[epoch 3] step 6/44: loss=0.5823 
[epoch 3] step 8/44: loss=0.5810 
[epoch 3] step 10/44: loss=0.5837 
[epoch 3] step 12/44: loss=0.5821 
[epoch 3] step 14/44: loss=0.5793 
[epoch 3] step 16/44: loss=0.5732 
[epoch 3] step 18/44: loss=0.5766 
[epoch 3] step 20/44: loss=0.5741 
[epoch 3] step 22/44: loss=0.5749 
[epoch 3] step 24/44: loss=0.5737 
[epoch 3] step 26/44: loss=0.5703 
[epoch 3] step 28/44: loss=0.5721 
[epoch 3] step 30/44: loss=0.5685 
[epoch 3] step 32/44: loss=0.5661 
[epoch 3] step 34/44: loss=0.5637 
[epoch 3] step 36/44: loss=0.5612 
[epoch 3] step 38/44: loss=0.5636 
[epoch 3] step 40/44: loss=0.5615 
[epoch 3] step 42/44: loss=0.5581 
[epoch 3] step 44/44: loss=0.5549 
[epoch 3] val_loss=0.9502 qwk=('0.5030', '0.5278', '0.6235') averageQWK=0.5514 macroEMD=0.2563 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    2   49    4    0
     0    1   93   31    0
     0    0   22   94    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0    9   36    7    0
     0    5   63   53    0
     0    0   10  124    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   27   39    3    0
     0   11  107   33    0
     0    0   19   82    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=0.4965 
[epoch 4] step 4/44: loss=0.4455 
[epoch 4] step 6/44: loss=0.4675 
[epoch 4] step 8/44: loss=0.4747 
[epoch 4] step 10/44: loss=0.4718 
[epoch 4] step 12/44: loss=0.4749 
[epoch 4] step 14/44: loss=0.4768 
[epoch 4] step 16/44: loss=0.4765 
[epoch 4] step 18/44: loss=0.4841 
[epoch 4] step 20/44: loss=0.4886 
[epoch 4] step 22/44: loss=0.4876 
[epoch 4] step 24/44: loss=0.4893 
[epoch 4] step 26/44: loss=0.4943 
[epoch 4] step 28/44: loss=0.4928 
[epoch 4] step 30/44: loss=0.4910 
[epoch 4] step 32/44: loss=0.4931 
[epoch 4] step 34/44: loss=0.4933 
[epoch 4] step 36/44: loss=0.4969 
[epoch 4] step 38/44: loss=0.5024 
[epoch 4] step 40/44: loss=0.5026 
[epoch 4] step 42/44: loss=0.5028 
[epoch 4] step 44/44: loss=0.5040 
[epoch 4] val_loss=0.9551 qwk=('0.5769', '0.5477', '0.4523') averageQWK=0.5256 macroEMD=0.2468 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    0    0
     0   22   31    2    0
     0    7  102   16    0
     0    0   36   80    0
     0    0    6   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    0    0
     0   12   40    0    0
     0    4  107   10    0
     0    0   51   83    0
     0    0    3    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   12   57    0    0
     0    4  142    5    0
     0    0   60   41    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=0.5243 
[epoch 5] step 4/44: loss=0.5027 
[epoch 5] step 6/44: loss=0.4925 
[epoch 5] step 8/44: loss=0.5122 
[epoch 5] step 10/44: loss=0.5167 
[epoch 5] step 12/44: loss=0.5021 
[epoch 5] step 14/44: loss=0.4951 
[epoch 5] step 16/44: loss=0.4918 
[epoch 5] step 18/44: loss=0.4963 
[epoch 5] step 20/44: loss=0.4938 
[epoch 5] step 22/44: loss=0.4924 
[epoch 5] step 24/44: loss=0.4903 
[epoch 5] step 26/44: loss=0.4875 
[epoch 5] step 28/44: loss=0.4847 
[epoch 5] step 30/44: loss=0.4830 
[epoch 5] step 32/44: loss=0.4802 
[epoch 5] step 34/44: loss=0.4797 
[epoch 5] step 36/44: loss=0.4772 
[epoch 5] step 38/44: loss=0.4749 
[epoch 5] step 40/44: loss=0.4741 
[epoch 5] step 42/44: loss=0.4727 
[epoch 5] step 44/44: loss=0.4711 
[epoch 5] val_loss=0.8960 qwk=('0.6358', '0.5093', '0.6503') averageQWK=0.5985 macroEMD=0.2230 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   28   25    2    0
     0   11   96   18    0
     0    0   34   79    3
     0    0    4   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    0
     0    0   51    1    0
     0    0  105   16    0
     0    0   39   95    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   54   15    0    0
     0   55   75   21    0
     0    5   24   72    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=0.4296 
[epoch 6] step 4/44: loss=0.4084 
[epoch 6] step 6/44: loss=0.4129 
[epoch 6] step 8/44: loss=0.4152 
[epoch 6] step 10/44: loss=0.4167 
[epoch 6] step 12/44: loss=0.4135 
[epoch 6] step 14/44: loss=0.4216 
[epoch 6] step 16/44: loss=0.4199 
[epoch 6] step 18/44: loss=0.4227 
[epoch 6] step 20/44: loss=0.4261 
[epoch 6] step 22/44: loss=0.4233 
[epoch 6] step 24/44: loss=0.4216 
[epoch 6] step 26/44: loss=0.4239 
[epoch 6] step 28/44: loss=0.4214 
[epoch 6] step 30/44: loss=0.4220 
[epoch 6] step 32/44: loss=0.4250 
[epoch 6] step 34/44: loss=0.4309 
[epoch 6] step 36/44: loss=0.4318 
[epoch 6] step 38/44: loss=0.4297 
[epoch 6] step 40/44: loss=0.4278 
[epoch 6] step 42/44: loss=0.4326 
[epoch 6] step 44/44: loss=0.4477 
[epoch 6] val_loss=1.0603 qwk=('0.5768', '0.5974', '0.5105') averageQWK=0.5615 macroEMD=0.2270 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   43   12    0    0
     0   36   80    9    0
     0    0   64   52    0
     0    1    9   13    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   29   22    1    0
     0   15   96   10    0
     0    0   62   72    0
     0    1    1   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   63    6    0    0
     0   80   69    2    0
     0    9   62   30    0
     0    0    1    1    0
[epoch 7] step 2/44: loss=0.4901 
[epoch 7] step 4/44: loss=0.4410 
[epoch 7] step 6/44: loss=0.4196 
[epoch 7] step 8/44: loss=0.4375 
[epoch 7] step 10/44: loss=0.4568 
[epoch 7] step 12/44: loss=0.4557 
[epoch 7] step 14/44: loss=0.4426 
[epoch 7] step 16/44: loss=0.4386 
[epoch 7] step 18/44: loss=0.4375 
[epoch 7] step 20/44: loss=0.4345 
[epoch 7] step 22/44: loss=0.4283 
[epoch 7] step 24/44: loss=0.4268 
[epoch 7] step 26/44: loss=0.4221 
[epoch 7] step 28/44: loss=0.4190 
[epoch 7] step 30/44: loss=0.4174 
[epoch 7] step 32/44: loss=0.4169 
[epoch 7] step 34/44: loss=0.4143 
[epoch 7] step 36/44: loss=0.4115 
[epoch 7] step 38/44: loss=0.4086 
[epoch 7] step 40/44: loss=0.4073 
[epoch 7] step 42/44: loss=0.4049 
[epoch 7] step 44/44: loss=0.4029 
[epoch 7] val_loss=0.8954 qwk=('0.6617', '0.6735', '0.6424') averageQWK=0.6592 macroEMD=0.2042 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   30   21    4    0
     0   22   74   29    0
     0    0   17   94    5
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   34   15    3    0
     0   20   71   30    0
     0    3   18  113    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   45   22    2    0
     0   30   81   40    0
     0    4   13   84    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=0.3051 
[epoch 8] step 4/44: loss=0.3365 
[epoch 8] step 6/44: loss=0.3448 
[epoch 8] step 8/44: loss=0.3703 
[epoch 8] step 10/44: loss=0.3731 
[epoch 8] step 12/44: loss=0.3855 
[epoch 8] step 14/44: loss=0.3901 
[epoch 8] step 16/44: loss=0.3851 
[epoch 8] step 18/44: loss=0.3862 
[epoch 8] step 20/44: loss=0.3926 
[epoch 8] step 22/44: loss=0.3933 
[epoch 8] step 24/44: loss=0.3890 
[epoch 8] step 26/44: loss=0.3859 
[epoch 8] step 28/44: loss=0.3825 
[epoch 8] step 30/44: loss=0.3797 
[epoch 8] step 32/44: loss=0.3814 
[epoch 8] step 34/44: loss=0.3789 
[epoch 8] step 36/44: loss=0.3747 
[epoch 8] step 38/44: loss=0.3721 
[epoch 8] step 40/44: loss=0.3722 
[epoch 8] step 42/44: loss=0.3729 
[epoch 8] step 44/44: loss=0.3738 
[epoch 8] val_loss=0.9246 qwk=('0.6239', '0.6367', '0.6112') averageQWK=0.6240 macroEMD=0.2052 tailR0=('0.2174', '0.0000', '0.0000') tailR0avg=0.0725
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   20   30    5    0
     0    6   81   35    3
     0    0   15   90   11
     0    0    2   11   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   20   26    6    0
     0   10   60   51    0
     0    0    7  127    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   22   44    3    0
     0    8   99   44    0
     0    0   15   86    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=0.3196 
[epoch 9] step 4/44: loss=0.3341 
[epoch 9] step 6/44: loss=0.3269 
[epoch 9] step 8/44: loss=0.3323 
[epoch 9] step 10/44: loss=0.3442 
[epoch 9] step 12/44: loss=0.3400 
[epoch 9] step 14/44: loss=0.3374 
[epoch 9] step 16/44: loss=0.3373 
[epoch 9] step 18/44: loss=0.3413 
[epoch 9] step 20/44: loss=0.3457 
[epoch 9] step 22/44: loss=0.3435 
[epoch 9] step 24/44: loss=0.3432 
[epoch 9] step 26/44: loss=0.3451 
[epoch 9] step 28/44: loss=0.3406 
[epoch 9] step 30/44: loss=0.3408 
[epoch 9] step 32/44: loss=0.3410 
[epoch 9] step 34/44: loss=0.3394 
[epoch 9] step 36/44: loss=0.3366 
[epoch 9] step 38/44: loss=0.3384 
[epoch 9] step 40/44: loss=0.3368 
[epoch 9] step 42/44: loss=0.3365 
[epoch 9] step 44/44: loss=0.3350 
[epoch 9] val_loss=0.8859 qwk=('0.6614', '0.6477', '0.6413') averageQWK=0.6501 macroEMD=0.1928 tailR0=('0.1957', '0.0000', '0.0000') tailR0avg=0.0652
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   32   23    0    0
     0   13   95   14    3
     0    2   31   76    7
     0    1    4    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   27   22    3    0
     0   12   86   23    0
     0    1   26  107    0
     0    1    0   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   43   26    0    0
     0   28  102   21    0
     0    3   33   65    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=0.2665 
[epoch 10] step 4/44: loss=0.2800 
[epoch 10] step 6/44: loss=0.2771 
[epoch 10] step 8/44: loss=0.2662 
[epoch 10] step 10/44: loss=0.2734 
[epoch 10] step 12/44: loss=0.2750 
[epoch 10] step 14/44: loss=0.2812 
[epoch 10] step 16/44: loss=0.2835 
[epoch 10] step 18/44: loss=0.2824 
[epoch 10] step 20/44: loss=0.2800 
[epoch 10] step 22/44: loss=0.2814 
[epoch 10] step 24/44: loss=0.2870 
[epoch 10] step 26/44: loss=0.2874 
[epoch 10] step 28/44: loss=0.2854 
[epoch 10] step 30/44: loss=0.2852 
[epoch 10] step 32/44: loss=0.2845 
[epoch 10] step 34/44: loss=0.2860 
[epoch 10] step 36/44: loss=0.2863 
[epoch 10] step 38/44: loss=0.2867 
[epoch 10] step 40/44: loss=0.2861 
[epoch 10] step 42/44: loss=0.2846 
[epoch 10] step 44/44: loss=0.2848 
[epoch 10] val_loss=0.9523 qwk=('0.6846', '0.6939', '0.6360') averageQWK=0.6715 macroEMD=0.1847 tailR0=('0.3068', '0.0556', '0.0000') tailR0avg=0.1208
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     1   33   19    1    1
     0   23   87   14    1
     0    2   28   77    9
     0    1    2   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    0    0
     0   29   21    2    0
     0   20   83   18    0
     0    0   28  102    4
     0    1    0   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   41   28    0    0
     0   28  109   14    0
     0    3   36   62    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.2943 
[epoch 11] step 4/44: loss=0.2766 
[epoch 11] step 6/44: loss=0.2620 
[epoch 11] step 8/44: loss=0.2575 
[epoch 11] step 10/44: loss=0.2543 
[epoch 11] step 12/44: loss=0.2467 
[epoch 11] step 14/44: loss=0.2469 
[epoch 11] step 16/44: loss=0.2539 
[epoch 11] step 18/44: loss=0.2544 
[epoch 11] step 20/44: loss=0.2578 
[epoch 11] step 22/44: loss=0.2542 
[epoch 11] step 24/44: loss=0.2516 
[epoch 11] step 26/44: loss=0.2525 
[epoch 11] step 28/44: loss=0.2539 
[epoch 11] step 30/44: loss=0.2543 
[epoch 11] step 32/44: loss=0.2543 
[epoch 11] step 34/44: loss=0.2525 
[epoch 11] step 36/44: loss=0.2535 
[epoch 11] step 38/44: loss=0.2537 
[epoch 11] step 40/44: loss=0.2547 
[epoch 11] step 42/44: loss=0.2582 
[epoch 11] step 44/44: loss=0.2638 
[epoch 11] val_loss=0.9710 qwk=('0.6148', '0.6331', '0.6168') averageQWK=0.6215 macroEMD=0.1993 tailR0=('0.1981', '0.0556', '0.0000') tailR0avg=0.0845
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    5    1    0
     0   21   28    6    0
     0    5   82   37    1
     0    0   16   98    2
     0    0    2   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     0   15   33    4    0
     0    6   77   38    0
     0    0   10  124    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   43    1    0
     0   14  106   31    0
     0    0   25   76    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=0.2767 
[epoch 12] step 4/44: loss=0.2642 
[epoch 12] step 6/44: loss=0.2571 
[epoch 12] step 8/44: loss=0.2472 
[epoch 12] step 10/44: loss=0.2449 
[epoch 12] step 12/44: loss=0.2390 
[epoch 12] step 14/44: loss=0.2429 
[epoch 12] step 16/44: loss=0.2417 
[epoch 12] step 18/44: loss=0.2421 
[epoch 12] step 20/44: loss=0.2403 
[epoch 12] step 22/44: loss=0.2396 
[epoch 12] step 24/44: loss=0.2425 
[epoch 12] step 26/44: loss=0.2413 
[epoch 12] step 28/44: loss=0.2416 
[epoch 12] step 30/44: loss=0.2409 
[epoch 12] step 32/44: loss=0.2399 
[epoch 12] step 34/44: loss=0.2397 
[epoch 12] step 36/44: loss=0.2390 
[epoch 12] step 38/44: loss=0.2389 
[epoch 12] step 40/44: loss=0.2369 
[epoch 12] step 42/44: loss=0.2353 
[epoch 12] step 44/44: loss=0.2353 
[epoch 12] val_loss=0.9985 qwk=('0.6620', '0.6706', '0.5926') averageQWK=0.6417 macroEMD=0.1856 tailR0=('0.1643', '0.0000', '0.0000') tailR0avg=0.0548
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     1   28   24    2    0
     0   13   89   22    1
     0    1   24   84    7
     0    0    5   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   27   21    4    0
     0   16   85   20    0
     0    1   28   99    6
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   28   40    1    0
     0   16  113   22    0
     0    0   38   63    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.1907 
[epoch 13] step 4/44: loss=0.1993 
[epoch 13] step 6/44: loss=0.2143 
[epoch 13] step 8/44: loss=0.2168 
[epoch 13] step 10/44: loss=0.2081 
[epoch 13] step 12/44: loss=0.2004 
[epoch 13] step 14/44: loss=0.2015 
[epoch 13] step 16/44: loss=0.2001 
[epoch 13] step 18/44: loss=0.2040 
[epoch 13] step 20/44: loss=0.2045 
[epoch 13] step 22/44: loss=0.2021 
[epoch 13] step 24/44: loss=0.2020 
[epoch 13] step 26/44: loss=0.2001 
[epoch 13] step 28/44: loss=0.1993 
[epoch 13] step 30/44: loss=0.2041 
[epoch 13] step 32/44: loss=0.2066 
[epoch 13] step 34/44: loss=0.2064 
[epoch 13] step 36/44: loss=0.2047 
[epoch 13] step 38/44: loss=0.2036 
[epoch 13] step 40/44: loss=0.2030 
[epoch 13] step 42/44: loss=0.2007 
[epoch 13] step 44/44: loss=0.2022 
[epoch 13] val_loss=1.0476 qwk=('0.6633', '0.6993', '0.5998') averageQWK=0.6541 macroEMD=0.1835 tailR0=('0.2415', '0.1111', '0.0000') tailR0avg=0.1176
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
     2   25   28    0    0
     1   13   90   20    1
     0    0   29   80    7
     0    0    5   12    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     2   29   18    3    0
     0   16   85   20    0
     0    0   29  100    5
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   25   43    1    0
     0   10  113   28    0
     0    0   35   66    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.1640 
[epoch 14] step 4/44: loss=0.1637 
[epoch 14] step 6/44: loss=0.1751 
[epoch 14] step 8/44: loss=0.1743 
[epoch 14] step 10/44: loss=0.1788 
[epoch 14] step 12/44: loss=0.1740 
[epoch 14] step 14/44: loss=0.1749 
[epoch 14] step 16/44: loss=0.1710 
[epoch 14] step 18/44: loss=0.1711 
[epoch 14] step 20/44: loss=0.1711 
[epoch 14] step 22/44: loss=0.1692 
[epoch 14] step 24/44: loss=0.1677 
[epoch 14] step 26/44: loss=0.1670 
[epoch 14] step 28/44: loss=0.1660 
[epoch 14] step 30/44: loss=0.1673 
[epoch 14] step 32/44: loss=0.1689 
[epoch 14] step 34/44: loss=0.1676 
[epoch 14] step 36/44: loss=0.1680 
[epoch 14] step 38/44: loss=0.1674 
[epoch 14] step 40/44: loss=0.1677 
[epoch 14] step 42/44: loss=0.1704 
[epoch 14] step 44/44: loss=0.1711 
[epoch 14] val_loss=1.0800 qwk=('0.6455', '0.6661', '0.5646') averageQWK=0.6254 macroEMD=0.1864 tailR0=('0.1981', '0.1528', '0.0000') tailR0avg=0.1169
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
     1   24   29    1    0
     0   10  101   13    1
     0    0   36   74    6
     0    0    5   14    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
     0   19   30    3    0
     0   10   91   20    0
     0    0   24  107    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   24   43    2    0
     0   13  115   23    0
     0    0   39   62    0
     0    0    0    2    0
[epoch 15] step 2/44: loss=0.1760 
[epoch 15] step 4/44: loss=0.1721 
[epoch 15] step 6/44: loss=0.1591 
[epoch 15] step 8/44: loss=0.1554 
[epoch 15] step 10/44: loss=0.1533 
[epoch 15] step 12/44: loss=0.1522 
[epoch 15] step 14/44: loss=0.1526 
[epoch 15] step 16/44: loss=0.1531 
[epoch 15] step 18/44: loss=0.1543 
[epoch 15] step 20/44: loss=0.1500 
[epoch 15] step 22/44: loss=0.1503 
[epoch 15] step 24/44: loss=0.1491 
[epoch 15] step 26/44: loss=0.1506 
[epoch 15] step 28/44: loss=0.1504 
[epoch 15] step 30/44: loss=0.1488 
[epoch 15] step 32/44: loss=0.1486 
[epoch 15] step 34/44: loss=0.1481 
[epoch 15] step 36/44: loss=0.1471 
[epoch 15] step 38/44: loss=0.1481 
[epoch 15] step 40/44: loss=0.1482 
[epoch 15] step 42/44: loss=0.1465 
[epoch 15] step 44/44: loss=0.1472 
[epoch 15] val_loss=1.1178 qwk=('0.6582', '0.6852', '0.6195') averageQWK=0.6543 macroEMD=0.1815 tailR0=('0.2633', '0.1111', '0.0000') tailR0avg=0.1248
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
     2   21   31    1    0
     0   13   85   26    1
     0    0   28   81    7
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     2   22   24    4    0
     0   10   83   28    0
     0    0   17  114    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   36   32    1    0
     0   25  104   22    0
     0    2   33   66    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=0.1449 
[epoch 16] step 4/44: loss=0.1347 
[epoch 16] step 6/44: loss=0.1328 
[epoch 16] step 8/44: loss=0.1316 
[epoch 16] step 10/44: loss=0.1358 
[epoch 16] step 12/44: loss=0.1343 
[epoch 16] step 14/44: loss=0.1338 
[epoch 16] step 16/44: loss=0.1301 
[epoch 16] step 18/44: loss=0.1282 
[epoch 16] step 20/44: loss=0.1245 
[epoch 16] step 22/44: loss=0.1250 
[epoch 16] step 24/44: loss=0.1273 
[epoch 16] step 26/44: loss=0.1245 
[epoch 16] step 28/44: loss=0.1225 
[epoch 16] step 30/44: loss=0.1232 
[epoch 16] step 32/44: loss=0.1229 
[epoch 16] step 34/44: loss=0.1254 
[epoch 16] step 36/44: loss=0.1274 
[epoch 16] step 38/44: loss=0.1262 
[epoch 16] step 40/44: loss=0.1262 
[epoch 16] step 42/44: loss=0.1252 
[epoch 16] step 44/44: loss=0.1247 
[epoch 16] val_loss=1.2593 qwk=('0.6058', '0.6309', '0.5962') averageQWK=0.6110 macroEMD=0.1927 tailR0=('0.1860', '0.0556', '0.0000') tailR0avg=0.0805
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   14   37    3    1
     0    4   90   30    1
     0    0   22   86    8
     0    0    3   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     0   15   33    4    0
     0    6   79   36    0
     0    0   12  120    2
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   26   42    1    0
     0   16  105   30    0
     0    0   31   70    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=0.1035 
[epoch 17] step 4/44: loss=0.1068 
[epoch 17] step 6/44: loss=0.1041 
[epoch 17] step 8/44: loss=0.1080 
[epoch 17] step 10/44: loss=0.1048 
[epoch 17] step 12/44: loss=0.1019 
[epoch 17] step 14/44: loss=0.1057 
[epoch 17] step 16/44: loss=0.1050 
[epoch 17] step 18/44: loss=0.1050 
[epoch 17] step 20/44: loss=0.1056 
[epoch 17] step 22/44: loss=0.1044 
[epoch 17] step 24/44: loss=0.1037 
[epoch 17] step 26/44: loss=0.1031 
[epoch 17] step 28/44: loss=0.1035 
[epoch 17] step 30/44: loss=0.1034 
[epoch 17] step 32/44: loss=0.1030 
[epoch 17] step 34/44: loss=0.1028 
[epoch 17] step 36/44: loss=0.1024 
[epoch 17] step 38/44: loss=0.1028 
[epoch 17] step 40/44: loss=0.1019 
[epoch 17] step 42/44: loss=0.1015 
[epoch 17] step 44/44: loss=0.1013 
[epoch 17] val_loss=1.2257 qwk=('0.6811', '0.6778', '0.6128') averageQWK=0.6572 macroEMD=0.1766 tailR0=('0.2198', '0.1944', '0.1000') tailR0avg=0.1714
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
     2   33   19    1    0
     0   19   80   25    1
     0    0   23   89    4
     0    1    3   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
     2   26   20    4    0
     0   15   85   21    0
     0    0   28  103    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   29   39    1    0
     0   23  107   21    0
     0    0   36   65    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=0.0910 
[epoch 18] step 4/44: loss=0.0840 
[epoch 18] step 6/44: loss=0.0940 
[epoch 18] step 8/44: loss=0.0950 
[epoch 18] step 10/44: loss=0.0937 
[epoch 18] step 12/44: loss=0.0933 
[epoch 18] step 14/44: loss=0.0937 
[epoch 18] step 16/44: loss=0.0962 
[epoch 18] step 18/44: loss=0.0912 
[epoch 18] step 20/44: loss=0.0897 
[epoch 18] step 22/44: loss=0.0906 
[epoch 18] step 24/44: loss=0.0896 
[epoch 18] step 26/44: loss=0.0911 
[epoch 18] step 28/44: loss=0.0901 
[epoch 18] step 30/44: loss=0.0895 
[epoch 18] step 32/44: loss=0.0889 
[epoch 18] step 34/44: loss=0.0881 
[epoch 18] step 36/44: loss=0.0881 
[epoch 18] step 38/44: loss=0.0873 
[epoch 18] step 40/44: loss=0.0868 
[epoch 18] step 42/44: loss=0.0865 
[epoch 18] step 44/44: loss=0.0877 
[epoch 18] val_loss=1.2829 qwk=('0.6346', '0.6577', '0.5721') averageQWK=0.6215 macroEMD=0.1869 tailR0=('0.1208', '0.0556', '0.0000') tailR0avg=0.0588
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   27   24    4    0
     0   10   86   28    1
     0    0   23   91    2
     0    1    2   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   19   32    1    0
     0   11   84   26    0
     0    0   21  111    2
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   24   42    3    0
     0   10  115   26    0
     0    0   35   66    0
     0    0    0    2    0
[epoch 19] step 2/44: loss=0.0632 
[epoch 19] step 4/44: loss=0.0674 
[epoch 19] step 6/44: loss=0.0666 
[epoch 19] step 8/44: loss=0.0661 
[epoch 19] step 10/44: loss=0.0684 
[epoch 19] step 12/44: loss=0.0713 
[epoch 19] step 14/44: loss=0.0735 
[epoch 19] step 16/44: loss=0.0709 
[epoch 19] step 18/44: loss=0.0749 
[epoch 19] step 20/44: loss=0.0748 
[epoch 19] step 22/44: loss=0.0766 
[epoch 19] step 24/44: loss=0.0773 
[epoch 19] step 26/44: loss=0.0781 
[epoch 19] step 28/44: loss=0.0783 
[epoch 19] step 30/44: loss=0.0778 
[epoch 19] step 32/44: loss=0.0777 
[epoch 19] step 34/44: loss=0.0768 
[epoch 19] step 36/44: loss=0.0769 
[epoch 19] step 38/44: loss=0.0766 
[epoch 19] step 40/44: loss=0.0752 
[epoch 19] step 42/44: loss=0.0753 
[epoch 19] step 44/44: loss=0.0742 
[epoch 19] val_loss=1.3882 qwk=('0.6228', '0.6440', '0.5823') averageQWK=0.6164 macroEMD=0.1895 tailR0=('0.1860', '0.0417', '0.0000') tailR0avg=0.0759
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   18   35    2    0
     0    6   92   26    1
     0    0   26   83    7
     0    0    5   12    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   18   29    5    0
     0    9   71   41    0
     0    0   10  121    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   29   38    2    0
     0   21  102   28    0
     0    1   32   68    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=0.0488 
[epoch 20] step 4/44: loss=0.0526 
[epoch 20] step 6/44: loss=0.0563 
[epoch 20] step 8/44: loss=0.0537 
[epoch 20] step 10/44: loss=0.0540 
[epoch 20] step 12/44: loss=0.0538 
[epoch 20] step 14/44: loss=0.0537 
[epoch 20] step 16/44: loss=0.0553 
[epoch 20] step 18/44: loss=0.0573 
[epoch 20] step 20/44: loss=0.0579 
[epoch 20] step 22/44: loss=0.0561 
[epoch 20] step 24/44: loss=0.0565 
[epoch 20] step 26/44: loss=0.0574 
[epoch 20] step 28/44: loss=0.0581 
[epoch 20] step 30/44: loss=0.0582 
[epoch 20] step 32/44: loss=0.0576 
[epoch 20] step 34/44: loss=0.0572 
[epoch 20] step 36/44: loss=0.0572 
[epoch 20] step 38/44: loss=0.0570 
[epoch 20] step 40/44: loss=0.0579 
[epoch 20] step 42/44: loss=0.0578 
[epoch 20] step 44/44: loss=0.0578 
[epoch 20] val_loss=1.3971 qwk=('0.6767', '0.6702', '0.5818') averageQWK=0.6429 macroEMD=0.1784 tailR0=('0.1860', '0.1111', '0.0000') tailR0avg=0.0990
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     1   33   21    0    0
     0   20   82   22    1
     0    0   27   81    8
     0    1    4   12    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
     0   24   26    2    0
     0   13   88   20    0
     0    0   26  105    3
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     0   30   36    3    0
     0   23   96   32    0
     0    0   28   73    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=0.0473 
[epoch 21] step 4/44: loss=0.0476 
[epoch 21] step 6/44: loss=0.0510 
[epoch 21] step 8/44: loss=0.0519 
[epoch 21] step 10/44: loss=0.0523 
[epoch 21] step 12/44: loss=0.0513 
[epoch 21] step 14/44: loss=0.0501 
[epoch 21] step 16/44: loss=0.0490 
[epoch 21] step 18/44: loss=0.0486 
[epoch 21] step 20/44: loss=0.0472 
[epoch 21] step 22/44: loss=0.0452 
[epoch 21] step 24/44: loss=0.0464 
[epoch 21] step 26/44: loss=0.0459 
[epoch 21] step 28/44: loss=0.0452 
[epoch 21] step 30/44: loss=0.0454 
[epoch 21] step 32/44: loss=0.0455 
[epoch 21] step 34/44: loss=0.0454 
[epoch 21] step 36/44: loss=0.0459 
[epoch 21] step 38/44: loss=0.0462 
[epoch 21] step 40/44: loss=0.0457 
[epoch 21] step 42/44: loss=0.0453 
[epoch 21] step 44/44: loss=0.0451 
[epoch 21] val_loss=1.4377 qwk=('0.6419', '0.6177', '0.5817') averageQWK=0.6138 macroEMD=0.1866 tailR0=('0.1208', '0.0000', '0.0000') tailR0avg=0.0403
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   30   21    4    0
     0   15   81   28    1
     0    0   25   89    2
     0    1    1   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   16   34    2    0
     0   12   89   20    0
     0    0   30  102    2
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   42    2    0
     0   17  112   22    0
     0    0   35   66    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=0.0488 
[epoch 22] step 4/44: loss=0.0473 
[epoch 22] step 6/44: loss=0.0434 
[epoch 22] step 8/44: loss=0.0419 
[epoch 22] step 10/44: loss=0.0421 
[epoch 22] step 12/44: loss=0.0405 
[epoch 22] step 14/44: loss=0.0392 
[epoch 22] step 16/44: loss=0.0414 
[epoch 22] step 18/44: loss=0.0400 
[epoch 22] step 20/44: loss=0.0401 
[epoch 22] step 22/44: loss=0.0405 
[epoch 22] step 24/44: loss=0.0414 
[epoch 22] step 26/44: loss=0.0421 
[epoch 22] step 28/44: loss=0.0421 
[epoch 22] step 30/44: loss=0.0416 
[epoch 22] step 32/44: loss=0.0418 
[epoch 22] step 34/44: loss=0.0412 
[epoch 22] step 36/44: loss=0.0409 
[epoch 22] step 38/44: loss=0.0406 
[epoch 22] step 40/44: loss=0.0408 
[epoch 22] step 42/44: loss=0.0409 
[epoch 22] step 44/44: loss=0.0415 
[epoch 22] val_loss=1.5564 qwk=('0.6285', '0.6558', '0.5833') averageQWK=0.6225 macroEMD=0.1833 tailR0=('0.2633', '0.1111', '0.1000') tailR0avg=0.1581
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    4    1    0
     1   18   34    2    0
     0   11   87   26    1
     0    0   22   86    8
     0    1    3   12    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     0   23   26    3    0
     0   17   79   25    0
     0    0   25  105    4
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    1    0
     0   27   40    2    0
     0   22  101   28    0
     0    1   30   70    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=0.0273 
[epoch 23] step 4/44: loss=0.0269 
[epoch 23] step 6/44: loss=0.0326 
[epoch 23] step 8/44: loss=0.0324 
[epoch 23] step 10/44: loss=0.0344 
[epoch 23] step 12/44: loss=0.0328 
[epoch 23] step 14/44: loss=0.0336 
[epoch 23] step 16/44: loss=0.0334 
[epoch 23] step 18/44: loss=0.0333 
[epoch 23] step 20/44: loss=0.0336 
[epoch 23] step 22/44: loss=0.0339 
[epoch 23] step 24/44: loss=0.0334 
[epoch 23] step 26/44: loss=0.0333 
[epoch 23] step 28/44: loss=0.0339 
[epoch 23] step 30/44: loss=0.0335 
[epoch 23] step 32/44: loss=0.0337 
[epoch 23] step 34/44: loss=0.0336 
[epoch 23] step 36/44: loss=0.0329 
[epoch 23] step 38/44: loss=0.0329 
[epoch 23] step 40/44: loss=0.0327 
[epoch 23] step 42/44: loss=0.0325 
[epoch 23] step 44/44: loss=0.0323 
[epoch 23] val_loss=1.5254 qwk=('0.6682', '0.6926', '0.6032') averageQWK=0.6547 macroEMD=0.1761 tailR0=('0.1425', '0.1111', '0.0000') tailR0avg=0.0845
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     0   33   22    0    0
     0   19   84   21    1
     0    0   28   85    3
     0    1    4   14    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     0   25   24    3    0
     0   20   75   26    0
     0    0   18  114    2
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   34   33    2    0
     0   30   99   22    0
     0    1   34   66    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=0.0253 
[epoch 24] step 4/44: loss=0.0274 
[epoch 24] step 6/44: loss=0.0239 
[epoch 24] step 8/44: loss=0.0234 
[epoch 24] step 10/44: loss=0.0243 
[epoch 24] step 12/44: loss=0.0263 
[epoch 24] step 14/44: loss=0.0260 
[epoch 24] step 16/44: loss=0.0253 
[epoch 24] step 18/44: loss=0.0251 
[epoch 24] step 20/44: loss=0.0254 
[epoch 24] step 22/44: loss=0.0255 
[epoch 24] step 24/44: loss=0.0259 
[epoch 24] step 26/44: loss=0.0255 
[epoch 24] step 28/44: loss=0.0251 
[epoch 24] step 30/44: loss=0.0254 
[epoch 24] step 32/44: loss=0.0257 
[epoch 24] step 34/44: loss=0.0257 
[epoch 24] step 36/44: loss=0.0255 
[epoch 24] step 38/44: loss=0.0254 
[epoch 24] step 40/44: loss=0.0260 
[epoch 24] step 42/44: loss=0.0263 
[epoch 24] step 44/44: loss=0.0275 
[epoch 24] val_loss=1.5540 qwk=('0.6554', '0.6895', '0.6092') averageQWK=0.6514 macroEMD=0.1774 tailR0=('0.1643', '0.0000', '0.0000') tailR0avg=0.0548
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   32   21    2    0
     0   18   79   27    1
     0    0   27   86    3
     0    1    2   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   25   24    3    0
     0   19   75   27    0
     0    0   15  116    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   33    1    0
     0   29  102   20    0
     0    2   34   65    0
     0    0    0    2    0
[epoch 25] step 2/44: loss=0.0267 
[epoch 25] step 4/44: loss=0.0260 
[epoch 25] step 6/44: loss=0.0278 
[epoch 25] step 8/44: loss=0.0281 
[epoch 25] step 10/44: loss=0.0260 
[epoch 25] step 12/44: loss=0.0251 
[epoch 25] step 14/44: loss=0.0254 
[epoch 25] step 16/44: loss=0.0257 
[epoch 25] step 18/44: loss=0.0254 
[epoch 25] step 20/44: loss=0.0249 
[epoch 25] step 22/44: loss=0.0243 
[epoch 25] step 24/44: loss=0.0244 
[epoch 25] step 26/44: loss=0.0241 
[epoch 25] step 28/44: loss=0.0239 
[epoch 25] step 30/44: loss=0.0240 
[epoch 25] step 32/44: loss=0.0239 
[epoch 25] step 34/44: loss=0.0239 
[epoch 25] step 36/44: loss=0.0233 
[epoch 25] step 38/44: loss=0.0232 
[epoch 25] step 40/44: loss=0.0234 
[epoch 25] step 42/44: loss=0.0231 
[epoch 25] step 44/44: loss=0.0249 
[epoch 25] val_loss=1.6736 qwk=('0.6272', '0.6497', '0.5645') averageQWK=0.6138 macroEMD=0.1882 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   19   34    2    0
     0    5   94   25    1
     0    0   23   92    1
     0    0    4   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   19   29    4    0
     0   16   76   29    0
     0    0   16  115    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   25   42    2    0
     0   13  114   24    0
     0    1   36   64    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=0.0169 
[epoch 26] step 4/44: loss=0.0177 
[epoch 26] step 6/44: loss=0.0202 
[epoch 26] step 8/44: loss=0.0201 
[epoch 26] step 10/44: loss=0.0204 
[epoch 26] step 12/44: loss=0.0209 
[epoch 26] step 14/44: loss=0.0209 
[epoch 26] step 16/44: loss=0.0213 
[epoch 26] step 18/44: loss=0.0214 
[epoch 26] step 20/44: loss=0.0215 
[epoch 26] step 22/44: loss=0.0207 
[epoch 26] step 24/44: loss=0.0205 
[epoch 26] step 26/44: loss=0.0202 
[epoch 26] step 28/44: loss=0.0196 
[epoch 26] step 30/44: loss=0.0193 
[epoch 26] step 32/44: loss=0.0190 
[epoch 26] step 34/44: loss=0.0188 
[epoch 26] step 36/44: loss=0.0187 
[epoch 26] step 38/44: loss=0.0191 
[epoch 26] step 40/44: loss=0.0188 
[epoch 26] step 42/44: loss=0.0185 
[epoch 26] step 44/44: loss=0.0181 
[epoch 26] val_loss=1.7195 qwk=('0.6534', '0.6483', '0.5787') averageQWK=0.6268 macroEMD=0.1857 tailR0=('0.1425', '0.0417', '0.0000') tailR0avg=0.0614
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   26   28    1    0
     0   10   91   23    1
     0    0   24   88    4
     0    1    3   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   19   30    3    0
     0    9   85   27    0
     0    0   19  112    3
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   29   38    2    0
     0   24   95   32    0
     0    1   29   71    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=0.0157 
[epoch 27] step 4/44: loss=0.0162 
[epoch 27] step 6/44: loss=0.0152 
[epoch 27] step 8/44: loss=0.0153 
[epoch 27] step 10/44: loss=0.0153 
[epoch 27] step 12/44: loss=0.0142 
[epoch 27] step 14/44: loss=0.0154 
[epoch 27] step 16/44: loss=0.0150 
[epoch 27] step 18/44: loss=0.0147 
[epoch 27] step 20/44: loss=0.0151 
[epoch 27] step 22/44: loss=0.0150 
[epoch 27] step 24/44: loss=0.0145 
[epoch 27] step 26/44: loss=0.0143 
[epoch 27] step 28/44: loss=0.0146 
[epoch 27] step 30/44: loss=0.0145 
[epoch 27] step 32/44: loss=0.0149 
[epoch 27] step 34/44: loss=0.0146 
[epoch 27] step 36/44: loss=0.0151 
[epoch 27] step 38/44: loss=0.0150 
[epoch 27] step 40/44: loss=0.0153 
[epoch 27] step 42/44: loss=0.0151 
[epoch 27] step 44/44: loss=0.0150 
[epoch 27] val_loss=1.7480 qwk=('0.6470', '0.6454', '0.5836') averageQWK=0.6253 macroEMD=0.1834 tailR0=('0.1304', '0.0972', '0.0000') tailR0avg=0.0759
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   22   33    0    0
     0    9   88   27    1
     0    0   26   84    6
     0    0    4   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   19   30    3    0
     0   14   76   31    0
     0    0   17  113    4
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   30   37    2    0
     0   27  101   23    0
     0    1   32   68    0
     0    0    0    2    0
[epoch 28] step 2/44: loss=0.0147 
[epoch 28] step 4/44: loss=0.0123 
[epoch 28] step 6/44: loss=0.0155 
[epoch 28] step 8/44: loss=0.0146 
[epoch 28] step 10/44: loss=0.0153 
[epoch 28] step 12/44: loss=0.0150 
[epoch 28] step 14/44: loss=0.0148 
[epoch 28] step 16/44: loss=0.0139 
[epoch 28] step 18/44: loss=0.0135 
[epoch 28] step 20/44: loss=0.0132 
[epoch 28] step 22/44: loss=0.0128 
[epoch 28] step 24/44: loss=0.0136 
[epoch 28] step 26/44: loss=0.0132 
[epoch 28] step 28/44: loss=0.0132 
[epoch 28] step 30/44: loss=0.0131 
[epoch 28] step 32/44: loss=0.0129 
[epoch 28] step 34/44: loss=0.0127 
[epoch 28] step 36/44: loss=0.0124 
[epoch 28] step 38/44: loss=0.0125 
[epoch 28] step 40/44: loss=0.0123 
[epoch 28] step 42/44: loss=0.0124 
[epoch 28] step 44/44: loss=0.0122 
[epoch 28] val_loss=1.7470 qwk=('0.6450', '0.6432', '0.5835') averageQWK=0.6239 macroEMD=0.1826 tailR0=('0.1425', '0.0417', '0.1000') tailR0avg=0.0947
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    1    0
     0   28   26    1    0
     0   12   81   31    1
     0    0   25   90    1
     0    1    1   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   19   31    2    0
     0   14   84   23    0
     0    0   24  106    4
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    1    0
     0   27   40    2    0
     0   18  104   29    0
     0    1   31   69    0
     0    0    0    2    0
[epoch 29] step 2/44: loss=0.0122 
[epoch 29] step 4/44: loss=0.0098 
[epoch 29] step 6/44: loss=0.0112 
[epoch 29] step 8/44: loss=0.0115 
[epoch 29] step 10/44: loss=0.0125 
[epoch 29] step 12/44: loss=0.0121 
[epoch 29] step 14/44: loss=0.0118 
[epoch 29] step 16/44: loss=0.0114 
[epoch 29] step 18/44: loss=0.0115 
[epoch 29] step 20/44: loss=0.0115 
[epoch 29] step 22/44: loss=0.0115 
[epoch 29] step 24/44: loss=0.0113 
[epoch 29] step 26/44: loss=0.0113 
[epoch 29] step 28/44: loss=0.0114 
[epoch 29] step 30/44: loss=0.0113 
[epoch 29] step 32/44: loss=0.0113 
[epoch 29] step 34/44: loss=0.0112 
[epoch 29] step 36/44: loss=0.0111 
[epoch 29] step 38/44: loss=0.0111 
[epoch 29] step 40/44: loss=0.0110 
[epoch 29] step 42/44: loss=0.0110 
[epoch 29] step 44/44: loss=0.0111 
[epoch 29] val_loss=1.7813 qwk=('0.6468', '0.6637', '0.5971') averageQWK=0.6359 macroEMD=0.1808 tailR0=('0.1425', '0.0556', '0.0000') tailR0avg=0.0660
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   25   30    0    0
     0   14   87   23    1
     0    0   26   85    5
     0    1    3   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   23   26    3    0
     0   17   77   27    0
     0    0   16  116    2
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   32    2    0
     0   28  102   21    0
     0    1   38   62    0
     0    0    0    2    0
[epoch 30] step 2/44: loss=0.0169 
[epoch 30] step 4/44: loss=0.0127 
[epoch 30] step 6/44: loss=0.0111 
[epoch 30] step 8/44: loss=0.0108 
[epoch 30] step 10/44: loss=0.0101 
[epoch 30] step 12/44: loss=0.0097 
[epoch 30] step 14/44: loss=0.0094 
[epoch 30] step 16/44: loss=0.0091 
[epoch 30] step 18/44: loss=0.0088 
[epoch 30] step 20/44: loss=0.0085 
[epoch 30] step 22/44: loss=0.0085 
[epoch 30] step 24/44: loss=0.0088 
[epoch 30] step 26/44: loss=0.0091 
[epoch 30] step 28/44: loss=0.0090 
[epoch 30] step 30/44: loss=0.0091 
[epoch 30] step 32/44: loss=0.0089 
[epoch 30] step 34/44: loss=0.0089 
[epoch 30] step 36/44: loss=0.0088 
[epoch 30] step 38/44: loss=0.0087 
[epoch 30] step 40/44: loss=0.0087 
[epoch 30] step 42/44: loss=0.0088 
[epoch 30] step 44/44: loss=0.0090 
[epoch 30] val_loss=1.8712 qwk=('0.6231', '0.6467', '0.5879') averageQWK=0.6193 macroEMD=0.1875 tailR0=('0.1425', '0.0972', '0.0000') tailR0avg=0.0799
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    1    0
     0   23   28    4    0
     0   10   76   38    1
     0    0   19   96    1
     0    0    2   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   15   34    3    0
     0    8   84   29    0
     0    0   15  115    4
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   28   39    2    0
     0   16  108   27    0
     0    1   31   69    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=0.0085 
[epoch 31] step 4/44: loss=0.0083 
[epoch 31] step 6/44: loss=0.0071 
[epoch 31] step 8/44: loss=0.0071 
[epoch 31] step 10/44: loss=0.0068 
[epoch 31] step 12/44: loss=0.0067 
[epoch 31] step 14/44: loss=0.0069 
[epoch 31] step 16/44: loss=0.0072 
[epoch 31] step 18/44: loss=0.0077 
[epoch 31] step 20/44: loss=0.0076 
[epoch 31] step 22/44: loss=0.0077 
[epoch 31] step 24/44: loss=0.0079 
[epoch 31] step 26/44: loss=0.0077 
[epoch 31] step 28/44: loss=0.0076 
[epoch 31] step 30/44: loss=0.0077 
[epoch 31] step 32/44: loss=0.0078 
[epoch 31] step 34/44: loss=0.0079 
[epoch 31] step 36/44: loss=0.0080 
[epoch 31] step 38/44: loss=0.0079 
[epoch 31] step 40/44: loss=0.0078 
[epoch 31] step 42/44: loss=0.0078 
[epoch 31] step 44/44: loss=0.0079 
[epoch 31] val_loss=1.8355 qwk=('0.6596', '0.6508', '0.5756') averageQWK=0.6287 macroEMD=0.1842 tailR0=('0.1425', '0.0972', '0.0000') tailR0avg=0.0799
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   26   28    1    0
     0   12   84   28    1
     0    0   24   90    2
     0    0    3   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   19   30    3    0
     0   13   83   25    0
     0    0   20  112    2
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   29   38    2    0
     0   21   96   34    0
     0    1   30   70    0
     0    0    0    2    0
[epoch 32] step 2/44: loss=0.0063 
[epoch 32] step 4/44: loss=0.0057 
[epoch 32] step 6/44: loss=0.0062 
[epoch 32] step 8/44: loss=0.0076 
[epoch 32] step 10/44: loss=0.0075 
[epoch 32] step 12/44: loss=0.0071 
[epoch 32] step 14/44: loss=0.0070 
[epoch 32] step 16/44: loss=0.0074 
[epoch 32] step 18/44: loss=0.0073 
[epoch 32] step 20/44: loss=0.0075 
[epoch 32] step 22/44: loss=0.0073 
[epoch 32] step 24/44: loss=0.0071 
[epoch 32] step 26/44: loss=0.0070 
[epoch 32] step 28/44: loss=0.0070 
[epoch 32] step 30/44: loss=0.0069 
[epoch 32] step 32/44: loss=0.0069 
[epoch 32] step 34/44: loss=0.0070 
[epoch 32] step 36/44: loss=0.0072 
[epoch 32] step 38/44: loss=0.0070 
[epoch 32] step 40/44: loss=0.0070 
[epoch 32] step 42/44: loss=0.0070 
[epoch 32] step 44/44: loss=0.0069 
[epoch 32] val_loss=1.8496 qwk=('0.6662', '0.6421', '0.5956') averageQWK=0.6346 macroEMD=0.1834 tailR0=('0.0870', '0.0417', '0.0000') tailR0avg=0.0429
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   30   24    1    0
     0   14   86   24    1
     0    0   23   91    2
     0    1    2   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   18   30    4    0
     0   12   83   26    0
     0    0   17  115    2
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   35    2    0
     0   27  104   20    0
     0    1   36   64    0
     0    0    0    2    0
[epoch 33] step 2/44: loss=0.0072 
[epoch 33] step 4/44: loss=0.0064 
[epoch 33] step 6/44: loss=0.0068 
[epoch 33] step 8/44: loss=0.0063 
[epoch 33] step 10/44: loss=0.0077 
[epoch 33] step 12/44: loss=0.0074 
[epoch 33] step 14/44: loss=0.0071 
[epoch 33] step 16/44: loss=0.0068 
[epoch 33] step 18/44: loss=0.0067 
[epoch 33] step 20/44: loss=0.0067 
[epoch 33] step 22/44: loss=0.0066 
[epoch 33] step 24/44: loss=0.0067 
[epoch 33] step 26/44: loss=0.0066 
[epoch 33] step 28/44: loss=0.0066 
[epoch 33] step 30/44: loss=0.0066 
[epoch 33] step 32/44: loss=0.0065 
[epoch 33] step 34/44: loss=0.0064 
[epoch 33] step 36/44: loss=0.0063 
[epoch 33] step 38/44: loss=0.0063 
[epoch 33] step 40/44: loss=0.0062 
[epoch 33] step 42/44: loss=0.0062 
[epoch 33] step 44/44: loss=0.0061 
[epoch 33] val_loss=1.8679 qwk=('0.6427', '0.6412', '0.5746') averageQWK=0.6195 macroEMD=0.1866 tailR0=('0.0870', '0.0417', '0.0000') tailR0avg=0.0429
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   26   28    1    0
     0   12   82   30    1
     0    0   23   91    2
     0    0    3   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   18   30    4    0
     0   11   83   27    0
     0    0   17  115    2
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   28   39    2    0
     0   21  102   28    0
     0    1   32   68    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=0.0065 
[epoch 34] step 4/44: loss=0.0061 
[epoch 34] step 6/44: loss=0.0058 
[epoch 34] step 8/44: loss=0.0067 
[epoch 34] step 10/44: loss=0.0065 
[epoch 34] step 12/44: loss=0.0065 
[epoch 34] step 14/44: loss=0.0062 
[epoch 34] step 16/44: loss=0.0059 
[epoch 34] step 18/44: loss=0.0060 
[epoch 34] step 20/44: loss=0.0059 
[epoch 34] step 22/44: loss=0.0058 
[epoch 34] step 24/44: loss=0.0059 
[epoch 34] step 26/44: loss=0.0059 
[epoch 34] step 28/44: loss=0.0059 
[epoch 34] step 30/44: loss=0.0057 
[epoch 34] step 32/44: loss=0.0058 
[epoch 34] step 34/44: loss=0.0059 
[epoch 34] step 36/44: loss=0.0058 
[epoch 34] step 38/44: loss=0.0058 
[epoch 34] step 40/44: loss=0.0057 
[epoch 34] step 42/44: loss=0.0057 
[epoch 34] step 44/44: loss=0.0057 
[epoch 34] val_loss=1.8564 qwk=('0.6565', '0.6536', '0.5793') averageQWK=0.6298 macroEMD=0.1846 tailR0=('0.0870', '0.0972', '0.0000') tailR0avg=0.0614
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   29   25    1    0
     0   13   83   28    1
     0    0   23   91    2
     0    1    2   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   18   31    3    0
     0   13   82   26    0
     0    0   17  115    2
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   29   38    2    0
     0   22  102   27    0
     0    1   32   68    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=0.0057 
[epoch 35] step 4/44: loss=0.0057 
[epoch 35] step 6/44: loss=0.0057 
[epoch 35] step 8/44: loss=0.0063 
[epoch 35] step 10/44: loss=0.0059 
[epoch 35] step 12/44: loss=0.0056 
[epoch 35] step 14/44: loss=0.0056 
[epoch 35] step 16/44: loss=0.0056 
[epoch 35] step 18/44: loss=0.0058 
[epoch 35] step 20/44: loss=0.0056 
[epoch 35] step 22/44: loss=0.0055 
[epoch 35] step 24/44: loss=0.0056 
[epoch 35] step 26/44: loss=0.0056 
[epoch 35] step 28/44: loss=0.0057 
[epoch 35] step 30/44: loss=0.0056 
[epoch 35] step 32/44: loss=0.0057 
[epoch 35] step 34/44: loss=0.0056 
[epoch 35] step 36/44: loss=0.0055 
[epoch 35] step 38/44: loss=0.0054 
[epoch 35] step 40/44: loss=0.0054 
[epoch 35] step 42/44: loss=0.0054 
[epoch 35] step 44/44: loss=0.0056 
[epoch 35] val_loss=1.8571 qwk=('0.6680', '0.6591', '0.5774') averageQWK=0.6348 macroEMD=0.1842 tailR0=('0.0870', '0.0972', '0.0000') tailR0avg=0.0614
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   28   26    1    0
     0   13   87   24    1
     0    0   24   90    2
     0    0    3   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   19   30    3    0
     0   15   82   24    0
     0    0   17  115    2
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   29   38    2    0
     0   22  101   28    0
     0    1   32   68    0
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/ce/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/ce/fold0/metrics.json
Done.
