[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.9751 
[epoch 1] step 4/44: loss=0.9552 
[epoch 1] step 6/44: loss=0.9513 
[epoch 1] step 8/44: loss=0.9506 
[epoch 1] step 10/44: loss=0.9464 
[epoch 1] step 12/44: loss=0.9420 
[epoch 1] step 14/44: loss=0.9422 
[epoch 1] step 16/44: loss=0.9354 
[epoch 1] step 18/44: loss=0.9322 
[epoch 1] step 20/44: loss=0.9314 
[epoch 1] step 22/44: loss=0.9282 
[epoch 1] step 24/44: loss=0.9291 
[epoch 1] step 26/44: loss=0.9256 
[epoch 1] step 28/44: loss=0.9237 
[epoch 1] step 30/44: loss=0.9231 
[epoch 1] step 32/44: loss=0.9214 
[epoch 1] step 34/44: loss=0.9182 
[epoch 1] step 36/44: loss=0.9152 
[epoch 1] step 38/44: loss=0.9118 
[epoch 1] step 40/44: loss=0.9089 
[epoch 1] step 42/44: loss=0.9056 
[epoch 1] step 44/44: loss=0.8999 
[epoch 1] val_loss=1.5591 qwk=('0.0440', '0.0844', '0.3229') averageQWK=0.1504 macroEMD=0.3718 tailR0=('0.0000', '0.0556', '0.5000') tailR0avg=0.1852
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    7    0
     0   20    0   34    0
     0   54    1   70    0
     0   40    2   74    0
     0    5    2   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    6    2    0
    22    0   24    7    0
    46    0   47   28    0
    50    0   28   55    0
     1    0    4    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   26   41    1    1
     0   31   91   21    8
     0   10   56   31    4
     0    0    0    0    2
[epoch 2] step 2/44: loss=0.7739 
[epoch 2] step 4/44: loss=0.7700 
[epoch 2] step 6/44: loss=0.7534 
[epoch 2] step 8/44: loss=0.7428 
[epoch 2] step 10/44: loss=0.7373 
[epoch 2] step 12/44: loss=0.7312 
[epoch 2] step 14/44: loss=0.7280 
[epoch 2] step 16/44: loss=0.7209 
[epoch 2] step 18/44: loss=0.7143 
[epoch 2] step 20/44: loss=0.7088 
[epoch 2] step 22/44: loss=0.7027 
[epoch 2] step 24/44: loss=0.6955 
[epoch 2] step 26/44: loss=0.6895 
[epoch 2] step 28/44: loss=0.6804 
[epoch 2] step 30/44: loss=0.6763 
[epoch 2] step 32/44: loss=0.6717 
[epoch 2] step 34/44: loss=0.6676 
[epoch 2] step 36/44: loss=0.6661 
[epoch 2] step 38/44: loss=0.6638 
[epoch 2] step 40/44: loss=0.6616 
[epoch 2] step 42/44: loss=0.6595 
[epoch 2] step 44/44: loss=0.6571 
[epoch 2] val_loss=1.1581 qwk=('0.4027', '0.4232', '0.4785') averageQWK=0.4348 macroEMD=0.3111 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    0   52    2    0
     0    0   95   30    0
     0    0   38   78    0
     0    0    8   15    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   45    8    0
     0    0   84   37    0
     0    0   36   97    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0   15   48    6    0
     0    8  100   43    0
     0    0   27   74    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=0.5586 
[epoch 3] step 4/44: loss=0.5802 
[epoch 3] step 6/44: loss=0.5725 
[epoch 3] step 8/44: loss=0.5697 
[epoch 3] step 10/44: loss=0.5672 
[epoch 3] step 12/44: loss=0.5667 
[epoch 3] step 14/44: loss=0.5642 
[epoch 3] step 16/44: loss=0.5638 
[epoch 3] step 18/44: loss=0.5631 
[epoch 3] step 20/44: loss=0.5609 
[epoch 3] step 22/44: loss=0.5665 
[epoch 3] step 24/44: loss=0.5658 
[epoch 3] step 26/44: loss=0.5682 
[epoch 3] step 28/44: loss=0.5647 
[epoch 3] step 30/44: loss=0.5644 
[epoch 3] step 32/44: loss=0.5682 
[epoch 3] step 34/44: loss=0.5684 
[epoch 3] step 36/44: loss=0.5632 
[epoch 3] step 38/44: loss=0.5645 
[epoch 3] step 40/44: loss=0.5620 
[epoch 3] step 42/44: loss=0.5595 
[epoch 3] step 44/44: loss=0.5664 
[epoch 3] val_loss=1.0199 qwk=('0.5169', '0.4538', '0.5910') averageQWK=0.5206 macroEMD=0.2525 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    0    0
     0    5   43    6    0
     0    3   75   47    0
     0    0   16  100    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   42   11    0
     0    0   77   44    0
     0    0   17  116    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   38   25    6    0
     0   26   87   38    0
     0    2   22   77    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=0.4884 
[epoch 4] step 4/44: loss=0.5088 
[epoch 4] step 6/44: loss=0.5259 
[epoch 4] step 8/44: loss=0.5181 
[epoch 4] step 10/44: loss=0.5128 
[epoch 4] step 12/44: loss=0.5167 
[epoch 4] step 14/44: loss=0.5229 
[epoch 4] step 16/44: loss=0.5182 
[epoch 4] step 18/44: loss=0.5145 
[epoch 4] step 20/44: loss=0.5179 
[epoch 4] step 22/44: loss=0.5175 
[epoch 4] step 24/44: loss=0.5198 
[epoch 4] step 26/44: loss=0.5173 
[epoch 4] step 28/44: loss=0.5113 
[epoch 4] step 30/44: loss=0.5081 
[epoch 4] step 32/44: loss=0.5080 
[epoch 4] step 34/44: loss=0.5080 
[epoch 4] step 36/44: loss=0.5111 
[epoch 4] step 38/44: loss=0.5090 
[epoch 4] step 40/44: loss=0.5103 
[epoch 4] step 42/44: loss=0.5111 
[epoch 4] step 44/44: loss=0.5107 
[epoch 4] val_loss=0.9676 qwk=('0.5450', '0.5007', '0.6172') averageQWK=0.5543 macroEMD=0.2310 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    0    0
     0    7   46    1    0
     0    8   83   34    0
     0    0   23   93    0
     0    0    4   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    5   44    4    0
     0    5   81   35    0
     0    1   28  104    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   48   17    4    0
     0   48   64   39    0
     0    4   19   78    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=0.4519 
[epoch 5] step 4/44: loss=0.4508 
[epoch 5] step 6/44: loss=0.4585 
[epoch 5] step 8/44: loss=0.4452 
[epoch 5] step 10/44: loss=0.4555 
[epoch 5] step 12/44: loss=0.4541 
[epoch 5] step 14/44: loss=0.4511 
[epoch 5] step 16/44: loss=0.4504 
[epoch 5] step 18/44: loss=0.4516 
[epoch 5] step 20/44: loss=0.4485 
[epoch 5] step 22/44: loss=0.4493 
[epoch 5] step 24/44: loss=0.4505 
[epoch 5] step 26/44: loss=0.4475 
[epoch 5] step 28/44: loss=0.4506 
[epoch 5] step 30/44: loss=0.4509 
[epoch 5] step 32/44: loss=0.4504 
[epoch 5] step 34/44: loss=0.4509 
[epoch 5] step 36/44: loss=0.4548 
[epoch 5] step 38/44: loss=0.4595 
[epoch 5] step 40/44: loss=0.4603 
[epoch 5] step 42/44: loss=0.4616 
[epoch 5] step 44/44: loss=0.4578 
[epoch 5] val_loss=0.9267 qwk=('0.6166', '0.6408', '0.6469') averageQWK=0.6348 macroEMD=0.2149 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   21   33    0    0
     0   23   76   26    0
     0    0   33   83    0
     0    0    5   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    0    0
     0   25   23    5    0
     0   32   53   36    0
     0    1   25  107    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   41   26    2    0
     0   28   97   26    0
     0    2   28   71    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=0.3894 
[epoch 6] step 4/44: loss=0.3946 
[epoch 6] step 6/44: loss=0.4040 
[epoch 6] step 8/44: loss=0.4134 
[epoch 6] step 10/44: loss=0.4227 
[epoch 6] step 12/44: loss=0.4110 
[epoch 6] step 14/44: loss=0.4071 
[epoch 6] step 16/44: loss=0.4067 
[epoch 6] step 18/44: loss=0.4134 
[epoch 6] step 20/44: loss=0.4162 
[epoch 6] step 22/44: loss=0.4143 
[epoch 6] step 24/44: loss=0.4152 
[epoch 6] step 26/44: loss=0.4131 
[epoch 6] step 28/44: loss=0.4156 
[epoch 6] step 30/44: loss=0.4134 
[epoch 6] step 32/44: loss=0.4126 
[epoch 6] step 34/44: loss=0.4153 
[epoch 6] step 36/44: loss=0.4141 
[epoch 6] step 38/44: loss=0.4154 
[epoch 6] step 40/44: loss=0.4137 
[epoch 6] step 42/44: loss=0.4121 
[epoch 6] step 44/44: loss=0.4110 
[epoch 6] val_loss=1.0772 qwk=('0.5445', '0.4986', '0.5312') averageQWK=0.5248 macroEMD=0.2236 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    0    0
     0    6   43    5    0
     0    3   63   59    0
     0    0   12  104    0
     0    0    1   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    0    0
     0    8   33   12    0
     0    5   60   56    0
     0    0   11  122    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   13   51    5    0
     0    3   96   52    0
     0    0   17   84    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=0.3772 
[epoch 7] step 4/44: loss=0.3746 
[epoch 7] step 6/44: loss=0.4100 
[epoch 7] step 8/44: loss=0.3929 
[epoch 7] step 10/44: loss=0.3927 
[epoch 7] step 12/44: loss=0.3855 
[epoch 7] step 14/44: loss=0.3823 
[epoch 7] step 16/44: loss=0.3871 
[epoch 7] step 18/44: loss=0.3802 
[epoch 7] step 20/44: loss=0.3798 
[epoch 7] step 22/44: loss=0.3756 
[epoch 7] step 24/44: loss=0.3770 
[epoch 7] step 26/44: loss=0.3770 
[epoch 7] step 28/44: loss=0.3806 
[epoch 7] step 30/44: loss=0.3821 
[epoch 7] step 32/44: loss=0.3819 
[epoch 7] step 34/44: loss=0.3787 
[epoch 7] step 36/44: loss=0.3773 
[epoch 7] step 38/44: loss=0.3772 
[epoch 7] step 40/44: loss=0.3767 
[epoch 7] step 42/44: loss=0.3738 
[epoch 7] step 44/44: loss=0.3717 
[epoch 7] val_loss=1.0076 qwk=('0.6285', '0.5366', '0.5806') averageQWK=0.5819 macroEMD=0.2078 tailR0=('0.1957', '0.0000', '0.0000') tailR0avg=0.0652
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   10   43    1    0
     0    7   85   30    3
     0    0   26   85    5
     0    0    1   13    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   10   34    9    0
     0   12   64   45    0
     0    0   23  110    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   23   43    3    0
     0   10  112   29    0
     0    0   33   68    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=0.3367 
[epoch 8] step 4/44: loss=0.3405 
[epoch 8] step 6/44: loss=0.3338 
[epoch 8] step 8/44: loss=0.3407 
[epoch 8] step 10/44: loss=0.3353 
[epoch 8] step 12/44: loss=0.3366 
[epoch 8] step 14/44: loss=0.3405 
[epoch 8] step 16/44: loss=0.3402 
[epoch 8] step 18/44: loss=0.3422 
[epoch 8] step 20/44: loss=0.3384 
[epoch 8] step 22/44: loss=0.3341 
[epoch 8] step 24/44: loss=0.3331 
[epoch 8] step 26/44: loss=0.3323 
[epoch 8] step 28/44: loss=0.3298 
[epoch 8] step 30/44: loss=0.3371 
[epoch 8] step 32/44: loss=0.3344 
[epoch 8] step 34/44: loss=0.3380 
[epoch 8] step 36/44: loss=0.3384 
[epoch 8] step 38/44: loss=0.3383 
[epoch 8] step 40/44: loss=0.3383 
[epoch 8] step 42/44: loss=0.3419 
[epoch 8] step 44/44: loss=0.3437 
[epoch 8] val_loss=1.0102 qwk=('0.5990', '0.5465', '0.6063') averageQWK=0.5839 macroEMD=0.2053 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   13   40    1    0
     0    7   88   30    0
     0    0   31   85    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   10   38    5    0
     0    9   85   27    0
     0    0   36   97    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   29   40    0    0
     0   11  123   17    0
     0    1   42   58    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=0.3139 
[epoch 9] step 4/44: loss=0.2869 
[epoch 9] step 6/44: loss=0.2970 
[epoch 9] step 8/44: loss=0.2988 
[epoch 9] step 10/44: loss=0.3027 
[epoch 9] step 12/44: loss=0.2958 
[epoch 9] step 14/44: loss=0.2928 
[epoch 9] step 16/44: loss=0.2940 
[epoch 9] step 18/44: loss=0.2997 
[epoch 9] step 20/44: loss=0.3065 
[epoch 9] step 22/44: loss=0.3088 
[epoch 9] step 24/44: loss=0.3040 
[epoch 9] step 26/44: loss=0.3025 
[epoch 9] step 28/44: loss=0.3015 
[epoch 9] step 30/44: loss=0.3019 
[epoch 9] step 32/44: loss=0.2992 
[epoch 9] step 34/44: loss=0.3000 
[epoch 9] step 36/44: loss=0.3003 
[epoch 9] step 38/44: loss=0.3013 
[epoch 9] step 40/44: loss=0.3006 
[epoch 9] step 42/44: loss=0.3005 
[epoch 9] step 44/44: loss=0.3028 
[epoch 9] val_loss=1.0210 qwk=('0.6432', '0.5647', '0.6296') averageQWK=0.6125 macroEMD=0.1887 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   21   32    1    0
     0   16   82   27    0
     0    0   36   80    0
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   17   31    5    0
     0   19   72   30    0
     0    1   35   97    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   40   28    1    0
     0   21  111   19    0
     0    3   35   63    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=0.2492 
[epoch 10] step 4/44: loss=0.2499 
[epoch 10] step 6/44: loss=0.2621 
[epoch 10] step 8/44: loss=0.2671 
[epoch 10] step 10/44: loss=0.2678 
[epoch 10] step 12/44: loss=0.2668 
[epoch 10] step 14/44: loss=0.2712 
[epoch 10] step 16/44: loss=0.2718 
[epoch 10] step 18/44: loss=0.2666 
[epoch 10] step 20/44: loss=0.2710 
[epoch 10] step 22/44: loss=0.2717 
[epoch 10] step 24/44: loss=0.2671 
[epoch 10] step 26/44: loss=0.2646 
[epoch 10] step 28/44: loss=0.2629 
[epoch 10] step 30/44: loss=0.2650 
[epoch 10] step 32/44: loss=0.2670 
[epoch 10] step 34/44: loss=0.2665 
[epoch 10] step 36/44: loss=0.2675 
[epoch 10] step 38/44: loss=0.2680 
[epoch 10] step 40/44: loss=0.2694 
[epoch 10] step 42/44: loss=0.2709 
[epoch 10] step 44/44: loss=0.2718 
[epoch 10] val_loss=1.0880 qwk=('0.6483', '0.5959', '0.5997') averageQWK=0.6146 macroEMD=0.1898 tailR0=('0.2174', '0.0417', '0.0000') tailR0avg=0.0864
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   15   37    2    0
     0   16   77   31    1
     0    0   31   79    6
     0    0    1   12   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   17   31    5    0
     0   10   74   37    0
     0    0   30  102    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   28   39    2    0
     0   11  114   26    0
     0    1   34   66    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.2735 
[epoch 11] step 4/44: loss=0.2582 
[epoch 11] step 6/44: loss=0.2673 
[epoch 11] step 8/44: loss=0.2693 
[epoch 11] step 10/44: loss=0.2569 
[epoch 11] step 12/44: loss=0.2572 
[epoch 11] step 14/44: loss=0.2625 
[epoch 11] step 16/44: loss=0.2555 
[epoch 11] step 18/44: loss=0.2511 
[epoch 11] step 20/44: loss=0.2493 
[epoch 11] step 22/44: loss=0.2524 
[epoch 11] step 24/44: loss=0.2562 
[epoch 11] step 26/44: loss=0.2543 
[epoch 11] step 28/44: loss=0.2510 
[epoch 11] step 30/44: loss=0.2502 
[epoch 11] step 32/44: loss=0.2509 
[epoch 11] step 34/44: loss=0.2486 
[epoch 11] step 36/44: loss=0.2487 
[epoch 11] step 38/44: loss=0.2466 
[epoch 11] step 40/44: loss=0.2457 
[epoch 11] step 42/44: loss=0.2447 
[epoch 11] step 44/44: loss=0.2479 
[epoch 11] val_loss=1.1080 qwk=('0.6329', '0.5708', '0.6202') averageQWK=0.6080 macroEMD=0.1898 tailR0=('0.1304', '0.0417', '0.0000') tailR0avg=0.0574
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   12   40    2    0
     0   10   80   35    0
     0    0   26   90    0
     0    0    1   16    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   14   33    6    0
     0   12   73   36    0
     0    1   29  102    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   38   31    0    0
     0   17  121   13    0
     0    1   48   52    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=0.2290 
[epoch 12] step 4/44: loss=0.2314 
[epoch 12] step 6/44: loss=0.2305 
[epoch 12] step 8/44: loss=0.2263 
[epoch 12] step 10/44: loss=0.2276 
[epoch 12] step 12/44: loss=0.2163 
[epoch 12] step 14/44: loss=0.2167 
[epoch 12] step 16/44: loss=0.2124 
[epoch 12] step 18/44: loss=0.2131 
[epoch 12] step 20/44: loss=0.2116 
[epoch 12] step 22/44: loss=0.2142 
[epoch 12] step 24/44: loss=0.2182 
[epoch 12] step 26/44: loss=0.2157 
[epoch 12] step 28/44: loss=0.2168 
[epoch 12] step 30/44: loss=0.2179 
[epoch 12] step 32/44: loss=0.2159 
[epoch 12] step 34/44: loss=0.2163 
[epoch 12] step 36/44: loss=0.2166 
[epoch 12] step 38/44: loss=0.2157 
[epoch 12] step 40/44: loss=0.2160 
[epoch 12] step 42/44: loss=0.2167 
[epoch 12] step 44/44: loss=0.2159 
[epoch 12] val_loss=1.1882 qwk=('0.5979', '0.5660', '0.6273') averageQWK=0.5971 macroEMD=0.1873 tailR0=('0.1522', '0.0417', '0.0000') tailR0avg=0.0646
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   14   40    0    0
     0   12   90   22    1
     0    0   43   73    0
     0    0    5   11    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   19   25    9    0
     0   14   62   45    0
     0    1   21  110    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   46   23    0    0
     0   31  104   16    0
     0    2   47   52    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.1873 
[epoch 13] step 4/44: loss=0.1709 
[epoch 13] step 6/44: loss=0.1774 
[epoch 13] step 8/44: loss=0.1816 
[epoch 13] step 10/44: loss=0.1847 
[epoch 13] step 12/44: loss=0.1845 
[epoch 13] step 14/44: loss=0.1904 
[epoch 13] step 16/44: loss=0.1903 
[epoch 13] step 18/44: loss=0.1923 
[epoch 13] step 20/44: loss=0.1917 
[epoch 13] step 22/44: loss=0.1934 
[epoch 13] step 24/44: loss=0.1954 
[epoch 13] step 26/44: loss=0.1959 
[epoch 13] step 28/44: loss=0.1980 
[epoch 13] step 30/44: loss=0.1987 
[epoch 13] step 32/44: loss=0.1986 
[epoch 13] step 34/44: loss=0.1994 
[epoch 13] step 36/44: loss=0.2000 
[epoch 13] step 38/44: loss=0.1990 
[epoch 13] step 40/44: loss=0.1989 
[epoch 13] step 42/44: loss=0.1988 
[epoch 13] step 44/44: loss=0.1985 
[epoch 13] val_loss=1.1617 qwk=('0.6713', '0.5904', '0.6011') averageQWK=0.6209 macroEMD=0.1831 tailR0=('0.1522', '0.0833', '0.0000') tailR0avg=0.0785
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   20   34    0    0
     0   17   78   30    0
     0    0   32   82    2
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   18   29    6    0
     0   14   77   30    0
     0    1   33   98    1
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   43   25    1    0
     0   27  108   16    0
     0    4   42   55    0
     0    0    1    1    0
[epoch 14] step 2/44: loss=0.2152 
[epoch 14] step 4/44: loss=0.1938 
[epoch 14] step 6/44: loss=0.1827 
[epoch 14] step 8/44: loss=0.1756 
[epoch 14] step 10/44: loss=0.1878 
[epoch 14] step 12/44: loss=0.1902 
[epoch 14] step 14/44: loss=0.1867 
[epoch 14] step 16/44: loss=0.1891 
[epoch 14] step 18/44: loss=0.1855 
[epoch 14] step 20/44: loss=0.1789 
[epoch 14] step 22/44: loss=0.1786 
[epoch 14] step 24/44: loss=0.1799 
[epoch 14] step 26/44: loss=0.1831 
[epoch 14] step 28/44: loss=0.1816 
[epoch 14] step 30/44: loss=0.1802 
[epoch 14] step 32/44: loss=0.1785 
[epoch 14] step 34/44: loss=0.1785 
[epoch 14] step 36/44: loss=0.1758 
[epoch 14] step 38/44: loss=0.1769 
[epoch 14] step 40/44: loss=0.1754 
[epoch 14] step 42/44: loss=0.1745 
[epoch 14] step 44/44: loss=0.1775 
[epoch 14] val_loss=1.2788 qwk=('0.6319', '0.5609', '0.6106') averageQWK=0.6011 macroEMD=0.1867 tailR0=('0.1304', '0.0833', '0.0000') tailR0avg=0.0713
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   16   34    4    0
     0   14   67   44    0
     0    0   22   93    1
     0    0    1   16    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   15   31    7    0
     0   12   70   39    0
     0    1   28  104    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   28   39    2    0
     0   12  116   23    0
     0    1   35   65    0
     0    0    0    2    0
[epoch 15] step 2/44: loss=0.1906 
[epoch 15] step 4/44: loss=0.1946 
[epoch 15] step 6/44: loss=0.1935 
[epoch 15] step 8/44: loss=0.1830 
[epoch 15] step 10/44: loss=0.1794 
[epoch 15] step 12/44: loss=0.1774 
[epoch 15] step 14/44: loss=0.1700 
[epoch 15] step 16/44: loss=0.1649 
[epoch 15] step 18/44: loss=0.1624 
[epoch 15] step 20/44: loss=0.1608 
[epoch 15] step 22/44: loss=0.1664 
[epoch 15] step 24/44: loss=0.1666 
[epoch 15] step 26/44: loss=0.1644 
[epoch 15] step 28/44: loss=0.1645 
[epoch 15] step 30/44: loss=0.1642 
[epoch 15] step 32/44: loss=0.1641 
[epoch 15] step 34/44: loss=0.1631 
[epoch 15] step 36/44: loss=0.1640 
[epoch 15] step 38/44: loss=0.1622 
[epoch 15] step 40/44: loss=0.1610 
[epoch 15] step 42/44: loss=0.1580 
[epoch 15] step 44/44: loss=0.1604 
[epoch 15] val_loss=1.3083 qwk=('0.6530', '0.5961', '0.5763') averageQWK=0.6085 macroEMD=0.1793 tailR0=('0.1304', '0.0833', '0.0000') tailR0avg=0.0713
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   18   35    1    0
     0   16   68   40    1
     0    0   23   90    3
     0    0    1   16    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   16   31    5    0
     0   14   69   38    0
     0    1   27  103    2
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   30   35    4    0
     0   14   83   54    0
     0    1   21   79    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=0.1701 
[epoch 16] step 4/44: loss=0.1521 
[epoch 16] step 6/44: loss=0.1576 
[epoch 16] step 8/44: loss=0.1473 
[epoch 16] step 10/44: loss=0.1445 
[epoch 16] step 12/44: loss=0.1387 
[epoch 16] step 14/44: loss=0.1350 
[epoch 16] step 16/44: loss=0.1350 
[epoch 16] step 18/44: loss=0.1359 
[epoch 16] step 20/44: loss=0.1328 
[epoch 16] step 22/44: loss=0.1325 
[epoch 16] step 24/44: loss=0.1321 
[epoch 16] step 26/44: loss=0.1333 
[epoch 16] step 28/44: loss=0.1328 
[epoch 16] step 30/44: loss=0.1333 
[epoch 16] step 32/44: loss=0.1349 
[epoch 16] step 34/44: loss=0.1353 
[epoch 16] step 36/44: loss=0.1354 
[epoch 16] step 38/44: loss=0.1357 
[epoch 16] step 40/44: loss=0.1360 
[epoch 16] step 42/44: loss=0.1359 
[epoch 16] step 44/44: loss=0.1354 
[epoch 16] val_loss=1.3405 qwk=('0.6173', '0.5639', '0.6326') averageQWK=0.6046 macroEMD=0.1834 tailR0=('0.0652', '0.0417', '0.0000') tailR0avg=0.0356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   15   37    2    0
     0   10   78   36    1
     0    0   28   88    0
     0    0    2   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   14   34    4    0
     0    9   88   24    0
     0    0   44   89    0
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   37   30    2    0
     0   16  111   24    0
     0    1   37   63    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=0.1113 
[epoch 17] step 4/44: loss=0.1170 
[epoch 17] step 6/44: loss=0.1120 
[epoch 17] step 8/44: loss=0.1161 
[epoch 17] step 10/44: loss=0.1177 
[epoch 17] step 12/44: loss=0.1217 
[epoch 17] step 14/44: loss=0.1230 
[epoch 17] step 16/44: loss=0.1197 
[epoch 17] step 18/44: loss=0.1269 
[epoch 17] step 20/44: loss=0.1270 
[epoch 17] step 22/44: loss=0.1248 
[epoch 17] step 24/44: loss=0.1251 
[epoch 17] step 26/44: loss=0.1258 
[epoch 17] step 28/44: loss=0.1258 
[epoch 17] step 30/44: loss=0.1264 
[epoch 17] step 32/44: loss=0.1267 
[epoch 17] step 34/44: loss=0.1257 
[epoch 17] step 36/44: loss=0.1232 
[epoch 17] step 38/44: loss=0.1234 
[epoch 17] step 40/44: loss=0.1237 
[epoch 17] step 42/44: loss=0.1230 
[epoch 17] step 44/44: loss=0.1223 
[epoch 17] val_loss=1.4353 qwk=('0.6237', '0.6023', '0.6211') averageQWK=0.6157 macroEMD=0.1790 tailR0=('0.1304', '0.0833', '0.1000') tailR0avg=0.1046
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   15   37    2    0
     0   10   73   41    1
     0    0   24   92    0
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   15   30    7    0
     0   14   62   45    0
     0    0   17  115    1
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   35   34    0    0
     0   16  115   20    0
     0    1   43   57    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=0.1047 
[epoch 18] step 4/44: loss=0.1041 
[epoch 18] step 6/44: loss=0.1033 
[epoch 18] step 8/44: loss=0.1029 
[epoch 18] step 10/44: loss=0.1036 
[epoch 18] step 12/44: loss=0.0986 
[epoch 18] step 14/44: loss=0.1000 
[epoch 18] step 16/44: loss=0.1021 
[epoch 18] step 18/44: loss=0.1038 
[epoch 18] step 20/44: loss=0.1036 
[epoch 18] step 22/44: loss=0.1047 
[epoch 18] step 24/44: loss=0.1046 
[epoch 18] step 26/44: loss=0.1036 
[epoch 18] step 28/44: loss=0.1036 
[epoch 18] step 30/44: loss=0.1043 
[epoch 18] step 32/44: loss=0.1024 
[epoch 18] step 34/44: loss=0.1032 
[epoch 18] step 36/44: loss=0.1035 
[epoch 18] step 38/44: loss=0.1026 
[epoch 18] step 40/44: loss=0.1020 
[epoch 18] step 42/44: loss=0.1023 
[epoch 18] step 44/44: loss=0.1014 
[epoch 18] val_loss=1.4205 qwk=('0.6413', '0.5655', '0.6358') averageQWK=0.6142 macroEMD=0.1761 tailR0=('0.1304', '0.0417', '0.1000') tailR0avg=0.0907
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   17   35    2    0
     0   11   73   40    1
     0    0   26   89    1
     0    0    1   16    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   12   34    6    0
     0   10   73   38    0
     0    0   32  100    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   35   33    1    0
     0   19  113   19    0
     0    1   39   61    0
     0    0    0    2    0
[epoch 19] step 2/44: loss=0.0826 
[epoch 19] step 4/44: loss=0.0820 
[epoch 19] step 6/44: loss=0.0888 
[epoch 19] step 8/44: loss=0.0892 
[epoch 19] step 10/44: loss=0.0869 
[epoch 19] step 12/44: loss=0.0893 
[epoch 19] step 14/44: loss=0.0881 
[epoch 19] step 16/44: loss=0.0875 
[epoch 19] step 18/44: loss=0.0871 
[epoch 19] step 20/44: loss=0.0878 
[epoch 19] step 22/44: loss=0.0864 
[epoch 19] step 24/44: loss=0.0906 
[epoch 19] step 26/44: loss=0.0927 
[epoch 19] step 28/44: loss=0.0908 
[epoch 19] step 30/44: loss=0.0903 
[epoch 19] step 32/44: loss=0.0909 
[epoch 19] step 34/44: loss=0.0903 
[epoch 19] step 36/44: loss=0.0898 
[epoch 19] step 38/44: loss=0.0894 
[epoch 19] step 40/44: loss=0.0886 
[epoch 19] step 42/44: loss=0.0875 
[epoch 19] step 44/44: loss=0.0853 
[epoch 19] val_loss=1.4676 qwk=('0.6444', '0.5810', '0.6278') averageQWK=0.6178 macroEMD=0.1760 tailR0=('0.0652', '0.0417', '0.0000') tailR0avg=0.0356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   18   34    2    0
     0   16   69   40    0
     0    0   22   94    0
     0    0    1   19    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   13   34    5    0
     0   14   76   31    0
     0    0   34   99    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   39   28    2    0
     0   24  105   22    0
     0    1   38   62    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=0.0557 
[epoch 20] step 4/44: loss=0.0504 
[epoch 20] step 6/44: loss=0.0551 
[epoch 20] step 8/44: loss=0.0624 
[epoch 20] step 10/44: loss=0.0665 
[epoch 20] step 12/44: loss=0.0655 
[epoch 20] step 14/44: loss=0.0686 
[epoch 20] step 16/44: loss=0.0684 
[epoch 20] step 18/44: loss=0.0709 
[epoch 20] step 20/44: loss=0.0700 
[epoch 20] step 22/44: loss=0.0720 
[epoch 20] step 24/44: loss=0.0721 
[epoch 20] step 26/44: loss=0.0715 
[epoch 20] step 28/44: loss=0.0712 
[epoch 20] step 30/44: loss=0.0699 
[epoch 20] step 32/44: loss=0.0690 
[epoch 20] step 34/44: loss=0.0701 
[epoch 20] step 36/44: loss=0.0698 
[epoch 20] step 38/44: loss=0.0700 
[epoch 20] step 40/44: loss=0.0703 
[epoch 20] step 42/44: loss=0.0701 
[epoch 20] step 44/44: loss=0.0703 
[epoch 20] val_loss=1.5284 qwk=('0.6467', '0.5875', '0.6264') averageQWK=0.6202 macroEMD=0.1727 tailR0=('0.1152', '0.0417', '0.1000') tailR0avg=0.0856
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    2    0    0
     0   16   37    1    0
     0   17   66   42    0
     0    0   21   95    0
     0    0    1   19    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   18   28    6    0
     0   16   67   38    0
     0    0   31  102    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   38   29    2    0
     0   24  107   20    0
     0    1   40   60    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=0.0638 
[epoch 21] step 4/44: loss=0.0601 
[epoch 21] step 6/44: loss=0.0593 
[epoch 21] step 8/44: loss=0.0619 
[epoch 21] step 10/44: loss=0.0604 
[epoch 21] step 12/44: loss=0.0574 
[epoch 21] step 14/44: loss=0.0573 
[epoch 21] step 16/44: loss=0.0566 
[epoch 21] step 18/44: loss=0.0578 
[epoch 21] step 20/44: loss=0.0580 
[epoch 21] step 22/44: loss=0.0575 
[epoch 21] step 24/44: loss=0.0594 
[epoch 21] step 26/44: loss=0.0580 
[epoch 21] step 28/44: loss=0.0584 
[epoch 21] step 30/44: loss=0.0584 
[epoch 21] step 32/44: loss=0.0583 
[epoch 21] step 34/44: loss=0.0596 
[epoch 21] step 36/44: loss=0.0596 
[epoch 21] step 38/44: loss=0.0613 
[epoch 21] step 40/44: loss=0.0627 
[epoch 21] step 42/44: loss=0.0628 
[epoch 21] step 44/44: loss=0.0626 
[epoch 21] val_loss=1.6961 qwk=('0.6208', '0.5618', '0.6010') averageQWK=0.5945 macroEMD=0.1856 tailR0=('0.1739', '0.1250', '0.0000') tailR0avg=0.0996
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   11   39    4    0
     0    6   75   41    3
     0    0   17   92    7
     0    0    1   14    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     1    9   34    9    0
     0    8   64   49    0
     0    0   12  119    2
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   34    4    0
     0   16   95   40    0
     0    1   24   76    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=0.0491 
[epoch 22] step 4/44: loss=0.0563 
[epoch 22] step 6/44: loss=0.0563 
[epoch 22] step 8/44: loss=0.0581 
[epoch 22] step 10/44: loss=0.0571 
[epoch 22] step 12/44: loss=0.0576 
[epoch 22] step 14/44: loss=0.0569 
[epoch 22] step 16/44: loss=0.0552 
[epoch 22] step 18/44: loss=0.0525 
[epoch 22] step 20/44: loss=0.0522 
[epoch 22] step 22/44: loss=0.0529 
[epoch 22] step 24/44: loss=0.0543 
[epoch 22] step 26/44: loss=0.0527 
[epoch 22] step 28/44: loss=0.0532 
[epoch 22] step 30/44: loss=0.0519 
[epoch 22] step 32/44: loss=0.0515 
[epoch 22] step 34/44: loss=0.0518 
[epoch 22] step 36/44: loss=0.0524 
[epoch 22] step 38/44: loss=0.0516 
[epoch 22] step 40/44: loss=0.0514 
[epoch 22] step 42/44: loss=0.0510 
[epoch 22] step 44/44: loss=0.0512 
[epoch 22] val_loss=1.7437 qwk=('0.6302', '0.5852', '0.6396') averageQWK=0.6183 macroEMD=0.1765 tailR0=('0.1804', '0.0833', '0.1000') tailR0avg=0.1213
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    3    0    0
     0   11   40    3    0
     0    7   67   50    1
     0    0   13  100    3
     0    0    1   16    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   11   34    7    0
     0    7   65   49    0
     0    0   17  115    1
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   39   28    2    0
     0   21   99   31    0
     0    1   33   67    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=0.0473 
[epoch 23] step 4/44: loss=0.0486 
[epoch 23] step 6/44: loss=0.0469 
[epoch 23] step 8/44: loss=0.0474 
[epoch 23] step 10/44: loss=0.0463 
[epoch 23] step 12/44: loss=0.0465 
[epoch 23] step 14/44: loss=0.0453 
[epoch 23] step 16/44: loss=0.0463 
[epoch 23] step 18/44: loss=0.0460 
[epoch 23] step 20/44: loss=0.0447 
[epoch 23] step 22/44: loss=0.0460 
[epoch 23] step 24/44: loss=0.0472 
[epoch 23] step 26/44: loss=0.0458 
[epoch 23] step 28/44: loss=0.0448 
[epoch 23] step 30/44: loss=0.0438 
[epoch 23] step 32/44: loss=0.0435 
[epoch 23] step 34/44: loss=0.0433 
[epoch 23] step 36/44: loss=0.0438 
[epoch 23] step 38/44: loss=0.0432 
[epoch 23] step 40/44: loss=0.0430 
[epoch 23] step 42/44: loss=0.0430 
[epoch 23] step 44/44: loss=0.0429 
[epoch 23] val_loss=1.7520 qwk=('0.6322', '0.5854', '0.5740') averageQWK=0.5972 macroEMD=0.1810 tailR0=('0.1304', '0.1250', '0.0000') tailR0avg=0.0851
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   15   37    2    0
     0    7   71   46    1
     0    0   21   94    1
     0    0    1   16    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   14   32    6    0
     0   12   74   35    0
     0    0   33   95    5
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   28   37    4    0
     0   13   98   40    0
     0    1   29   71    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=0.0340 
[epoch 24] step 4/44: loss=0.0309 
[epoch 24] step 6/44: loss=0.0337 
[epoch 24] step 8/44: loss=0.0353 
[epoch 24] step 10/44: loss=0.0368 
[epoch 24] step 12/44: loss=0.0353 
[epoch 24] step 14/44: loss=0.0351 
[epoch 24] step 16/44: loss=0.0349 
[epoch 24] step 18/44: loss=0.0352 
[epoch 24] step 20/44: loss=0.0359 
[epoch 24] step 22/44: loss=0.0356 
[epoch 24] step 24/44: loss=0.0350 
[epoch 24] step 26/44: loss=0.0347 
[epoch 24] step 28/44: loss=0.0349 
[epoch 24] step 30/44: loss=0.0346 
[epoch 24] step 32/44: loss=0.0356 
[epoch 24] step 34/44: loss=0.0351 
[epoch 24] step 36/44: loss=0.0344 
[epoch 24] step 38/44: loss=0.0346 
[epoch 24] step 40/44: loss=0.0347 
[epoch 24] step 42/44: loss=0.0346 
[epoch 24] step 44/44: loss=0.0348 
[epoch 24] val_loss=1.7562 qwk=('0.6401', '0.5777', '0.6277') averageQWK=0.6152 macroEMD=0.1778 tailR0=('0.1522', '0.0417', '0.0000') tailR0avg=0.0646
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   14   38    2    0
     0   10   72   42    1
     0    0   20   95    1
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   12   32    8    0
     0   10   71   40    0
     0    0   22  109    2
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   37   32    0    0
     0   23  111   17    0
     0    1   43   57    0
     0    0    0    2    0
[epoch 25] step 2/44: loss=0.0283 
[epoch 25] step 4/44: loss=0.0281 
[epoch 25] step 6/44: loss=0.0292 
[epoch 25] step 8/44: loss=0.0273 
[epoch 25] step 10/44: loss=0.0269 
[epoch 25] step 12/44: loss=0.0271 
[epoch 25] step 14/44: loss=0.0272 
[epoch 25] step 16/44: loss=0.0265 
[epoch 25] step 18/44: loss=0.0261 
[epoch 25] step 20/44: loss=0.0264 
[epoch 25] step 22/44: loss=0.0261 
[epoch 25] step 24/44: loss=0.0263 
[epoch 25] step 26/44: loss=0.0264 
[epoch 25] step 28/44: loss=0.0271 
[epoch 25] step 30/44: loss=0.0269 
[epoch 25] step 32/44: loss=0.0272 
[epoch 25] step 34/44: loss=0.0270 
[epoch 25] step 36/44: loss=0.0268 
[epoch 25] step 38/44: loss=0.0270 
[epoch 25] step 40/44: loss=0.0276 
[epoch 25] step 42/44: loss=0.0272 
[epoch 25] step 44/44: loss=0.0269 
[epoch 25] val_loss=1.7818 qwk=('0.6402', '0.5925', '0.6358') averageQWK=0.6228 macroEMD=0.1752 tailR0=('0.1304', '0.1250', '0.0000') tailR0avg=0.0851
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   16   36    2    0
     0   12   72   40    1
     0    0   22   93    1
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     1   13   32    7    0
     0   10   68   43    0
     0    0   18  115    0
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   35   32    2    0
     0   17  109   25    0
     0    1   33   67    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=0.0187 
[epoch 26] step 4/44: loss=0.0201 
[epoch 26] step 6/44: loss=0.0201 
[epoch 26] step 8/44: loss=0.0232 
[epoch 26] step 10/44: loss=0.0247 
[epoch 26] step 12/44: loss=0.0241 
[epoch 26] step 14/44: loss=0.0232 
[epoch 26] step 16/44: loss=0.0225 
[epoch 26] step 18/44: loss=0.0225 
[epoch 26] step 20/44: loss=0.0227 
[epoch 26] step 22/44: loss=0.0227 
[epoch 26] step 24/44: loss=0.0231 
[epoch 26] step 26/44: loss=0.0233 
[epoch 26] step 28/44: loss=0.0229 
[epoch 26] step 30/44: loss=0.0230 
[epoch 26] step 32/44: loss=0.0237 
[epoch 26] step 34/44: loss=0.0246 
[epoch 26] step 36/44: loss=0.0248 
[epoch 26] step 38/44: loss=0.0245 
[epoch 26] step 40/44: loss=0.0252 
[epoch 26] step 42/44: loss=0.0252 
[epoch 26] step 44/44: loss=0.0249 
[epoch 26] val_loss=1.8485 qwk=('0.6326', '0.5946', '0.6112') averageQWK=0.6128 macroEMD=0.1714 tailR0=('0.2304', '0.0417', '0.1000') tailR0avg=0.1240
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    3    0    0
     0   15   37    2    0
     0   11   83   31    0
     0    0   31   84    1
     0    0    3   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     1   20   25    7    0
     0   19   67   35    0
     0    1   30  102    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   34   32    3    0
     0   19  100   32    0
     0    1   31   69    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=0.0199 
[epoch 27] step 4/44: loss=0.0257 
[epoch 27] step 6/44: loss=0.0235 
[epoch 27] step 8/44: loss=0.0216 
[epoch 27] step 10/44: loss=0.0211 
[epoch 27] step 12/44: loss=0.0212 
[epoch 27] step 14/44: loss=0.0215 
[epoch 27] step 16/44: loss=0.0219 
[epoch 27] step 18/44: loss=0.0210 
[epoch 27] step 20/44: loss=0.0201 
[epoch 27] step 22/44: loss=0.0199 
[epoch 27] step 24/44: loss=0.0196 
[epoch 27] step 26/44: loss=0.0197 
[epoch 27] step 28/44: loss=0.0198 
[epoch 27] step 30/44: loss=0.0197 
[epoch 27] step 32/44: loss=0.0201 
[epoch 27] step 34/44: loss=0.0206 
[epoch 27] step 36/44: loss=0.0210 
[epoch 27] step 38/44: loss=0.0214 
[epoch 27] step 40/44: loss=0.0219 
[epoch 27] step 42/44: loss=0.0215 
[epoch 27] step 44/44: loss=0.0210 
[epoch 27] val_loss=1.8928 qwk=('0.6460', '0.5864', '0.6415') averageQWK=0.6246 macroEMD=0.1695 tailR0=('0.1804', '0.1250', '0.1000') tailR0avg=0.1351
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    2    0    0
     0   16   36    2    0
     0   12   78   34    1
     0    0   26   89    1
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   15   31    6    0
     0   14   70   37    0
     0    0   32   99    2
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   36   30    3    0
     0   18  103   30    0
     0    1   29   71    0
     0    0    0    2    0
[epoch 28] step 2/44: loss=0.0186 
[epoch 28] step 4/44: loss=0.0192 
[epoch 28] step 6/44: loss=0.0191 
[epoch 28] step 8/44: loss=0.0188 
[epoch 28] step 10/44: loss=0.0178 
[epoch 28] step 12/44: loss=0.0173 
[epoch 28] step 14/44: loss=0.0189 
[epoch 28] step 16/44: loss=0.0188 
[epoch 28] step 18/44: loss=0.0188 
[epoch 28] step 20/44: loss=0.0187 
[epoch 28] step 22/44: loss=0.0183 
[epoch 28] step 24/44: loss=0.0183 
[epoch 28] step 26/44: loss=0.0181 
[epoch 28] step 28/44: loss=0.0179 
[epoch 28] step 30/44: loss=0.0179 
[epoch 28] step 32/44: loss=0.0177 
[epoch 28] step 34/44: loss=0.0178 
[epoch 28] step 36/44: loss=0.0178 
[epoch 28] step 38/44: loss=0.0180 
[epoch 28] step 40/44: loss=0.0177 
[epoch 28] step 42/44: loss=0.0176 
[epoch 28] step 44/44: loss=0.0173 
[epoch 28] val_loss=1.9275 qwk=('0.6390', '0.5600', '0.6256') averageQWK=0.6082 macroEMD=0.1749 tailR0=('0.1304', '0.0833', '0.1000') tailR0avg=0.1046
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   16   36    2    0
     0   12   76   36    1
     0    0   25   90    1
     0    0    1   16    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   13   33    6    0
     0   12   79   30    0
     0    0   39   92    2
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   33   34    2    0
     0   16  105   30    0
     0    1   33   67    0
     0    0    0    2    0
[epoch 29] step 2/44: loss=0.0198 
[epoch 29] step 4/44: loss=0.0169 
[epoch 29] step 6/44: loss=0.0158 
[epoch 29] step 8/44: loss=0.0146 
[epoch 29] step 10/44: loss=0.0162 
[epoch 29] step 12/44: loss=0.0152 
[epoch 29] step 14/44: loss=0.0143 
[epoch 29] step 16/44: loss=0.0145 
[epoch 29] step 18/44: loss=0.0147 
[epoch 29] step 20/44: loss=0.0142 
[epoch 29] step 22/44: loss=0.0143 
[epoch 29] step 24/44: loss=0.0153 
[epoch 29] step 26/44: loss=0.0156 
[epoch 29] step 28/44: loss=0.0156 
[epoch 29] step 30/44: loss=0.0152 
[epoch 29] step 32/44: loss=0.0151 
[epoch 29] step 34/44: loss=0.0149 
[epoch 29] step 36/44: loss=0.0148 
[epoch 29] step 38/44: loss=0.0149 
[epoch 29] step 40/44: loss=0.0148 
[epoch 29] step 42/44: loss=0.0146 
[epoch 29] step 44/44: loss=0.0153 
[epoch 29] val_loss=1.9697 qwk=('0.6327', '0.5751', '0.6413') averageQWK=0.6163 macroEMD=0.1683 tailR0=('0.1587', '0.0833', '0.1000') tailR0avg=0.1140
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    2    0    0
     1   15   36    2    0
     0   12   85   27    1
     0    0   32   83    1
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     2   17   27    7    0
     0   19   69   33    0
     0    1   35   95    2
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   47   22    0    0
     0   29  110   12    0
     0    3   46   52    0
     0    0    0    2    0
[epoch 30] step 2/44: loss=0.0116 
[epoch 30] step 4/44: loss=0.0127 
[epoch 30] step 6/44: loss=0.0120 
[epoch 30] step 8/44: loss=0.0131 
[epoch 30] step 10/44: loss=0.0129 
[epoch 30] step 12/44: loss=0.0136 
[epoch 30] step 14/44: loss=0.0137 
[epoch 30] step 16/44: loss=0.0136 
[epoch 30] step 18/44: loss=0.0133 
[epoch 30] step 20/44: loss=0.0135 
[epoch 30] step 22/44: loss=0.0133 
[epoch 30] step 24/44: loss=0.0135 
[epoch 30] step 26/44: loss=0.0140 
[epoch 30] step 28/44: loss=0.0140 
[epoch 30] step 30/44: loss=0.0139 
[epoch 30] step 32/44: loss=0.0139 
[epoch 30] step 34/44: loss=0.0138 
[epoch 30] step 36/44: loss=0.0136 
[epoch 30] step 38/44: loss=0.0139 
[epoch 30] step 40/44: loss=0.0138 
[epoch 30] step 42/44: loss=0.0137 
[epoch 30] step 44/44: loss=0.0136 
[epoch 30] val_loss=2.0172 qwk=('0.6358', '0.5884', '0.6304') averageQWK=0.6182 macroEMD=0.1722 tailR0=('0.1152', '0.0417', '0.1000') tailR0avg=0.0856
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    2    0    0
     0   16   36    2    0
     0   13   71   41    0
     0    0   25   91    0
     0    0    1   19    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   17   28    7    0
     0   15   69   37    0
     0    0   28  104    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   44   25    0    0
     0   27  111   13    0
     0    3   46   52    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=0.0178 
[epoch 31] step 4/44: loss=0.0136 
[epoch 31] step 6/44: loss=0.0122 
[epoch 31] step 8/44: loss=0.0112 
[epoch 31] step 10/44: loss=0.0115 
[epoch 31] step 12/44: loss=0.0114 
[epoch 31] step 14/44: loss=0.0116 
[epoch 31] step 16/44: loss=0.0112 
[epoch 31] step 18/44: loss=0.0115 
[epoch 31] step 20/44: loss=0.0114 
[epoch 31] step 22/44: loss=0.0118 
[epoch 31] step 24/44: loss=0.0118 
[epoch 31] step 26/44: loss=0.0116 
[epoch 31] step 28/44: loss=0.0113 
[epoch 31] step 30/44: loss=0.0110 
[epoch 31] step 32/44: loss=0.0112 
[epoch 31] step 34/44: loss=0.0111 
[epoch 31] step 36/44: loss=0.0110 
[epoch 31] step 38/44: loss=0.0114 
[epoch 31] step 40/44: loss=0.0113 
[epoch 31] step 42/44: loss=0.0111 
[epoch 31] step 44/44: loss=0.0111 
[epoch 31] val_loss=2.0536 qwk=('0.6246', '0.5856', '0.6388') averageQWK=0.6163 macroEMD=0.1724 tailR0=('0.1087', '0.0417', '0.1000') tailR0avg=0.0835
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   15   37    2    0
     0   11   70   44    0
     0    0   25   90    1
     0    0    2   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   17   28    7    0
     0   16   67   38    0
     0    0   28  103    2
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   38   30    1    0
     0   18  116   17    0
     0    1   43   57    0
     0    0    0    2    0
[epoch 32] step 2/44: loss=0.0092 
[epoch 32] step 4/44: loss=0.0082 
[epoch 32] step 6/44: loss=0.0087 
[epoch 32] step 8/44: loss=0.0098 
[epoch 32] step 10/44: loss=0.0097 
[epoch 32] step 12/44: loss=0.0094 
[epoch 32] step 14/44: loss=0.0092 
[epoch 32] step 16/44: loss=0.0090 
[epoch 32] step 18/44: loss=0.0097 
[epoch 32] step 20/44: loss=0.0097 
[epoch 32] step 22/44: loss=0.0099 
[epoch 32] step 24/44: loss=0.0098 
[epoch 32] step 26/44: loss=0.0099 
[epoch 32] step 28/44: loss=0.0097 
[epoch 32] step 30/44: loss=0.0096 
[epoch 32] step 32/44: loss=0.0095 
[epoch 32] step 34/44: loss=0.0093 
[epoch 32] step 36/44: loss=0.0095 
[epoch 32] step 38/44: loss=0.0096 
[epoch 32] step 40/44: loss=0.0096 
[epoch 32] step 42/44: loss=0.0096 
[epoch 32] step 44/44: loss=0.0099 
[epoch 32] val_loss=2.0637 qwk=('0.6472', '0.5785', '0.6256') averageQWK=0.6171 macroEMD=0.1710 tailR0=('0.1804', '0.1250', '0.1000') tailR0avg=0.1351
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    2    0    0
     0   15   37    2    0
     0   11   73   40    1
     0    0   23   92    1
     0    0    1   16    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   13   32    7    0
     0   14   69   38    0
     0    0   29  102    2
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   38   30    1    0
     0   19  117   15    0
     0    1   47   53    0
     0    0    0    2    0
[epoch 33] step 2/44: loss=0.0075 
[epoch 33] step 4/44: loss=0.0071 
[epoch 33] step 6/44: loss=0.0081 
[epoch 33] step 8/44: loss=0.0086 
[epoch 33] step 10/44: loss=0.0099 
[epoch 33] step 12/44: loss=0.0095 
[epoch 33] step 14/44: loss=0.0094 
[epoch 33] step 16/44: loss=0.0092 
[epoch 33] step 18/44: loss=0.0090 
[epoch 33] step 20/44: loss=0.0091 
[epoch 33] step 22/44: loss=0.0092 
[epoch 33] step 24/44: loss=0.0090 
[epoch 33] step 26/44: loss=0.0089 
[epoch 33] step 28/44: loss=0.0088 
[epoch 33] step 30/44: loss=0.0088 
[epoch 33] step 32/44: loss=0.0087 
[epoch 33] step 34/44: loss=0.0086 
[epoch 33] step 36/44: loss=0.0087 
[epoch 33] step 38/44: loss=0.0089 
[epoch 33] step 40/44: loss=0.0089 
[epoch 33] step 42/44: loss=0.0089 
[epoch 33] step 44/44: loss=0.0088 
[epoch 33] val_loss=2.0831 qwk=('0.6419', '0.5737', '0.6292') averageQWK=0.6149 macroEMD=0.1732 tailR0=('0.1087', '0.0833', '0.1000') tailR0avg=0.0973
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   15   37    2    0
     0   11   71   43    0
     0    0   22   94    0
     0    0    1   17    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   15   31    6    0
     0   14   73   34    0
     0    0   34   97    2
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   40   27    2    0
     0   25  106   20    0
     0    1   41   59    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=0.0053 
[epoch 34] step 4/44: loss=0.0057 
[epoch 34] step 6/44: loss=0.0065 
[epoch 34] step 8/44: loss=0.0069 
[epoch 34] step 10/44: loss=0.0076 
[epoch 34] step 12/44: loss=0.0074 
[epoch 34] step 14/44: loss=0.0075 
[epoch 34] step 16/44: loss=0.0079 
[epoch 34] step 18/44: loss=0.0080 
[epoch 34] step 20/44: loss=0.0080 
[epoch 34] step 22/44: loss=0.0079 
[epoch 34] step 24/44: loss=0.0078 
[epoch 34] step 26/44: loss=0.0079 
[epoch 34] step 28/44: loss=0.0080 
[epoch 34] step 30/44: loss=0.0081 
[epoch 34] step 32/44: loss=0.0080 
[epoch 34] step 34/44: loss=0.0078 
[epoch 34] step 36/44: loss=0.0078 
[epoch 34] step 38/44: loss=0.0078 
[epoch 34] step 40/44: loss=0.0078 
[epoch 34] step 42/44: loss=0.0080 
[epoch 34] step 44/44: loss=0.0080 
[epoch 34] val_loss=2.1015 qwk=('0.6292', '0.5803', '0.6374') averageQWK=0.6156 macroEMD=0.1738 tailR0=('0.1087', '0.0833', '0.1000') tailR0avg=0.0973
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   15   37    2    0
     0   10   72   43    0
     0    0   24   91    1
     0    0    1   17    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   13   33    6    0
     0   14   72   35    0
     0    0   31  100    2
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   38   30    1    0
     0   19  117   15    0
     0    1   44   56    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=0.0073 
[epoch 35] step 4/44: loss=0.0082 
[epoch 35] step 6/44: loss=0.0088 
[epoch 35] step 8/44: loss=0.0081 
[epoch 35] step 10/44: loss=0.0081 
[epoch 35] step 12/44: loss=0.0080 
[epoch 35] step 14/44: loss=0.0079 
[epoch 35] step 16/44: loss=0.0079 
[epoch 35] step 18/44: loss=0.0078 
[epoch 35] step 20/44: loss=0.0077 
[epoch 35] step 22/44: loss=0.0076 
[epoch 35] step 24/44: loss=0.0076 
[epoch 35] step 26/44: loss=0.0076 
[epoch 35] step 28/44: loss=0.0077 
[epoch 35] step 30/44: loss=0.0076 
[epoch 35] step 32/44: loss=0.0080 
[epoch 35] step 34/44: loss=0.0083 
[epoch 35] step 36/44: loss=0.0082 
[epoch 35] step 38/44: loss=0.0081 
[epoch 35] step 40/44: loss=0.0082 
[epoch 35] step 42/44: loss=0.0081 
[epoch 35] step 44/44: loss=0.0080 
[epoch 35] val_loss=2.1049 qwk=('0.6288', '0.5763', '0.6283') averageQWK=0.6111 macroEMD=0.1735 tailR0=('0.1087', '0.0833', '0.1000') tailR0avg=0.0973
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   15   37    2    0
     0   11   71   42    1
     0    0   22   93    1
     0    0    1   17    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   13   32    7    0
     0   13   71   37    0
     0    0   29  102    2
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   37   30    2    0
     0   18  113   20    0
     0    1   41   59    0
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/ce/fold2/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/ce/fold2/metrics.json
Done.
