[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.9743 
[epoch 1] step 4/44: loss=0.9523 
[epoch 1] step 6/44: loss=0.9328 
[epoch 1] step 8/44: loss=0.9361 
[epoch 1] step 10/44: loss=0.9366 
[epoch 1] step 12/44: loss=0.9360 
[epoch 1] step 14/44: loss=0.9343 
[epoch 1] step 16/44: loss=0.9385 
[epoch 1] step 18/44: loss=0.9370 
[epoch 1] step 20/44: loss=0.9381 
[epoch 1] step 22/44: loss=0.9353 
[epoch 1] step 24/44: loss=0.9351 
[epoch 1] step 26/44: loss=0.9354 
[epoch 1] step 28/44: loss=0.9340 
[epoch 1] step 30/44: loss=0.9325 
[epoch 1] step 32/44: loss=0.9304 
[epoch 1] step 34/44: loss=0.9293 
[epoch 1] step 36/44: loss=0.9261 
[epoch 1] step 38/44: loss=0.9201 
[epoch 1] step 40/44: loss=0.9159 
[epoch 1] step 42/44: loss=0.9117 
[epoch 1] step 44/44: loss=0.9060 
[epoch 1] val_loss=1.5677 qwk=('0.0709', '0.1182', '0.2217') averageQWK=0.1369 macroEMD=0.3658 tailR0=('0.0000', '0.2778', '0.5000') tailR0avg=0.2593
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    4    0
     0   20    2   33    0
     0   45    9   71    0
     0   39   21   56    0
     0    1    6   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     5    0    4    0    0
    20    0   33    0    0
    46    0   75    1    0
    37    0   90    6    0
     0    0   11    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   16   47    1    5
     0   23  106    5   18
     0   15   55   14   17
     0    0    0    0    2
[epoch 2] step 2/44: loss=0.7711 
[epoch 2] step 4/44: loss=0.7713 
[epoch 2] step 6/44: loss=0.7625 
[epoch 2] step 8/44: loss=0.7537 
[epoch 2] step 10/44: loss=0.7463 
[epoch 2] step 12/44: loss=0.7434 
[epoch 2] step 14/44: loss=0.7401 
[epoch 2] step 16/44: loss=0.7372 
[epoch 2] step 18/44: loss=0.7312 
[epoch 2] step 20/44: loss=0.7182 
[epoch 2] step 22/44: loss=0.7120 
[epoch 2] step 24/44: loss=0.7054 
[epoch 2] step 26/44: loss=0.6954 
[epoch 2] step 28/44: loss=0.6911 
[epoch 2] step 30/44: loss=0.6837 
[epoch 2] step 32/44: loss=0.6789 
[epoch 2] step 34/44: loss=0.6761 
[epoch 2] step 36/44: loss=0.6741 
[epoch 2] step 38/44: loss=0.6695 
[epoch 2] step 40/44: loss=0.6672 
[epoch 2] step 42/44: loss=0.6635 
[epoch 2] step 44/44: loss=0.6621 
[epoch 2] val_loss=1.1822 qwk=('0.1280', '0.2928', '0.3553') averageQWK=0.2587 macroEMD=0.3178 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    5    0
     0    0   12   43    0
     0    0   15  110    0
     0    0    3  113    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   28   25    0
     0    0   34   88    0
     0    0    7  126    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    0   57   12    0
     0    0   68   84    0
     0    0   16   85    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=0.5532 
[epoch 3] step 4/44: loss=0.5582 
[epoch 3] step 6/44: loss=0.5584 
[epoch 3] step 8/44: loss=0.5626 
[epoch 3] step 10/44: loss=0.5720 
[epoch 3] step 12/44: loss=0.5709 
[epoch 3] step 14/44: loss=0.5733 
[epoch 3] step 16/44: loss=0.5726 
[epoch 3] step 18/44: loss=0.5669 
[epoch 3] step 20/44: loss=0.5678 
[epoch 3] step 22/44: loss=0.5638 
[epoch 3] step 24/44: loss=0.5630 
[epoch 3] step 26/44: loss=0.5643 
[epoch 3] step 28/44: loss=0.5625 
[epoch 3] step 30/44: loss=0.5643 
[epoch 3] step 32/44: loss=0.5649 
[epoch 3] step 34/44: loss=0.5641 
[epoch 3] step 36/44: loss=0.5608 
[epoch 3] step 38/44: loss=0.5576 
[epoch 3] step 40/44: loss=0.5568 
[epoch 3] step 42/44: loss=0.5543 
[epoch 3] step 44/44: loss=0.5542 
[epoch 3] val_loss=1.0715 qwk=('0.4344', '0.4173', '0.4500') averageQWK=0.4339 macroEMD=0.2702 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    0   43   12    0
     0    3   59   63    0
     0    0    8  108    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   39   14    0
     0    0   51   71    0
     0    0    2  131    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    8   54    7    0
     0    2  106   44    0
     0    0   25   76    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=0.6031 
[epoch 4] step 4/44: loss=0.5579 
[epoch 4] step 6/44: loss=0.5586 
[epoch 4] step 8/44: loss=0.5399 
[epoch 4] step 10/44: loss=0.5229 
[epoch 4] step 12/44: loss=0.5195 
[epoch 4] step 14/44: loss=0.5169 
[epoch 4] step 16/44: loss=0.5200 
[epoch 4] step 18/44: loss=0.5132 
[epoch 4] step 20/44: loss=0.5089 
[epoch 4] step 22/44: loss=0.5070 
[epoch 4] step 24/44: loss=0.5042 
[epoch 4] step 26/44: loss=0.4994 
[epoch 4] step 28/44: loss=0.4930 
[epoch 4] step 30/44: loss=0.4985 
[epoch 4] step 32/44: loss=0.4992 
[epoch 4] step 34/44: loss=0.4965 
[epoch 4] step 36/44: loss=0.4969 
[epoch 4] step 38/44: loss=0.4961 
[epoch 4] step 40/44: loss=0.4948 
[epoch 4] step 42/44: loss=0.4961 
[epoch 4] step 44/44: loss=0.4917 
[epoch 4] val_loss=0.9967 qwk=('0.4575', '0.5279', '0.5198') averageQWK=0.5017 macroEMD=0.2333 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    3   47    5    0
     0    3   85   37    0
     0    0   29   87    0
     0    0    4   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    0
     0    3   46    4    0
     0    3   83   36    0
     0    0   23  110    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   17   47    5    0
     0   11   91   50    0
     0    0   20   81    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=0.4431 
[epoch 5] step 4/44: loss=0.4300 
[epoch 5] step 6/44: loss=0.4486 
[epoch 5] step 8/44: loss=0.4392 
[epoch 5] step 10/44: loss=0.4337 
[epoch 5] step 12/44: loss=0.4429 
[epoch 5] step 14/44: loss=0.4473 
[epoch 5] step 16/44: loss=0.4455 
[epoch 5] step 18/44: loss=0.4519 
[epoch 5] step 20/44: loss=0.4525 
[epoch 5] step 22/44: loss=0.4566 
[epoch 5] step 24/44: loss=0.4564 
[epoch 5] step 26/44: loss=0.4535 
[epoch 5] step 28/44: loss=0.4529 
[epoch 5] step 30/44: loss=0.4565 
[epoch 5] step 32/44: loss=0.4575 
[epoch 5] step 34/44: loss=0.4627 
[epoch 5] step 36/44: loss=0.4652 
[epoch 5] step 38/44: loss=0.4662 
[epoch 5] step 40/44: loss=0.4608 
[epoch 5] step 42/44: loss=0.4627 
[epoch 5] step 44/44: loss=0.4601 
[epoch 5] val_loss=0.9601 qwk=('0.6014', '0.5574', '0.5465') averageQWK=0.5684 macroEMD=0.2270 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   26   25    4    0
     0   24   61   40    0
     0    0   24   92    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   13   34    6    0
     0   12   70   40    0
     0    0   24  109    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   17   49    3    0
     0    9   99   44    0
     0    0   23   78    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=0.3825 
[epoch 6] step 4/44: loss=0.4134 
[epoch 6] step 6/44: loss=0.4100 
[epoch 6] step 8/44: loss=0.4139 
[epoch 6] step 10/44: loss=0.4089 
[epoch 6] step 12/44: loss=0.4107 
[epoch 6] step 14/44: loss=0.4117 
[epoch 6] step 16/44: loss=0.4086 
[epoch 6] step 18/44: loss=0.4007 
[epoch 6] step 20/44: loss=0.4040 
[epoch 6] step 22/44: loss=0.4080 
[epoch 6] step 24/44: loss=0.4064 
[epoch 6] step 26/44: loss=0.4088 
[epoch 6] step 28/44: loss=0.4073 
[epoch 6] step 30/44: loss=0.4067 
[epoch 6] step 32/44: loss=0.4075 
[epoch 6] step 34/44: loss=0.4094 
[epoch 6] step 36/44: loss=0.4125 
[epoch 6] step 38/44: loss=0.4117 
[epoch 6] step 40/44: loss=0.4133 
[epoch 6] step 42/44: loss=0.4121 
[epoch 6] step 44/44: loss=0.4092 
[epoch 6] val_loss=1.1171 qwk=('0.5557', '0.4904', '0.5220') averageQWK=0.5227 macroEMD=0.2255 tailR0=('0.1957', '0.0000', '0.0000') tailR0avg=0.0652
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   12   33   10    0
     0    8   49   65    3
     0    0    8   95   13
     0    0    0   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0    7   35   11    0
     0    4   59   59    0
     0    0    9  124    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   13   52    4    0
     0    3   98   51    0
     0    0   19   82    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=0.3474 
[epoch 7] step 4/44: loss=0.3719 
[epoch 7] step 6/44: loss=0.3655 
[epoch 7] step 8/44: loss=0.3658 
[epoch 7] step 10/44: loss=0.3659 
[epoch 7] step 12/44: loss=0.3668 
[epoch 7] step 14/44: loss=0.3744 
[epoch 7] step 16/44: loss=0.3735 
[epoch 7] step 18/44: loss=0.3777 
[epoch 7] step 20/44: loss=0.3724 
[epoch 7] step 22/44: loss=0.3690 
[epoch 7] step 24/44: loss=0.3687 
[epoch 7] step 26/44: loss=0.3685 
[epoch 7] step 28/44: loss=0.3650 
[epoch 7] step 30/44: loss=0.3686 
[epoch 7] step 32/44: loss=0.3659 
[epoch 7] step 34/44: loss=0.3637 
[epoch 7] step 36/44: loss=0.3621 
[epoch 7] step 38/44: loss=0.3654 
[epoch 7] step 40/44: loss=0.3633 
[epoch 7] step 42/44: loss=0.3659 
[epoch 7] step 44/44: loss=0.3634 
[epoch 7] val_loss=1.1210 qwk=('0.6410', '0.5542', '0.5343') averageQWK=0.5765 macroEMD=0.2086 tailR0=('0.3043', '0.0000', '0.0000') tailR0avg=0.1014
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   15   36    4    0
     0    9   71   40    5
     0    0   14   81   21
     0    0    1    8   14
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   14   29   10    0
     0    7   70   45    0
     0    0   15  117    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   17   47    5    0
     0    4   86   62    0
     0    0   16   85    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=0.3246 
[epoch 8] step 4/44: loss=0.3178 
[epoch 8] step 6/44: loss=0.3270 
[epoch 8] step 8/44: loss=0.3218 
[epoch 8] step 10/44: loss=0.3210 
[epoch 8] step 12/44: loss=0.3316 
[epoch 8] step 14/44: loss=0.3373 
[epoch 8] step 16/44: loss=0.3449 
[epoch 8] step 18/44: loss=0.3398 
[epoch 8] step 20/44: loss=0.3325 
[epoch 8] step 22/44: loss=0.3365 
[epoch 8] step 24/44: loss=0.3385 
[epoch 8] step 26/44: loss=0.3394 
[epoch 8] step 28/44: loss=0.3351 
[epoch 8] step 30/44: loss=0.3355 
[epoch 8] step 32/44: loss=0.3351 
[epoch 8] step 34/44: loss=0.3309 
[epoch 8] step 36/44: loss=0.3316 
[epoch 8] step 38/44: loss=0.3321 
[epoch 8] step 40/44: loss=0.3334 
[epoch 8] step 42/44: loss=0.3360 
[epoch 8] step 44/44: loss=0.3314 
[epoch 8] val_loss=1.0239 qwk=('0.6039', '0.6076', '0.5690') averageQWK=0.5935 macroEMD=0.2086 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   18   35    2    0
     0   10   80   35    0
     0    0   26   88    2
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   18   31    4    0
     0   12   83   27    0
     0    0   29  104    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   26   42    1    0
     0   17  104   31    0
     0    0   37   64    0
     0    0    1    1    0
[epoch 9] step 2/44: loss=0.2945 
[epoch 9] step 4/44: loss=0.3088 
[epoch 9] step 6/44: loss=0.3406 
[epoch 9] step 8/44: loss=0.3537 
[epoch 9] step 10/44: loss=0.3311 
[epoch 9] step 12/44: loss=0.3311 
[epoch 9] step 14/44: loss=0.3352 
[epoch 9] step 16/44: loss=0.3312 
[epoch 9] step 18/44: loss=0.3288 
[epoch 9] step 20/44: loss=0.3239 
[epoch 9] step 22/44: loss=0.3214 
[epoch 9] step 24/44: loss=0.3217 
[epoch 9] step 26/44: loss=0.3196 
[epoch 9] step 28/44: loss=0.3157 
[epoch 9] step 30/44: loss=0.3142 
[epoch 9] step 32/44: loss=0.3169 
[epoch 9] step 34/44: loss=0.3146 
[epoch 9] step 36/44: loss=0.3124 
[epoch 9] step 38/44: loss=0.3113 
[epoch 9] step 40/44: loss=0.3105 
[epoch 9] step 42/44: loss=0.3077 
[epoch 9] step 44/44: loss=0.3086 
[epoch 9] val_loss=1.0378 qwk=('0.6145', '0.6343', '0.5821') averageQWK=0.6103 macroEMD=0.2004 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   22   32    1    0
     0   15   74   34    2
     0    0   27   83    6
     0    0    4   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   22   25    6    0
     0   18   69   35    0
     0    0   14  119    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   34   35    0    0
     0   26   91   35    0
     0    2   36   63    0
     0    0    1    1    0
[epoch 10] step 2/44: loss=0.2616 
[epoch 10] step 4/44: loss=0.2665 
[epoch 10] step 6/44: loss=0.2604 
[epoch 10] step 8/44: loss=0.2591 
[epoch 10] step 10/44: loss=0.2622 
[epoch 10] step 12/44: loss=0.2576 
[epoch 10] step 14/44: loss=0.2574 
[epoch 10] step 16/44: loss=0.2594 
[epoch 10] step 18/44: loss=0.2638 
[epoch 10] step 20/44: loss=0.2665 
[epoch 10] step 22/44: loss=0.2690 
[epoch 10] step 24/44: loss=0.2687 
[epoch 10] step 26/44: loss=0.2673 
[epoch 10] step 28/44: loss=0.2654 
[epoch 10] step 30/44: loss=0.2677 
[epoch 10] step 32/44: loss=0.2665 
[epoch 10] step 34/44: loss=0.2659 
[epoch 10] step 36/44: loss=0.2670 
[epoch 10] step 38/44: loss=0.2681 
[epoch 10] step 40/44: loss=0.2677 
[epoch 10] step 42/44: loss=0.2665 
[epoch 10] step 44/44: loss=0.2676 
[epoch 10] val_loss=1.1574 qwk=('0.5887', '0.6013', '0.5857') averageQWK=0.5919 macroEMD=0.2046 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   15   38    2    0
     0   10   69   45    1
     0    0   19   92    5
     0    0    2   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   18   26    9    0
     0   11   59   52    0
     0    0   11  122    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   21   48    0    0
     0    5  108   39    0
     0    0   30   71    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.2290 
[epoch 11] step 4/44: loss=0.2361 
[epoch 11] step 6/44: loss=0.2409 
[epoch 11] step 8/44: loss=0.2412 
[epoch 11] step 10/44: loss=0.2363 
[epoch 11] step 12/44: loss=0.2320 
[epoch 11] step 14/44: loss=0.2316 
[epoch 11] step 16/44: loss=0.2361 
[epoch 11] step 18/44: loss=0.2337 
[epoch 11] step 20/44: loss=0.2359 
[epoch 11] step 22/44: loss=0.2368 
[epoch 11] step 24/44: loss=0.2381 
[epoch 11] step 26/44: loss=0.2419 
[epoch 11] step 28/44: loss=0.2443 
[epoch 11] step 30/44: loss=0.2418 
[epoch 11] step 32/44: loss=0.2399 
[epoch 11] step 34/44: loss=0.2401 
[epoch 11] step 36/44: loss=0.2377 
[epoch 11] step 38/44: loss=0.2381 
[epoch 11] step 40/44: loss=0.2359 
[epoch 11] step 42/44: loss=0.2331 
[epoch 11] step 44/44: loss=0.2397 
[epoch 11] val_loss=1.2188 qwk=('0.5738', '0.5734', '0.5872') averageQWK=0.5781 macroEMD=0.2015 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   13   40    2    0
     0   10   70   44    1
     0    0   19   94    3
     0    0    2   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   12   36    5    0
     0    8   79   34    1
     0    0   27  104    2
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   21   47    1    0
     0   12  104   36    0
     0    0   29   72    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=0.1706 
[epoch 12] step 4/44: loss=0.1919 
[epoch 12] step 6/44: loss=0.2026 
[epoch 12] step 8/44: loss=0.1998 
[epoch 12] step 10/44: loss=0.2040 
[epoch 12] step 12/44: loss=0.2058 
[epoch 12] step 14/44: loss=0.2068 
[epoch 12] step 16/44: loss=0.2039 
[epoch 12] step 18/44: loss=0.2066 
[epoch 12] step 20/44: loss=0.2079 
[epoch 12] step 22/44: loss=0.2083 
[epoch 12] step 24/44: loss=0.2112 
[epoch 12] step 26/44: loss=0.2109 
[epoch 12] step 28/44: loss=0.2106 
[epoch 12] step 30/44: loss=0.2086 
[epoch 12] step 32/44: loss=0.2086 
[epoch 12] step 34/44: loss=0.2101 
[epoch 12] step 36/44: loss=0.2103 
[epoch 12] step 38/44: loss=0.2107 
[epoch 12] step 40/44: loss=0.2104 
[epoch 12] step 42/44: loss=0.2109 
[epoch 12] step 44/44: loss=0.2134 
[epoch 12] val_loss=1.2339 qwk=('0.6306', '0.5971', '0.5784') averageQWK=0.6020 macroEMD=0.1991 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   19   35    1    0
     0   11   74   39    1
     0    0   25   84    7
     0    0    1   16    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   14   35    4    0
     0   11   81   28    2
     0    0   22  109    2
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   23   46    0    0
     0   14  103   35    0
     0    0   30   71    0
     0    0    1    1    0
[epoch 13] step 2/44: loss=0.1708 
[epoch 13] step 4/44: loss=0.1877 
[epoch 13] step 6/44: loss=0.1947 
[epoch 13] step 8/44: loss=0.1963 
[epoch 13] step 10/44: loss=0.1867 
[epoch 13] step 12/44: loss=0.1853 
[epoch 13] step 14/44: loss=0.1864 
[epoch 13] step 16/44: loss=0.1855 
[epoch 13] step 18/44: loss=0.1859 
[epoch 13] step 20/44: loss=0.1880 
[epoch 13] step 22/44: loss=0.1859 
[epoch 13] step 24/44: loss=0.1849 
[epoch 13] step 26/44: loss=0.1844 
[epoch 13] step 28/44: loss=0.1852 
[epoch 13] step 30/44: loss=0.1830 
[epoch 13] step 32/44: loss=0.1824 
[epoch 13] step 34/44: loss=0.1820 
[epoch 13] step 36/44: loss=0.1822 
[epoch 13] step 38/44: loss=0.1830 
[epoch 13] step 40/44: loss=0.1830 
[epoch 13] step 42/44: loss=0.1823 
[epoch 13] step 44/44: loss=0.1841 
[epoch 13] val_loss=1.3574 qwk=('0.6209', '0.5853', '0.5726') averageQWK=0.5929 macroEMD=0.1953 tailR0=('0.1739', '0.0000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   18   33    4    0
     0   11   69   44    1
     0    0   17   90    9
     0    0    1   14    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   17   27    9    0
     0   15   59   47    1
     0    0   12  119    2
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   23   45    1    0
     0   17   80   55    0
     0    0   24   77    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.2051 
[epoch 14] step 4/44: loss=0.1942 
[epoch 14] step 6/44: loss=0.1887 
[epoch 14] step 8/44: loss=0.1786 
[epoch 14] step 10/44: loss=0.1742 
[epoch 14] step 12/44: loss=0.1696 
[epoch 14] step 14/44: loss=0.1723 
[epoch 14] step 16/44: loss=0.1699 
[epoch 14] step 18/44: loss=0.1685 
[epoch 14] step 20/44: loss=0.1685 
[epoch 14] step 22/44: loss=0.1646 
[epoch 14] step 24/44: loss=0.1629 
[epoch 14] step 26/44: loss=0.1637 
[epoch 14] step 28/44: loss=0.1618 
[epoch 14] step 30/44: loss=0.1617 
[epoch 14] step 32/44: loss=0.1616 
[epoch 14] step 34/44: loss=0.1603 
[epoch 14] step 36/44: loss=0.1603 
[epoch 14] step 38/44: loss=0.1605 
[epoch 14] step 40/44: loss=0.1603 
[epoch 14] step 42/44: loss=0.1593 
[epoch 14] step 44/44: loss=0.1579 
[epoch 14] val_loss=1.3648 qwk=('0.5644', '0.6184', '0.5411') averageQWK=0.5746 macroEMD=0.2106 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   11   44    0    0
     0    5   88   31    1
     0    0   33   78    5
     0    0    4   18    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   13   35    5    0
     0    9   82   31    0
     0    0   17  116    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   23   46    0    0
     0   11  114   27    0
     0    0   41   60    0
     0    0    1    1    0
[epoch 15] step 2/44: loss=0.1399 
[epoch 15] step 4/44: loss=0.1453 
[epoch 15] step 6/44: loss=0.1439 
[epoch 15] step 8/44: loss=0.1375 
[epoch 15] step 10/44: loss=0.1356 
[epoch 15] step 12/44: loss=0.1363 
[epoch 15] step 14/44: loss=0.1356 
[epoch 15] step 16/44: loss=0.1331 
[epoch 15] step 18/44: loss=0.1379 
[epoch 15] step 20/44: loss=0.1416 
[epoch 15] step 22/44: loss=0.1434 
[epoch 15] step 24/44: loss=0.1443 
[epoch 15] step 26/44: loss=0.1459 
[epoch 15] step 28/44: loss=0.1474 
[epoch 15] step 30/44: loss=0.1457 
[epoch 15] step 32/44: loss=0.1484 
[epoch 15] step 34/44: loss=0.1491 
[epoch 15] step 36/44: loss=0.1482 
[epoch 15] step 38/44: loss=0.1484 
[epoch 15] step 40/44: loss=0.1503 
[epoch 15] step 42/44: loss=0.1502 
[epoch 15] step 44/44: loss=0.1488 
[epoch 15] val_loss=1.4711 qwk=('0.5474', '0.6016', '0.5255') averageQWK=0.5582 macroEMD=0.2096 tailR0=('0.0435', '0.0417', '0.0000') tailR0avg=0.0284
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   10   40    5    0
     0    6   74   44    1
     0    0   23   88    5
     0    0    1   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0    9   38    6    0
     0    8   81   31    2
     0    0   15  117    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   16   53    0    0
     0    8  113   31    0
     0    0   36   65    0
     0    0    1    1    0
[epoch 16] step 2/44: loss=0.1687 
[epoch 16] step 4/44: loss=0.1426 
[epoch 16] step 6/44: loss=0.1349 
[epoch 16] step 8/44: loss=0.1290 
[epoch 16] step 10/44: loss=0.1252 
[epoch 16] step 12/44: loss=0.1286 
[epoch 16] step 14/44: loss=0.1280 
[epoch 16] step 16/44: loss=0.1253 
[epoch 16] step 18/44: loss=0.1262 
[epoch 16] step 20/44: loss=0.1279 
[epoch 16] step 22/44: loss=0.1294 
[epoch 16] step 24/44: loss=0.1284 
[epoch 16] step 26/44: loss=0.1268 
[epoch 16] step 28/44: loss=0.1266 
[epoch 16] step 30/44: loss=0.1240 
[epoch 16] step 32/44: loss=0.1237 
[epoch 16] step 34/44: loss=0.1222 
[epoch 16] step 36/44: loss=0.1220 
[epoch 16] step 38/44: loss=0.1214 
[epoch 16] step 40/44: loss=0.1210 
[epoch 16] step 42/44: loss=0.1210 
[epoch 16] step 44/44: loss=0.1216 
[epoch 16] val_loss=1.5015 qwk=('0.5714', '0.5646', '0.5560') averageQWK=0.5640 macroEMD=0.2023 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   19   34    2    0
     0   12   73   40    0
     0    1   27   82    6
     0    0    3   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   15   32    6    0
     0   13   78   29    2
     0    1   28  102    2
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   18   51    0    0
     0   11  105   36    0
     0    0   33   68    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=0.0947 
[epoch 17] step 4/44: loss=0.1040 
[epoch 17] step 6/44: loss=0.1059 
[epoch 17] step 8/44: loss=0.1102 
[epoch 17] step 10/44: loss=0.1074 
[epoch 17] step 12/44: loss=0.1069 
[epoch 17] step 14/44: loss=0.1034 
[epoch 17] step 16/44: loss=0.1029 
[epoch 17] step 18/44: loss=0.1016 
[epoch 17] step 20/44: loss=0.1024 
[epoch 17] step 22/44: loss=0.1003 
[epoch 17] step 24/44: loss=0.0995 
[epoch 17] step 26/44: loss=0.1003 
[epoch 17] step 28/44: loss=0.0994 
[epoch 17] step 30/44: loss=0.1008 
[epoch 17] step 32/44: loss=0.1034 
[epoch 17] step 34/44: loss=0.1065 
[epoch 17] step 36/44: loss=0.1066 
[epoch 17] step 38/44: loss=0.1064 
[epoch 17] step 40/44: loss=0.1081 
[epoch 17] step 42/44: loss=0.1090 
[epoch 17] step 44/44: loss=0.1098 
[epoch 17] val_loss=1.6429 qwk=('0.5327', '0.5627', '0.5781') averageQWK=0.5578 macroEMD=0.2036 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0    9   40    6    0
     0    6   62   56    1
     0    0   17   93    6
     0    0    1   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0    8   38    7    0
     0    6   77   37    2
     0    0   16  114    3
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   22   47    0    0
     0   10  105   37    0
     0    0   32   69    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=0.1034 
[epoch 18] step 4/44: loss=0.1146 
[epoch 18] step 6/44: loss=0.1140 
[epoch 18] step 8/44: loss=0.1089 
[epoch 18] step 10/44: loss=0.1086 
[epoch 18] step 12/44: loss=0.1043 
[epoch 18] step 14/44: loss=0.1041 
[epoch 18] step 16/44: loss=0.1036 
[epoch 18] step 18/44: loss=0.1024 
[epoch 18] step 20/44: loss=0.0998 
[epoch 18] step 22/44: loss=0.1003 
[epoch 18] step 24/44: loss=0.0993 
[epoch 18] step 26/44: loss=0.0981 
[epoch 18] step 28/44: loss=0.0976 
[epoch 18] step 30/44: loss=0.0962 
[epoch 18] step 32/44: loss=0.0952 
[epoch 18] step 34/44: loss=0.0949 
[epoch 18] step 36/44: loss=0.0944 
[epoch 18] step 38/44: loss=0.0937 
[epoch 18] step 40/44: loss=0.0932 
[epoch 18] step 42/44: loss=0.0929 
[epoch 18] step 44/44: loss=0.0923 
[epoch 18] val_loss=1.4986 qwk=('0.6051', '0.5928', '0.6103') averageQWK=0.6027 macroEMD=0.1957 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   22   30    3    0
     0   12   77   34    2
     0    0   29   78    9
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   20   27    6    0
     0   19   70   31    2
     0    2   22  108    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   37   32    0    0
     0   20  104   28    0
     0    0   41   60    0
     0    0    2    0    0
[epoch 19] step 2/44: loss=0.0758 
[epoch 19] step 4/44: loss=0.0783 
[epoch 19] step 6/44: loss=0.0725 
[epoch 19] step 8/44: loss=0.0703 
[epoch 19] step 10/44: loss=0.0706 
[epoch 19] step 12/44: loss=0.0697 
[epoch 19] step 14/44: loss=0.0715 
[epoch 19] step 16/44: loss=0.0716 
[epoch 19] step 18/44: loss=0.0714 
[epoch 19] step 20/44: loss=0.0723 
[epoch 19] step 22/44: loss=0.0726 
[epoch 19] step 24/44: loss=0.0728 
[epoch 19] step 26/44: loss=0.0725 
[epoch 19] step 28/44: loss=0.0716 
[epoch 19] step 30/44: loss=0.0721 
[epoch 19] step 32/44: loss=0.0724 
[epoch 19] step 34/44: loss=0.0722 
[epoch 19] step 36/44: loss=0.0738 
[epoch 19] step 38/44: loss=0.0738 
[epoch 19] step 40/44: loss=0.0720 
[epoch 19] step 42/44: loss=0.0721 
[epoch 19] step 44/44: loss=0.0732 
[epoch 19] val_loss=1.6752 qwk=('0.5683', '0.5357', '0.6278') averageQWK=0.5773 macroEMD=0.1962 tailR0=('0.0870', '0.0000', '0.0000') tailR0avg=0.0290
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    0    0
     0    9   43    3    0
     0    6   79   39    1
     0    0   24   83    9
     0    0    2   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   16   27   10    0
     0   12   58   51    1
     0    1   11  118    3
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   39   30    0    0
     0   25   98   29    0
     0    1   38   62    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=0.0785 
[epoch 20] step 4/44: loss=0.0820 
[epoch 20] step 6/44: loss=0.0771 
[epoch 20] step 8/44: loss=0.0723 
[epoch 20] step 10/44: loss=0.0706 
[epoch 20] step 12/44: loss=0.0693 
[epoch 20] step 14/44: loss=0.0669 
[epoch 20] step 16/44: loss=0.0669 
[epoch 20] step 18/44: loss=0.0655 
[epoch 20] step 20/44: loss=0.0640 
[epoch 20] step 22/44: loss=0.0646 
[epoch 20] step 24/44: loss=0.0630 
[epoch 20] step 26/44: loss=0.0621 
[epoch 20] step 28/44: loss=0.0612 
[epoch 20] step 30/44: loss=0.0602 
[epoch 20] step 32/44: loss=0.0604 
[epoch 20] step 34/44: loss=0.0603 
[epoch 20] step 36/44: loss=0.0597 
[epoch 20] step 38/44: loss=0.0598 
[epoch 20] step 40/44: loss=0.0604 
[epoch 20] step 42/44: loss=0.0609 
[epoch 20] step 44/44: loss=0.0611 
[epoch 20] val_loss=1.7768 qwk=('0.5747', '0.5793', '0.5746') averageQWK=0.5762 macroEMD=0.2004 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   15   36    4    0
     0   12   65   48    0
     0    0   22   88    6
     0    0    1   19    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   14   33    6    0
     0   12   69   39    2
     0    0   15  113    5
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   44    0    0
     0   17   99   36    0
     0    0   34   67    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=0.0582 
[epoch 21] step 4/44: loss=0.0527 
[epoch 21] step 6/44: loss=0.0544 
[epoch 21] step 8/44: loss=0.0532 
[epoch 21] step 10/44: loss=0.0517 
[epoch 21] step 12/44: loss=0.0522 
[epoch 21] step 14/44: loss=0.0515 
[epoch 21] step 16/44: loss=0.0517 
[epoch 21] step 18/44: loss=0.0506 
[epoch 21] step 20/44: loss=0.0497 
[epoch 21] step 22/44: loss=0.0483 
[epoch 21] step 24/44: loss=0.0487 
[epoch 21] step 26/44: loss=0.0490 
[epoch 21] step 28/44: loss=0.0486 
[epoch 21] step 30/44: loss=0.0487 
[epoch 21] step 32/44: loss=0.0485 
[epoch 21] step 34/44: loss=0.0474 
[epoch 21] step 36/44: loss=0.0470 
[epoch 21] step 38/44: loss=0.0475 
[epoch 21] step 40/44: loss=0.0479 
[epoch 21] step 42/44: loss=0.0482 
[epoch 21] step 44/44: loss=0.0480 
[epoch 21] val_loss=1.8074 qwk=('0.5631', '0.5745', '0.5772') averageQWK=0.5716 macroEMD=0.2029 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   12   40    3    0
     0   10   72   43    0
     0    0   23   90    3
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   17   30    6    0
     0   14   71   35    2
     0    0   20  112    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   28   41    0    0
     0   13  109   30    0
     0    0   41   60    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=0.0453 
[epoch 22] step 4/44: loss=0.0473 
[epoch 22] step 6/44: loss=0.0412 
[epoch 22] step 8/44: loss=0.0397 
[epoch 22] step 10/44: loss=0.0373 
[epoch 22] step 12/44: loss=0.0381 
[epoch 22] step 14/44: loss=0.0386 
[epoch 22] step 16/44: loss=0.0387 
[epoch 22] step 18/44: loss=0.0388 
[epoch 22] step 20/44: loss=0.0382 
[epoch 22] step 22/44: loss=0.0393 
[epoch 22] step 24/44: loss=0.0383 
[epoch 22] step 26/44: loss=0.0378 
[epoch 22] step 28/44: loss=0.0376 
[epoch 22] step 30/44: loss=0.0377 
[epoch 22] step 32/44: loss=0.0382 
[epoch 22] step 34/44: loss=0.0378 
[epoch 22] step 36/44: loss=0.0378 
[epoch 22] step 38/44: loss=0.0372 
[epoch 22] step 40/44: loss=0.0371 
[epoch 22] step 42/44: loss=0.0376 
[epoch 22] step 44/44: loss=0.0402 
[epoch 22] val_loss=1.8371 qwk=('0.5770', '0.6068', '0.5662') averageQWK=0.5834 macroEMD=0.2021 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   12   42    1    0
     0    8   82   35    0
     0    0   29   84    3
     0    0    3   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   19   28    6    0
     0   17   67   38    0
     0    2   16  115    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   26   43    0    0
     0   17  107   28    0
     0    0   41   60    0
     0    0    1    1    0
[epoch 23] step 2/44: loss=0.0313 
[epoch 23] step 4/44: loss=0.0365 
[epoch 23] step 6/44: loss=0.0371 
[epoch 23] step 8/44: loss=0.0372 
[epoch 23] step 10/44: loss=0.0357 
[epoch 23] step 12/44: loss=0.0345 
[epoch 23] step 14/44: loss=0.0339 
[epoch 23] step 16/44: loss=0.0333 
[epoch 23] step 18/44: loss=0.0321 
[epoch 23] step 20/44: loss=0.0318 
[epoch 23] step 22/44: loss=0.0310 
[epoch 23] step 24/44: loss=0.0312 
[epoch 23] step 26/44: loss=0.0310 
[epoch 23] step 28/44: loss=0.0310 
[epoch 23] step 30/44: loss=0.0307 
[epoch 23] step 32/44: loss=0.0306 
[epoch 23] step 34/44: loss=0.0312 
[epoch 23] step 36/44: loss=0.0313 
[epoch 23] step 38/44: loss=0.0315 
[epoch 23] step 40/44: loss=0.0321 
[epoch 23] step 42/44: loss=0.0324 
[epoch 23] step 44/44: loss=0.0326 
[epoch 23] val_loss=1.8870 qwk=('0.5740', '0.6244', '0.5783') averageQWK=0.5922 macroEMD=0.2028 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   12   40    3    0
     0    8   89   27    1
     0    0   33   76    7
     0    0    2   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   22   25    6    0
     0   19   66   36    1
     0    1   15  116    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   36   33    0    0
     0   23  103   26    0
     0    1   45   55    0
     0    0    2    0    0
[epoch 24] step 2/44: loss=0.0326 
[epoch 24] step 4/44: loss=0.0298 
[epoch 24] step 6/44: loss=0.0275 
[epoch 24] step 8/44: loss=0.0272 
[epoch 24] step 10/44: loss=0.0290 
[epoch 24] step 12/44: loss=0.0288 
[epoch 24] step 14/44: loss=0.0276 
[epoch 24] step 16/44: loss=0.0271 
[epoch 24] step 18/44: loss=0.0273 
[epoch 24] step 20/44: loss=0.0268 
[epoch 24] step 22/44: loss=0.0265 
[epoch 24] step 24/44: loss=0.0266 
[epoch 24] step 26/44: loss=0.0280 
[epoch 24] step 28/44: loss=0.0274 
[epoch 24] step 30/44: loss=0.0279 
[epoch 24] step 32/44: loss=0.0282 
[epoch 24] step 34/44: loss=0.0280 
[epoch 24] step 36/44: loss=0.0277 
[epoch 24] step 38/44: loss=0.0274 
[epoch 24] step 40/44: loss=0.0279 
[epoch 24] step 42/44: loss=0.0275 
[epoch 24] step 44/44: loss=0.0270 
[epoch 24] val_loss=1.9879 qwk=('0.5792', '0.5904', '0.6136') averageQWK=0.5944 macroEMD=0.1969 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   15   36    4    0
     0   11   77   36    1
     0    0   26   82    8
     0    0    2   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   17   30    6    0
     0   16   69   36    1
     0    0   19  112    2
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   33   36    0    0
     0   23   96   33    0
     0    0   37   64    0
     0    0    0    2    0
[epoch 25] step 2/44: loss=0.0227 
[epoch 25] step 4/44: loss=0.0235 
[epoch 25] step 6/44: loss=0.0218 
[epoch 25] step 8/44: loss=0.0216 
[epoch 25] step 10/44: loss=0.0234 
[epoch 25] step 12/44: loss=0.0235 
[epoch 25] step 14/44: loss=0.0243 
[epoch 25] step 16/44: loss=0.0246 
[epoch 25] step 18/44: loss=0.0251 
[epoch 25] step 20/44: loss=0.0249 
[epoch 25] step 22/44: loss=0.0248 
[epoch 25] step 24/44: loss=0.0247 
[epoch 25] step 26/44: loss=0.0245 
[epoch 25] step 28/44: loss=0.0244 
[epoch 25] step 30/44: loss=0.0242 
[epoch 25] step 32/44: loss=0.0239 
[epoch 25] step 34/44: loss=0.0238 
[epoch 25] step 36/44: loss=0.0235 
[epoch 25] step 38/44: loss=0.0241 
[epoch 25] step 40/44: loss=0.0238 
[epoch 25] step 42/44: loss=0.0237 
[epoch 25] step 44/44: loss=0.0238 
[epoch 25] val_loss=1.9953 qwk=('0.6029', '0.5991', '0.6300') averageQWK=0.6107 macroEMD=0.1852 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   20   33    2    0
     0   14   73   38    0
     0    0   27   86    3
     0    0    2   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   21   26    6    0
     0   18   66   36    2
     0    1   18  112    2
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   41   28    0    0
     0   26   91   35    0
     0    1   36   64    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=0.0238 
[epoch 26] step 4/44: loss=0.0201 
[epoch 26] step 6/44: loss=0.0223 
[epoch 26] step 8/44: loss=0.0223 
[epoch 26] step 10/44: loss=0.0227 
[epoch 26] step 12/44: loss=0.0223 
[epoch 26] step 14/44: loss=0.0210 
[epoch 26] step 16/44: loss=0.0204 
[epoch 26] step 18/44: loss=0.0200 
[epoch 26] step 20/44: loss=0.0198 
[epoch 26] step 22/44: loss=0.0202 
[epoch 26] step 24/44: loss=0.0198 
[epoch 26] step 26/44: loss=0.0205 
[epoch 26] step 28/44: loss=0.0205 
[epoch 26] step 30/44: loss=0.0202 
[epoch 26] step 32/44: loss=0.0201 
[epoch 26] step 34/44: loss=0.0198 
[epoch 26] step 36/44: loss=0.0195 
[epoch 26] step 38/44: loss=0.0193 
[epoch 26] step 40/44: loss=0.0193 
[epoch 26] step 42/44: loss=0.0194 
[epoch 26] step 44/44: loss=0.0204 
[epoch 26] val_loss=2.0304 qwk=('0.5860', '0.6043', '0.6273') averageQWK=0.6059 macroEMD=0.1910 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   19   35    1    0
     0   17   77   31    0
     0    0   31   82    3
     0    0    4   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   21   26    6    0
     0   17   77   27    1
     0    1   25  106    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   39   30    0    0
     0   24   96   32    0
     0    1   37   63    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=0.0174 
[epoch 27] step 4/44: loss=0.0214 
[epoch 27] step 6/44: loss=0.0195 
[epoch 27] step 8/44: loss=0.0184 
[epoch 27] step 10/44: loss=0.0189 
[epoch 27] step 12/44: loss=0.0188 
[epoch 27] step 14/44: loss=0.0176 
[epoch 27] step 16/44: loss=0.0173 
[epoch 27] step 18/44: loss=0.0169 
[epoch 27] step 20/44: loss=0.0166 
[epoch 27] step 22/44: loss=0.0168 
[epoch 27] step 24/44: loss=0.0170 
[epoch 27] step 26/44: loss=0.0179 
[epoch 27] step 28/44: loss=0.0187 
[epoch 27] step 30/44: loss=0.0190 
[epoch 27] step 32/44: loss=0.0186 
[epoch 27] step 34/44: loss=0.0185 
[epoch 27] step 36/44: loss=0.0184 
[epoch 27] step 38/44: loss=0.0186 
[epoch 27] step 40/44: loss=0.0182 
[epoch 27] step 42/44: loss=0.0185 
[epoch 27] step 44/44: loss=0.0181 
[epoch 27] val_loss=2.1101 qwk=('0.5633', '0.5882', '0.5665') averageQWK=0.5727 macroEMD=0.2017 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    0    0
     0   11   41    3    0
     0    6   83   36    0
     0    0   28   80    8
     0    0    2   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   18   27    8    0
     0   14   66   41    1
     0    1   13  117    2
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   27   42    0    0
     0   20  102   30    0
     0    0   40   61    0
     0    0    1    1    0
[epoch 28] step 2/44: loss=0.0114 
[epoch 28] step 4/44: loss=0.0168 
[epoch 28] step 6/44: loss=0.0157 
[epoch 28] step 8/44: loss=0.0144 
[epoch 28] step 10/44: loss=0.0142 
[epoch 28] step 12/44: loss=0.0149 
[epoch 28] step 14/44: loss=0.0147 
[epoch 28] step 16/44: loss=0.0150 
[epoch 28] step 18/44: loss=0.0149 
[epoch 28] step 20/44: loss=0.0151 
[epoch 28] step 22/44: loss=0.0151 
[epoch 28] step 24/44: loss=0.0159 
[epoch 28] step 26/44: loss=0.0160 
[epoch 28] step 28/44: loss=0.0157 
[epoch 28] step 30/44: loss=0.0153 
[epoch 28] step 32/44: loss=0.0151 
[epoch 28] step 34/44: loss=0.0151 
[epoch 28] step 36/44: loss=0.0149 
[epoch 28] step 38/44: loss=0.0149 
[epoch 28] step 40/44: loss=0.0151 
[epoch 28] step 42/44: loss=0.0150 
[epoch 28] step 44/44: loss=0.0151 
[epoch 28] val_loss=2.1718 qwk=('0.5457', '0.5818', '0.5870') averageQWK=0.5715 macroEMD=0.2041 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    0    0
     0   11   41    3    0
     0    8   76   41    0
     0    0   27   85    4
     0    0    3   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   15   32    6    0
     0   11   75   35    1
     0    0   21  112    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   37    0    0
     0   21  103   28    0
     0    0   41   60    0
     0    0    1    1    0
[epoch 29] step 2/44: loss=0.0160 
[epoch 29] step 4/44: loss=0.0174 
[epoch 29] step 6/44: loss=0.0152 
[epoch 29] step 8/44: loss=0.0141 
[epoch 29] step 10/44: loss=0.0144 
[epoch 29] step 12/44: loss=0.0138 
[epoch 29] step 14/44: loss=0.0134 
[epoch 29] step 16/44: loss=0.0135 
[epoch 29] step 18/44: loss=0.0142 
[epoch 29] step 20/44: loss=0.0145 
[epoch 29] step 22/44: loss=0.0139 
[epoch 29] step 24/44: loss=0.0136 
[epoch 29] step 26/44: loss=0.0136 
[epoch 29] step 28/44: loss=0.0137 
[epoch 29] step 30/44: loss=0.0138 
[epoch 29] step 32/44: loss=0.0135 
[epoch 29] step 34/44: loss=0.0134 
[epoch 29] step 36/44: loss=0.0135 
[epoch 29] step 38/44: loss=0.0134 
[epoch 29] step 40/44: loss=0.0135 
[epoch 29] step 42/44: loss=0.0133 
[epoch 29] step 44/44: loss=0.0131 
[epoch 29] val_loss=2.1817 qwk=('0.5456', '0.6216', '0.5476') averageQWK=0.5716 macroEMD=0.1988 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    0    0
     0   11   41    3    0
     0    7   81   37    0
     0    0   28   85    3
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   23   24    6    0
     0   17   76   28    1
     0    1   24  108    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   24   45    0    0
     0   14  104   34    0
     0    0   39   62    0
     0    0    1    1    0
[epoch 30] step 2/44: loss=0.0110 
[epoch 30] step 4/44: loss=0.0114 
[epoch 30] step 6/44: loss=0.0137 
[epoch 30] step 8/44: loss=0.0126 
[epoch 30] step 10/44: loss=0.0120 
[epoch 30] step 12/44: loss=0.0114 
[epoch 30] step 14/44: loss=0.0132 
[epoch 30] step 16/44: loss=0.0128 
[epoch 30] step 18/44: loss=0.0129 
[epoch 30] step 20/44: loss=0.0125 
[epoch 30] step 22/44: loss=0.0127 
[epoch 30] step 24/44: loss=0.0125 
[epoch 30] step 26/44: loss=0.0121 
[epoch 30] step 28/44: loss=0.0118 
[epoch 30] step 30/44: loss=0.0118 
[epoch 30] step 32/44: loss=0.0116 
[epoch 30] step 34/44: loss=0.0114 
[epoch 30] step 36/44: loss=0.0114 
[epoch 30] step 38/44: loss=0.0111 
[epoch 30] step 40/44: loss=0.0110 
[epoch 30] step 42/44: loss=0.0111 
[epoch 30] step 44/44: loss=0.0112 
[epoch 30] val_loss=2.1908 qwk=('0.5846', '0.6032', '0.5939') averageQWK=0.5939 macroEMD=0.1932 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   18   34    3    0
     0   14   77   34    0
     0    0   27   86    3
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   21   26    6    0
     0   16   74   31    1
     0    0   26  106    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   29   40    0    0
     0   20   97   35    0
     0    0   38   63    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=0.0144 
[epoch 31] step 4/44: loss=0.0147 
[epoch 31] step 6/44: loss=0.0122 
[epoch 31] step 8/44: loss=0.0115 
[epoch 31] step 10/44: loss=0.0112 
[epoch 31] step 12/44: loss=0.0112 
[epoch 31] step 14/44: loss=0.0106 
[epoch 31] step 16/44: loss=0.0103 
[epoch 31] step 18/44: loss=0.0101 
[epoch 31] step 20/44: loss=0.0100 
[epoch 31] step 22/44: loss=0.0097 
[epoch 31] step 24/44: loss=0.0097 
[epoch 31] step 26/44: loss=0.0097 
[epoch 31] step 28/44: loss=0.0097 
[epoch 31] step 30/44: loss=0.0095 
[epoch 31] step 32/44: loss=0.0095 
[epoch 31] step 34/44: loss=0.0093 
[epoch 31] step 36/44: loss=0.0094 
[epoch 31] step 38/44: loss=0.0093 
[epoch 31] step 40/44: loss=0.0092 
[epoch 31] step 42/44: loss=0.0093 
[epoch 31] step 44/44: loss=0.0091 
[epoch 31] val_loss=2.2845 qwk=('0.5679', '0.6220', '0.5803') averageQWK=0.5901 macroEMD=0.1951 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    0    0
     0   12   40    3    0
     0    8   76   41    0
     0    0   25   86    5
     0    0    2   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   20   27    6    0
     0   15   69   37    1
     0    0   17  115    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   26   43    0    0
     0   16  102   34    0
     0    0   35   66    0
     0    0    0    2    0
[epoch 32] step 2/44: loss=0.0059 
[epoch 32] step 4/44: loss=0.0086 
[epoch 32] step 6/44: loss=0.0090 
[epoch 32] step 8/44: loss=0.0083 
[epoch 32] step 10/44: loss=0.0082 
[epoch 32] step 12/44: loss=0.0080 
[epoch 32] step 14/44: loss=0.0076 
[epoch 32] step 16/44: loss=0.0075 
[epoch 32] step 18/44: loss=0.0077 
[epoch 32] step 20/44: loss=0.0082 
[epoch 32] step 22/44: loss=0.0083 
[epoch 32] step 24/44: loss=0.0081 
[epoch 32] step 26/44: loss=0.0081 
[epoch 32] step 28/44: loss=0.0080 
[epoch 32] step 30/44: loss=0.0082 
[epoch 32] step 32/44: loss=0.0080 
[epoch 32] step 34/44: loss=0.0079 
[epoch 32] step 36/44: loss=0.0079 
[epoch 32] step 38/44: loss=0.0082 
[epoch 32] step 40/44: loss=0.0082 
[epoch 32] step 42/44: loss=0.0081 
[epoch 32] step 44/44: loss=0.0079 
[epoch 32] val_loss=2.2913 qwk=('0.5792', '0.6077', '0.5645') averageQWK=0.5838 macroEMD=0.1952 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   13   39    3    0
     0    8   78   39    0
     0    0   25   86    5
     0    0    2   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   20   27    6    0
     0   17   69   35    1
     0    1   17  114    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   44    0    0
     0   18  102   32    0
     0    0   38   63    0
     0    0    0    2    0
[epoch 33] step 2/44: loss=0.0062 
[epoch 33] step 4/44: loss=0.0059 
[epoch 33] step 6/44: loss=0.0060 
[epoch 33] step 8/44: loss=0.0063 
[epoch 33] step 10/44: loss=0.0062 
[epoch 33] step 12/44: loss=0.0071 
[epoch 33] step 14/44: loss=0.0071 
[epoch 33] step 16/44: loss=0.0072 
[epoch 33] step 18/44: loss=0.0074 
[epoch 33] step 20/44: loss=0.0074 
[epoch 33] step 22/44: loss=0.0073 
[epoch 33] step 24/44: loss=0.0072 
[epoch 33] step 26/44: loss=0.0072 
[epoch 33] step 28/44: loss=0.0072 
[epoch 33] step 30/44: loss=0.0072 
[epoch 33] step 32/44: loss=0.0073 
[epoch 33] step 34/44: loss=0.0073 
[epoch 33] step 36/44: loss=0.0073 
[epoch 33] step 38/44: loss=0.0073 
[epoch 33] step 40/44: loss=0.0073 
[epoch 33] step 42/44: loss=0.0072 
[epoch 33] step 44/44: loss=0.0072 
[epoch 33] val_loss=2.2938 qwk=('0.5812', '0.6022', '0.5657') averageQWK=0.5830 macroEMD=0.1971 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   14   38    3    0
     0    8   80   37    0
     0    0   27   84    5
     0    0    2   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   20   27    6    0
     0   16   74   31    1
     0    1   22  109    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   44    0    0
     0   17  105   30    0
     0    0   39   62    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=0.0054 
[epoch 34] step 4/44: loss=0.0057 
[epoch 34] step 6/44: loss=0.0061 
[epoch 34] step 8/44: loss=0.0062 
[epoch 34] step 10/44: loss=0.0068 
[epoch 34] step 12/44: loss=0.0066 
[epoch 34] step 14/44: loss=0.0068 
[epoch 34] step 16/44: loss=0.0069 
[epoch 34] step 18/44: loss=0.0070 
[epoch 34] step 20/44: loss=0.0070 
[epoch 34] step 22/44: loss=0.0070 
[epoch 34] step 24/44: loss=0.0069 
[epoch 34] step 26/44: loss=0.0069 
[epoch 34] step 28/44: loss=0.0068 
[epoch 34] step 30/44: loss=0.0068 
[epoch 34] step 32/44: loss=0.0067 
[epoch 34] step 34/44: loss=0.0067 
[epoch 34] step 36/44: loss=0.0067 
[epoch 34] step 38/44: loss=0.0067 
[epoch 34] step 40/44: loss=0.0070 
[epoch 34] step 42/44: loss=0.0070 
[epoch 34] step 44/44: loss=0.0069 
[epoch 34] val_loss=2.3208 qwk=('0.5743', '0.6020', '0.5603') averageQWK=0.5789 macroEMD=0.1967 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   12   40    3    0
     0    8   76   41    0
     0    0   25   86    5
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   17   30    6    0
     0   15   73   33    1
     0    0   20  112    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   24   45    0    0
     0   18  100   34    0
     0    0   37   64    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=0.0057 
[epoch 35] step 4/44: loss=0.0054 
[epoch 35] step 6/44: loss=0.0070 
[epoch 35] step 8/44: loss=0.0067 
[epoch 35] step 10/44: loss=0.0065 
[epoch 35] step 12/44: loss=0.0065 
[epoch 35] step 14/44: loss=0.0064 
[epoch 35] step 16/44: loss=0.0062 
[epoch 35] step 18/44: loss=0.0062 
[epoch 35] step 20/44: loss=0.0062 
[epoch 35] step 22/44: loss=0.0061 
[epoch 35] step 24/44: loss=0.0062 
[epoch 35] step 26/44: loss=0.0062 
[epoch 35] step 28/44: loss=0.0062 
[epoch 35] step 30/44: loss=0.0062 
[epoch 35] step 32/44: loss=0.0061 
[epoch 35] step 34/44: loss=0.0063 
[epoch 35] step 36/44: loss=0.0063 
[epoch 35] step 38/44: loss=0.0064 
[epoch 35] step 40/44: loss=0.0064 
[epoch 35] step 42/44: loss=0.0065 
[epoch 35] step 44/44: loss=0.0065 
[epoch 35] val_loss=2.3097 qwk=('0.5613', '0.6030', '0.5754') averageQWK=0.5799 macroEMD=0.1968 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   13   39    3    0
     0    8   78   39    0
     0    0   27   84    5
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   19   28    6    0
     0   16   72   33    1
     0    1   19  112    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   27   42    0    0
     0   18  103   31    0
     0    0   38   63    0
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/ce/fold5/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/ce/fold5/metrics.json
Done.
