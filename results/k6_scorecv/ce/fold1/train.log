[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.9609 
[epoch 1] step 4/44: loss=0.9458 
[epoch 1] step 6/44: loss=0.9467 
[epoch 1] step 8/44: loss=0.9449 
[epoch 1] step 10/44: loss=0.9438 
[epoch 1] step 12/44: loss=0.9352 
[epoch 1] step 14/44: loss=0.9360 
[epoch 1] step 16/44: loss=0.9343 
[epoch 1] step 18/44: loss=0.9378 
[epoch 1] step 20/44: loss=0.9356 
[epoch 1] step 22/44: loss=0.9350 
[epoch 1] step 24/44: loss=0.9353 
[epoch 1] step 26/44: loss=0.9318 
[epoch 1] step 28/44: loss=0.9310 
[epoch 1] step 30/44: loss=0.9279 
[epoch 1] step 32/44: loss=0.9264 
[epoch 1] step 34/44: loss=0.9245 
[epoch 1] step 36/44: loss=0.9210 
[epoch 1] step 38/44: loss=0.9175 
[epoch 1] step 40/44: loss=0.9121 
[epoch 1] step 42/44: loss=0.9055 
[epoch 1] step 44/44: loss=0.9000 
[epoch 1] val_loss=1.4694 qwk=('0.1973', '0.2255', '0.2175') averageQWK=0.2134 macroEMD=0.3670 tailR0=('0.0000', '0.1111', '0.0000') tailR0avg=0.0370
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    5    0
     0   18    2   34    0
     0   48    0   78    0
     0   23    3   90    0
     0    1    0   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    4    3    0
    20    0   14   18    0
    46    0   22   54    0
    22    0   24   87    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    6   61    0    1
     0    9  123   13    7
     0    5   67   22    7
     0    0    1    1    0
[epoch 2] step 2/44: loss=0.7659 
[epoch 2] step 4/44: loss=0.7496 
[epoch 2] step 6/44: loss=0.7574 
[epoch 2] step 8/44: loss=0.7393 
[epoch 2] step 10/44: loss=0.7320 
[epoch 2] step 12/44: loss=0.7200 
[epoch 2] step 14/44: loss=0.7121 
[epoch 2] step 16/44: loss=0.7048 
[epoch 2] step 18/44: loss=0.6978 
[epoch 2] step 20/44: loss=0.6921 
[epoch 2] step 22/44: loss=0.6854 
[epoch 2] step 24/44: loss=0.6794 
[epoch 2] step 26/44: loss=0.6722 
[epoch 2] step 28/44: loss=0.6680 
[epoch 2] step 30/44: loss=0.6663 
[epoch 2] step 32/44: loss=0.6634 
[epoch 2] step 34/44: loss=0.6603 
[epoch 2] step 36/44: loss=0.6587 
[epoch 2] step 38/44: loss=0.6581 
[epoch 2] step 40/44: loss=0.6563 
[epoch 2] step 42/44: loss=0.6527 
[epoch 2] step 44/44: loss=0.6490 
[epoch 2] val_loss=1.1857 qwk=('0.3489', '0.1978', '0.3728') averageQWK=0.3065 macroEMD=0.3210 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   50    4    0
     0    0   98   28    0
     0    0   44   72    0
     0    0    9   14    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    5    0
     0    0   22   30    0
     0    0   23   99    0
     0    0    5  128    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    0   54   14    0
     0    0   73   79    0
     0    0   10   91    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=0.5754 
[epoch 3] step 4/44: loss=0.5773 
[epoch 3] step 6/44: loss=0.6085 
[epoch 3] step 8/44: loss=0.5950 
[epoch 3] step 10/44: loss=0.6005 
[epoch 3] step 12/44: loss=0.5958 
[epoch 3] step 14/44: loss=0.5916 
[epoch 3] step 16/44: loss=0.5829 
[epoch 3] step 18/44: loss=0.5846 
[epoch 3] step 20/44: loss=0.5843 
[epoch 3] step 22/44: loss=0.5836 
[epoch 3] step 24/44: loss=0.5792 
[epoch 3] step 26/44: loss=0.5763 
[epoch 3] step 28/44: loss=0.5798 
[epoch 3] step 30/44: loss=0.5791 
[epoch 3] step 32/44: loss=0.5731 
[epoch 3] step 34/44: loss=0.5722 
[epoch 3] step 36/44: loss=0.5684 
[epoch 3] step 38/44: loss=0.5711 
[epoch 3] step 40/44: loss=0.5737 
[epoch 3] step 42/44: loss=0.5754 
[epoch 3] step 44/44: loss=0.5793 
[epoch 3] val_loss=1.0376 qwk=('0.5325', '0.4330', '0.5240') averageQWK=0.4965 macroEMD=0.2677 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    2    0
     0   11   39    4    0
     0    4   81   41    0
     0    0   23   93    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    0   50    2    0
     0    0   82   40    0
     0    0   37   96    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   22   36   10    0
     0   26   67   59    0
     0    1    9   91    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=0.5063 
[epoch 4] step 4/44: loss=0.5061 
[epoch 4] step 6/44: loss=0.5294 
[epoch 4] step 8/44: loss=0.5388 
[epoch 4] step 10/44: loss=0.5398 
[epoch 4] step 12/44: loss=0.5364 
[epoch 4] step 14/44: loss=0.5373 
[epoch 4] step 16/44: loss=0.5378 
[epoch 4] step 18/44: loss=0.5331 
[epoch 4] step 20/44: loss=0.5299 
[epoch 4] step 22/44: loss=0.5263 
[epoch 4] step 24/44: loss=0.5281 
[epoch 4] step 26/44: loss=0.5284 
[epoch 4] step 28/44: loss=0.5265 
[epoch 4] step 30/44: loss=0.5198 
[epoch 4] step 32/44: loss=0.5189 
[epoch 4] step 34/44: loss=0.5164 
[epoch 4] step 36/44: loss=0.5153 
[epoch 4] step 38/44: loss=0.5148 
[epoch 4] step 40/44: loss=0.5139 
[epoch 4] step 42/44: loss=0.5146 
[epoch 4] step 44/44: loss=0.5125 
[epoch 4] val_loss=0.9662 qwk=('0.5413', '0.5162', '0.5855') averageQWK=0.5476 macroEMD=0.2431 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    2    0
     0    9   42    3    0
     0    2   89   35    0
     0    0   24   92    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0    9   40    3    0
     0    7   75   40    0
     0    0   26  107    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   19   44    5    0
     0   12  101   39    0
     0    0   13   88    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=0.4329 
[epoch 5] step 4/44: loss=0.4573 
[epoch 5] step 6/44: loss=0.4524 
[epoch 5] step 8/44: loss=0.4648 
[epoch 5] step 10/44: loss=0.4627 
[epoch 5] step 12/44: loss=0.4612 
[epoch 5] step 14/44: loss=0.4674 
[epoch 5] step 16/44: loss=0.4618 
[epoch 5] step 18/44: loss=0.4591 
[epoch 5] step 20/44: loss=0.4622 
[epoch 5] step 22/44: loss=0.4617 
[epoch 5] step 24/44: loss=0.4644 
[epoch 5] step 26/44: loss=0.4692 
[epoch 5] step 28/44: loss=0.4748 
[epoch 5] step 30/44: loss=0.4718 
[epoch 5] step 32/44: loss=0.4714 
[epoch 5] step 34/44: loss=0.4760 
[epoch 5] step 36/44: loss=0.4735 
[epoch 5] step 38/44: loss=0.4745 
[epoch 5] step 40/44: loss=0.4765 
[epoch 5] step 42/44: loss=0.4767 
[epoch 5] step 44/44: loss=0.4735 
[epoch 5] val_loss=0.9621 qwk=('0.6080', '0.5436', '0.5843') averageQWK=0.5786 macroEMD=0.2333 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   20   31    3    0
     0    3   82   41    0
     0    0   19   97    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   11   38    3    0
     0    6   70   46    0
     0    0   25  108    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   18   44    6    0
     0    5  102   45    0
     0    0   10   91    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=0.3987 
[epoch 6] step 4/44: loss=0.4240 
[epoch 6] step 6/44: loss=0.4336 
[epoch 6] step 8/44: loss=0.4406 
[epoch 6] step 10/44: loss=0.4391 
[epoch 6] step 12/44: loss=0.4423 
[epoch 6] step 14/44: loss=0.4369 
[epoch 6] step 16/44: loss=0.4396 
[epoch 6] step 18/44: loss=0.4368 
[epoch 6] step 20/44: loss=0.4320 
[epoch 6] step 22/44: loss=0.4290 
[epoch 6] step 24/44: loss=0.4271 
[epoch 6] step 26/44: loss=0.4326 
[epoch 6] step 28/44: loss=0.4291 
[epoch 6] step 30/44: loss=0.4241 
[epoch 6] step 32/44: loss=0.4243 
[epoch 6] step 34/44: loss=0.4233 
[epoch 6] step 36/44: loss=0.4223 
[epoch 6] step 38/44: loss=0.4236 
[epoch 6] step 40/44: loss=0.4254 
[epoch 6] step 42/44: loss=0.4262 
[epoch 6] step 44/44: loss=0.4252 
[epoch 6] val_loss=0.9099 qwk=('0.5884', '0.5661', '0.6524') averageQWK=0.6023 macroEMD=0.2200 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   15   38    1    0
     0    2   97   26    1
     0    0   31   82    3
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0    9   41    2    0
     0    7   84   31    0
     0    0   35   98    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   30   37    1    0
     0   23  109   20    0
     0    0   26   75    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=0.3466 
[epoch 7] step 4/44: loss=0.3854 
[epoch 7] step 6/44: loss=0.3947 
[epoch 7] step 8/44: loss=0.4005 
[epoch 7] step 10/44: loss=0.4073 
[epoch 7] step 12/44: loss=0.4064 
[epoch 7] step 14/44: loss=0.4101 
[epoch 7] step 16/44: loss=0.4008 
[epoch 7] step 18/44: loss=0.3941 
[epoch 7] step 20/44: loss=0.3960 
[epoch 7] step 22/44: loss=0.3975 
[epoch 7] step 24/44: loss=0.3932 
[epoch 7] step 26/44: loss=0.3890 
[epoch 7] step 28/44: loss=0.3862 
[epoch 7] step 30/44: loss=0.3873 
[epoch 7] step 32/44: loss=0.3841 
[epoch 7] step 34/44: loss=0.3854 
[epoch 7] step 36/44: loss=0.3855 
[epoch 7] step 38/44: loss=0.3840 
[epoch 7] step 40/44: loss=0.3827 
[epoch 7] step 42/44: loss=0.3830 
[epoch 7] step 44/44: loss=0.3839 
[epoch 7] val_loss=0.9314 qwk=('0.6718', '0.6192', '0.6494') averageQWK=0.6468 macroEMD=0.2015 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   30   21    3    0
     0   19   81   24    2
     0    0   25   84    7
     0    0    1   16    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   18   32    2    0
     0   14   77   31    0
     0    1   28  104    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   27   39    2    0
     0   14  106   32    0
     0    0   19   82    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=0.3271 
[epoch 8] step 4/44: loss=0.3474 
[epoch 8] step 6/44: loss=0.3331 
[epoch 8] step 8/44: loss=0.3431 
[epoch 8] step 10/44: loss=0.3387 
[epoch 8] step 12/44: loss=0.3466 
[epoch 8] step 14/44: loss=0.3497 
[epoch 8] step 16/44: loss=0.3538 
[epoch 8] step 18/44: loss=0.3499 
[epoch 8] step 20/44: loss=0.3468 
[epoch 8] step 22/44: loss=0.3535 
[epoch 8] step 24/44: loss=0.3510 
[epoch 8] step 26/44: loss=0.3483 
[epoch 8] step 28/44: loss=0.3519 
[epoch 8] step 30/44: loss=0.3564 
[epoch 8] step 32/44: loss=0.3542 
[epoch 8] step 34/44: loss=0.3537 
[epoch 8] step 36/44: loss=0.3534 
[epoch 8] step 38/44: loss=0.3558 
[epoch 8] step 40/44: loss=0.3542 
[epoch 8] step 42/44: loss=0.3537 
[epoch 8] step 44/44: loss=0.3498 
[epoch 8] val_loss=0.9490 qwk=('0.6370', '0.5519', '0.6396') averageQWK=0.6095 macroEMD=0.2048 tailR0=('0.2391', '0.0000', '0.0000') tailR0avg=0.0797
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   19   32    3    0
     0    2   97   24    3
     0    0   30   73   13
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0    6   43    3    0
     0    3   79   40    0
     0    0   28  105    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   20   47    1    0
     0   11  115   26    0
     0    0   18   83    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=0.3048 
[epoch 9] step 4/44: loss=0.3123 
[epoch 9] step 6/44: loss=0.3066 
[epoch 9] step 8/44: loss=0.3113 
[epoch 9] step 10/44: loss=0.3147 
[epoch 9] step 12/44: loss=0.3076 
[epoch 9] step 14/44: loss=0.3112 
[epoch 9] step 16/44: loss=0.3062 
[epoch 9] step 18/44: loss=0.3057 
[epoch 9] step 20/44: loss=0.3092 
[epoch 9] step 22/44: loss=0.3080 
[epoch 9] step 24/44: loss=0.3054 
[epoch 9] step 26/44: loss=0.3027 
[epoch 9] step 28/44: loss=0.3019 
[epoch 9] step 30/44: loss=0.2980 
[epoch 9] step 32/44: loss=0.2988 
[epoch 9] step 34/44: loss=0.2993 
[epoch 9] step 36/44: loss=0.3000 
[epoch 9] step 38/44: loss=0.3009 
[epoch 9] step 40/44: loss=0.3010 
[epoch 9] step 42/44: loss=0.3012 
[epoch 9] step 44/44: loss=0.3000 
[epoch 9] val_loss=1.0881 qwk=('0.6153', '0.5734', '0.6610') averageQWK=0.6166 macroEMD=0.1985 tailR0=('0.4130', '0.1250', '0.0000') tailR0avg=0.1793
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   16   33    3    2
     0    4   75   40    7
     0    0   15   69   32
     0    0    0    4   19
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0   14   31    7    0
     0    7   67   48    0
     0    1   18  111    3
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   32   34    2    0
     0   21   93   38    0
     0    0   12   89    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=0.2941 
[epoch 10] step 4/44: loss=0.2842 
[epoch 10] step 6/44: loss=0.2804 
[epoch 10] step 8/44: loss=0.2877 
[epoch 10] step 10/44: loss=0.2865 
[epoch 10] step 12/44: loss=0.2824 
[epoch 10] step 14/44: loss=0.2827 
[epoch 10] step 16/44: loss=0.2798 
[epoch 10] step 18/44: loss=0.2772 
[epoch 10] step 20/44: loss=0.2825 
[epoch 10] step 22/44: loss=0.2849 
[epoch 10] step 24/44: loss=0.2875 
[epoch 10] step 26/44: loss=0.2867 
[epoch 10] step 28/44: loss=0.2850 
[epoch 10] step 30/44: loss=0.2842 
[epoch 10] step 32/44: loss=0.2828 
[epoch 10] step 34/44: loss=0.2812 
[epoch 10] step 36/44: loss=0.2813 
[epoch 10] step 38/44: loss=0.2825 
[epoch 10] step 40/44: loss=0.2823 
[epoch 10] step 42/44: loss=0.2812 
[epoch 10] step 44/44: loss=0.2834 
[epoch 10] val_loss=1.0278 qwk=('0.6432', '0.5922', '0.6661') averageQWK=0.6338 macroEMD=0.1915 tailR0=('0.1739', '0.0833', '0.0000') tailR0avg=0.0857
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   23   28    3    0
     0   13   76   34    3
     0    0   23   86    7
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   16   33    3    0
     0   18   67   37    0
     0    2   27  104    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   33    0    0
     0   27   98   27    0
     0    0   24   77    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.2524 
[epoch 11] step 4/44: loss=0.2532 
[epoch 11] step 6/44: loss=0.2644 
[epoch 11] step 8/44: loss=0.2647 
[epoch 11] step 10/44: loss=0.2612 
[epoch 11] step 12/44: loss=0.2546 
[epoch 11] step 14/44: loss=0.2547 
[epoch 11] step 16/44: loss=0.2529 
[epoch 11] step 18/44: loss=0.2449 
[epoch 11] step 20/44: loss=0.2457 
[epoch 11] step 22/44: loss=0.2447 
[epoch 11] step 24/44: loss=0.2467 
[epoch 11] step 26/44: loss=0.2480 
[epoch 11] step 28/44: loss=0.2465 
[epoch 11] step 30/44: loss=0.2446 
[epoch 11] step 32/44: loss=0.2437 
[epoch 11] step 34/44: loss=0.2441 
[epoch 11] step 36/44: loss=0.2427 
[epoch 11] step 38/44: loss=0.2410 
[epoch 11] step 40/44: loss=0.2396 
[epoch 11] step 42/44: loss=0.2390 
[epoch 11] step 44/44: loss=0.2392 
[epoch 11] val_loss=1.0477 qwk=('0.6391', '0.6098', '0.6755') averageQWK=0.6415 macroEMD=0.1881 tailR0=('0.1087', '0.0833', '0.0000') tailR0avg=0.0640
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   25   27    2    0
     0   15   90   20    1
     0    0   37   76    3
     0    0    1   17    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   19   32    1    0
     0   21   79   22    0
     0    2   39   92    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   43   25    0    0
     0   28  112   12    0
     0    2   32   67    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=0.2767 
[epoch 12] step 4/44: loss=0.2554 
[epoch 12] step 6/44: loss=0.2505 
[epoch 12] step 8/44: loss=0.2341 
[epoch 12] step 10/44: loss=0.2282 
[epoch 12] step 12/44: loss=0.2219 
[epoch 12] step 14/44: loss=0.2224 
[epoch 12] step 16/44: loss=0.2229 
[epoch 12] step 18/44: loss=0.2193 
[epoch 12] step 20/44: loss=0.2177 
[epoch 12] step 22/44: loss=0.2187 
[epoch 12] step 24/44: loss=0.2176 
[epoch 12] step 26/44: loss=0.2185 
[epoch 12] step 28/44: loss=0.2208 
[epoch 12] step 30/44: loss=0.2227 
[epoch 12] step 32/44: loss=0.2231 
[epoch 12] step 34/44: loss=0.2192 
[epoch 12] step 36/44: loss=0.2197 
[epoch 12] step 38/44: loss=0.2171 
[epoch 12] step 40/44: loss=0.2152 
[epoch 12] step 42/44: loss=0.2139 
[epoch 12] step 44/44: loss=0.2159 
[epoch 12] val_loss=1.1115 qwk=('0.6361', '0.5703', '0.6669') averageQWK=0.6244 macroEMD=0.1846 tailR0=('0.2609', '0.1667', '0.0000') tailR0avg=0.1425
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   17   33    4    0
     0   10   84   28    4
     0    0   24   76   16
     0    0    0   11   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   10   36    6    0
     0   14   69   38    1
     0    1   24  104    4
     0    0    0    8    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   33   34    1    0
     0   22  105   25    0
     0    0   23   78    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.1661 
[epoch 13] step 4/44: loss=0.1594 
[epoch 13] step 6/44: loss=0.1605 
[epoch 13] step 8/44: loss=0.1746 
[epoch 13] step 10/44: loss=0.1636 
[epoch 13] step 12/44: loss=0.1640 
[epoch 13] step 14/44: loss=0.1669 
[epoch 13] step 16/44: loss=0.1660 
[epoch 13] step 18/44: loss=0.1715 
[epoch 13] step 20/44: loss=0.1720 
[epoch 13] step 22/44: loss=0.1747 
[epoch 13] step 24/44: loss=0.1787 
[epoch 13] step 26/44: loss=0.1784 
[epoch 13] step 28/44: loss=0.1793 
[epoch 13] step 30/44: loss=0.1859 
[epoch 13] step 32/44: loss=0.1871 
[epoch 13] step 34/44: loss=0.1861 
[epoch 13] step 36/44: loss=0.1890 
[epoch 13] step 38/44: loss=0.1872 
[epoch 13] step 40/44: loss=0.1878 
[epoch 13] step 42/44: loss=0.1876 
[epoch 13] step 44/44: loss=0.1890 
[epoch 13] val_loss=1.1686 qwk=('0.6625', '0.5988', '0.6547') averageQWK=0.6386 macroEMD=0.1798 tailR0=('0.2174', '0.1250', '0.0000') tailR0avg=0.1141
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   24   27    3    0
     0   11   90   21    4
     0    0   27   80    9
     0    0    0   13   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   23   24    5    0
     0   20   58   43    1
     0    3   21  107    2
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   34   31    3    0
     0   19   96   37    0
     0    1   15   85    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.1711 
[epoch 14] step 4/44: loss=0.1831 
[epoch 14] step 6/44: loss=0.1803 
[epoch 14] step 8/44: loss=0.1835 
[epoch 14] step 10/44: loss=0.1843 
[epoch 14] step 12/44: loss=0.1777 
[epoch 14] step 14/44: loss=0.1707 
[epoch 14] step 16/44: loss=0.1678 
[epoch 14] step 18/44: loss=0.1683 
[epoch 14] step 20/44: loss=0.1676 
[epoch 14] step 22/44: loss=0.1644 
[epoch 14] step 24/44: loss=0.1622 
[epoch 14] step 26/44: loss=0.1610 
[epoch 14] step 28/44: loss=0.1606 
[epoch 14] step 30/44: loss=0.1584 
[epoch 14] step 32/44: loss=0.1588 
[epoch 14] step 34/44: loss=0.1576 
[epoch 14] step 36/44: loss=0.1590 
[epoch 14] step 38/44: loss=0.1614 
[epoch 14] step 40/44: loss=0.1638 
[epoch 14] step 42/44: loss=0.1628 
[epoch 14] step 44/44: loss=0.1631 
[epoch 14] val_loss=1.2279 qwk=('0.6782', '0.6181', '0.6556') averageQWK=0.6506 macroEMD=0.1765 tailR0=('0.2609', '0.1667', '0.0000') tailR0avg=0.1425
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   24   29    1    0
     0   16   90   16    4
     0    0   31   73   12
     0    0    1   10   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   19   30    3    0
     0   18   75   27    2
     0    2   27   97    7
     0    0    0    8    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   31    2    0
     0   26   95   31    0
     0    0   21   80    0
     0    0    0    2    0
[epoch 15] step 2/44: loss=0.1445 
[epoch 15] step 4/44: loss=0.1465 
[epoch 15] step 6/44: loss=0.1376 
[epoch 15] step 8/44: loss=0.1373 
[epoch 15] step 10/44: loss=0.1391 
[epoch 15] step 12/44: loss=0.1410 
[epoch 15] step 14/44: loss=0.1404 
[epoch 15] step 16/44: loss=0.1395 
[epoch 15] step 18/44: loss=0.1381 
[epoch 15] step 20/44: loss=0.1377 
[epoch 15] step 22/44: loss=0.1381 
[epoch 15] step 24/44: loss=0.1349 
[epoch 15] step 26/44: loss=0.1328 
[epoch 15] step 28/44: loss=0.1344 
[epoch 15] step 30/44: loss=0.1335 
[epoch 15] step 32/44: loss=0.1356 
[epoch 15] step 34/44: loss=0.1355 
[epoch 15] step 36/44: loss=0.1337 
[epoch 15] step 38/44: loss=0.1343 
[epoch 15] step 40/44: loss=0.1333 
[epoch 15] step 42/44: loss=0.1334 
[epoch 15] step 44/44: loss=0.1336 
[epoch 15] val_loss=1.3020 qwk=('0.6412', '0.5632', '0.6266') averageQWK=0.6103 macroEMD=0.1828 tailR0=('0.2391', '0.1250', '0.0000') tailR0avg=0.1214
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   20   31    3    0
     0    7   92   23    4
     0    0   32   63   21
     0    0    0   12   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0   11   36    5    0
     0   15   68   37    2
     0    2   20  102    9
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   34   31    3    0
     0   30   94   28    0
     0    2   20   78    1
     0    0    0    2    0
[epoch 16] step 2/44: loss=0.1261 
[epoch 16] step 4/44: loss=0.1188 
[epoch 16] step 6/44: loss=0.1170 
[epoch 16] step 8/44: loss=0.1114 
[epoch 16] step 10/44: loss=0.1123 
[epoch 16] step 12/44: loss=0.1116 
[epoch 16] step 14/44: loss=0.1186 
[epoch 16] step 16/44: loss=0.1183 
[epoch 16] step 18/44: loss=0.1157 
[epoch 16] step 20/44: loss=0.1172 
[epoch 16] step 22/44: loss=0.1169 
[epoch 16] step 24/44: loss=0.1174 
[epoch 16] step 26/44: loss=0.1166 
[epoch 16] step 28/44: loss=0.1184 
[epoch 16] step 30/44: loss=0.1190 
[epoch 16] step 32/44: loss=0.1185 
[epoch 16] step 34/44: loss=0.1176 
[epoch 16] step 36/44: loss=0.1156 
[epoch 16] step 38/44: loss=0.1152 
[epoch 16] step 40/44: loss=0.1153 
[epoch 16] step 42/44: loss=0.1149 
[epoch 16] step 44/44: loss=0.1157 
[epoch 16] val_loss=1.3519 qwk=('0.6647', '0.6142', '0.6575') averageQWK=0.6455 macroEMD=0.1761 tailR0=('0.1957', '0.1250', '0.0000') tailR0avg=0.1069
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   23   28    3    0
     0   16   83   24    3
     0    0   26   83    7
     0    0    0   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   18   33    1    0
     0   16   81   23    2
     0    2   35   87    9
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   32    1    0
     0   24   98   30    0
     0    2   18   81    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=0.1239 
[epoch 17] step 4/44: loss=0.1187 
[epoch 17] step 6/44: loss=0.1042 
[epoch 17] step 8/44: loss=0.1095 
[epoch 17] step 10/44: loss=0.1029 
[epoch 17] step 12/44: loss=0.0969 
[epoch 17] step 14/44: loss=0.0950 
[epoch 17] step 16/44: loss=0.0947 
[epoch 17] step 18/44: loss=0.0920 
[epoch 17] step 20/44: loss=0.0926 
[epoch 17] step 22/44: loss=0.0918 
[epoch 17] step 24/44: loss=0.0911 
[epoch 17] step 26/44: loss=0.0924 
[epoch 17] step 28/44: loss=0.0934 
[epoch 17] step 30/44: loss=0.0922 
[epoch 17] step 32/44: loss=0.0949 
[epoch 17] step 34/44: loss=0.0950 
[epoch 17] step 36/44: loss=0.0960 
[epoch 17] step 38/44: loss=0.0953 
[epoch 17] step 40/44: loss=0.0951 
[epoch 17] step 42/44: loss=0.0943 
[epoch 17] step 44/44: loss=0.0935 
[epoch 17] val_loss=1.4744 qwk=('0.6009', '0.5516', '0.6098') averageQWK=0.5874 macroEMD=0.1942 tailR0=('0.2391', '0.1250', '0.0000') tailR0avg=0.1214
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0    9   41    4    0
     0    2   91   29    4
     0    0   26   78   12
     0    0    0   12   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0    7   43    2    0
     0    5   82   34    1
     0    1   33   95    4
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   27   40    1    0
     0   18  113   21    0
     0    1   30   68    2
     0    0    0    2    0
[epoch 18] step 2/44: loss=0.0633 
[epoch 18] step 4/44: loss=0.0747 
[epoch 18] step 6/44: loss=0.0778 
[epoch 18] step 8/44: loss=0.0804 
[epoch 18] step 10/44: loss=0.0817 
[epoch 18] step 12/44: loss=0.0810 
[epoch 18] step 14/44: loss=0.0779 
[epoch 18] step 16/44: loss=0.0772 
[epoch 18] step 18/44: loss=0.0775 
[epoch 18] step 20/44: loss=0.0773 
[epoch 18] step 22/44: loss=0.0761 
[epoch 18] step 24/44: loss=0.0764 
[epoch 18] step 26/44: loss=0.0781 
[epoch 18] step 28/44: loss=0.0788 
[epoch 18] step 30/44: loss=0.0772 
[epoch 18] step 32/44: loss=0.0774 
[epoch 18] step 34/44: loss=0.0786 
[epoch 18] step 36/44: loss=0.0789 
[epoch 18] step 38/44: loss=0.0785 
[epoch 18] step 40/44: loss=0.0781 
[epoch 18] step 42/44: loss=0.0791 
[epoch 18] step 44/44: loss=0.0805 
[epoch 18] val_loss=1.4957 qwk=('0.6084', '0.5608', '0.6529') averageQWK=0.6073 macroEMD=0.1909 tailR0=('0.1304', '0.1250', '0.0000') tailR0avg=0.0851
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   13   38    3    0
     0    7   92   25    2
     0    0   32   80    4
     0    0    0   17    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0   11   37    4    0
     0    7   81   33    1
     0    2   27  103    1
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   29   39    0    0
     0   17  112   23    0
     0    0   28   72    1
     0    0    0    2    0
[epoch 19] step 2/44: loss=0.0632 
[epoch 19] step 4/44: loss=0.0729 
[epoch 19] step 6/44: loss=0.0753 
[epoch 19] step 8/44: loss=0.0737 
[epoch 19] step 10/44: loss=0.0723 
[epoch 19] step 12/44: loss=0.0694 
[epoch 19] step 14/44: loss=0.0722 
[epoch 19] step 16/44: loss=0.0704 
[epoch 19] step 18/44: loss=0.0697 
[epoch 19] step 20/44: loss=0.0684 
[epoch 19] step 22/44: loss=0.0714 
[epoch 19] step 24/44: loss=0.0714 
[epoch 19] step 26/44: loss=0.0715 
[epoch 19] step 28/44: loss=0.0711 
[epoch 19] step 30/44: loss=0.0699 
[epoch 19] step 32/44: loss=0.0705 
[epoch 19] step 34/44: loss=0.0710 
[epoch 19] step 36/44: loss=0.0698 
[epoch 19] step 38/44: loss=0.0699 
[epoch 19] step 40/44: loss=0.0692 
[epoch 19] step 42/44: loss=0.0697 
[epoch 19] step 44/44: loss=0.0687 
[epoch 19] val_loss=1.6035 qwk=('0.5965', '0.5520', '0.6197') averageQWK=0.5894 macroEMD=0.1919 tailR0=('0.0870', '0.1250', '0.0000') tailR0avg=0.0707
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0    6   45    3    0
     0    0  103   22    1
     0    0   30   85    1
     0    0    0   19    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0    8   38    6    0
     0    6   76   39    1
     0    1   23  108    1
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   24   42    2    0
     0   17  108   27    0
     0    0   25   74    2
     0    0    0    2    0
[epoch 20] step 2/44: loss=0.0594 
[epoch 20] step 4/44: loss=0.0606 
[epoch 20] step 6/44: loss=0.0589 
[epoch 20] step 8/44: loss=0.0565 
[epoch 20] step 10/44: loss=0.0545 
[epoch 20] step 12/44: loss=0.0552 
[epoch 20] step 14/44: loss=0.0555 
[epoch 20] step 16/44: loss=0.0566 
[epoch 20] step 18/44: loss=0.0572 
[epoch 20] step 20/44: loss=0.0565 
[epoch 20] step 22/44: loss=0.0559 
[epoch 20] step 24/44: loss=0.0560 
[epoch 20] step 26/44: loss=0.0561 
[epoch 20] step 28/44: loss=0.0552 
[epoch 20] step 30/44: loss=0.0551 
[epoch 20] step 32/44: loss=0.0546 
[epoch 20] step 34/44: loss=0.0537 
[epoch 20] step 36/44: loss=0.0535 
[epoch 20] step 38/44: loss=0.0529 
[epoch 20] step 40/44: loss=0.0534 
[epoch 20] step 42/44: loss=0.0531 
[epoch 20] step 44/44: loss=0.0524 
[epoch 20] val_loss=1.6433 qwk=('0.6318', '0.6017', '0.6307') averageQWK=0.6214 macroEMD=0.1831 tailR0=('0.2174', '0.1250', '0.0000') tailR0avg=0.1141
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   17   34    3    0
     0    6   95   22    3
     0    0   35   73    8
     0    0    0   13   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0    7   44    1    0
     0    5   91   25    1
     0    1   31   99    2
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   33    4    0
     0   24   98   30    0
     0    1   18   81    1
     0    0    0    2    0
[epoch 21] step 2/44: loss=0.0369 
[epoch 21] step 4/44: loss=0.0385 
[epoch 21] step 6/44: loss=0.0433 
[epoch 21] step 8/44: loss=0.0428 
[epoch 21] step 10/44: loss=0.0479 
[epoch 21] step 12/44: loss=0.0490 
[epoch 21] step 14/44: loss=0.0494 
[epoch 21] step 16/44: loss=0.0487 
[epoch 21] step 18/44: loss=0.0485 
[epoch 21] step 20/44: loss=0.0476 
[epoch 21] step 22/44: loss=0.0459 
[epoch 21] step 24/44: loss=0.0454 
[epoch 21] step 26/44: loss=0.0448 
[epoch 21] step 28/44: loss=0.0450 
[epoch 21] step 30/44: loss=0.0445 
[epoch 21] step 32/44: loss=0.0441 
[epoch 21] step 34/44: loss=0.0439 
[epoch 21] step 36/44: loss=0.0442 
[epoch 21] step 38/44: loss=0.0442 
[epoch 21] step 40/44: loss=0.0438 
[epoch 21] step 42/44: loss=0.0433 
[epoch 21] step 44/44: loss=0.0432 
[epoch 21] val_loss=1.6755 qwk=('0.6199', '0.5857', '0.6553') averageQWK=0.6203 macroEMD=0.1806 tailR0=('0.1087', '0.0833', '0.0000') tailR0avg=0.0640
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   16   35    3    0
     0    7   99   19    1
     0    0   37   76    3
     0    0    0   18    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   17   32    3    0
     0   14   82   25    1
     0    3   32   95    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   31    2    0
     0   21  112   19    0
     0    1   27   71    2
     0    0    0    2    0
[epoch 22] step 2/44: loss=0.0231 
[epoch 22] step 4/44: loss=0.0299 
[epoch 22] step 6/44: loss=0.0352 
[epoch 22] step 8/44: loss=0.0345 
[epoch 22] step 10/44: loss=0.0355 
[epoch 22] step 12/44: loss=0.0341 
[epoch 22] step 14/44: loss=0.0360 
[epoch 22] step 16/44: loss=0.0376 
[epoch 22] step 18/44: loss=0.0372 
[epoch 22] step 20/44: loss=0.0367 
[epoch 22] step 22/44: loss=0.0364 
[epoch 22] step 24/44: loss=0.0368 
[epoch 22] step 26/44: loss=0.0372 
[epoch 22] step 28/44: loss=0.0368 
[epoch 22] step 30/44: loss=0.0364 
[epoch 22] step 32/44: loss=0.0381 
[epoch 22] step 34/44: loss=0.0377 
[epoch 22] step 36/44: loss=0.0373 
[epoch 22] step 38/44: loss=0.0377 
[epoch 22] step 40/44: loss=0.0386 
[epoch 22] step 42/44: loss=0.0384 
[epoch 22] step 44/44: loss=0.0379 
[epoch 22] val_loss=1.7312 qwk=('0.6188', '0.5542', '0.6488') averageQWK=0.6073 macroEMD=0.1873 tailR0=('0.1739', '0.1250', '0.0000') tailR0avg=0.0996
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   14   37    3    0
     0    7   95   21    3
     0    0   33   75    8
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0   11   35    6    0
     0   11   69   41    1
     0    1   24  105    3
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   40   27    1    0
     0   29  102   21    0
     0    3   23   73    2
     0    0    1    1    0
[epoch 23] step 2/44: loss=0.0246 
[epoch 23] step 4/44: loss=0.0229 
[epoch 23] step 6/44: loss=0.0235 
[epoch 23] step 8/44: loss=0.0251 
[epoch 23] step 10/44: loss=0.0252 
[epoch 23] step 12/44: loss=0.0254 
[epoch 23] step 14/44: loss=0.0273 
[epoch 23] step 16/44: loss=0.0285 
[epoch 23] step 18/44: loss=0.0284 
[epoch 23] step 20/44: loss=0.0287 
[epoch 23] step 22/44: loss=0.0282 
[epoch 23] step 24/44: loss=0.0282 
[epoch 23] step 26/44: loss=0.0279 
[epoch 23] step 28/44: loss=0.0283 
[epoch 23] step 30/44: loss=0.0288 
[epoch 23] step 32/44: loss=0.0284 
[epoch 23] step 34/44: loss=0.0284 
[epoch 23] step 36/44: loss=0.0284 
[epoch 23] step 38/44: loss=0.0285 
[epoch 23] step 40/44: loss=0.0282 
[epoch 23] step 42/44: loss=0.0284 
[epoch 23] step 44/44: loss=0.0290 
[epoch 23] val_loss=1.8641 qwk=('0.6020', '0.5772', '0.6474') averageQWK=0.6088 macroEMD=0.1835 tailR0=('0.1739', '0.1250', '0.0000') tailR0avg=0.0996
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   14   36    4    0
     0    3   92   29    2
     0    0   31   78    7
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0    5   45    2    0
     0    8   86   27    1
     0    1   29   95    8
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   27   40    1    0
     0   18  106   28    0
     0    0   22   77    2
     0    0    0    2    0
[epoch 24] step 2/44: loss=0.0221 
[epoch 24] step 4/44: loss=0.0248 
[epoch 24] step 6/44: loss=0.0248 
[epoch 24] step 8/44: loss=0.0241 
[epoch 24] step 10/44: loss=0.0227 
[epoch 24] step 12/44: loss=0.0228 
[epoch 24] step 14/44: loss=0.0226 
[epoch 24] step 16/44: loss=0.0222 
[epoch 24] step 18/44: loss=0.0219 
[epoch 24] step 20/44: loss=0.0213 
[epoch 24] step 22/44: loss=0.0218 
[epoch 24] step 24/44: loss=0.0223 
[epoch 24] step 26/44: loss=0.0222 
[epoch 24] step 28/44: loss=0.0222 
[epoch 24] step 30/44: loss=0.0225 
[epoch 24] step 32/44: loss=0.0226 
[epoch 24] step 34/44: loss=0.0221 
[epoch 24] step 36/44: loss=0.0219 
[epoch 24] step 38/44: loss=0.0220 
[epoch 24] step 40/44: loss=0.0216 
[epoch 24] step 42/44: loss=0.0214 
[epoch 24] step 44/44: loss=0.0210 
[epoch 24] val_loss=1.8558 qwk=('0.6117', '0.5917', '0.6617') averageQWK=0.6217 macroEMD=0.1816 tailR0=('0.1957', '0.1250', '0.0000') tailR0avg=0.1069
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   15   36    3    0
     0    5   99   18    4
     0    0   39   68    9
     0    0    0   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0   15   34    3    0
     0   11   74   36    1
     0    1   27   99    6
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   33    3    0
     0   20  107   25    0
     0    0   20   79    2
     0    0    0    2    0
[epoch 25] step 2/44: loss=0.0163 
[epoch 25] step 4/44: loss=0.0168 
[epoch 25] step 6/44: loss=0.0191 
[epoch 25] step 8/44: loss=0.0194 
[epoch 25] step 10/44: loss=0.0183 
[epoch 25] step 12/44: loss=0.0184 
[epoch 25] step 14/44: loss=0.0179 
[epoch 25] step 16/44: loss=0.0170 
[epoch 25] step 18/44: loss=0.0169 
[epoch 25] step 20/44: loss=0.0170 
[epoch 25] step 22/44: loss=0.0171 
[epoch 25] step 24/44: loss=0.0175 
[epoch 25] step 26/44: loss=0.0179 
[epoch 25] step 28/44: loss=0.0185 
[epoch 25] step 30/44: loss=0.0195 
[epoch 25] step 32/44: loss=0.0196 
[epoch 25] step 34/44: loss=0.0196 
[epoch 25] step 36/44: loss=0.0193 
[epoch 25] step 38/44: loss=0.0192 
[epoch 25] step 40/44: loss=0.0193 
[epoch 25] step 42/44: loss=0.0196 
[epoch 25] step 44/44: loss=0.0197 
[epoch 25] val_loss=1.9570 qwk=('0.6136', '0.5623', '0.6540') averageQWK=0.6100 macroEMD=0.1859 tailR0=('0.1522', '0.1250', '0.0000') tailR0avg=0.0924
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   14   37    3    0
     0    5   89   30    2
     0    0   26   82    8
     0    0    0   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0    9   38    5    0
     0    9   72   40    1
     0    0   25  104    4
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   28   39    1    0
     0   20  107   25    0
     0    0   22   77    2
     0    0    0    2    0
[epoch 26] step 2/44: loss=0.0149 
[epoch 26] step 4/44: loss=0.0155 
[epoch 26] step 6/44: loss=0.0174 
[epoch 26] step 8/44: loss=0.0169 
[epoch 26] step 10/44: loss=0.0157 
[epoch 26] step 12/44: loss=0.0158 
[epoch 26] step 14/44: loss=0.0152 
[epoch 26] step 16/44: loss=0.0156 
[epoch 26] step 18/44: loss=0.0162 
[epoch 26] step 20/44: loss=0.0160 
[epoch 26] step 22/44: loss=0.0156 
[epoch 26] step 24/44: loss=0.0159 
[epoch 26] step 26/44: loss=0.0156 
[epoch 26] step 28/44: loss=0.0155 
[epoch 26] step 30/44: loss=0.0156 
[epoch 26] step 32/44: loss=0.0158 
[epoch 26] step 34/44: loss=0.0155 
[epoch 26] step 36/44: loss=0.0154 
[epoch 26] step 38/44: loss=0.0158 
[epoch 26] step 40/44: loss=0.0157 
[epoch 26] step 42/44: loss=0.0155 
[epoch 26] step 44/44: loss=0.0153 
[epoch 26] val_loss=1.9734 qwk=('0.6269', '0.5948', '0.6648') averageQWK=0.6288 macroEMD=0.1806 tailR0=('0.1522', '0.1250', '0.0000') tailR0avg=0.0924
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   15   36    3    0
     0    7   94   23    2
     0    0   31   81    4
     0    0    0   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   12   38    2    0
     0    9   86   26    1
     0    2   30   97    4
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   33    0    0
     0   26  103   23    0
     0    1   24   74    2
     0    0    0    2    0
[epoch 27] step 2/44: loss=0.0142 
[epoch 27] step 4/44: loss=0.0142 
[epoch 27] step 6/44: loss=0.0132 
[epoch 27] step 8/44: loss=0.0125 
[epoch 27] step 10/44: loss=0.0122 
[epoch 27] step 12/44: loss=0.0128 
[epoch 27] step 14/44: loss=0.0136 
[epoch 27] step 16/44: loss=0.0140 
[epoch 27] step 18/44: loss=0.0147 
[epoch 27] step 20/44: loss=0.0143 
[epoch 27] step 22/44: loss=0.0141 
[epoch 27] step 24/44: loss=0.0138 
[epoch 27] step 26/44: loss=0.0136 
[epoch 27] step 28/44: loss=0.0137 
[epoch 27] step 30/44: loss=0.0135 
[epoch 27] step 32/44: loss=0.0136 
[epoch 27] step 34/44: loss=0.0134 
[epoch 27] step 36/44: loss=0.0138 
[epoch 27] step 38/44: loss=0.0140 
[epoch 27] step 40/44: loss=0.0141 
[epoch 27] step 42/44: loss=0.0139 
[epoch 27] step 44/44: loss=0.0135 
[epoch 27] val_loss=2.0147 qwk=('0.6083', '0.5833', '0.6313') averageQWK=0.6076 macroEMD=0.1850 tailR0=('0.1739', '0.1250', '0.0000') tailR0avg=0.0996
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   16   35    3    0
     0    5   92   25    4
     0    0   31   77    8
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0    9   40    3    0
     0    9   87   25    1
     0    1   31   99    2
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   31    2    0
     0   23  108   21    0
     0    1   29   70    1
     0    0    1    1    0
[epoch 28] step 2/44: loss=0.0098 
[epoch 28] step 4/44: loss=0.0099 
[epoch 28] step 6/44: loss=0.0122 
[epoch 28] step 8/44: loss=0.0134 
[epoch 28] step 10/44: loss=0.0127 
[epoch 28] step 12/44: loss=0.0126 
[epoch 28] step 14/44: loss=0.0125 
[epoch 28] step 16/44: loss=0.0120 
[epoch 28] step 18/44: loss=0.0122 
[epoch 28] step 20/44: loss=0.0117 
[epoch 28] step 22/44: loss=0.0115 
[epoch 28] step 24/44: loss=0.0114 
[epoch 28] step 26/44: loss=0.0112 
[epoch 28] step 28/44: loss=0.0114 
[epoch 28] step 30/44: loss=0.0111 
[epoch 28] step 32/44: loss=0.0109 
[epoch 28] step 34/44: loss=0.0109 
[epoch 28] step 36/44: loss=0.0108 
[epoch 28] step 38/44: loss=0.0108 
[epoch 28] step 40/44: loss=0.0107 
[epoch 28] step 42/44: loss=0.0108 
[epoch 28] step 44/44: loss=0.0106 
[epoch 28] val_loss=2.0766 qwk=('0.6046', '0.5956', '0.6229') averageQWK=0.6077 macroEMD=0.1836 tailR0=('0.1739', '0.1250', '0.0000') tailR0avg=0.0996
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   14   37    3    0
     0    5   91   26    4
     0    0   29   80    7
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   12   37    3    0
     0   10   82   29    1
     0    1   28  100    4
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   30   36    2    0
     0   21  109   22    0
     0    0   29   70    2
     0    0    0    2    0
[epoch 29] step 2/44: loss=0.0085 
[epoch 29] step 4/44: loss=0.0103 
[epoch 29] step 6/44: loss=0.0109 
[epoch 29] step 8/44: loss=0.0107 
[epoch 29] step 10/44: loss=0.0105 
[epoch 29] step 12/44: loss=0.0104 
[epoch 29] step 14/44: loss=0.0102 
[epoch 29] step 16/44: loss=0.0105 
[epoch 29] step 18/44: loss=0.0102 
[epoch 29] step 20/44: loss=0.0098 
[epoch 29] step 22/44: loss=0.0095 
[epoch 29] step 24/44: loss=0.0094 
[epoch 29] step 26/44: loss=0.0094 
[epoch 29] step 28/44: loss=0.0094 
[epoch 29] step 30/44: loss=0.0095 
[epoch 29] step 32/44: loss=0.0093 
[epoch 29] step 34/44: loss=0.0092 
[epoch 29] step 36/44: loss=0.0094 
[epoch 29] step 38/44: loss=0.0093 
[epoch 29] step 40/44: loss=0.0091 
[epoch 29] step 42/44: loss=0.0094 
[epoch 29] step 44/44: loss=0.0094 
[epoch 29] val_loss=2.0596 qwk=('0.6212', '0.5683', '0.6573') averageQWK=0.6156 macroEMD=0.1807 tailR0=('0.1957', '0.1250', '0.0000') tailR0avg=0.1069
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   14   37    3    0
     0    3   99   21    3
     0    0   31   77    8
     0    0    0   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0   12   35    5    0
     0   10   74   37    1
     0    2   23  103    5
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   34   31    3    0
     0   23  104   25    0
     0    0   22   77    2
     0    0    0    2    0
[epoch 30] step 2/44: loss=0.0060 
[epoch 30] step 4/44: loss=0.0067 
[epoch 30] step 6/44: loss=0.0073 
[epoch 30] step 8/44: loss=0.0074 
[epoch 30] step 10/44: loss=0.0074 
[epoch 30] step 12/44: loss=0.0071 
[epoch 30] step 14/44: loss=0.0071 
[epoch 30] step 16/44: loss=0.0069 
[epoch 30] step 18/44: loss=0.0069 
[epoch 30] step 20/44: loss=0.0072 
[epoch 30] step 22/44: loss=0.0073 
[epoch 30] step 24/44: loss=0.0072 
[epoch 30] step 26/44: loss=0.0075 
[epoch 30] step 28/44: loss=0.0074 
[epoch 30] step 30/44: loss=0.0073 
[epoch 30] step 32/44: loss=0.0072 
[epoch 30] step 34/44: loss=0.0072 
[epoch 30] step 36/44: loss=0.0071 
[epoch 30] step 38/44: loss=0.0071 
[epoch 30] step 40/44: loss=0.0075 
[epoch 30] step 42/44: loss=0.0076 
[epoch 30] step 44/44: loss=0.0076 
[epoch 30] val_loss=2.1546 qwk=('0.6087', '0.5420', '0.6355') averageQWK=0.5954 macroEMD=0.1852 tailR0=('0.1739', '0.1250', '0.0000') tailR0avg=0.0996
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   15   35    4    0
     0    3   90   29    4
     0    0   25   84    7
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0    7   40    5    0
     0    9   76   36    1
     0    1   26  102    4
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   28   38    2    0
     0   20  109   23    0
     0    0   26   73    2
     0    0    0    2    0
[epoch 31] step 2/44: loss=0.0063 
[epoch 31] step 4/44: loss=0.0055 
[epoch 31] step 6/44: loss=0.0053 
[epoch 31] step 8/44: loss=0.0054 
[epoch 31] step 10/44: loss=0.0058 
[epoch 31] step 12/44: loss=0.0059 
[epoch 31] step 14/44: loss=0.0061 
[epoch 31] step 16/44: loss=0.0059 
[epoch 31] step 18/44: loss=0.0061 
[epoch 31] step 20/44: loss=0.0060 
[epoch 31] step 22/44: loss=0.0060 
[epoch 31] step 24/44: loss=0.0061 
[epoch 31] step 26/44: loss=0.0060 
[epoch 31] step 28/44: loss=0.0060 
[epoch 31] step 30/44: loss=0.0064 
[epoch 31] step 32/44: loss=0.0063 
[epoch 31] step 34/44: loss=0.0063 
[epoch 31] step 36/44: loss=0.0064 
[epoch 31] step 38/44: loss=0.0064 
[epoch 31] step 40/44: loss=0.0064 
[epoch 31] step 42/44: loss=0.0064 
[epoch 31] step 44/44: loss=0.0069 
[epoch 31] val_loss=2.1410 qwk=('0.6119', '0.5547', '0.6480') averageQWK=0.6048 macroEMD=0.1834 tailR0=('0.1739', '0.1250', '0.0000') tailR0avg=0.0996
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   17   33    4    0
     0    7   90   25    4
     0    0   28   82    6
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0    7   41    4    0
     0    9   79   33    1
     0    0   29  100    4
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   34    2    0
     0   21  107   24    0
     0    0   26   74    1
     0    0    0    2    0
[epoch 32] step 2/44: loss=0.0062 
[epoch 32] step 4/44: loss=0.0068 
[epoch 32] step 6/44: loss=0.0062 
[epoch 32] step 8/44: loss=0.0061 
[epoch 32] step 10/44: loss=0.0063 
[epoch 32] step 12/44: loss=0.0063 
[epoch 32] step 14/44: loss=0.0061 
[epoch 32] step 16/44: loss=0.0063 
[epoch 32] step 18/44: loss=0.0061 
[epoch 32] step 20/44: loss=0.0060 
[epoch 32] step 22/44: loss=0.0058 
[epoch 32] step 24/44: loss=0.0058 
[epoch 32] step 26/44: loss=0.0059 
[epoch 32] step 28/44: loss=0.0064 
[epoch 32] step 30/44: loss=0.0064 
[epoch 32] step 32/44: loss=0.0063 
[epoch 32] step 34/44: loss=0.0062 
[epoch 32] step 36/44: loss=0.0061 
[epoch 32] step 38/44: loss=0.0062 
[epoch 32] step 40/44: loss=0.0061 
[epoch 32] step 42/44: loss=0.0061 
[epoch 32] step 44/44: loss=0.0061 
[epoch 32] val_loss=2.1654 qwk=('0.6174', '0.5612', '0.6450') averageQWK=0.6079 macroEMD=0.1823 tailR0=('0.1739', '0.1250', '0.0000') tailR0avg=0.0996
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   17   34    3    0
     0    7   91   24    4
     0    0   29   81    6
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0    9   39    4    0
     0    8   77   36    1
     0    0   28  100    5
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   30   36    2    0
     0   20  106   26    0
     0    0   24   76    1
     0    0    0    2    0
[epoch 33] step 2/44: loss=0.0048 
[epoch 33] step 4/44: loss=0.0047 
[epoch 33] step 6/44: loss=0.0047 
[epoch 33] step 8/44: loss=0.0044 
[epoch 33] step 10/44: loss=0.0052 
[epoch 33] step 12/44: loss=0.0049 
[epoch 33] step 14/44: loss=0.0048 
[epoch 33] step 16/44: loss=0.0052 
[epoch 33] step 18/44: loss=0.0055 
[epoch 33] step 20/44: loss=0.0053 
[epoch 33] step 22/44: loss=0.0053 
[epoch 33] step 24/44: loss=0.0053 
[epoch 33] step 26/44: loss=0.0052 
[epoch 33] step 28/44: loss=0.0053 
[epoch 33] step 30/44: loss=0.0052 
[epoch 33] step 32/44: loss=0.0051 
[epoch 33] step 34/44: loss=0.0051 
[epoch 33] step 36/44: loss=0.0052 
[epoch 33] step 38/44: loss=0.0052 
[epoch 33] step 40/44: loss=0.0053 
[epoch 33] step 42/44: loss=0.0053 
[epoch 33] step 44/44: loss=0.0052 
[epoch 33] val_loss=2.1764 qwk=('0.6165', '0.5634', '0.6480') averageQWK=0.6093 macroEMD=0.1820 tailR0=('0.1739', '0.1250', '0.0000') tailR0avg=0.0996
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   16   35    3    0
     0    5   95   22    4
     0    0   30   78    8
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0    9   39    4    0
     0    8   78   35    1
     0    1   25  102    5
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   33   33    2    0
     0   21  105   26    0
     0    0   26   74    1
     0    0    0    2    0
[epoch 34] step 2/44: loss=0.0038 
[epoch 34] step 4/44: loss=0.0062 
[epoch 34] step 6/44: loss=0.0054 
[epoch 34] step 8/44: loss=0.0055 
[epoch 34] step 10/44: loss=0.0054 
[epoch 34] step 12/44: loss=0.0052 
[epoch 34] step 14/44: loss=0.0051 
[epoch 34] step 16/44: loss=0.0053 
[epoch 34] step 18/44: loss=0.0054 
[epoch 34] step 20/44: loss=0.0055 
[epoch 34] step 22/44: loss=0.0059 
[epoch 34] step 24/44: loss=0.0060 
[epoch 34] step 26/44: loss=0.0059 
[epoch 34] step 28/44: loss=0.0058 
[epoch 34] step 30/44: loss=0.0057 
[epoch 34] step 32/44: loss=0.0056 
[epoch 34] step 34/44: loss=0.0055 
[epoch 34] step 36/44: loss=0.0055 
[epoch 34] step 38/44: loss=0.0055 
[epoch 34] step 40/44: loss=0.0055 
[epoch 34] step 42/44: loss=0.0055 
[epoch 34] step 44/44: loss=0.0054 
[epoch 34] val_loss=2.2059 qwk=('0.6083', '0.5636', '0.6339') averageQWK=0.6019 macroEMD=0.1850 tailR0=('0.1739', '0.1250', '0.0000') tailR0avg=0.0996
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   15   36    3    0
     0    4   90   28    4
     0    0   28   83    5
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0    7   41    4    0
     0    8   78   35    1
     0    0   29  100    4
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   29   37    2    0
     0   20  108   24    0
     0    0   27   72    2
     0    0    0    2    0
[epoch 35] step 2/44: loss=0.0049 
[epoch 35] step 4/44: loss=0.0044 
[epoch 35] step 6/44: loss=0.0051 
[epoch 35] step 8/44: loss=0.0055 
[epoch 35] step 10/44: loss=0.0057 
[epoch 35] step 12/44: loss=0.0054 
[epoch 35] step 14/44: loss=0.0053 
[epoch 35] step 16/44: loss=0.0053 
[epoch 35] step 18/44: loss=0.0054 
[epoch 35] step 20/44: loss=0.0055 
[epoch 35] step 22/44: loss=0.0054 
[epoch 35] step 24/44: loss=0.0054 
[epoch 35] step 26/44: loss=0.0056 
[epoch 35] step 28/44: loss=0.0055 
[epoch 35] step 30/44: loss=0.0055 
[epoch 35] step 32/44: loss=0.0055 
[epoch 35] step 34/44: loss=0.0055 
[epoch 35] step 36/44: loss=0.0054 
[epoch 35] step 38/44: loss=0.0053 
[epoch 35] step 40/44: loss=0.0052 
[epoch 35] step 42/44: loss=0.0052 
[epoch 35] step 44/44: loss=0.0052 
[epoch 35] val_loss=2.1777 qwk=('0.6133', '0.5683', '0.6387') averageQWK=0.6067 macroEMD=0.1825 tailR0=('0.1739', '0.1250', '0.0000') tailR0avg=0.0996
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   16   35    3    0
     0    6   94   22    4
     0    0   31   80    5
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0    9   39    4    0
     0    9   80   32    1
     0    1   29   99    4
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   35    2    0
     0   22  106   24    0
     0    0   27   72    2
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/ce/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/ce/fold1/metrics.json
Done.
