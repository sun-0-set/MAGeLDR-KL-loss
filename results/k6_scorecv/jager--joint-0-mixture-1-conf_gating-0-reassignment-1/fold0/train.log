[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.7623 
[epoch 1] step 4/44: loss=0.7385 
[epoch 1] step 6/44: loss=0.7266 
[epoch 1] step 8/44: loss=0.7187 
[epoch 1] step 10/44: loss=0.7151 
[epoch 1] step 12/44: loss=0.7129 
[epoch 1] step 14/44: loss=0.7119 
[epoch 1] step 16/44: loss=0.7122 
[epoch 1] step 18/44: loss=0.7148 
[epoch 1] step 20/44: loss=0.7147 
[epoch 1] step 22/44: loss=0.7156 
[epoch 1] step 24/44: loss=0.7163 
[epoch 1] step 26/44: loss=0.7139 
[epoch 1] step 28/44: loss=0.7123 
[epoch 1] step 30/44: loss=0.7120 
[epoch 1] step 32/44: loss=0.7112 
[epoch 1] step 34/44: loss=0.7109 
[epoch 1] step 36/44: loss=0.7106 
[epoch 1] step 38/44: loss=0.7101 
[epoch 1] step 40/44: loss=0.7110 
[epoch 1] step 42/44: loss=0.7127 
[epoch 1] step 44/44: loss=0.7176 
[epoch 1] train_loss(avg per step)=1.4352 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.4985 qwk=('0.1338', '0.1250', '0.0924') averageQWK=0.1170 macroEMD=0.3786 tailR0=('0.0000', '0.1667', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    5    0
     0   27    0   28    0
     0   67    0   58    0
     0   47    0   69    0
     0    4    0   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    6    0    0
    24    0   27    1    0
    54    0   61    6    0
    39    0   75   20    0
     2    0    7    3    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   19   50    0    0
     0   16  135    0    0
     0   12   88    1    0
     0    1    1    0    0
[epoch 2] step 2/44: loss=0.8653 
[epoch 2] step 4/44: loss=0.8803 
[epoch 2] step 6/44: loss=0.9149 
[epoch 2] step 8/44: loss=0.9440 
[epoch 2] step 10/44: loss=0.9652 
[epoch 2] step 12/44: loss=0.9651 
[epoch 2] step 14/44: loss=0.9565 
[epoch 2] step 16/44: loss=0.9447 
[epoch 2] step 18/44: loss=0.9325 
[epoch 2] step 20/44: loss=0.9195 
[epoch 2] step 22/44: loss=0.9047 
[epoch 2] step 24/44: loss=0.8940 
[epoch 2] step 26/44: loss=0.8830 
[epoch 2] step 28/44: loss=0.8792 
[epoch 2] step 30/44: loss=0.8773 
[epoch 2] step 32/44: loss=0.8749 
[epoch 2] step 34/44: loss=0.8726 
[epoch 2] step 36/44: loss=0.8697 
[epoch 2] step 38/44: loss=0.8652 
[epoch 2] step 40/44: loss=0.8610 
[epoch 2] step 42/44: loss=0.8550 
[epoch 2] step 44/44: loss=0.8506 
[epoch 2] train_loss(avg per step)=1.7013 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.2461 qwk=('0.4387', '0.4348', '0.4452') averageQWK=0.4396 macroEMD=0.3550 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    0    0
     0   51    0    4    0
     0   90    0   35    0
     0   35    0   81    0
     0    7    0   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   46    6    0
     0    0   85   36    0
     0    0   29  105    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   65    3    1    0
     0  104   11   36    0
     0   30   10   61    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=0.6947 
[epoch 3] step 4/44: loss=0.7152 
[epoch 3] step 6/44: loss=0.7165 
[epoch 3] step 8/44: loss=0.7261 
[epoch 3] step 10/44: loss=0.7323 
[epoch 3] step 12/44: loss=0.7381 
[epoch 3] step 14/44: loss=0.7468 
[epoch 3] step 16/44: loss=0.7524 
[epoch 3] step 18/44: loss=0.7623 
[epoch 3] step 20/44: loss=0.7677 
[epoch 3] step 22/44: loss=0.7746 
[epoch 3] step 24/44: loss=0.7840 
[epoch 3] step 26/44: loss=0.7912 
[epoch 3] step 28/44: loss=0.7940 
[epoch 3] step 30/44: loss=0.7935 
[epoch 3] step 32/44: loss=0.7950 
[epoch 3] step 34/44: loss=0.7954 
[epoch 3] step 36/44: loss=0.7987 
[epoch 3] step 38/44: loss=0.8018 
[epoch 3] step 40/44: loss=0.8027 
[epoch 3] step 42/44: loss=0.8015 
[epoch 3] step 44/44: loss=0.7975 
[epoch 3] train_loss(avg per step)=1.5949 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=1.4183 qwk=('0.5671', '0.4293', '0.5367') averageQWK=0.5111 macroEMD=0.3241 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   13   40    2    0
     0    1   91   33    0
     0    0   21   95    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   10   24   18    0
     0   10   30   81    0
     0    0    4  130    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   26   35    8    0
     0   15   60   76    0
     0    0    4   97    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=0.8160 
[epoch 4] step 4/44: loss=0.7987 
[epoch 4] step 6/44: loss=0.8274 
[epoch 4] step 8/44: loss=0.8359 
[epoch 4] step 10/44: loss=0.8267 
[epoch 4] step 12/44: loss=0.8268 
[epoch 4] step 14/44: loss=0.8307 
[epoch 4] step 16/44: loss=0.8281 
[epoch 4] step 18/44: loss=0.8309 
[epoch 4] step 20/44: loss=0.8332 
[epoch 4] step 22/44: loss=0.8313 
[epoch 4] step 24/44: loss=0.8311 
[epoch 4] step 26/44: loss=0.8308 
[epoch 4] step 28/44: loss=0.8287 
[epoch 4] step 30/44: loss=0.8234 
[epoch 4] step 32/44: loss=0.8210 
[epoch 4] step 34/44: loss=0.8183 
[epoch 4] step 36/44: loss=0.8172 
[epoch 4] step 38/44: loss=0.8185 
[epoch 4] step 40/44: loss=0.8180 
[epoch 4] step 42/44: loss=0.8188 
[epoch 4] step 44/44: loss=0.8177 
[epoch 4] train_loss(avg per step)=1.6354 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=1.3842 qwk=('0.5470', '0.5757', '0.5796') averageQWK=0.5674 macroEMD=0.3082 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0   12   39    4    0
     0    3   88   34    0
     0    0   16  100    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   10   37    5    0
     0    5   68   48    0
     0    0    4  130    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     0   16   50    3    0
     0    5   93   53    0
     0    0   10   91    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=0.7950 
[epoch 5] step 4/44: loss=0.7798 
[epoch 5] step 6/44: loss=0.7813 
[epoch 5] step 8/44: loss=0.7979 
[epoch 5] step 10/44: loss=0.8111 
[epoch 5] step 12/44: loss=0.8069 
[epoch 5] step 14/44: loss=0.8109 
[epoch 5] step 16/44: loss=0.8105 
[epoch 5] step 18/44: loss=0.8118 
[epoch 5] step 20/44: loss=0.8156 
[epoch 5] step 22/44: loss=0.8215 
[epoch 5] step 24/44: loss=0.8209 
[epoch 5] step 26/44: loss=0.8178 
[epoch 5] step 28/44: loss=0.8124 
[epoch 5] step 30/44: loss=0.8091 
[epoch 5] step 32/44: loss=0.8051 
[epoch 5] step 34/44: loss=0.8066 
[epoch 5] step 36/44: loss=0.8038 
[epoch 5] step 38/44: loss=0.8029 
[epoch 5] step 40/44: loss=0.8045 
[epoch 5] step 42/44: loss=0.8065 
[epoch 5] step 44/44: loss=0.8057 
[epoch 5] train_loss(avg per step)=1.6114 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=1.3893 qwk=('0.5577', '0.5877', '0.6935') averageQWK=0.6130 macroEMD=0.2992 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    0
     0   11   42    2    0
     0    3   95   27    0
     0    0   23   93    0
     0    0    4   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    0    0
     0    8   41    3    0
     0    5   87   29    0
     0    0   19  115    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   45   22    2    0
     0   29   95   27    0
     0    0   21   80    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=0.8155 
[epoch 6] step 4/44: loss=0.8261 
[epoch 6] step 6/44: loss=0.8123 
[epoch 6] step 8/44: loss=0.8135 
[epoch 6] step 10/44: loss=0.8181 
[epoch 6] step 12/44: loss=0.8201 
[epoch 6] step 14/44: loss=0.8267 
[epoch 6] step 16/44: loss=0.8318 
[epoch 6] step 18/44: loss=0.8365 
[epoch 6] step 20/44: loss=0.8402 
[epoch 6] step 22/44: loss=0.8387 
[epoch 6] step 24/44: loss=0.8354 
[epoch 6] step 26/44: loss=0.8319 
[epoch 6] step 28/44: loss=0.8267 
[epoch 6] step 30/44: loss=0.8236 
[epoch 6] step 32/44: loss=0.8239 
[epoch 6] step 34/44: loss=0.8239 
[epoch 6] step 36/44: loss=0.8189 
[epoch 6] step 38/44: loss=0.8165 
[epoch 6] step 40/44: loss=0.8154 
[epoch 6] step 42/44: loss=0.8151 
[epoch 6] step 44/44: loss=0.8138 
[epoch 6] train_loss(avg per step)=1.6276 lambda[min,max]=[0.498477,1.000000]
[epoch 6] val_loss=1.4353 qwk=('0.5274', '0.5251', '0.6519') averageQWK=0.5682 macroEMD=0.2907 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    5   46    4    0
     0    2   85   38    0
     0    0   14  102    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0    7   38    7    0
     0    5   63   53    0
     0    0    8  126    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   31   36    2    0
     0   16   98   37    0
     0    0   16   85    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=0.7971 
[epoch 7] step 4/44: loss=0.8182 
[epoch 7] step 6/44: loss=0.7933 
[epoch 7] step 8/44: loss=0.7943 
[epoch 7] step 10/44: loss=0.8007 
[epoch 7] step 12/44: loss=0.7967 
[epoch 7] step 14/44: loss=0.7946 
[epoch 7] step 16/44: loss=0.7931 
[epoch 7] step 18/44: loss=0.7927 
[epoch 7] step 20/44: loss=0.7924 
[epoch 7] step 22/44: loss=0.7923 
[epoch 7] step 24/44: loss=0.7931 
[epoch 7] step 26/44: loss=0.7902 
[epoch 7] step 28/44: loss=0.7882 
[epoch 7] step 30/44: loss=0.7856 
[epoch 7] step 32/44: loss=0.7864 
[epoch 7] step 34/44: loss=0.7870 
[epoch 7] step 36/44: loss=0.7865 
[epoch 7] step 38/44: loss=0.7835 
[epoch 7] step 40/44: loss=0.7859 
[epoch 7] step 42/44: loss=0.7870 
[epoch 7] step 44/44: loss=0.7869 
[epoch 7] train_loss(avg per step)=1.5738 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.3809 qwk=('0.5807', '0.6032', '0.6275') averageQWK=0.6038 macroEMD=0.2825 tailR0=('0.1739', '0.0000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0    7   46    2    0
     0    2  105   18    0
     0    0   31   78    7
     0    0    6    9    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   11   39    2    0
     0    6   84   31    0
     0    1   19  114    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   37    1    0
     0   21  106   24    0
     0    0   32   69    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=0.7807 
[epoch 8] step 4/44: loss=0.7909 
[epoch 8] step 6/44: loss=0.7861 
[epoch 8] step 8/44: loss=0.7901 
[epoch 8] step 10/44: loss=0.7818 
[epoch 8] step 12/44: loss=0.7805 
[epoch 8] step 14/44: loss=0.7788 
[epoch 8] step 16/44: loss=0.7777 
[epoch 8] step 18/44: loss=0.7775 
[epoch 8] step 20/44: loss=0.7804 
[epoch 8] step 22/44: loss=0.7830 
[epoch 8] step 24/44: loss=0.7842 
[epoch 8] step 26/44: loss=0.7838 
[epoch 8] step 28/44: loss=0.7830 
[epoch 8] step 30/44: loss=0.7825 
[epoch 8] step 32/44: loss=0.7841 
[epoch 8] step 34/44: loss=0.7834 
[epoch 8] step 36/44: loss=0.7789 
[epoch 8] step 38/44: loss=0.7810 
[epoch 8] step 40/44: loss=0.7817 
[epoch 8] step 42/44: loss=0.7801 
[epoch 8] step 44/44: loss=0.7813 
[epoch 8] train_loss(avg per step)=1.5625 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.4043 qwk=('0.6453', '0.5838', '0.6234') averageQWK=0.6175 macroEMD=0.2793 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   17   35    3    0
     0    8   84   33    0
     0    0   14   96    6
     0    0    2   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   18   26    8    0
     0   14   58   49    0
     0    0    8  126    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   22   45    2    0
     0    9  105   37    0
     0    0   17   84    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=0.7676 
[epoch 9] step 4/44: loss=0.7582 
[epoch 9] step 6/44: loss=0.7721 
[epoch 9] step 8/44: loss=0.7743 
[epoch 9] step 10/44: loss=0.7766 
[epoch 9] step 12/44: loss=0.7769 
[epoch 9] step 14/44: loss=0.7705 
[epoch 9] step 16/44: loss=0.7681 
[epoch 9] step 18/44: loss=0.7674 
[epoch 9] step 20/44: loss=0.7643 
[epoch 9] step 22/44: loss=0.7616 
[epoch 9] step 24/44: loss=0.7598 
[epoch 9] step 26/44: loss=0.7603 
[epoch 9] step 28/44: loss=0.7619 
[epoch 9] step 30/44: loss=0.7603 
[epoch 9] step 32/44: loss=0.7615 
[epoch 9] step 34/44: loss=0.7611 
[epoch 9] step 36/44: loss=0.7596 
[epoch 9] step 38/44: loss=0.7631 
[epoch 9] step 40/44: loss=0.7619 
[epoch 9] step 42/44: loss=0.7625 
[epoch 9] step 44/44: loss=0.7591 
[epoch 9] train_loss(avg per step)=1.5183 lambda[min,max]=[0.493805,1.000000]
[epoch 9] val_loss=1.3724 qwk=('0.6349', '0.6281', '0.6205') averageQWK=0.6279 macroEMD=0.2754 tailR0=('0.1739', '0.0000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   23   26    6    0
     0   10   72   42    1
     0    0   14   93    9
     0    0    3   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   20   27    5    0
     0   12   67   42    0
     0    0   12  122    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   28   40    1    0
     0   21  103   27    0
     0    0   29   72    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=0.7771 
[epoch 10] step 4/44: loss=0.7808 
[epoch 10] step 6/44: loss=0.7701 
[epoch 10] step 8/44: loss=0.7778 
[epoch 10] step 10/44: loss=0.7761 
[epoch 10] step 12/44: loss=0.7790 
[epoch 10] step 14/44: loss=0.7739 
[epoch 10] step 16/44: loss=0.7748 
[epoch 10] step 18/44: loss=0.7709 
[epoch 10] step 20/44: loss=0.7673 
[epoch 10] step 22/44: loss=0.7628 
[epoch 10] step 24/44: loss=0.7599 
[epoch 10] step 26/44: loss=0.7576 
[epoch 10] step 28/44: loss=0.7586 
[epoch 10] step 30/44: loss=0.7570 
[epoch 10] step 32/44: loss=0.7541 
[epoch 10] step 34/44: loss=0.7494 
[epoch 10] step 36/44: loss=0.7484 
[epoch 10] step 38/44: loss=0.7494 
[epoch 10] step 40/44: loss=0.7493 
[epoch 10] step 42/44: loss=0.7480 
[epoch 10] step 44/44: loss=0.7495 
[epoch 10] train_loss(avg per step)=1.4989 lambda[min,max]=[0.499237,1.000000]
[epoch 10] val_loss=1.4241 qwk=('0.6419', '0.6720', '0.5947') averageQWK=0.6362 macroEMD=0.2748 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   30   22    3    0
     0   20   72   32    1
     0    0   18   93    5
     0    0    5   15    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   33   15    4    0
     0   35   52   34    0
     0    0   21  113    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   42   26    1    0
     0   42   87   22    0
     0    3   33   65    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.7926 
[epoch 11] step 4/44: loss=0.7880 
[epoch 11] step 6/44: loss=0.7701 
[epoch 11] step 8/44: loss=0.7790 
[epoch 11] step 10/44: loss=0.7672 
[epoch 11] step 12/44: loss=0.7585 
[epoch 11] step 14/44: loss=0.7494 
[epoch 11] step 16/44: loss=0.7452 
[epoch 11] step 18/44: loss=0.7421 
[epoch 11] step 20/44: loss=0.7423 
[epoch 11] step 22/44: loss=0.7405 
[epoch 11] step 24/44: loss=0.7397 
[epoch 11] step 26/44: loss=0.7410 
[epoch 11] step 28/44: loss=0.7419 
[epoch 11] step 30/44: loss=0.7433 
[epoch 11] step 32/44: loss=0.7444 
[epoch 11] step 34/44: loss=0.7415 
[epoch 11] step 36/44: loss=0.7400 
[epoch 11] step 38/44: loss=0.7366 
[epoch 11] step 40/44: loss=0.7349 
[epoch 11] step 42/44: loss=0.7363 
[epoch 11] step 44/44: loss=0.7373 
[epoch 11] train_loss(avg per step)=1.4745 lambda[min,max]=[0.446442,1.000000]
[epoch 11] val_loss=1.3173 qwk=('0.5820', '0.6538', '0.5747') averageQWK=0.6035 macroEMD=0.2797 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   20   32    3    0
     0   12   84   28    1
     0    0   21   94    1
     0    0    6   16    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   22   26    4    0
     0   12   78   31    0
     0    0   16  118    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   25   43    1    0
     0   19  109   23    0
     0    0   40   61    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=0.7005 
[epoch 12] step 4/44: loss=0.7026 
[epoch 12] step 6/44: loss=0.7042 
[epoch 12] step 8/44: loss=0.7073 
[epoch 12] step 10/44: loss=0.7192 
[epoch 12] step 12/44: loss=0.7242 
[epoch 12] step 14/44: loss=0.7315 
[epoch 12] step 16/44: loss=0.7347 
[epoch 12] step 18/44: loss=0.7394 
[epoch 12] step 20/44: loss=0.7366 
[epoch 12] step 22/44: loss=0.7455 
[epoch 12] step 24/44: loss=0.7466 
[epoch 12] step 26/44: loss=0.7451 
[epoch 12] step 28/44: loss=0.7441 
[epoch 12] step 30/44: loss=0.7419 
[epoch 12] step 32/44: loss=0.7392 
[epoch 12] step 34/44: loss=0.7362 
[epoch 12] step 36/44: loss=0.7347 
[epoch 12] step 38/44: loss=0.7334 
[epoch 12] step 40/44: loss=0.7309 
[epoch 12] step 42/44: loss=0.7285 
[epoch 12] step 44/44: loss=0.7289 
[epoch 12] train_loss(avg per step)=1.4579 lambda[min,max]=[0.467163,1.000000]
[epoch 12] val_loss=1.2964 qwk=('0.5847', '0.6521', '0.5819') averageQWK=0.6062 macroEMD=0.2781 tailR0=('0.2729', '0.0556', '0.0000') tailR0avg=0.1095
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    2    0
     1   19   27    7    1
     1   13   66   41    4
     0    0   12   97    7
     0    0    3   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     1   18   27    6    0
     0   10   71   40    0
     0    0   10  122    2
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     0   23   45    1    0
     0   16   97   38    0
     0    0   24   77    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.7118 
[epoch 13] step 4/44: loss=0.7056 
[epoch 13] step 6/44: loss=0.7094 
[epoch 13] step 8/44: loss=0.7132 
[epoch 13] step 10/44: loss=0.7190 
[epoch 13] step 12/44: loss=0.7212 
[epoch 13] step 14/44: loss=0.7218 
[epoch 13] step 16/44: loss=0.7208 
[epoch 13] step 18/44: loss=0.7189 
[epoch 13] step 20/44: loss=0.7178 
[epoch 13] step 22/44: loss=0.7151 
[epoch 13] step 24/44: loss=0.7123 
[epoch 13] step 26/44: loss=0.7116 
[epoch 13] step 28/44: loss=0.7092 
[epoch 13] step 30/44: loss=0.7089 
[epoch 13] step 32/44: loss=0.7116 
[epoch 13] step 34/44: loss=0.7112 
[epoch 13] step 36/44: loss=0.7139 
[epoch 13] step 38/44: loss=0.7156 
[epoch 13] step 40/44: loss=0.7145 
[epoch 13] step 42/44: loss=0.7134 
[epoch 13] step 44/44: loss=0.7159 
[epoch 13] train_loss(avg per step)=1.4319 lambda[min,max]=[0.417391,1.000000]
[epoch 13] val_loss=1.3679 qwk=('0.6730', '0.6875', '0.6449') averageQWK=0.6685 macroEMD=0.2763 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   36   18    1    0
     0   26   81   16    2
     0    0   31   82    3
     0    0    6   11    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   36   14    2    0
     0   32   70   19    0
     0    0   36   97    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   34    0    0
     0   20  112   19    0
     0    1   34   66    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.7313 
[epoch 14] step 4/44: loss=0.7351 
[epoch 14] step 6/44: loss=0.7534 
[epoch 14] step 8/44: loss=0.7490 
[epoch 14] step 10/44: loss=0.7487 
[epoch 14] step 12/44: loss=0.7430 
[epoch 14] step 14/44: loss=0.7334 
[epoch 14] step 16/44: loss=0.7306 
[epoch 14] step 18/44: loss=0.7229 
[epoch 14] step 20/44: loss=0.7151 
[epoch 14] step 22/44: loss=0.7097 
[epoch 14] step 24/44: loss=0.7081 
[epoch 14] step 26/44: loss=0.7077 
[epoch 14] step 28/44: loss=0.7073 
[epoch 14] step 30/44: loss=0.7073 
[epoch 14] step 32/44: loss=0.7077 
[epoch 14] step 34/44: loss=0.7096 
[epoch 14] step 36/44: loss=0.7107 
[epoch 14] step 38/44: loss=0.7117 
[epoch 14] step 40/44: loss=0.7124 
[epoch 14] step 42/44: loss=0.7136 
[epoch 14] step 44/44: loss=0.7131 
[epoch 14] train_loss(avg per step)=1.4263 lambda[min,max]=[0.426299,1.000000]
[epoch 14] val_loss=1.2689 qwk=('0.6479', '0.6618', '0.6141') averageQWK=0.6413 macroEMD=0.2773 tailR0=('0.2391', '0.0972', '0.0000') tailR0avg=0.1121
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     1   31   17    5    1
     0   17   68   37    3
     0    0   14   87   15
     0    0    3    9   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     1   25   19    7    0
     1   15   62   43    0
     0    0    8  120    6
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   29   38    2    0
     0   19   99   33    0
     0    0   24   77    0
     0    0    0    2    0
[epoch 15] step 2/44: loss=0.6784 
[epoch 15] step 4/44: loss=0.6779 
[epoch 15] step 6/44: loss=0.6714 
[epoch 15] step 8/44: loss=0.6718 
[epoch 15] step 10/44: loss=0.6749 
[epoch 15] step 12/44: loss=0.6819 
[epoch 15] step 14/44: loss=0.6813 
[epoch 15] step 16/44: loss=0.6857 
[epoch 15] step 18/44: loss=0.6860 
[epoch 15] step 20/44: loss=0.6819 
[epoch 15] step 22/44: loss=0.6802 
[epoch 15] step 24/44: loss=0.6792 
[epoch 15] step 26/44: loss=0.6773 
[epoch 15] step 28/44: loss=0.6772 
[epoch 15] step 30/44: loss=0.6754 
[epoch 15] step 32/44: loss=0.6751 
[epoch 15] step 34/44: loss=0.6741 
[epoch 15] step 36/44: loss=0.6749 
[epoch 15] step 38/44: loss=0.6750 
[epoch 15] step 40/44: loss=0.6765 
[epoch 15] step 42/44: loss=0.6766 
[epoch 15] step 44/44: loss=0.6776 
[epoch 15] train_loss(avg per step)=1.3552 lambda[min,max]=[0.418405,1.000000]
[epoch 15] val_loss=1.3050 qwk=('0.6181', '0.6685', '0.6171') averageQWK=0.6346 macroEMD=0.2762 tailR0=('0.2295', '0.0972', '0.0000') tailR0avg=0.1089
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     1   31   16    6    1
     0   20   64   39    2
     0    0   20   89    7
     0    0    4   11    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     2   23   24    3    0
     0   16   77   27    1
     0    0   22  108    4
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   33   34    2    0
     0   23   99   29    0
     0    1   25   75    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=0.7000 
[epoch 16] step 4/44: loss=0.6698 
[epoch 16] step 6/44: loss=0.6686 
[epoch 16] step 8/44: loss=0.6714 
[epoch 16] step 10/44: loss=0.6742 
[epoch 16] step 12/44: loss=0.6755 
[epoch 16] step 14/44: loss=0.6822 
[epoch 16] step 16/44: loss=0.6793 
[epoch 16] step 18/44: loss=0.6747 
[epoch 16] step 20/44: loss=0.6693 
[epoch 16] step 22/44: loss=0.6691 
[epoch 16] step 24/44: loss=0.6704 
[epoch 16] step 26/44: loss=0.6717 
[epoch 16] step 28/44: loss=0.6698 
[epoch 16] step 30/44: loss=0.6721 
[epoch 16] step 32/44: loss=0.6705 
[epoch 16] step 34/44: loss=0.6690 
[epoch 16] step 36/44: loss=0.6684 
[epoch 16] step 38/44: loss=0.6678 
[epoch 16] step 40/44: loss=0.6663 
[epoch 16] step 42/44: loss=0.6642 
[epoch 16] step 44/44: loss=0.6619 
[epoch 16] train_loss(avg per step)=1.3239 lambda[min,max]=[0.410738,1.000000]
[epoch 16] val_loss=1.2331 qwk=('0.6270', '0.6293', '0.6169') averageQWK=0.6244 macroEMD=0.2835 tailR0=('0.4275', '0.1389', '0.0000') tailR0avg=0.1888
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    5    1    0
     3   15   35    1    1
     2    7   97   17    2
     0    0   31   78    7
     0    0    4    7   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     2   19   24    7    0
     0   11   68   42    0
     0    0   14  117    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   36    1    0
     0   27  109   15    0
     0    1   35   65    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=0.6805 
[epoch 17] step 4/44: loss=0.6510 
[epoch 17] step 6/44: loss=0.6523 
[epoch 17] step 8/44: loss=0.6499 
[epoch 17] step 10/44: loss=0.6500 
[epoch 17] step 12/44: loss=0.6490 
[epoch 17] step 14/44: loss=0.6518 
[epoch 17] step 16/44: loss=0.6564 
[epoch 17] step 18/44: loss=0.6591 
[epoch 17] step 20/44: loss=0.6564 
[epoch 17] step 22/44: loss=0.6566 
[epoch 17] step 24/44: loss=0.6561 
[epoch 17] step 26/44: loss=0.6550 
[epoch 17] step 28/44: loss=0.6585 
[epoch 17] step 30/44: loss=0.6579 
[epoch 17] step 32/44: loss=0.6570 
[epoch 17] step 34/44: loss=0.6557 
[epoch 17] step 36/44: loss=0.6537 
[epoch 17] step 38/44: loss=0.6514 
[epoch 17] step 40/44: loss=0.6487 
[epoch 17] step 42/44: loss=0.6482 
[epoch 17] step 44/44: loss=0.6488 
[epoch 17] train_loss(avg per step)=1.2976 lambda[min,max]=[0.394330,1.000000]
[epoch 17] val_loss=1.2510 qwk=('0.6146', '0.6294', '0.6215') averageQWK=0.6219 macroEMD=0.2779 tailR0=('0.2947', '0.0972', '0.0000') tailR0avg=0.1306
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     1   23   24    6    1
     1   14   68   39    3
     0    0   16   88   12
     0    0    3    9   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    1    0
     3   22   19    8    0
     0   15   56   50    0
     0    0    7  124    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     1   28   39    1    0
     0   21  104   26    0
     0    1   24   76    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=0.7099 
[epoch 18] step 4/44: loss=0.6936 
[epoch 18] step 6/44: loss=0.6911 
[epoch 18] step 8/44: loss=0.6888 
[epoch 18] step 10/44: loss=0.6798 
[epoch 18] step 12/44: loss=0.6819 
[epoch 18] step 14/44: loss=0.6736 
[epoch 18] step 16/44: loss=0.6611 
[epoch 18] step 18/44: loss=0.6533 
[epoch 18] step 20/44: loss=0.6454 
[epoch 18] step 22/44: loss=0.6391 
[epoch 18] step 24/44: loss=0.6429 
[epoch 18] step 26/44: loss=0.6416 
[epoch 18] step 28/44: loss=0.6417 
[epoch 18] step 30/44: loss=0.6434 
[epoch 18] step 32/44: loss=0.6440 
[epoch 18] step 34/44: loss=0.6473 
[epoch 18] step 36/44: loss=0.6462 
[epoch 18] step 38/44: loss=0.6453 
[epoch 18] step 40/44: loss=0.6470 
[epoch 18] step 42/44: loss=0.6450 
[epoch 18] step 44/44: loss=0.6400 
[epoch 18] train_loss(avg per step)=1.2800 lambda[min,max]=[0.387909,1.000000]
[epoch 18] val_loss=1.1707 qwk=('0.6546', '0.6920', '0.6321') averageQWK=0.6596 macroEMD=0.2798 tailR0=('0.4275', '0.0972', '0.0000') tailR0avg=0.1749
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    3    1    0
     6   22   24    2    1
     1   19   86   17    2
     0    0   31   76    9
     0    0    5    6   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     6   26   16    4    0
     1   25   67   28    0
     0    0   19  113    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   36   33    0    0
     0   28  106   17    0
     0    2   33   66    0
     0    0    0    2    0
[epoch 19] step 2/44: loss=0.5789 
[epoch 19] step 4/44: loss=0.5880 
[epoch 19] step 6/44: loss=0.5996 
[epoch 19] step 8/44: loss=0.6044 
[epoch 19] step 10/44: loss=0.6054 
[epoch 19] step 12/44: loss=0.6108 
[epoch 19] step 14/44: loss=0.6139 
[epoch 19] step 16/44: loss=0.6133 
[epoch 19] step 18/44: loss=0.6149 
[epoch 19] step 20/44: loss=0.6178 
[epoch 19] step 22/44: loss=0.6205 
[epoch 19] step 24/44: loss=0.6209 
[epoch 19] step 26/44: loss=0.6206 
[epoch 19] step 28/44: loss=0.6194 
[epoch 19] step 30/44: loss=0.6180 
[epoch 19] step 32/44: loss=0.6175 
[epoch 19] step 34/44: loss=0.6179 
[epoch 19] step 36/44: loss=0.6179 
[epoch 19] step 38/44: loss=0.6192 
[epoch 19] step 40/44: loss=0.6200 
[epoch 19] step 42/44: loss=0.6222 
[epoch 19] step 44/44: loss=0.6224 
[epoch 19] train_loss(avg per step)=1.2449 lambda[min,max]=[0.372446,1.000000]
[epoch 19] val_loss=1.2301 qwk=('0.6487', '0.6874', '0.6510') averageQWK=0.6624 macroEMD=0.2764 tailR0=('0.2971', '0.0556', '0.0000') tailR0avg=0.1176
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    2    1    0
     4   22   26    2    1
     2   18   80   24    1
     0    0   23   86    7
     0    0    4   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    1    0
     2   33   12    5    0
     0   31   54   36    0
     0    0   13  121    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     1   47   21    0    0
     0   40   95   16    0
     0    3   33   65    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=0.6592 
[epoch 20] step 4/44: loss=0.6455 
[epoch 20] step 6/44: loss=0.6530 
[epoch 20] step 8/44: loss=0.6421 
[epoch 20] step 10/44: loss=0.6371 
[epoch 20] step 12/44: loss=0.6288 
[epoch 20] step 14/44: loss=0.6249 
[epoch 20] step 16/44: loss=0.6214 
[epoch 20] step 18/44: loss=0.6207 
[epoch 20] step 20/44: loss=0.6161 
[epoch 20] step 22/44: loss=0.6191 
[epoch 20] step 24/44: loss=0.6193 
[epoch 20] step 26/44: loss=0.6201 
[epoch 20] step 28/44: loss=0.6228 
[epoch 20] step 30/44: loss=0.6245 
[epoch 20] step 32/44: loss=0.6250 
[epoch 20] step 34/44: loss=0.6228 
[epoch 20] step 36/44: loss=0.6198 
[epoch 20] step 38/44: loss=0.6169 
[epoch 20] step 40/44: loss=0.6148 
[epoch 20] step 42/44: loss=0.6135 
[epoch 20] step 44/44: loss=0.6136 
[epoch 20] train_loss(avg per step)=1.2273 lambda[min,max]=[0.393799,1.000000]
[epoch 20] val_loss=1.1298 qwk=('0.6116', '0.6199', '0.6136') averageQWK=0.6151 macroEMD=0.2820 tailR0=('0.3188', '0.0972', '0.0000') tailR0avg=0.1387
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    3    1    0
     5   16   28    6    0
     2   12   64   46    1
     0    0   17   94    5
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    1    0
     5   18   22    7    0
     1   13   62   44    1
     0    0    9  123    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     1   26   39    3    0
     0   24   94   33    0
     0    0   18   83    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=0.6164 
[epoch 21] step 4/44: loss=0.6129 
[epoch 21] step 6/44: loss=0.6031 
[epoch 21] step 8/44: loss=0.6043 
[epoch 21] step 10/44: loss=0.6045 
[epoch 21] step 12/44: loss=0.6088 
[epoch 21] step 14/44: loss=0.6129 
[epoch 21] step 16/44: loss=0.6168 
[epoch 21] step 18/44: loss=0.6211 
[epoch 21] step 20/44: loss=0.6202 
[epoch 21] step 22/44: loss=0.6177 
[epoch 21] step 24/44: loss=0.6184 
[epoch 21] step 26/44: loss=0.6145 
[epoch 21] step 28/44: loss=0.6148 
[epoch 21] step 30/44: loss=0.6155 
[epoch 21] step 32/44: loss=0.6143 
[epoch 21] step 34/44: loss=0.6128 
[epoch 21] step 36/44: loss=0.6113 
[epoch 21] step 38/44: loss=0.6084 
[epoch 21] step 40/44: loss=0.6075 
[epoch 21] step 42/44: loss=0.6073 
[epoch 21] step 44/44: loss=0.6096 
[epoch 21] train_loss(avg per step)=1.2192 lambda[min,max]=[0.381538,1.000000]
[epoch 21] val_loss=1.1628 qwk=('0.6144', '0.6669', '0.6310') averageQWK=0.6374 macroEMD=0.2813 tailR0=('0.2415', '0.0556', '0.2000') tailR0avg=0.1657
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    2    2    0
     2   28   18    6    1
     0   22   54   47    2
     0    0   13   98    5
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     2   29   15    6    0
     0   25   59   37    0
     0    0   12  119    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    0    1    0
     1   22   44    2    0
     0   12  111   28    0
     0    0   22   79    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=0.6413 
[epoch 22] step 4/44: loss=0.6183 
[epoch 22] step 6/44: loss=0.6185 
[epoch 22] step 8/44: loss=0.5930 
[epoch 22] step 10/44: loss=0.5768 
[epoch 22] step 12/44: loss=0.5662 
[epoch 22] step 14/44: loss=0.5692 
[epoch 22] step 16/44: loss=0.5687 
[epoch 22] step 18/44: loss=0.5766 
[epoch 22] step 20/44: loss=0.5844 
[epoch 22] step 22/44: loss=0.5848 
[epoch 22] step 24/44: loss=0.5848 
[epoch 22] step 26/44: loss=0.5852 
[epoch 22] step 28/44: loss=0.5858 
[epoch 22] step 30/44: loss=0.5864 
[epoch 22] step 32/44: loss=0.5876 
[epoch 22] step 34/44: loss=0.5902 
[epoch 22] step 36/44: loss=0.5904 
[epoch 22] step 38/44: loss=0.5895 
[epoch 22] step 40/44: loss=0.5885 
[epoch 22] step 42/44: loss=0.5880 
[epoch 22] step 44/44: loss=0.5876 
[epoch 22] train_loss(avg per step)=1.1751 lambda[min,max]=[0.355473,1.000000]
[epoch 22] val_loss=1.0801 qwk=('0.6128', '0.6379', '0.6299') averageQWK=0.6269 macroEMD=0.2789 tailR0=('0.2633', '0.0972', '0.2000') tailR0avg=0.1868
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    4    1    0
     6   20   23    5    1
     4   14   77   28    2
     0    0   21   88    7
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     5   22   19    6    0
     2   17   61   41    0
     0    0   14  117    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    1    0    0
     1   26   42    0    0
     0   18  115   18    0
     0    1   34   66    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=0.5267 
[epoch 23] step 4/44: loss=0.5411 
[epoch 23] step 6/44: loss=0.5560 
[epoch 23] step 8/44: loss=0.5661 
[epoch 23] step 10/44: loss=0.5789 
[epoch 23] step 12/44: loss=0.5819 
[epoch 23] step 14/44: loss=0.5871 
[epoch 23] step 16/44: loss=0.5916 
[epoch 23] step 18/44: loss=0.5901 
[epoch 23] step 20/44: loss=0.5886 
[epoch 23] step 22/44: loss=0.5878 
[epoch 23] step 24/44: loss=0.5843 
[epoch 23] step 26/44: loss=0.5809 
[epoch 23] step 28/44: loss=0.5798 
[epoch 23] step 30/44: loss=0.5799 
[epoch 23] step 32/44: loss=0.5815 
[epoch 23] step 34/44: loss=0.5817 
[epoch 23] step 36/44: loss=0.5795 
[epoch 23] step 38/44: loss=0.5808 
[epoch 23] step 40/44: loss=0.5812 
[epoch 23] step 42/44: loss=0.5808 
[epoch 23] step 44/44: loss=0.5840 
[epoch 23] train_loss(avg per step)=1.1681 lambda[min,max]=[0.375201,1.000000]
[epoch 23] val_loss=1.1485 qwk=('0.6220', '0.6567', '0.6141') averageQWK=0.6309 macroEMD=0.2766 tailR0=('0.2850', '0.0972', '0.1000') tailR0avg=0.1607
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    1    0
     4   19   28    3    1
     2   11   77   33    2
     0    0   20   87    9
     0    0    4   11    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     3   27   15    7    0
     1   21   59   40    0
     0    0   12  122    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     2   24   42    1    0
     0   20  107   24    0
     0    2   24   75    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=0.5962 
[epoch 24] step 4/44: loss=0.6013 
[epoch 24] step 6/44: loss=0.6077 
[epoch 24] step 8/44: loss=0.6055 
[epoch 24] step 10/44: loss=0.6055 
[epoch 24] step 12/44: loss=0.6039 
[epoch 24] step 14/44: loss=0.6002 
[epoch 24] step 16/44: loss=0.5939 
[epoch 24] step 18/44: loss=0.5865 
[epoch 24] step 20/44: loss=0.5790 
[epoch 24] step 22/44: loss=0.5757 
[epoch 24] step 24/44: loss=0.5754 
[epoch 24] step 26/44: loss=0.5741 
[epoch 24] step 28/44: loss=0.5742 
[epoch 24] step 30/44: loss=0.5775 
[epoch 24] step 32/44: loss=0.5833 
[epoch 24] step 34/44: loss=0.5851 
[epoch 24] step 36/44: loss=0.5864 
[epoch 24] step 38/44: loss=0.5882 
[epoch 24] step 40/44: loss=0.5860 
[epoch 24] step 42/44: loss=0.5843 
[epoch 24] step 44/44: loss=0.5842 
[epoch 24] train_loss(avg per step)=1.1684 lambda[min,max]=[0.369071,1.000000]
[epoch 24] val_loss=1.0645 qwk=('0.6229', '0.6534', '0.6360') averageQWK=0.6374 macroEMD=0.2805 tailR0=('0.2850', '0.0972', '0.2000') tailR0avg=0.1941
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    1    0
     2   21   27    4    1
     1   14   76   32    2
     0    0   18   88   10
     0    0    4   11    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     5   21   19    7    0
     1   14   66   40    0
     0    0   12  119    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    1    0    0
     2   23   43    1    0
     0   12  123   16    0
     0    0   35   66    0
     0    0    0    2    0
[epoch 25] step 2/44: loss=0.5732 
[epoch 25] step 4/44: loss=0.5593 
[epoch 25] step 6/44: loss=0.5622 
[epoch 25] step 8/44: loss=0.5564 
[epoch 25] step 10/44: loss=0.5486 
[epoch 25] step 12/44: loss=0.5531 
[epoch 25] step 14/44: loss=0.5557 
[epoch 25] step 16/44: loss=0.5602 
[epoch 25] step 18/44: loss=0.5677 
[epoch 25] step 20/44: loss=0.5712 
[epoch 25] step 22/44: loss=0.5777 
[epoch 25] step 24/44: loss=0.5793 
[epoch 25] step 26/44: loss=0.5794 
[epoch 25] step 28/44: loss=0.5804 
[epoch 25] step 30/44: loss=0.5772 
[epoch 25] step 32/44: loss=0.5751 
[epoch 25] step 34/44: loss=0.5733 
[epoch 25] step 36/44: loss=0.5705 
[epoch 25] step 38/44: loss=0.5695 
[epoch 25] step 40/44: loss=0.5698 
[epoch 25] step 42/44: loss=0.5711 
[epoch 25] step 44/44: loss=0.5763 
[epoch 25] train_loss(avg per step)=1.1527 lambda[min,max]=[0.364215,1.000000]
[epoch 25] val_loss=1.1028 qwk=('0.6353', '0.6913', '0.6466') averageQWK=0.6577 macroEMD=0.2773 tailR0=('0.2415', '0.0972', '0.1000') tailR0avg=0.1463
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    1    0
     5   23   24    3    0
     4   17   69   33    2
     0    0   21   90    5
     0    0    3   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     5   28   16    3    0
     2   24   66   29    0
     0    0   21  113    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    1    0
     3   39   26    1    0
     1   28   96   26    0
     0    3   22   76    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=0.5489 
[epoch 26] step 4/44: loss=0.5593 
[epoch 26] step 6/44: loss=0.5521 
[epoch 26] step 8/44: loss=0.5624 
[epoch 26] step 10/44: loss=0.5639 
[epoch 26] step 12/44: loss=0.5618 
[epoch 26] step 14/44: loss=0.5618 
[epoch 26] step 16/44: loss=0.5613 
[epoch 26] step 18/44: loss=0.5629 
[epoch 26] step 20/44: loss=0.5640 
[epoch 26] step 22/44: loss=0.5660 
[epoch 26] step 24/44: loss=0.5663 
[epoch 26] step 26/44: loss=0.5688 
[epoch 26] step 28/44: loss=0.5672 
[epoch 26] step 30/44: loss=0.5683 
[epoch 26] step 32/44: loss=0.5701 
[epoch 26] step 34/44: loss=0.5680 
[epoch 26] step 36/44: loss=0.5647 
[epoch 26] step 38/44: loss=0.5641 
[epoch 26] step 40/44: loss=0.5615 
[epoch 26] step 42/44: loss=0.5616 
[epoch 26] step 44/44: loss=0.5618 
[epoch 26] train_loss(avg per step)=1.1236 lambda[min,max]=[0.367505,1.000000]
[epoch 26] val_loss=1.0838 qwk=('0.5993', '0.6306', '0.6288') averageQWK=0.6196 macroEMD=0.2765 tailR0=('0.2850', '0.0972', '0.2000') tailR0avg=0.1941
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    4    1    0
     5   17   27    5    1
     3    8   80   32    2
     0    0   21   88    7
     0    0    4   11    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    1    0
     3   21   21    7    0
     1   15   62   43    0
     0    0   11  123    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    0    1    0
     3   25   40    1    0
     0   20  107   24    0
     0    1   26   74    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=0.6121 
[epoch 27] step 4/44: loss=0.6116 
[epoch 27] step 6/44: loss=0.5984 
[epoch 27] step 8/44: loss=0.5904 
[epoch 27] step 10/44: loss=0.5918 
[epoch 27] step 12/44: loss=0.5873 
[epoch 27] step 14/44: loss=0.5899 
[epoch 27] step 16/44: loss=0.5867 
[epoch 27] step 18/44: loss=0.5836 
[epoch 27] step 20/44: loss=0.5855 
[epoch 27] step 22/44: loss=0.5850 
[epoch 27] step 24/44: loss=0.5831 
[epoch 27] step 26/44: loss=0.5820 
[epoch 27] step 28/44: loss=0.5809 
[epoch 27] step 30/44: loss=0.5782 
[epoch 27] step 32/44: loss=0.5728 
[epoch 27] step 34/44: loss=0.5701 
[epoch 27] step 36/44: loss=0.5662 
[epoch 27] step 38/44: loss=0.5643 
[epoch 27] step 40/44: loss=0.5626 
[epoch 27] step 42/44: loss=0.5618 
[epoch 27] step 44/44: loss=0.5628 
[epoch 27] train_loss(avg per step)=1.1256 lambda[min,max]=[0.372458,1.000000]
[epoch 27] val_loss=1.0800 qwk=('0.6031', '0.6528', '0.6401') averageQWK=0.6320 macroEMD=0.2773 tailR0=('0.2850', '0.0972', '0.1000') tailR0avg=0.1607
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    4    1    0
     3   16   31    4    1
     2    7   81   33    2
     0    0   21   88    7
     0    0    3   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     2   22   23    5    0
     0   17   71   33    0
     0    0   17  117    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     2   28   38    1    0
     0   22  108   21    0
     0    1   25   75    0
     0    0    0    2    0
[epoch 28] step 2/44: loss=0.5628 
[epoch 28] step 4/44: loss=0.5664 
[epoch 28] step 6/44: loss=0.5707 
[epoch 28] step 8/44: loss=0.5705 
[epoch 28] step 10/44: loss=0.5726 
[epoch 28] step 12/44: loss=0.5785 
[epoch 28] step 14/44: loss=0.5836 
[epoch 28] step 16/44: loss=0.5856 
[epoch 28] step 18/44: loss=0.5842 
[epoch 28] step 20/44: loss=0.5820 
[epoch 28] step 22/44: loss=0.5788 
[epoch 28] step 24/44: loss=0.5746 
[epoch 28] step 26/44: loss=0.5679 
[epoch 28] step 28/44: loss=0.5637 
[epoch 28] step 30/44: loss=0.5618 
[epoch 28] step 32/44: loss=0.5603 
[epoch 28] step 34/44: loss=0.5597 
[epoch 28] step 36/44: loss=0.5575 
[epoch 28] step 38/44: loss=0.5571 
[epoch 28] step 40/44: loss=0.5578 
[epoch 28] step 42/44: loss=0.5591 
[epoch 28] step 44/44: loss=0.5600 
[epoch 28] train_loss(avg per step)=1.1199 lambda[min,max]=[0.363812,1.000000]
[epoch 28] val_loss=1.1194 qwk=('0.6353', '0.6792', '0.6526') averageQWK=0.6557 macroEMD=0.2749 tailR0=('0.2850', '0.0972', '0.1000') tailR0avg=0.1607
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    1    0
     2   21   28    3    1
     0   16   83   24    2
     0    0   22   86    8
     0    0    4   11    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     2   23   25    2    0
     0   17   77   27    0
     0    0   23  109    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     1   33   34    1    0
     0   23  107   21    0
     0    1   28   72    0
     0    0    0    2    0
[epoch 29] step 2/44: loss=0.5986 
[epoch 29] step 4/44: loss=0.6178 
[epoch 29] step 6/44: loss=0.6062 
[epoch 29] step 8/44: loss=0.5969 
[epoch 29] step 10/44: loss=0.5935 
[epoch 29] step 12/44: loss=0.5902 
[epoch 29] step 14/44: loss=0.5841 
[epoch 29] step 16/44: loss=0.5765 
[epoch 29] step 18/44: loss=0.5675 
[epoch 29] step 20/44: loss=0.5616 
[epoch 29] step 22/44: loss=0.5609 
[epoch 29] step 24/44: loss=0.5557 
[epoch 29] step 26/44: loss=0.5569 
[epoch 29] step 28/44: loss=0.5604 
[epoch 29] step 30/44: loss=0.5596 
[epoch 29] step 32/44: loss=0.5605 
[epoch 29] step 34/44: loss=0.5611 
[epoch 29] step 36/44: loss=0.5598 
[epoch 29] step 38/44: loss=0.5600 
[epoch 29] step 40/44: loss=0.5605 
[epoch 29] step 42/44: loss=0.5619 
[epoch 29] step 44/44: loss=0.5616 
[epoch 29] train_loss(avg per step)=1.1232 lambda[min,max]=[0.364317,1.000000]
[epoch 29] val_loss=1.0884 qwk=('0.6192', '0.6613', '0.6311') averageQWK=0.6372 macroEMD=0.2761 tailR0=('0.2850', '0.0972', '0.1000') tailR0avg=0.1607
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    1    0
     3   19   28    4    1
     3   11   76   33    2
     0    0   18   87   11
     0    0    3   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     2   26   19    5    0
     1   21   60   39    0
     0    0   13  121    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    1    0
     3   25   40    1    0
     0   19  102   30    0
     0    1   21   79    0
     0    0    0    2    0
[epoch 30] step 2/44: loss=0.5646 
[epoch 30] step 4/44: loss=0.5794 
[epoch 30] step 6/44: loss=0.5865 
[epoch 30] step 8/44: loss=0.5843 
[epoch 30] step 10/44: loss=0.5779 
[epoch 30] step 12/44: loss=0.5731 
[epoch 30] step 14/44: loss=0.5619 
[epoch 30] step 16/44: loss=0.5573 
[epoch 30] step 18/44: loss=0.5539 
[epoch 30] step 20/44: loss=0.5527 
[epoch 30] step 22/44: loss=0.5528 
[epoch 30] step 24/44: loss=0.5526 
[epoch 30] step 26/44: loss=0.5529 
[epoch 30] step 28/44: loss=0.5532 
[epoch 30] step 30/44: loss=0.5509 
[epoch 30] step 32/44: loss=0.5511 
[epoch 30] step 34/44: loss=0.5511 
[epoch 30] step 36/44: loss=0.5484 
[epoch 30] step 38/44: loss=0.5498 
[epoch 30] step 40/44: loss=0.5488 
[epoch 30] step 42/44: loss=0.5471 
[epoch 30] step 44/44: loss=0.5471 
[epoch 30] train_loss(avg per step)=1.0942 lambda[min,max]=[0.368852,1.000000]
[epoch 30] val_loss=1.0722 qwk=('0.6466', '0.6920', '0.6289') averageQWK=0.6558 macroEMD=0.2752 tailR0=('0.2633', '0.0972', '0.1000') tailR0avg=0.1535
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     6   20   27    2    0
     5   11   86   21    2
     0    0   25   83    8
     0    0    5   11    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     1   30   18    3    0
     1   25   64   31    0
     0    0   18  116    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    1    0
     2   31   35    1    0
     0   24  105   22    0
     0    2   26   73    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=0.5577 
[epoch 31] step 4/44: loss=0.5520 
[epoch 31] step 6/44: loss=0.5520 
[epoch 31] step 8/44: loss=0.5610 
[epoch 31] step 10/44: loss=0.5636 
[epoch 31] step 12/44: loss=0.5631 
[epoch 31] step 14/44: loss=0.5631 
[epoch 31] step 16/44: loss=0.5587 
[epoch 31] step 18/44: loss=0.5596 
[epoch 31] step 20/44: loss=0.5569 
[epoch 31] step 22/44: loss=0.5548 
[epoch 31] step 24/44: loss=0.5574 
[epoch 31] step 26/44: loss=0.5557 
[epoch 31] step 28/44: loss=0.5571 
[epoch 31] step 30/44: loss=0.5595 
[epoch 31] step 32/44: loss=0.5628 
[epoch 31] step 34/44: loss=0.5636 
[epoch 31] step 36/44: loss=0.5642 
[epoch 31] step 38/44: loss=0.5639 
[epoch 31] step 40/44: loss=0.5613 
[epoch 31] step 42/44: loss=0.5597 
[epoch 31] step 44/44: loss=0.5568 
[epoch 31] train_loss(avg per step)=1.1137 lambda[min,max]=[0.378224,1.000000]
[epoch 31] val_loss=1.0496 qwk=('0.6398', '0.6796', '0.6282') averageQWK=0.6492 macroEMD=0.2779 tailR0=('0.2850', '0.0972', '0.1000') tailR0avg=0.1607
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    1    0
     3   22   27    2    1
     1   16   77   29    2
     0    0   20   88    8
     0    0    4   11    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     3   27   18    4    0
     0   20   67   34    0
     0    0   18  114    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    1    0
     2   28   38    1    0
     0   19  108   24    0
     0    1   27   73    0
     0    0    0    2    0
[epoch 32] step 2/44: loss=0.5828 
[epoch 32] step 4/44: loss=0.5826 
[epoch 32] step 6/44: loss=0.5595 
[epoch 32] step 8/44: loss=0.5505 
[epoch 32] step 10/44: loss=0.5586 
[epoch 32] step 12/44: loss=0.5494 
[epoch 32] step 14/44: loss=0.5396 
[epoch 32] step 16/44: loss=0.5375 
[epoch 32] step 18/44: loss=0.5384 
[epoch 32] step 20/44: loss=0.5393 
[epoch 32] step 22/44: loss=0.5398 
[epoch 32] step 24/44: loss=0.5399 
[epoch 32] step 26/44: loss=0.5397 
[epoch 32] step 28/44: loss=0.5415 
[epoch 32] step 30/44: loss=0.5434 
[epoch 32] step 32/44: loss=0.5435 
[epoch 32] step 34/44: loss=0.5438 
[epoch 32] step 36/44: loss=0.5435 
[epoch 32] step 38/44: loss=0.5455 
[epoch 32] step 40/44: loss=0.5454 
[epoch 32] step 42/44: loss=0.5456 
[epoch 32] step 44/44: loss=0.5493 
[epoch 32] train_loss(avg per step)=1.0985 lambda[min,max]=[0.378205,1.000000]
[epoch 32] val_loss=1.0552 qwk=('0.6236', '0.6570', '0.6188') averageQWK=0.6331 macroEMD=0.2753 tailR0=('0.3285', '0.0972', '0.1000') tailR0avg=0.1752
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    5    1    0
     3   18   31    3    0
     3    9   86   25    2
     0    0   24   83    9
     0    0    4    9   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     4   21   22    5    0
     0   16   73   32    0
     0    0   18  114    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    1    0
     3   28   37    1    0
     0   21  106   24    0
     0    2   27   72    0
     0    0    0    2    0
[epoch 33] step 2/44: loss=0.5485 
[epoch 33] step 4/44: loss=0.5716 
[epoch 33] step 6/44: loss=0.5703 
[epoch 33] step 8/44: loss=0.5670 
[epoch 33] step 10/44: loss=0.5572 
[epoch 33] step 12/44: loss=0.5563 
[epoch 33] step 14/44: loss=0.5524 
[epoch 33] step 16/44: loss=0.5520 
[epoch 33] step 18/44: loss=0.5517 
[epoch 33] step 20/44: loss=0.5524 
[epoch 33] step 22/44: loss=0.5499 
[epoch 33] step 24/44: loss=0.5512 
[epoch 33] step 26/44: loss=0.5520 
[epoch 33] step 28/44: loss=0.5488 
[epoch 33] step 30/44: loss=0.5478 
[epoch 33] step 32/44: loss=0.5484 
[epoch 33] step 34/44: loss=0.5487 
[epoch 33] step 36/44: loss=0.5486 
[epoch 33] step 38/44: loss=0.5489 
[epoch 33] step 40/44: loss=0.5482 
[epoch 33] step 42/44: loss=0.5490 
[epoch 33] step 44/44: loss=0.5517 
[epoch 33] train_loss(avg per step)=1.1034 lambda[min,max]=[0.380736,1.000000]
[epoch 33] val_loss=1.0483 qwk=('0.6226', '0.6826', '0.6203') averageQWK=0.6419 macroEMD=0.2784 tailR0=('0.2850', '0.0972', '0.1000') tailR0avg=0.1607
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    1    0
     2   20   29    4    0
     2   12   76   33    2
     0    0   21   87    8
     0    0    4   11    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     3   24   22    3    0
     0   18   74   29    0
     0    0   20  112    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     3   26   39    1    0
     0   21  110   20    0
     0    2   30   69    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=0.5383 
[epoch 34] step 4/44: loss=0.5440 
[epoch 34] step 6/44: loss=0.5393 
[epoch 34] step 8/44: loss=0.5269 
[epoch 34] step 10/44: loss=0.5311 
[epoch 34] step 12/44: loss=0.5409 
[epoch 34] step 14/44: loss=0.5438 
[epoch 34] step 16/44: loss=0.5450 
[epoch 34] step 18/44: loss=0.5463 
[epoch 34] step 20/44: loss=0.5454 
[epoch 34] step 22/44: loss=0.5449 
[epoch 34] step 24/44: loss=0.5459 
[epoch 34] step 26/44: loss=0.5484 
[epoch 34] step 28/44: loss=0.5490 
[epoch 34] step 30/44: loss=0.5470 
[epoch 34] step 32/44: loss=0.5471 
[epoch 34] step 34/44: loss=0.5462 
[epoch 34] step 36/44: loss=0.5467 
[epoch 34] step 38/44: loss=0.5471 
[epoch 34] step 40/44: loss=0.5466 
[epoch 34] step 42/44: loss=0.5456 
[epoch 34] step 44/44: loss=0.5431 
[epoch 34] train_loss(avg per step)=1.0861 lambda[min,max]=[0.349989,1.000000]
[epoch 34] val_loss=1.0490 qwk=('0.6354', '0.6748', '0.6246') averageQWK=0.6449 macroEMD=0.2768 tailR0=('0.2850', '0.0972', '0.1000') tailR0avg=0.1607
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    1    0
     4   20   27    4    0
     2   12   82   27    2
     0    0   23   85    8
     0    0    4   11    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     3   25   21    3    0
     1   18   70   32    0
     0    0   16  117    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    1    0
     3   28   37    1    0
     0   22  107   22    0
     0    2   26   73    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=0.5750 
[epoch 35] step 4/44: loss=0.5659 
[epoch 35] step 6/44: loss=0.5649 
[epoch 35] step 8/44: loss=0.5564 
[epoch 35] step 10/44: loss=0.5585 
[epoch 35] step 12/44: loss=0.5506 
[epoch 35] step 14/44: loss=0.5442 
[epoch 35] step 16/44: loss=0.5428 
[epoch 35] step 18/44: loss=0.5432 
[epoch 35] step 20/44: loss=0.5429 
[epoch 35] step 22/44: loss=0.5420 
[epoch 35] step 24/44: loss=0.5399 
[epoch 35] step 26/44: loss=0.5408 
[epoch 35] step 28/44: loss=0.5416 
[epoch 35] step 30/44: loss=0.5424 
[epoch 35] step 32/44: loss=0.5416 
[epoch 35] step 34/44: loss=0.5423 
[epoch 35] step 36/44: loss=0.5408 
[epoch 35] step 38/44: loss=0.5407 
[epoch 35] step 40/44: loss=0.5404 
[epoch 35] step 42/44: loss=0.5397 
[epoch 35] step 44/44: loss=0.5404 
[epoch 35] train_loss(avg per step)=1.0809 lambda[min,max]=[0.364865,1.000000]
[epoch 35] val_loss=1.0540 qwk=('0.6423', '0.6837', '0.6338') averageQWK=0.6533 macroEMD=0.2762 tailR0=('0.2850', '0.0972', '0.1000') tailR0avg=0.1607
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    1    0
     3   20   30    2    0
     3   11   85   24    2
     0    0   24   84    8
     0    0    4   11    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     3   24   22    3    0
     1   18   71   31    0
     0    0   16  116    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     3   27   38    1    0
     0   22  109   20    0
     0    2   27   72    0
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-1/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-1/fold0/metrics.json
Done.
