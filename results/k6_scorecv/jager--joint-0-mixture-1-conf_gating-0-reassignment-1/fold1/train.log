[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.7294 
[epoch 1] step 4/44: loss=0.7222 
[epoch 1] step 6/44: loss=0.7258 
[epoch 1] step 8/44: loss=0.7245 
[epoch 1] step 10/44: loss=0.7226 
[epoch 1] step 12/44: loss=0.7163 
[epoch 1] step 14/44: loss=0.7175 
[epoch 1] step 16/44: loss=0.7149 
[epoch 1] step 18/44: loss=0.7162 
[epoch 1] step 20/44: loss=0.7153 
[epoch 1] step 22/44: loss=0.7142 
[epoch 1] step 24/44: loss=0.7147 
[epoch 1] step 26/44: loss=0.7132 
[epoch 1] step 28/44: loss=0.7140 
[epoch 1] step 30/44: loss=0.7113 
[epoch 1] step 32/44: loss=0.7112 
[epoch 1] step 34/44: loss=0.7103 
[epoch 1] step 36/44: loss=0.7104 
[epoch 1] step 38/44: loss=0.7105 
[epoch 1] step 40/44: loss=0.7140 
[epoch 1] step 42/44: loss=0.7161 
[epoch 1] step 44/44: loss=0.7208 
[epoch 1] train_loss(avg per step)=1.4417 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.5967 qwk=('0.1852', '0.1968', '-0.0178') averageQWK=0.1214 macroEMD=0.3647 tailR0=('0.0000', '0.1111', '0.0000') tailR0avg=0.0370
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    6    0
     0   15    0   39    0
     0   36    0   90    0
     0   16    0  100    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    3    4    0
    11    0   22   19    0
    30    0   35   57    0
    16    0   30   87    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    9   59    0    0
     0   12  140    0    0
     0   14   87    0    0
     0    0    2    0    0
[epoch 2] step 2/44: loss=0.8997 
[epoch 2] step 4/44: loss=0.9349 
[epoch 2] step 6/44: loss=0.9627 
[epoch 2] step 8/44: loss=0.9776 
[epoch 2] step 10/44: loss=0.9911 
[epoch 2] step 12/44: loss=0.9919 
[epoch 2] step 14/44: loss=0.9800 
[epoch 2] step 16/44: loss=0.9577 
[epoch 2] step 18/44: loss=0.9418 
[epoch 2] step 20/44: loss=0.9284 
[epoch 2] step 22/44: loss=0.9171 
[epoch 2] step 24/44: loss=0.9065 
[epoch 2] step 26/44: loss=0.8957 
[epoch 2] step 28/44: loss=0.8921 
[epoch 2] step 30/44: loss=0.8929 
[epoch 2] step 32/44: loss=0.8922 
[epoch 2] step 34/44: loss=0.8887 
[epoch 2] step 36/44: loss=0.8856 
[epoch 2] step 38/44: loss=0.8839 
[epoch 2] step 40/44: loss=0.8830 
[epoch 2] step 42/44: loss=0.8786 
[epoch 2] step 44/44: loss=0.8713 
[epoch 2] train_loss(avg per step)=1.7426 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.0268 qwk=('0.4274', '0.3599', '0.3303') averageQWK=0.3725 macroEMD=0.3588 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    4    0
     0   31    3   20    0
     0   34   10   82    0
     0    5    7  104    0
     0    1    0   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    3    0
     0    0   42   10    0
     0    0   58   64    0
     0    0   23  110    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0   10   37   21    0
     0   10   51   91    0
     0    3    8   90    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=0.7058 
[epoch 3] step 4/44: loss=0.7023 
[epoch 3] step 6/44: loss=0.7089 
[epoch 3] step 8/44: loss=0.7160 
[epoch 3] step 10/44: loss=0.7234 
[epoch 3] step 12/44: loss=0.7272 
[epoch 3] step 14/44: loss=0.7331 
[epoch 3] step 16/44: loss=0.7346 
[epoch 3] step 18/44: loss=0.7393 
[epoch 3] step 20/44: loss=0.7466 
[epoch 3] step 22/44: loss=0.7531 
[epoch 3] step 24/44: loss=0.7578 
[epoch 3] step 26/44: loss=0.7623 
[epoch 3] step 28/44: loss=0.7641 
[epoch 3] step 30/44: loss=0.7688 
[epoch 3] step 32/44: loss=0.7719 
[epoch 3] step 34/44: loss=0.7756 
[epoch 3] step 36/44: loss=0.7795 
[epoch 3] step 38/44: loss=0.7865 
[epoch 3] step 40/44: loss=0.7908 
[epoch 3] step 42/44: loss=0.7936 
[epoch 3] step 44/44: loss=0.7944 
[epoch 3] train_loss(avg per step)=1.5889 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=1.4300 qwk=('0.5548', '0.4499', '0.5771') averageQWK=0.5273 macroEMD=0.3309 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0   37   15    2    0
     0   44   64   18    0
     0    7   43   66    0
     0    0    4   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0    1   50    1    0
     0    0   93   29    0
     0    0   43   90    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   61    3    4    0
     0  100   27   25    0
     0   11   11   79    0
     0    0    1    1    0
[epoch 4] step 2/44: loss=0.8053 
[epoch 4] step 4/44: loss=0.7833 
[epoch 4] step 6/44: loss=0.7809 
[epoch 4] step 8/44: loss=0.7943 
[epoch 4] step 10/44: loss=0.7991 
[epoch 4] step 12/44: loss=0.8051 
[epoch 4] step 14/44: loss=0.8067 
[epoch 4] step 16/44: loss=0.8064 
[epoch 4] step 18/44: loss=0.8126 
[epoch 4] step 20/44: loss=0.8122 
[epoch 4] step 22/44: loss=0.8129 
[epoch 4] step 24/44: loss=0.8129 
[epoch 4] step 26/44: loss=0.8124 
[epoch 4] step 28/44: loss=0.8136 
[epoch 4] step 30/44: loss=0.8137 
[epoch 4] step 32/44: loss=0.8168 
[epoch 4] step 34/44: loss=0.8189 
[epoch 4] step 36/44: loss=0.8194 
[epoch 4] step 38/44: loss=0.8208 
[epoch 4] step 40/44: loss=0.8210 
[epoch 4] step 42/44: loss=0.8210 
[epoch 4] step 44/44: loss=0.8179 
[epoch 4] train_loss(avg per step)=1.6359 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=1.4345 qwk=('0.5868', '0.5400', '0.5418') averageQWK=0.5562 macroEMD=0.3138 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    2    0
     0   19   30    5    0
     0    4   83   39    0
     0    1   18   97    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   22   26    4    0
     0   30   52   40    0
     0    7   21  105    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   32   24   12    0
     0   26   57   69    0
     0    1    6   94    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=0.7892 
[epoch 5] step 4/44: loss=0.8025 
[epoch 5] step 6/44: loss=0.7965 
[epoch 5] step 8/44: loss=0.7898 
[epoch 5] step 10/44: loss=0.7880 
[epoch 5] step 12/44: loss=0.7904 
[epoch 5] step 14/44: loss=0.7938 
[epoch 5] step 16/44: loss=0.7931 
[epoch 5] step 18/44: loss=0.7905 
[epoch 5] step 20/44: loss=0.7933 
[epoch 5] step 22/44: loss=0.7959 
[epoch 5] step 24/44: loss=0.7963 
[epoch 5] step 26/44: loss=0.8003 
[epoch 5] step 28/44: loss=0.8074 
[epoch 5] step 30/44: loss=0.8124 
[epoch 5] step 32/44: loss=0.8154 
[epoch 5] step 34/44: loss=0.8204 
[epoch 5] step 36/44: loss=0.8225 
[epoch 5] step 38/44: loss=0.8204 
[epoch 5] step 40/44: loss=0.8182 
[epoch 5] step 42/44: loss=0.8139 
[epoch 5] step 44/44: loss=0.8128 
[epoch 5] train_loss(avg per step)=1.6257 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=1.3718 qwk=('0.6039', '0.5355', '0.5899') averageQWK=0.5765 macroEMD=0.3208 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   28   24    2    0
     0   20   84   22    0
     0    2   30   84    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0    9   43    0    0
     0    4   95   23    0
     0    3   43   87    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   20   48    0    0
     0   10  125   17    0
     0    0   32   69    0
     0    0    2    0    0
[epoch 6] step 2/44: loss=0.7633 
[epoch 6] step 4/44: loss=0.7693 
[epoch 6] step 6/44: loss=0.7763 
[epoch 6] step 8/44: loss=0.7932 
[epoch 6] step 10/44: loss=0.8033 
[epoch 6] step 12/44: loss=0.8086 
[epoch 6] step 14/44: loss=0.8099 
[epoch 6] step 16/44: loss=0.8034 
[epoch 6] step 18/44: loss=0.7995 
[epoch 6] step 20/44: loss=0.7976 
[epoch 6] step 22/44: loss=0.7991 
[epoch 6] step 24/44: loss=0.7989 
[epoch 6] step 26/44: loss=0.8041 
[epoch 6] step 28/44: loss=0.8019 
[epoch 6] step 30/44: loss=0.8035 
[epoch 6] step 32/44: loss=0.8040 
[epoch 6] step 34/44: loss=0.8043 
[epoch 6] step 36/44: loss=0.8046 
[epoch 6] step 38/44: loss=0.8077 
[epoch 6] step 40/44: loss=0.8094 
[epoch 6] step 42/44: loss=0.8091 
[epoch 6] step 44/44: loss=0.8056 
[epoch 6] train_loss(avg per step)=1.6112 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=1.4508 qwk=('0.5638', '0.4264', '0.6527') averageQWK=0.5476 macroEMD=0.3034 tailR0=('0.0870', '0.0000', '0.0000') tailR0avg=0.0290
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    3    0
     0   11   41    2    0
     0    1   93   29    3
     0    0   23   86    7
     0    0    1   18    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0    4   36   12    0
     0    2   73   47    0
     0    0   22  111    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   36   30    2    0
     0   25  100   27    0
     0    2   17   82    0
     0    0    1    1    0
[epoch 7] step 2/44: loss=0.7793 
[epoch 7] step 4/44: loss=0.8073 
[epoch 7] step 6/44: loss=0.8083 
[epoch 7] step 8/44: loss=0.8110 
[epoch 7] step 10/44: loss=0.8084 
[epoch 7] step 12/44: loss=0.8082 
[epoch 7] step 14/44: loss=0.8097 
[epoch 7] step 16/44: loss=0.8064 
[epoch 7] step 18/44: loss=0.8019 
[epoch 7] step 20/44: loss=0.8017 
[epoch 7] step 22/44: loss=0.7991 
[epoch 7] step 24/44: loss=0.7996 
[epoch 7] step 26/44: loss=0.8003 
[epoch 7] step 28/44: loss=0.7995 
[epoch 7] step 30/44: loss=0.8002 
[epoch 7] step 32/44: loss=0.7988 
[epoch 7] step 34/44: loss=0.7976 
[epoch 7] step 36/44: loss=0.7961 
[epoch 7] step 38/44: loss=0.7938 
[epoch 7] step 40/44: loss=0.7928 
[epoch 7] step 42/44: loss=0.7916 
[epoch 7] step 44/44: loss=0.7924 
[epoch 7] train_loss(avg per step)=1.5849 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.4290 qwk=('0.6107', '0.5322', '0.5849') averageQWK=0.5759 macroEMD=0.2967 tailR0=('0.1739', '0.0000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   26   21    7    0
     0   17   70   36    3
     0    1   18   88    9
     0    0    1   14    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0    8   39    5    0
     0    8   75   39    0
     0    2   22  109    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   19   49    0    0
     0    9  122   21    0
     0    1   30   70    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=0.7712 
[epoch 8] step 4/44: loss=0.7772 
[epoch 8] step 6/44: loss=0.7765 
[epoch 8] step 8/44: loss=0.7759 
[epoch 8] step 10/44: loss=0.7693 
[epoch 8] step 12/44: loss=0.7774 
[epoch 8] step 14/44: loss=0.7745 
[epoch 8] step 16/44: loss=0.7742 
[epoch 8] step 18/44: loss=0.7669 
[epoch 8] step 20/44: loss=0.7665 
[epoch 8] step 22/44: loss=0.7690 
[epoch 8] step 24/44: loss=0.7662 
[epoch 8] step 26/44: loss=0.7665 
[epoch 8] step 28/44: loss=0.7688 
[epoch 8] step 30/44: loss=0.7707 
[epoch 8] step 32/44: loss=0.7720 
[epoch 8] step 34/44: loss=0.7736 
[epoch 8] step 36/44: loss=0.7756 
[epoch 8] step 38/44: loss=0.7772 
[epoch 8] step 40/44: loss=0.7780 
[epoch 8] step 42/44: loss=0.7756 
[epoch 8] step 44/44: loss=0.7726 
[epoch 8] train_loss(avg per step)=1.5451 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.4667 qwk=('0.6381', '0.5971', '0.5712') averageQWK=0.6021 macroEMD=0.2940 tailR0=('0.0870', '0.0000', '0.0000') tailR0avg=0.0290
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   23   30    1    0
     0   14   92   20    0
     0    0   40   74    2
     0    0    2   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   11   40    1    0
     0   11   87   24    0
     0    0   38   95    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   28   40    0    0
     0   16  128    8    0
     0    2   44   55    0
     0    0    2    0    0
[epoch 9] step 2/44: loss=0.7609 
[epoch 9] step 4/44: loss=0.7928 
[epoch 9] step 6/44: loss=0.7897 
[epoch 9] step 8/44: loss=0.7828 
[epoch 9] step 10/44: loss=0.7825 
[epoch 9] step 12/44: loss=0.7784 
[epoch 9] step 14/44: loss=0.7797 
[epoch 9] step 16/44: loss=0.7759 
[epoch 9] step 18/44: loss=0.7755 
[epoch 9] step 20/44: loss=0.7731 
[epoch 9] step 22/44: loss=0.7710 
[epoch 9] step 24/44: loss=0.7682 
[epoch 9] step 26/44: loss=0.7658 
[epoch 9] step 28/44: loss=0.7646 
[epoch 9] step 30/44: loss=0.7635 
[epoch 9] step 32/44: loss=0.7652 
[epoch 9] step 34/44: loss=0.7645 
[epoch 9] step 36/44: loss=0.7633 
[epoch 9] step 38/44: loss=0.7599 
[epoch 9] step 40/44: loss=0.7574 
[epoch 9] step 42/44: loss=0.7555 
[epoch 9] step 44/44: loss=0.7542 
[epoch 9] train_loss(avg per step)=1.5083 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.4185 qwk=('0.4798', '0.4576', '0.5889') averageQWK=0.5088 macroEMD=0.2920 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    4    0
     0    6   40    7    1
     0    0   84   40    2
     0    0   21   90    5
     0    0    1   17    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    3    0
     0   10   29   13    0
     0    5   65   52    0
     0    2   16  115    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   21   44    3    0
     0   12   99   41    0
     0    1   17   83    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=0.7397 
[epoch 10] step 4/44: loss=0.7501 
[epoch 10] step 6/44: loss=0.7577 
[epoch 10] step 8/44: loss=0.7678 
[epoch 10] step 10/44: loss=0.7766 
[epoch 10] step 12/44: loss=0.7730 
[epoch 10] step 14/44: loss=0.7703 
[epoch 10] step 16/44: loss=0.7667 
[epoch 10] step 18/44: loss=0.7599 
[epoch 10] step 20/44: loss=0.7557 
[epoch 10] step 22/44: loss=0.7572 
[epoch 10] step 24/44: loss=0.7537 
[epoch 10] step 26/44: loss=0.7522 
[epoch 10] step 28/44: loss=0.7516 
[epoch 10] step 30/44: loss=0.7501 
[epoch 10] step 32/44: loss=0.7488 
[epoch 10] step 34/44: loss=0.7472 
[epoch 10] step 36/44: loss=0.7488 
[epoch 10] step 38/44: loss=0.7509 
[epoch 10] step 40/44: loss=0.7514 
[epoch 10] step 42/44: loss=0.7521 
[epoch 10] step 44/44: loss=0.7542 
[epoch 10] train_loss(avg per step)=1.5085 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.4244 qwk=('0.5796', '0.4972', '0.6235') averageQWK=0.5668 macroEMD=0.2844 tailR0=('0.1739', '0.0000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    4    0
     0   19   28    7    0
     0   16   64   44    2
     0    0   16   92    8
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    2    0
     0   13   27   12    0
     0   13   62   47    0
     0    0   21  112    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   36   29    3    0
     0   32   87   33    0
     0    3   14   84    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.7317 
[epoch 11] step 4/44: loss=0.7481 
[epoch 11] step 6/44: loss=0.7496 
[epoch 11] step 8/44: loss=0.7508 
[epoch 11] step 10/44: loss=0.7467 
[epoch 11] step 12/44: loss=0.7462 
[epoch 11] step 14/44: loss=0.7383 
[epoch 11] step 16/44: loss=0.7354 
[epoch 11] step 18/44: loss=0.7340 
[epoch 11] step 20/44: loss=0.7376 
[epoch 11] step 22/44: loss=0.7419 
[epoch 11] step 24/44: loss=0.7406 
[epoch 11] step 26/44: loss=0.7385 
[epoch 11] step 28/44: loss=0.7370 
[epoch 11] step 30/44: loss=0.7353 
[epoch 11] step 32/44: loss=0.7354 
[epoch 11] step 34/44: loss=0.7362 
[epoch 11] step 36/44: loss=0.7371 
[epoch 11] step 38/44: loss=0.7354 
[epoch 11] step 40/44: loss=0.7350 
[epoch 11] step 42/44: loss=0.7350 
[epoch 11] step 44/44: loss=0.7380 
[epoch 11] train_loss(avg per step)=1.4760 lambda[min,max]=[0.472869,1.000000]
[epoch 11] val_loss=1.4298 qwk=('0.5735', '0.4757', '0.6160') averageQWK=0.5551 macroEMD=0.2824 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    2    0
     0   11   36    7    0
     0    3   84   37    2
     0    0   19   91    6
     0    0    0   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0    9   33   10    0
     0    7   68   47    0
     0    1   24  108    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   23   41    4    0
     0   11  109   32    0
     0    0   18   83    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=0.7700 
[epoch 12] step 4/44: loss=0.7626 
[epoch 12] step 6/44: loss=0.7337 
[epoch 12] step 8/44: loss=0.7292 
[epoch 12] step 10/44: loss=0.7272 
[epoch 12] step 12/44: loss=0.7345 
[epoch 12] step 14/44: loss=0.7352 
[epoch 12] step 16/44: loss=0.7382 
[epoch 12] step 18/44: loss=0.7357 
[epoch 12] step 20/44: loss=0.7344 
[epoch 12] step 22/44: loss=0.7356 
[epoch 12] step 24/44: loss=0.7353 
[epoch 12] step 26/44: loss=0.7337 
[epoch 12] step 28/44: loss=0.7321 
[epoch 12] step 30/44: loss=0.7292 
[epoch 12] step 32/44: loss=0.7286 
[epoch 12] step 34/44: loss=0.7262 
[epoch 12] step 36/44: loss=0.7260 
[epoch 12] step 38/44: loss=0.7242 
[epoch 12] step 40/44: loss=0.7252 
[epoch 12] step 42/44: loss=0.7260 
[epoch 12] step 44/44: loss=0.7260 
[epoch 12] train_loss(avg per step)=1.4519 lambda[min,max]=[0.449806,1.000000]
[epoch 12] val_loss=1.4537 qwk=('0.6063', '0.5734', '0.6507') averageQWK=0.6101 macroEMD=0.2744 tailR0=('0.3043', '0.0000', '0.0000') tailR0avg=0.1014
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   17   34    2    1
     0    5   98   20    3
     0    0   37   65   14
     0    0    2    7   14
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   14   36    2    0
     0   12   80   30    0
     0    3   30  100    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   36   30    2    0
     0   31   86   35    0
     0    2   13   86    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.7514 
[epoch 13] step 4/44: loss=0.7464 
[epoch 13] step 6/44: loss=0.7469 
[epoch 13] step 8/44: loss=0.7541 
[epoch 13] step 10/44: loss=0.7548 
[epoch 13] step 12/44: loss=0.7449 
[epoch 13] step 14/44: loss=0.7364 
[epoch 13] step 16/44: loss=0.7271 
[epoch 13] step 18/44: loss=0.7230 
[epoch 13] step 20/44: loss=0.7206 
[epoch 13] step 22/44: loss=0.7168 
[epoch 13] step 24/44: loss=0.7117 
[epoch 13] step 26/44: loss=0.7123 
[epoch 13] step 28/44: loss=0.7134 
[epoch 13] step 30/44: loss=0.7161 
[epoch 13] step 32/44: loss=0.7146 
[epoch 13] step 34/44: loss=0.7172 
[epoch 13] step 36/44: loss=0.7202 
[epoch 13] step 38/44: loss=0.7185 
[epoch 13] step 40/44: loss=0.7186 
[epoch 13] step 42/44: loss=0.7181 
[epoch 13] step 44/44: loss=0.7181 
[epoch 13] train_loss(avg per step)=1.4362 lambda[min,max]=[0.459255,1.000000]
[epoch 13] val_loss=1.3578 qwk=('0.5697', '0.5262', '0.6208') averageQWK=0.5722 macroEMD=0.2824 tailR0=('0.1739', '0.0417', '0.0000') tailR0avg=0.0719
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   18   31    5    0
     0   10   79   35    2
     0    0   30   73   13
     0    0    2   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   12   33    7    0
     0   13   73   36    0
     0    3   29   98    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   19   49    0    0
     0    6  132   14    0
     0    0   32   69    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.7323 
[epoch 14] step 4/44: loss=0.7133 
[epoch 14] step 6/44: loss=0.6923 
[epoch 14] step 8/44: loss=0.6853 
[epoch 14] step 10/44: loss=0.6876 
[epoch 14] step 12/44: loss=0.6894 
[epoch 14] step 14/44: loss=0.6907 
[epoch 14] step 16/44: loss=0.6930 
[epoch 14] step 18/44: loss=0.6946 
[epoch 14] step 20/44: loss=0.6939 
[epoch 14] step 22/44: loss=0.6927 
[epoch 14] step 24/44: loss=0.6915 
[epoch 14] step 26/44: loss=0.6882 
[epoch 14] step 28/44: loss=0.6885 
[epoch 14] step 30/44: loss=0.6879 
[epoch 14] step 32/44: loss=0.6869 
[epoch 14] step 34/44: loss=0.6854 
[epoch 14] step 36/44: loss=0.6874 
[epoch 14] step 38/44: loss=0.6877 
[epoch 14] step 40/44: loss=0.6882 
[epoch 14] step 42/44: loss=0.6893 
[epoch 14] step 44/44: loss=0.6879 
[epoch 14] train_loss(avg per step)=1.3758 lambda[min,max]=[0.425764,1.000000]
[epoch 14] val_loss=1.3813 qwk=('0.5562', '0.5432', '0.6335') averageQWK=0.5776 macroEMD=0.2851 tailR0=('0.2077', '0.0000', '0.0000') tailR0avg=0.0692
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    3    0
     0   18   33    3    0
     0   14   90   20    2
     0    1   46   62    7
     0    0    2   14    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   16   31    5    0
     0   14   82   26    0
     0    4   35   92    2
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   41   27    0    0
     0   31  112    9    0
     0    4   33   64    0
     0    0    1    1    0
[epoch 15] step 2/44: loss=0.7014 
[epoch 15] step 4/44: loss=0.7009 
[epoch 15] step 6/44: loss=0.7072 
[epoch 15] step 8/44: loss=0.7030 
[epoch 15] step 10/44: loss=0.6951 
[epoch 15] step 12/44: loss=0.6937 
[epoch 15] step 14/44: loss=0.6903 
[epoch 15] step 16/44: loss=0.6866 
[epoch 15] step 18/44: loss=0.6847 
[epoch 15] step 20/44: loss=0.6792 
[epoch 15] step 22/44: loss=0.6801 
[epoch 15] step 24/44: loss=0.6772 
[epoch 15] step 26/44: loss=0.6792 
[epoch 15] step 28/44: loss=0.6812 
[epoch 15] step 30/44: loss=0.6840 
[epoch 15] step 32/44: loss=0.6833 
[epoch 15] step 34/44: loss=0.6822 
[epoch 15] step 36/44: loss=0.6813 
[epoch 15] step 38/44: loss=0.6795 
[epoch 15] step 40/44: loss=0.6819 
[epoch 15] step 42/44: loss=0.6802 
[epoch 15] step 44/44: loss=0.6800 
[epoch 15] train_loss(avg per step)=1.3600 lambda[min,max]=[0.405369,1.000000]
[epoch 15] val_loss=1.3218 qwk=('0.4668', '0.4642', '0.6114') averageQWK=0.5141 macroEMD=0.2914 tailR0=('0.1860', '0.0000', '0.0000') tailR0avg=0.0620
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    3    4    0
     0    9   34   11    0
     0    0   64   59    3
     0    0   16   96    4
     0    0    0   17    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    3    0
     0    7   34   11    0
     0    4   60   58    0
     0    0   16  117    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   20   45    3    0
     0    7  106   39    0
     0    0   16   85    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=0.6698 
[epoch 16] step 4/44: loss=0.6738 
[epoch 16] step 6/44: loss=0.6761 
[epoch 16] step 8/44: loss=0.6686 
[epoch 16] step 10/44: loss=0.6656 
[epoch 16] step 12/44: loss=0.6571 
[epoch 16] step 14/44: loss=0.6623 
[epoch 16] step 16/44: loss=0.6623 
[epoch 16] step 18/44: loss=0.6602 
[epoch 16] step 20/44: loss=0.6595 
[epoch 16] step 22/44: loss=0.6593 
[epoch 16] step 24/44: loss=0.6565 
[epoch 16] step 26/44: loss=0.6569 
[epoch 16] step 28/44: loss=0.6570 
[epoch 16] step 30/44: loss=0.6595 
[epoch 16] step 32/44: loss=0.6608 
[epoch 16] step 34/44: loss=0.6606 
[epoch 16] step 36/44: loss=0.6588 
[epoch 16] step 38/44: loss=0.6601 
[epoch 16] step 40/44: loss=0.6608 
[epoch 16] step 42/44: loss=0.6617 
[epoch 16] step 44/44: loss=0.6628 
[epoch 16] train_loss(avg per step)=1.3256 lambda[min,max]=[0.388857,1.000000]
[epoch 16] val_loss=1.2994 qwk=('0.6081', '0.5822', '0.6121') averageQWK=0.6008 macroEMD=0.2791 tailR0=('0.2512', '0.1250', '0.0000') tailR0avg=0.1254
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    3    0
     0   18   33    3    0
     0   11   84   30    1
     0    0   34   69   13
     0    0    0   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   15   32    5    0
     0   11   84   27    0
     0    1   35   91    6
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   22   44    2    0
     0   17   95   40    0
     0    0   18   83    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=0.6037 
[epoch 17] step 4/44: loss=0.6069 
[epoch 17] step 6/44: loss=0.6139 
[epoch 17] step 8/44: loss=0.6374 
[epoch 17] step 10/44: loss=0.6380 
[epoch 17] step 12/44: loss=0.6364 
[epoch 17] step 14/44: loss=0.6410 
[epoch 17] step 16/44: loss=0.6485 
[epoch 17] step 18/44: loss=0.6498 
[epoch 17] step 20/44: loss=0.6522 
[epoch 17] step 22/44: loss=0.6536 
[epoch 17] step 24/44: loss=0.6573 
[epoch 17] step 26/44: loss=0.6564 
[epoch 17] step 28/44: loss=0.6570 
[epoch 17] step 30/44: loss=0.6564 
[epoch 17] step 32/44: loss=0.6521 
[epoch 17] step 34/44: loss=0.6499 
[epoch 17] step 36/44: loss=0.6502 
[epoch 17] step 38/44: loss=0.6500 
[epoch 17] step 40/44: loss=0.6514 
[epoch 17] step 42/44: loss=0.6510 
[epoch 17] step 44/44: loss=0.6511 
[epoch 17] train_loss(avg per step)=1.3023 lambda[min,max]=[0.418807,1.000000]
[epoch 17] val_loss=1.3515 qwk=('0.5585', '0.5489', '0.6368') averageQWK=0.5814 macroEMD=0.2860 tailR0=('0.2077', '0.0000', '0.0000') tailR0avg=0.0692
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    4    2    0
     0   13   38    3    0
     0    3  100   21    2
     0    0   41   70    5
     0    0    2   14    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   11   38    3    0
     0    8   85   29    0
     0    2   32   99    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   39   29    0    0
     0   31  103   18    0
     0    3   28   70    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=0.6643 
[epoch 18] step 4/44: loss=0.6462 
[epoch 18] step 6/44: loss=0.6446 
[epoch 18] step 8/44: loss=0.6368 
[epoch 18] step 10/44: loss=0.6351 
[epoch 18] step 12/44: loss=0.6367 
[epoch 18] step 14/44: loss=0.6317 
[epoch 18] step 16/44: loss=0.6305 
[epoch 18] step 18/44: loss=0.6331 
[epoch 18] step 20/44: loss=0.6375 
[epoch 18] step 22/44: loss=0.6346 
[epoch 18] step 24/44: loss=0.6336 
[epoch 18] step 26/44: loss=0.6354 
[epoch 18] step 28/44: loss=0.6354 
[epoch 18] step 30/44: loss=0.6360 
[epoch 18] step 32/44: loss=0.6369 
[epoch 18] step 34/44: loss=0.6366 
[epoch 18] step 36/44: loss=0.6365 
[epoch 18] step 38/44: loss=0.6357 
[epoch 18] step 40/44: loss=0.6362 
[epoch 18] step 42/44: loss=0.6376 
[epoch 18] step 44/44: loss=0.6384 
[epoch 18] train_loss(avg per step)=1.2769 lambda[min,max]=[0.387496,1.000000]
[epoch 18] val_loss=1.2901 qwk=('0.4944', '0.4813', '0.5668') averageQWK=0.5142 macroEMD=0.2955 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    3    0
     0   12   29   13    0
     0    4   59   62    1
     0    0   16   92    8
     0    0    0   17    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    2    0
     0    7   38    7    0
     0    4   78   40    0
     0    2   29  101    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   23   41    4    0
     0   18  106   28    0
     0    2   24   75    0
     0    0    0    2    0
[epoch 19] step 2/44: loss=0.6638 
[epoch 19] step 4/44: loss=0.6612 
[epoch 19] step 6/44: loss=0.6411 
[epoch 19] step 8/44: loss=0.6254 
[epoch 19] step 10/44: loss=0.6221 
[epoch 19] step 12/44: loss=0.6274 
[epoch 19] step 14/44: loss=0.6281 
[epoch 19] step 16/44: loss=0.6267 
[epoch 19] step 18/44: loss=0.6304 
[epoch 19] step 20/44: loss=0.6296 
[epoch 19] step 22/44: loss=0.6315 
[epoch 19] step 24/44: loss=0.6303 
[epoch 19] step 26/44: loss=0.6297 
[epoch 19] step 28/44: loss=0.6253 
[epoch 19] step 30/44: loss=0.6254 
[epoch 19] step 32/44: loss=0.6261 
[epoch 19] step 34/44: loss=0.6258 
[epoch 19] step 36/44: loss=0.6269 
[epoch 19] step 38/44: loss=0.6254 
[epoch 19] step 40/44: loss=0.6243 
[epoch 19] step 42/44: loss=0.6235 
[epoch 19] step 44/44: loss=0.6260 
[epoch 19] train_loss(avg per step)=1.2519 lambda[min,max]=[0.389311,1.000000]
[epoch 19] val_loss=1.2876 qwk=('0.5370', '0.4748', '0.6197') averageQWK=0.5439 macroEMD=0.2867 tailR0=('0.1304', '0.0417', '0.0000') tailR0avg=0.0574
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    2    0
     0   11   38    5    0
     0    4   79   41    2
     0    0   32   80    4
     0    0    0   17    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   11   29   12    0
     0   11   55   56    0
     0    2   16  114    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   27   40    1    0
     0   15  111   26    0
     0    1   26   74    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=0.6423 
[epoch 20] step 4/44: loss=0.6351 
[epoch 20] step 6/44: loss=0.6436 
[epoch 20] step 8/44: loss=0.6450 
[epoch 20] step 10/44: loss=0.6421 
[epoch 20] step 12/44: loss=0.6389 
[epoch 20] step 14/44: loss=0.6311 
[epoch 20] step 16/44: loss=0.6253 
[epoch 20] step 18/44: loss=0.6251 
[epoch 20] step 20/44: loss=0.6242 
[epoch 20] step 22/44: loss=0.6212 
[epoch 20] step 24/44: loss=0.6179 
[epoch 20] step 26/44: loss=0.6188 
[epoch 20] step 28/44: loss=0.6184 
[epoch 20] step 30/44: loss=0.6189 
[epoch 20] step 32/44: loss=0.6173 
[epoch 20] step 34/44: loss=0.6153 
[epoch 20] step 36/44: loss=0.6167 
[epoch 20] step 38/44: loss=0.6177 
[epoch 20] step 40/44: loss=0.6192 
[epoch 20] step 42/44: loss=0.6192 
[epoch 20] step 44/44: loss=0.6226 
[epoch 20] train_loss(avg per step)=1.2451 lambda[min,max]=[0.380367,1.000000]
[epoch 20] val_loss=1.2693 qwk=('0.5726', '0.5632', '0.5866') averageQWK=0.5741 macroEMD=0.2851 tailR0=('0.1739', '0.0417', '0.0000') tailR0avg=0.0719
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   16   35    3    0
     0    9   86   29    2
     0    0   39   67   10
     0    0    2   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   15   35    2    0
     0   15   75   32    0
     0    3   32   92    6
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   18   48    2    0
     0    8  116   28    0
     0    0   27   74    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=0.6369 
[epoch 21] step 4/44: loss=0.6342 
[epoch 21] step 6/44: loss=0.6146 
[epoch 21] step 8/44: loss=0.6098 
[epoch 21] step 10/44: loss=0.6033 
[epoch 21] step 12/44: loss=0.5987 
[epoch 21] step 14/44: loss=0.5982 
[epoch 21] step 16/44: loss=0.6027 
[epoch 21] step 18/44: loss=0.6059 
[epoch 21] step 20/44: loss=0.6098 
[epoch 21] step 22/44: loss=0.6077 
[epoch 21] step 24/44: loss=0.6057 
[epoch 21] step 26/44: loss=0.6022 
[epoch 21] step 28/44: loss=0.6034 
[epoch 21] step 30/44: loss=0.6011 
[epoch 21] step 32/44: loss=0.6028 
[epoch 21] step 34/44: loss=0.6028 
[epoch 21] step 36/44: loss=0.6038 
[epoch 21] step 38/44: loss=0.6045 
[epoch 21] step 40/44: loss=0.6038 
[epoch 21] step 42/44: loss=0.6038 
[epoch 21] step 44/44: loss=0.6020 
[epoch 21] train_loss(avg per step)=1.2041 lambda[min,max]=[0.374113,1.000000]
[epoch 21] val_loss=1.2857 qwk=('0.5443', '0.5856', '0.6384') averageQWK=0.5894 macroEMD=0.2878 tailR0=('0.1087', '0.0417', '0.0000') tailR0avg=0.0501
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   13   38    3    0
     0    9   88   28    1
     0    0   40   70    6
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   18   33    1    0
     0   19   79   24    0
     0    5   32   88    8
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   27   40    1    0
     0   15  117   20    0
     0    0   30   71    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=0.6059 
[epoch 22] step 4/44: loss=0.6076 
[epoch 22] step 6/44: loss=0.5948 
[epoch 22] step 8/44: loss=0.5945 
[epoch 22] step 10/44: loss=0.5965 
[epoch 22] step 12/44: loss=0.5943 
[epoch 22] step 14/44: loss=0.5942 
[epoch 22] step 16/44: loss=0.5968 
[epoch 22] step 18/44: loss=0.5964 
[epoch 22] step 20/44: loss=0.5980 
[epoch 22] step 22/44: loss=0.5958 
[epoch 22] step 24/44: loss=0.5926 
[epoch 22] step 26/44: loss=0.5913 
[epoch 22] step 28/44: loss=0.5933 
[epoch 22] step 30/44: loss=0.5950 
[epoch 22] step 32/44: loss=0.5946 
[epoch 22] step 34/44: loss=0.5957 
[epoch 22] step 36/44: loss=0.5961 
[epoch 22] step 38/44: loss=0.5975 
[epoch 22] step 40/44: loss=0.5985 
[epoch 22] step 42/44: loss=0.5992 
[epoch 22] step 44/44: loss=0.5967 
[epoch 22] train_loss(avg per step)=1.1934 lambda[min,max]=[0.375402,1.000000]
[epoch 22] val_loss=1.2436 qwk=('0.5518', '0.4692', '0.6191') averageQWK=0.5467 macroEMD=0.2880 tailR0=('0.2512', '0.0417', '0.0000') tailR0avg=0.0976
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    2    0
     0   12   39    3    0
     0    3   90   30    3
     0    0   41   66    9
     0    0    3   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0    9   31   12    0
     0    8   61   53    0
     0    2   21  109    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   43    0    0
     0   15  111   26    0
     0    1   26   74    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=0.5839 
[epoch 23] step 4/44: loss=0.6033 
[epoch 23] step 6/44: loss=0.6101 
[epoch 23] step 8/44: loss=0.6106 
[epoch 23] step 10/44: loss=0.6034 
[epoch 23] step 12/44: loss=0.6004 
[epoch 23] step 14/44: loss=0.5975 
[epoch 23] step 16/44: loss=0.5946 
[epoch 23] step 18/44: loss=0.5897 
[epoch 23] step 20/44: loss=0.5854 
[epoch 23] step 22/44: loss=0.5822 
[epoch 23] step 24/44: loss=0.5819 
[epoch 23] step 26/44: loss=0.5821 
[epoch 23] step 28/44: loss=0.5818 
[epoch 23] step 30/44: loss=0.5849 
[epoch 23] step 32/44: loss=0.5852 
[epoch 23] step 34/44: loss=0.5865 
[epoch 23] step 36/44: loss=0.5886 
[epoch 23] step 38/44: loss=0.5874 
[epoch 23] step 40/44: loss=0.5882 
[epoch 23] step 42/44: loss=0.5866 
[epoch 23] step 44/44: loss=0.5837 
[epoch 23] train_loss(avg per step)=1.1674 lambda[min,max]=[0.381521,1.000000]
[epoch 23] val_loss=1.1839 qwk=('0.5865', '0.5234', '0.6181') averageQWK=0.5760 macroEMD=0.2906 tailR0=('0.1522', '0.0417', '0.0000') tailR0avg=0.0646
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   15   35    4    0
     0    8   79   38    1
     0    0   26   84    6
     0    0    0   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   11   34    7    0
     0    8   78   36    0
     0    3   26   99    5
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   33   33    2    0
     0   22  100   30    0
     0    2   23   76    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=0.5806 
[epoch 24] step 4/44: loss=0.6108 
[epoch 24] step 6/44: loss=0.5996 
[epoch 24] step 8/44: loss=0.6018 
[epoch 24] step 10/44: loss=0.5934 
[epoch 24] step 12/44: loss=0.5901 
[epoch 24] step 14/44: loss=0.5849 
[epoch 24] step 16/44: loss=0.5813 
[epoch 24] step 18/44: loss=0.5811 
[epoch 24] step 20/44: loss=0.5793 
[epoch 24] step 22/44: loss=0.5793 
[epoch 24] step 24/44: loss=0.5809 
[epoch 24] step 26/44: loss=0.5801 
[epoch 24] step 28/44: loss=0.5799 
[epoch 24] step 30/44: loss=0.5803 
[epoch 24] step 32/44: loss=0.5823 
[epoch 24] step 34/44: loss=0.5812 
[epoch 24] step 36/44: loss=0.5800 
[epoch 24] step 38/44: loss=0.5782 
[epoch 24] step 40/44: loss=0.5746 
[epoch 24] step 42/44: loss=0.5762 
[epoch 24] step 44/44: loss=0.5757 
[epoch 24] train_loss(avg per step)=1.1515 lambda[min,max]=[0.374350,1.000000]
[epoch 24] val_loss=1.1841 qwk=('0.5507', '0.4966', '0.5768') averageQWK=0.5414 macroEMD=0.2905 tailR0=('0.1739', '0.0000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    2    0
     0   11   40    3    0
     0    2   92   31    1
     0    0   37   71    8
     0    0    3   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   16   26   10    0
     0   10   68   44    0
     0    4   24  102    3
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   23   40    5    0
     0   14   98   40    0
     0    0   21   80    0
     0    0    0    2    0
[epoch 25] step 2/44: loss=0.5700 
[epoch 25] step 4/44: loss=0.5730 
[epoch 25] step 6/44: loss=0.5804 
[epoch 25] step 8/44: loss=0.5840 
[epoch 25] step 10/44: loss=0.5800 
[epoch 25] step 12/44: loss=0.5723 
[epoch 25] step 14/44: loss=0.5703 
[epoch 25] step 16/44: loss=0.5723 
[epoch 25] step 18/44: loss=0.5722 
[epoch 25] step 20/44: loss=0.5736 
[epoch 25] step 22/44: loss=0.5757 
[epoch 25] step 24/44: loss=0.5761 
[epoch 25] step 26/44: loss=0.5775 
[epoch 25] step 28/44: loss=0.5810 
[epoch 25] step 30/44: loss=0.5798 
[epoch 25] step 32/44: loss=0.5794 
[epoch 25] step 34/44: loss=0.5775 
[epoch 25] step 36/44: loss=0.5733 
[epoch 25] step 38/44: loss=0.5701 
[epoch 25] step 40/44: loss=0.5669 
[epoch 25] step 42/44: loss=0.5651 
[epoch 25] step 44/44: loss=0.5645 
[epoch 25] train_loss(avg per step)=1.1289 lambda[min,max]=[0.378827,1.000000]
[epoch 25] val_loss=1.1557 qwk=('0.5439', '0.4603', '0.6189') averageQWK=0.5410 macroEMD=0.2949 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   11   37    6    0
     0    4   77   44    1
     0    0   27   81    8
     0    0    0   17    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   11   28   13    0
     0    7   59   56    0
     0    2   17  114    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   24   43    1    0
     0   11  112   29    0
     0    0   26   75    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=0.5710 
[epoch 26] step 4/44: loss=0.5671 
[epoch 26] step 6/44: loss=0.5651 
[epoch 26] step 8/44: loss=0.5770 
[epoch 26] step 10/44: loss=0.5786 
[epoch 26] step 12/44: loss=0.5748 
[epoch 26] step 14/44: loss=0.5741 
[epoch 26] step 16/44: loss=0.5773 
[epoch 26] step 18/44: loss=0.5742 
[epoch 26] step 20/44: loss=0.5758 
[epoch 26] step 22/44: loss=0.5758 
[epoch 26] step 24/44: loss=0.5748 
[epoch 26] step 26/44: loss=0.5741 
[epoch 26] step 28/44: loss=0.5734 
[epoch 26] step 30/44: loss=0.5721 
[epoch 26] step 32/44: loss=0.5720 
[epoch 26] step 34/44: loss=0.5714 
[epoch 26] step 36/44: loss=0.5726 
[epoch 26] step 38/44: loss=0.5718 
[epoch 26] step 40/44: loss=0.5716 
[epoch 26] step 42/44: loss=0.5742 
[epoch 26] step 44/44: loss=0.5715 
[epoch 26] train_loss(avg per step)=1.1430 lambda[min,max]=[0.372224,1.000000]
[epoch 26] val_loss=1.1628 qwk=('0.5693', '0.5301', '0.6240') averageQWK=0.5745 macroEMD=0.2946 tailR0=('0.2174', '0.0417', '0.0000') tailR0avg=0.0864
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   14   37    3    0
     0    3   92   29    2
     0    0   40   64   12
     0    0    3   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    2    0
     0   11   36    5    0
     0    6   79   37    0
     0    2   28   98    5
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   43    0    0
     0   17  113   22    0
     0    1   26   74    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=0.5307 
[epoch 27] step 4/44: loss=0.5412 
[epoch 27] step 6/44: loss=0.5516 
[epoch 27] step 8/44: loss=0.5445 
[epoch 27] step 10/44: loss=0.5489 
[epoch 27] step 12/44: loss=0.5567 
[epoch 27] step 14/44: loss=0.5635 
[epoch 27] step 16/44: loss=0.5644 
[epoch 27] step 18/44: loss=0.5669 
[epoch 27] step 20/44: loss=0.5632 
[epoch 27] step 22/44: loss=0.5634 
[epoch 27] step 24/44: loss=0.5615 
[epoch 27] step 26/44: loss=0.5598 
[epoch 27] step 28/44: loss=0.5606 
[epoch 27] step 30/44: loss=0.5614 
[epoch 27] step 32/44: loss=0.5604 
[epoch 27] step 34/44: loss=0.5598 
[epoch 27] step 36/44: loss=0.5583 
[epoch 27] step 38/44: loss=0.5592 
[epoch 27] step 40/44: loss=0.5601 
[epoch 27] step 42/44: loss=0.5602 
[epoch 27] step 44/44: loss=0.5596 
[epoch 27] train_loss(avg per step)=1.1193 lambda[min,max]=[0.375122,1.000000]
[epoch 27] val_loss=1.1818 qwk=('0.5989', '0.5527', '0.6271') averageQWK=0.5929 macroEMD=0.2852 tailR0=('0.2729', '0.0000', '0.0000') tailR0avg=0.0910
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    2    0
     0   17   33    4    0
     0    8   88   28    2
     0    0   37   69   10
     0    0    1   12   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0   19   27    6    0
     0   17   71   34    0
     0    4   27   98    4
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   29   38    1    0
     0   20  100   32    0
     0    1   21   79    0
     0    0    0    2    0
[epoch 28] step 2/44: loss=0.5900 
[epoch 28] step 4/44: loss=0.6089 
[epoch 28] step 6/44: loss=0.5964 
[epoch 28] step 8/44: loss=0.5854 
[epoch 28] step 10/44: loss=0.5788 
[epoch 28] step 12/44: loss=0.5750 
[epoch 28] step 14/44: loss=0.5773 
[epoch 28] step 16/44: loss=0.5792 
[epoch 28] step 18/44: loss=0.5718 
[epoch 28] step 20/44: loss=0.5659 
[epoch 28] step 22/44: loss=0.5685 
[epoch 28] step 24/44: loss=0.5664 
[epoch 28] step 26/44: loss=0.5654 
[epoch 28] step 28/44: loss=0.5669 
[epoch 28] step 30/44: loss=0.5644 
[epoch 28] step 32/44: loss=0.5639 
[epoch 28] step 34/44: loss=0.5638 
[epoch 28] step 36/44: loss=0.5639 
[epoch 28] step 38/44: loss=0.5629 
[epoch 28] step 40/44: loss=0.5631 
[epoch 28] step 42/44: loss=0.5621 
[epoch 28] step 44/44: loss=0.5620 
[epoch 28] train_loss(avg per step)=1.1241 lambda[min,max]=[0.359687,1.000000]
[epoch 28] val_loss=1.1640 qwk=('0.5860', '0.5245', '0.6301') averageQWK=0.5802 macroEMD=0.2870 tailR0=('0.2729', '0.0000', '0.0000') tailR0avg=0.0910
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    2    0
     0   16   35    3    0
     0    8   87   29    2
     0    0   37   69   10
     0    0    3   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   15   32    5    0
     0   12   74   36    0
     0    4   30   96    3
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   28   40    0    0
     0   21  109   22    0
     0    1   26   74    0
     0    0    0    2    0
[epoch 29] step 2/44: loss=0.5732 
[epoch 29] step 4/44: loss=0.5638 
[epoch 29] step 6/44: loss=0.5573 
[epoch 29] step 8/44: loss=0.5526 
[epoch 29] step 10/44: loss=0.5477 
[epoch 29] step 12/44: loss=0.5436 
[epoch 29] step 14/44: loss=0.5457 
[epoch 29] step 16/44: loss=0.5443 
[epoch 29] step 18/44: loss=0.5470 
[epoch 29] step 20/44: loss=0.5443 
[epoch 29] step 22/44: loss=0.5452 
[epoch 29] step 24/44: loss=0.5448 
[epoch 29] step 26/44: loss=0.5458 
[epoch 29] step 28/44: loss=0.5449 
[epoch 29] step 30/44: loss=0.5435 
[epoch 29] step 32/44: loss=0.5417 
[epoch 29] step 34/44: loss=0.5453 
[epoch 29] step 36/44: loss=0.5463 
[epoch 29] step 38/44: loss=0.5461 
[epoch 29] step 40/44: loss=0.5467 
[epoch 29] step 42/44: loss=0.5469 
[epoch 29] step 44/44: loss=0.5476 
[epoch 29] train_loss(avg per step)=1.0951 lambda[min,max]=[0.383586,1.000000]
[epoch 29] val_loss=1.1440 qwk=('0.5773', '0.4639', '0.6239') averageQWK=0.5550 macroEMD=0.2904 tailR0=('0.2077', '0.0000', '0.0000') tailR0avg=0.0692
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    4    2    0
     0   13   38    3    0
     0    4   88   33    1
     0    0   31   77    8
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   14   26   12    0
     0   11   51   60    0
     0    4   17  112    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   34   33    1    0
     0   26  100   26    0
     0    3   22   76    0
     0    0    0    2    0
[epoch 30] step 2/44: loss=0.6276 
[epoch 30] step 4/44: loss=0.6196 
[epoch 30] step 6/44: loss=0.6026 
[epoch 30] step 8/44: loss=0.5953 
[epoch 30] step 10/44: loss=0.5892 
[epoch 30] step 12/44: loss=0.5769 
[epoch 30] step 14/44: loss=0.5650 
[epoch 30] step 16/44: loss=0.5610 
[epoch 30] step 18/44: loss=0.5608 
[epoch 30] step 20/44: loss=0.5563 
[epoch 30] step 22/44: loss=0.5562 
[epoch 30] step 24/44: loss=0.5526 
[epoch 30] step 26/44: loss=0.5549 
[epoch 30] step 28/44: loss=0.5549 
[epoch 30] step 30/44: loss=0.5546 
[epoch 30] step 32/44: loss=0.5541 
[epoch 30] step 34/44: loss=0.5561 
[epoch 30] step 36/44: loss=0.5567 
[epoch 30] step 38/44: loss=0.5580 
[epoch 30] step 40/44: loss=0.5578 
[epoch 30] step 42/44: loss=0.5570 
[epoch 30] step 44/44: loss=0.5551 
[epoch 30] train_loss(avg per step)=1.1102 lambda[min,max]=[0.382252,1.000000]
[epoch 30] val_loss=1.1518 qwk=('0.5553', '0.4668', '0.6190') averageQWK=0.5470 macroEMD=0.2899 tailR0=('0.1522', '0.0417', '0.0000') tailR0avg=0.0646
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    2    0
     0   12   39    3    0
     0    4   92   29    1
     0    0   36   70   10
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    3    0
     0   14   27   11    0
     0   10   63   49    0
     0    3   24  104    2
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   26   42    0    0
     0   18  112   22    0
     0    2   25   74    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=0.5476 
[epoch 31] step 4/44: loss=0.5275 
[epoch 31] step 6/44: loss=0.5364 
[epoch 31] step 8/44: loss=0.5421 
[epoch 31] step 10/44: loss=0.5466 
[epoch 31] step 12/44: loss=0.5413 
[epoch 31] step 14/44: loss=0.5449 
[epoch 31] step 16/44: loss=0.5460 
[epoch 31] step 18/44: loss=0.5400 
[epoch 31] step 20/44: loss=0.5404 
[epoch 31] step 22/44: loss=0.5438 
[epoch 31] step 24/44: loss=0.5482 
[epoch 31] step 26/44: loss=0.5489 
[epoch 31] step 28/44: loss=0.5507 
[epoch 31] step 30/44: loss=0.5520 
[epoch 31] step 32/44: loss=0.5533 
[epoch 31] step 34/44: loss=0.5543 
[epoch 31] step 36/44: loss=0.5552 
[epoch 31] step 38/44: loss=0.5516 
[epoch 31] step 40/44: loss=0.5521 
[epoch 31] step 42/44: loss=0.5515 
[epoch 31] step 44/44: loss=0.5521 
[epoch 31] train_loss(avg per step)=1.1043 lambda[min,max]=[0.385151,1.000000]
[epoch 31] val_loss=1.1534 qwk=('0.5875', '0.5411', '0.6182') averageQWK=0.5823 macroEMD=0.2875 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   18   33    3    0
     0    7   90   28    1
     0    0   38   72    6
     0    0    2   14    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0   19   26    7    0
     0   12   69   41    0
     0    4   25  104    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   28   40    0    0
     0   21  105   26    0
     0    1   27   73    0
     0    0    0    2    0
[epoch 32] step 2/44: loss=0.5257 
[epoch 32] step 4/44: loss=0.5408 
[epoch 32] step 6/44: loss=0.5426 
[epoch 32] step 8/44: loss=0.5430 
[epoch 32] step 10/44: loss=0.5427 
[epoch 32] step 12/44: loss=0.5381 
[epoch 32] step 14/44: loss=0.5361 
[epoch 32] step 16/44: loss=0.5358 
[epoch 32] step 18/44: loss=0.5337 
[epoch 32] step 20/44: loss=0.5380 
[epoch 32] step 22/44: loss=0.5395 
[epoch 32] step 24/44: loss=0.5374 
[epoch 32] step 26/44: loss=0.5381 
[epoch 32] step 28/44: loss=0.5387 
[epoch 32] step 30/44: loss=0.5440 
[epoch 32] step 32/44: loss=0.5463 
[epoch 32] step 34/44: loss=0.5488 
[epoch 32] step 36/44: loss=0.5487 
[epoch 32] step 38/44: loss=0.5480 
[epoch 32] step 40/44: loss=0.5472 
[epoch 32] step 42/44: loss=0.5485 
[epoch 32] step 44/44: loss=0.5485 
[epoch 32] train_loss(avg per step)=1.0970 lambda[min,max]=[0.361444,1.000000]
[epoch 32] val_loss=1.1249 qwk=('0.5708', '0.4778', '0.6055') averageQWK=0.5514 macroEMD=0.2891 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   17   32    5    0
     0    8   74   43    1
     0    0   29   80    7
     0    0    0   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   14   27   11    0
     0   11   60   51    0
     0    3   20  109    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   23   43    2    0
     0   14  109   29    0
     0    0   25   76    0
     0    0    0    2    0
[epoch 33] step 2/44: loss=0.5319 
[epoch 33] step 4/44: loss=0.5283 
[epoch 33] step 6/44: loss=0.5270 
[epoch 33] step 8/44: loss=0.5297 
[epoch 33] step 10/44: loss=0.5337 
[epoch 33] step 12/44: loss=0.5342 
[epoch 33] step 14/44: loss=0.5335 
[epoch 33] step 16/44: loss=0.5302 
[epoch 33] step 18/44: loss=0.5313 
[epoch 33] step 20/44: loss=0.5348 
[epoch 33] step 22/44: loss=0.5349 
[epoch 33] step 24/44: loss=0.5338 
[epoch 33] step 26/44: loss=0.5346 
[epoch 33] step 28/44: loss=0.5376 
[epoch 33] step 30/44: loss=0.5385 
[epoch 33] step 32/44: loss=0.5374 
[epoch 33] step 34/44: loss=0.5379 
[epoch 33] step 36/44: loss=0.5399 
[epoch 33] step 38/44: loss=0.5414 
[epoch 33] step 40/44: loss=0.5414 
[epoch 33] step 42/44: loss=0.5411 
[epoch 33] step 44/44: loss=0.5411 
[epoch 33] train_loss(avg per step)=1.0822 lambda[min,max]=[0.368033,1.000000]
[epoch 33] val_loss=1.1553 qwk=('0.5832', '0.5011', '0.6131') averageQWK=0.5658 macroEMD=0.2873 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   15   35    4    0
     0    5   90   30    1
     0    0   35   73    8
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    2    0
     0   13   32    7    0
     0    8   74   40    0
     0    3   28  101    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   27   40    1    0
     0   23  108   21    0
     0    2   24   75    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=0.5890 
[epoch 34] step 4/44: loss=0.5653 
[epoch 34] step 6/44: loss=0.5571 
[epoch 34] step 8/44: loss=0.5548 
[epoch 34] step 10/44: loss=0.5599 
[epoch 34] step 12/44: loss=0.5591 
[epoch 34] step 14/44: loss=0.5592 
[epoch 34] step 16/44: loss=0.5559 
[epoch 34] step 18/44: loss=0.5535 
[epoch 34] step 20/44: loss=0.5560 
[epoch 34] step 22/44: loss=0.5576 
[epoch 34] step 24/44: loss=0.5563 
[epoch 34] step 26/44: loss=0.5573 
[epoch 34] step 28/44: loss=0.5577 
[epoch 34] step 30/44: loss=0.5555 
[epoch 34] step 32/44: loss=0.5559 
[epoch 34] step 34/44: loss=0.5560 
[epoch 34] step 36/44: loss=0.5528 
[epoch 34] step 38/44: loss=0.5502 
[epoch 34] step 40/44: loss=0.5498 
[epoch 34] step 42/44: loss=0.5485 
[epoch 34] step 44/44: loss=0.5465 
[epoch 34] train_loss(avg per step)=1.0930 lambda[min,max]=[0.362632,1.000000]
[epoch 34] val_loss=1.1320 qwk=('0.5905', '0.4973', '0.6218') averageQWK=0.5699 macroEMD=0.2888 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   17   33    4    0
     0    6   84   35    1
     0    0   34   75    7
     0    0    0   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   17   25   10    0
     0   11   66   45    0
     0    4   24  104    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   42    1    0
     0   18  110   24    0
     0    0   26   75    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=0.5730 
[epoch 35] step 4/44: loss=0.5416 
[epoch 35] step 6/44: loss=0.5442 
[epoch 35] step 8/44: loss=0.5393 
[epoch 35] step 10/44: loss=0.5419 
[epoch 35] step 12/44: loss=0.5503 
[epoch 35] step 14/44: loss=0.5496 
[epoch 35] step 16/44: loss=0.5461 
[epoch 35] step 18/44: loss=0.5463 
[epoch 35] step 20/44: loss=0.5458 
[epoch 35] step 22/44: loss=0.5455 
[epoch 35] step 24/44: loss=0.5457 
[epoch 35] step 26/44: loss=0.5456 
[epoch 35] step 28/44: loss=0.5465 
[epoch 35] step 30/44: loss=0.5466 
[epoch 35] step 32/44: loss=0.5468 
[epoch 35] step 34/44: loss=0.5431 
[epoch 35] step 36/44: loss=0.5431 
[epoch 35] step 38/44: loss=0.5450 
[epoch 35] step 40/44: loss=0.5453 
[epoch 35] step 42/44: loss=0.5475 
[epoch 35] step 44/44: loss=0.5463 
[epoch 35] train_loss(avg per step)=1.0926 lambda[min,max]=[0.353958,1.000000]
[epoch 35] val_loss=1.1309 qwk=('0.5868', '0.4942', '0.6129') averageQWK=0.5646 macroEMD=0.2883 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   15   35    4    0
     0    6   86   33    1
     0    0   34   74    8
     0    0    0   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   15   28    9    0
     0   11   65   46    0
     0    4   24  103    2
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   42    1    0
     0   20  109   23    0
     0    1   25   75    0
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-1/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-1/fold1/metrics.json
Done.
