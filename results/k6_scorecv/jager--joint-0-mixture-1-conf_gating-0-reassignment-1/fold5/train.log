[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.7328 
[epoch 1] step 4/44: loss=0.7233 
[epoch 1] step 6/44: loss=0.7123 
[epoch 1] step 8/44: loss=0.7178 
[epoch 1] step 10/44: loss=0.7175 
[epoch 1] step 12/44: loss=0.7172 
[epoch 1] step 14/44: loss=0.7158 
[epoch 1] step 16/44: loss=0.7152 
[epoch 1] step 18/44: loss=0.7140 
[epoch 1] step 20/44: loss=0.7154 
[epoch 1] step 22/44: loss=0.7136 
[epoch 1] step 24/44: loss=0.7145 
[epoch 1] step 26/44: loss=0.7144 
[epoch 1] step 28/44: loss=0.7137 
[epoch 1] step 30/44: loss=0.7141 
[epoch 1] step 32/44: loss=0.7131 
[epoch 1] step 34/44: loss=0.7137 
[epoch 1] step 36/44: loss=0.7110 
[epoch 1] step 38/44: loss=0.7112 
[epoch 1] step 40/44: loss=0.7125 
[epoch 1] step 42/44: loss=0.7171 
[epoch 1] step 44/44: loss=0.7201 
[epoch 1] train_loss(avg per step)=1.4402 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.5946 qwk=('0.1721', '0.1637', '0.0574') averageQWK=0.1311 macroEMD=0.3639 tailR0=('0.0000', '0.2222', '0.0000') tailR0avg=0.0741
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    0    3    0
     0   17    0   38    0
     0   37    0   88    0
     0   27    0   89    0
     0    2    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    0    5    0    0
    15    0   38    0    0
    31    0   84    7    0
    24    0   88   21    0
     0    0   10    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   11   58    0    0
     0   14  138    0    0
     0   12   88    1    0
     0    0    2    0    0
[epoch 2] step 2/44: loss=0.9320 
[epoch 2] step 4/44: loss=0.9135 
[epoch 2] step 6/44: loss=0.9218 
[epoch 2] step 8/44: loss=0.9459 
[epoch 2] step 10/44: loss=0.9585 
[epoch 2] step 12/44: loss=0.9606 
[epoch 2] step 14/44: loss=0.9517 
[epoch 2] step 16/44: loss=0.9407 
[epoch 2] step 18/44: loss=0.9296 
[epoch 2] step 20/44: loss=0.9147 
[epoch 2] step 22/44: loss=0.8995 
[epoch 2] step 24/44: loss=0.8872 
[epoch 2] step 26/44: loss=0.8733 
[epoch 2] step 28/44: loss=0.8667 
[epoch 2] step 30/44: loss=0.8628 
[epoch 2] step 32/44: loss=0.8639 
[epoch 2] step 34/44: loss=0.8639 
[epoch 2] step 36/44: loss=0.8656 
[epoch 2] step 38/44: loss=0.8650 
[epoch 2] step 40/44: loss=0.8664 
[epoch 2] step 42/44: loss=0.8658 
[epoch 2] step 44/44: loss=0.8636 
[epoch 2] train_loss(avg per step)=1.7272 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.2329 qwk=('0.2083', '0.2078', '0.2596') averageQWK=0.2253 macroEMD=0.3484 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    6    0
     0   10    3   42    0
     0    7   11  107    0
     0    0    1  115    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    0   17   36    0
     0    0   19  103    0
     0    0    0  133    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0    0   44   25    0
     0    0   55   97    0
     0    0   12   89    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=0.7513 
[epoch 3] step 4/44: loss=0.7492 
[epoch 3] step 6/44: loss=0.7401 
[epoch 3] step 8/44: loss=0.7309 
[epoch 3] step 10/44: loss=0.7350 
[epoch 3] step 12/44: loss=0.7432 
[epoch 3] step 14/44: loss=0.7489 
[epoch 3] step 16/44: loss=0.7539 
[epoch 3] step 18/44: loss=0.7592 
[epoch 3] step 20/44: loss=0.7683 
[epoch 3] step 22/44: loss=0.7750 
[epoch 3] step 24/44: loss=0.7798 
[epoch 3] step 26/44: loss=0.7847 
[epoch 3] step 28/44: loss=0.7874 
[epoch 3] step 30/44: loss=0.7873 
[epoch 3] step 32/44: loss=0.7879 
[epoch 3] step 34/44: loss=0.7884 
[epoch 3] step 36/44: loss=0.7912 
[epoch 3] step 38/44: loss=0.7931 
[epoch 3] step 40/44: loss=0.7965 
[epoch 3] step 42/44: loss=0.7978 
[epoch 3] step 44/44: loss=0.8001 
[epoch 3] train_loss(avg per step)=1.6003 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=1.5060 qwk=('0.4822', '0.4661', '0.5984') averageQWK=0.5156 macroEMD=0.3215 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    1    0
     0    3   48    4    0
     0    4   97   24    0
     0    0   31   85    0
     0    0    5   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   44    9    0
     0    0   78   44    0
     0    0   18  115    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   50   14    5    0
     0   60   44   48    0
     0    5   13   83    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=0.8641 
[epoch 4] step 4/44: loss=0.8440 
[epoch 4] step 6/44: loss=0.8463 
[epoch 4] step 8/44: loss=0.8371 
[epoch 4] step 10/44: loss=0.8264 
[epoch 4] step 12/44: loss=0.8225 
[epoch 4] step 14/44: loss=0.8152 
[epoch 4] step 16/44: loss=0.8166 
[epoch 4] step 18/44: loss=0.8146 
[epoch 4] step 20/44: loss=0.8164 
[epoch 4] step 22/44: loss=0.8191 
[epoch 4] step 24/44: loss=0.8210 
[epoch 4] step 26/44: loss=0.8201 
[epoch 4] step 28/44: loss=0.8182 
[epoch 4] step 30/44: loss=0.8183 
[epoch 4] step 32/44: loss=0.8188 
[epoch 4] step 34/44: loss=0.8150 
[epoch 4] step 36/44: loss=0.8122 
[epoch 4] step 38/44: loss=0.8080 
[epoch 4] step 40/44: loss=0.8067 
[epoch 4] step 42/44: loss=0.8089 
[epoch 4] step 44/44: loss=0.8100 
[epoch 4] train_loss(avg per step)=1.6199 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=1.5427 qwk=('0.4744', '0.5473', '0.4708') averageQWK=0.4975 macroEMD=0.3112 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    1    0
     0    2   47    6    0
     0    2   79   44    0
     0    0   21   95    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   10   34    9    0
     0    8   68   46    0
     0    0   13  120    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    3   61    5    0
     0    2   92   58    0
     0    0   13   88    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=0.8450 
[epoch 5] step 4/44: loss=0.8316 
[epoch 5] step 6/44: loss=0.8282 
[epoch 5] step 8/44: loss=0.8216 
[epoch 5] step 10/44: loss=0.8108 
[epoch 5] step 12/44: loss=0.8145 
[epoch 5] step 14/44: loss=0.8124 
[epoch 5] step 16/44: loss=0.8104 
[epoch 5] step 18/44: loss=0.8116 
[epoch 5] step 20/44: loss=0.8098 
[epoch 5] step 22/44: loss=0.8111 
[epoch 5] step 24/44: loss=0.8086 
[epoch 5] step 26/44: loss=0.8069 
[epoch 5] step 28/44: loss=0.8043 
[epoch 5] step 30/44: loss=0.8078 
[epoch 5] step 32/44: loss=0.8086 
[epoch 5] step 34/44: loss=0.8106 
[epoch 5] step 36/44: loss=0.8109 
[epoch 5] step 38/44: loss=0.8088 
[epoch 5] step 40/44: loss=0.8060 
[epoch 5] step 42/44: loss=0.8046 
[epoch 5] step 44/44: loss=0.8030 
[epoch 5] train_loss(avg per step)=1.6060 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=1.4276 qwk=('0.6238', '0.5856', '0.5684') averageQWK=0.5926 macroEMD=0.3044 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   31   18    6    0
     0   27   60   38    0
     0    2   17   97    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   23   23    7    0
     0   27   49   46    0
     0    1   14  118    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   22   44    3    0
     0   11   92   49    0
     0    0   20   81    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=0.7780 
[epoch 6] step 4/44: loss=0.7960 
[epoch 6] step 6/44: loss=0.8001 
[epoch 6] step 8/44: loss=0.8186 
[epoch 6] step 10/44: loss=0.8229 
[epoch 6] step 12/44: loss=0.8318 
[epoch 6] step 14/44: loss=0.8372 
[epoch 6] step 16/44: loss=0.8346 
[epoch 6] step 18/44: loss=0.8326 
[epoch 6] step 20/44: loss=0.8368 
[epoch 6] step 22/44: loss=0.8341 
[epoch 6] step 24/44: loss=0.8292 
[epoch 6] step 26/44: loss=0.8256 
[epoch 6] step 28/44: loss=0.8198 
[epoch 6] step 30/44: loss=0.8172 
[epoch 6] step 32/44: loss=0.8161 
[epoch 6] step 34/44: loss=0.8162 
[epoch 6] step 36/44: loss=0.8181 
[epoch 6] step 38/44: loss=0.8172 
[epoch 6] step 40/44: loss=0.8175 
[epoch 6] step 42/44: loss=0.8176 
[epoch 6] step 44/44: loss=0.8163 
[epoch 6] train_loss(avg per step)=1.6326 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=1.4980 qwk=('0.5595', '0.5316', '0.4798') averageQWK=0.5236 macroEMD=0.2973 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   20   24   11    0
     0   12   49   64    0
     0    0    8  108    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0    8   37    8    0
     0    3   72   47    0
     0    0   12  121    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0    7   57    5    0
     0    4   84   64    0
     0    0   15   86    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=0.7849 
[epoch 7] step 4/44: loss=0.7816 
[epoch 7] step 6/44: loss=0.7765 
[epoch 7] step 8/44: loss=0.7713 
[epoch 7] step 10/44: loss=0.7687 
[epoch 7] step 12/44: loss=0.7673 
[epoch 7] step 14/44: loss=0.7696 
[epoch 7] step 16/44: loss=0.7681 
[epoch 7] step 18/44: loss=0.7657 
[epoch 7] step 20/44: loss=0.7641 
[epoch 7] step 22/44: loss=0.7642 
[epoch 7] step 24/44: loss=0.7671 
[epoch 7] step 26/44: loss=0.7706 
[epoch 7] step 28/44: loss=0.7706 
[epoch 7] step 30/44: loss=0.7773 
[epoch 7] step 32/44: loss=0.7792 
[epoch 7] step 34/44: loss=0.7809 
[epoch 7] step 36/44: loss=0.7835 
[epoch 7] step 38/44: loss=0.7849 
[epoch 7] step 40/44: loss=0.7860 
[epoch 7] step 42/44: loss=0.7854 
[epoch 7] step 44/44: loss=0.7849 
[epoch 7] train_loss(avg per step)=1.5697 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.4786 qwk=('0.5928', '0.5476', '0.4799') averageQWK=0.5401 macroEMD=0.2898 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   17   33    5    0
     0    7   66   51    1
     0    0   13  100    3
     0    0    2   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   16   27   10    0
     0   11   57   54    0
     0    0   10  123    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   12   51    6    0
     0    3   90   59    0
     0    0   21   80    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=0.7985 
[epoch 8] step 4/44: loss=0.7879 
[epoch 8] step 6/44: loss=0.7914 
[epoch 8] step 8/44: loss=0.7861 
[epoch 8] step 10/44: loss=0.7793 
[epoch 8] step 12/44: loss=0.7787 
[epoch 8] step 14/44: loss=0.7773 
[epoch 8] step 16/44: loss=0.7803 
[epoch 8] step 18/44: loss=0.7747 
[epoch 8] step 20/44: loss=0.7705 
[epoch 8] step 22/44: loss=0.7695 
[epoch 8] step 24/44: loss=0.7707 
[epoch 8] step 26/44: loss=0.7691 
[epoch 8] step 28/44: loss=0.7666 
[epoch 8] step 30/44: loss=0.7664 
[epoch 8] step 32/44: loss=0.7663 
[epoch 8] step 34/44: loss=0.7700 
[epoch 8] step 36/44: loss=0.7733 
[epoch 8] step 38/44: loss=0.7780 
[epoch 8] step 40/44: loss=0.7828 
[epoch 8] step 42/44: loss=0.7851 
[epoch 8] step 44/44: loss=0.7846 
[epoch 8] train_loss(avg per step)=1.5693 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.4518 qwk=('0.6220', '0.5762', '0.6032') averageQWK=0.6005 macroEMD=0.2857 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   29   22    4    0
     0   18   71   35    1
     0    2   23   86    5
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   25   22    6    0
     0   19   68   35    0
     0    4   21  108    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   41   25    3    0
     0   26   80   46    0
     0    2   29   70    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=0.7999 
[epoch 9] step 4/44: loss=0.7921 
[epoch 9] step 6/44: loss=0.7965 
[epoch 9] step 8/44: loss=0.8022 
[epoch 9] step 10/44: loss=0.7957 
[epoch 9] step 12/44: loss=0.7874 
[epoch 9] step 14/44: loss=0.7846 
[epoch 9] step 16/44: loss=0.7822 
[epoch 9] step 18/44: loss=0.7789 
[epoch 9] step 20/44: loss=0.7761 
[epoch 9] step 22/44: loss=0.7731 
[epoch 9] step 24/44: loss=0.7709 
[epoch 9] step 26/44: loss=0.7686 
[epoch 9] step 28/44: loss=0.7640 
[epoch 9] step 30/44: loss=0.7614 
[epoch 9] step 32/44: loss=0.7612 
[epoch 9] step 34/44: loss=0.7592 
[epoch 9] step 36/44: loss=0.7570 
[epoch 9] step 38/44: loss=0.7586 
[epoch 9] step 40/44: loss=0.7592 
[epoch 9] step 42/44: loss=0.7604 
[epoch 9] step 44/44: loss=0.7602 
[epoch 9] train_loss(avg per step)=1.5204 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.4300 qwk=('0.6039', '0.6297', '0.6477') averageQWK=0.6271 macroEMD=0.2772 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   17   35    3    0
     0   11   76   36    2
     0    0   28   77   11
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   31   16    6    0
     0   24   61   37    0
     0    6   13  114    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   53   16    0    0
     0   37   80   35    0
     0    4   30   67    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=0.7791 
[epoch 10] step 4/44: loss=0.7843 
[epoch 10] step 6/44: loss=0.7847 
[epoch 10] step 8/44: loss=0.7859 
[epoch 10] step 10/44: loss=0.7930 
[epoch 10] step 12/44: loss=0.7951 
[epoch 10] step 14/44: loss=0.7912 
[epoch 10] step 16/44: loss=0.7944 
[epoch 10] step 18/44: loss=0.7893 
[epoch 10] step 20/44: loss=0.7857 
[epoch 10] step 22/44: loss=0.7786 
[epoch 10] step 24/44: loss=0.7751 
[epoch 10] step 26/44: loss=0.7696 
[epoch 10] step 28/44: loss=0.7649 
[epoch 10] step 30/44: loss=0.7649 
[epoch 10] step 32/44: loss=0.7634 
[epoch 10] step 34/44: loss=0.7617 
[epoch 10] step 36/44: loss=0.7603 
[epoch 10] step 38/44: loss=0.7582 
[epoch 10] step 40/44: loss=0.7579 
[epoch 10] step 42/44: loss=0.7568 
[epoch 10] step 44/44: loss=0.7581 
[epoch 10] train_loss(avg per step)=1.5163 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.4115 qwk=('0.5948', '0.5716', '0.5829') averageQWK=0.5831 macroEMD=0.2827 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   12   40    3    0
     0    7   76   41    1
     0    0   22   90    4
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   16   27   10    0
     0    9   72   41    0
     0    0   14  119    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   26   42    1    0
     0   13   89   50    0
     0    1   23   77    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.7050 
[epoch 11] step 4/44: loss=0.7110 
[epoch 11] step 6/44: loss=0.7143 
[epoch 11] step 8/44: loss=0.7090 
[epoch 11] step 10/44: loss=0.7127 
[epoch 11] step 12/44: loss=0.7161 
[epoch 11] step 14/44: loss=0.7192 
[epoch 11] step 16/44: loss=0.7245 
[epoch 11] step 18/44: loss=0.7277 
[epoch 11] step 20/44: loss=0.7287 
[epoch 11] step 22/44: loss=0.7330 
[epoch 11] step 24/44: loss=0.7369 
[epoch 11] step 26/44: loss=0.7399 
[epoch 11] step 28/44: loss=0.7421 
[epoch 11] step 30/44: loss=0.7414 
[epoch 11] step 32/44: loss=0.7383 
[epoch 11] step 34/44: loss=0.7393 
[epoch 11] step 36/44: loss=0.7362 
[epoch 11] step 38/44: loss=0.7383 
[epoch 11] step 40/44: loss=0.7384 
[epoch 11] step 42/44: loss=0.7391 
[epoch 11] step 44/44: loss=0.7383 
[epoch 11] train_loss(avg per step)=1.4766 lambda[min,max]=[0.493832,1.000000]
[epoch 11] val_loss=1.4942 qwk=('0.6375', '0.5973', '0.6043') averageQWK=0.6130 macroEMD=0.2851 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   31   23    1    0
     0   27   68   30    0
     0    1   31   83    1
     0    0    3   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   26   21    6    0
     0   23   72   27    0
     0    3   32   98    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   41   28    0    0
     0   24  109   19    0
     0    2   44   55    0
     0    0    2    0    0
[epoch 12] step 2/44: loss=0.7861 
[epoch 12] step 4/44: loss=0.7836 
[epoch 12] step 6/44: loss=0.7836 
[epoch 12] step 8/44: loss=0.7775 
[epoch 12] step 10/44: loss=0.7770 
[epoch 12] step 12/44: loss=0.7798 
[epoch 12] step 14/44: loss=0.7781 
[epoch 12] step 16/44: loss=0.7731 
[epoch 12] step 18/44: loss=0.7689 
[epoch 12] step 20/44: loss=0.7679 
[epoch 12] step 22/44: loss=0.7657 
[epoch 12] step 24/44: loss=0.7601 
[epoch 12] step 26/44: loss=0.7564 
[epoch 12] step 28/44: loss=0.7523 
[epoch 12] step 30/44: loss=0.7481 
[epoch 12] step 32/44: loss=0.7418 
[epoch 12] step 34/44: loss=0.7399 
[epoch 12] step 36/44: loss=0.7391 
[epoch 12] step 38/44: loss=0.7357 
[epoch 12] step 40/44: loss=0.7342 
[epoch 12] step 42/44: loss=0.7322 
[epoch 12] step 44/44: loss=0.7319 
[epoch 12] train_loss(avg per step)=1.4638 lambda[min,max]=[0.468786,1.000000]
[epoch 12] val_loss=1.4312 qwk=('0.6067', '0.5848', '0.5898') averageQWK=0.5938 macroEMD=0.2762 tailR0=('0.2174', '0.0000', '0.0000') tailR0avg=0.0725
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   19   26   10    0
     0   10   63   50    2
     0    0   13   91   12
     0    0    1   12   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   19   25    9    0
     0   10   68   44    0
     0    0   11  122    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   29   38    2    0
     0   13   95   44    0
     0    1   28   72    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.7667 
[epoch 13] step 4/44: loss=0.7579 
[epoch 13] step 6/44: loss=0.7462 
[epoch 13] step 8/44: loss=0.7521 
[epoch 13] step 10/44: loss=0.7438 
[epoch 13] step 12/44: loss=0.7506 
[epoch 13] step 14/44: loss=0.7539 
[epoch 13] step 16/44: loss=0.7502 
[epoch 13] step 18/44: loss=0.7464 
[epoch 13] step 20/44: loss=0.7440 
[epoch 13] step 22/44: loss=0.7407 
[epoch 13] step 24/44: loss=0.7377 
[epoch 13] step 26/44: loss=0.7329 
[epoch 13] step 28/44: loss=0.7303 
[epoch 13] step 30/44: loss=0.7288 
[epoch 13] step 32/44: loss=0.7284 
[epoch 13] step 34/44: loss=0.7254 
[epoch 13] step 36/44: loss=0.7276 
[epoch 13] step 38/44: loss=0.7270 
[epoch 13] step 40/44: loss=0.7272 
[epoch 13] step 42/44: loss=0.7251 
[epoch 13] step 44/44: loss=0.7271 
[epoch 13] train_loss(avg per step)=1.4543 lambda[min,max]=[0.486859,1.000000]
[epoch 13] val_loss=1.3659 qwk=('0.5817', '0.5543', '0.5684') averageQWK=0.5681 macroEMD=0.2860 tailR0=('0.2391', '0.0833', '0.0000') tailR0avg=0.1075
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   12   38    5    0
     0    8   75   39    3
     0    0   31   72   13
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   16   29    8    0
     0   12   74   34    2
     0    0   23  107    3
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   26   42    1    0
     0    6  113   33    0
     0    0   35   66    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.7075 
[epoch 14] step 4/44: loss=0.7077 
[epoch 14] step 6/44: loss=0.6880 
[epoch 14] step 8/44: loss=0.6979 
[epoch 14] step 10/44: loss=0.6960 
[epoch 14] step 12/44: loss=0.6975 
[epoch 14] step 14/44: loss=0.6957 
[epoch 14] step 16/44: loss=0.6987 
[epoch 14] step 18/44: loss=0.7011 
[epoch 14] step 20/44: loss=0.7029 
[epoch 14] step 22/44: loss=0.7085 
[epoch 14] step 24/44: loss=0.7116 
[epoch 14] step 26/44: loss=0.7134 
[epoch 14] step 28/44: loss=0.7126 
[epoch 14] step 30/44: loss=0.7112 
[epoch 14] step 32/44: loss=0.7121 
[epoch 14] step 34/44: loss=0.7098 
[epoch 14] step 36/44: loss=0.7061 
[epoch 14] step 38/44: loss=0.7038 
[epoch 14] step 40/44: loss=0.7011 
[epoch 14] step 42/44: loss=0.6993 
[epoch 14] step 44/44: loss=0.6979 
[epoch 14] train_loss(avg per step)=1.3958 lambda[min,max]=[0.452540,1.000000]
[epoch 14] val_loss=1.3868 qwk=('0.6044', '0.6335', '0.5734') averageQWK=0.6038 macroEMD=0.2824 tailR0=('0.1739', '0.0000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   19   35    1    0
     0   13   75   35    2
     0    0   36   73    7
     0    0    3   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   23   24    6    0
     0   16   71   35    0
     0    0   18  114    1
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   29   40    0    0
     0   15  108   29    0
     0    1   40   60    0
     0    0    1    1    0
[epoch 15] step 2/44: loss=0.7217 
[epoch 15] step 4/44: loss=0.7252 
[epoch 15] step 6/44: loss=0.7297 
[epoch 15] step 8/44: loss=0.7334 
[epoch 15] step 10/44: loss=0.7351 
[epoch 15] step 12/44: loss=0.7343 
[epoch 15] step 14/44: loss=0.7345 
[epoch 15] step 16/44: loss=0.7280 
[epoch 15] step 18/44: loss=0.7230 
[epoch 15] step 20/44: loss=0.7171 
[epoch 15] step 22/44: loss=0.7107 
[epoch 15] step 24/44: loss=0.7038 
[epoch 15] step 26/44: loss=0.6984 
[epoch 15] step 28/44: loss=0.6953 
[epoch 15] step 30/44: loss=0.6914 
[epoch 15] step 32/44: loss=0.6917 
[epoch 15] step 34/44: loss=0.6908 
[epoch 15] step 36/44: loss=0.6878 
[epoch 15] step 38/44: loss=0.6911 
[epoch 15] step 40/44: loss=0.6924 
[epoch 15] step 42/44: loss=0.6938 
[epoch 15] step 44/44: loss=0.6940 
[epoch 15] train_loss(avg per step)=1.3879 lambda[min,max]=[0.396332,1.000000]
[epoch 15] val_loss=1.4505 qwk=('0.5697', '0.5786', '0.5326') averageQWK=0.5603 macroEMD=0.2826 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   15   34    6    0
     0    8   72   45    0
     0    0   26   87    3
     0    0    2   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   16   31    6    0
     0    7   78   37    0
     0    1   20  110    2
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   19   50    0    0
     0    7  108   37    0
     0    0   38   63    0
     0    0    1    1    0
[epoch 16] step 2/44: loss=0.7909 
[epoch 16] step 4/44: loss=0.7625 
[epoch 16] step 6/44: loss=0.7439 
[epoch 16] step 8/44: loss=0.7366 
[epoch 16] step 10/44: loss=0.7255 
[epoch 16] step 12/44: loss=0.7148 
[epoch 16] step 14/44: loss=0.7089 
[epoch 16] step 16/44: loss=0.6995 
[epoch 16] step 18/44: loss=0.6966 
[epoch 16] step 20/44: loss=0.6934 
[epoch 16] step 22/44: loss=0.6920 
[epoch 16] step 24/44: loss=0.6917 
[epoch 16] step 26/44: loss=0.6886 
[epoch 16] step 28/44: loss=0.6881 
[epoch 16] step 30/44: loss=0.6877 
[epoch 16] step 32/44: loss=0.6866 
[epoch 16] step 34/44: loss=0.6852 
[epoch 16] step 36/44: loss=0.6855 
[epoch 16] step 38/44: loss=0.6844 
[epoch 16] step 40/44: loss=0.6849 
[epoch 16] step 42/44: loss=0.6840 
[epoch 16] step 44/44: loss=0.6833 
[epoch 16] train_loss(avg per step)=1.3666 lambda[min,max]=[0.409161,1.000000]
[epoch 16] val_loss=1.3252 qwk=('0.6173', '0.6013', '0.6046') averageQWK=0.6077 macroEMD=0.2855 tailR0=('0.1739', '0.0000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   20   33    2    0
     0   14   82   27    2
     0    0   35   74    7
     0    0    3   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   20   28    5    0
     0   17   71   34    0
     0    2   19  112    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   34   34    1    0
     0   18   99   35    0
     0    1   34   66    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=0.7057 
[epoch 17] step 4/44: loss=0.6955 
[epoch 17] step 6/44: loss=0.6925 
[epoch 17] step 8/44: loss=0.6853 
[epoch 17] step 10/44: loss=0.6790 
[epoch 17] step 12/44: loss=0.6749 
[epoch 17] step 14/44: loss=0.6622 
[epoch 17] step 16/44: loss=0.6610 
[epoch 17] step 18/44: loss=0.6625 
[epoch 17] step 20/44: loss=0.6673 
[epoch 17] step 22/44: loss=0.6648 
[epoch 17] step 24/44: loss=0.6675 
[epoch 17] step 26/44: loss=0.6716 
[epoch 17] step 28/44: loss=0.6719 
[epoch 17] step 30/44: loss=0.6697 
[epoch 17] step 32/44: loss=0.6688 
[epoch 17] step 34/44: loss=0.6703 
[epoch 17] step 36/44: loss=0.6697 
[epoch 17] step 38/44: loss=0.6699 
[epoch 17] step 40/44: loss=0.6691 
[epoch 17] step 42/44: loss=0.6683 
[epoch 17] step 44/44: loss=0.6677 
[epoch 17] train_loss(avg per step)=1.3354 lambda[min,max]=[0.395452,1.000000]
[epoch 17] val_loss=1.3228 qwk=('0.5825', '0.6082', '0.5364') averageQWK=0.5757 macroEMD=0.2855 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   17   33    5    0
     0    9   76   38    2
     0    0   27   80    9
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   23   23    7    0
     0   17   63   42    0
     0    2   13  115    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   26   43    0    0
     0   15  115   22    0
     0    1   46   54    0
     0    0    1    1    0
[epoch 18] step 2/44: loss=0.6646 
[epoch 18] step 4/44: loss=0.6708 
[epoch 18] step 6/44: loss=0.6711 
[epoch 18] step 8/44: loss=0.6574 
[epoch 18] step 10/44: loss=0.6629 
[epoch 18] step 12/44: loss=0.6548 
[epoch 18] step 14/44: loss=0.6521 
[epoch 18] step 16/44: loss=0.6521 
[epoch 18] step 18/44: loss=0.6546 
[epoch 18] step 20/44: loss=0.6531 
[epoch 18] step 22/44: loss=0.6561 
[epoch 18] step 24/44: loss=0.6544 
[epoch 18] step 26/44: loss=0.6610 
[epoch 18] step 28/44: loss=0.6570 
[epoch 18] step 30/44: loss=0.6541 
[epoch 18] step 32/44: loss=0.6523 
[epoch 18] step 34/44: loss=0.6529 
[epoch 18] step 36/44: loss=0.6524 
[epoch 18] step 38/44: loss=0.6518 
[epoch 18] step 40/44: loss=0.6502 
[epoch 18] step 42/44: loss=0.6522 
[epoch 18] step 44/44: loss=0.6531 
[epoch 18] train_loss(avg per step)=1.3061 lambda[min,max]=[0.410938,1.000000]
[epoch 18] val_loss=1.3418 qwk=('0.6210', '0.6073', '0.5853') averageQWK=0.6045 macroEMD=0.2877 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   29   23    3    0
     0   24   68   32    1
     0    0   40   69    7
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   25   24    4    0
     0   19   73   30    0
     0    2   28  100    3
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   37   32    0    0
     0   20  108   24    0
     0    2   41   58    0
     0    0    2    0    0
[epoch 19] step 2/44: loss=0.6444 
[epoch 19] step 4/44: loss=0.6671 
[epoch 19] step 6/44: loss=0.6681 
[epoch 19] step 8/44: loss=0.6598 
[epoch 19] step 10/44: loss=0.6574 
[epoch 19] step 12/44: loss=0.6550 
[epoch 19] step 14/44: loss=0.6533 
[epoch 19] step 16/44: loss=0.6481 
[epoch 19] step 18/44: loss=0.6473 
[epoch 19] step 20/44: loss=0.6467 
[epoch 19] step 22/44: loss=0.6460 
[epoch 19] step 24/44: loss=0.6422 
[epoch 19] step 26/44: loss=0.6441 
[epoch 19] step 28/44: loss=0.6431 
[epoch 19] step 30/44: loss=0.6417 
[epoch 19] step 32/44: loss=0.6428 
[epoch 19] step 34/44: loss=0.6448 
[epoch 19] step 36/44: loss=0.6450 
[epoch 19] step 38/44: loss=0.6455 
[epoch 19] step 40/44: loss=0.6449 
[epoch 19] step 42/44: loss=0.6462 
[epoch 19] step 44/44: loss=0.6464 
[epoch 19] train_loss(avg per step)=1.2929 lambda[min,max]=[0.390245,1.000000]
[epoch 19] val_loss=1.3058 qwk=('0.5533', '0.6050', '0.5885') averageQWK=0.5823 macroEMD=0.2893 tailR0=('0.0870', '0.0000', '0.0000') tailR0avg=0.0290
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   24   28    3    0
     0   20   77   26    2
     0    0   42   67    7
     0    0    8   11    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   26   19    8    0
     0   23   64   35    0
     0    3   19  109    2
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   34   35    0    0
     0   22  104   26    0
     0    1   43   57    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=0.6261 
[epoch 20] step 4/44: loss=0.6304 
[epoch 20] step 6/44: loss=0.6325 
[epoch 20] step 8/44: loss=0.6328 
[epoch 20] step 10/44: loss=0.6275 
[epoch 20] step 12/44: loss=0.6282 
[epoch 20] step 14/44: loss=0.6214 
[epoch 20] step 16/44: loss=0.6183 
[epoch 20] step 18/44: loss=0.6204 
[epoch 20] step 20/44: loss=0.6214 
[epoch 20] step 22/44: loss=0.6212 
[epoch 20] step 24/44: loss=0.6246 
[epoch 20] step 26/44: loss=0.6266 
[epoch 20] step 28/44: loss=0.6253 
[epoch 20] step 30/44: loss=0.6257 
[epoch 20] step 32/44: loss=0.6263 
[epoch 20] step 34/44: loss=0.6291 
[epoch 20] step 36/44: loss=0.6299 
[epoch 20] step 38/44: loss=0.6296 
[epoch 20] step 40/44: loss=0.6295 
[epoch 20] step 42/44: loss=0.6280 
[epoch 20] step 44/44: loss=0.6262 
[epoch 20] train_loss(avg per step)=1.2525 lambda[min,max]=[0.386170,1.000000]
[epoch 20] val_loss=1.2260 qwk=('0.5984', '0.5931', '0.5689') averageQWK=0.5868 macroEMD=0.2927 tailR0=('0.2174', '0.0000', '0.0000') tailR0avg=0.0725
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   20   32    3    0
     0   13   79   32    1
     1    0   34   68   13
     0    0    4    9   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     1   19   26    7    0
     0   10   75   36    1
     0    0   19  111    3
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   30   39    0    0
     0   18  105   29    0
     0    1   41   59    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=0.6326 
[epoch 21] step 4/44: loss=0.6288 
[epoch 21] step 6/44: loss=0.6254 
[epoch 21] step 8/44: loss=0.6179 
[epoch 21] step 10/44: loss=0.6055 
[epoch 21] step 12/44: loss=0.6118 
[epoch 21] step 14/44: loss=0.6072 
[epoch 21] step 16/44: loss=0.6106 
[epoch 21] step 18/44: loss=0.6180 
[epoch 21] step 20/44: loss=0.6211 
[epoch 21] step 22/44: loss=0.6251 
[epoch 21] step 24/44: loss=0.6266 
[epoch 21] step 26/44: loss=0.6247 
[epoch 21] step 28/44: loss=0.6246 
[epoch 21] step 30/44: loss=0.6272 
[epoch 21] step 32/44: loss=0.6279 
[epoch 21] step 34/44: loss=0.6268 
[epoch 21] step 36/44: loss=0.6234 
[epoch 21] step 38/44: loss=0.6218 
[epoch 21] step 40/44: loss=0.6213 
[epoch 21] step 42/44: loss=0.6208 
[epoch 21] step 44/44: loss=0.6181 
[epoch 21] train_loss(avg per step)=1.2362 lambda[min,max]=[0.361636,1.000000]
[epoch 21] val_loss=1.2561 qwk=('0.5648', '0.5929', '0.5813') averageQWK=0.5797 macroEMD=0.2868 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   17   34    4    0
     0   12   74   38    1
     0    0   33   78    5
     0    0    4   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   19   26    8    0
     0   11   69   42    0
     0    0   16  115    2
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   28   39    2    0
     0   10  107   35    0
     0    1   32   68    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=0.6376 
[epoch 22] step 4/44: loss=0.6463 
[epoch 22] step 6/44: loss=0.6231 
[epoch 22] step 8/44: loss=0.6224 
[epoch 22] step 10/44: loss=0.6241 
[epoch 22] step 12/44: loss=0.6239 
[epoch 22] step 14/44: loss=0.6228 
[epoch 22] step 16/44: loss=0.6252 
[epoch 22] step 18/44: loss=0.6232 
[epoch 22] step 20/44: loss=0.6216 
[epoch 22] step 22/44: loss=0.6241 
[epoch 22] step 24/44: loss=0.6199 
[epoch 22] step 26/44: loss=0.6180 
[epoch 22] step 28/44: loss=0.6173 
[epoch 22] step 30/44: loss=0.6167 
[epoch 22] step 32/44: loss=0.6152 
[epoch 22] step 34/44: loss=0.6120 
[epoch 22] step 36/44: loss=0.6095 
[epoch 22] step 38/44: loss=0.6097 
[epoch 22] step 40/44: loss=0.6098 
[epoch 22] step 42/44: loss=0.6099 
[epoch 22] step 44/44: loss=0.6115 
[epoch 22] train_loss(avg per step)=1.2230 lambda[min,max]=[0.343898,1.000000]
[epoch 22] val_loss=1.2698 qwk=('0.6098', '0.6153', '0.5699') averageQWK=0.5983 macroEMD=0.2874 tailR0=('0.1739', '0.0000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   23   28    4    0
     0   17   69   37    2
     0    0   29   80    7
     0    0    2   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   23   23    7    0
     0   14   69   39    0
     0    0   17  115    1
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   29   40    0    0
     0   13  115   24    0
     0    2   41   58    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=0.5975 
[epoch 23] step 4/44: loss=0.6370 
[epoch 23] step 6/44: loss=0.6498 
[epoch 23] step 8/44: loss=0.6474 
[epoch 23] step 10/44: loss=0.6441 
[epoch 23] step 12/44: loss=0.6363 
[epoch 23] step 14/44: loss=0.6309 
[epoch 23] step 16/44: loss=0.6212 
[epoch 23] step 18/44: loss=0.6171 
[epoch 23] step 20/44: loss=0.6146 
[epoch 23] step 22/44: loss=0.6108 
[epoch 23] step 24/44: loss=0.6059 
[epoch 23] step 26/44: loss=0.6039 
[epoch 23] step 28/44: loss=0.6012 
[epoch 23] step 30/44: loss=0.5999 
[epoch 23] step 32/44: loss=0.6009 
[epoch 23] step 34/44: loss=0.6034 
[epoch 23] step 36/44: loss=0.6037 
[epoch 23] step 38/44: loss=0.6036 
[epoch 23] step 40/44: loss=0.6064 
[epoch 23] step 42/44: loss=0.6052 
[epoch 23] step 44/44: loss=0.6037 
[epoch 23] train_loss(avg per step)=1.2074 lambda[min,max]=[0.374040,1.000000]
[epoch 23] val_loss=1.2190 qwk=('0.5824', '0.5924', '0.5326') averageQWK=0.5691 macroEMD=0.2966 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   22   29    4    0
     0   13   70   42    0
     0    0   30   83    3
     0    0    3   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     1   19   28    5    0
     0   12   76   34    0
     0    0   27  103    3
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   23   46    0    0
     0   11  117   24    0
     0    1   44   56    0
     0    0    1    1    0
[epoch 24] step 2/44: loss=0.5747 
[epoch 24] step 4/44: loss=0.6008 
[epoch 24] step 6/44: loss=0.6016 
[epoch 24] step 8/44: loss=0.6036 
[epoch 24] step 10/44: loss=0.6066 
[epoch 24] step 12/44: loss=0.6018 
[epoch 24] step 14/44: loss=0.5983 
[epoch 24] step 16/44: loss=0.5982 
[epoch 24] step 18/44: loss=0.6006 
[epoch 24] step 20/44: loss=0.6015 
[epoch 24] step 22/44: loss=0.6002 
[epoch 24] step 24/44: loss=0.5992 
[epoch 24] step 26/44: loss=0.5988 
[epoch 24] step 28/44: loss=0.5964 
[epoch 24] step 30/44: loss=0.5959 
[epoch 24] step 32/44: loss=0.5956 
[epoch 24] step 34/44: loss=0.5953 
[epoch 24] step 36/44: loss=0.5954 
[epoch 24] step 38/44: loss=0.5949 
[epoch 24] step 40/44: loss=0.5928 
[epoch 24] step 42/44: loss=0.5927 
[epoch 24] step 44/44: loss=0.5914 
[epoch 24] train_loss(avg per step)=1.1827 lambda[min,max]=[0.376151,1.000000]
[epoch 24] val_loss=1.1997 qwk=('0.6344', '0.6156', '0.5769') averageQWK=0.6090 macroEMD=0.2904 tailR0=('0.1739', '0.0000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   27   24    4    0
     0   20   69   35    1
     0    0   30   80    6
     0    0    2   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   26   18    9    0
     0   20   61   41    0
     0    2   15  115    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   31   38    0    0
     0   14  115   23    0
     0    1   42   58    0
     0    0    1    1    0
[epoch 25] step 2/44: loss=0.6084 
[epoch 25] step 4/44: loss=0.6087 
[epoch 25] step 6/44: loss=0.5913 
[epoch 25] step 8/44: loss=0.5981 
[epoch 25] step 10/44: loss=0.6098 
[epoch 25] step 12/44: loss=0.6124 
[epoch 25] step 14/44: loss=0.6107 
[epoch 25] step 16/44: loss=0.6057 
[epoch 25] step 18/44: loss=0.6025 
[epoch 25] step 20/44: loss=0.6010 
[epoch 25] step 22/44: loss=0.5973 
[epoch 25] step 24/44: loss=0.5940 
[epoch 25] step 26/44: loss=0.5962 
[epoch 25] step 28/44: loss=0.5952 
[epoch 25] step 30/44: loss=0.5948 
[epoch 25] step 32/44: loss=0.5945 
[epoch 25] step 34/44: loss=0.5928 
[epoch 25] step 36/44: loss=0.5914 
[epoch 25] step 38/44: loss=0.5925 
[epoch 25] step 40/44: loss=0.5963 
[epoch 25] step 42/44: loss=0.5982 
[epoch 25] step 44/44: loss=0.5993 
[epoch 25] train_loss(avg per step)=1.1986 lambda[min,max]=[0.368685,1.000000]
[epoch 25] val_loss=1.1979 qwk=('0.6041', '0.6298', '0.5679') averageQWK=0.6006 macroEMD=0.2915 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   20   30    5    0
     0   14   69   42    0
     0    0   25   86    5
     0    0    1   17    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   22   25    6    0
     0   14   68   40    0
     0    0   15  118    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   30   39    0    0
     0   12  114   26    0
     0    2   42   57    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=0.6270 
[epoch 26] step 4/44: loss=0.6036 
[epoch 26] step 6/44: loss=0.5962 
[epoch 26] step 8/44: loss=0.5844 
[epoch 26] step 10/44: loss=0.5878 
[epoch 26] step 12/44: loss=0.5801 
[epoch 26] step 14/44: loss=0.5850 
[epoch 26] step 16/44: loss=0.5818 
[epoch 26] step 18/44: loss=0.5856 
[epoch 26] step 20/44: loss=0.5849 
[epoch 26] step 22/44: loss=0.5833 
[epoch 26] step 24/44: loss=0.5823 
[epoch 26] step 26/44: loss=0.5821 
[epoch 26] step 28/44: loss=0.5824 
[epoch 26] step 30/44: loss=0.5837 
[epoch 26] step 32/44: loss=0.5838 
[epoch 26] step 34/44: loss=0.5828 
[epoch 26] step 36/44: loss=0.5833 
[epoch 26] step 38/44: loss=0.5828 
[epoch 26] step 40/44: loss=0.5830 
[epoch 26] step 42/44: loss=0.5842 
[epoch 26] step 44/44: loss=0.5845 
[epoch 26] train_loss(avg per step)=1.1690 lambda[min,max]=[0.372661,1.000000]
[epoch 26] val_loss=1.1708 qwk=('0.5673', '0.6119', '0.5782') averageQWK=0.5858 macroEMD=0.2949 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   24   28    3    0
     0   17   75   32    1
     0    1   41   69    5
     0    0    5   12    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   19   30    4    0
     0   11   74   37    0
     0    1   19  112    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   33   36    0    0
     0   18  111   23    0
     0    2   42   57    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=0.5604 
[epoch 27] step 4/44: loss=0.5715 
[epoch 27] step 6/44: loss=0.5774 
[epoch 27] step 8/44: loss=0.5865 
[epoch 27] step 10/44: loss=0.5911 
[epoch 27] step 12/44: loss=0.5835 
[epoch 27] step 14/44: loss=0.5792 
[epoch 27] step 16/44: loss=0.5790 
[epoch 27] step 18/44: loss=0.5761 
[epoch 27] step 20/44: loss=0.5745 
[epoch 27] step 22/44: loss=0.5766 
[epoch 27] step 24/44: loss=0.5741 
[epoch 27] step 26/44: loss=0.5687 
[epoch 27] step 28/44: loss=0.5674 
[epoch 27] step 30/44: loss=0.5680 
[epoch 27] step 32/44: loss=0.5698 
[epoch 27] step 34/44: loss=0.5710 
[epoch 27] step 36/44: loss=0.5733 
[epoch 27] step 38/44: loss=0.5732 
[epoch 27] step 40/44: loss=0.5762 
[epoch 27] step 42/44: loss=0.5759 
[epoch 27] step 44/44: loss=0.5759 
[epoch 27] train_loss(avg per step)=1.1518 lambda[min,max]=[0.379766,1.000000]
[epoch 27] val_loss=1.1982 qwk=('0.6001', '0.5821', '0.5896') averageQWK=0.5906 macroEMD=0.2912 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   23   29    3    0
     0   20   67   37    1
     0    0   28   80    8
     0    0    4   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   22   24    7    0
     0   15   65   42    0
     0    2   16  112    3
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   33   36    0    0
     0   16  111   25    0
     0    1   42   57    1
     0    0    0    2    0
[epoch 28] step 2/44: loss=0.5935 
[epoch 28] step 4/44: loss=0.5985 
[epoch 28] step 6/44: loss=0.6000 
[epoch 28] step 8/44: loss=0.6059 
[epoch 28] step 10/44: loss=0.6003 
[epoch 28] step 12/44: loss=0.5989 
[epoch 28] step 14/44: loss=0.6012 
[epoch 28] step 16/44: loss=0.5931 
[epoch 28] step 18/44: loss=0.5862 
[epoch 28] step 20/44: loss=0.5792 
[epoch 28] step 22/44: loss=0.5783 
[epoch 28] step 24/44: loss=0.5780 
[epoch 28] step 26/44: loss=0.5756 
[epoch 28] step 28/44: loss=0.5736 
[epoch 28] step 30/44: loss=0.5735 
[epoch 28] step 32/44: loss=0.5735 
[epoch 28] step 34/44: loss=0.5735 
[epoch 28] step 36/44: loss=0.5739 
[epoch 28] step 38/44: loss=0.5753 
[epoch 28] step 40/44: loss=0.5777 
[epoch 28] step 42/44: loss=0.5786 
[epoch 28] step 44/44: loss=0.5812 
[epoch 28] train_loss(avg per step)=1.1624 lambda[min,max]=[0.379421,1.000000]
[epoch 28] val_loss=1.1994 qwk=('0.6170', '0.6114', '0.5789') averageQWK=0.6024 macroEMD=0.2888 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   24   27    4    0
     0   20   65   40    0
     0    0   29   83    4
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   23   25    5    0
     0   15   67   40    0
     0    1   19  110    3
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   29   40    0    0
     0   14  113   25    0
     0    1   41   58    1
     0    0    0    2    0
[epoch 29] step 2/44: loss=0.5838 
[epoch 29] step 4/44: loss=0.6042 
[epoch 29] step 6/44: loss=0.5850 
[epoch 29] step 8/44: loss=0.5819 
[epoch 29] step 10/44: loss=0.5772 
[epoch 29] step 12/44: loss=0.5750 
[epoch 29] step 14/44: loss=0.5722 
[epoch 29] step 16/44: loss=0.5688 
[epoch 29] step 18/44: loss=0.5708 
[epoch 29] step 20/44: loss=0.5687 
[epoch 29] step 22/44: loss=0.5689 
[epoch 29] step 24/44: loss=0.5671 
[epoch 29] step 26/44: loss=0.5669 
[epoch 29] step 28/44: loss=0.5699 
[epoch 29] step 30/44: loss=0.5701 
[epoch 29] step 32/44: loss=0.5712 
[epoch 29] step 34/44: loss=0.5710 
[epoch 29] step 36/44: loss=0.5736 
[epoch 29] step 38/44: loss=0.5747 
[epoch 29] step 40/44: loss=0.5763 
[epoch 29] step 42/44: loss=0.5756 
[epoch 29] step 44/44: loss=0.5749 
[epoch 29] train_loss(avg per step)=1.1499 lambda[min,max]=[0.377859,1.000000]
[epoch 29] val_loss=1.1773 qwk=('0.6080', '0.6121', '0.6000') averageQWK=0.6067 macroEMD=0.2879 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   25   27    3    0
     0   20   70   35    0
     0    1   34   74    7
     0    0    3   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   23   25    5    0
     0   15   66   41    0
     1    1   15  113    3
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   36   33    0    0
     0   19  103   30    0
     0    2   36   63    0
     0    0    0    2    0
[epoch 30] step 2/44: loss=0.5560 
[epoch 30] step 4/44: loss=0.5890 
[epoch 30] step 6/44: loss=0.5812 
[epoch 30] step 8/44: loss=0.5707 
[epoch 30] step 10/44: loss=0.5633 
[epoch 30] step 12/44: loss=0.5550 
[epoch 30] step 14/44: loss=0.5560 
[epoch 30] step 16/44: loss=0.5539 
[epoch 30] step 18/44: loss=0.5549 
[epoch 30] step 20/44: loss=0.5544 
[epoch 30] step 22/44: loss=0.5589 
[epoch 30] step 24/44: loss=0.5618 
[epoch 30] step 26/44: loss=0.5659 
[epoch 30] step 28/44: loss=0.5660 
[epoch 30] step 30/44: loss=0.5648 
[epoch 30] step 32/44: loss=0.5644 
[epoch 30] step 34/44: loss=0.5652 
[epoch 30] step 36/44: loss=0.5669 
[epoch 30] step 38/44: loss=0.5671 
[epoch 30] step 40/44: loss=0.5682 
[epoch 30] step 42/44: loss=0.5680 
[epoch 30] step 44/44: loss=0.5672 
[epoch 30] train_loss(avg per step)=1.1344 lambda[min,max]=[0.376014,1.000000]
[epoch 30] val_loss=1.1671 qwk=('0.6114', '0.6224', '0.5871') averageQWK=0.6070 macroEMD=0.2927 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   23   29    3    0
     0   15   73   37    0
     0    0   33   78    5
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   24   24    5    0
     0   10   73   39    0
     0    0   19  113    1
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   37   32    0    0
     0   16  112   24    0
     0    2   42   57    0
     0    0    1    1    0
[epoch 31] step 2/44: loss=0.5585 
[epoch 31] step 4/44: loss=0.5675 
[epoch 31] step 6/44: loss=0.5614 
[epoch 31] step 8/44: loss=0.5657 
[epoch 31] step 10/44: loss=0.5680 
[epoch 31] step 12/44: loss=0.5679 
[epoch 31] step 14/44: loss=0.5685 
[epoch 31] step 16/44: loss=0.5697 
[epoch 31] step 18/44: loss=0.5676 
[epoch 31] step 20/44: loss=0.5680 
[epoch 31] step 22/44: loss=0.5662 
[epoch 31] step 24/44: loss=0.5655 
[epoch 31] step 26/44: loss=0.5665 
[epoch 31] step 28/44: loss=0.5656 
[epoch 31] step 30/44: loss=0.5657 
[epoch 31] step 32/44: loss=0.5633 
[epoch 31] step 34/44: loss=0.5623 
[epoch 31] step 36/44: loss=0.5615 
[epoch 31] step 38/44: loss=0.5635 
[epoch 31] step 40/44: loss=0.5647 
[epoch 31] step 42/44: loss=0.5656 
[epoch 31] step 44/44: loss=0.5666 
[epoch 31] train_loss(avg per step)=1.1332 lambda[min,max]=[0.368876,1.000000]
[epoch 31] val_loss=1.1600 qwk=('0.5885', '0.6165', '0.5855') averageQWK=0.5968 macroEMD=0.2916 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   23   29    3    0
     0   18   69   38    0
     0    0   35   75    6
     0    0    4   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   22   26    5    0
     0   14   69   39    0
     0    0   20  112    1
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   31   38    0    0
     0   14  110   28    0
     0    1   40   60    0
     0    0    0    2    0
[epoch 32] step 2/44: loss=0.5306 
[epoch 32] step 4/44: loss=0.5491 
[epoch 32] step 6/44: loss=0.5483 
[epoch 32] step 8/44: loss=0.5529 
[epoch 32] step 10/44: loss=0.5576 
[epoch 32] step 12/44: loss=0.5603 
[epoch 32] step 14/44: loss=0.5586 
[epoch 32] step 16/44: loss=0.5573 
[epoch 32] step 18/44: loss=0.5585 
[epoch 32] step 20/44: loss=0.5567 
[epoch 32] step 22/44: loss=0.5590 
[epoch 32] step 24/44: loss=0.5577 
[epoch 32] step 26/44: loss=0.5582 
[epoch 32] step 28/44: loss=0.5596 
[epoch 32] step 30/44: loss=0.5622 
[epoch 32] step 32/44: loss=0.5629 
[epoch 32] step 34/44: loss=0.5617 
[epoch 32] step 36/44: loss=0.5625 
[epoch 32] step 38/44: loss=0.5631 
[epoch 32] step 40/44: loss=0.5617 
[epoch 32] step 42/44: loss=0.5632 
[epoch 32] step 44/44: loss=0.5626 
[epoch 32] train_loss(avg per step)=1.1252 lambda[min,max]=[0.373729,1.000000]
[epoch 32] val_loss=1.1560 qwk=('0.5995', '0.6271', '0.5789') averageQWK=0.6018 macroEMD=0.2927 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   24   28    3    0
     0   20   67   38    0
     0    0   34   76    6
     0    0    3   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   24   23    6    0
     0   16   64   42    0
     0    2   16  114    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   31   38    0    0
     0   13  112   27    0
     0    1   40   60    0
     0    0    1    1    0
[epoch 33] step 2/44: loss=0.5679 
[epoch 33] step 4/44: loss=0.5596 
[epoch 33] step 6/44: loss=0.5592 
[epoch 33] step 8/44: loss=0.5562 
[epoch 33] step 10/44: loss=0.5613 
[epoch 33] step 12/44: loss=0.5629 
[epoch 33] step 14/44: loss=0.5608 
[epoch 33] step 16/44: loss=0.5635 
[epoch 33] step 18/44: loss=0.5633 
[epoch 33] step 20/44: loss=0.5638 
[epoch 33] step 22/44: loss=0.5616 
[epoch 33] step 24/44: loss=0.5614 
[epoch 33] step 26/44: loss=0.5605 
[epoch 33] step 28/44: loss=0.5575 
[epoch 33] step 30/44: loss=0.5579 
[epoch 33] step 32/44: loss=0.5573 
[epoch 33] step 34/44: loss=0.5595 
[epoch 33] step 36/44: loss=0.5582 
[epoch 33] step 38/44: loss=0.5583 
[epoch 33] step 40/44: loss=0.5563 
[epoch 33] step 42/44: loss=0.5562 
[epoch 33] step 44/44: loss=0.5554 
[epoch 33] train_loss(avg per step)=1.1108 lambda[min,max]=[0.378516,1.000000]
[epoch 33] val_loss=1.1483 qwk=('0.5909', '0.6220', '0.5644') averageQWK=0.5924 macroEMD=0.2948 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   22   30    3    0
     0   17   69   39    0
     0    0   35   74    7
     0    0    3   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   21   26    6    0
     0   12   69   41    0
     0    0   19  112    2
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   30   39    0    0
     0   13  113   26    0
     0    2   40   59    0
     0    0    1    1    0
[epoch 34] step 2/44: loss=0.5409 
[epoch 34] step 4/44: loss=0.5625 
[epoch 34] step 6/44: loss=0.5755 
[epoch 34] step 8/44: loss=0.5830 
[epoch 34] step 10/44: loss=0.5789 
[epoch 34] step 12/44: loss=0.5755 
[epoch 34] step 14/44: loss=0.5672 
[epoch 34] step 16/44: loss=0.5657 
[epoch 34] step 18/44: loss=0.5653 
[epoch 34] step 20/44: loss=0.5655 
[epoch 34] step 22/44: loss=0.5659 
[epoch 34] step 24/44: loss=0.5632 
[epoch 34] step 26/44: loss=0.5624 
[epoch 34] step 28/44: loss=0.5635 
[epoch 34] step 30/44: loss=0.5601 
[epoch 34] step 32/44: loss=0.5581 
[epoch 34] step 34/44: loss=0.5565 
[epoch 34] step 36/44: loss=0.5580 
[epoch 34] step 38/44: loss=0.5570 
[epoch 34] step 40/44: loss=0.5588 
[epoch 34] step 42/44: loss=0.5597 
[epoch 34] step 44/44: loss=0.5614 
[epoch 34] train_loss(avg per step)=1.1228 lambda[min,max]=[0.354107,1.000000]
[epoch 34] val_loss=1.1475 qwk=('0.6018', '0.6220', '0.5907') averageQWK=0.6049 macroEMD=0.2913 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   21   31    3    0
     0   15   71   39    0
     0    0   30   81    5
     0    0    3   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   21   26    6    0
     0   13   67   42    0
     0    0   18  114    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   33   36    0    0
     0   14  112   26    0
     0    2   39   60    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=0.5699 
[epoch 35] step 4/44: loss=0.5492 
[epoch 35] step 6/44: loss=0.5613 
[epoch 35] step 8/44: loss=0.5561 
[epoch 35] step 10/44: loss=0.5508 
[epoch 35] step 12/44: loss=0.5491 
[epoch 35] step 14/44: loss=0.5519 
[epoch 35] step 16/44: loss=0.5539 
[epoch 35] step 18/44: loss=0.5553 
[epoch 35] step 20/44: loss=0.5546 
[epoch 35] step 22/44: loss=0.5553 
[epoch 35] step 24/44: loss=0.5560 
[epoch 35] step 26/44: loss=0.5552 
[epoch 35] step 28/44: loss=0.5557 
[epoch 35] step 30/44: loss=0.5570 
[epoch 35] step 32/44: loss=0.5578 
[epoch 35] step 34/44: loss=0.5558 
[epoch 35] step 36/44: loss=0.5550 
[epoch 35] step 38/44: loss=0.5544 
[epoch 35] step 40/44: loss=0.5558 
[epoch 35] step 42/44: loss=0.5575 
[epoch 35] step 44/44: loss=0.5587 
[epoch 35] train_loss(avg per step)=1.1175 lambda[min,max]=[0.366720,1.000000]
[epoch 35] val_loss=1.1520 qwk=('0.5918', '0.6335', '0.5865') averageQWK=0.6039 macroEMD=0.2922 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   23   29    3    0
     0   17   69   39    0
     0    0   36   74    6
     0    0    3   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   22   26    5    0
     0   13   69   40    0
     0    0   19  112    2
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   30   39    0    0
     0   13  113   26    0
     0    1   40   60    0
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-1/fold5/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-1/fold5/metrics.json
Done.
