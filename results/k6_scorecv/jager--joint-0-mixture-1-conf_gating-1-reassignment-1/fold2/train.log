[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.5326 
[epoch 1] step 4/44: loss=0.5186 
[epoch 1] step 6/44: loss=0.5185 
[epoch 1] step 8/44: loss=0.5212 
[epoch 1] step 10/44: loss=0.5210 
[epoch 1] step 12/44: loss=0.5208 
[epoch 1] step 14/44: loss=0.5242 
[epoch 1] step 16/44: loss=0.5235 
[epoch 1] step 18/44: loss=0.5253 
[epoch 1] step 20/44: loss=0.5292 
[epoch 1] step 22/44: loss=0.5322 
[epoch 1] step 24/44: loss=0.5366 
[epoch 1] step 26/44: loss=0.5386 
[epoch 1] step 28/44: loss=0.5418 
[epoch 1] step 30/44: loss=0.5466 
[epoch 1] step 32/44: loss=0.5506 
[epoch 1] step 34/44: loss=0.5531 
[epoch 1] step 36/44: loss=0.5566 
[epoch 1] step 38/44: loss=0.5600 
[epoch 1] step 40/44: loss=0.5636 
[epoch 1] step 42/44: loss=0.5671 
[epoch 1] step 44/44: loss=0.5699 
[epoch 1] train_loss(avg per step)=1.1397 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=0.9781 qwk=('0.0774', '0.0483', '0.1871') averageQWK=0.1043 macroEMD=0.3733 tailR0=('0.0000', '0.0556', '0.2500') tailR0avg=0.1019
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    7    0
     0   19    0   35    0
     0   56    0   69    0
     0   37    2   77    0
     0    3    2   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    0    0
    22    0   30    1    0
    45    0   69    7    0
    46    0   76   11    0
     1    0    9    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   35   33    0    1
     0   61   79    8    3
     0   32   54   11    4
     0    0    0    1    1
[epoch 2] step 2/44: loss=0.6651 
[epoch 2] step 4/44: loss=0.6757 
[epoch 2] step 6/44: loss=0.6809 
[epoch 2] step 8/44: loss=0.6934 
[epoch 2] step 10/44: loss=0.7080 
[epoch 2] step 12/44: loss=0.7196 
[epoch 2] step 14/44: loss=0.7385 
[epoch 2] step 16/44: loss=0.7503 
[epoch 2] step 18/44: loss=0.7585 
[epoch 2] step 20/44: loss=0.7698 
[epoch 2] step 22/44: loss=0.7791 
[epoch 2] step 24/44: loss=0.7822 
[epoch 2] step 26/44: loss=0.7839 
[epoch 2] step 28/44: loss=0.7833 
[epoch 2] step 30/44: loss=0.7835 
[epoch 2] step 32/44: loss=0.7844 
[epoch 2] step 34/44: loss=0.7856 
[epoch 2] step 36/44: loss=0.7889 
[epoch 2] step 38/44: loss=0.7920 
[epoch 2] step 40/44: loss=0.7983 
[epoch 2] step 42/44: loss=0.8015 
[epoch 2] step 44/44: loss=0.8025 
[epoch 2] train_loss(avg per step)=1.6049 lambda[min,max]=[0.503588,1.000000]
[epoch 2] val_loss=1.5114 qwk=('0.3682', '0.3359', '0.3586') averageQWK=0.3542 macroEMD=0.3623 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   16   22   16    0
     0   19   41   65    0
     0    1   28   87    0
     0    3    3   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   53    0    0
     0    0  109   12    0
     0    0   78   55    0
     0    0    4    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   66    1    2    0
     0  128    1   22    0
     0   44    2   55    0
     0    0    1    1    0
[epoch 3] step 2/44: loss=0.7476 
[epoch 3] step 4/44: loss=0.7310 
[epoch 3] step 6/44: loss=0.7177 
[epoch 3] step 8/44: loss=0.7215 
[epoch 3] step 10/44: loss=0.7316 
[epoch 3] step 12/44: loss=0.7402 
[epoch 3] step 14/44: loss=0.7560 
[epoch 3] step 16/44: loss=0.7712 
[epoch 3] step 18/44: loss=0.7849 
[epoch 3] step 20/44: loss=0.7950 
[epoch 3] step 22/44: loss=0.8008 
[epoch 3] step 24/44: loss=0.8018 
[epoch 3] step 26/44: loss=0.7977 
[epoch 3] step 28/44: loss=0.7942 
[epoch 3] step 30/44: loss=0.7919 
[epoch 3] step 32/44: loss=0.7928 
[epoch 3] step 34/44: loss=0.7897 
[epoch 3] step 36/44: loss=0.7878 
[epoch 3] step 38/44: loss=0.7870 
[epoch 3] step 40/44: loss=0.7864 
[epoch 3] step 42/44: loss=0.7874 
[epoch 3] step 44/44: loss=0.7868 
[epoch 3] train_loss(avg per step)=1.5736 lambda[min,max]=[0.509634,1.000000]
[epoch 3] val_loss=1.4098 qwk=('0.5228', '0.3719', '0.5903') averageQWK=0.4950 macroEMD=0.3374 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   11   40    3    0
     0   15   92   18    0
     0    0   40   76    0
     0    1    4   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   34   19    0
     0    0   55   66    0
     0    0   11  122    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   51   18    0    0
     0   48   96    7    0
     0    6   46   49    0
     0    0    1    1    0
[epoch 4] step 2/44: loss=0.7517 
[epoch 4] step 4/44: loss=0.7609 
[epoch 4] step 6/44: loss=0.7623 
[epoch 4] step 8/44: loss=0.7606 
[epoch 4] step 10/44: loss=0.7631 
[epoch 4] step 12/44: loss=0.7739 
[epoch 4] step 14/44: loss=0.7805 
[epoch 4] step 16/44: loss=0.7894 
[epoch 4] step 18/44: loss=0.7975 
[epoch 4] step 20/44: loss=0.8057 
[epoch 4] step 22/44: loss=0.8129 
[epoch 4] step 24/44: loss=0.8128 
[epoch 4] step 26/44: loss=0.8163 
[epoch 4] step 28/44: loss=0.8163 
[epoch 4] step 30/44: loss=0.8170 
[epoch 4] step 32/44: loss=0.8181 
[epoch 4] step 34/44: loss=0.8191 
[epoch 4] step 36/44: loss=0.8167 
[epoch 4] step 38/44: loss=0.8141 
[epoch 4] step 40/44: loss=0.8131 
[epoch 4] step 42/44: loss=0.8134 
[epoch 4] step 44/44: loss=0.8152 
[epoch 4] train_loss(avg per step)=1.6305 lambda[min,max]=[0.500658,1.000000]
[epoch 4] val_loss=1.4472 qwk=('0.5420', '0.4068', '0.4315') averageQWK=0.4601 macroEMD=0.3144 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    0    0
     0    6   43    5    0
     0    5   72   48    0
     0    0   16  100    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    0
     0    4   30   19    0
     0    5   51   65    0
     0    0   10  123    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    3   63    3    0
     0    1  119   31    0
     0    0   35   66    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=0.8599 
[epoch 5] step 4/44: loss=0.8507 
[epoch 5] step 6/44: loss=0.8579 
[epoch 5] step 8/44: loss=0.8552 
[epoch 5] step 10/44: loss=0.8499 
[epoch 5] step 12/44: loss=0.8442 
[epoch 5] step 14/44: loss=0.8348 
[epoch 5] step 16/44: loss=0.8296 
[epoch 5] step 18/44: loss=0.8237 
[epoch 5] step 20/44: loss=0.8188 
[epoch 5] step 22/44: loss=0.8156 
[epoch 5] step 24/44: loss=0.8189 
[epoch 5] step 26/44: loss=0.8207 
[epoch 5] step 28/44: loss=0.8246 
[epoch 5] step 30/44: loss=0.8275 
[epoch 5] step 32/44: loss=0.8315 
[epoch 5] step 34/44: loss=0.8330 
[epoch 5] step 36/44: loss=0.8354 
[epoch 5] step 38/44: loss=0.8373 
[epoch 5] step 40/44: loss=0.8386 
[epoch 5] step 42/44: loss=0.8385 
[epoch 5] step 44/44: loss=0.8347 
[epoch 5] train_loss(avg per step)=1.6693 lambda[min,max]=[0.500032,1.000000]
[epoch 5] val_loss=1.4676 qwk=('0.5427', '0.5141', '0.5732') averageQWK=0.5433 macroEMD=0.3039 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   14   29   11    0
     0    9   49   67    0
     0    0    6  110    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   11   29   13    0
     0    8   61   52    0
     0    0   13  120    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   21   48    0    0
     0    7  122   22    0
     0    1   40   60    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=0.8213 
[epoch 6] step 4/44: loss=0.7955 
[epoch 6] step 6/44: loss=0.7965 
[epoch 6] step 8/44: loss=0.7894 
[epoch 6] step 10/44: loss=0.7802 
[epoch 6] step 12/44: loss=0.7753 
[epoch 6] step 14/44: loss=0.7756 
[epoch 6] step 16/44: loss=0.7781 
[epoch 6] step 18/44: loss=0.7793 
[epoch 6] step 20/44: loss=0.7845 
[epoch 6] step 22/44: loss=0.7888 
[epoch 6] step 24/44: loss=0.7922 
[epoch 6] step 26/44: loss=0.7985 
[epoch 6] step 28/44: loss=0.8016 
[epoch 6] step 30/44: loss=0.8036 
[epoch 6] step 32/44: loss=0.8042 
[epoch 6] step 34/44: loss=0.8033 
[epoch 6] step 36/44: loss=0.8006 
[epoch 6] step 38/44: loss=0.8012 
[epoch 6] step 40/44: loss=0.8013 
[epoch 6] step 42/44: loss=0.8009 
[epoch 6] step 44/44: loss=0.7998 
[epoch 6] train_loss(avg per step)=1.5996 lambda[min,max]=[0.500002,1.000000]
[epoch 6] val_loss=1.4097 qwk=('0.5511', '0.4824', '0.5230') averageQWK=0.5188 macroEMD=0.2926 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    0    0
     0    7   45    2    0
     0    4   84   36    1
     0    0   28   88    0
     0    0    2   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    4   38   11    0
     0    1   77   43    0
     0    0   15  118    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   13   54    2    0
     0    2  119   30    0
     0    1   29   71    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=0.8236 
[epoch 7] step 4/44: loss=0.8368 
[epoch 7] step 6/44: loss=0.8276 
[epoch 7] step 8/44: loss=0.8075 
[epoch 7] step 10/44: loss=0.8021 
[epoch 7] step 12/44: loss=0.7959 
[epoch 7] step 14/44: loss=0.7896 
[epoch 7] step 16/44: loss=0.7920 
[epoch 7] step 18/44: loss=0.7891 
[epoch 7] step 20/44: loss=0.7855 
[epoch 7] step 22/44: loss=0.7848 
[epoch 7] step 24/44: loss=0.7859 
[epoch 7] step 26/44: loss=0.7896 
[epoch 7] step 28/44: loss=0.7954 
[epoch 7] step 30/44: loss=0.7978 
[epoch 7] step 32/44: loss=0.8001 
[epoch 7] step 34/44: loss=0.7991 
[epoch 7] step 36/44: loss=0.7978 
[epoch 7] step 38/44: loss=0.7977 
[epoch 7] step 40/44: loss=0.7979 
[epoch 7] step 42/44: loss=0.7987 
[epoch 7] step 44/44: loss=0.7978 
[epoch 7] train_loss(avg per step)=1.5956 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.4316 qwk=('0.6199', '0.5710', '0.5767') averageQWK=0.5892 macroEMD=0.2866 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   17   36    1    0
     0   14   89   22    0
     0    0   35   81    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   14   36    3    0
     0   11   89   21    0
     0    1   39   93    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   46   23    0    0
     0   38  101   12    0
     0    5   46   50    0
     0    0    2    0    0
[epoch 8] step 2/44: loss=0.8018 
[epoch 8] step 4/44: loss=0.8013 
[epoch 8] step 6/44: loss=0.8063 
[epoch 8] step 8/44: loss=0.7969 
[epoch 8] step 10/44: loss=0.7817 
[epoch 8] step 12/44: loss=0.7800 
[epoch 8] step 14/44: loss=0.7802 
[epoch 8] step 16/44: loss=0.7741 
[epoch 8] step 18/44: loss=0.7734 
[epoch 8] step 20/44: loss=0.7699 
[epoch 8] step 22/44: loss=0.7728 
[epoch 8] step 24/44: loss=0.7742 
[epoch 8] step 26/44: loss=0.7796 
[epoch 8] step 28/44: loss=0.7835 
[epoch 8] step 30/44: loss=0.7867 
[epoch 8] step 32/44: loss=0.7849 
[epoch 8] step 34/44: loss=0.7854 
[epoch 8] step 36/44: loss=0.7855 
[epoch 8] step 38/44: loss=0.7862 
[epoch 8] step 40/44: loss=0.7855 
[epoch 8] step 42/44: loss=0.7850 
[epoch 8] step 44/44: loss=0.7846 
[epoch 8] train_loss(avg per step)=1.5692 lambda[min,max]=[0.472877,1.000000]
[epoch 8] val_loss=1.4146 qwk=('0.5780', '0.5594', '0.6374') averageQWK=0.5916 macroEMD=0.2790 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   11   38    5    0
     0   11   66   48    0
     0    0   15  101    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0    9   38    6    0
     0    5   74   42    0
     0    1   22  110    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   40   28    1    0
     0   22  106   23    0
     0    4   30   67    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=0.7402 
[epoch 9] step 4/44: loss=0.7612 
[epoch 9] step 6/44: loss=0.7525 
[epoch 9] step 8/44: loss=0.7540 
[epoch 9] step 10/44: loss=0.7567 
[epoch 9] step 12/44: loss=0.7531 
[epoch 9] step 14/44: loss=0.7522 
[epoch 9] step 16/44: loss=0.7523 
[epoch 9] step 18/44: loss=0.7520 
[epoch 9] step 20/44: loss=0.7524 
[epoch 9] step 22/44: loss=0.7544 
[epoch 9] step 24/44: loss=0.7551 
[epoch 9] step 26/44: loss=0.7546 
[epoch 9] step 28/44: loss=0.7580 
[epoch 9] step 30/44: loss=0.7601 
[epoch 9] step 32/44: loss=0.7605 
[epoch 9] step 34/44: loss=0.7600 
[epoch 9] step 36/44: loss=0.7578 
[epoch 9] step 38/44: loss=0.7579 
[epoch 9] step 40/44: loss=0.7583 
[epoch 9] step 42/44: loss=0.7600 
[epoch 9] step 44/44: loss=0.7586 
[epoch 9] train_loss(avg per step)=1.5173 lambda[min,max]=[0.487850,1.000000]
[epoch 9] val_loss=1.4061 qwk=('0.6559', '0.6027', '0.6410') averageQWK=0.6332 macroEMD=0.2780 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    1    0    0
     0   22   32    0    0
     0   23   72   30    0
     0    0   32   84    0
     0    0    1   21    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   21   27    5    0
     0   23   73   25    0
     0    2   30  101    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   42   27    0    0
     0   23  111   17    0
     0    2   42   57    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=0.7659 
[epoch 10] step 4/44: loss=0.7750 
[epoch 10] step 6/44: loss=0.7869 
[epoch 10] step 8/44: loss=0.7936 
[epoch 10] step 10/44: loss=0.7892 
[epoch 10] step 12/44: loss=0.7880 
[epoch 10] step 14/44: loss=0.7871 
[epoch 10] step 16/44: loss=0.7824 
[epoch 10] step 18/44: loss=0.7710 
[epoch 10] step 20/44: loss=0.7668 
[epoch 10] step 22/44: loss=0.7611 
[epoch 10] step 24/44: loss=0.7595 
[epoch 10] step 26/44: loss=0.7579 
[epoch 10] step 28/44: loss=0.7586 
[epoch 10] step 30/44: loss=0.7598 
[epoch 10] step 32/44: loss=0.7594 
[epoch 10] step 34/44: loss=0.7601 
[epoch 10] step 36/44: loss=0.7620 
[epoch 10] step 38/44: loss=0.7613 
[epoch 10] step 40/44: loss=0.7616 
[epoch 10] step 42/44: loss=0.7600 
[epoch 10] step 44/44: loss=0.7586 
[epoch 10] train_loss(avg per step)=1.5172 lambda[min,max]=[0.469437,1.000000]
[epoch 10] val_loss=1.4340 qwk=('0.5569', '0.5349', '0.5368') averageQWK=0.5429 macroEMD=0.2835 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0    8   35   11    0
     0   10   61   52    2
     0    0   12  103    1
     0    0    0   18    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0    8   36    9    0
     1    4   72   44    0
     0    1   16  116    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   21   41    7    0
     0    8   84   59    0
     0    0   16   85    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.7419 
[epoch 11] step 4/44: loss=0.7445 
[epoch 11] step 6/44: loss=0.7308 
[epoch 11] step 8/44: loss=0.7145 
[epoch 11] step 10/44: loss=0.7128 
[epoch 11] step 12/44: loss=0.7147 
[epoch 11] step 14/44: loss=0.7155 
[epoch 11] step 16/44: loss=0.7190 
[epoch 11] step 18/44: loss=0.7184 
[epoch 11] step 20/44: loss=0.7188 
[epoch 11] step 22/44: loss=0.7225 
[epoch 11] step 24/44: loss=0.7266 
[epoch 11] step 26/44: loss=0.7278 
[epoch 11] step 28/44: loss=0.7296 
[epoch 11] step 30/44: loss=0.7301 
[epoch 11] step 32/44: loss=0.7302 
[epoch 11] step 34/44: loss=0.7334 
[epoch 11] step 36/44: loss=0.7335 
[epoch 11] step 38/44: loss=0.7331 
[epoch 11] step 40/44: loss=0.7334 
[epoch 11] step 42/44: loss=0.7334 
[epoch 11] step 44/44: loss=0.7328 
[epoch 11] train_loss(avg per step)=1.4656 lambda[min,max]=[0.467685,1.000000]
[epoch 11] val_loss=1.3874 qwk=('0.5642', '0.5317', '0.6278') averageQWK=0.5745 macroEMD=0.2813 tailR0=('0.1739', '0.0000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0    6   48    0    0
     0    7   93   19    6
     0    0   38   71    7
     0    0    5   10    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   10   32   10    0
     1   11   62   47    0
     0    1   19  113    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   33   36    0    0
     0   23  106   22    0
     0    1   36   64    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=0.7293 
[epoch 12] step 4/44: loss=0.7331 
[epoch 12] step 6/44: loss=0.7267 
[epoch 12] step 8/44: loss=0.7304 
[epoch 12] step 10/44: loss=0.7332 
[epoch 12] step 12/44: loss=0.7292 
[epoch 12] step 14/44: loss=0.7321 
[epoch 12] step 16/44: loss=0.7317 
[epoch 12] step 18/44: loss=0.7287 
[epoch 12] step 20/44: loss=0.7236 
[epoch 12] step 22/44: loss=0.7259 
[epoch 12] step 24/44: loss=0.7288 
[epoch 12] step 26/44: loss=0.7292 
[epoch 12] step 28/44: loss=0.7266 
[epoch 12] step 30/44: loss=0.7281 
[epoch 12] step 32/44: loss=0.7280 
[epoch 12] step 34/44: loss=0.7278 
[epoch 12] step 36/44: loss=0.7286 
[epoch 12] step 38/44: loss=0.7277 
[epoch 12] step 40/44: loss=0.7265 
[epoch 12] step 42/44: loss=0.7253 
[epoch 12] step 44/44: loss=0.7237 
[epoch 12] train_loss(avg per step)=1.4475 lambda[min,max]=[0.436191,1.000000]
[epoch 12] val_loss=1.4175 qwk=('0.5783', '0.5640', '0.6336') averageQWK=0.5920 macroEMD=0.2860 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0    8   44    2    0
     0    7   90   24    4
     0    0   35   74    7
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   13   33    5    1
     1   14   69   37    0
     0    2   21  110    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   39   30    0    0
     0   19  102   30    0
     0    4   27   70    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.7061 
[epoch 13] step 4/44: loss=0.7049 
[epoch 13] step 6/44: loss=0.7136 
[epoch 13] step 8/44: loss=0.7181 
[epoch 13] step 10/44: loss=0.7224 
[epoch 13] step 12/44: loss=0.7323 
[epoch 13] step 14/44: loss=0.7407 
[epoch 13] step 16/44: loss=0.7361 
[epoch 13] step 18/44: loss=0.7329 
[epoch 13] step 20/44: loss=0.7309 
[epoch 13] step 22/44: loss=0.7327 
[epoch 13] step 24/44: loss=0.7314 
[epoch 13] step 26/44: loss=0.7329 
[epoch 13] step 28/44: loss=0.7274 
[epoch 13] step 30/44: loss=0.7235 
[epoch 13] step 32/44: loss=0.7195 
[epoch 13] step 34/44: loss=0.7148 
[epoch 13] step 36/44: loss=0.7123 
[epoch 13] step 38/44: loss=0.7085 
[epoch 13] step 40/44: loss=0.7077 
[epoch 13] step 42/44: loss=0.7086 
[epoch 13] step 44/44: loss=0.7096 
[epoch 13] train_loss(avg per step)=1.4192 lambda[min,max]=[0.428996,1.000000]
[epoch 13] val_loss=1.4233 qwk=('0.6359', '0.5732', '0.6034') averageQWK=0.6042 macroEMD=0.2839 tailR0=('0.0217', '0.0833', '0.0000') tailR0avg=0.0350
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    1    0    0
     0   22   31    1    0
     0   20   83   20    2
     0    0   35   80    1
     0    0    3   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     1   16   34    1    1
     1   23   86   11    0
     0    1   50   81    1
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   50   19    0    0
     0   37  103   11    0
     0    4   47   50    0
     0    0    2    0    0
[epoch 14] step 2/44: loss=0.7591 
[epoch 14] step 4/44: loss=0.7551 
[epoch 14] step 6/44: loss=0.7426 
[epoch 14] step 8/44: loss=0.7433 
[epoch 14] step 10/44: loss=0.7513 
[epoch 14] step 12/44: loss=0.7562 
[epoch 14] step 14/44: loss=0.7458 
[epoch 14] step 16/44: loss=0.7399 
[epoch 14] step 18/44: loss=0.7285 
[epoch 14] step 20/44: loss=0.7189 
[epoch 14] step 22/44: loss=0.7169 
[epoch 14] step 24/44: loss=0.7155 
[epoch 14] step 26/44: loss=0.7144 
[epoch 14] step 28/44: loss=0.7121 
[epoch 14] step 30/44: loss=0.7108 
[epoch 14] step 32/44: loss=0.7102 
[epoch 14] step 34/44: loss=0.7096 
[epoch 14] step 36/44: loss=0.7095 
[epoch 14] step 38/44: loss=0.7081 
[epoch 14] step 40/44: loss=0.7086 
[epoch 14] step 42/44: loss=0.7097 
[epoch 14] step 44/44: loss=0.7092 
[epoch 14] train_loss(avg per step)=1.4184 lambda[min,max]=[0.436763,1.000000]
[epoch 14] val_loss=1.4363 qwk=('0.6605', '0.5725', '0.6520') averageQWK=0.6283 macroEMD=0.2814 tailR0=('0.2609', '0.1389', '0.0000') tailR0avg=0.1333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    1    0    0
     1   19   32    2    0
     0   23   63   34    5
     0    0   23   83   10
     0    0    1   10   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     2   19   28    3    1
     1   20   68   31    1
     0    5   27   95    6
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   37   32    0    0
     0   21  113   17    0
     0    2   32   67    0
     0    0    1    1    0
[epoch 15] step 2/44: loss=0.6980 
[epoch 15] step 4/44: loss=0.6886 
[epoch 15] step 6/44: loss=0.6859 
[epoch 15] step 8/44: loss=0.6895 
[epoch 15] step 10/44: loss=0.6974 
[epoch 15] step 12/44: loss=0.6934 
[epoch 15] step 14/44: loss=0.6896 
[epoch 15] step 16/44: loss=0.6914 
[epoch 15] step 18/44: loss=0.6881 
[epoch 15] step 20/44: loss=0.6859 
[epoch 15] step 22/44: loss=0.6880 
[epoch 15] step 24/44: loss=0.6853 
[epoch 15] step 26/44: loss=0.6848 
[epoch 15] step 28/44: loss=0.6845 
[epoch 15] step 30/44: loss=0.6845 
[epoch 15] step 32/44: loss=0.6840 
[epoch 15] step 34/44: loss=0.6849 
[epoch 15] step 36/44: loss=0.6850 
[epoch 15] step 38/44: loss=0.6840 
[epoch 15] step 40/44: loss=0.6825 
[epoch 15] step 42/44: loss=0.6817 
[epoch 15] step 44/44: loss=0.6814 
[epoch 15] train_loss(avg per step)=1.3627 lambda[min,max]=[0.437535,1.000000]
[epoch 15] val_loss=1.4541 qwk=('0.6195', '0.5997', '0.6377') averageQWK=0.6190 macroEMD=0.2877 tailR0=('0.1522', '0.1389', '0.0000') tailR0avg=0.0970
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    0    0    0
     1   25   25    3    0
     0   39   55   27    4
     0    4   26   79    7
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    1    0    0
     1   25   24    2    1
     0   31   73   15    2
     0    3   47   78    5
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   42   27    0    0
     0   27  104   20    0
     0    4   31   66    0
     0    0    1    1    0
[epoch 16] step 2/44: loss=0.6535 
[epoch 16] step 4/44: loss=0.6621 
[epoch 16] step 6/44: loss=0.6591 
[epoch 16] step 8/44: loss=0.6610 
[epoch 16] step 10/44: loss=0.6594 
[epoch 16] step 12/44: loss=0.6590 
[epoch 16] step 14/44: loss=0.6606 
[epoch 16] step 16/44: loss=0.6597 
[epoch 16] step 18/44: loss=0.6595 
[epoch 16] step 20/44: loss=0.6590 
[epoch 16] step 22/44: loss=0.6568 
[epoch 16] step 24/44: loss=0.6546 
[epoch 16] step 26/44: loss=0.6547 
[epoch 16] step 28/44: loss=0.6563 
[epoch 16] step 30/44: loss=0.6583 
[epoch 16] step 32/44: loss=0.6598 
[epoch 16] step 34/44: loss=0.6621 
[epoch 16] step 36/44: loss=0.6652 
[epoch 16] step 38/44: loss=0.6651 
[epoch 16] step 40/44: loss=0.6668 
[epoch 16] step 42/44: loss=0.6664 
[epoch 16] step 44/44: loss=0.6653 
[epoch 16] train_loss(avg per step)=1.3307 lambda[min,max]=[0.390091,1.000000]
[epoch 16] val_loss=1.4021 qwk=('0.5908', '0.5481', '0.6069') averageQWK=0.5820 macroEMD=0.2882 tailR0=('0.0717', '0.1389', '0.0000') tailR0avg=0.0702
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    3    0    0
     0   10   39    5    0
     0   11   75   38    1
     0    0   23   92    1
     0    0    0   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     0    8   41    3    1
     0    8   85   26    2
     0    1   34   95    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   38    0    0
     0   21  105   25    0
     0    2   33   66    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=0.6646 
[epoch 17] step 4/44: loss=0.6572 
[epoch 17] step 6/44: loss=0.6393 
[epoch 17] step 8/44: loss=0.6369 
[epoch 17] step 10/44: loss=0.6401 
[epoch 17] step 12/44: loss=0.6422 
[epoch 17] step 14/44: loss=0.6507 
[epoch 17] step 16/44: loss=0.6541 
[epoch 17] step 18/44: loss=0.6530 
[epoch 17] step 20/44: loss=0.6470 
[epoch 17] step 22/44: loss=0.6479 
[epoch 17] step 24/44: loss=0.6485 
[epoch 17] step 26/44: loss=0.6454 
[epoch 17] step 28/44: loss=0.6480 
[epoch 17] step 30/44: loss=0.6460 
[epoch 17] step 32/44: loss=0.6490 
[epoch 17] step 34/44: loss=0.6480 
[epoch 17] step 36/44: loss=0.6451 
[epoch 17] step 38/44: loss=0.6446 
[epoch 17] step 40/44: loss=0.6435 
[epoch 17] step 42/44: loss=0.6445 
[epoch 17] step 44/44: loss=0.6438 
[epoch 17] train_loss(avg per step)=1.2876 lambda[min,max]=[0.387126,1.000000]
[epoch 17] val_loss=1.3975 qwk=('0.6010', '0.5574', '0.6419') averageQWK=0.6001 macroEMD=0.2892 tailR0=('0.1152', '0.0972', '0.1000') tailR0avg=0.1041
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    2    0    0
     2   14   37    1    0
     3   11   78   28    5
     0    0   31   83    2
     0    0    2   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     4   12   33    3    1
     2   17   75   26    1
     0    1   39   91    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   43   26    0    0
     0   27  103   21    0
     0    2   38   61    0
     0    0    1    1    0
[epoch 18] step 2/44: loss=0.5869 
[epoch 18] step 4/44: loss=0.6084 
[epoch 18] step 6/44: loss=0.6135 
[epoch 18] step 8/44: loss=0.6215 
[epoch 18] step 10/44: loss=0.6282 
[epoch 18] step 12/44: loss=0.6344 
[epoch 18] step 14/44: loss=0.6363 
[epoch 18] step 16/44: loss=0.6385 
[epoch 18] step 18/44: loss=0.6383 
[epoch 18] step 20/44: loss=0.6372 
[epoch 18] step 22/44: loss=0.6375 
[epoch 18] step 24/44: loss=0.6366 
[epoch 18] step 26/44: loss=0.6346 
[epoch 18] step 28/44: loss=0.6314 
[epoch 18] step 30/44: loss=0.6316 
[epoch 18] step 32/44: loss=0.6312 
[epoch 18] step 34/44: loss=0.6342 
[epoch 18] step 36/44: loss=0.6357 
[epoch 18] step 38/44: loss=0.6386 
[epoch 18] step 40/44: loss=0.6387 
[epoch 18] step 42/44: loss=0.6373 
[epoch 18] step 44/44: loss=0.6354 
[epoch 18] train_loss(avg per step)=1.2708 lambda[min,max]=[0.371218,1.000000]
[epoch 18] val_loss=1.4041 qwk=('0.6041', '0.5664', '0.6294') averageQWK=0.6000 macroEMD=0.2903 tailR0=('0.2522', '0.0972', '0.1000') tailR0avg=0.1498
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    3    0    0
     1   16   35    2    0
     0   15   78   28    4
     0    0   32   78    6
     0    0    5   11    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     3   13   33    3    1
     1   11   76   31    2
     0    1   36   94    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   38   30    1    0
     0   23  100   28    0
     0    2   32   67    0
     0    0    1    1    0
[epoch 19] step 2/44: loss=0.6673 
[epoch 19] step 4/44: loss=0.6598 
[epoch 19] step 6/44: loss=0.6573 
[epoch 19] step 8/44: loss=0.6437 
[epoch 19] step 10/44: loss=0.6392 
[epoch 19] step 12/44: loss=0.6396 
[epoch 19] step 14/44: loss=0.6313 
[epoch 19] step 16/44: loss=0.6230 
[epoch 19] step 18/44: loss=0.6189 
[epoch 19] step 20/44: loss=0.6191 
[epoch 19] step 22/44: loss=0.6206 
[epoch 19] step 24/44: loss=0.6253 
[epoch 19] step 26/44: loss=0.6295 
[epoch 19] step 28/44: loss=0.6272 
[epoch 19] step 30/44: loss=0.6257 
[epoch 19] step 32/44: loss=0.6252 
[epoch 19] step 34/44: loss=0.6231 
[epoch 19] step 36/44: loss=0.6223 
[epoch 19] step 38/44: loss=0.6251 
[epoch 19] step 40/44: loss=0.6257 
[epoch 19] step 42/44: loss=0.6260 
[epoch 19] step 44/44: loss=0.6241 
[epoch 19] train_loss(avg per step)=1.2482 lambda[min,max]=[0.342703,1.000000]
[epoch 19] val_loss=1.3836 qwk=('0.6320', '0.5748', '0.6250') averageQWK=0.6106 macroEMD=0.2859 tailR0=('0.2152', '0.1111', '0.2000') tailR0avg=0.1754
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    3    0    0
     2   12   37    3    0
     1   11   84   29    0
     0    0   30   84    2
     0    0    1   19    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     4   11   31    7    0
     2   10   65   44    0
     0    1   26  106    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   34   34    1    0
     0   22  107   22    0
     0    1   37   63    0
     0    0    1    1    0
[epoch 20] step 2/44: loss=0.6464 
[epoch 20] step 4/44: loss=0.6399 
[epoch 20] step 6/44: loss=0.6261 
[epoch 20] step 8/44: loss=0.6231 
[epoch 20] step 10/44: loss=0.6138 
[epoch 20] step 12/44: loss=0.6067 
[epoch 20] step 14/44: loss=0.5998 
[epoch 20] step 16/44: loss=0.5950 
[epoch 20] step 18/44: loss=0.5960 
[epoch 20] step 20/44: loss=0.5878 
[epoch 20] step 22/44: loss=0.5894 
[epoch 20] step 24/44: loss=0.5904 
[epoch 20] step 26/44: loss=0.5922 
[epoch 20] step 28/44: loss=0.5959 
[epoch 20] step 30/44: loss=0.5987 
[epoch 20] step 32/44: loss=0.5985 
[epoch 20] step 34/44: loss=0.6008 
[epoch 20] step 36/44: loss=0.6027 
[epoch 20] step 38/44: loss=0.6039 
[epoch 20] step 40/44: loss=0.6044 
[epoch 20] step 42/44: loss=0.6043 
[epoch 20] step 44/44: loss=0.6083 
[epoch 20] train_loss(avg per step)=1.2167 lambda[min,max]=[0.361729,1.000000]
[epoch 20] val_loss=1.4059 qwk=('0.6091', '0.5574', '0.6351') averageQWK=0.6005 macroEMD=0.2891 tailR0=('0.1217', '0.0556', '0.2000') tailR0avg=0.1258
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    8    0    0    0
     1   16   31    6    0
     0   20   64   39    2
     0    1   23   90    2
     0    0    1   21    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     1   15   32    5    0
     2   18   71   28    2
     0    2   30  100    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   32   37    0    0
     0   24   95   32    0
     0    1   28   72    0
     0    0    1    1    0
[epoch 21] step 2/44: loss=0.5815 
[epoch 21] step 4/44: loss=0.5824 
[epoch 21] step 6/44: loss=0.5844 
[epoch 21] step 8/44: loss=0.5800 
[epoch 21] step 10/44: loss=0.5813 
[epoch 21] step 12/44: loss=0.5902 
[epoch 21] step 14/44: loss=0.5930 
[epoch 21] step 16/44: loss=0.5957 
[epoch 21] step 18/44: loss=0.5995 
[epoch 21] step 20/44: loss=0.5972 
[epoch 21] step 22/44: loss=0.5952 
[epoch 21] step 24/44: loss=0.5980 
[epoch 21] step 26/44: loss=0.5955 
[epoch 21] step 28/44: loss=0.5948 
[epoch 21] step 30/44: loss=0.5924 
[epoch 21] step 32/44: loss=0.5930 
[epoch 21] step 34/44: loss=0.5966 
[epoch 21] step 36/44: loss=0.5980 
[epoch 21] step 38/44: loss=0.5994 
[epoch 21] step 40/44: loss=0.6003 
[epoch 21] step 42/44: loss=0.6003 
[epoch 21] step 44/44: loss=0.6003 
[epoch 21] train_loss(avg per step)=1.2006 lambda[min,max]=[0.359299,1.000000]
[epoch 21] val_loss=1.4052 qwk=('0.5951', '0.5486', '0.6120') averageQWK=0.5852 macroEMD=0.2895 tailR0=('0.1804', '0.0972', '0.1000') tailR0avg=0.1259
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    2    0    0
     0   14   40    0    0
     1   17   78   25    4
     0    0   35   76    5
     0    0    5   12    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     1   14   31    6    1
     1   19   58   42    1
     0    1   26  104    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   41   28    0    0
     0   28  102   21    0
     0    3   38   60    0
     0    0    1    1    0
[epoch 22] step 2/44: loss=0.5782 
[epoch 22] step 4/44: loss=0.5869 
[epoch 22] step 6/44: loss=0.5808 
[epoch 22] step 8/44: loss=0.5843 
[epoch 22] step 10/44: loss=0.5803 
[epoch 22] step 12/44: loss=0.5851 
[epoch 22] step 14/44: loss=0.5839 
[epoch 22] step 16/44: loss=0.5838 
[epoch 22] step 18/44: loss=0.5829 
[epoch 22] step 20/44: loss=0.5868 
[epoch 22] step 22/44: loss=0.5873 
[epoch 22] step 24/44: loss=0.5867 
[epoch 22] step 26/44: loss=0.5849 
[epoch 22] step 28/44: loss=0.5866 
[epoch 22] step 30/44: loss=0.5849 
[epoch 22] step 32/44: loss=0.5858 
[epoch 22] step 34/44: loss=0.5889 
[epoch 22] step 36/44: loss=0.5918 
[epoch 22] step 38/44: loss=0.5928 
[epoch 22] step 40/44: loss=0.5944 
[epoch 22] step 42/44: loss=0.5945 
[epoch 22] step 44/44: loss=0.5929 
[epoch 22] train_loss(avg per step)=1.1858 lambda[min,max]=[0.367404,1.000000]
[epoch 22] val_loss=1.4104 qwk=('0.6062', '0.5521', '0.6479') averageQWK=0.6020 macroEMD=0.2879 tailR0=('0.2804', '0.0972', '0.2000') tailR0avg=0.1926
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    6    1    0    0
     2   14   36    2    0
     4   17   64   35    5
     0    1   27   83    5
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     3   14   30    5    1
     4   17   60   39    1
     0    2   23  106    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     1   35   33    0    0
     0   21  105   25    0
     0    1   34   66    0
     0    0    1    1    0
[epoch 23] step 2/44: loss=0.5768 
[epoch 23] step 4/44: loss=0.5692 
[epoch 23] step 6/44: loss=0.5702 
[epoch 23] step 8/44: loss=0.5680 
[epoch 23] step 10/44: loss=0.5679 
[epoch 23] step 12/44: loss=0.5733 
[epoch 23] step 14/44: loss=0.5799 
[epoch 23] step 16/44: loss=0.5849 
[epoch 23] step 18/44: loss=0.5867 
[epoch 23] step 20/44: loss=0.5877 
[epoch 23] step 22/44: loss=0.5884 
[epoch 23] step 24/44: loss=0.5866 
[epoch 23] step 26/44: loss=0.5867 
[epoch 23] step 28/44: loss=0.5890 
[epoch 23] step 30/44: loss=0.5911 
[epoch 23] step 32/44: loss=0.5907 
[epoch 23] step 34/44: loss=0.5896 
[epoch 23] step 36/44: loss=0.5866 
[epoch 23] step 38/44: loss=0.5853 
[epoch 23] step 40/44: loss=0.5843 
[epoch 23] step 42/44: loss=0.5821 
[epoch 23] step 44/44: loss=0.5793 
[epoch 23] train_loss(avg per step)=1.1587 lambda[min,max]=[0.366779,1.000000]
[epoch 23] val_loss=1.4279 qwk=('0.5753', '0.5905', '0.6496') averageQWK=0.6051 macroEMD=0.2877 tailR0=('0.1652', '0.0972', '0.2000') tailR0avg=0.1541
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    7    1    0    0
     1   17   31    5    0
     1   26   55   39    4
     0    2   27   84    3
     0    0    2   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     4   13   34    1    1
     0   18   73   29    1
     0    2   34   93    4
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   39   28    2    0
     0   25   84   42    0
     0    0   27   74    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=0.5616 
[epoch 24] step 4/44: loss=0.5777 
[epoch 24] step 6/44: loss=0.5923 
[epoch 24] step 8/44: loss=0.6004 
[epoch 24] step 10/44: loss=0.6029 
[epoch 24] step 12/44: loss=0.5996 
[epoch 24] step 14/44: loss=0.6027 
[epoch 24] step 16/44: loss=0.6029 
[epoch 24] step 18/44: loss=0.6038 
[epoch 24] step 20/44: loss=0.6011 
[epoch 24] step 22/44: loss=0.5999 
[epoch 24] step 24/44: loss=0.5960 
[epoch 24] step 26/44: loss=0.5956 
[epoch 24] step 28/44: loss=0.5945 
[epoch 24] step 30/44: loss=0.5921 
[epoch 24] step 32/44: loss=0.5930 
[epoch 24] step 34/44: loss=0.5937 
[epoch 24] step 36/44: loss=0.5902 
[epoch 24] step 38/44: loss=0.5877 
[epoch 24] step 40/44: loss=0.5851 
[epoch 24] step 42/44: loss=0.5856 
[epoch 24] step 44/44: loss=0.5849 
[epoch 24] train_loss(avg per step)=1.1698 lambda[min,max]=[0.362814,1.000000]
[epoch 24] val_loss=1.3897 qwk=('0.5839', '0.5765', '0.6442') averageQWK=0.6015 macroEMD=0.2907 tailR0=('0.2152', '0.0556', '0.2000') tailR0avg=0.1569
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    3    0    0
     0   11   41    2    0
     1   11   89   22    2
     0    0   35   79    2
     0    0    5   15    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     3   14   32    4    0
     0   16   68   37    0
     0    2   30  100    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   38   31    0    0
     0   25  106   20    0
     0    1   38   62    0
     0    0    1    1    0
[epoch 25] step 2/44: loss=0.5720 
[epoch 25] step 4/44: loss=0.5677 
[epoch 25] step 6/44: loss=0.5765 
[epoch 25] step 8/44: loss=0.5841 
[epoch 25] step 10/44: loss=0.5955 
[epoch 25] step 12/44: loss=0.5875 
[epoch 25] step 14/44: loss=0.5841 
[epoch 25] step 16/44: loss=0.5839 
[epoch 25] step 18/44: loss=0.5788 
[epoch 25] step 20/44: loss=0.5795 
[epoch 25] step 22/44: loss=0.5816 
[epoch 25] step 24/44: loss=0.5820 
[epoch 25] step 26/44: loss=0.5810 
[epoch 25] step 28/44: loss=0.5797 
[epoch 25] step 30/44: loss=0.5755 
[epoch 25] step 32/44: loss=0.5733 
[epoch 25] step 34/44: loss=0.5719 
[epoch 25] step 36/44: loss=0.5728 
[epoch 25] step 38/44: loss=0.5730 
[epoch 25] step 40/44: loss=0.5743 
[epoch 25] step 42/44: loss=0.5761 
[epoch 25] step 44/44: loss=0.5777 
[epoch 25] train_loss(avg per step)=1.1554 lambda[min,max]=[0.356146,1.000000]
[epoch 25] val_loss=1.4392 qwk=('0.6233', '0.5963', '0.6449') averageQWK=0.6215 macroEMD=0.2844 tailR0=('0.1804', '0.1528', '0.2000') tailR0avg=0.1777
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    9    0    0    0
     1   25   27    1    0
     1   35   56   30    3
     0    3   30   79    4
     0    0    4   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    0    0
     2   19   29    2    1
     0   25   64   30    2
     0    3   31   97    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   44   25    0    0
     0   32   95   24    0
     0    4   30   67    0
     0    0    1    1    0
[epoch 26] step 2/44: loss=0.6031 
[epoch 26] step 4/44: loss=0.6060 
[epoch 26] step 6/44: loss=0.6072 
[epoch 26] step 8/44: loss=0.6030 
[epoch 26] step 10/44: loss=0.5997 
[epoch 26] step 12/44: loss=0.5964 
[epoch 26] step 14/44: loss=0.5951 
[epoch 26] step 16/44: loss=0.5892 
[epoch 26] step 18/44: loss=0.5831 
[epoch 26] step 20/44: loss=0.5791 
[epoch 26] step 22/44: loss=0.5764 
[epoch 26] step 24/44: loss=0.5726 
[epoch 26] step 26/44: loss=0.5706 
[epoch 26] step 28/44: loss=0.5673 
[epoch 26] step 30/44: loss=0.5666 
[epoch 26] step 32/44: loss=0.5662 
[epoch 26] step 34/44: loss=0.5631 
[epoch 26] step 36/44: loss=0.5643 
[epoch 26] step 38/44: loss=0.5644 
[epoch 26] step 40/44: loss=0.5645 
[epoch 26] step 42/44: loss=0.5669 
[epoch 26] step 44/44: loss=0.5702 
[epoch 26] train_loss(avg per step)=1.1404 lambda[min,max]=[0.362013,1.000000]
[epoch 26] val_loss=1.4053 qwk=('0.6192', '0.5663', '0.6614') averageQWK=0.6156 macroEMD=0.2800 tailR0=('0.2304', '0.0972', '0.2000') tailR0avg=0.1759
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    7    1    0    0
     1   13   38    2    0
     2   13   73   34    3
     0    0   30   83    3
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     1   15   30    6    1
     0   18   61   42    0
     0    2   22  108    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   44   25    0    0
     0   27   99   25    0
     0    2   33   66    0
     0    0    1    1    0
[epoch 27] step 2/44: loss=0.6308 
[epoch 27] step 4/44: loss=0.5994 
[epoch 27] step 6/44: loss=0.6021 
[epoch 27] step 8/44: loss=0.6053 
[epoch 27] step 10/44: loss=0.5957 
[epoch 27] step 12/44: loss=0.5859 
[epoch 27] step 14/44: loss=0.5849 
[epoch 27] step 16/44: loss=0.5824 
[epoch 27] step 18/44: loss=0.5805 
[epoch 27] step 20/44: loss=0.5739 
[epoch 27] step 22/44: loss=0.5690 
[epoch 27] step 24/44: loss=0.5640 
[epoch 27] step 26/44: loss=0.5632 
[epoch 27] step 28/44: loss=0.5618 
[epoch 27] step 30/44: loss=0.5625 
[epoch 27] step 32/44: loss=0.5658 
[epoch 27] step 34/44: loss=0.5669 
[epoch 27] step 36/44: loss=0.5673 
[epoch 27] step 38/44: loss=0.5680 
[epoch 27] step 40/44: loss=0.5701 
[epoch 27] step 42/44: loss=0.5726 
[epoch 27] step 44/44: loss=0.5736 
[epoch 27] train_loss(avg per step)=1.1473 lambda[min,max]=[0.367565,1.000000]
[epoch 27] val_loss=1.4120 qwk=('0.6007', '0.5636', '0.6272') averageQWK=0.5972 macroEMD=0.2882 tailR0=('0.2370', '0.1528', '0.1000') tailR0avg=0.1632
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    5    2    0    0
     1   13   38    2    0
     1   14   73   33    4
     0    0   30   82    4
     0    0    3   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     3   10   34    5    1
     0   15   67   39    0
     0    1   30   99    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   40   29    0    0
     0   26  101   24    0
     0    2   35   64    0
     0    0    1    1    0
[epoch 28] step 2/44: loss=0.5602 
[epoch 28] step 4/44: loss=0.5448 
[epoch 28] step 6/44: loss=0.5477 
[epoch 28] step 8/44: loss=0.5413 
[epoch 28] step 10/44: loss=0.5434 
[epoch 28] step 12/44: loss=0.5419 
[epoch 28] step 14/44: loss=0.5437 
[epoch 28] step 16/44: loss=0.5429 
[epoch 28] step 18/44: loss=0.5474 
[epoch 28] step 20/44: loss=0.5460 
[epoch 28] step 22/44: loss=0.5494 
[epoch 28] step 24/44: loss=0.5542 
[epoch 28] step 26/44: loss=0.5550 
[epoch 28] step 28/44: loss=0.5574 
[epoch 28] step 30/44: loss=0.5585 
[epoch 28] step 32/44: loss=0.5595 
[epoch 28] step 34/44: loss=0.5611 
[epoch 28] step 36/44: loss=0.5609 
[epoch 28] step 38/44: loss=0.5609 
[epoch 28] step 40/44: loss=0.5603 
[epoch 28] step 42/44: loss=0.5599 
[epoch 28] step 44/44: loss=0.5599 
[epoch 28] train_loss(avg per step)=1.1197 lambda[min,max]=[0.376094,1.000000]
[epoch 28] val_loss=1.4038 qwk=('0.5846', '0.5555', '0.6404') averageQWK=0.5935 macroEMD=0.2876 tailR0=('0.1435', '0.1111', '0.1000') tailR0avg=0.1182
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    7    1    0    0
     0   12   37    5    0
     1   13   67   40    4
     0    0   22   91    3
     0    0    2   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    1    0
     3    8   36    5    1
     0   11   65   45    0
     0    1   21  110    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   43   26    0    0
     0   25  100   26    0
     0    2   34   65    0
     0    0    1    1    0
[epoch 29] step 2/44: loss=0.4866 
[epoch 29] step 4/44: loss=0.5198 
[epoch 29] step 6/44: loss=0.5281 
[epoch 29] step 8/44: loss=0.5357 
[epoch 29] step 10/44: loss=0.5391 
[epoch 29] step 12/44: loss=0.5422 
[epoch 29] step 14/44: loss=0.5455 
[epoch 29] step 16/44: loss=0.5484 
[epoch 29] step 18/44: loss=0.5495 
[epoch 29] step 20/44: loss=0.5536 
[epoch 29] step 22/44: loss=0.5540 
[epoch 29] step 24/44: loss=0.5551 
[epoch 29] step 26/44: loss=0.5592 
[epoch 29] step 28/44: loss=0.5583 
[epoch 29] step 30/44: loss=0.5595 
[epoch 29] step 32/44: loss=0.5610 
[epoch 29] step 34/44: loss=0.5591 
[epoch 29] step 36/44: loss=0.5565 
[epoch 29] step 38/44: loss=0.5549 
[epoch 29] step 40/44: loss=0.5550 
[epoch 29] step 42/44: loss=0.5545 
[epoch 29] step 44/44: loss=0.5536 
[epoch 29] train_loss(avg per step)=1.1073 lambda[min,max]=[0.354529,1.000000]
[epoch 29] val_loss=1.3975 qwk=('0.6191', '0.5410', '0.6354') averageQWK=0.5985 macroEMD=0.2875 tailR0=('0.1435', '0.1111', '0.2000') tailR0avg=0.1515
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    7    1    0    0
     1   15   37    1    0
     1   14   77   30    3
     0    0   30   82    4
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     2   13   31    6    1
     1   18   57   45    0
     0    1   30  101    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   35   34    0    0
     0   25  102   24    0
     0    1   35   65    0
     0    0    1    1    0
[epoch 30] step 2/44: loss=0.5587 
[epoch 30] step 4/44: loss=0.5484 
[epoch 30] step 6/44: loss=0.5447 
[epoch 30] step 8/44: loss=0.5492 
[epoch 30] step 10/44: loss=0.5494 
[epoch 30] step 12/44: loss=0.5517 
[epoch 30] step 14/44: loss=0.5555 
[epoch 30] step 16/44: loss=0.5575 
[epoch 30] step 18/44: loss=0.5589 
[epoch 30] step 20/44: loss=0.5591 
[epoch 30] step 22/44: loss=0.5615 
[epoch 30] step 24/44: loss=0.5596 
[epoch 30] step 26/44: loss=0.5593 
[epoch 30] step 28/44: loss=0.5578 
[epoch 30] step 30/44: loss=0.5570 
[epoch 30] step 32/44: loss=0.5578 
[epoch 30] step 34/44: loss=0.5571 
[epoch 30] step 36/44: loss=0.5559 
[epoch 30] step 38/44: loss=0.5571 
[epoch 30] step 40/44: loss=0.5570 
[epoch 30] step 42/44: loss=0.5556 
[epoch 30] step 44/44: loss=0.5557 
[epoch 30] train_loss(avg per step)=1.1114 lambda[min,max]=[0.360237,1.000000]
[epoch 30] val_loss=1.4126 qwk=('0.6034', '0.5846', '0.6458') averageQWK=0.6112 macroEMD=0.2888 tailR0=('0.1435', '0.1528', '0.2000') tailR0avg=0.1654
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    7    1    0    0
     1   15   37    1    0
     1   18   67   35    4
     0    0   29   84    3
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     1   15   32    5    0
     2   17   68   34    0
     0    1   31   99    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   40   29    0    0
     0   28  106   17    0
     0    1   40   60    0
     0    0    1    1    0
[epoch 31] step 2/44: loss=0.5560 
[epoch 31] step 4/44: loss=0.5543 
[epoch 31] step 6/44: loss=0.5475 
[epoch 31] step 8/44: loss=0.5527 
[epoch 31] step 10/44: loss=0.5512 
[epoch 31] step 12/44: loss=0.5525 
[epoch 31] step 14/44: loss=0.5498 
[epoch 31] step 16/44: loss=0.5492 
[epoch 31] step 18/44: loss=0.5504 
[epoch 31] step 20/44: loss=0.5483 
[epoch 31] step 22/44: loss=0.5472 
[epoch 31] step 24/44: loss=0.5436 
[epoch 31] step 26/44: loss=0.5459 
[epoch 31] step 28/44: loss=0.5483 
[epoch 31] step 30/44: loss=0.5484 
[epoch 31] step 32/44: loss=0.5495 
[epoch 31] step 34/44: loss=0.5498 
[epoch 31] step 36/44: loss=0.5481 
[epoch 31] step 38/44: loss=0.5490 
[epoch 31] step 40/44: loss=0.5499 
[epoch 31] step 42/44: loss=0.5491 
[epoch 31] step 44/44: loss=0.5480 
[epoch 31] train_loss(avg per step)=1.0961 lambda[min,max]=[0.363000,1.000000]
[epoch 31] val_loss=1.4176 qwk=('0.5878', '0.5380', '0.6508') averageQWK=0.5922 macroEMD=0.2875 tailR0=('0.1587', '0.0972', '0.2000') tailR0avg=0.1520
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    8    1    0    0
     1   15   36    2    0
     1   21   64   35    4
     0    2   29   81    4
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     1   14   31    6    1
     1   20   60   40    0
     0    2   30  100    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   38   31    0    0
     0   26  100   25    0
     0    1   33   67    0
     0    0    1    1    0
[epoch 32] step 2/44: loss=0.5740 
[epoch 32] step 4/44: loss=0.5811 
[epoch 32] step 6/44: loss=0.5744 
[epoch 32] step 8/44: loss=0.5761 
[epoch 32] step 10/44: loss=0.5690 
[epoch 32] step 12/44: loss=0.5633 
[epoch 32] step 14/44: loss=0.5607 
[epoch 32] step 16/44: loss=0.5570 
[epoch 32] step 18/44: loss=0.5559 
[epoch 32] step 20/44: loss=0.5573 
[epoch 32] step 22/44: loss=0.5588 
[epoch 32] step 24/44: loss=0.5580 
[epoch 32] step 26/44: loss=0.5564 
[epoch 32] step 28/44: loss=0.5530 
[epoch 32] step 30/44: loss=0.5531 
[epoch 32] step 32/44: loss=0.5517 
[epoch 32] step 34/44: loss=0.5504 
[epoch 32] step 36/44: loss=0.5495 
[epoch 32] step 38/44: loss=0.5499 
[epoch 32] step 40/44: loss=0.5504 
[epoch 32] step 42/44: loss=0.5498 
[epoch 32] step 44/44: loss=0.5480 
[epoch 32] train_loss(avg per step)=1.0960 lambda[min,max]=[0.352341,1.000000]
[epoch 32] val_loss=1.4127 qwk=('0.6048', '0.5507', '0.6563') averageQWK=0.6039 macroEMD=0.2860 tailR0=('0.1870', '0.1528', '0.2000') tailR0avg=0.1799
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    7    1    0    0
     1   13   38    2    0
     1   14   71   35    4
     0    0   28   85    3
     0    0    3   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     1   13   33    5    1
     1   18   59   43    0
     0    1   30  101    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   39   30    0    0
     0   25  101   25    0
     0    1   33   67    0
     0    0    1    1    0
[epoch 33] step 2/44: loss=0.5902 
[epoch 33] step 4/44: loss=0.5741 
[epoch 33] step 6/44: loss=0.5639 
[epoch 33] step 8/44: loss=0.5686 
[epoch 33] step 10/44: loss=0.5665 
[epoch 33] step 12/44: loss=0.5662 
[epoch 33] step 14/44: loss=0.5699 
[epoch 33] step 16/44: loss=0.5730 
[epoch 33] step 18/44: loss=0.5727 
[epoch 33] step 20/44: loss=0.5698 
[epoch 33] step 22/44: loss=0.5664 
[epoch 33] step 24/44: loss=0.5647 
[epoch 33] step 26/44: loss=0.5650 
[epoch 33] step 28/44: loss=0.5613 
[epoch 33] step 30/44: loss=0.5619 
[epoch 33] step 32/44: loss=0.5607 
[epoch 33] step 34/44: loss=0.5587 
[epoch 33] step 36/44: loss=0.5581 
[epoch 33] step 38/44: loss=0.5550 
[epoch 33] step 40/44: loss=0.5545 
[epoch 33] step 42/44: loss=0.5534 
[epoch 33] step 44/44: loss=0.5508 
[epoch 33] train_loss(avg per step)=1.1017 lambda[min,max]=[0.372559,1.000000]
[epoch 33] val_loss=1.4170 qwk=('0.5947', '0.5526', '0.6609') averageQWK=0.6028 macroEMD=0.2892 tailR0=('0.1870', '0.1528', '0.2000') tailR0avg=0.1799
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    2    0    0
     1   12   40    1    0
     1   12   78   30    4
     0    1   31   80    4
     0    0    3   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     1   14   32    5    1
     1   18   61   41    0
     0    1   32   99    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   40   29    0    0
     0   25  105   21    0
     0    1   35   65    0
     0    0    1    1    0
[epoch 34] step 2/44: loss=0.5826 
[epoch 34] step 4/44: loss=0.5590 
[epoch 34] step 6/44: loss=0.5394 
[epoch 34] step 8/44: loss=0.5400 
[epoch 34] step 10/44: loss=0.5437 
[epoch 34] step 12/44: loss=0.5459 
[epoch 34] step 14/44: loss=0.5409 
[epoch 34] step 16/44: loss=0.5472 
[epoch 34] step 18/44: loss=0.5473 
[epoch 34] step 20/44: loss=0.5480 
[epoch 34] step 22/44: loss=0.5482 
[epoch 34] step 24/44: loss=0.5488 
[epoch 34] step 26/44: loss=0.5527 
[epoch 34] step 28/44: loss=0.5501 
[epoch 34] step 30/44: loss=0.5496 
[epoch 34] step 32/44: loss=0.5485 
[epoch 34] step 34/44: loss=0.5480 
[epoch 34] step 36/44: loss=0.5476 
[epoch 34] step 38/44: loss=0.5460 
[epoch 34] step 40/44: loss=0.5456 
[epoch 34] step 42/44: loss=0.5457 
[epoch 34] step 44/44: loss=0.5455 
[epoch 34] train_loss(avg per step)=1.0909 lambda[min,max]=[0.368804,1.000000]
[epoch 34] val_loss=1.4160 qwk=('0.5899', '0.5647', '0.6646') averageQWK=0.6064 macroEMD=0.2887 tailR0=('0.0935', '0.1528', '0.2000') tailR0avg=0.1488
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    8    1    0    0
     1   15   36    2    0
     1   18   69   34    3
     0    1   30   82    3
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     2   15   30    5    1
     1   20   60   40    0
     0    1   31  100    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   41   28    0    0
     0   26  103   22    0
     0    1   34   66    0
     0    0    1    1    0
[epoch 35] step 2/44: loss=0.5526 
[epoch 35] step 4/44: loss=0.5393 
[epoch 35] step 6/44: loss=0.5273 
[epoch 35] step 8/44: loss=0.5445 
[epoch 35] step 10/44: loss=0.5407 
[epoch 35] step 12/44: loss=0.5408 
[epoch 35] step 14/44: loss=0.5396 
[epoch 35] step 16/44: loss=0.5412 
[epoch 35] step 18/44: loss=0.5423 
[epoch 35] step 20/44: loss=0.5415 
[epoch 35] step 22/44: loss=0.5473 
[epoch 35] step 24/44: loss=0.5439 
[epoch 35] step 26/44: loss=0.5477 
[epoch 35] step 28/44: loss=0.5490 
[epoch 35] step 30/44: loss=0.5496 
[epoch 35] step 32/44: loss=0.5483 
[epoch 35] step 34/44: loss=0.5505 
[epoch 35] step 36/44: loss=0.5509 
[epoch 35] step 38/44: loss=0.5523 
[epoch 35] step 40/44: loss=0.5507 
[epoch 35] step 42/44: loss=0.5504 
[epoch 35] step 44/44: loss=0.5518 
[epoch 35] train_loss(avg per step)=1.1037 lambda[min,max]=[0.370455,1.000000]
[epoch 35] val_loss=1.4233 qwk=('0.5871', '0.5562', '0.6610') averageQWK=0.6014 macroEMD=0.2877 tailR0=('0.0935', '0.1528', '0.2000') tailR0avg=0.1488
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    8    1    0    0
     1   15   36    2    0
     1   16   68   36    4
     0    1   28   84    3
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     1   14   32    5    1
     1   17   62   41    0
     0    1   31  100    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   41   28    0    0
     0   27  101   23    0
     0    1   34   66    0
     0    0    1    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold2/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold2/metrics.json
Done.
