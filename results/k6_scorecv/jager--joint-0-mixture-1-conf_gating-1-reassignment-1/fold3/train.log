[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.5182 
[epoch 1] step 4/44: loss=0.5219 
[epoch 1] step 6/44: loss=0.5223 
[epoch 1] step 8/44: loss=0.5200 
[epoch 1] step 10/44: loss=0.5175 
[epoch 1] step 12/44: loss=0.5172 
[epoch 1] step 14/44: loss=0.5213 
[epoch 1] step 16/44: loss=0.5236 
[epoch 1] step 18/44: loss=0.5271 
[epoch 1] step 20/44: loss=0.5295 
[epoch 1] step 22/44: loss=0.5337 
[epoch 1] step 24/44: loss=0.5378 
[epoch 1] step 26/44: loss=0.5418 
[epoch 1] step 28/44: loss=0.5450 
[epoch 1] step 30/44: loss=0.5490 
[epoch 1] step 32/44: loss=0.5541 
[epoch 1] step 34/44: loss=0.5577 
[epoch 1] step 36/44: loss=0.5611 
[epoch 1] step 38/44: loss=0.5640 
[epoch 1] step 40/44: loss=0.5669 
[epoch 1] step 42/44: loss=0.5695 
[epoch 1] step 44/44: loss=0.5721 
[epoch 1] train_loss(avg per step)=1.1441 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=0.9528 qwk=('0.0405', '0.0405', '0.1523') averageQWK=0.0778 macroEMD=0.3747 tailR0=('0.0000', '0.1000', '0.5000') tailR0avg=0.2000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    5    0
     0   19    2   34    0
     0   47    9   70    0
     0   43    8   65    0
     0    3    3   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    8    0    0
    17    0   35    1    0
    49    0   58   12    0
    44    0   72   18    0
     2    0    8    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0   14   53    0    2
     0   16  120    3   12
     0    9   82    0   11
     0    0    0    0    1
[epoch 2] step 2/44: loss=0.6725 
[epoch 2] step 4/44: loss=0.6809 
[epoch 2] step 6/44: loss=0.6922 
[epoch 2] step 8/44: loss=0.7027 
[epoch 2] step 10/44: loss=0.7164 
[epoch 2] step 12/44: loss=0.7320 
[epoch 2] step 14/44: loss=0.7524 
[epoch 2] step 16/44: loss=0.7669 
[epoch 2] step 18/44: loss=0.7805 
[epoch 2] step 20/44: loss=0.7936 
[epoch 2] step 22/44: loss=0.8039 
[epoch 2] step 24/44: loss=0.8091 
[epoch 2] step 26/44: loss=0.8117 
[epoch 2] step 28/44: loss=0.8155 
[epoch 2] step 30/44: loss=0.8176 
[epoch 2] step 32/44: loss=0.8187 
[epoch 2] step 34/44: loss=0.8222 
[epoch 2] step 36/44: loss=0.8233 
[epoch 2] step 38/44: loss=0.8238 
[epoch 2] step 40/44: loss=0.8210 
[epoch 2] step 42/44: loss=0.8198 
[epoch 2] step 44/44: loss=0.8155 
[epoch 2] train_loss(avg per step)=1.6311 lambda[min,max]=[0.504052,1.000000]
[epoch 2] val_loss=1.4584 qwk=('0.1556', '0.1476', '0.2314') averageQWK=0.1782 macroEMD=0.3574 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    5    0
     0    2   12   41    0
     0    1   11  114    0
     0    0    1  115    0
     0    0    0   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    4    0
     0    0   13   40    0
     0    0    7  112    0
     0    0    1  133    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    2    0
     0   19    1   49    0
     0   20    3  128    0
     0    1    0  101    0
     0    0    0    1    0
[epoch 3] step 2/44: loss=0.7076 
[epoch 3] step 4/44: loss=0.7153 
[epoch 3] step 6/44: loss=0.7243 
[epoch 3] step 8/44: loss=0.7326 
[epoch 3] step 10/44: loss=0.7426 
[epoch 3] step 12/44: loss=0.7494 
[epoch 3] step 14/44: loss=0.7572 
[epoch 3] step 16/44: loss=0.7647 
[epoch 3] step 18/44: loss=0.7659 
[epoch 3] step 20/44: loss=0.7721 
[epoch 3] step 22/44: loss=0.7768 
[epoch 3] step 24/44: loss=0.7775 
[epoch 3] step 26/44: loss=0.7778 
[epoch 3] step 28/44: loss=0.7819 
[epoch 3] step 30/44: loss=0.7844 
[epoch 3] step 32/44: loss=0.7894 
[epoch 3] step 34/44: loss=0.7951 
[epoch 3] step 36/44: loss=0.7987 
[epoch 3] step 38/44: loss=0.8035 
[epoch 3] step 40/44: loss=0.8027 
[epoch 3] step 42/44: loss=0.8015 
[epoch 3] step 44/44: loss=0.8028 
[epoch 3] train_loss(avg per step)=1.6057 lambda[min,max]=[0.505684,1.000000]
[epoch 3] val_loss=1.4387 qwk=('0.5619', '0.4233', '0.5541') averageQWK=0.5131 macroEMD=0.3290 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   41    6    8    0
     0   64   17   45    0
     0   11   10   95    0
     0    1    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    1    0
     0    0   48    5    0
     0    0   84   35    0
     0    0   37   97    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   55   13    1    0
     0   72   43   36    0
     0   12   22   68    0
     0    0    0    1    0
[epoch 4] step 2/44: loss=0.8052 
[epoch 4] step 4/44: loss=0.8018 
[epoch 4] step 6/44: loss=0.7926 
[epoch 4] step 8/44: loss=0.7851 
[epoch 4] step 10/44: loss=0.7864 
[epoch 4] step 12/44: loss=0.7979 
[epoch 4] step 14/44: loss=0.7967 
[epoch 4] step 16/44: loss=0.7989 
[epoch 4] step 18/44: loss=0.8030 
[epoch 4] step 20/44: loss=0.8060 
[epoch 4] step 22/44: loss=0.8083 
[epoch 4] step 24/44: loss=0.8115 
[epoch 4] step 26/44: loss=0.8171 
[epoch 4] step 28/44: loss=0.8225 
[epoch 4] step 30/44: loss=0.8233 
[epoch 4] step 32/44: loss=0.8233 
[epoch 4] step 34/44: loss=0.8220 
[epoch 4] step 36/44: loss=0.8233 
[epoch 4] step 38/44: loss=0.8242 
[epoch 4] step 40/44: loss=0.8239 
[epoch 4] step 42/44: loss=0.8226 
[epoch 4] step 44/44: loss=0.8216 
[epoch 4] train_loss(avg per step)=1.6432 lambda[min,max]=[0.500757,1.000000]
[epoch 4] val_loss=1.4820 qwk=('0.4135', '0.4377', '0.3110') averageQWK=0.3874 macroEMD=0.3132 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   11   21   23    0
     0    2   44   80    0
     0    0    7  109    0
     0    0    0   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     0    6   29   18    0
     0    2   43   74    0
     0    0    6  128    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     0   11   28   30    0
     0    6   35  110    0
     0    1    5   96    0
     0    0    0    1    0
[epoch 5] step 2/44: loss=0.8126 
[epoch 5] step 4/44: loss=0.8158 
[epoch 5] step 6/44: loss=0.8119 
[epoch 5] step 8/44: loss=0.8204 
[epoch 5] step 10/44: loss=0.8204 
[epoch 5] step 12/44: loss=0.8167 
[epoch 5] step 14/44: loss=0.8133 
[epoch 5] step 16/44: loss=0.8109 
[epoch 5] step 18/44: loss=0.8069 
[epoch 5] step 20/44: loss=0.8039 
[epoch 5] step 22/44: loss=0.8021 
[epoch 5] step 24/44: loss=0.8014 
[epoch 5] step 26/44: loss=0.7982 
[epoch 5] step 28/44: loss=0.8014 
[epoch 5] step 30/44: loss=0.8019 
[epoch 5] step 32/44: loss=0.8033 
[epoch 5] step 34/44: loss=0.8020 
[epoch 5] step 36/44: loss=0.8028 
[epoch 5] step 38/44: loss=0.8046 
[epoch 5] step 40/44: loss=0.8049 
[epoch 5] step 42/44: loss=0.8039 
[epoch 5] step 44/44: loss=0.8033 
[epoch 5] train_loss(avg per step)=1.6066 lambda[min,max]=[0.500038,1.000000]
[epoch 5] val_loss=1.4152 qwk=('0.5214', '0.5608', '0.5296') averageQWK=0.5372 macroEMD=0.3042 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   14   31   10    0
     0    6   66   54    0
     0    2   13  101    0
     0    0    1   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   12   31   10    0
     0    5   65   49    0
     0    0   16  118    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   16   51    2    0
     0    9  105   37    0
     0    3   25   74    0
     0    0    0    1    0
[epoch 6] step 2/44: loss=0.8260 
[epoch 6] step 4/44: loss=0.8237 
[epoch 6] step 6/44: loss=0.8284 
[epoch 6] step 8/44: loss=0.8178 
[epoch 6] step 10/44: loss=0.8186 
[epoch 6] step 12/44: loss=0.8178 
[epoch 6] step 14/44: loss=0.8136 
[epoch 6] step 16/44: loss=0.8148 
[epoch 6] step 18/44: loss=0.8137 
[epoch 6] step 20/44: loss=0.8157 
[epoch 6] step 22/44: loss=0.8174 
[epoch 6] step 24/44: loss=0.8127 
[epoch 6] step 26/44: loss=0.8116 
[epoch 6] step 28/44: loss=0.8100 
[epoch 6] step 30/44: loss=0.8077 
[epoch 6] step 32/44: loss=0.8083 
[epoch 6] step 34/44: loss=0.8099 
[epoch 6] step 36/44: loss=0.8103 
[epoch 6] step 38/44: loss=0.8121 
[epoch 6] step 40/44: loss=0.8130 
[epoch 6] step 42/44: loss=0.8111 
[epoch 6] step 44/44: loss=0.8078 
[epoch 6] train_loss(avg per step)=1.6156 lambda[min,max]=[0.500001,1.000000]
[epoch 6] val_loss=1.4414 qwk=('0.6177', '0.4977', '0.5155') averageQWK=0.5436 macroEMD=0.3030 tailR0=('0.1364', '0.0000', '0.0000') tailR0avg=0.0455
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   26   24    4    1
     0   14   70   39    3
     0    2   19   89    6
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    1    0
     0    2   44    7    0
     0    0   82   37    0
     0    0   16  118    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   15   52    2    0
     0   10  108   33    0
     0    3   26   73    0
     0    0    0    1    0
[epoch 7] step 2/44: loss=0.7724 
[epoch 7] step 4/44: loss=0.7585 
[epoch 7] step 6/44: loss=0.7566 
[epoch 7] step 8/44: loss=0.7581 
[epoch 7] step 10/44: loss=0.7667 
[epoch 7] step 12/44: loss=0.7703 
[epoch 7] step 14/44: loss=0.7729 
[epoch 7] step 16/44: loss=0.7774 
[epoch 7] step 18/44: loss=0.7769 
[epoch 7] step 20/44: loss=0.7788 
[epoch 7] step 22/44: loss=0.7798 
[epoch 7] step 24/44: loss=0.7813 
[epoch 7] step 26/44: loss=0.7798 
[epoch 7] step 28/44: loss=0.7790 
[epoch 7] step 30/44: loss=0.7789 
[epoch 7] step 32/44: loss=0.7806 
[epoch 7] step 34/44: loss=0.7819 
[epoch 7] step 36/44: loss=0.7815 
[epoch 7] step 38/44: loss=0.7812 
[epoch 7] step 40/44: loss=0.7803 
[epoch 7] step 42/44: loss=0.7787 
[epoch 7] step 44/44: loss=0.7767 
[epoch 7] train_loss(avg per step)=1.5535 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.4138 qwk=('0.6673', '0.6429', '0.5870') averageQWK=0.6324 macroEMD=0.2925 tailR0=('0.1364', '0.0000', '0.0000') tailR0avg=0.0455
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   31   20    4    0
     0   19   92   13    2
     0    2   35   75    4
     0    0    2   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   30   20    3    0
     0   16   85   18    0
     0    4   38   92    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   38   29    2    0
     0   37   86   28    0
     0    5   28   69    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=0.7300 
[epoch 8] step 4/44: loss=0.7419 
[epoch 8] step 6/44: loss=0.7547 
[epoch 8] step 8/44: loss=0.7710 
[epoch 8] step 10/44: loss=0.7852 
[epoch 8] step 12/44: loss=0.7860 
[epoch 8] step 14/44: loss=0.7796 
[epoch 8] step 16/44: loss=0.7796 
[epoch 8] step 18/44: loss=0.7789 
[epoch 8] step 20/44: loss=0.7773 
[epoch 8] step 22/44: loss=0.7780 
[epoch 8] step 24/44: loss=0.7793 
[epoch 8] step 26/44: loss=0.7791 
[epoch 8] step 28/44: loss=0.7809 
[epoch 8] step 30/44: loss=0.7809 
[epoch 8] step 32/44: loss=0.7776 
[epoch 8] step 34/44: loss=0.7793 
[epoch 8] step 36/44: loss=0.7783 
[epoch 8] step 38/44: loss=0.7782 
[epoch 8] step 40/44: loss=0.7777 
[epoch 8] step 42/44: loss=0.7751 
[epoch 8] step 44/44: loss=0.7763 
[epoch 8] train_loss(avg per step)=1.5527 lambda[min,max]=[0.481484,1.000000]
[epoch 8] val_loss=1.4169 qwk=('0.6493', '0.6223', '0.5793') averageQWK=0.6170 macroEMD=0.2860 tailR0=('0.1136', '0.0000', '0.0000') tailR0avg=0.0379
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   23   28    4    0
     0   14   83   27    2
     0    2   21   92    1
     0    0    1   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   20   29    4    0
     0   15   76   28    0
     0    4   19  111    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   36   30    3    0
     0   28   89   34    0
     0    5   24   73    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=0.7270 
[epoch 9] step 4/44: loss=0.7393 
[epoch 9] step 6/44: loss=0.7454 
[epoch 9] step 8/44: loss=0.7476 
[epoch 9] step 10/44: loss=0.7469 
[epoch 9] step 12/44: loss=0.7463 
[epoch 9] step 14/44: loss=0.7477 
[epoch 9] step 16/44: loss=0.7547 
[epoch 9] step 18/44: loss=0.7626 
[epoch 9] step 20/44: loss=0.7621 
[epoch 9] step 22/44: loss=0.7613 
[epoch 9] step 24/44: loss=0.7571 
[epoch 9] step 26/44: loss=0.7606 
[epoch 9] step 28/44: loss=0.7608 
[epoch 9] step 30/44: loss=0.7588 
[epoch 9] step 32/44: loss=0.7562 
[epoch 9] step 34/44: loss=0.7551 
[epoch 9] step 36/44: loss=0.7541 
[epoch 9] step 38/44: loss=0.7518 
[epoch 9] step 40/44: loss=0.7516 
[epoch 9] step 42/44: loss=0.7542 
[epoch 9] step 44/44: loss=0.7557 
[epoch 9] train_loss(avg per step)=1.5113 lambda[min,max]=[0.469856,1.000000]
[epoch 9] val_loss=1.4039 qwk=('0.6365', '0.6225', '0.5982') averageQWK=0.6191 macroEMD=0.2773 tailR0=('0.2273', '0.0000', '0.0000') tailR0avg=0.0758
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   23   29    1    2
     0    9   91   22    4
     0    2   27   75   12
     0    0    1   11   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   20   28    5    0
     0   18   75   26    0
     0    3   24  107    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   33   34    2    0
     0   24   96   31    0
     0    4   26   72    0
     0    0    0    1    0
[epoch 10] step 2/44: loss=0.7267 
[epoch 10] step 4/44: loss=0.7622 
[epoch 10] step 6/44: loss=0.7780 
[epoch 10] step 8/44: loss=0.7910 
[epoch 10] step 10/44: loss=0.7849 
[epoch 10] step 12/44: loss=0.7757 
[epoch 10] step 14/44: loss=0.7635 
[epoch 10] step 16/44: loss=0.7608 
[epoch 10] step 18/44: loss=0.7551 
[epoch 10] step 20/44: loss=0.7500 
[epoch 10] step 22/44: loss=0.7441 
[epoch 10] step 24/44: loss=0.7428 
[epoch 10] step 26/44: loss=0.7396 
[epoch 10] step 28/44: loss=0.7422 
[epoch 10] step 30/44: loss=0.7440 
[epoch 10] step 32/44: loss=0.7438 
[epoch 10] step 34/44: loss=0.7464 
[epoch 10] step 36/44: loss=0.7462 
[epoch 10] step 38/44: loss=0.7478 
[epoch 10] step 40/44: loss=0.7482 
[epoch 10] step 42/44: loss=0.7511 
[epoch 10] step 44/44: loss=0.7555 
[epoch 10] train_loss(avg per step)=1.5110 lambda[min,max]=[0.481679,1.000000]
[epoch 10] val_loss=1.4626 qwk=('0.6351', '0.5840', '0.5976') averageQWK=0.6056 macroEMD=0.2785 tailR0=('0.2500', '0.0000', '0.0000') tailR0avg=0.0833
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   27   25    1    2
     0   16   87   17    6
     0    2   31   70   13
     0    0    3    8   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   37   10    6    0
     0   45   49   25    0
     0   15   15  104    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   44   25    0    0
     0   34  102   15    0
     0    4   46   52    0
     0    0    0    1    0
[epoch 11] step 2/44: loss=0.8083 
[epoch 11] step 4/44: loss=0.7744 
[epoch 11] step 6/44: loss=0.7607 
[epoch 11] step 8/44: loss=0.7611 
[epoch 11] step 10/44: loss=0.7516 
[epoch 11] step 12/44: loss=0.7435 
[epoch 11] step 14/44: loss=0.7389 
[epoch 11] step 16/44: loss=0.7333 
[epoch 11] step 18/44: loss=0.7315 
[epoch 11] step 20/44: loss=0.7295 
[epoch 11] step 22/44: loss=0.7288 
[epoch 11] step 24/44: loss=0.7279 
[epoch 11] step 26/44: loss=0.7305 
[epoch 11] step 28/44: loss=0.7323 
[epoch 11] step 30/44: loss=0.7314 
[epoch 11] step 32/44: loss=0.7321 
[epoch 11] step 34/44: loss=0.7316 
[epoch 11] step 36/44: loss=0.7318 
[epoch 11] step 38/44: loss=0.7337 
[epoch 11] step 40/44: loss=0.7352 
[epoch 11] step 42/44: loss=0.7350 
[epoch 11] step 44/44: loss=0.7342 
[epoch 11] train_loss(avg per step)=1.4684 lambda[min,max]=[0.491434,1.000000]
[epoch 11] val_loss=1.3837 qwk=('0.6171', '0.6306', '0.5606') averageQWK=0.6028 macroEMD=0.2792 tailR0=('0.2045', '0.0000', '0.0000') tailR0avg=0.0682
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   19   29    7    0
     0    2   94   27    3
     0    0   23   88    5
     0    0    1   12    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   18   30    5    0
     0    7   88   24    0
     0    0   23  111    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   20   47    2    0
     0    9  112   30    0
     0    2   28   72    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=0.7318 
[epoch 12] step 4/44: loss=0.7326 
[epoch 12] step 6/44: loss=0.7394 
[epoch 12] step 8/44: loss=0.7319 
[epoch 12] step 10/44: loss=0.7200 
[epoch 12] step 12/44: loss=0.7094 
[epoch 12] step 14/44: loss=0.7063 
[epoch 12] step 16/44: loss=0.7067 
[epoch 12] step 18/44: loss=0.7086 
[epoch 12] step 20/44: loss=0.7077 
[epoch 12] step 22/44: loss=0.7085 
[epoch 12] step 24/44: loss=0.7104 
[epoch 12] step 26/44: loss=0.7096 
[epoch 12] step 28/44: loss=0.7082 
[epoch 12] step 30/44: loss=0.7096 
[epoch 12] step 32/44: loss=0.7115 
[epoch 12] step 34/44: loss=0.7139 
[epoch 12] step 36/44: loss=0.7132 
[epoch 12] step 38/44: loss=0.7125 
[epoch 12] step 40/44: loss=0.7134 
[epoch 12] step 42/44: loss=0.7135 
[epoch 12] step 44/44: loss=0.7139 
[epoch 12] train_loss(avg per step)=1.4277 lambda[min,max]=[0.452641,1.000000]
[epoch 12] val_loss=1.3907 qwk=('0.6520', '0.6430', '0.5764') averageQWK=0.6238 macroEMD=0.2754 tailR0=('0.2727', '0.0000', '0.0000') tailR0avg=0.0909
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   18   33    4    0
     0    7   90   25    4
     0    1   23   85    7
     0    0    1    9   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   22   28    3    0
     0   14   77   28    0
     0    3   21  108    2
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   23   45    1    0
     0   18  108   25    0
     0    2   31   69    0
     0    0    0    1    0
[epoch 13] step 2/44: loss=0.7282 
[epoch 13] step 4/44: loss=0.7285 
[epoch 13] step 6/44: loss=0.7241 
[epoch 13] step 8/44: loss=0.7255 
[epoch 13] step 10/44: loss=0.7263 
[epoch 13] step 12/44: loss=0.7181 
[epoch 13] step 14/44: loss=0.7236 
[epoch 13] step 16/44: loss=0.7210 
[epoch 13] step 18/44: loss=0.7233 
[epoch 13] step 20/44: loss=0.7181 
[epoch 13] step 22/44: loss=0.7147 
[epoch 13] step 24/44: loss=0.7095 
[epoch 13] step 26/44: loss=0.7070 
[epoch 13] step 28/44: loss=0.7042 
[epoch 13] step 30/44: loss=0.7028 
[epoch 13] step 32/44: loss=0.7006 
[epoch 13] step 34/44: loss=0.7009 
[epoch 13] step 36/44: loss=0.7021 
[epoch 13] step 38/44: loss=0.7024 
[epoch 13] step 40/44: loss=0.7040 
[epoch 13] step 42/44: loss=0.7057 
[epoch 13] step 44/44: loss=0.7056 
[epoch 13] train_loss(avg per step)=1.4112 lambda[min,max]=[0.457343,1.000000]
[epoch 13] val_loss=1.4502 qwk=('0.6824', '0.5870', '0.5960') averageQWK=0.6218 macroEMD=0.2645 tailR0=('0.3409', '0.0833', '0.0000') tailR0avg=0.1414
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   33   18    4    0
     0   24   72   26    4
     0    3   26   74   13
     0    0    1    6   15
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   26   19    8    0
     0   28   53   37    1
     0    6   18  107    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   44   23    2    0
     0   42   74   35    0
     0    5   24   73    0
     0    0    0    1    0
[epoch 14] step 2/44: loss=0.7215 
[epoch 14] step 4/44: loss=0.7052 
[epoch 14] step 6/44: loss=0.7046 
[epoch 14] step 8/44: loss=0.7076 
[epoch 14] step 10/44: loss=0.7045 
[epoch 14] step 12/44: loss=0.6941 
[epoch 14] step 14/44: loss=0.6837 
[epoch 14] step 16/44: loss=0.6805 
[epoch 14] step 18/44: loss=0.6832 
[epoch 14] step 20/44: loss=0.6826 
[epoch 14] step 22/44: loss=0.6814 
[epoch 14] step 24/44: loss=0.6872 
[epoch 14] step 26/44: loss=0.6895 
[epoch 14] step 28/44: loss=0.6919 
[epoch 14] step 30/44: loss=0.6967 
[epoch 14] step 32/44: loss=0.6987 
[epoch 14] step 34/44: loss=0.6977 
[epoch 14] step 36/44: loss=0.6978 
[epoch 14] step 38/44: loss=0.6970 
[epoch 14] step 40/44: loss=0.6958 
[epoch 14] step 42/44: loss=0.6960 
[epoch 14] step 44/44: loss=0.6967 
[epoch 14] train_loss(avg per step)=1.3934 lambda[min,max]=[0.426489,1.000000]
[epoch 14] val_loss=1.4340 qwk=('0.6717', '0.5650', '0.5821') averageQWK=0.6063 macroEMD=0.2716 tailR0=('0.3409', '0.0000', '0.0000') tailR0avg=0.1136
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     2   24   25    4    0
     0   13   91   18    4
     0    2   36   65   13
     0    0    1    6   15
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     1   23   18   11    0
     0   18   56   45    0
     0    6   11  116    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   34   34    1    0
     0   35   91   25    0
     0    4   32   66    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=0.7142 
[epoch 15] step 4/44: loss=0.6855 
[epoch 15] step 6/44: loss=0.6850 
[epoch 15] step 8/44: loss=0.6734 
[epoch 15] step 10/44: loss=0.6566 
[epoch 15] step 12/44: loss=0.6546 
[epoch 15] step 14/44: loss=0.6471 
[epoch 15] step 16/44: loss=0.6458 
[epoch 15] step 18/44: loss=0.6515 
[epoch 15] step 20/44: loss=0.6506 
[epoch 15] step 22/44: loss=0.6539 
[epoch 15] step 24/44: loss=0.6568 
[epoch 15] step 26/44: loss=0.6643 
[epoch 15] step 28/44: loss=0.6706 
[epoch 15] step 30/44: loss=0.6770 
[epoch 15] step 32/44: loss=0.6792 
[epoch 15] step 34/44: loss=0.6816 
[epoch 15] step 36/44: loss=0.6833 
[epoch 15] step 38/44: loss=0.6818 
[epoch 15] step 40/44: loss=0.6792 
[epoch 15] step 42/44: loss=0.6760 
[epoch 15] step 44/44: loss=0.6724 
[epoch 15] train_loss(avg per step)=1.3448 lambda[min,max]=[0.393931,1.000000]
[epoch 15] val_loss=1.3810 qwk=('0.6092', '0.5923', '0.5942') averageQWK=0.5986 macroEMD=0.2789 tailR0=('0.3182', '0.1333', '0.0000') tailR0avg=0.1505
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     4   10   39    2    0
     1    4  104   13    4
     0    0   44   58   14
     0    0    3    5   14
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    5    0    0
     2    9   39    3    0
     0    5   85   27    2
     0    0   32   98    4
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   37    1    0
     0   18  107   26    0
     0    3   32   67    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=0.5830 
[epoch 16] step 4/44: loss=0.5790 
[epoch 16] step 6/44: loss=0.5914 
[epoch 16] step 8/44: loss=0.6142 
[epoch 16] step 10/44: loss=0.6153 
[epoch 16] step 12/44: loss=0.6277 
[epoch 16] step 14/44: loss=0.6348 
[epoch 16] step 16/44: loss=0.6407 
[epoch 16] step 18/44: loss=0.6445 
[epoch 16] step 20/44: loss=0.6458 
[epoch 16] step 22/44: loss=0.6509 
[epoch 16] step 24/44: loss=0.6527 
[epoch 16] step 26/44: loss=0.6506 
[epoch 16] step 28/44: loss=0.6504 
[epoch 16] step 30/44: loss=0.6477 
[epoch 16] step 32/44: loss=0.6411 
[epoch 16] step 34/44: loss=0.6419 
[epoch 16] step 36/44: loss=0.6435 
[epoch 16] step 38/44: loss=0.6441 
[epoch 16] step 40/44: loss=0.6432 
[epoch 16] step 42/44: loss=0.6440 
[epoch 16] step 44/44: loss=0.6445 
[epoch 16] train_loss(avg per step)=1.2890 lambda[min,max]=[0.405180,1.000000]
[epoch 16] val_loss=1.4000 qwk=('0.6695', '0.6004', '0.5682') averageQWK=0.6127 macroEMD=0.2654 tailR0=('0.3283', '0.0833', '0.0000') tailR0avg=0.1372
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    1    0    0
     2   23   25    4    1
     0   12   85   24    5
     0    2   20   80   14
     0    0    1    9   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     2   22   21    8    0
     0   13   76   30    0
     0    6   20  105    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   27   41    1    0
     0   19   98   34    0
     0    3   30   69    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=0.7074 
[epoch 17] step 4/44: loss=0.6986 
[epoch 17] step 6/44: loss=0.6962 
[epoch 17] step 8/44: loss=0.6903 
[epoch 17] step 10/44: loss=0.6768 
[epoch 17] step 12/44: loss=0.6670 
[epoch 17] step 14/44: loss=0.6637 
[epoch 17] step 16/44: loss=0.6585 
[epoch 17] step 18/44: loss=0.6574 
[epoch 17] step 20/44: loss=0.6562 
[epoch 17] step 22/44: loss=0.6554 
[epoch 17] step 24/44: loss=0.6532 
[epoch 17] step 26/44: loss=0.6517 
[epoch 17] step 28/44: loss=0.6540 
[epoch 17] step 30/44: loss=0.6536 
[epoch 17] step 32/44: loss=0.6554 
[epoch 17] step 34/44: loss=0.6533 
[epoch 17] step 36/44: loss=0.6532 
[epoch 17] step 38/44: loss=0.6521 
[epoch 17] step 40/44: loss=0.6495 
[epoch 17] step 42/44: loss=0.6490 
[epoch 17] step 44/44: loss=0.6484 
[epoch 17] train_loss(avg per step)=1.2968 lambda[min,max]=[0.369751,1.000000]
[epoch 17] val_loss=1.4214 qwk=('0.6309', '0.6169', '0.5435') averageQWK=0.5971 macroEMD=0.2763 tailR0=('0.3283', '0.1667', '0.0000') tailR0avg=0.1650
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    1    0
     3   20   26    6    0
     0    9   87   26    4
     0    2   26   79    9
     0    0    3    7   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     2   20   27    4    0
     0   16   75   26    2
     0    5   25   97    7
     0    0    2    6    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   21   46    2    0
     0   17  106   28    0
     0    3   31   68    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=0.6287 
[epoch 18] step 4/44: loss=0.6490 
[epoch 18] step 6/44: loss=0.6349 
[epoch 18] step 8/44: loss=0.6323 
[epoch 18] step 10/44: loss=0.6322 
[epoch 18] step 12/44: loss=0.6278 
[epoch 18] step 14/44: loss=0.6230 
[epoch 18] step 16/44: loss=0.6206 
[epoch 18] step 18/44: loss=0.6186 
[epoch 18] step 20/44: loss=0.6200 
[epoch 18] step 22/44: loss=0.6236 
[epoch 18] step 24/44: loss=0.6268 
[epoch 18] step 26/44: loss=0.6296 
[epoch 18] step 28/44: loss=0.6311 
[epoch 18] step 30/44: loss=0.6329 
[epoch 18] step 32/44: loss=0.6350 
[epoch 18] step 34/44: loss=0.6352 
[epoch 18] step 36/44: loss=0.6351 
[epoch 18] step 38/44: loss=0.6337 
[epoch 18] step 40/44: loss=0.6319 
[epoch 18] step 42/44: loss=0.6303 
[epoch 18] step 44/44: loss=0.6307 
[epoch 18] train_loss(avg per step)=1.2614 lambda[min,max]=[0.385557,1.000000]
[epoch 18] val_loss=1.3750 qwk=('0.6096', '0.5964', '0.5391') averageQWK=0.5817 macroEMD=0.2846 tailR0=('0.4293', '0.0917', '0.0000') tailR0avg=0.1737
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    4    1    0
     5    7   39    4    0
     0    3   95   24    4
     0    0   34   74    8
     0    0    2    6   14
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    3    0    0
     5    6   36    6    0
     0    7   82   30    0
     0    0   31  101    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   20   45    4    0
     0   12  109   30    0
     0    3   28   71    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=0.5790 
[epoch 19] step 4/44: loss=0.5911 
[epoch 19] step 6/44: loss=0.5902 
[epoch 19] step 8/44: loss=0.5888 
[epoch 19] step 10/44: loss=0.5996 
[epoch 19] step 12/44: loss=0.6116 
[epoch 19] step 14/44: loss=0.6200 
[epoch 19] step 16/44: loss=0.6248 
[epoch 19] step 18/44: loss=0.6291 
[epoch 19] step 20/44: loss=0.6302 
[epoch 19] step 22/44: loss=0.6338 
[epoch 19] step 24/44: loss=0.6340 
[epoch 19] step 26/44: loss=0.6329 
[epoch 19] step 28/44: loss=0.6298 
[epoch 19] step 30/44: loss=0.6266 
[epoch 19] step 32/44: loss=0.6235 
[epoch 19] step 34/44: loss=0.6195 
[epoch 19] step 36/44: loss=0.6173 
[epoch 19] step 38/44: loss=0.6188 
[epoch 19] step 40/44: loss=0.6170 
[epoch 19] step 42/44: loss=0.6173 
[epoch 19] step 44/44: loss=0.6187 
[epoch 19] train_loss(avg per step)=1.2375 lambda[min,max]=[0.391668,1.000000]
[epoch 19] val_loss=1.4004 qwk=('0.6273', '0.5962', '0.5456') averageQWK=0.5897 macroEMD=0.2849 tailR0=('0.2045', '0.0000', '0.0000') tailR0avg=0.0682
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     3   21   24    7    0
     0   11   79   33    3
     0    2   19   89    6
     0    0    1   12    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     1   25   21    6    0
     0   21   66   31    1
     0    7   14  111    2
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   25   42    2    0
     0   18  115   18    0
     0    3   39   60    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=0.6142 
[epoch 20] step 4/44: loss=0.6456 
[epoch 20] step 6/44: loss=0.6476 
[epoch 20] step 8/44: loss=0.6380 
[epoch 20] step 10/44: loss=0.6332 
[epoch 20] step 12/44: loss=0.6172 
[epoch 20] step 14/44: loss=0.6093 
[epoch 20] step 16/44: loss=0.6105 
[epoch 20] step 18/44: loss=0.6137 
[epoch 20] step 20/44: loss=0.6090 
[epoch 20] step 22/44: loss=0.6062 
[epoch 20] step 24/44: loss=0.6070 
[epoch 20] step 26/44: loss=0.6083 
[epoch 20] step 28/44: loss=0.6080 
[epoch 20] step 30/44: loss=0.6087 
[epoch 20] step 32/44: loss=0.6073 
[epoch 20] step 34/44: loss=0.6062 
[epoch 20] step 36/44: loss=0.6044 
[epoch 20] step 38/44: loss=0.6052 
[epoch 20] step 40/44: loss=0.6068 
[epoch 20] step 42/44: loss=0.6065 
[epoch 20] step 44/44: loss=0.6085 
[epoch 20] train_loss(avg per step)=1.2170 lambda[min,max]=[0.373531,1.000000]
[epoch 20] val_loss=1.4017 qwk=('0.6665', '0.6222', '0.5474') averageQWK=0.6120 macroEMD=0.2728 tailR0=('0.4848', '0.1750', '0.0000') tailR0avg=0.2199
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    3    0    0
     6   15   30    4    0
     1    6   94   21    4
     0    1   32   68   15
     0    0    1    7   14
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     6   12   30    5    0
     0    8   87   23    1
     0    1   32   96    5
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   25   40    4    0
     0   18  102   31    0
     0    3   29   70    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=0.6076 
[epoch 21] step 4/44: loss=0.6371 
[epoch 21] step 6/44: loss=0.6324 
[epoch 21] step 8/44: loss=0.6253 
[epoch 21] step 10/44: loss=0.6182 
[epoch 21] step 12/44: loss=0.6093 
[epoch 21] step 14/44: loss=0.5963 
[epoch 21] step 16/44: loss=0.5912 
[epoch 21] step 18/44: loss=0.5880 
[epoch 21] step 20/44: loss=0.5890 
[epoch 21] step 22/44: loss=0.5872 
[epoch 21] step 24/44: loss=0.5885 
[epoch 21] step 26/44: loss=0.5877 
[epoch 21] step 28/44: loss=0.5907 
[epoch 21] step 30/44: loss=0.5955 
[epoch 21] step 32/44: loss=0.5984 
[epoch 21] step 34/44: loss=0.6022 
[epoch 21] step 36/44: loss=0.6043 
[epoch 21] step 38/44: loss=0.6041 
[epoch 21] step 40/44: loss=0.6044 
[epoch 21] step 42/44: loss=0.6024 
[epoch 21] step 44/44: loss=0.6044 
[epoch 21] train_loss(avg per step)=1.2088 lambda[min,max]=[0.358509,1.000000]
[epoch 21] val_loss=1.3870 qwk=('0.6336', '0.6239', '0.5372') averageQWK=0.5983 macroEMD=0.2855 tailR0=('0.4394', '0.2250', '0.1000') tailR0avg=0.2548
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    1    1    0
     6   13   31    4    1
     1    8   84   29    4
     0    1   28   78    9
     0    0    1    9   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    4    0    0
     8    3   39    3    0
     0    5   88   26    0
     0    0   35   96    3
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   18   49    2    0
     0   11  120   20    0
     0    1   42   59    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=0.4918 
[epoch 22] step 4/44: loss=0.5115 
[epoch 22] step 6/44: loss=0.5206 
[epoch 22] step 8/44: loss=0.5318 
[epoch 22] step 10/44: loss=0.5425 
[epoch 22] step 12/44: loss=0.5544 
[epoch 22] step 14/44: loss=0.5677 
[epoch 22] step 16/44: loss=0.5752 
[epoch 22] step 18/44: loss=0.5797 
[epoch 22] step 20/44: loss=0.5878 
[epoch 22] step 22/44: loss=0.5860 
[epoch 22] step 24/44: loss=0.5864 
[epoch 22] step 26/44: loss=0.5908 
[epoch 22] step 28/44: loss=0.5920 
[epoch 22] step 30/44: loss=0.5905 
[epoch 22] step 32/44: loss=0.5861 
[epoch 22] step 34/44: loss=0.5836 
[epoch 22] step 36/44: loss=0.5780 
[epoch 22] step 38/44: loss=0.5745 
[epoch 22] step 40/44: loss=0.5736 
[epoch 22] step 42/44: loss=0.5756 
[epoch 22] step 44/44: loss=0.5775 
[epoch 22] train_loss(avg per step)=1.1549 lambda[min,max]=[0.344975,1.000000]
[epoch 22] val_loss=1.3827 qwk=('0.5952', '0.5919', '0.5948') averageQWK=0.5940 macroEMD=0.2808 tailR0=('0.2727', '0.0417', '0.1000') tailR0avg=0.1381
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     2   20   25    8    0
     0   13   66   43    4
     0    2   19   88    7
     0    0    1    9   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     2   20   23    8    0
     0   11   69   39    0
     0    4   19  110    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   29   38    2    0
     0   16  113   22    0
     0    2   35   65    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=0.6099 
[epoch 23] step 4/44: loss=0.6138 
[epoch 23] step 6/44: loss=0.6258 
[epoch 23] step 8/44: loss=0.6354 
[epoch 23] step 10/44: loss=0.6333 
[epoch 23] step 12/44: loss=0.6306 
[epoch 23] step 14/44: loss=0.6291 
[epoch 23] step 16/44: loss=0.6200 
[epoch 23] step 18/44: loss=0.6119 
[epoch 23] step 20/44: loss=0.6026 
[epoch 23] step 22/44: loss=0.5959 
[epoch 23] step 24/44: loss=0.5931 
[epoch 23] step 26/44: loss=0.5891 
[epoch 23] step 28/44: loss=0.5876 
[epoch 23] step 30/44: loss=0.5860 
[epoch 23] step 32/44: loss=0.5845 
[epoch 23] step 34/44: loss=0.5848 
[epoch 23] step 36/44: loss=0.5846 
[epoch 23] step 38/44: loss=0.5844 
[epoch 23] step 40/44: loss=0.5840 
[epoch 23] step 42/44: loss=0.5877 
[epoch 23] step 44/44: loss=0.5896 
[epoch 23] train_loss(avg per step)=1.1793 lambda[min,max]=[0.362046,1.000000]
[epoch 23] val_loss=1.4160 qwk=('0.6387', '0.5722', '0.5591') averageQWK=0.5900 macroEMD=0.2803 tailR0=('0.2955', '0.0000', '0.0000') tailR0avg=0.0985
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     2   23   24    6    0
     0   14   73   35    4
     0    3   22   84    7
     0    0    1    8   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     3   16   23   11    0
     0   11   65   43    0
     0    1   20  112    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   26   40    3    0
     0   17  102   32    0
     0    3   29   70    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=0.6051 
[epoch 24] step 4/44: loss=0.6021 
[epoch 24] step 6/44: loss=0.5959 
[epoch 24] step 8/44: loss=0.5917 
[epoch 24] step 10/44: loss=0.5846 
[epoch 24] step 12/44: loss=0.5864 
[epoch 24] step 14/44: loss=0.5809 
[epoch 24] step 16/44: loss=0.5757 
[epoch 24] step 18/44: loss=0.5746 
[epoch 24] step 20/44: loss=0.5739 
[epoch 24] step 22/44: loss=0.5724 
[epoch 24] step 24/44: loss=0.5687 
[epoch 24] step 26/44: loss=0.5696 
[epoch 24] step 28/44: loss=0.5704 
[epoch 24] step 30/44: loss=0.5716 
[epoch 24] step 32/44: loss=0.5708 
[epoch 24] step 34/44: loss=0.5720 
[epoch 24] step 36/44: loss=0.5732 
[epoch 24] step 38/44: loss=0.5730 
[epoch 24] step 40/44: loss=0.5730 
[epoch 24] step 42/44: loss=0.5739 
[epoch 24] step 44/44: loss=0.5781 
[epoch 24] train_loss(avg per step)=1.1561 lambda[min,max]=[0.360976,1.000000]
[epoch 24] val_loss=1.3949 qwk=('0.6328', '0.5705', '0.5837') averageQWK=0.5957 macroEMD=0.2830 tailR0=('0.2955', '0.1333', '0.0000') tailR0avg=0.1429
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     8   13   29    4    1
     0    8   87   26    5
     0    0   27   78   11
     0    0    2    7   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     3   17   25    8    0
     1   11   74   33    0
     1    5   22  102    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   30   38    1    0
     0   23  107   21    0
     0    3   34   65    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=0.5227 
[epoch 25] step 4/44: loss=0.5349 
[epoch 25] step 6/44: loss=0.5330 
[epoch 25] step 8/44: loss=0.5294 
[epoch 25] step 10/44: loss=0.5405 
[epoch 25] step 12/44: loss=0.5427 
[epoch 25] step 14/44: loss=0.5437 
[epoch 25] step 16/44: loss=0.5505 
[epoch 25] step 18/44: loss=0.5564 
[epoch 25] step 20/44: loss=0.5587 
[epoch 25] step 22/44: loss=0.5642 
[epoch 25] step 24/44: loss=0.5644 
[epoch 25] step 26/44: loss=0.5645 
[epoch 25] step 28/44: loss=0.5637 
[epoch 25] step 30/44: loss=0.5662 
[epoch 25] step 32/44: loss=0.5685 
[epoch 25] step 34/44: loss=0.5718 
[epoch 25] step 36/44: loss=0.5732 
[epoch 25] step 38/44: loss=0.5729 
[epoch 25] step 40/44: loss=0.5705 
[epoch 25] step 42/44: loss=0.5700 
[epoch 25] step 44/44: loss=0.5663 
[epoch 25] train_loss(avg per step)=1.1325 lambda[min,max]=[0.346570,1.000000]
[epoch 25] val_loss=1.3946 qwk=('0.5983', '0.5958', '0.5624') averageQWK=0.5855 macroEMD=0.2861 tailR0=('0.2955', '0.1333', '0.0000') tailR0avg=0.1429
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     3   17   30    4    1
     0    8   93   21    4
     0    3   32   74    7
     0    0    3    6   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    1    1    0
     2   17   27    7    0
     0   11   79   28    1
     0    5   22  105    2
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   28   41    0    0
     0   24  109   18    0
     0    3   40   59    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=0.5824 
[epoch 26] step 4/44: loss=0.5526 
[epoch 26] step 6/44: loss=0.5553 
[epoch 26] step 8/44: loss=0.5603 
[epoch 26] step 10/44: loss=0.5588 
[epoch 26] step 12/44: loss=0.5611 
[epoch 26] step 14/44: loss=0.5561 
[epoch 26] step 16/44: loss=0.5596 
[epoch 26] step 18/44: loss=0.5573 
[epoch 26] step 20/44: loss=0.5580 
[epoch 26] step 22/44: loss=0.5615 
[epoch 26] step 24/44: loss=0.5600 
[epoch 26] step 26/44: loss=0.5555 
[epoch 26] step 28/44: loss=0.5589 
[epoch 26] step 30/44: loss=0.5572 
[epoch 26] step 32/44: loss=0.5568 
[epoch 26] step 34/44: loss=0.5574 
[epoch 26] step 36/44: loss=0.5582 
[epoch 26] step 38/44: loss=0.5591 
[epoch 26] step 40/44: loss=0.5608 
[epoch 26] step 42/44: loss=0.5601 
[epoch 26] step 44/44: loss=0.5572 
[epoch 26] train_loss(avg per step)=1.1145 lambda[min,max]=[0.362190,1.000000]
[epoch 26] val_loss=1.4048 qwk=('0.6177', '0.6239', '0.5632') averageQWK=0.6016 macroEMD=0.2814 tailR0=('0.2955', '0.1750', '0.1000') tailR0avg=0.1902
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     4   18   27    5    1
     0   15   77   30    4
     0    3   24   75   14
     0    0    1    8   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    3    0    0
     4   15   31    3    0
     0    9   82   26    2
     0    3   30   96    5
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   21   45    3    0
     0   11  118   22    0
     0    3   31   68    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=0.5905 
[epoch 27] step 4/44: loss=0.6058 
[epoch 27] step 6/44: loss=0.5877 
[epoch 27] step 8/44: loss=0.5778 
[epoch 27] step 10/44: loss=0.5721 
[epoch 27] step 12/44: loss=0.5725 
[epoch 27] step 14/44: loss=0.5686 
[epoch 27] step 16/44: loss=0.5677 
[epoch 27] step 18/44: loss=0.5714 
[epoch 27] step 20/44: loss=0.5711 
[epoch 27] step 22/44: loss=0.5696 
[epoch 27] step 24/44: loss=0.5688 
[epoch 27] step 26/44: loss=0.5663 
[epoch 27] step 28/44: loss=0.5649 
[epoch 27] step 30/44: loss=0.5635 
[epoch 27] step 32/44: loss=0.5642 
[epoch 27] step 34/44: loss=0.5625 
[epoch 27] step 36/44: loss=0.5625 
[epoch 27] step 38/44: loss=0.5628 
[epoch 27] step 40/44: loss=0.5620 
[epoch 27] step 42/44: loss=0.5622 
[epoch 27] step 44/44: loss=0.5627 
[epoch 27] train_loss(avg per step)=1.1254 lambda[min,max]=[0.352495,1.000000]
[epoch 27] val_loss=1.3974 qwk=('0.6116', '0.6228', '0.5570') averageQWK=0.5972 macroEMD=0.2768 tailR0=('0.2727', '0.1333', '0.1000') tailR0avg=0.1687
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     5   15   30    4    1
     0   13   83   26    4
     0    3   26   78    9
     0    0    2    8   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    3    0    0
     4   14   31    4    0
     0    9   81   29    0
     0    3   28  101    2
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   25   41    3    0
     0   21  103   27    0
     0    3   31   68    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=0.5839 
[epoch 28] step 4/44: loss=0.5619 
[epoch 28] step 6/44: loss=0.5706 
[epoch 28] step 8/44: loss=0.5661 
[epoch 28] step 10/44: loss=0.5645 
[epoch 28] step 12/44: loss=0.5667 
[epoch 28] step 14/44: loss=0.5647 
[epoch 28] step 16/44: loss=0.5627 
[epoch 28] step 18/44: loss=0.5615 
[epoch 28] step 20/44: loss=0.5601 
[epoch 28] step 22/44: loss=0.5636 
[epoch 28] step 24/44: loss=0.5633 
[epoch 28] step 26/44: loss=0.5625 
[epoch 28] step 28/44: loss=0.5611 
[epoch 28] step 30/44: loss=0.5605 
[epoch 28] step 32/44: loss=0.5587 
[epoch 28] step 34/44: loss=0.5572 
[epoch 28] step 36/44: loss=0.5565 
[epoch 28] step 38/44: loss=0.5549 
[epoch 28] step 40/44: loss=0.5552 
[epoch 28] step 42/44: loss=0.5568 
[epoch 28] step 44/44: loss=0.5590 
[epoch 28] train_loss(avg per step)=1.1179 lambda[min,max]=[0.360908,1.000000]
[epoch 28] val_loss=1.4041 qwk=('0.6063', '0.5824', '0.5805') averageQWK=0.5897 macroEMD=0.2840 tailR0=('0.2727', '0.0500', '0.1000') tailR0avg=0.1409
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     2   15   31    7    0
     0   12   82   29    3
     0    2   27   79    8
     0    0    3    7   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    1    1    0
     1   21   24    7    0
     0   15   69   35    0
     0    6   18  107    3
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   26   42    1    0
     0   18  114   19    0
     0    3   35   64    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=0.5643 
[epoch 29] step 4/44: loss=0.5842 
[epoch 29] step 6/44: loss=0.5919 
[epoch 29] step 8/44: loss=0.5820 
[epoch 29] step 10/44: loss=0.5774 
[epoch 29] step 12/44: loss=0.5710 
[epoch 29] step 14/44: loss=0.5698 
[epoch 29] step 16/44: loss=0.5682 
[epoch 29] step 18/44: loss=0.5615 
[epoch 29] step 20/44: loss=0.5564 
[epoch 29] step 22/44: loss=0.5545 
[epoch 29] step 24/44: loss=0.5550 
[epoch 29] step 26/44: loss=0.5544 
[epoch 29] step 28/44: loss=0.5541 
[epoch 29] step 30/44: loss=0.5552 
[epoch 29] step 32/44: loss=0.5554 
[epoch 29] step 34/44: loss=0.5570 
[epoch 29] step 36/44: loss=0.5577 
[epoch 29] step 38/44: loss=0.5593 
[epoch 29] step 40/44: loss=0.5605 
[epoch 29] step 42/44: loss=0.5603 
[epoch 29] step 44/44: loss=0.5600 
[epoch 29] train_loss(avg per step)=1.1201 lambda[min,max]=[0.352705,1.000000]
[epoch 29] val_loss=1.4256 qwk=('0.6096', '0.5781', '0.5927') averageQWK=0.5935 macroEMD=0.2820 tailR0=('0.3510', '0.0917', '0.1000') tailR0avg=0.1809
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     6   11   31    6    1
     0   11   84   27    4
     0    2   26   76   12
     0    0    2    7   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    1    1    0
     2   20   21   10    0
     1   14   68   36    0
     0    5   21  107    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   32   34    3    0
     0   21  106   24    0
     0    3   31   68    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=0.5542 
[epoch 30] step 4/44: loss=0.5499 
[epoch 30] step 6/44: loss=0.5481 
[epoch 30] step 8/44: loss=0.5449 
[epoch 30] step 10/44: loss=0.5413 
[epoch 30] step 12/44: loss=0.5388 
[epoch 30] step 14/44: loss=0.5354 
[epoch 30] step 16/44: loss=0.5382 
[epoch 30] step 18/44: loss=0.5419 
[epoch 30] step 20/44: loss=0.5438 
[epoch 30] step 22/44: loss=0.5472 
[epoch 30] step 24/44: loss=0.5501 
[epoch 30] step 26/44: loss=0.5527 
[epoch 30] step 28/44: loss=0.5531 
[epoch 30] step 30/44: loss=0.5548 
[epoch 30] step 32/44: loss=0.5568 
[epoch 30] step 34/44: loss=0.5582 
[epoch 30] step 36/44: loss=0.5579 
[epoch 30] step 38/44: loss=0.5572 
[epoch 30] step 40/44: loss=0.5549 
[epoch 30] step 42/44: loss=0.5532 
[epoch 30] step 44/44: loss=0.5517 
[epoch 30] train_loss(avg per step)=1.1033 lambda[min,max]=[0.359873,1.000000]
[epoch 30] val_loss=1.4043 qwk=('0.6134', '0.5959', '0.5898') averageQWK=0.5997 macroEMD=0.2846 tailR0=('0.2955', '0.0917', '0.1000') tailR0avg=0.1624
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     4   17   28    5    1
     0   14   75   33    4
     0    3   23   80   10
     0    0    1    8   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    1    1    0
     4   15   27    7    0
     0   11   78   30    0
     0    3   28  101    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   27   41    1    0
     0   15  117   19    0
     0    3   35   64    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=0.5098 
[epoch 31] step 4/44: loss=0.5190 
[epoch 31] step 6/44: loss=0.5276 
[epoch 31] step 8/44: loss=0.5231 
[epoch 31] step 10/44: loss=0.5198 
[epoch 31] step 12/44: loss=0.5274 
[epoch 31] step 14/44: loss=0.5297 
[epoch 31] step 16/44: loss=0.5305 
[epoch 31] step 18/44: loss=0.5333 
[epoch 31] step 20/44: loss=0.5378 
[epoch 31] step 22/44: loss=0.5444 
[epoch 31] step 24/44: loss=0.5480 
[epoch 31] step 26/44: loss=0.5502 
[epoch 31] step 28/44: loss=0.5527 
[epoch 31] step 30/44: loss=0.5540 
[epoch 31] step 32/44: loss=0.5532 
[epoch 31] step 34/44: loss=0.5523 
[epoch 31] step 36/44: loss=0.5532 
[epoch 31] step 38/44: loss=0.5532 
[epoch 31] step 40/44: loss=0.5536 
[epoch 31] step 42/44: loss=0.5528 
[epoch 31] step 44/44: loss=0.5528 
[epoch 31] train_loss(avg per step)=1.1056 lambda[min,max]=[0.352048,1.000000]
[epoch 31] val_loss=1.4177 qwk=('0.6067', '0.5941', '0.5694') averageQWK=0.5900 macroEMD=0.2821 tailR0=('0.2955', '0.1333', '0.1000') tailR0avg=0.1763
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     2   18   28    6    1
     0   14   80   28    4
     0    3   26   76   11
     0    0    1    8   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    1    1    0
     2   18   26    7    0
     0   11   78   30    0
     0    4   28   96    6
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   26   40    3    0
     0   15  115   21    0
     0    3   34   65    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=0.5595 
[epoch 32] step 4/44: loss=0.5432 
[epoch 32] step 6/44: loss=0.5394 
[epoch 32] step 8/44: loss=0.5348 
[epoch 32] step 10/44: loss=0.5345 
[epoch 32] step 12/44: loss=0.5377 
[epoch 32] step 14/44: loss=0.5337 
[epoch 32] step 16/44: loss=0.5325 
[epoch 32] step 18/44: loss=0.5331 
[epoch 32] step 20/44: loss=0.5352 
[epoch 32] step 22/44: loss=0.5357 
[epoch 32] step 24/44: loss=0.5360 
[epoch 32] step 26/44: loss=0.5367 
[epoch 32] step 28/44: loss=0.5409 
[epoch 32] step 30/44: loss=0.5409 
[epoch 32] step 32/44: loss=0.5408 
[epoch 32] step 34/44: loss=0.5412 
[epoch 32] step 36/44: loss=0.5427 
[epoch 32] step 38/44: loss=0.5438 
[epoch 32] step 40/44: loss=0.5426 
[epoch 32] step 42/44: loss=0.5436 
[epoch 32] step 44/44: loss=0.5423 
[epoch 32] train_loss(avg per step)=1.0846 lambda[min,max]=[0.381538,1.000000]
[epoch 32] val_loss=1.3980 qwk=('0.6130', '0.5826', '0.5853') averageQWK=0.5936 macroEMD=0.2822 tailR0=('0.2955', '0.0417', '0.1000') tailR0avg=0.1457
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     3   15   31    4    2
     0   13   85   24    4
     0    3   26   76   11
     0    0    1    8   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     2   18   25    8    0
     0   11   75   33    0
     0    4   24  105    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   27   41    1    0
     0   14  117   20    0
     0    3   36   63    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=0.5327 
[epoch 33] step 4/44: loss=0.5299 
[epoch 33] step 6/44: loss=0.5270 
[epoch 33] step 8/44: loss=0.5292 
[epoch 33] step 10/44: loss=0.5327 
[epoch 33] step 12/44: loss=0.5393 
[epoch 33] step 14/44: loss=0.5459 
[epoch 33] step 16/44: loss=0.5467 
[epoch 33] step 18/44: loss=0.5517 
[epoch 33] step 20/44: loss=0.5523 
[epoch 33] step 22/44: loss=0.5514 
[epoch 33] step 24/44: loss=0.5496 
[epoch 33] step 26/44: loss=0.5504 
[epoch 33] step 28/44: loss=0.5479 
[epoch 33] step 30/44: loss=0.5463 
[epoch 33] step 32/44: loss=0.5455 
[epoch 33] step 34/44: loss=0.5453 
[epoch 33] step 36/44: loss=0.5458 
[epoch 33] step 38/44: loss=0.5458 
[epoch 33] step 40/44: loss=0.5460 
[epoch 33] step 42/44: loss=0.5449 
[epoch 33] step 44/44: loss=0.5443 
[epoch 33] train_loss(avg per step)=1.0886 lambda[min,max]=[0.366957,1.000000]
[epoch 33] val_loss=1.4053 qwk=('0.5802', '0.5744', '0.5815') averageQWK=0.5787 macroEMD=0.2824 tailR0=('0.2955', '0.0917', '0.1000') tailR0avg=0.1624
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     4   14   30    5    2
     0   15   78   29    4
     0    4   24   79    9
     0    0    1    8   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     4   14   25   10    0
     0    9   74   36    0
     0    3   21  109    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   29   37    3    0
     0   20  107   24    0
     0    3   31   68    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=0.5441 
[epoch 34] step 4/44: loss=0.5418 
[epoch 34] step 6/44: loss=0.5441 
[epoch 34] step 8/44: loss=0.5431 
[epoch 34] step 10/44: loss=0.5484 
[epoch 34] step 12/44: loss=0.5406 
[epoch 34] step 14/44: loss=0.5436 
[epoch 34] step 16/44: loss=0.5420 
[epoch 34] step 18/44: loss=0.5441 
[epoch 34] step 20/44: loss=0.5431 
[epoch 34] step 22/44: loss=0.5444 
[epoch 34] step 24/44: loss=0.5476 
[epoch 34] step 26/44: loss=0.5484 
[epoch 34] step 28/44: loss=0.5490 
[epoch 34] step 30/44: loss=0.5477 
[epoch 34] step 32/44: loss=0.5468 
[epoch 34] step 34/44: loss=0.5473 
[epoch 34] step 36/44: loss=0.5477 
[epoch 34] step 38/44: loss=0.5471 
[epoch 34] step 40/44: loss=0.5473 
[epoch 34] step 42/44: loss=0.5460 
[epoch 34] step 44/44: loss=0.5466 
[epoch 34] train_loss(avg per step)=1.0932 lambda[min,max]=[0.364663,1.000000]
[epoch 34] val_loss=1.4096 qwk=('0.6130', '0.5826', '0.5833') averageQWK=0.5930 macroEMD=0.2832 tailR0=('0.2955', '0.0417', '0.1000') tailR0avg=0.1457
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     3   18   28    5    1
     0   14   81   27    4
     0    4   24   79    9
     0    0    1    8   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     3   16   26    8    0
     0   11   75   33    0
     0    3   26  104    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   26   41    2    0
     0   14  114   23    0
     0    3   32   67    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=0.5293 
[epoch 35] step 4/44: loss=0.5400 
[epoch 35] step 6/44: loss=0.5390 
[epoch 35] step 8/44: loss=0.5406 
[epoch 35] step 10/44: loss=0.5437 
[epoch 35] step 12/44: loss=0.5409 
[epoch 35] step 14/44: loss=0.5467 
[epoch 35] step 16/44: loss=0.5464 
[epoch 35] step 18/44: loss=0.5466 
[epoch 35] step 20/44: loss=0.5452 
[epoch 35] step 22/44: loss=0.5459 
[epoch 35] step 24/44: loss=0.5433 
[epoch 35] step 26/44: loss=0.5443 
[epoch 35] step 28/44: loss=0.5455 
[epoch 35] step 30/44: loss=0.5469 
[epoch 35] step 32/44: loss=0.5455 
[epoch 35] step 34/44: loss=0.5431 
[epoch 35] step 36/44: loss=0.5431 
[epoch 35] step 38/44: loss=0.5412 
[epoch 35] step 40/44: loss=0.5378 
[epoch 35] step 42/44: loss=0.5395 
[epoch 35] step 44/44: loss=0.5404 
[epoch 35] train_loss(avg per step)=1.0809 lambda[min,max]=[0.375335,1.000000]
[epoch 35] val_loss=1.4001 qwk=('0.6114', '0.5764', '0.5942') averageQWK=0.5940 macroEMD=0.2826 tailR0=('0.2955', '0.0500', '0.1000') tailR0avg=0.1485
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     3   18   27    6    1
     0   13   81   28    4
     0    3   25   79    9
     0    0    1    8   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    1    1    0
     4   15   24   10    0
     0   10   72   37    0
     0    3   22  108    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   29   38    2    0
     0   18  110   23    0
     0    3   31   68    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold3/metrics.json
Done.
