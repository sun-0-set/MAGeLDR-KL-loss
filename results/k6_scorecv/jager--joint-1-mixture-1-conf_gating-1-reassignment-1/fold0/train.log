[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.5766 
[epoch 1] step 4/44: loss=6.1920 
[epoch 1] step 6/44: loss=6.0710 
[epoch 1] step 8/44: loss=5.9605 
[epoch 1] step 10/44: loss=5.8685 
[epoch 1] step 12/44: loss=5.8526 
[epoch 1] step 14/44: loss=5.8736 
[epoch 1] step 16/44: loss=5.9060 
[epoch 1] step 18/44: loss=5.9758 
[epoch 1] step 20/44: loss=5.9595 
[epoch 1] step 22/44: loss=5.9706 
[epoch 1] step 24/44: loss=6.0121 
[epoch 1] step 26/44: loss=5.9980 
[epoch 1] step 28/44: loss=5.9775 
[epoch 1] step 30/44: loss=6.0007 
[epoch 1] step 32/44: loss=6.0573 
[epoch 1] step 34/44: loss=6.0944 
[epoch 1] step 36/44: loss=6.1328 
[epoch 1] step 38/44: loss=6.1798 
[epoch 1] step 40/44: loss=6.2179 
[epoch 1] step 42/44: loss=6.2374 
[epoch 1] step 44/44: loss=6.3480 
[epoch 1] train_loss(avg per step)=12.6960 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=6.6199 qwk=('0.1412', '0.1151', '0.1290') averageQWK=0.1285 macroEMD=0.3824 tailR0=('0.0000', '0.1111', '0.0000') tailR0avg=0.0370
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    5    0
     0   26    0   29    0
     0   63    0   62    0
     0   45    0   71    0
     0    3    0   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    6    1    0
    21    0   23    8    0
    49    0   34   38    0
    39    0   34   61    0
     3    0    4    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0    4   64    1    0
     0    4  142    5    0
     0    1   89   11    0
     0    0    2    0    0
[epoch 2] step 2/44: loss=9.8317 
[epoch 2] step 4/44: loss=9.7366 
[epoch 2] step 6/44: loss=10.0571 
[epoch 2] step 8/44: loss=10.1656 
[epoch 2] step 10/44: loss=10.3424 
[epoch 2] step 12/44: loss=10.4812 
[epoch 2] step 14/44: loss=10.6743 
[epoch 2] step 16/44: loss=10.8516 
[epoch 2] step 18/44: loss=10.9993 
[epoch 2] step 20/44: loss=11.1069 
[epoch 2] step 22/44: loss=11.2063 
[epoch 2] step 24/44: loss=11.2474 
[epoch 2] step 26/44: loss=11.2736 
[epoch 2] step 28/44: loss=11.3696 
[epoch 2] step 30/44: loss=11.4631 
[epoch 2] step 32/44: loss=11.5364 
[epoch 2] step 34/44: loss=11.5715 
[epoch 2] step 36/44: loss=11.6207 
[epoch 2] step 38/44: loss=11.6963 
[epoch 2] step 40/44: loss=11.7634 
[epoch 2] step 42/44: loss=11.8510 
[epoch 2] step 44/44: loss=11.9086 
[epoch 2] train_loss(avg per step)=23.8171 lambda[min,max]=[0.502026,1.000000]
[epoch 2] val_loss=13.3399 qwk=('0.2727', '0.1104', '0.4170') averageQWK=0.2667 macroEMD=0.3936 tailR0=('0.0000', '0.0000', '0.1000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    2    2
     0   29    8   15    3
     0   30   12   75    8
     0   17    9   80   10
     0    3    1   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    3    6    0
     0    0   12   40    0
     0    0    3  118    0
     0    0    0  134    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    3    0    0
    32    1   24   12    0
    27    1   50   73    0
     4    0   19   78    0
     0    0    1    1    0
[epoch 3] step 2/44: loss=11.5909 
[epoch 3] step 4/44: loss=11.7051 
[epoch 3] step 6/44: loss=12.1563 
[epoch 3] step 8/44: loss=12.2211 
[epoch 3] step 10/44: loss=12.5597 
[epoch 3] step 12/44: loss=12.5997 
[epoch 3] step 14/44: loss=12.6645 
[epoch 3] step 16/44: loss=12.6840 
[epoch 3] step 18/44: loss=12.6433 
[epoch 3] step 20/44: loss=12.6537 
[epoch 3] step 22/44: loss=12.7297 
[epoch 3] step 24/44: loss=12.7888 
[epoch 3] step 26/44: loss=12.8383 
[epoch 3] step 28/44: loss=12.8254 
[epoch 3] step 30/44: loss=12.8063 
[epoch 3] step 32/44: loss=12.7998 
[epoch 3] step 34/44: loss=12.7814 
[epoch 3] step 36/44: loss=12.7940 
[epoch 3] step 38/44: loss=12.7472 
[epoch 3] step 40/44: loss=12.6750 
[epoch 3] step 42/44: loss=12.6107 
[epoch 3] step 44/44: loss=12.6004 
[epoch 3] train_loss(avg per step)=25.2008 lambda[min,max]=[0.546522,1.000000]
[epoch 3] val_loss=14.2248 qwk=('0.3781', '0.3903', '0.2483') averageQWK=0.3389 macroEMD=0.3846 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    0   48    7    0
     0    0   75   50    0
     0    0   24   92    0
     0    0    5   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0    5   31   16    0
     0    1   39   81    0
     0    0    4  130    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    3   65    1    0
     0    0  143    8    0
     0    1   71   29    0
     0    0    1    1    0
[epoch 4] step 2/44: loss=13.7166 
[epoch 4] step 4/44: loss=13.2651 
[epoch 4] step 6/44: loss=12.9365 
[epoch 4] step 8/44: loss=12.6708 
[epoch 4] step 10/44: loss=12.6134 
[epoch 4] step 12/44: loss=12.4022 
[epoch 4] step 14/44: loss=12.2720 
[epoch 4] step 16/44: loss=12.1704 
[epoch 4] step 18/44: loss=12.1698 
[epoch 4] step 20/44: loss=12.1016 
[epoch 4] step 22/44: loss=12.1250 
[epoch 4] step 24/44: loss=12.0471 
[epoch 4] step 26/44: loss=11.8855 
[epoch 4] step 28/44: loss=11.7709 
[epoch 4] step 30/44: loss=11.6845 
[epoch 4] step 32/44: loss=11.7131 
[epoch 4] step 34/44: loss=11.7292 
[epoch 4] step 36/44: loss=11.7112 
[epoch 4] step 38/44: loss=11.6677 
[epoch 4] step 40/44: loss=11.5750 
[epoch 4] step 42/44: loss=11.5268 
[epoch 4] step 44/44: loss=11.4505 
[epoch 4] train_loss(avg per step)=22.9009 lambda[min,max]=[0.525829,1.000000]
[epoch 4] val_loss=13.0848 qwk=('0.2977', '0.5041', '0.0216') averageQWK=0.2744 macroEMD=0.3865 tailR0=('0.4517', '0.0000', '0.0000') tailR0avg=0.1506
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     5    1    1    0    2
    34    3    6    1   11
    68    0    4   23   30
    21    0    1   71   23
     3    0    0   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    4   42    6    0
     0    1   81   39    0
     0    0   19  115    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    2   67    0    0
     0    0  151    0    0
     0    0  101    0    0
     0    0    2    0    0
[epoch 5] step 2/44: loss=10.7600 
[epoch 5] step 4/44: loss=11.1775 
[epoch 5] step 6/44: loss=11.0070 
[epoch 5] step 8/44: loss=10.7007 
[epoch 5] step 10/44: loss=10.2825 
[epoch 5] step 12/44: loss=10.1218 
[epoch 5] step 14/44: loss=10.0370 
[epoch 5] step 16/44: loss=10.1539 
[epoch 5] step 18/44: loss=10.2475 
[epoch 5] step 20/44: loss=10.2526 
[epoch 5] step 22/44: loss=10.2648 
[epoch 5] step 24/44: loss=10.1933 
[epoch 5] step 26/44: loss=10.0538 
[epoch 5] step 28/44: loss=10.0265 
[epoch 5] step 30/44: loss=10.0026 
[epoch 5] step 32/44: loss=10.0004 
[epoch 5] step 34/44: loss=10.0544 
[epoch 5] step 36/44: loss=10.0278 
[epoch 5] step 38/44: loss=9.9915 
[epoch 5] step 40/44: loss=9.9234 
[epoch 5] step 42/44: loss=9.8404 
[epoch 5] step 44/44: loss=9.8036 
[epoch 5] train_loss(avg per step)=19.6073 lambda[min,max]=[0.500196,1.000000]
[epoch 5] val_loss=11.3287 qwk=('0.4546', '0.3395', '0.5265') averageQWK=0.4402 macroEMD=0.3798 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    2
     0    3   45    6    1
     0    1   86   35    3
     0    0   14  101    1
     0    0    1   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    2    0
     0    3   27   22    0
     0    1   28   92    0
     0    0    1  133    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   53    0   16    0
     0   57    0   94    0
     0    3    0   98    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=9.1048 
[epoch 6] step 4/44: loss=9.7820 
[epoch 6] step 6/44: loss=9.9981 
[epoch 6] step 8/44: loss=9.7606 
[epoch 6] step 10/44: loss=9.5816 
[epoch 6] step 12/44: loss=9.4883 
[epoch 6] step 14/44: loss=9.4200 
[epoch 6] step 16/44: loss=9.4166 
[epoch 6] step 18/44: loss=9.2505 
[epoch 6] step 20/44: loss=9.1271 
[epoch 6] step 22/44: loss=9.0113 
[epoch 6] step 24/44: loss=8.9337 
[epoch 6] step 26/44: loss=8.8872 
[epoch 6] step 28/44: loss=8.9579 
[epoch 6] step 30/44: loss=8.9938 
[epoch 6] step 32/44: loss=9.0020 
[epoch 6] step 34/44: loss=9.0355 
[epoch 6] step 36/44: loss=8.9829 
[epoch 6] step 38/44: loss=8.9416 
[epoch 6] step 40/44: loss=8.8710 
[epoch 6] step 42/44: loss=8.8643 
[epoch 6] step 44/44: loss=8.8691 
[epoch 6] train_loss(avg per step)=17.7381 lambda[min,max]=[0.500025,1.000000]
[epoch 6] val_loss=10.4191 qwk=('0.4168', '0.3981', '0.3869') averageQWK=0.4006 macroEMD=0.3737 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0   14   22   19    0
     0    3   42   80    0
     0    0    6  110    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    2    0
     0   11   19   22    0
     0    5   31   85    0
     0    0    1  133    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     1   26   14   28    0
     0   10   24  117    0
     0    0    0  101    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=9.6227 
[epoch 7] step 4/44: loss=9.4310 
[epoch 7] step 6/44: loss=9.2243 
[epoch 7] step 8/44: loss=9.0841 
[epoch 7] step 10/44: loss=9.1896 
[epoch 7] step 12/44: loss=9.0318 
[epoch 7] step 14/44: loss=8.7057 
[epoch 7] step 16/44: loss=8.5575 
[epoch 7] step 18/44: loss=8.5894 
[epoch 7] step 20/44: loss=8.6325 
[epoch 7] step 22/44: loss=8.6357 
[epoch 7] step 24/44: loss=8.5936 
[epoch 7] step 26/44: loss=8.5164 
[epoch 7] step 28/44: loss=8.4338 
[epoch 7] step 30/44: loss=8.4820 
[epoch 7] step 32/44: loss=8.5779 
[epoch 7] step 34/44: loss=8.5912 
[epoch 7] step 36/44: loss=8.6172 
[epoch 7] step 38/44: loss=8.6449 
[epoch 7] step 40/44: loss=8.6626 
[epoch 7] step 42/44: loss=8.6401 
[epoch 7] step 44/44: loss=8.6348 
[epoch 7] train_loss(avg per step)=17.2696 lambda[min,max]=[0.500002,1.000000]
[epoch 7] val_loss=10.3445 qwk=('0.3757', '0.5159', '0.6585') averageQWK=0.5167 macroEMD=0.3814 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    3
     1   16   26    6    6
     2    4   48   62    9
     1    0    6  101    8
     0    0    1   19    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   51    1    0
     0    0  100   21    0
     0    0   31  103    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   47   20    2    0
     0   38   91   22    0
     0    4   20   77    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=7.0004 
[epoch 8] step 4/44: loss=6.8518 
[epoch 8] step 6/44: loss=7.1911 
[epoch 8] step 8/44: loss=7.4540 
[epoch 8] step 10/44: loss=7.7827 
[epoch 8] step 12/44: loss=7.8845 
[epoch 8] step 14/44: loss=7.8899 
[epoch 8] step 16/44: loss=7.9621 
[epoch 8] step 18/44: loss=8.0546 
[epoch 8] step 20/44: loss=8.1571 
[epoch 8] step 22/44: loss=8.1485 
[epoch 8] step 24/44: loss=8.0129 
[epoch 8] step 26/44: loss=7.9348 
[epoch 8] step 28/44: loss=7.8279 
[epoch 8] step 30/44: loss=7.8011 
[epoch 8] step 32/44: loss=7.8490 
[epoch 8] step 34/44: loss=7.9407 
[epoch 8] step 36/44: loss=7.9982 
[epoch 8] step 38/44: loss=8.0453 
[epoch 8] step 40/44: loss=8.0865 
[epoch 8] step 42/44: loss=8.0658 
[epoch 8] step 44/44: loss=8.0542 
[epoch 8] train_loss(avg per step)=16.1083 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=9.7718 qwk=('0.3757', '0.3483', '0.5304') averageQWK=0.4181 macroEMD=0.3763 tailR0=('0.0773', '0.0556', '0.0000') tailR0avg=0.0443
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    6    1    1
     2    1   39    9    4
     1    1   53   68    2
     0    0    8  106    2
     0    0    1   21    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    6    2    0
     2    0   29   21    0
     0    0   34   87    0
     0    0    3  131    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    6   62    1    0
     0    2  122   27    0
     0    0   23   78    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=7.6806 
[epoch 9] step 4/44: loss=7.9846 
[epoch 9] step 6/44: loss=7.9853 
[epoch 9] step 8/44: loss=7.8521 
[epoch 9] step 10/44: loss=8.0079 
[epoch 9] step 12/44: loss=7.9941 
[epoch 9] step 14/44: loss=7.9813 
[epoch 9] step 16/44: loss=7.9728 
[epoch 9] step 18/44: loss=8.0290 
[epoch 9] step 20/44: loss=8.0492 
[epoch 9] step 22/44: loss=7.9995 
[epoch 9] step 24/44: loss=8.0941 
[epoch 9] step 26/44: loss=8.1630 
[epoch 9] step 28/44: loss=8.2245 
[epoch 9] step 30/44: loss=8.1745 
[epoch 9] step 32/44: loss=8.1010 
[epoch 9] step 34/44: loss=8.0086 
[epoch 9] step 36/44: loss=7.9907 
[epoch 9] step 38/44: loss=8.0208 
[epoch 9] step 40/44: loss=8.0386 
[epoch 9] step 42/44: loss=8.0682 
[epoch 9] step 44/44: loss=8.0895 
[epoch 9] train_loss(avg per step)=16.1789 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=9.7933 qwk=('0.5468', '0.6147', '0.6080') averageQWK=0.5898 macroEMD=0.3698 tailR0=('0.1111', '0.0000', '0.0000') tailR0avg=0.0370
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    6    1    0
     4    2   46    3    0
     1    1   94   29    0
     0    0   23   93    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   48    0    4    0
     0   78    7   36    0
     0   15    1  118    0
     0    1    0   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   45   16    8    0
     0   29   51   71    0
     0    2    2   97    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=8.3762 
[epoch 10] step 4/44: loss=8.2478 
[epoch 10] step 6/44: loss=8.3090 
[epoch 10] step 8/44: loss=8.4605 
[epoch 10] step 10/44: loss=8.5704 
[epoch 10] step 12/44: loss=8.3524 
[epoch 10] step 14/44: loss=8.1691 
[epoch 10] step 16/44: loss=8.0044 
[epoch 10] step 18/44: loss=7.8992 
[epoch 10] step 20/44: loss=7.7965 
[epoch 10] step 22/44: loss=7.7909 
[epoch 10] step 24/44: loss=7.9006 
[epoch 10] step 26/44: loss=8.0730 
[epoch 10] step 28/44: loss=8.2162 
[epoch 10] step 30/44: loss=8.2299 
[epoch 10] step 32/44: loss=8.1465 
[epoch 10] step 34/44: loss=8.0306 
[epoch 10] step 36/44: loss=7.9976 
[epoch 10] step 38/44: loss=7.9447 
[epoch 10] step 40/44: loss=7.9430 
[epoch 10] step 42/44: loss=7.9797 
[epoch 10] step 44/44: loss=7.9784 
[epoch 10] train_loss(avg per step)=15.9569 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=9.7497 qwk=('0.5559', '0.6319', '0.5960') averageQWK=0.5946 macroEMD=0.3682 tailR0=('0.3043', '0.0000', '0.0000') tailR0avg=0.1014
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   22   31    0    2
     0    6  109    4    6
     0    0   58   36   22
     0    0    8    1   14
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   34   13    5    0
     0   16   52   53    0
     0    3    6  125    0
     0    1    0   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   58    6    5    0
     0   71   29   51    0
     0    8    2   91    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=8.2758 
[epoch 11] step 4/44: loss=8.0447 
[epoch 11] step 6/44: loss=8.2047 
[epoch 11] step 8/44: loss=8.4502 
[epoch 11] step 10/44: loss=8.5456 
[epoch 11] step 12/44: loss=8.4532 
[epoch 11] step 14/44: loss=8.2804 
[epoch 11] step 16/44: loss=8.0859 
[epoch 11] step 18/44: loss=7.9108 
[epoch 11] step 20/44: loss=7.8811 
[epoch 11] step 22/44: loss=7.8302 
[epoch 11] step 24/44: loss=7.8696 
[epoch 11] step 26/44: loss=7.8920 
[epoch 11] step 28/44: loss=7.9950 
[epoch 11] step 30/44: loss=8.0191 
[epoch 11] step 32/44: loss=8.0639 
[epoch 11] step 34/44: loss=8.0123 
[epoch 11] step 36/44: loss=7.9440 
[epoch 11] step 38/44: loss=7.9148 
[epoch 11] step 40/44: loss=7.9150 
[epoch 11] step 42/44: loss=7.9496 
[epoch 11] step 44/44: loss=7.9838 
[epoch 11] train_loss(avg per step)=15.9676 lambda[min,max]=[0.538056,1.000000]
[epoch 11] val_loss=9.7298 qwk=('0.6339', '0.5945', '0.6181') averageQWK=0.6155 macroEMD=0.3669 tailR0=('0.2101', '0.0000', '0.0000') tailR0avg=0.0700
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    1    5    0    0
    14    5   33    2    1
     3    2  102   18    0
     0    0   31   83    2
     0    0    2   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   17   30    5    0
     0    6   74   41    0
     0    1   16  117    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   49   18    2    0
     0   43   69   39    0
     0    7   11   83    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=7.8304 
[epoch 12] step 4/44: loss=7.6167 
[epoch 12] step 6/44: loss=7.7976 
[epoch 12] step 8/44: loss=8.1628 
[epoch 12] step 10/44: loss=8.4727 
[epoch 12] step 12/44: loss=8.4412 
[epoch 12] step 14/44: loss=8.2775 
[epoch 12] step 16/44: loss=8.0813 
[epoch 12] step 18/44: loss=7.9371 
[epoch 12] step 20/44: loss=7.9191 
[epoch 12] step 22/44: loss=8.1029 
[epoch 12] step 24/44: loss=8.0933 
[epoch 12] step 26/44: loss=8.1722 
[epoch 12] step 28/44: loss=8.1710 
[epoch 12] step 30/44: loss=8.1054 
[epoch 12] step 32/44: loss=7.9804 
[epoch 12] step 34/44: loss=7.8635 
[epoch 12] step 36/44: loss=7.8271 
[epoch 12] step 38/44: loss=7.8701 
[epoch 12] step 40/44: loss=7.9586 
[epoch 12] step 42/44: loss=8.0056 
[epoch 12] step 44/44: loss=8.0395 
[epoch 12] train_loss(avg per step)=16.0789 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=9.9991 qwk=('0.6147', '0.6128', '0.6521') averageQWK=0.6265 macroEMD=0.3713 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   34   18    2    1
     0   21   79   24    1
     0    3   20   89    4
     0    1    3   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   23   23    6    0
     0   18   67   36    0
     0    2   15  117    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     1   46   21    1    0
     0   29   89   33    0
     0    4   16   81    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=7.1567 
[epoch 13] step 4/44: loss=6.8911 
[epoch 13] step 6/44: loss=7.1027 
[epoch 13] step 8/44: loss=7.4364 
[epoch 13] step 10/44: loss=7.5471 
[epoch 13] step 12/44: loss=7.5796 
[epoch 13] step 14/44: loss=7.6077 
[epoch 13] step 16/44: loss=7.6204 
[epoch 13] step 18/44: loss=7.6286 
[epoch 13] step 20/44: loss=7.6894 
[epoch 13] step 22/44: loss=7.6998 
[epoch 13] step 24/44: loss=7.7327 
[epoch 13] step 26/44: loss=7.7106 
[epoch 13] step 28/44: loss=7.7103 
[epoch 13] step 30/44: loss=7.7564 
[epoch 13] step 32/44: loss=7.8395 
[epoch 13] step 34/44: loss=7.8442 
[epoch 13] step 36/44: loss=7.8763 
[epoch 13] step 38/44: loss=7.8586 
[epoch 13] step 40/44: loss=7.7871 
[epoch 13] step 42/44: loss=7.8083 
[epoch 13] step 44/44: loss=7.7913 
[epoch 13] train_loss(avg per step)=15.5827 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=9.7643 qwk=('0.6130', '0.6261', '0.6516') averageQWK=0.6303 macroEMD=0.3665 tailR0=('0.3188', '0.0000', '0.0000') tailR0avg=0.1063
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    1    5    0    0
     8   22   24    0    1
     1   15  100    8    1
     0    0   50   56   10
     0    0    9    7    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     2   36   12    2    0
     0   39   64   18    0
     0    6   36   92    0
     0    1    1   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   51   18    0    0
     0   50   88   13    0
     0    5   27   69    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=7.9112 
[epoch 14] step 4/44: loss=8.3964 
[epoch 14] step 6/44: loss=8.6050 
[epoch 14] step 8/44: loss=8.7769 
[epoch 14] step 10/44: loss=8.9425 
[epoch 14] step 12/44: loss=8.9171 
[epoch 14] step 14/44: loss=8.6818 
[epoch 14] step 16/44: loss=8.4665 
[epoch 14] step 18/44: loss=8.3411 
[epoch 14] step 20/44: loss=8.2055 
[epoch 14] step 22/44: loss=8.0743 
[epoch 14] step 24/44: loss=8.0317 
[epoch 14] step 26/44: loss=8.0636 
[epoch 14] step 28/44: loss=8.0831 
[epoch 14] step 30/44: loss=8.0825 
[epoch 14] step 32/44: loss=8.0698 
[epoch 14] step 34/44: loss=8.0349 
[epoch 14] step 36/44: loss=7.9595 
[epoch 14] step 38/44: loss=7.9370 
[epoch 14] step 40/44: loss=8.0132 
[epoch 14] step 42/44: loss=8.0008 
[epoch 14] step 44/44: loss=7.9206 
[epoch 14] train_loss(avg per step)=15.8412 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=10.0654 qwk=('0.6121', '0.6385', '0.6045') averageQWK=0.6184 macroEMD=0.3667 tailR0=('0.1087', '0.0556', '0.0000') tailR0avg=0.0548
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   43   10    2    0
     0   46   47   30    2
     0    8   17   83    8
     0    2    1   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     5   30   10    7    0
     1   27   47   46    0
     0    2   12  120    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     1   48   16    4    0
     0   44   71   36    0
     0    7   10   84    0
     0    0    0    2    0
[epoch 15] step 2/44: loss=7.0558 
[epoch 15] step 4/44: loss=7.2480 
[epoch 15] step 6/44: loss=7.6380 
[epoch 15] step 8/44: loss=8.0890 
[epoch 15] step 10/44: loss=8.3242 
[epoch 15] step 12/44: loss=8.3654 
[epoch 15] step 14/44: loss=8.2099 
[epoch 15] step 16/44: loss=8.1212 
[epoch 15] step 18/44: loss=7.9804 
[epoch 15] step 20/44: loss=7.9120 
[epoch 15] step 22/44: loss=7.9253 
[epoch 15] step 24/44: loss=7.9565 
[epoch 15] step 26/44: loss=7.9665 
[epoch 15] step 28/44: loss=7.9422 
[epoch 15] step 30/44: loss=7.9670 
[epoch 15] step 32/44: loss=8.0071 
[epoch 15] step 34/44: loss=8.0364 
[epoch 15] step 36/44: loss=8.0294 
[epoch 15] step 38/44: loss=7.9953 
[epoch 15] step 40/44: loss=7.9495 
[epoch 15] step 42/44: loss=7.9568 
[epoch 15] step 44/44: loss=7.9593 
[epoch 15] train_loss(avg per step)=15.9186 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=10.1552 qwk=('0.5295', '0.5257', '0.5445') averageQWK=0.5332 macroEMD=0.3686 tailR0=('0.2536', '0.0556', '0.1000') tailR0avg=0.1364
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    4    2    0
     4    0   44    7    0
     2    0   77   45    1
     0    0   15   95    6
     0    0    2   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    0    0
     2    0   43    7    0
     2    1   74   44    0
     0    0   12  122    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    1    0
     2   23   36    8    0
     1   15   65   70    0
     0    1    4   96    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=8.6224 
[epoch 16] step 4/44: loss=8.0053 
[epoch 16] step 6/44: loss=7.7202 
[epoch 16] step 8/44: loss=7.4829 
[epoch 16] step 10/44: loss=7.3650 
[epoch 16] step 12/44: loss=7.4626 
[epoch 16] step 14/44: loss=7.7298 
[epoch 16] step 16/44: loss=7.9446 
[epoch 16] step 18/44: loss=7.9571 
[epoch 16] step 20/44: loss=7.8955 
[epoch 16] step 22/44: loss=7.9076 
[epoch 16] step 24/44: loss=7.7931 
[epoch 16] step 26/44: loss=7.8203 
[epoch 16] step 28/44: loss=7.8402 
[epoch 16] step 30/44: loss=7.8710 
[epoch 16] step 32/44: loss=7.8490 
[epoch 16] step 34/44: loss=7.8487 
[epoch 16] step 36/44: loss=7.8498 
[epoch 16] step 38/44: loss=7.8867 
[epoch 16] step 40/44: loss=7.8919 
[epoch 16] step 42/44: loss=7.8605 
[epoch 16] step 44/44: loss=7.8425 
[epoch 16] train_loss(avg per step)=15.6851 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=9.8921 qwk=('0.6371', '0.6552', '0.6359') averageQWK=0.6427 macroEMD=0.3636 tailR0=('0.2971', '0.0556', '0.1000') tailR0avg=0.1509
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    1    4    1    0
    16    8   29    2    0
     6    3   77   38    1
     0    0   22   88    6
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
    10   25   12    5    0
     1   19   51   50    0
     0    2   11  120    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     3   34   30    2    0
     1   19   88   43    0
     0    1   16   84    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=8.4278 
[epoch 17] step 4/44: loss=8.1393 
[epoch 17] step 6/44: loss=8.1144 
[epoch 17] step 8/44: loss=8.0647 
[epoch 17] step 10/44: loss=8.1286 
[epoch 17] step 12/44: loss=8.2273 
[epoch 17] step 14/44: loss=8.1813 
[epoch 17] step 16/44: loss=8.2508 
[epoch 17] step 18/44: loss=8.2896 
[epoch 17] step 20/44: loss=8.1273 
[epoch 17] step 22/44: loss=7.9836 
[epoch 17] step 24/44: loss=7.9182 
[epoch 17] step 26/44: loss=7.9286 
[epoch 17] step 28/44: loss=8.0084 
[epoch 17] step 30/44: loss=8.0339 
[epoch 17] step 32/44: loss=8.0288 
[epoch 17] step 34/44: loss=7.9869 
[epoch 17] step 36/44: loss=7.9118 
[epoch 17] step 38/44: loss=7.8905 
[epoch 17] step 40/44: loss=7.8746 
[epoch 17] step 42/44: loss=7.9026 
[epoch 17] step 44/44: loss=7.9246 
[epoch 17] train_loss(avg per step)=15.8492 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=9.9666 qwk=('0.6145', '0.6083', '0.6188') averageQWK=0.6139 macroEMD=0.3641 tailR0=('0.2101', '0.1111', '0.1000') tailR0avg=0.1404
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    1    4    1    0
     9   11   33    2    0
     2    8   86   28    1
     0    0   28   86    2
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    6    0    0
     6    7   35    4    0
     1    6   85   29    0
     0    0   24  109    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     2   22   45    0    0
     0   15  110   26    0
     0    0   26   75    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=9.1097 
[epoch 18] step 4/44: loss=8.6424 
[epoch 18] step 6/44: loss=8.3094 
[epoch 18] step 8/44: loss=8.0497 
[epoch 18] step 10/44: loss=7.9506 
[epoch 18] step 12/44: loss=8.2449 
[epoch 18] step 14/44: loss=8.2245 
[epoch 18] step 16/44: loss=8.1601 
[epoch 18] step 18/44: loss=8.1798 
[epoch 18] step 20/44: loss=8.1752 
[epoch 18] step 22/44: loss=8.1615 
[epoch 18] step 24/44: loss=8.2104 
[epoch 18] step 26/44: loss=8.1659 
[epoch 18] step 28/44: loss=8.1105 
[epoch 18] step 30/44: loss=8.0389 
[epoch 18] step 32/44: loss=7.9856 
[epoch 18] step 34/44: loss=8.0056 
[epoch 18] step 36/44: loss=8.0263 
[epoch 18] step 38/44: loss=8.0721 
[epoch 18] step 40/44: loss=8.1120 
[epoch 18] step 42/44: loss=8.0985 
[epoch 18] step 44/44: loss=8.0805 
[epoch 18] train_loss(avg per step)=16.1610 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=10.4560 qwk=('0.6640', '0.5977', '0.6339') averageQWK=0.6319 macroEMD=0.3669 tailR0=('0.3841', '0.0556', '0.1000') tailR0avg=0.1799
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    3    0    1
    11   19   24    1    0
     4    8   93   16    4
     0    0   29   73   14
     0    0    3   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     2   32    6   12    0
     1   29   36   55    0
     0    1    7  124    2
     0    1    0   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     2   25   41    1    0
     0   11  114   26    0
     0    0   25   76    0
     0    0    0    2    0
[epoch 19] step 2/44: loss=7.4392 
[epoch 19] step 4/44: loss=7.1658 
[epoch 19] step 6/44: loss=7.1780 
[epoch 19] step 8/44: loss=7.4383 
[epoch 19] step 10/44: loss=7.4386 
[epoch 19] step 12/44: loss=7.6716 
[epoch 19] step 14/44: loss=7.9210 
[epoch 19] step 16/44: loss=8.1190 
[epoch 19] step 18/44: loss=8.1459 
[epoch 19] step 20/44: loss=8.1188 
[epoch 19] step 22/44: loss=8.1258 
[epoch 19] step 24/44: loss=8.0319 
[epoch 19] step 26/44: loss=7.9176 
[epoch 19] step 28/44: loss=7.7863 
[epoch 19] step 30/44: loss=7.6770 
[epoch 19] step 32/44: loss=7.6172 
[epoch 19] step 34/44: loss=7.5899 
[epoch 19] step 36/44: loss=7.5682 
[epoch 19] step 38/44: loss=7.6083 
[epoch 19] step 40/44: loss=7.6938 
[epoch 19] step 42/44: loss=7.7861 
[epoch 19] step 44/44: loss=7.8591 
[epoch 19] train_loss(avg per step)=15.7181 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=9.9441 qwk=('0.5507', '0.5382', '0.5498') averageQWK=0.5463 macroEMD=0.3639 tailR0=('0.2101', '0.0556', '0.0000') tailR0avg=0.0886
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    4    2    0
     2    7   41    5    0
     2    2   82   38    1
     0    0   18   96    2
     0    0    2   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    0    0
     2   10   30   10    0
     0    4   68   49    0
     0    0   14  120    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     1   13   53    2    0
     0    7  107   37    0
     0    0   19   82    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=9.3602 
[epoch 20] step 4/44: loss=9.0041 
[epoch 20] step 6/44: loss=8.4870 
[epoch 20] step 8/44: loss=8.0272 
[epoch 20] step 10/44: loss=7.7657 
[epoch 20] step 12/44: loss=7.6705 
[epoch 20] step 14/44: loss=7.6693 
[epoch 20] step 16/44: loss=7.6406 
[epoch 20] step 18/44: loss=7.6176 
[epoch 20] step 20/44: loss=7.6623 
[epoch 20] step 22/44: loss=7.7848 
[epoch 20] step 24/44: loss=7.8331 
[epoch 20] step 26/44: loss=7.8895 
[epoch 20] step 28/44: loss=7.9477 
[epoch 20] step 30/44: loss=7.9781 
[epoch 20] step 32/44: loss=7.9557 
[epoch 20] step 34/44: loss=7.9459 
[epoch 20] step 36/44: loss=7.9105 
[epoch 20] step 38/44: loss=7.8474 
[epoch 20] step 40/44: loss=7.8280 
[epoch 20] step 42/44: loss=7.8550 
[epoch 20] step 44/44: loss=7.8777 
[epoch 20] train_loss(avg per step)=15.7553 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=10.0773 qwk=('0.6611', '0.6496', '0.6379') averageQWK=0.6495 macroEMD=0.3648 tailR0=('0.2536', '0.0556', '0.1000') tailR0avg=0.1364
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    3    0    0
     1   30   23    1    0
     1   17   85   21    1
     0    1   35   76    4
     0    0    4   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     3   26   19    4    0
     2   15   78   26    0
     0    0   30  103    1
     0    1    0   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     2   36   31    0    0
     1   29   98   23    0
     0    3   27   71    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=7.8478 
[epoch 21] step 4/44: loss=7.6921 
[epoch 21] step 6/44: loss=8.0931 
[epoch 21] step 8/44: loss=8.2285 
[epoch 21] step 10/44: loss=8.2091 
[epoch 21] step 12/44: loss=8.2439 
[epoch 21] step 14/44: loss=8.0858 
[epoch 21] step 16/44: loss=7.9786 
[epoch 21] step 18/44: loss=7.8323 
[epoch 21] step 20/44: loss=7.7914 
[epoch 21] step 22/44: loss=7.7724 
[epoch 21] step 24/44: loss=7.7983 
[epoch 21] step 26/44: loss=7.8183 
[epoch 21] step 28/44: loss=7.8933 
[epoch 21] step 30/44: loss=7.8950 
[epoch 21] step 32/44: loss=7.8880 
[epoch 21] step 34/44: loss=7.8668 
[epoch 21] step 36/44: loss=7.8051 
[epoch 21] step 38/44: loss=7.8286 
[epoch 21] step 40/44: loss=7.8483 
[epoch 21] step 42/44: loss=7.8751 
[epoch 21] step 44/44: loss=7.8147 
[epoch 21] train_loss(avg per step)=15.6295 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=10.0518 qwk=('0.5792', '0.6030', '0.6142') averageQWK=0.5988 macroEMD=0.3668 tailR0=('0.2319', '0.0556', '0.1000') tailR0avg=0.1291
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    6    0    0
     2   11   41    1    0
     5    5   93   21    1
     0    0   33   77    6
     0    0    4   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    0    0
     5   13   29    5    0
     0   10   73   38    0
     0    0   19  115    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    1    0
     2   20   46    1    0
     0   10  118   23    0
     0    0   24   77    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=7.2797 
[epoch 22] step 4/44: loss=7.5604 
[epoch 22] step 6/44: loss=7.8158 
[epoch 22] step 8/44: loss=7.8978 
[epoch 22] step 10/44: loss=7.9281 
[epoch 22] step 12/44: loss=8.1260 
[epoch 22] step 14/44: loss=8.1485 
[epoch 22] step 16/44: loss=8.0652 
[epoch 22] step 18/44: loss=8.1743 
[epoch 22] step 20/44: loss=8.1987 
[epoch 22] step 22/44: loss=8.2166 
[epoch 22] step 24/44: loss=8.1141 
[epoch 22] step 26/44: loss=8.0350 
[epoch 22] step 28/44: loss=8.0159 
[epoch 22] step 30/44: loss=7.9709 
[epoch 22] step 32/44: loss=7.9957 
[epoch 22] step 34/44: loss=8.0614 
[epoch 22] step 36/44: loss=8.0529 
[epoch 22] step 38/44: loss=8.0449 
[epoch 22] step 40/44: loss=8.0272 
[epoch 22] step 42/44: loss=8.0032 
[epoch 22] step 44/44: loss=7.9949 
[epoch 22] train_loss(avg per step)=15.9897 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=10.4893 qwk=('0.6206', '0.5884', '0.5952') averageQWK=0.6014 macroEMD=0.3667 tailR0=('0.3285', '0.0556', '0.1000') tailR0avg=0.1614
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    4    0    1
     1   24   26    2    2
     0   11   82   28    4
     0    0   21   76   19
     0    0    2   11   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     2   22   19    9    0
     1   18   51   51    0
     0    1   11  119    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    1    0
     2   16   50    1    0
     0    6  114   31    0
     0    0   22   79    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=7.8077 
[epoch 23] step 4/44: loss=7.6135 
[epoch 23] step 6/44: loss=7.8354 
[epoch 23] step 8/44: loss=7.8609 
[epoch 23] step 10/44: loss=7.8671 
[epoch 23] step 12/44: loss=7.8223 
[epoch 23] step 14/44: loss=7.8232 
[epoch 23] step 16/44: loss=7.8021 
[epoch 23] step 18/44: loss=7.8064 
[epoch 23] step 20/44: loss=7.8258 
[epoch 23] step 22/44: loss=7.8627 
[epoch 23] step 24/44: loss=7.9013 
[epoch 23] step 26/44: loss=7.8995 
[epoch 23] step 28/44: loss=7.9030 
[epoch 23] step 30/44: loss=7.8502 
[epoch 23] step 32/44: loss=7.8151 
[epoch 23] step 34/44: loss=7.8236 
[epoch 23] step 36/44: loss=7.7878 
[epoch 23] step 38/44: loss=7.7863 
[epoch 23] step 40/44: loss=7.7931 
[epoch 23] step 42/44: loss=7.7898 
[epoch 23] step 44/44: loss=7.8092 
[epoch 23] train_loss(avg per step)=15.6185 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=10.0956 qwk=('0.6804', '0.6249', '0.6224') averageQWK=0.6426 macroEMD=0.3645 tailR0=('0.2536', '0.0556', '0.1000') tailR0avg=0.1364
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    3    0    0
     1   35   17    2    0
     0   25   72   26    2
     0    0   28   85    3
     0    1    1   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    0    0
     2   24   20    6    0
     1   23   61   36    0
     0    2   19  113    0
     0    1    0   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     2   27   40    0    0
     0   19  114   18    0
     0    1   30   70    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=7.9670 
[epoch 24] step 4/44: loss=8.1395 
[epoch 24] step 6/44: loss=8.4306 
[epoch 24] step 8/44: loss=8.4882 
[epoch 24] step 10/44: loss=8.4409 
[epoch 24] step 12/44: loss=8.3517 
[epoch 24] step 14/44: loss=8.2621 
[epoch 24] step 16/44: loss=8.0267 
[epoch 24] step 18/44: loss=7.8874 
[epoch 24] step 20/44: loss=7.7461 
[epoch 24] step 22/44: loss=7.6810 
[epoch 24] step 24/44: loss=7.7596 
[epoch 24] step 26/44: loss=7.8043 
[epoch 24] step 28/44: loss=7.9119 
[epoch 24] step 30/44: loss=7.9846 
[epoch 24] step 32/44: loss=8.0332 
[epoch 24] step 34/44: loss=8.0599 
[epoch 24] step 36/44: loss=8.0366 
[epoch 24] step 38/44: loss=8.0600 
[epoch 24] step 40/44: loss=8.0512 
[epoch 24] step 42/44: loss=8.0253 
[epoch 24] step 44/44: loss=8.0202 
[epoch 24] train_loss(avg per step)=16.0404 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=10.4346 qwk=('0.5867', '0.5484', '0.6066') averageQWK=0.5806 macroEMD=0.3687 tailR0=('0.1425', '0.0000', '0.0000') tailR0avg=0.0475
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    1
     2   16   34    3    0
     0    9   79   35    2
     0    0   24   89    3
     0    0    2   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     2   18   20   12    0
     0   12   48   61    0
     0    0    7  127    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     1   29   37    2    0
     0   16  108   27    0
     0    1   26   74    0
     0    0    0    2    0
[epoch 25] step 2/44: loss=7.6956 
[epoch 25] step 4/44: loss=7.6917 
[epoch 25] step 6/44: loss=7.7503 
[epoch 25] step 8/44: loss=7.6400 
[epoch 25] step 10/44: loss=7.6984 
[epoch 25] step 12/44: loss=7.6962 
[epoch 25] step 14/44: loss=7.7656 
[epoch 25] step 16/44: loss=7.7384 
[epoch 25] step 18/44: loss=7.7530 
[epoch 25] step 20/44: loss=7.7771 
[epoch 25] step 22/44: loss=7.8396 
[epoch 25] step 24/44: loss=7.9218 
[epoch 25] step 26/44: loss=7.9319 
[epoch 25] step 28/44: loss=7.9411 
[epoch 25] step 30/44: loss=7.9217 
[epoch 25] step 32/44: loss=7.8553 
[epoch 25] step 34/44: loss=7.8189 
[epoch 25] step 36/44: loss=7.7996 
[epoch 25] step 38/44: loss=7.8081 
[epoch 25] step 40/44: loss=7.7866 
[epoch 25] step 42/44: loss=7.7770 
[epoch 25] step 44/44: loss=7.8136 
[epoch 25] train_loss(avg per step)=15.6272 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=10.1078 qwk=('0.6466', '0.6345', '0.6339') averageQWK=0.6383 macroEMD=0.3653 tailR0=('0.2754', '0.0556', '0.1000') tailR0avg=0.1436
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    1    5    0    0
     1   22   30    2    0
     1   12   87   22    3
     0    0   28   83    5
     0    0    2   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     4   26   17    5    0
     1   21   63   36    0
     0    4   15  114    1
     0    1    0   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    1    0
     5   31   31    2    0
     1   23   96   31    0
     0    2   20   79    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=8.2624 
[epoch 26] step 4/44: loss=8.6973 
[epoch 26] step 6/44: loss=8.5552 
[epoch 26] step 8/44: loss=8.5053 
[epoch 26] step 10/44: loss=8.4737 
[epoch 26] step 12/44: loss=8.3848 
[epoch 26] step 14/44: loss=8.3503 
[epoch 26] step 16/44: loss=8.2149 
[epoch 26] step 18/44: loss=8.1590 
[epoch 26] step 20/44: loss=8.0889 
[epoch 26] step 22/44: loss=8.1094 
[epoch 26] step 24/44: loss=8.0562 
[epoch 26] step 26/44: loss=8.0339 
[epoch 26] step 28/44: loss=8.0218 
[epoch 26] step 30/44: loss=8.0357 
[epoch 26] step 32/44: loss=8.0158 
[epoch 26] step 34/44: loss=7.9788 
[epoch 26] step 36/44: loss=7.9781 
[epoch 26] step 38/44: loss=7.9602 
[epoch 26] step 40/44: loss=7.9207 
[epoch 26] step 42/44: loss=7.9509 
[epoch 26] step 44/44: loss=7.9967 
[epoch 26] train_loss(avg per step)=15.9935 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=10.3569 qwk=('0.6116', '0.5992', '0.6049') averageQWK=0.6053 macroEMD=0.3672 tailR0=('0.2536', '0.0556', '0.0000') tailR0avg=0.1031
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    6    0    0
     1   16   35    3    0
     0    6   86   30    3
     0    0   25   87    4
     0    0    2   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     2   14   31    5    0
     0    9   80   32    0
     0    0   24  106    4
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     2   21   44    2    0
     0   11  105   35    0
     0    1   17   83    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=8.4340 
[epoch 27] step 4/44: loss=8.5520 
[epoch 27] step 6/44: loss=8.2878 
[epoch 27] step 8/44: loss=8.0124 
[epoch 27] step 10/44: loss=7.8077 
[epoch 27] step 12/44: loss=7.7431 
[epoch 27] step 14/44: loss=7.5986 
[epoch 27] step 16/44: loss=7.7534 
[epoch 27] step 18/44: loss=7.8083 
[epoch 27] step 20/44: loss=7.8360 
[epoch 27] step 22/44: loss=7.8919 
[epoch 27] step 24/44: loss=7.8578 
[epoch 27] step 26/44: loss=7.8648 
[epoch 27] step 28/44: loss=7.8406 
[epoch 27] step 30/44: loss=7.8845 
[epoch 27] step 32/44: loss=7.8763 
[epoch 27] step 34/44: loss=7.8791 
[epoch 27] step 36/44: loss=7.8741 
[epoch 27] step 38/44: loss=7.8555 
[epoch 27] step 40/44: loss=7.8764 
[epoch 27] step 42/44: loss=7.8937 
[epoch 27] step 44/44: loss=7.9131 
[epoch 27] train_loss(avg per step)=15.8262 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=10.2438 qwk=('0.6084', '0.6373', '0.6393') averageQWK=0.6283 macroEMD=0.3671 tailR0=('0.2754', '0.0556', '0.1000') tailR0avg=0.1436
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    6    0    0
     4    9   40    2    0
     1    6   96   19    3
     0    0   29   81    6
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     2   21   24    5    0
     0   14   70   37    0
     0    0   21  112    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    1    0
     2   25   40    2    0
     0   15  100   36    0
     0    0   17   84    0
     0    0    0    2    0
[epoch 28] step 2/44: loss=8.1477 
[epoch 28] step 4/44: loss=7.5415 
[epoch 28] step 6/44: loss=7.7599 
[epoch 28] step 8/44: loss=7.9338 
[epoch 28] step 10/44: loss=7.8397 
[epoch 28] step 12/44: loss=7.6993 
[epoch 28] step 14/44: loss=7.7644 
[epoch 28] step 16/44: loss=7.8579 
[epoch 28] step 18/44: loss=7.8252 
[epoch 28] step 20/44: loss=7.8657 
[epoch 28] step 22/44: loss=7.9297 
[epoch 28] step 24/44: loss=7.9097 
[epoch 28] step 26/44: loss=7.9387 
[epoch 28] step 28/44: loss=7.8994 
[epoch 28] step 30/44: loss=7.9128 
[epoch 28] step 32/44: loss=7.9502 
[epoch 28] step 34/44: loss=7.8920 
[epoch 28] step 36/44: loss=7.8658 
[epoch 28] step 38/44: loss=7.8657 
[epoch 28] step 40/44: loss=7.8765 
[epoch 28] step 42/44: loss=7.8709 
[epoch 28] step 44/44: loss=7.8677 
[epoch 28] train_loss(avg per step)=15.7355 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=10.2902 qwk=('0.6545', '0.6434', '0.6206') averageQWK=0.6395 macroEMD=0.3687 tailR0=('0.1860', '0.0556', '0.0000') tailR0avg=0.0805
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     1   28   24    2    0
     0   15   87   20    3
     0    0   26   82    8
     0    1    3   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     2   22   22    6    0
     0   14   76   31    0
     0    0   25  108    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     2   26   39    2    0
     0   18  108   25    0
     0    1   24   76    0
     0    0    0    2    0
[epoch 29] step 2/44: loss=7.4598 
[epoch 29] step 4/44: loss=7.7635 
[epoch 29] step 6/44: loss=7.9689 
[epoch 29] step 8/44: loss=7.9205 
[epoch 29] step 10/44: loss=7.9305 
[epoch 29] step 12/44: loss=7.9966 
[epoch 29] step 14/44: loss=8.1174 
[epoch 29] step 16/44: loss=8.0853 
[epoch 29] step 18/44: loss=8.0638 
[epoch 29] step 20/44: loss=8.0085 
[epoch 29] step 22/44: loss=7.9239 
[epoch 29] step 24/44: loss=7.8749 
[epoch 29] step 26/44: loss=7.8869 
[epoch 29] step 28/44: loss=7.9004 
[epoch 29] step 30/44: loss=7.9077 
[epoch 29] step 32/44: loss=7.8819 
[epoch 29] step 34/44: loss=7.9299 
[epoch 29] step 36/44: loss=7.9346 
[epoch 29] step 38/44: loss=7.9146 
[epoch 29] step 40/44: loss=7.9280 
[epoch 29] step 42/44: loss=7.9108 
[epoch 29] step 44/44: loss=7.9482 
[epoch 29] train_loss(avg per step)=15.8965 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=10.5035 qwk=('0.6184', '0.5909', '0.6099') averageQWK=0.6064 macroEMD=0.3670 tailR0=('0.2101', '0.0556', '0.1000') tailR0avg=0.1219
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    1    4    1    0
     2   27   22    4    0
     2   14   65   42    2
     0    0   19   96    1
     0    1    0   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    1    0
     3   19   22    8    0
     1   16   58   46    0
     0    0   14  120    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     2   28   38    1    0
     1   19  100   31    0
     0    1   24   76    0
     0    0    0    2    0
[epoch 30] step 2/44: loss=8.0496 
[epoch 30] step 4/44: loss=8.3311 
[epoch 30] step 6/44: loss=8.3071 
[epoch 30] step 8/44: loss=8.4998 
[epoch 30] step 10/44: loss=8.5730 
[epoch 30] step 12/44: loss=8.4100 
[epoch 30] step 14/44: loss=8.1452 
[epoch 30] step 16/44: loss=8.1583 
[epoch 30] step 18/44: loss=8.1335 
[epoch 30] step 20/44: loss=8.1573 
[epoch 30] step 22/44: loss=8.1276 
[epoch 30] step 24/44: loss=8.0893 
[epoch 30] step 26/44: loss=8.0904 
[epoch 30] step 28/44: loss=8.0843 
[epoch 30] step 30/44: loss=8.0116 
[epoch 30] step 32/44: loss=8.0350 
[epoch 30] step 34/44: loss=7.9971 
[epoch 30] step 36/44: loss=7.9441 
[epoch 30] step 38/44: loss=7.9591 
[epoch 30] step 40/44: loss=7.9401 
[epoch 30] step 42/44: loss=7.9259 
[epoch 30] step 44/44: loss=7.9141 
[epoch 30] train_loss(avg per step)=15.8282 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=10.2816 qwk=('0.6522', '0.5960', '0.6066') averageQWK=0.6183 macroEMD=0.3667 tailR0=('0.2536', '0.0556', '0.1000') tailR0avg=0.1364
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    3    1    0
     2   26   25    2    0
     0   14   78   31    2
     0    0   26   86    4
     0    1    0   18    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     2   14   30    6    0
     0   10   71   40    0
     0    0   20  114    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     2   28   37    2    0
     1   20  100   30    0
     0    1   23   77    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=9.1871 
[epoch 31] step 4/44: loss=8.8254 
[epoch 31] step 6/44: loss=8.7521 
[epoch 31] step 8/44: loss=8.4648 
[epoch 31] step 10/44: loss=8.3079 
[epoch 31] step 12/44: loss=8.3400 
[epoch 31] step 14/44: loss=8.3851 
[epoch 31] step 16/44: loss=8.3156 
[epoch 31] step 18/44: loss=8.3439 
[epoch 31] step 20/44: loss=8.3308 
[epoch 31] step 22/44: loss=8.2652 
[epoch 31] step 24/44: loss=8.1917 
[epoch 31] step 26/44: loss=8.1621 
[epoch 31] step 28/44: loss=8.0995 
[epoch 31] step 30/44: loss=8.0795 
[epoch 31] step 32/44: loss=8.0932 
[epoch 31] step 34/44: loss=8.0527 
[epoch 31] step 36/44: loss=8.0267 
[epoch 31] step 38/44: loss=8.0758 
[epoch 31] step 40/44: loss=8.0687 
[epoch 31] step 42/44: loss=8.0543 
[epoch 31] step 44/44: loss=8.0591 
[epoch 31] train_loss(avg per step)=16.1182 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=10.6648 qwk=('0.6397', '0.6121', '0.5935') averageQWK=0.6151 macroEMD=0.3676 tailR0=('0.2754', '0.0556', '0.1000') tailR0avg=0.1436
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    1    4    1    0
     2   24   27    2    0
     0    9   80   34    2
     0    0   24   87    5
     0    1    1   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     2   20   24    6    0
     1   11   64   45    0
     0    0   17  116    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     2   19   46    2    0
     0    6  107   38    0
     0    1   20   80    0
     0    0    0    2    0
[epoch 32] step 2/44: loss=8.3709 
[epoch 32] step 4/44: loss=8.2659 
[epoch 32] step 6/44: loss=8.1708 
[epoch 32] step 8/44: loss=8.3030 
[epoch 32] step 10/44: loss=8.2561 
[epoch 32] step 12/44: loss=8.3124 
[epoch 32] step 14/44: loss=8.2253 
[epoch 32] step 16/44: loss=8.1827 
[epoch 32] step 18/44: loss=8.0385 
[epoch 32] step 20/44: loss=7.9421 
[epoch 32] step 22/44: loss=7.8773 
[epoch 32] step 24/44: loss=7.8146 
[epoch 32] step 26/44: loss=7.7993 
[epoch 32] step 28/44: loss=7.8294 
[epoch 32] step 30/44: loss=7.8506 
[epoch 32] step 32/44: loss=7.8627 
[epoch 32] step 34/44: loss=7.8798 
[epoch 32] step 36/44: loss=7.8756 
[epoch 32] step 38/44: loss=7.9264 
[epoch 32] step 40/44: loss=7.9404 
[epoch 32] step 42/44: loss=7.9190 
[epoch 32] step 44/44: loss=7.9449 
[epoch 32] train_loss(avg per step)=15.8898 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=10.4195 qwk=('0.6541', '0.6450', '0.6129') averageQWK=0.6373 macroEMD=0.3683 tailR0=('0.1981', '0.0556', '0.1000') tailR0avg=0.1179
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    1    0
     3   28   22    2    0
     0   16   76   30    3
     0    0   25   86    5
     0    1    1   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     2   26   18    6    0
     1   20   53   47    0
     0    0   14  119    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     2   28   37    2    0
     1   22  107   21    0
     0    1   25   75    0
     0    0    0    2    0
[epoch 33] step 2/44: loss=7.5677 
[epoch 33] step 4/44: loss=7.4584 
[epoch 33] step 6/44: loss=7.6037 
[epoch 33] step 8/44: loss=7.8362 
[epoch 33] step 10/44: loss=7.7746 
[epoch 33] step 12/44: loss=7.7611 
[epoch 33] step 14/44: loss=7.6535 
[epoch 33] step 16/44: loss=7.6452 
[epoch 33] step 18/44: loss=7.7103 
[epoch 33] step 20/44: loss=7.6637 
[epoch 33] step 22/44: loss=7.7129 
[epoch 33] step 24/44: loss=7.7361 
[epoch 33] step 26/44: loss=7.7623 
[epoch 33] step 28/44: loss=7.7735 
[epoch 33] step 30/44: loss=7.7969 
[epoch 33] step 32/44: loss=7.8124 
[epoch 33] step 34/44: loss=7.8430 
[epoch 33] step 36/44: loss=7.8864 
[epoch 33] step 38/44: loss=7.9002 
[epoch 33] step 40/44: loss=7.9027 
[epoch 33] step 42/44: loss=7.9141 
[epoch 33] step 44/44: loss=7.8891 
[epoch 33] train_loss(avg per step)=15.7783 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=10.3488 qwk=('0.6312', '0.6125', '0.6104') averageQWK=0.6180 macroEMD=0.3681 tailR0=('0.2198', '0.0556', '0.1000') tailR0avg=0.1251
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    4    1    0
     2   21   30    2    0
     0   13   79   30    3
     0    0   24   85    7
     0    0    2   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     2   18   26    6    0
     0   12   69   40    0
     0    0   19  114    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     2   24   41    2    0
     0   16  107   28    0
     0    1   22   78    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=7.8488 
[epoch 34] step 4/44: loss=7.9049 
[epoch 34] step 6/44: loss=7.9618 
[epoch 34] step 8/44: loss=8.0556 
[epoch 34] step 10/44: loss=7.8886 
[epoch 34] step 12/44: loss=7.8875 
[epoch 34] step 14/44: loss=7.8600 
[epoch 34] step 16/44: loss=7.9107 
[epoch 34] step 18/44: loss=7.9093 
[epoch 34] step 20/44: loss=7.8916 
[epoch 34] step 22/44: loss=7.9024 
[epoch 34] step 24/44: loss=7.9032 
[epoch 34] step 26/44: loss=7.9573 
[epoch 34] step 28/44: loss=7.9652 
[epoch 34] step 30/44: loss=7.9496 
[epoch 34] step 32/44: loss=7.9419 
[epoch 34] step 34/44: loss=7.9218 
[epoch 34] step 36/44: loss=7.9126 
[epoch 34] step 38/44: loss=7.9043 
[epoch 34] step 40/44: loss=7.9187 
[epoch 34] step 42/44: loss=7.8912 
[epoch 34] step 44/44: loss=7.8487 
[epoch 34] train_loss(avg per step)=15.6975 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=10.3716 qwk=('0.6351', '0.5997', '0.6224') averageQWK=0.6191 macroEMD=0.3680 tailR0=('0.2754', '0.0556', '0.1000') tailR0avg=0.1436
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    1    4    1    0
     3   21   29    2    0
     2   11   79   30    3
     0    0   23   86    7
     0    0    2   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     2   17   27    6    0
     0   11   65   45    0
     0    0   16  118    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    1    0
     2   27   38    2    0
     0   16  105   30    0
     0    1   21   79    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=7.6564 
[epoch 35] step 4/44: loss=7.5066 
[epoch 35] step 6/44: loss=7.8500 
[epoch 35] step 8/44: loss=7.7682 
[epoch 35] step 10/44: loss=7.8510 
[epoch 35] step 12/44: loss=7.9547 
[epoch 35] step 14/44: loss=7.9350 
[epoch 35] step 16/44: loss=7.9586 
[epoch 35] step 18/44: loss=7.9009 
[epoch 35] step 20/44: loss=7.8728 
[epoch 35] step 22/44: loss=7.9329 
[epoch 35] step 24/44: loss=7.9437 
[epoch 35] step 26/44: loss=7.9446 
[epoch 35] step 28/44: loss=7.9510 
[epoch 35] step 30/44: loss=7.9587 
[epoch 35] step 32/44: loss=7.9106 
[epoch 35] step 34/44: loss=7.9382 
[epoch 35] step 36/44: loss=7.9196 
[epoch 35] step 38/44: loss=7.8979 
[epoch 35] step 40/44: loss=7.8979 
[epoch 35] step 42/44: loss=7.8952 
[epoch 35] step 44/44: loss=7.8844 
[epoch 35] train_loss(avg per step)=15.7688 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=10.3735 qwk=('0.6447', '0.6256', '0.6241') averageQWK=0.6315 macroEMD=0.3677 tailR0=('0.1981', '0.0556', '0.0000') tailR0avg=0.0845
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    1    0
     2   24   27    2    0
     1   12   80   30    2
     0    0   25   85    6
     0    0    2   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     2   20   24    6    0
     0   13   67   41    0
     0    0   19  114    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     2   30   35    2    0
     0   20  104   27    0
     0    1   22   78    0
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-1-reassignment-1/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-1-reassignment-1/fold0/metrics.json
Done.
