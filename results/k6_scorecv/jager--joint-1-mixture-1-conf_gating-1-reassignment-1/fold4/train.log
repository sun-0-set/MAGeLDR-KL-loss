[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.1341 
[epoch 1] step 4/44: loss=6.2385 
[epoch 1] step 6/44: loss=5.9982 
[epoch 1] step 8/44: loss=6.1273 
[epoch 1] step 10/44: loss=6.0281 
[epoch 1] step 12/44: loss=6.0665 
[epoch 1] step 14/44: loss=6.0323 
[epoch 1] step 16/44: loss=5.9626 
[epoch 1] step 18/44: loss=5.8922 
[epoch 1] step 20/44: loss=5.9088 
[epoch 1] step 22/44: loss=5.9225 
[epoch 1] step 24/44: loss=5.9273 
[epoch 1] step 26/44: loss=5.9552 
[epoch 1] step 28/44: loss=5.9743 
[epoch 1] step 30/44: loss=6.0059 
[epoch 1] step 32/44: loss=6.0503 
[epoch 1] step 34/44: loss=6.1033 
[epoch 1] step 36/44: loss=6.1251 
[epoch 1] step 38/44: loss=6.1212 
[epoch 1] step 40/44: loss=6.1357 
[epoch 1] step 42/44: loss=6.1851 
[epoch 1] step 44/44: loss=6.2561 
[epoch 1] train_loss(avg per step)=12.5122 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=5.6832 qwk=('0.0938', '0.1394', '0.0820') averageQWK=0.1051 macroEMD=0.3857 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    3    0
     0   30    8   17    0
     0   69   14   42    0
     0   48   16   52    0
     0    8    6    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
    16    0   30    7    0
    37    0   64   21    0
    18    0   79   36    0
     0    0    9    3    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    5   64    0    0
     0    6  146    0    0
     0    1   97    4    0
     0    0    2    0    0
[epoch 2] step 2/44: loss=8.2910 
[epoch 2] step 4/44: loss=8.6773 
[epoch 2] step 6/44: loss=8.9478 
[epoch 2] step 8/44: loss=9.2225 
[epoch 2] step 10/44: loss=9.4343 
[epoch 2] step 12/44: loss=9.7423 
[epoch 2] step 14/44: loss=9.8718 
[epoch 2] step 16/44: loss=10.0787 
[epoch 2] step 18/44: loss=10.2050 
[epoch 2] step 20/44: loss=10.3188 
[epoch 2] step 22/44: loss=10.4037 
[epoch 2] step 24/44: loss=10.5053 
[epoch 2] step 26/44: loss=10.5681 
[epoch 2] step 28/44: loss=10.7045 
[epoch 2] step 30/44: loss=10.8269 
[epoch 2] step 32/44: loss=10.9650 
[epoch 2] step 34/44: loss=11.0932 
[epoch 2] step 36/44: loss=11.1779 
[epoch 2] step 38/44: loss=11.2801 
[epoch 2] step 40/44: loss=11.3362 
[epoch 2] step 42/44: loss=11.4009 
[epoch 2] step 44/44: loss=11.5225 
[epoch 2] train_loss(avg per step)=23.0450 lambda[min,max]=[0.500311,1.000000]
[epoch 2] val_loss=13.1232 qwk=('0.2614', '0.2056', '0.1959') averageQWK=0.2210 macroEMD=0.3920 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    1
     1   18    0   30    6
     0   17    0  100    8
     0    6    0  109    1
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    6    0
     0    8    8   37    0
     0    5    5  112    0
     0    0    1  132    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    0   69    0    0
     0    0  147    5    0
     0    0   78   24    0
     0    0    2    0    0
[epoch 3] step 2/44: loss=12.9251 
[epoch 3] step 4/44: loss=12.9132 
[epoch 3] step 6/44: loss=12.6794 
[epoch 3] step 8/44: loss=12.8089 
[epoch 3] step 10/44: loss=12.9103 
[epoch 3] step 12/44: loss=13.0282 
[epoch 3] step 14/44: loss=12.9566 
[epoch 3] step 16/44: loss=12.9563 
[epoch 3] step 18/44: loss=13.0131 
[epoch 3] step 20/44: loss=13.0216 
[epoch 3] step 22/44: loss=13.0402 
[epoch 3] step 24/44: loss=12.9491 
[epoch 3] step 26/44: loss=12.9504 
[epoch 3] step 28/44: loss=12.9829 
[epoch 3] step 30/44: loss=12.9817 
[epoch 3] step 32/44: loss=12.9513 
[epoch 3] step 34/44: loss=12.9042 
[epoch 3] step 36/44: loss=12.8549 
[epoch 3] step 38/44: loss=12.8519 
[epoch 3] step 40/44: loss=12.8253 
[epoch 3] step 42/44: loss=12.8302 
[epoch 3] step 44/44: loss=12.7920 
[epoch 3] train_loss(avg per step)=25.5839 lambda[min,max]=[0.560066,1.000000]
[epoch 3] val_loss=14.4073 qwk=('0.3122', '0.3939', '0.5064') averageQWK=0.4042 macroEMD=0.3900 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    1    0
     0    0   47    8    0
     0    0   79   46    0
     0    0   34   82    0
     0    0   10   13    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   47    6    0
     0    0   88   34    0
     0    0   41   92    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   28   31   10    0
     0   27   58   67    0
     0    2   13   87    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=11.9886 
[epoch 4] step 4/44: loss=11.9456 
[epoch 4] step 6/44: loss=12.1534 
[epoch 4] step 8/44: loss=12.0428 
[epoch 4] step 10/44: loss=12.0577 
[epoch 4] step 12/44: loss=12.0931 
[epoch 4] step 14/44: loss=12.0197 
[epoch 4] step 16/44: loss=12.0712 
[epoch 4] step 18/44: loss=12.0403 
[epoch 4] step 20/44: loss=12.0466 
[epoch 4] step 22/44: loss=12.1075 
[epoch 4] step 24/44: loss=12.0224 
[epoch 4] step 26/44: loss=11.9586 
[epoch 4] step 28/44: loss=11.9685 
[epoch 4] step 30/44: loss=12.0059 
[epoch 4] step 32/44: loss=12.0230 
[epoch 4] step 34/44: loss=11.9567 
[epoch 4] step 36/44: loss=11.8673 
[epoch 4] step 38/44: loss=11.8554 
[epoch 4] step 40/44: loss=11.8719 
[epoch 4] step 42/44: loss=11.8759 
[epoch 4] step 44/44: loss=11.8980 
[epoch 4] train_loss(avg per step)=23.7960 lambda[min,max]=[0.530943,1.000000]
[epoch 4] val_loss=13.1295 qwk=('0.2458', '0.4765', '0.3896') averageQWK=0.3706 macroEMD=0.3856 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0    5   49    1    0
     0    1  122    2    0
     0    0   84   32    0
     0    0   22    1    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   50    0    3    0
     0   92    0   30    0
     0   37    0   96    0
     0    2    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0   10   59    0    0
     0    3  137   12    0
     0    0   63   39    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=12.5440 
[epoch 5] step 4/44: loss=11.7010 
[epoch 5] step 6/44: loss=11.6227 
[epoch 5] step 8/44: loss=11.5362 
[epoch 5] step 10/44: loss=11.5013 
[epoch 5] step 12/44: loss=11.5331 
[epoch 5] step 14/44: loss=11.3930 
[epoch 5] step 16/44: loss=11.3102 
[epoch 5] step 18/44: loss=11.1816 
[epoch 5] step 20/44: loss=11.0434 
[epoch 5] step 22/44: loss=10.9998 
[epoch 5] step 24/44: loss=10.9844 
[epoch 5] step 26/44: loss=10.9142 
[epoch 5] step 28/44: loss=10.8820 
[epoch 5] step 30/44: loss=10.9145 
[epoch 5] step 32/44: loss=10.8545 
[epoch 5] step 34/44: loss=10.8552 
[epoch 5] step 36/44: loss=10.7878 
[epoch 5] step 38/44: loss=10.6678 
[epoch 5] step 40/44: loss=10.6256 
[epoch 5] step 42/44: loss=10.6034 
[epoch 5] step 44/44: loss=10.6233 
[epoch 5] train_loss(avg per step)=21.2467 lambda[min,max]=[0.527039,1.000000]
[epoch 5] val_loss=12.0618 qwk=('0.3824', '0.3283', '0.2799') averageQWK=0.3302 macroEMD=0.3785 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0    3   50    2    0
     0    3  114    7    1
     0    0   65   51    0
     0    0   14    6    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    0    0
     0    2   50    1    0
     0    0  115    7    0
     0    0   87   46    0
     0    0    5    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0   26   43    0    0
     0   27  125    0    0
     0    2   93    7    0
     0    0    2    0    0
[epoch 6] step 2/44: loss=11.8165 
[epoch 6] step 4/44: loss=11.2655 
[epoch 6] step 6/44: loss=10.5633 
[epoch 6] step 8/44: loss=9.9745 
[epoch 6] step 10/44: loss=9.6104 
[epoch 6] step 12/44: loss=9.4652 
[epoch 6] step 14/44: loss=9.3783 
[epoch 6] step 16/44: loss=9.4802 
[epoch 6] step 18/44: loss=9.6001 
[epoch 6] step 20/44: loss=9.6201 
[epoch 6] step 22/44: loss=9.6094 
[epoch 6] step 24/44: loss=9.5208 
[epoch 6] step 26/44: loss=9.4508 
[epoch 6] step 28/44: loss=9.4268 
[epoch 6] step 30/44: loss=9.4017 
[epoch 6] step 32/44: loss=9.3818 
[epoch 6] step 34/44: loss=9.3261 
[epoch 6] step 36/44: loss=9.2950 
[epoch 6] step 38/44: loss=9.2556 
[epoch 6] step 40/44: loss=9.2824 
[epoch 6] step 42/44: loss=9.2482 
[epoch 6] step 44/44: loss=9.2185 
[epoch 6] train_loss(avg per step)=18.4369 lambda[min,max]=[0.500013,1.000000]
[epoch 6] val_loss=10.6697 qwk=('0.3874', '0.4640', '0.4527') averageQWK=0.4347 macroEMD=0.3812 tailR0=('0.3543', '0.0000', '0.0000') tailR0avg=0.1181
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    4    0    0
     1    5   44    1    4
     7    4  102    1   11
     5    1   58   29   23
     0    0    8    1   14
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   22   10   21    0
     0   17   19   86    0
     0    1    1  131    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    7   59    3    0
     0    2  122   28    0
     0    0   40   62    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=7.9253 
[epoch 7] step 4/44: loss=8.1896 
[epoch 7] step 6/44: loss=8.4068 
[epoch 7] step 8/44: loss=8.4251 
[epoch 7] step 10/44: loss=8.4527 
[epoch 7] step 12/44: loss=8.5107 
[epoch 7] step 14/44: loss=8.5513 
[epoch 7] step 16/44: loss=8.5015 
[epoch 7] step 18/44: loss=8.4865 
[epoch 7] step 20/44: loss=8.4624 
[epoch 7] step 22/44: loss=8.4210 
[epoch 7] step 24/44: loss=8.4546 
[epoch 7] step 26/44: loss=8.5200 
[epoch 7] step 28/44: loss=8.5957 
[epoch 7] step 30/44: loss=8.6995 
[epoch 7] step 32/44: loss=8.7935 
[epoch 7] step 34/44: loss=8.7424 
[epoch 7] step 36/44: loss=8.7309 
[epoch 7] step 38/44: loss=8.6845 
[epoch 7] step 40/44: loss=8.6507 
[epoch 7] step 42/44: loss=8.6555 
[epoch 7] step 44/44: loss=8.6290 
[epoch 7] train_loss(avg per step)=17.2580 lambda[min,max]=[0.500005,1.000000]
[epoch 7] val_loss=10.2488 qwk=('0.5720', '0.5389', '0.4655') averageQWK=0.5255 macroEMD=0.3767 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   15   33    7    0
     0   17   61   47    0
     0    2   14  100    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0    7   42    4    0
     0    5   87   30    0
     0    1   31  101    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    3   65    1    0
     0    0  124   28    0
     0    0   37   65    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=7.7114 
[epoch 8] step 4/44: loss=7.5954 
[epoch 8] step 6/44: loss=7.8574 
[epoch 8] step 8/44: loss=8.0789 
[epoch 8] step 10/44: loss=8.1555 
[epoch 8] step 12/44: loss=8.1303 
[epoch 8] step 14/44: loss=8.2587 
[epoch 8] step 16/44: loss=8.2898 
[epoch 8] step 18/44: loss=8.2432 
[epoch 8] step 20/44: loss=8.2574 
[epoch 8] step 22/44: loss=8.1695 
[epoch 8] step 24/44: loss=8.0477 
[epoch 8] step 26/44: loss=8.0092 
[epoch 8] step 28/44: loss=8.0271 
[epoch 8] step 30/44: loss=8.1096 
[epoch 8] step 32/44: loss=8.1579 
[epoch 8] step 34/44: loss=8.1683 
[epoch 8] step 36/44: loss=8.1226 
[epoch 8] step 38/44: loss=8.0727 
[epoch 8] step 40/44: loss=8.1065 
[epoch 8] step 42/44: loss=8.1411 
[epoch 8] step 44/44: loss=8.2621 
[epoch 8] train_loss(avg per step)=16.5241 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=9.9775 qwk=('0.2285', '0.5510', '0.5161') averageQWK=0.4319 macroEMD=0.3726 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    2   53    0    0
     0    0  123    1    1
     0    0   88   25    3
     0    0   19    1    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   21   28    4    0
     0   25   79   18    0
     0    4   51   78    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   61    7    1    0
     0   82   54   16    0
     0   11   47   44    0
     0    0    1    1    0
[epoch 9] step 2/44: loss=9.1169 
[epoch 9] step 4/44: loss=8.5657 
[epoch 9] step 6/44: loss=8.0498 
[epoch 9] step 8/44: loss=7.9442 
[epoch 9] step 10/44: loss=7.8201 
[epoch 9] step 12/44: loss=7.8004 
[epoch 9] step 14/44: loss=7.9394 
[epoch 9] step 16/44: loss=8.0999 
[epoch 9] step 18/44: loss=8.1857 
[epoch 9] step 20/44: loss=8.1849 
[epoch 9] step 22/44: loss=8.0689 
[epoch 9] step 24/44: loss=7.8617 
[epoch 9] step 26/44: loss=7.7417 
[epoch 9] step 28/44: loss=7.8026 
[epoch 9] step 30/44: loss=7.9513 
[epoch 9] step 32/44: loss=8.1212 
[epoch 9] step 34/44: loss=8.1963 
[epoch 9] step 36/44: loss=8.1813 
[epoch 9] step 38/44: loss=8.1404 
[epoch 9] step 40/44: loss=8.0630 
[epoch 9] step 42/44: loss=8.0634 
[epoch 9] step 44/44: loss=8.0128 
[epoch 9] train_loss(avg per step)=16.0256 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=9.8298 qwk=('0.5306', '0.5358', '0.6414') averageQWK=0.5693 macroEMD=0.3718 tailR0=('0.0217', '0.0556', '0.0000') tailR0avg=0.0258
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    0    0
     0    1   51    3    0
     0    0  100   25    0
     0    0   29   86    1
     0    0    1   21    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    6    1    0
     0    2   46    5    0
     0    0   86   36    0
     0    0   19  114    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   41   27    1    0
     0   36   94   22    0
     0    2   30   70    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=8.6404 
[epoch 10] step 4/44: loss=8.6345 
[epoch 10] step 6/44: loss=8.4306 
[epoch 10] step 8/44: loss=8.2748 
[epoch 10] step 10/44: loss=7.8856 
[epoch 10] step 12/44: loss=7.7927 
[epoch 10] step 14/44: loss=7.8272 
[epoch 10] step 16/44: loss=7.7179 
[epoch 10] step 18/44: loss=7.8745 
[epoch 10] step 20/44: loss=8.0605 
[epoch 10] step 22/44: loss=8.1667 
[epoch 10] step 24/44: loss=8.2012 
[epoch 10] step 26/44: loss=8.1636 
[epoch 10] step 28/44: loss=8.0610 
[epoch 10] step 30/44: loss=7.9596 
[epoch 10] step 32/44: loss=7.9359 
[epoch 10] step 34/44: loss=7.9337 
[epoch 10] step 36/44: loss=7.9861 
[epoch 10] step 38/44: loss=8.0244 
[epoch 10] step 40/44: loss=8.0647 
[epoch 10] step 42/44: loss=8.1122 
[epoch 10] step 44/44: loss=8.0759 
[epoch 10] train_loss(avg per step)=16.1518 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=9.9451 qwk=('0.4352', '0.6223', '0.6062') averageQWK=0.5545 macroEMD=0.3671 tailR0=('0.0435', '0.0556', '0.0000') tailR0avg=0.0330
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   13   41    1    0
     0    4  112    8    1
     0    1   64   46    5
     0    0   16    5    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    1    0
     0   23   24    6    0
     0   24   61   37    0
     0    2   18  113    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   30   34    5    0
     0   20   89   43    0
     0    0   16   86    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=8.0253 
[epoch 11] step 4/44: loss=8.3386 
[epoch 11] step 6/44: loss=8.0327 
[epoch 11] step 8/44: loss=7.8675 
[epoch 11] step 10/44: loss=7.7479 
[epoch 11] step 12/44: loss=7.7962 
[epoch 11] step 14/44: loss=7.7947 
[epoch 11] step 16/44: loss=7.9134 
[epoch 11] step 18/44: loss=7.9235 
[epoch 11] step 20/44: loss=7.9021 
[epoch 11] step 22/44: loss=7.8491 
[epoch 11] step 24/44: loss=7.8516 
[epoch 11] step 26/44: loss=7.8717 
[epoch 11] step 28/44: loss=7.8313 
[epoch 11] step 30/44: loss=7.8533 
[epoch 11] step 32/44: loss=7.8463 
[epoch 11] step 34/44: loss=7.8074 
[epoch 11] step 36/44: loss=7.8171 
[epoch 11] step 38/44: loss=7.8036 
[epoch 11] step 40/44: loss=7.8367 
[epoch 11] step 42/44: loss=7.8470 
[epoch 11] step 44/44: loss=7.8823 
[epoch 11] train_loss(avg per step)=15.7646 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=9.8427 qwk=('0.6486', '0.6291', '0.5047') averageQWK=0.5942 macroEMD=0.3677 tailR0=('0.0935', '0.0000', '0.0000') tailR0avg=0.0312
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    8    0    1    0
     3   39    7    5    1
     0   38   34   53    0
     0    3    7  105    1
     0    1    0   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   16   34    3    0
     0    7   94   21    0
     0    1   36   96    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   43   26    0    0
     0   38  106    8    0
     0    2   68   32    0
     0    0    2    0    0
[epoch 12] step 2/44: loss=8.1329 
[epoch 12] step 4/44: loss=8.0877 
[epoch 12] step 6/44: loss=8.0529 
[epoch 12] step 8/44: loss=7.8365 
[epoch 12] step 10/44: loss=7.7549 
[epoch 12] step 12/44: loss=7.8618 
[epoch 12] step 14/44: loss=7.8265 
[epoch 12] step 16/44: loss=7.8935 
[epoch 12] step 18/44: loss=7.9392 
[epoch 12] step 20/44: loss=7.9759 
[epoch 12] step 22/44: loss=8.0068 
[epoch 12] step 24/44: loss=8.0327 
[epoch 12] step 26/44: loss=8.1161 
[epoch 12] step 28/44: loss=8.1179 
[epoch 12] step 30/44: loss=8.0644 
[epoch 12] step 32/44: loss=7.9428 
[epoch 12] step 34/44: loss=7.8943 
[epoch 12] step 36/44: loss=7.8816 
[epoch 12] step 38/44: loss=7.8954 
[epoch 12] step 40/44: loss=7.9393 
[epoch 12] step 42/44: loss=7.9994 
[epoch 12] step 44/44: loss=8.0062 
[epoch 12] train_loss(avg per step)=16.0125 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=9.9254 qwk=('0.5789', '0.5956', '0.5853') averageQWK=0.5866 macroEMD=0.3618 tailR0=('0.0000', '0.0556', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   18   34    3    0
     0   11   63   51    0
     0    2   20   94    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     0   16   31    6    0
     0    7   68   47    0
     0    1   17  115    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   23   41    5    0
     0   11   89   52    0
     0    0   13   89    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=8.3652 
[epoch 13] step 4/44: loss=8.2701 
[epoch 13] step 6/44: loss=8.2207 
[epoch 13] step 8/44: loss=8.2810 
[epoch 13] step 10/44: loss=8.2730 
[epoch 13] step 12/44: loss=8.2387 
[epoch 13] step 14/44: loss=8.0179 
[epoch 13] step 16/44: loss=7.8764 
[epoch 13] step 18/44: loss=7.7493 
[epoch 13] step 20/44: loss=7.7590 
[epoch 13] step 22/44: loss=7.7410 
[epoch 13] step 24/44: loss=7.8316 
[epoch 13] step 26/44: loss=7.9474 
[epoch 13] step 28/44: loss=7.9756 
[epoch 13] step 30/44: loss=7.9620 
[epoch 13] step 32/44: loss=7.9511 
[epoch 13] step 34/44: loss=7.9448 
[epoch 13] step 36/44: loss=7.9291 
[epoch 13] step 38/44: loss=7.8865 
[epoch 13] step 40/44: loss=7.8809 
[epoch 13] step 42/44: loss=7.8528 
[epoch 13] step 44/44: loss=7.8485 
[epoch 13] train_loss(avg per step)=15.6971 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=9.8914 qwk=('0.5307', '0.6108', '0.5223') averageQWK=0.5546 macroEMD=0.3685 tailR0=('0.2891', '0.0556', '0.0000') tailR0avg=0.1149
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    8    0    0
     0    6   48    1    0
     0    1  105   17    2
     0    0   49   57   10
     0    0    6    6   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     1   11   37    4    0
     0    8   78   35    1
     0    0   17  116    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   16   51    2    0
     0    8  122   22    0
     0    0   41   61    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=7.7047 
[epoch 14] step 4/44: loss=7.7760 
[epoch 14] step 6/44: loss=7.5832 
[epoch 14] step 8/44: loss=7.6861 
[epoch 14] step 10/44: loss=7.7931 
[epoch 14] step 12/44: loss=8.0088 
[epoch 14] step 14/44: loss=8.1087 
[epoch 14] step 16/44: loss=8.1524 
[epoch 14] step 18/44: loss=8.1152 
[epoch 14] step 20/44: loss=8.0331 
[epoch 14] step 22/44: loss=7.9484 
[epoch 14] step 24/44: loss=7.9075 
[epoch 14] step 26/44: loss=7.8975 
[epoch 14] step 28/44: loss=7.8845 
[epoch 14] step 30/44: loss=7.8657 
[epoch 14] step 32/44: loss=7.8709 
[epoch 14] step 34/44: loss=7.8856 
[epoch 14] step 36/44: loss=7.9232 
[epoch 14] step 38/44: loss=7.9934 
[epoch 14] step 40/44: loss=8.0301 
[epoch 14] step 42/44: loss=8.0444 
[epoch 14] step 44/44: loss=8.0531 
[epoch 14] train_loss(avg per step)=16.1063 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=10.2034 qwk=('0.5842', '0.5716', '0.5449') averageQWK=0.5669 macroEMD=0.3694 tailR0=('0.2739', '0.2083', '0.0000') tailR0avg=0.1607
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    4    0    0
     4   11   39    1    0
     0    4   97   22    2
     0    1   51   55    9
     0    0    4   11    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    2    1    0
     0    8   43    2    0
     1    2   98   21    0
     0    0   44   89    0
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   22   46    1    0
     0    8  128   16    0
     0    0   45   57    0
     0    0    1    1    0
[epoch 15] step 2/44: loss=7.1560 
[epoch 15] step 4/44: loss=6.9208 
[epoch 15] step 6/44: loss=6.6422 
[epoch 15] step 8/44: loss=6.6878 
[epoch 15] step 10/44: loss=6.9537 
[epoch 15] step 12/44: loss=7.4262 
[epoch 15] step 14/44: loss=7.8442 
[epoch 15] step 16/44: loss=8.1467 
[epoch 15] step 18/44: loss=8.2517 
[epoch 15] step 20/44: loss=8.2314 
[epoch 15] step 22/44: loss=8.0940 
[epoch 15] step 24/44: loss=7.9658 
[epoch 15] step 26/44: loss=7.8579 
[epoch 15] step 28/44: loss=7.8208 
[epoch 15] step 30/44: loss=7.8187 
[epoch 15] step 32/44: loss=7.8772 
[epoch 15] step 34/44: loss=7.8927 
[epoch 15] step 36/44: loss=7.9340 
[epoch 15] step 38/44: loss=7.9556 
[epoch 15] step 40/44: loss=7.9660 
[epoch 15] step 42/44: loss=8.0134 
[epoch 15] step 44/44: loss=8.0281 
[epoch 15] train_loss(avg per step)=16.0562 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=10.2368 qwk=('0.6147', '0.6345', '0.5974') averageQWK=0.6155 macroEMD=0.3689 tailR0=('0.3391', '0.0556', '0.1250') tailR0avg=0.1732
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    1    1    0
     1   17   33    2    2
     0    9   79   32    5
     0    1   27   72   16
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     0   25   24    4    0
     0   13   80   29    0
     0    1   28  104    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     0   26   42    1    0
     0    8  117   27    0
     0    0   34   68    0
     0    0    1    1    0
[epoch 16] step 2/44: loss=6.9763 
[epoch 16] step 4/44: loss=6.6873 
[epoch 16] step 6/44: loss=6.5268 
[epoch 16] step 8/44: loss=6.9629 
[epoch 16] step 10/44: loss=7.3081 
[epoch 16] step 12/44: loss=7.6378 
[epoch 16] step 14/44: loss=7.6709 
[epoch 16] step 16/44: loss=7.7131 
[epoch 16] step 18/44: loss=7.7934 
[epoch 16] step 20/44: loss=7.8948 
[epoch 16] step 22/44: loss=7.8462 
[epoch 16] step 24/44: loss=7.7579 
[epoch 16] step 26/44: loss=7.7503 
[epoch 16] step 28/44: loss=7.7204 
[epoch 16] step 30/44: loss=7.7127 
[epoch 16] step 32/44: loss=7.7016 
[epoch 16] step 34/44: loss=7.7129 
[epoch 16] step 36/44: loss=7.7556 
[epoch 16] step 38/44: loss=7.7775 
[epoch 16] step 40/44: loss=7.8138 
[epoch 16] step 42/44: loss=7.8337 
[epoch 16] step 44/44: loss=7.8111 
[epoch 16] train_loss(avg per step)=15.6221 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=10.0099 qwk=('0.5796', '0.6281', '0.6316') averageQWK=0.6131 macroEMD=0.3656 tailR0=('0.2522', '0.0556', '0.1250') tailR0avg=0.1442
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    3    0    0
     4   14   34    2    1
     2    8   84   27    4
     0    3   32   73    8
     0    0    4   12    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     0   27   19    7    0
     0   22   61   39    0
     0    3   12  118    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   39   29    1    0
     0   26   92   34    0
     0    1   28   73    0
     0    0    1    1    0
[epoch 17] step 2/44: loss=8.0943 
[epoch 17] step 4/44: loss=7.8626 
[epoch 17] step 6/44: loss=7.8944 
[epoch 17] step 8/44: loss=8.1100 
[epoch 17] step 10/44: loss=7.9852 
[epoch 17] step 12/44: loss=7.9227 
[epoch 17] step 14/44: loss=7.9019 
[epoch 17] step 16/44: loss=7.8519 
[epoch 17] step 18/44: loss=7.8151 
[epoch 17] step 20/44: loss=7.7981 
[epoch 17] step 22/44: loss=7.9067 
[epoch 17] step 24/44: loss=8.0103 
[epoch 17] step 26/44: loss=8.0234 
[epoch 17] step 28/44: loss=8.0032 
[epoch 17] step 30/44: loss=7.9327 
[epoch 17] step 32/44: loss=7.8823 
[epoch 17] step 34/44: loss=7.8882 
[epoch 17] step 36/44: loss=7.9393 
[epoch 17] step 38/44: loss=7.9750 
[epoch 17] step 40/44: loss=7.9429 
[epoch 17] step 42/44: loss=7.9433 
[epoch 17] step 44/44: loss=7.8937 
[epoch 17] train_loss(avg per step)=15.7874 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=10.1454 qwk=('0.6228', '0.6478', '0.6147') averageQWK=0.6284 macroEMD=0.3635 tailR0=('0.2957', '0.0556', '0.1250') tailR0avg=0.1587
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    2    0    0
     4   20   29    2    0
     1   13   88   20    3
     0    2   44   59   11
     0    0    4   10    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    1    0
     0   33   16    4    0
     0   32   60   30    0
     0    4   22  107    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   43   20    6    0
     0   25   76   51    0
     0    0   24   78    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=7.5745 
[epoch 18] step 4/44: loss=7.9265 
[epoch 18] step 6/44: loss=8.0728 
[epoch 18] step 8/44: loss=8.2277 
[epoch 18] step 10/44: loss=8.2646 
[epoch 18] step 12/44: loss=8.2020 
[epoch 18] step 14/44: loss=8.0087 
[epoch 18] step 16/44: loss=7.9096 
[epoch 18] step 18/44: loss=7.8923 
[epoch 18] step 20/44: loss=7.9106 
[epoch 18] step 22/44: loss=7.8169 
[epoch 18] step 24/44: loss=7.8332 
[epoch 18] step 26/44: loss=7.8449 
[epoch 18] step 28/44: loss=7.9364 
[epoch 18] step 30/44: loss=7.9992 
[epoch 18] step 32/44: loss=7.9728 
[epoch 18] step 34/44: loss=7.9673 
[epoch 18] step 36/44: loss=7.9534 
[epoch 18] step 38/44: loss=7.9279 
[epoch 18] step 40/44: loss=7.9235 
[epoch 18] step 42/44: loss=7.8827 
[epoch 18] step 44/44: loss=7.8632 
[epoch 18] train_loss(avg per step)=15.7263 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=10.0376 qwk=('0.6272', '0.5926', '0.5769') averageQWK=0.5989 macroEMD=0.3622 tailR0=('0.1587', '0.0556', '0.1250') tailR0avg=0.1131
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    8    1    0    0
     0   26   26    3    0
     0   18   74   31    2
     0    2   31   79    4
     0    0    4   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     0   18   32    3    0
     1    9   82   30    0
     0    0   36   97    0
     0    0    3    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   24   43    2    0
     0   11  124   17    0
     0    0   41   61    0
     0    0    1    1    0
[epoch 19] step 2/44: loss=8.4128 
[epoch 19] step 4/44: loss=8.6830 
[epoch 19] step 6/44: loss=8.7742 
[epoch 19] step 8/44: loss=8.6302 
[epoch 19] step 10/44: loss=8.3334 
[epoch 19] step 12/44: loss=8.2375 
[epoch 19] step 14/44: loss=8.1468 
[epoch 19] step 16/44: loss=8.0679 
[epoch 19] step 18/44: loss=8.0205 
[epoch 19] step 20/44: loss=8.0204 
[epoch 19] step 22/44: loss=8.0759 
[epoch 19] step 24/44: loss=8.0778 
[epoch 19] step 26/44: loss=8.1406 
[epoch 19] step 28/44: loss=8.1347 
[epoch 19] step 30/44: loss=8.1113 
[epoch 19] step 32/44: loss=8.1116 
[epoch 19] step 34/44: loss=8.1101 
[epoch 19] step 36/44: loss=8.0915 
[epoch 19] step 38/44: loss=8.0574 
[epoch 19] step 40/44: loss=8.0052 
[epoch 19] step 42/44: loss=8.0024 
[epoch 19] step 44/44: loss=8.0353 
[epoch 19] train_loss(avg per step)=16.0706 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=10.3798 qwk=('0.5337', '0.5766', '0.6178') averageQWK=0.5760 macroEMD=0.3631 tailR0=('0.3174', '0.0972', '0.1250') tailR0avg=0.1799
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    4    1    1
     2   12   38    2    1
     1    5   93   22    4
     0    2   39   63   12
     0    0    3   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     0   17   33    3    0
     0   12   89   20    1
     0    0   52   79    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     1   40   25    3    0
     0   25   89   38    0
     0    1   31   70    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=8.6303 
[epoch 20] step 4/44: loss=8.4028 
[epoch 20] step 6/44: loss=8.1643 
[epoch 20] step 8/44: loss=8.2038 
[epoch 20] step 10/44: loss=8.1430 
[epoch 20] step 12/44: loss=8.0686 
[epoch 20] step 14/44: loss=7.9678 
[epoch 20] step 16/44: loss=7.8438 
[epoch 20] step 18/44: loss=7.8822 
[epoch 20] step 20/44: loss=7.9269 
[epoch 20] step 22/44: loss=7.8478 
[epoch 20] step 24/44: loss=7.8640 
[epoch 20] step 26/44: loss=7.9367 
[epoch 20] step 28/44: loss=7.9727 
[epoch 20] step 30/44: loss=7.9488 
[epoch 20] step 32/44: loss=7.9371 
[epoch 20] step 34/44: loss=7.9101 
[epoch 20] step 36/44: loss=7.8771 
[epoch 20] step 38/44: loss=7.8641 
[epoch 20] step 40/44: loss=7.8520 
[epoch 20] step 42/44: loss=7.8522 
[epoch 20] step 44/44: loss=7.8699 
[epoch 20] train_loss(avg per step)=15.7398 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=10.1699 qwk=('0.5692', '0.6175', '0.6350') averageQWK=0.6072 macroEMD=0.3623 tailR0=('0.1435', '0.0972', '0.1250') tailR0avg=0.1219
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    2    0    0
     1   21   29    4    0
     0   18   84   21    2
     0    2   41   71    2
     0    1    4   16    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    1    0
     0   27   23    3    0
     0   23   73   26    0
     0    4   33   94    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     2   40   26    1    0
     0   26  104   22    0
     0    0   40   62    0
     0    0    1    1    0
[epoch 21] step 2/44: loss=8.2233 
[epoch 21] step 4/44: loss=8.3012 
[epoch 21] step 6/44: loss=8.7115 
[epoch 21] step 8/44: loss=8.4811 
[epoch 21] step 10/44: loss=8.2635 
[epoch 21] step 12/44: loss=8.1585 
[epoch 21] step 14/44: loss=8.0176 
[epoch 21] step 16/44: loss=7.9731 
[epoch 21] step 18/44: loss=8.0384 
[epoch 21] step 20/44: loss=8.1026 
[epoch 21] step 22/44: loss=8.0801 
[epoch 21] step 24/44: loss=8.1609 
[epoch 21] step 26/44: loss=8.1512 
[epoch 21] step 28/44: loss=8.0735 
[epoch 21] step 30/44: loss=7.9754 
[epoch 21] step 32/44: loss=7.9561 
[epoch 21] step 34/44: loss=7.9462 
[epoch 21] step 36/44: loss=7.8829 
[epoch 21] step 38/44: loss=7.8611 
[epoch 21] step 40/44: loss=7.8571 
[epoch 21] step 42/44: loss=7.8884 
[epoch 21] step 44/44: loss=7.9849 
[epoch 21] train_loss(avg per step)=15.9697 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=10.3992 qwk=('0.5893', '0.6106', '0.5228') averageQWK=0.5742 macroEMD=0.3622 tailR0=('0.2957', '0.2222', '0.1250') tailR0avg=0.2143
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    5    0    0
     0   18   35    2    0
     0    7   95   21    2
     0    2   42   63    9
     0    0    5    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    1    0
     0   25   25    2    1
     0   25   67   26    4
     0    2   30   92    9
     0    0    1    7    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   25   36    8    0
     0   16   93   43    0
     0    0   30   72    0
     0    0    1    1    0
[epoch 22] step 2/44: loss=7.5058 
[epoch 22] step 4/44: loss=8.0159 
[epoch 22] step 6/44: loss=7.8976 
[epoch 22] step 8/44: loss=7.9416 
[epoch 22] step 10/44: loss=7.9086 
[epoch 22] step 12/44: loss=7.8756 
[epoch 22] step 14/44: loss=7.9492 
[epoch 22] step 16/44: loss=7.9170 
[epoch 22] step 18/44: loss=7.9004 
[epoch 22] step 20/44: loss=7.9059 
[epoch 22] step 22/44: loss=7.9735 
[epoch 22] step 24/44: loss=7.9877 
[epoch 22] step 26/44: loss=7.9962 
[epoch 22] step 28/44: loss=8.0350 
[epoch 22] step 30/44: loss=8.0641 
[epoch 22] step 32/44: loss=8.0812 
[epoch 22] step 34/44: loss=8.1031 
[epoch 22] step 36/44: loss=8.1107 
[epoch 22] step 38/44: loss=8.1032 
[epoch 22] step 40/44: loss=8.0565 
[epoch 22] step 42/44: loss=7.9872 
[epoch 22] step 44/44: loss=7.9487 
[epoch 22] train_loss(avg per step)=15.8973 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=10.4224 qwk=('0.5163', '0.5532', '0.5365') averageQWK=0.5353 macroEMD=0.3666 tailR0=('0.1435', '0.1389', '0.1250') tailR0avg=0.1358
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    3    0    0
     0   20   33    2    0
     0   10   95   18    2
     0    3   52   58    3
     0    1    7   13    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     0   23   28    1    1
     0   18   92   11    1
     0    2   62   65    4
     0    0    3    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   26   37    6    0
     0   18   96   38    0
     0    0   33   69    0
     0    0    1    1    0
[epoch 23] step 2/44: loss=7.0822 
[epoch 23] step 4/44: loss=7.2814 
[epoch 23] step 6/44: loss=7.5733 
[epoch 23] step 8/44: loss=7.8233 
[epoch 23] step 10/44: loss=8.0101 
[epoch 23] step 12/44: loss=8.0892 
[epoch 23] step 14/44: loss=8.0661 
[epoch 23] step 16/44: loss=8.0943 
[epoch 23] step 18/44: loss=8.0498 
[epoch 23] step 20/44: loss=8.0233 
[epoch 23] step 22/44: loss=8.0456 
[epoch 23] step 24/44: loss=8.0712 
[epoch 23] step 26/44: loss=8.0254 
[epoch 23] step 28/44: loss=7.9845 
[epoch 23] step 30/44: loss=8.0015 
[epoch 23] step 32/44: loss=7.9828 
[epoch 23] step 34/44: loss=7.9986 
[epoch 23] step 36/44: loss=7.9667 
[epoch 23] step 38/44: loss=7.9592 
[epoch 23] step 40/44: loss=7.9621 
[epoch 23] step 42/44: loss=7.9954 
[epoch 23] step 44/44: loss=8.0151 
[epoch 23] train_loss(avg per step)=16.0302 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=10.5231 qwk=('0.5560', '0.5644', '0.4372') averageQWK=0.5192 macroEMD=0.3657 tailR0=('0.2304', '0.0556', '0.1250') tailR0avg=0.1370
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    1    0
     1   12   33    9    0
     0    5   69   49    2
     0    1   21   89    5
     0    0    0   17    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    5    1    0
     0   14   33    5    1
     0    7   78   37    0
     0    0   22  109    2
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    3    0    0
     0    9   53    7    0
     0    4   97   51    0
     0    0   29   73    0
     0    0    1    1    0
[epoch 24] step 2/44: loss=8.7536 
[epoch 24] step 4/44: loss=8.4105 
[epoch 24] step 6/44: loss=7.9762 
[epoch 24] step 8/44: loss=7.6175 
[epoch 24] step 10/44: loss=7.5696 
[epoch 24] step 12/44: loss=7.5263 
[epoch 24] step 14/44: loss=7.5611 
[epoch 24] step 16/44: loss=7.6470 
[epoch 24] step 18/44: loss=7.7412 
[epoch 24] step 20/44: loss=7.7930 
[epoch 24] step 22/44: loss=7.7727 
[epoch 24] step 24/44: loss=7.7132 
[epoch 24] step 26/44: loss=7.7161 
[epoch 24] step 28/44: loss=7.7229 
[epoch 24] step 30/44: loss=7.7375 
[epoch 24] step 32/44: loss=7.7325 
[epoch 24] step 34/44: loss=7.7441 
[epoch 24] step 36/44: loss=7.7701 
[epoch 24] step 38/44: loss=7.7593 
[epoch 24] step 40/44: loss=7.7945 
[epoch 24] step 42/44: loss=7.7884 
[epoch 24] step 44/44: loss=7.8346 
[epoch 24] train_loss(avg per step)=15.6692 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=10.1762 qwk=('0.6182', '0.6467', '0.5499') averageQWK=0.6049 macroEMD=0.3649 tailR0=('0.2522', '0.2222', '0.1250') tailR0avg=0.1998
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    1    0
     0   20   31    4    0
     0    9   75   38    3
     0    1   23   81   11
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     0   22   28    2    1
     0   12   82   27    1
     0    2   23   99    9
     0    0    0    8    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   32   31    6    0
     0   18   91   43    0
     0    0   34   68    0
     0    0    1    1    0
[epoch 25] step 2/44: loss=8.0756 
[epoch 25] step 4/44: loss=7.7832 
[epoch 25] step 6/44: loss=7.7412 
[epoch 25] step 8/44: loss=7.9217 
[epoch 25] step 10/44: loss=7.9678 
[epoch 25] step 12/44: loss=7.8882 
[epoch 25] step 14/44: loss=7.9237 
[epoch 25] step 16/44: loss=8.0036 
[epoch 25] step 18/44: loss=7.9591 
[epoch 25] step 20/44: loss=7.9082 
[epoch 25] step 22/44: loss=7.9200 
[epoch 25] step 24/44: loss=7.8792 
[epoch 25] step 26/44: loss=7.8879 
[epoch 25] step 28/44: loss=7.8775 
[epoch 25] step 30/44: loss=7.8633 
[epoch 25] step 32/44: loss=7.8349 
[epoch 25] step 34/44: loss=7.8245 
[epoch 25] step 36/44: loss=7.8085 
[epoch 25] step 38/44: loss=7.8192 
[epoch 25] step 40/44: loss=7.8084 
[epoch 25] step 42/44: loss=7.8488 
[epoch 25] step 44/44: loss=7.8787 
[epoch 25] train_loss(avg per step)=15.7574 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=10.3527 qwk=('0.5916', '0.5962', '0.5224') averageQWK=0.5701 macroEMD=0.3636 tailR0=('0.1435', '0.1389', '0.1250') tailR0avg=0.1358
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    7    1    0    0
     1   19   28    7    0
     0   14   65   44    2
     0    2   23   88    3
     0    0    2   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     0   25   24    3    1
     1   14   86   20    1
     0    0   43   86    4
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   26   35    8    0
     0   16   81   55    0
     0    0   26   76    0
     0    0    1    1    0
[epoch 26] step 2/44: loss=8.2101 
[epoch 26] step 4/44: loss=8.1629 
[epoch 26] step 6/44: loss=7.9686 
[epoch 26] step 8/44: loss=7.7844 
[epoch 26] step 10/44: loss=7.7642 
[epoch 26] step 12/44: loss=7.8561 
[epoch 26] step 14/44: loss=7.9774 
[epoch 26] step 16/44: loss=8.1272 
[epoch 26] step 18/44: loss=8.2039 
[epoch 26] step 20/44: loss=8.2272 
[epoch 26] step 22/44: loss=8.1976 
[epoch 26] step 24/44: loss=8.1018 
[epoch 26] step 26/44: loss=8.0560 
[epoch 26] step 28/44: loss=7.9922 
[epoch 26] step 30/44: loss=7.9520 
[epoch 26] step 32/44: loss=7.9242 
[epoch 26] step 34/44: loss=7.9178 
[epoch 26] step 36/44: loss=7.9135 
[epoch 26] step 38/44: loss=7.9296 
[epoch 26] step 40/44: loss=7.9324 
[epoch 26] step 42/44: loss=7.9069 
[epoch 26] step 44/44: loss=7.8969 
[epoch 26] train_loss(avg per step)=15.7938 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=10.3962 qwk=('0.6085', '0.6442', '0.5189') averageQWK=0.5905 macroEMD=0.3656 tailR0=('0.2087', '0.1528', '0.1250') tailR0avg=0.1622
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    4    0    0
     1   21   29    4    0
     0   12   78   33    2
     0    2   30   77    7
     0    0    2   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    1    0
     0   25   24    4    0
     1   17   79   25    0
     0    1   30  100    2
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     0   21   45    3    0
     0   13  114   25    0
     0    0   42   60    0
     0    0    1    1    0
[epoch 27] step 2/44: loss=8.3009 
[epoch 27] step 4/44: loss=8.2025 
[epoch 27] step 6/44: loss=8.1900 
[epoch 27] step 8/44: loss=8.0793 
[epoch 27] step 10/44: loss=7.9059 
[epoch 27] step 12/44: loss=7.8462 
[epoch 27] step 14/44: loss=7.7532 
[epoch 27] step 16/44: loss=7.6839 
[epoch 27] step 18/44: loss=7.7566 
[epoch 27] step 20/44: loss=7.8886 
[epoch 27] step 22/44: loss=7.9508 
[epoch 27] step 24/44: loss=7.9858 
[epoch 27] step 26/44: loss=8.0317 
[epoch 27] step 28/44: loss=8.0306 
[epoch 27] step 30/44: loss=8.0723 
[epoch 27] step 32/44: loss=8.0682 
[epoch 27] step 34/44: loss=7.9990 
[epoch 27] step 36/44: loss=7.9503 
[epoch 27] step 38/44: loss=7.9146 
[epoch 27] step 40/44: loss=7.8450 
[epoch 27] step 42/44: loss=7.8467 
[epoch 27] step 44/44: loss=7.8422 
[epoch 27] train_loss(avg per step)=15.6844 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=10.2965 qwk=('0.5654', '0.6143', '0.5774') averageQWK=0.5857 macroEMD=0.3646 tailR0=('0.2087', '0.0556', '0.1250') tailR0avg=0.1298
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    1
     1   21   29    4    0
     0   11   91   21    2
     0    1   44   66    5
     0    0    4   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     0   22   25    6    0
     1   16   73   32    0
     0    2   21  108    2
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   33   34    2    0
     0   21  101   30    0
     0    1   38   63    0
     0    0    1    1    0
[epoch 28] step 2/44: loss=8.5170 
[epoch 28] step 4/44: loss=8.1372 
[epoch 28] step 6/44: loss=8.1307 
[epoch 28] step 8/44: loss=8.0587 
[epoch 28] step 10/44: loss=8.1154 
[epoch 28] step 12/44: loss=8.1992 
[epoch 28] step 14/44: loss=8.1716 
[epoch 28] step 16/44: loss=8.0532 
[epoch 28] step 18/44: loss=8.0550 
[epoch 28] step 20/44: loss=8.0728 
[epoch 28] step 22/44: loss=8.0452 
[epoch 28] step 24/44: loss=8.0217 
[epoch 28] step 26/44: loss=8.0089 
[epoch 28] step 28/44: loss=7.9996 
[epoch 28] step 30/44: loss=7.9912 
[epoch 28] step 32/44: loss=7.9788 
[epoch 28] step 34/44: loss=7.9702 
[epoch 28] step 36/44: loss=7.9600 
[epoch 28] step 38/44: loss=8.0013 
[epoch 28] step 40/44: loss=8.0158 
[epoch 28] step 42/44: loss=8.0166 
[epoch 28] step 44/44: loss=8.0429 
[epoch 28] train_loss(avg per step)=16.0859 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=10.6403 qwk=('0.5966', '0.5897', '0.5236') averageQWK=0.5700 macroEMD=0.3646 tailR0=('0.2087', '0.0556', '0.1250') tailR0avg=0.1298
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    1
     1   21   29    4    0
     0   12   73   39    1
     0    2   24   85    5
     0    0    2   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     0   18   30    4    1
     1   13   80   28    0
     0    1   27  104    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   23   39    7    0
     0   15   90   47    0
     0    0   28   74    0
     0    0    1    1    0
[epoch 29] step 2/44: loss=8.5463 
[epoch 29] step 4/44: loss=8.0877 
[epoch 29] step 6/44: loss=8.1439 
[epoch 29] step 8/44: loss=8.1728 
[epoch 29] step 10/44: loss=8.1059 
[epoch 29] step 12/44: loss=7.9790 
[epoch 29] step 14/44: loss=7.8473 
[epoch 29] step 16/44: loss=7.7652 
[epoch 29] step 18/44: loss=7.6925 
[epoch 29] step 20/44: loss=7.7117 
[epoch 29] step 22/44: loss=7.6664 
[epoch 29] step 24/44: loss=7.7199 
[epoch 29] step 26/44: loss=7.7063 
[epoch 29] step 28/44: loss=7.7641 
[epoch 29] step 30/44: loss=7.7555 
[epoch 29] step 32/44: loss=7.7464 
[epoch 29] step 34/44: loss=7.7841 
[epoch 29] step 36/44: loss=7.8409 
[epoch 29] step 38/44: loss=7.8498 
[epoch 29] step 40/44: loss=7.8699 
[epoch 29] step 42/44: loss=7.8384 
[epoch 29] step 44/44: loss=7.8521 
[epoch 29] train_loss(avg per step)=15.7042 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=10.3584 qwk=('0.6181', '0.6390', '0.5821') averageQWK=0.6131 macroEMD=0.3656 tailR0=('0.2304', '0.0972', '0.1250') tailR0avg=0.1509
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    7    1    0    0
     1   23   27    4    0
     0   17   68   36    4
     0    2   28   76   10
     0    0    3   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     0   26   23    3    1
     1   16   80   25    0
     0    1   28  100    4
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   34   33    2    0
     0   18   96   38    0
     0    0   38   64    0
     0    0    1    1    0
[epoch 30] step 2/44: loss=7.4117 
[epoch 30] step 4/44: loss=7.3702 
[epoch 30] step 6/44: loss=7.6437 
[epoch 30] step 8/44: loss=7.6941 
[epoch 30] step 10/44: loss=7.7786 
[epoch 30] step 12/44: loss=7.8283 
[epoch 30] step 14/44: loss=7.8607 
[epoch 30] step 16/44: loss=7.9562 
[epoch 30] step 18/44: loss=8.0502 
[epoch 30] step 20/44: loss=8.0477 
[epoch 30] step 22/44: loss=7.9648 
[epoch 30] step 24/44: loss=7.9931 
[epoch 30] step 26/44: loss=7.9692 
[epoch 30] step 28/44: loss=7.9025 
[epoch 30] step 30/44: loss=7.8325 
[epoch 30] step 32/44: loss=7.7996 
[epoch 30] step 34/44: loss=7.8033 
[epoch 30] step 36/44: loss=7.8044 
[epoch 30] step 38/44: loss=7.8151 
[epoch 30] step 40/44: loss=7.8601 
[epoch 30] step 42/44: loss=7.8838 
[epoch 30] step 44/44: loss=7.8969 
[epoch 30] train_loss(avg per step)=15.7939 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=10.3504 qwk=('0.5658', '0.6000', '0.5524') averageQWK=0.5727 macroEMD=0.3643 tailR0=('0.2304', '0.1389', '0.1250') tailR0avg=0.1648
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    0    1
     1   23   27    4    0
     0   19   76   27    3
     0    2   35   68   11
     0    0    6   11    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     1   24   24    3    1
     1   15   84   21    1
     0    1   38   91    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   30   35    4    0
     0   19   93   40    0
     0    0   36   66    0
     0    0    1    1    0
[epoch 31] step 2/44: loss=8.1633 
[epoch 31] step 4/44: loss=7.8814 
[epoch 31] step 6/44: loss=7.8718 
[epoch 31] step 8/44: loss=7.8676 
[epoch 31] step 10/44: loss=7.8033 
[epoch 31] step 12/44: loss=7.8064 
[epoch 31] step 14/44: loss=7.8121 
[epoch 31] step 16/44: loss=7.9593 
[epoch 31] step 18/44: loss=8.0119 
[epoch 31] step 20/44: loss=7.9639 
[epoch 31] step 22/44: loss=8.0326 
[epoch 31] step 24/44: loss=8.0968 
[epoch 31] step 26/44: loss=8.1054 
[epoch 31] step 28/44: loss=8.0238 
[epoch 31] step 30/44: loss=7.9701 
[epoch 31] step 32/44: loss=7.9476 
[epoch 31] step 34/44: loss=7.8985 
[epoch 31] step 36/44: loss=7.8734 
[epoch 31] step 38/44: loss=7.8676 
[epoch 31] step 40/44: loss=7.8843 
[epoch 31] step 42/44: loss=7.9224 
[epoch 31] step 44/44: loss=7.9102 
[epoch 31] train_loss(avg per step)=15.8204 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=10.4920 qwk=('0.5785', '0.6154', '0.5418') averageQWK=0.5786 macroEMD=0.3660 tailR0=('0.2957', '0.2222', '0.1250') tailR0avg=0.2143
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    6    0    0
     1   19   31    4    0
     0    6   94   22    3
     0    2   39   63   12
     0    0    5    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     0   20   29    3    1
     1   12   85   23    1
     0    0   34   94    5
     0    0    0    8    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   31   32    6    0
     0   21   88   43    0
     0    0   34   68    0
     0    0    1    1    0
[epoch 32] step 2/44: loss=7.5156 
[epoch 32] step 4/44: loss=7.7856 
[epoch 32] step 6/44: loss=8.0194 
[epoch 32] step 8/44: loss=8.1867 
[epoch 32] step 10/44: loss=8.2076 
[epoch 32] step 12/44: loss=8.1226 
[epoch 32] step 14/44: loss=8.1051 
[epoch 32] step 16/44: loss=8.0995 
[epoch 32] step 18/44: loss=8.0357 
[epoch 32] step 20/44: loss=8.0073 
[epoch 32] step 22/44: loss=7.9758 
[epoch 32] step 24/44: loss=7.9219 
[epoch 32] step 26/44: loss=7.9396 
[epoch 32] step 28/44: loss=7.9565 
[epoch 32] step 30/44: loss=7.9177 
[epoch 32] step 32/44: loss=7.9124 
[epoch 32] step 34/44: loss=7.8968 
[epoch 32] step 36/44: loss=7.8838 
[epoch 32] step 38/44: loss=7.8522 
[epoch 32] step 40/44: loss=7.8750 
[epoch 32] step 42/44: loss=7.8768 
[epoch 32] step 44/44: loss=7.9010 
[epoch 32] train_loss(avg per step)=15.8020 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=10.4043 qwk=('0.6004', '0.6209', '0.5473') averageQWK=0.5895 macroEMD=0.3662 tailR0=('0.2304', '0.0556', '0.1250') tailR0avg=0.1370
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    2    0    0
     1   24   26    4    0
     0   15   73   33    4
     0    2   34   72    8
     0    0    4   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     0   28   21    3    1
     1   18   78   25    0
     0    4   26  101    2
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     0   28   37    4    0
     0   16  108   28    0
     0    0   39   63    0
     0    0    1    1    0
[epoch 33] step 2/44: loss=8.0897 
[epoch 33] step 4/44: loss=8.2624 
[epoch 33] step 6/44: loss=8.2770 
[epoch 33] step 8/44: loss=8.3104 
[epoch 33] step 10/44: loss=8.2329 
[epoch 33] step 12/44: loss=8.1536 
[epoch 33] step 14/44: loss=8.1143 
[epoch 33] step 16/44: loss=8.0351 
[epoch 33] step 18/44: loss=7.9104 
[epoch 33] step 20/44: loss=7.9278 
[epoch 33] step 22/44: loss=7.9190 
[epoch 33] step 24/44: loss=7.9032 
[epoch 33] step 26/44: loss=7.9061 
[epoch 33] step 28/44: loss=7.8900 
[epoch 33] step 30/44: loss=7.9227 
[epoch 33] step 32/44: loss=7.9395 
[epoch 33] step 34/44: loss=7.9046 
[epoch 33] step 36/44: loss=7.9149 
[epoch 33] step 38/44: loss=7.8974 
[epoch 33] step 40/44: loss=7.9052 
[epoch 33] step 42/44: loss=7.8853 
[epoch 33] step 44/44: loss=7.8820 
[epoch 33] train_loss(avg per step)=15.7640 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=10.4514 qwk=('0.5859', '0.6064', '0.5560') averageQWK=0.5828 macroEMD=0.3666 tailR0=('0.2739', '0.0972', '0.1250') tailR0avg=0.1654
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    3    0    0
     1   20   30    4    0
     0   12   92   18    3
     0    2   43   61   10
     0    0    6    9    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     0   24   25    3    1
     1   16   81   24    0
     0    3   32   95    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   32   32    5    0
     0   21   96   35    0
     0    0   37   65    0
     0    0    1    1    0
[epoch 34] step 2/44: loss=7.4770 
[epoch 34] step 4/44: loss=7.6918 
[epoch 34] step 6/44: loss=8.0016 
[epoch 34] step 8/44: loss=8.1135 
[epoch 34] step 10/44: loss=8.0144 
[epoch 34] step 12/44: loss=8.1329 
[epoch 34] step 14/44: loss=8.1050 
[epoch 34] step 16/44: loss=8.1495 
[epoch 34] step 18/44: loss=8.0961 
[epoch 34] step 20/44: loss=8.1393 
[epoch 34] step 22/44: loss=8.0882 
[epoch 34] step 24/44: loss=8.0867 
[epoch 34] step 26/44: loss=8.0279 
[epoch 34] step 28/44: loss=8.0264 
[epoch 34] step 30/44: loss=8.0157 
[epoch 34] step 32/44: loss=8.0168 
[epoch 34] step 34/44: loss=7.9947 
[epoch 34] step 36/44: loss=7.9731 
[epoch 34] step 38/44: loss=7.9353 
[epoch 34] step 40/44: loss=7.9522 
[epoch 34] step 42/44: loss=7.9463 
[epoch 34] step 44/44: loss=7.9183 
[epoch 34] train_loss(avg per step)=15.8365 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=10.5301 qwk=('0.5610', '0.6045', '0.5358') averageQWK=0.5671 macroEMD=0.3666 tailR0=('0.2087', '0.0972', '0.1250') tailR0avg=0.1436
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    3    0    0
     1   20   30    4    0
     0   12   79   31    3
     0    2   39   68    7
     0    0    6   12    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     0   20   29    3    1
     1   13   85   23    0
     0    1   35   94    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   32   30    7    0
     0   21   93   38    0
     0    0   37   65    0
     0    0    1    1    0
[epoch 35] step 2/44: loss=8.2760 
[epoch 35] step 4/44: loss=8.6306 
[epoch 35] step 6/44: loss=8.3572 
[epoch 35] step 8/44: loss=8.2432 
[epoch 35] step 10/44: loss=8.1474 
[epoch 35] step 12/44: loss=8.0531 
[epoch 35] step 14/44: loss=8.0297 
[epoch 35] step 16/44: loss=8.0871 
[epoch 35] step 18/44: loss=8.0735 
[epoch 35] step 20/44: loss=8.0936 
[epoch 35] step 22/44: loss=8.0617 
[epoch 35] step 24/44: loss=8.0586 
[epoch 35] step 26/44: loss=8.0255 
[epoch 35] step 28/44: loss=8.0174 
[epoch 35] step 30/44: loss=8.0017 
[epoch 35] step 32/44: loss=8.0138 
[epoch 35] step 34/44: loss=8.0066 
[epoch 35] step 36/44: loss=7.9906 
[epoch 35] step 38/44: loss=7.9723 
[epoch 35] step 40/44: loss=7.9912 
[epoch 35] step 42/44: loss=7.9902 
[epoch 35] step 44/44: loss=7.9732 
[epoch 35] train_loss(avg per step)=15.9464 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=10.6620 qwk=('0.5772', '0.6090', '0.5468') averageQWK=0.5777 macroEMD=0.3667 tailR0=('0.2087', '0.1389', '0.1250') tailR0avg=0.1575
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    2    0    0
     1   20   30    4    0
     0   11   86   25    3
     0    2   40   65    9
     0    0    6   12    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    1    0
     0   20   29    3    1
     1   15   81   25    0
     0    1   33   95    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0   32   31    6    0
     0   21   95   36    0
     0    0   37   65    0
     0    0    1    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-1-reassignment-1/fold4/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-1-reassignment-1/fold4/metrics.json
Done.
