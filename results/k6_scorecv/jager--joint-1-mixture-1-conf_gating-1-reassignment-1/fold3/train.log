[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.1171 
[epoch 1] step 4/44: loss=6.2434 
[epoch 1] step 6/44: loss=6.1828 
[epoch 1] step 8/44: loss=6.0471 
[epoch 1] step 10/44: loss=5.8935 
[epoch 1] step 12/44: loss=5.8271 
[epoch 1] step 14/44: loss=5.8518 
[epoch 1] step 16/44: loss=5.8400 
[epoch 1] step 18/44: loss=5.8487 
[epoch 1] step 20/44: loss=5.8113 
[epoch 1] step 22/44: loss=5.8462 
[epoch 1] step 24/44: loss=5.9051 
[epoch 1] step 26/44: loss=5.9400 
[epoch 1] step 28/44: loss=5.9477 
[epoch 1] step 30/44: loss=6.0022 
[epoch 1] step 32/44: loss=6.0788 
[epoch 1] step 34/44: loss=6.1333 
[epoch 1] step 36/44: loss=6.1851 
[epoch 1] step 38/44: loss=6.2392 
[epoch 1] step 40/44: loss=6.2896 
[epoch 1] step 42/44: loss=6.3475 
[epoch 1] step 44/44: loss=6.3974 
[epoch 1] train_loss(avg per step)=12.7948 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=7.8109 qwk=('0.0253', '0.0330', '0.1375') averageQWK=0.0652 macroEMD=0.3964 tailR0=('0.0000', '0.1417', '0.0000') tailR0avg=0.0472
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    0    0
     0   55    0    0    0
     0  118    2    6    0
     0  111    1    4    0
     0   19    2    1    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    8    0    0
    18    0   35    0    0
    45    0   73    1    0
    41    0   90    3    0
     3    0    7    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0   12   57    0    0
     0   11  134    2    4
     0    3   95    0    4
     0    0    1    0    0
[epoch 2] step 2/44: loss=9.1981 
[epoch 2] step 4/44: loss=9.5978 
[epoch 2] step 6/44: loss=9.9125 
[epoch 2] step 8/44: loss=10.1433 
[epoch 2] step 10/44: loss=10.4137 
[epoch 2] step 12/44: loss=10.6616 
[epoch 2] step 14/44: loss=10.8783 
[epoch 2] step 16/44: loss=10.9961 
[epoch 2] step 18/44: loss=11.1077 
[epoch 2] step 20/44: loss=11.2341 
[epoch 2] step 22/44: loss=11.3738 
[epoch 2] step 24/44: loss=11.4617 
[epoch 2] step 26/44: loss=11.5606 
[epoch 2] step 28/44: loss=11.6583 
[epoch 2] step 30/44: loss=11.7335 
[epoch 2] step 32/44: loss=11.8035 
[epoch 2] step 34/44: loss=11.8563 
[epoch 2] step 36/44: loss=11.9322 
[epoch 2] step 38/44: loss=11.9976 
[epoch 2] step 40/44: loss=12.0919 
[epoch 2] step 42/44: loss=12.1421 
[epoch 2] step 44/44: loss=12.1982 
[epoch 2] train_loss(avg per step)=24.3963 lambda[min,max]=[0.500174,1.000000]
[epoch 2] val_loss=13.6082 qwk=('0.2118', '0.3015', '0.3537') averageQWK=0.2890 macroEMD=0.3921 tailR0=('0.0000', '0.0000', '0.3000') tailR0avg=0.1000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     2    3   40   10    0
     1    1   76   48    0
     1    1   54   60    0
     0    0   11   11    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    0   52    1    0
     0    0  104   15    0
     0    0   75   59    0
     0    0    7    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    0    0    0
    30   18    0   21    0
    47   15    0   88    1
    12    0    0   90    0
     0    0    0    1    0
[epoch 3] step 2/44: loss=12.5427 
[epoch 3] step 4/44: loss=12.3758 
[epoch 3] step 6/44: loss=12.3503 
[epoch 3] step 8/44: loss=12.6110 
[epoch 3] step 10/44: loss=12.8269 
[epoch 3] step 12/44: loss=12.9133 
[epoch 3] step 14/44: loss=13.0286 
[epoch 3] step 16/44: loss=13.0333 
[epoch 3] step 18/44: loss=12.9852 
[epoch 3] step 20/44: loss=12.9567 
[epoch 3] step 22/44: loss=12.9823 
[epoch 3] step 24/44: loss=13.0051 
[epoch 3] step 26/44: loss=12.9511 
[epoch 3] step 28/44: loss=12.9304 
[epoch 3] step 30/44: loss=12.9660 
[epoch 3] step 32/44: loss=12.9661 
[epoch 3] step 34/44: loss=12.9724 
[epoch 3] step 36/44: loss=12.9674 
[epoch 3] step 38/44: loss=12.8912 
[epoch 3] step 40/44: loss=12.8789 
[epoch 3] step 42/44: loss=12.8493 
[epoch 3] step 44/44: loss=12.8543 
[epoch 3] train_loss(avg per step)=25.7086 lambda[min,max]=[0.522231,1.000000]
[epoch 3] val_loss=14.3020 qwk=('0.1350', '0.3796', '0.1954') averageQWK=0.2367 macroEMD=0.3893 tailR0=('0.0227', '0.0000', '0.1000') tailR0avg=0.0409
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    0    1
     3    0   50    0    2
     0    0  117    5    4
     0    0   89   23    4
     0    0   19    2    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    0   53    0    0
     0    0  108   11    0
     0    0   68   66    0
     0    0    4    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    3    0    0
     0    6   62    1    0
     0    1  147    3    0
     0    0   91   11    0
     0    0    1    0    0
[epoch 4] step 2/44: loss=12.1245 
[epoch 4] step 4/44: loss=12.2590 
[epoch 4] step 6/44: loss=12.3437 
[epoch 4] step 8/44: loss=12.3229 
[epoch 4] step 10/44: loss=12.2561 
[epoch 4] step 12/44: loss=12.2102 
[epoch 4] step 14/44: loss=12.0767 
[epoch 4] step 16/44: loss=11.9174 
[epoch 4] step 18/44: loss=11.7917 
[epoch 4] step 20/44: loss=11.8793 
[epoch 4] step 22/44: loss=11.9479 
[epoch 4] step 24/44: loss=11.9698 
[epoch 4] step 26/44: loss=11.8558 
[epoch 4] step 28/44: loss=11.7701 
[epoch 4] step 30/44: loss=11.6635 
[epoch 4] step 32/44: loss=11.6837 
[epoch 4] step 34/44: loss=11.7545 
[epoch 4] step 36/44: loss=11.7418 
[epoch 4] step 38/44: loss=11.7764 
[epoch 4] step 40/44: loss=11.7299 
[epoch 4] step 42/44: loss=11.6467 
[epoch 4] step 44/44: loss=11.5372 
[epoch 4] train_loss(avg per step)=23.0743 lambda[min,max]=[0.531073,1.000000]
[epoch 4] val_loss=13.2130 qwk=('0.2976', '0.3201', '0.3918') averageQWK=0.3365 macroEMD=0.3844 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   16    0   39    0
     0    7    0  119    0
     0    0    0  116    0
     0    0    0   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    2    0
     0    3   25   25    0
     0    0   32   87    0
     0    0    7  127    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0    5   62    2    0
     0    0  128   23    0
     0    0   49   53    0
     0    0    1    0    0
[epoch 5] step 2/44: loss=11.8768 
[epoch 5] step 4/44: loss=11.2122 
[epoch 5] step 6/44: loss=11.1788 
[epoch 5] step 8/44: loss=11.0346 
[epoch 5] step 10/44: loss=10.7069 
[epoch 5] step 12/44: loss=10.6235 
[epoch 5] step 14/44: loss=10.7556 
[epoch 5] step 16/44: loss=10.6786 
[epoch 5] step 18/44: loss=10.6424 
[epoch 5] step 20/44: loss=10.5362 
[epoch 5] step 22/44: loss=10.4647 
[epoch 5] step 24/44: loss=10.3099 
[epoch 5] step 26/44: loss=10.2072 
[epoch 5] step 28/44: loss=10.2555 
[epoch 5] step 30/44: loss=10.3128 
[epoch 5] step 32/44: loss=10.2748 
[epoch 5] step 34/44: loss=10.2447 
[epoch 5] step 36/44: loss=10.1558 
[epoch 5] step 38/44: loss=10.0845 
[epoch 5] step 40/44: loss=10.0242 
[epoch 5] step 42/44: loss=10.0133 
[epoch 5] step 44/44: loss=9.9749 
[epoch 5] train_loss(avg per step)=19.9499 lambda[min,max]=[0.500720,1.000000]
[epoch 5] val_loss=11.2421 qwk=('0.5557', '0.4818', '0.4624') averageQWK=0.4999 macroEMD=0.3770 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   23   22   10    0
     0   13   69   44    0
     1    3   12  100    0
     0    1    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    0   50    3    0
     0    0   92   27    0
     0    0   33  101    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0    7   54    8    0
     0    2   91   58    0
     0    0   19   83    0
     0    0    0    1    0
[epoch 6] step 2/44: loss=10.3530 
[epoch 6] step 4/44: loss=9.8759 
[epoch 6] step 6/44: loss=9.7260 
[epoch 6] step 8/44: loss=9.2559 
[epoch 6] step 10/44: loss=9.1148 
[epoch 6] step 12/44: loss=8.7429 
[epoch 6] step 14/44: loss=8.8632 
[epoch 6] step 16/44: loss=8.9948 
[epoch 6] step 18/44: loss=9.2062 
[epoch 6] step 20/44: loss=9.3061 
[epoch 6] step 22/44: loss=9.2516 
[epoch 6] step 24/44: loss=9.1279 
[epoch 6] step 26/44: loss=8.9869 
[epoch 6] step 28/44: loss=8.9209 
[epoch 6] step 30/44: loss=8.8688 
[epoch 6] step 32/44: loss=8.9324 
[epoch 6] step 34/44: loss=9.0366 
[epoch 6] step 36/44: loss=9.0689 
[epoch 6] step 38/44: loss=9.0127 
[epoch 6] step 40/44: loss=8.9593 
[epoch 6] step 42/44: loss=8.9154 
[epoch 6] step 44/44: loss=8.9536 
[epoch 6] train_loss(avg per step)=17.9072 lambda[min,max]=[0.500020,1.000000]
[epoch 6] val_loss=10.4043 qwk=('0.4382', '0.3093', '0.4265') averageQWK=0.3913 macroEMD=0.3758 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   45   10    0
     0    0   76   50    0
     0    0   16  100    0
     0    0    0   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    3    0
     0    6   16   31    0
     0    2   33   84    0
     0    0    4  130    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   23   21    0
     0   16   50   85    0
     0    2   10   90    0
     0    0    0    1    0
[epoch 7] step 2/44: loss=10.5103 
[epoch 7] step 4/44: loss=9.7447 
[epoch 7] step 6/44: loss=9.1347 
[epoch 7] step 8/44: loss=9.0435 
[epoch 7] step 10/44: loss=8.8605 
[epoch 7] step 12/44: loss=8.6411 
[epoch 7] step 14/44: loss=8.8353 
[epoch 7] step 16/44: loss=8.9950 
[epoch 7] step 18/44: loss=9.0518 
[epoch 7] step 20/44: loss=9.0525 
[epoch 7] step 22/44: loss=8.9537 
[epoch 7] step 24/44: loss=8.8745 
[epoch 7] step 26/44: loss=8.8105 
[epoch 7] step 28/44: loss=8.6819 
[epoch 7] step 30/44: loss=8.6883 
[epoch 7] step 32/44: loss=8.7704 
[epoch 7] step 34/44: loss=8.8960 
[epoch 7] step 36/44: loss=8.9529 
[epoch 7] step 38/44: loss=8.9728 
[epoch 7] step 40/44: loss=8.8890 
[epoch 7] step 42/44: loss=8.7941 
[epoch 7] step 44/44: loss=8.7112 
[epoch 7] train_loss(avg per step)=17.4225 lambda[min,max]=[0.524403,1.000000]
[epoch 7] val_loss=10.4617 qwk=('0.6049', '0.5848', '0.3829') averageQWK=0.5242 macroEMD=0.3733 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   45    7    3    0
     0   54   56   16    0
     0   11   26   77    2
     0    1    3   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    1    0
     0   44    0    9    0
     0   68    0   51    0
     0   11    0  123    0
     0    1    0   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   24   21   24    0
     0   11   52   88    0
     0    3    8   91    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=8.1499 
[epoch 8] step 4/44: loss=8.4288 
[epoch 8] step 6/44: loss=8.7646 
[epoch 8] step 8/44: loss=9.3061 
[epoch 8] step 10/44: loss=9.5827 
[epoch 8] step 12/44: loss=9.5642 
[epoch 8] step 14/44: loss=9.3832 
[epoch 8] step 16/44: loss=9.0958 
[epoch 8] step 18/44: loss=8.8714 
[epoch 8] step 20/44: loss=8.6876 
[epoch 8] step 22/44: loss=8.5801 
[epoch 8] step 24/44: loss=8.5677 
[epoch 8] step 26/44: loss=8.5489 
[epoch 8] step 28/44: loss=8.6409 
[epoch 8] step 30/44: loss=8.6975 
[epoch 8] step 32/44: loss=8.7104 
[epoch 8] step 34/44: loss=8.6833 
[epoch 8] step 36/44: loss=8.6136 
[epoch 8] step 38/44: loss=8.5514 
[epoch 8] step 40/44: loss=8.5450 
[epoch 8] step 42/44: loss=8.5484 
[epoch 8] step 44/44: loss=8.5927 
[epoch 8] train_loss(avg per step)=17.1854 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=10.2771 qwk=('0.5835', '0.5375', '0.5351') averageQWK=0.5520 macroEMD=0.3734 tailR0=('0.2045', '0.0000', '0.0000') tailR0avg=0.0682
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    0    1
     0   42    7    2    4
     0   51   47   18   10
     0    4   23   70   19
     0    1    0   12    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    0    0
     0    3   46    4    0
     0    0   95   24    0
     0    0   28  106    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   21   48    0    0
     0   11  120   20    0
     0    2   40   60    0
     0    0    1    0    0
[epoch 9] step 2/44: loss=8.2658 
[epoch 9] step 4/44: loss=7.8942 
[epoch 9] step 6/44: loss=7.9609 
[epoch 9] step 8/44: loss=8.1691 
[epoch 9] step 10/44: loss=8.2444 
[epoch 9] step 12/44: loss=8.3619 
[epoch 9] step 14/44: loss=8.2054 
[epoch 9] step 16/44: loss=8.1094 
[epoch 9] step 18/44: loss=8.2366 
[epoch 9] step 20/44: loss=8.3396 
[epoch 9] step 22/44: loss=8.4279 
[epoch 9] step 24/44: loss=8.4892 
[epoch 9] step 26/44: loss=8.5211 
[epoch 9] step 28/44: loss=8.4333 
[epoch 9] step 30/44: loss=8.3785 
[epoch 9] step 32/44: loss=8.3182 
[epoch 9] step 34/44: loss=8.2870 
[epoch 9] step 36/44: loss=8.2133 
[epoch 9] step 38/44: loss=8.1748 
[epoch 9] step 40/44: loss=8.1927 
[epoch 9] step 42/44: loss=8.2357 
[epoch 9] step 44/44: loss=8.3094 
[epoch 9] train_loss(avg per step)=16.6188 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=10.0211 qwk=('0.5943', '0.6231', '0.6085') averageQWK=0.6086 macroEMD=0.3661 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     2   28   17    8    0
     0   20   64   42    0
     0    2   21   93    0
     0    0    1   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   21   26    6    0
     0    7   75   37    0
     0    4   13  117    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   33   34    2    0
     0   17   89   45    0
     0    3   22   77    0
     0    0    0    1    0
[epoch 10] step 2/44: loss=8.3769 
[epoch 10] step 4/44: loss=8.2966 
[epoch 10] step 6/44: loss=7.7461 
[epoch 10] step 8/44: loss=7.6051 
[epoch 10] step 10/44: loss=7.5651 
[epoch 10] step 12/44: loss=7.4481 
[epoch 10] step 14/44: loss=7.3655 
[epoch 10] step 16/44: loss=7.4708 
[epoch 10] step 18/44: loss=7.6069 
[epoch 10] step 20/44: loss=7.7446 
[epoch 10] step 22/44: loss=7.8680 
[epoch 10] step 24/44: loss=7.9353 
[epoch 10] step 26/44: loss=7.9737 
[epoch 10] step 28/44: loss=7.9252 
[epoch 10] step 30/44: loss=7.9267 
[epoch 10] step 32/44: loss=8.0249 
[epoch 10] step 34/44: loss=8.0522 
[epoch 10] step 36/44: loss=8.0923 
[epoch 10] step 38/44: loss=8.0319 
[epoch 10] step 40/44: loss=7.9622 
[epoch 10] step 42/44: loss=7.9039 
[epoch 10] step 44/44: loss=7.8831 
[epoch 10] train_loss(avg per step)=15.7662 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=9.6451 qwk=('0.6141', '0.5754', '0.4844') averageQWK=0.5580 macroEMD=0.3678 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     1   27   21    6    0
     0   18   68   40    0
     0    2   17   97    0
     0    0    1   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    2    0
     0   42    0   11    0
     0   60    1   58    0
     0    9    0  125    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   21   48    0    0
     0    9  136    6    0
     0    1   62   39    0
     0    0    1    0    0
[epoch 11] step 2/44: loss=7.8782 
[epoch 11] step 4/44: loss=8.0210 
[epoch 11] step 6/44: loss=8.2021 
[epoch 11] step 8/44: loss=8.1803 
[epoch 11] step 10/44: loss=8.0741 
[epoch 11] step 12/44: loss=7.9761 
[epoch 11] step 14/44: loss=7.9561 
[epoch 11] step 16/44: loss=7.9968 
[epoch 11] step 18/44: loss=8.0640 
[epoch 11] step 20/44: loss=8.1962 
[epoch 11] step 22/44: loss=8.1633 
[epoch 11] step 24/44: loss=8.1265 
[epoch 11] step 26/44: loss=8.0476 
[epoch 11] step 28/44: loss=8.0004 
[epoch 11] step 30/44: loss=7.8933 
[epoch 11] step 32/44: loss=7.9163 
[epoch 11] step 34/44: loss=7.9795 
[epoch 11] step 36/44: loss=8.0433 
[epoch 11] step 38/44: loss=8.0520 
[epoch 11] step 40/44: loss=8.0524 
[epoch 11] step 42/44: loss=8.0201 
[epoch 11] step 44/44: loss=7.9591 
[epoch 11] train_loss(avg per step)=15.9183 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=9.8519 qwk=('0.5830', '0.5618', '0.5485') averageQWK=0.5645 macroEMD=0.3663 tailR0=('0.1591', '0.0000', '0.0000') tailR0avg=0.0530
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   28   24    1    2
     0   24   83   12    7
     0    5   32   67   12
     0    0    4   11    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    2    0
     0   26   15   12    0
     0   18   38   63    0
     0    5    2  127    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   24   43    2    0
     0   10  119   22    0
     0    2   36   64    0
     0    0    1    0    0
[epoch 12] step 2/44: loss=7.6217 
[epoch 12] step 4/44: loss=7.9757 
[epoch 12] step 6/44: loss=8.4328 
[epoch 12] step 8/44: loss=8.5129 
[epoch 12] step 10/44: loss=8.3814 
[epoch 12] step 12/44: loss=8.3655 
[epoch 12] step 14/44: loss=8.3383 
[epoch 12] step 16/44: loss=8.2600 
[epoch 12] step 18/44: loss=8.2218 
[epoch 12] step 20/44: loss=8.1145 
[epoch 12] step 22/44: loss=8.0396 
[epoch 12] step 24/44: loss=8.0845 
[epoch 12] step 26/44: loss=8.1085 
[epoch 12] step 28/44: loss=8.0460 
[epoch 12] step 30/44: loss=8.0361 
[epoch 12] step 32/44: loss=8.0375 
[epoch 12] step 34/44: loss=8.0693 
[epoch 12] step 36/44: loss=8.0129 
[epoch 12] step 38/44: loss=8.0046 
[epoch 12] step 40/44: loss=8.0454 
[epoch 12] step 42/44: loss=8.0860 
[epoch 12] step 44/44: loss=8.0835 
[epoch 12] train_loss(avg per step)=16.1670 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=9.9881 qwk=('0.6052', '0.5705', '0.5714') averageQWK=0.5824 macroEMD=0.3681 tailR0=('0.1566', '0.0500', '0.0000') tailR0avg=0.0689
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
    11    7   34    3    0
     2    5  100   18    1
     0    1   34   80    1
     0    0    3   17    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    1    0
     1    8   41    3    0
     0    3   85   31    0
     0    0   28  106    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   34   30    5    0
     0   23   88   40    0
     0    4   22   76    0
     0    0    0    1    0
[epoch 13] step 2/44: loss=6.8056 
[epoch 13] step 4/44: loss=7.4765 
[epoch 13] step 6/44: loss=7.9876 
[epoch 13] step 8/44: loss=8.2377 
[epoch 13] step 10/44: loss=8.0856 
[epoch 13] step 12/44: loss=7.7862 
[epoch 13] step 14/44: loss=7.5224 
[epoch 13] step 16/44: loss=7.3705 
[epoch 13] step 18/44: loss=7.3871 
[epoch 13] step 20/44: loss=7.4763 
[epoch 13] step 22/44: loss=7.7170 
[epoch 13] step 24/44: loss=7.8706 
[epoch 13] step 26/44: loss=7.9579 
[epoch 13] step 28/44: loss=7.9651 
[epoch 13] step 30/44: loss=7.9581 
[epoch 13] step 32/44: loss=7.9254 
[epoch 13] step 34/44: loss=7.8470 
[epoch 13] step 36/44: loss=7.8329 
[epoch 13] step 38/44: loss=7.8658 
[epoch 13] step 40/44: loss=7.9008 
[epoch 13] step 42/44: loss=7.8727 
[epoch 13] step 44/44: loss=7.8317 
[epoch 13] train_loss(avg per step)=15.6634 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=9.7339 qwk=('0.6357', '0.6508', '0.5897') averageQWK=0.6254 macroEMD=0.3684 tailR0=('0.2475', '0.0000', '0.0000') tailR0avg=0.0825
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    1    0    0
     3   23   26    1    2
     0   20   80   19    7
     0    2   26   76   12
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   31   19    3    0
     0   25   68   26    0
     0    5   24  105    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   41   25    3    0
     0   35   77   39    0
     0    5   24   73    0
     0    0    0    1    0
[epoch 14] step 2/44: loss=6.7802 
[epoch 14] step 4/44: loss=7.0414 
[epoch 14] step 6/44: loss=7.3980 
[epoch 14] step 8/44: loss=7.7572 
[epoch 14] step 10/44: loss=7.9305 
[epoch 14] step 12/44: loss=8.0163 
[epoch 14] step 14/44: loss=7.9518 
[epoch 14] step 16/44: loss=7.9801 
[epoch 14] step 18/44: loss=7.9133 
[epoch 14] step 20/44: loss=7.8468 
[epoch 14] step 22/44: loss=7.7483 
[epoch 14] step 24/44: loss=7.6910 
[epoch 14] step 26/44: loss=7.7188 
[epoch 14] step 28/44: loss=7.8368 
[epoch 14] step 30/44: loss=7.9232 
[epoch 14] step 32/44: loss=8.0507 
[epoch 14] step 34/44: loss=8.1254 
[epoch 14] step 36/44: loss=8.1842 
[epoch 14] step 38/44: loss=8.2078 
[epoch 14] step 40/44: loss=8.1504 
[epoch 14] step 42/44: loss=8.0650 
[epoch 14] step 44/44: loss=7.9606 
[epoch 14] train_loss(avg per step)=15.9212 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=10.1587 qwk=('0.6291', '0.6135', '0.5622') averageQWK=0.6016 macroEMD=0.3709 tailR0=('0.3131', '0.1500', '0.0000') tailR0avg=0.1544
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    3    2    0    0
    12   14   26    3    0
     7   11   91   15    2
     0    2   37   73    4
     0    0    3   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    5    2    0    0
     5   13   33    2    0
     3    4   98   14    0
     1    1   47   85    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   41   27    1    0
     0   34  101   16    0
     0    4   47   51    0
     0    0    1    0    0
[epoch 15] step 2/44: loss=6.5137 
[epoch 15] step 4/44: loss=6.1784 
[epoch 15] step 6/44: loss=6.4168 
[epoch 15] step 8/44: loss=6.9047 
[epoch 15] step 10/44: loss=7.1630 
[epoch 15] step 12/44: loss=7.3950 
[epoch 15] step 14/44: loss=7.5995 
[epoch 15] step 16/44: loss=7.6813 
[epoch 15] step 18/44: loss=7.7805 
[epoch 15] step 20/44: loss=7.8055 
[epoch 15] step 22/44: loss=7.7320 
[epoch 15] step 24/44: loss=7.6465 
[epoch 15] step 26/44: loss=7.5753 
[epoch 15] step 28/44: loss=7.5787 
[epoch 15] step 30/44: loss=7.6447 
[epoch 15] step 32/44: loss=7.6382 
[epoch 15] step 34/44: loss=7.6758 
[epoch 15] step 36/44: loss=7.7256 
[epoch 15] step 38/44: loss=7.7872 
[epoch 15] step 40/44: loss=7.7800 
[epoch 15] step 42/44: loss=7.7699 
[epoch 15] step 44/44: loss=7.7898 
[epoch 15] train_loss(avg per step)=15.5796 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=9.8999 qwk=('0.6076', '0.6082', '0.5562') averageQWK=0.5907 macroEMD=0.3658 tailR0=('0.3131', '0.2500', '0.1000') tailR0avg=0.2210
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    2    3    0    0
     6   10   34    4    1
     1    2   78   42    3
     0    1   18   93    4
     0    0    2   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     5    1    3    1    0
     6    3   38    6    0
     1    1   75   42    0
     0    0   16  118    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   22   42    5    0
     0    9   92   50    0
     0    1   21   80    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=7.4156 
[epoch 16] step 4/44: loss=7.4199 
[epoch 16] step 6/44: loss=7.5810 
[epoch 16] step 8/44: loss=7.5869 
[epoch 16] step 10/44: loss=7.6976 
[epoch 16] step 12/44: loss=8.1141 
[epoch 16] step 14/44: loss=8.1288 
[epoch 16] step 16/44: loss=8.0978 
[epoch 16] step 18/44: loss=8.0730 
[epoch 16] step 20/44: loss=8.0056 
[epoch 16] step 22/44: loss=7.9939 
[epoch 16] step 24/44: loss=7.9758 
[epoch 16] step 26/44: loss=7.9244 
[epoch 16] step 28/44: loss=7.9254 
[epoch 16] step 30/44: loss=7.8713 
[epoch 16] step 32/44: loss=7.8472 
[epoch 16] step 34/44: loss=7.8797 
[epoch 16] step 36/44: loss=7.9707 
[epoch 16] step 38/44: loss=7.9946 
[epoch 16] step 40/44: loss=7.9718 
[epoch 16] step 42/44: loss=7.9279 
[epoch 16] step 44/44: loss=7.8688 
[epoch 16] train_loss(avg per step)=15.7377 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=10.1173 qwk=('0.5773', '0.5156', '0.5071') averageQWK=0.5333 macroEMD=0.3654 tailR0=('0.3838', '0.0417', '0.0000') tailR0avg=0.1418
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    6    0    0
     2    9   38    3    3
     0    3   87   31    5
     0    0   23   82   11
     0    0    1    9   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    3   45    5    0
     0    1   79   39    0
     0    0   20  114    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   21   41    7    0
     0   14   81   56    0
     0    2   20   80    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=6.8822 
[epoch 17] step 4/44: loss=7.6091 
[epoch 17] step 6/44: loss=7.6253 
[epoch 17] step 8/44: loss=7.8021 
[epoch 17] step 10/44: loss=7.7637 
[epoch 17] step 12/44: loss=7.8982 
[epoch 17] step 14/44: loss=7.8376 
[epoch 17] step 16/44: loss=7.8578 
[epoch 17] step 18/44: loss=7.9106 
[epoch 17] step 20/44: loss=7.8991 
[epoch 17] step 22/44: loss=7.9653 
[epoch 17] step 24/44: loss=7.9263 
[epoch 17] step 26/44: loss=7.8754 
[epoch 17] step 28/44: loss=7.9124 
[epoch 17] step 30/44: loss=7.9090 
[epoch 17] step 32/44: loss=7.8958 
[epoch 17] step 34/44: loss=7.9083 
[epoch 17] step 36/44: loss=7.8733 
[epoch 17] step 38/44: loss=7.8858 
[epoch 17] step 40/44: loss=7.8716 
[epoch 17] step 42/44: loss=7.8667 
[epoch 17] step 44/44: loss=7.8232 
[epoch 17] train_loss(avg per step)=15.6464 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=9.9958 qwk=('0.6067', '0.5822', '0.5807') averageQWK=0.5899 macroEMD=0.3671 tailR0=('0.2121', '0.0000', '0.0000') tailR0avg=0.0707
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    4    0    0
     6   10   33    6    0
     1    1   84   40    0
     0    1   20   94    1
     0    0    2   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   12   36    5    0
     0    2   81   36    0
     0    0   27  107    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   30   38    1    0
     0   16  105   30    0
     0    2   36   64    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=8.3329 
[epoch 18] step 4/44: loss=7.8554 
[epoch 18] step 6/44: loss=7.3665 
[epoch 18] step 8/44: loss=7.3218 
[epoch 18] step 10/44: loss=7.3583 
[epoch 18] step 12/44: loss=7.3289 
[epoch 18] step 14/44: loss=7.6162 
[epoch 18] step 16/44: loss=7.8706 
[epoch 18] step 18/44: loss=8.0125 
[epoch 18] step 20/44: loss=8.0499 
[epoch 18] step 22/44: loss=8.0141 
[epoch 18] step 24/44: loss=7.9412 
[epoch 18] step 26/44: loss=7.8618 
[epoch 18] step 28/44: loss=7.8490 
[epoch 18] step 30/44: loss=7.8504 
[epoch 18] step 32/44: loss=7.8177 
[epoch 18] step 34/44: loss=7.7921 
[epoch 18] step 36/44: loss=7.8193 
[epoch 18] step 38/44: loss=7.8363 
[epoch 18] step 40/44: loss=7.8480 
[epoch 18] step 42/44: loss=7.8772 
[epoch 18] step 44/44: loss=7.9367 
[epoch 18] train_loss(avg per step)=15.8734 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=10.0575 qwk=('0.6095', '0.6220', '0.5390') averageQWK=0.5902 macroEMD=0.3645 tailR0=('0.2020', '0.0417', '0.0000') tailR0avg=0.0812
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    0    0
     3   19   30    3    0
     0   11   96   16    3
     0    2   37   71    6
     0    0    5   13    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   24   26    3    0
     0   19   79   21    0
     0    3   39   92    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   28   39    2    0
     0   16  112   23    0
     0    2   40   60    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=8.0305 
[epoch 19] step 4/44: loss=7.2516 
[epoch 19] step 6/44: loss=6.9420 
[epoch 19] step 8/44: loss=6.9220 
[epoch 19] step 10/44: loss=7.0137 
[epoch 19] step 12/44: loss=7.1217 
[epoch 19] step 14/44: loss=7.3717 
[epoch 19] step 16/44: loss=7.4777 
[epoch 19] step 18/44: loss=7.6765 
[epoch 19] step 20/44: loss=7.7216 
[epoch 19] step 22/44: loss=7.8021 
[epoch 19] step 24/44: loss=7.7724 
[epoch 19] step 26/44: loss=7.8183 
[epoch 19] step 28/44: loss=7.8564 
[epoch 19] step 30/44: loss=7.8320 
[epoch 19] step 32/44: loss=7.8374 
[epoch 19] step 34/44: loss=7.8084 
[epoch 19] step 36/44: loss=7.7975 
[epoch 19] step 38/44: loss=7.7790 
[epoch 19] step 40/44: loss=7.7056 
[epoch 19] step 42/44: loss=7.6930 
[epoch 19] step 44/44: loss=7.7361 
[epoch 19] train_loss(avg per step)=15.4722 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=9.8368 qwk=('0.6525', '0.6148', '0.5896') averageQWK=0.6190 macroEMD=0.3630 tailR0=('0.2374', '0.0000', '0.0000') tailR0avg=0.0791
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    0    0
     2   21   29    2    1
     0   13   90   20    3
     0    2   26   79    9
     0    0    2   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   24   22    7    0
     0   15   63   41    0
     0    3   14  117    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   29   38    2    0
     0   14  108   29    0
     0    2   32   68    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=8.5013 
[epoch 20] step 4/44: loss=8.4485 
[epoch 20] step 6/44: loss=8.2846 
[epoch 20] step 8/44: loss=8.0706 
[epoch 20] step 10/44: loss=7.8910 
[epoch 20] step 12/44: loss=7.9013 
[epoch 20] step 14/44: loss=7.8256 
[epoch 20] step 16/44: loss=7.7382 
[epoch 20] step 18/44: loss=7.7320 
[epoch 20] step 20/44: loss=7.7322 
[epoch 20] step 22/44: loss=7.7836 
[epoch 20] step 24/44: loss=7.8222 
[epoch 20] step 26/44: loss=7.9058 
[epoch 20] step 28/44: loss=7.9049 
[epoch 20] step 30/44: loss=7.8775 
[epoch 20] step 32/44: loss=7.8506 
[epoch 20] step 34/44: loss=7.8236 
[epoch 20] step 36/44: loss=7.8374 
[epoch 20] step 38/44: loss=7.8623 
[epoch 20] step 40/44: loss=7.8899 
[epoch 20] step 42/44: loss=7.9079 
[epoch 20] step 44/44: loss=7.9140 
[epoch 20] train_loss(avg per step)=15.8280 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=10.3191 qwk=('0.6427', '0.6060', '0.5659') averageQWK=0.6049 macroEMD=0.3628 tailR0=('0.2803', '0.0417', '0.0000') tailR0avg=0.1073
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    5    1    0    0
     5   19   25    6    0
     1   14   72   37    2
     0    2   19   90    5
     0    0    2   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   26   18    9    0
     0   17   48   54    0
     0    4    7  123    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   40   19   10    0
     0   28   57   66    0
     0    3   12   87    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=7.7300 
[epoch 21] step 4/44: loss=7.2928 
[epoch 21] step 6/44: loss=7.2469 
[epoch 21] step 8/44: loss=7.3137 
[epoch 21] step 10/44: loss=7.3335 
[epoch 21] step 12/44: loss=7.3811 
[epoch 21] step 14/44: loss=7.3774 
[epoch 21] step 16/44: loss=7.5319 
[epoch 21] step 18/44: loss=7.6602 
[epoch 21] step 20/44: loss=7.6982 
[epoch 21] step 22/44: loss=7.7649 
[epoch 21] step 24/44: loss=7.7994 
[epoch 21] step 26/44: loss=7.8093 
[epoch 21] step 28/44: loss=7.7858 
[epoch 21] step 30/44: loss=7.7794 
[epoch 21] step 32/44: loss=7.7758 
[epoch 21] step 34/44: loss=7.7496 
[epoch 21] step 36/44: loss=7.6898 
[epoch 21] step 38/44: loss=7.7181 
[epoch 21] step 40/44: loss=7.7281 
[epoch 21] step 42/44: loss=7.7933 
[epoch 21] step 44/44: loss=7.7750 
[epoch 21] train_loss(avg per step)=15.5501 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=10.0549 qwk=('0.6340', '0.6020', '0.5946') averageQWK=0.6102 macroEMD=0.3649 tailR0=('0.2702', '0.0417', '0.1000') tailR0avg=0.1373
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    0    0
     5   15   30    5    0
     2    9   80   32    3
     0    0   25   82    9
     0    0    2   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     1   14   33    5    0
     0    8   77   33    1
     0    3   16  115    0
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   26   41    2    0
     0   13  111   27    0
     0    1   36   65    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=8.1045 
[epoch 22] step 4/44: loss=7.7900 
[epoch 22] step 6/44: loss=7.4307 
[epoch 22] step 8/44: loss=7.4275 
[epoch 22] step 10/44: loss=7.5233 
[epoch 22] step 12/44: loss=7.5449 
[epoch 22] step 14/44: loss=7.6908 
[epoch 22] step 16/44: loss=7.7662 
[epoch 22] step 18/44: loss=7.7849 
[epoch 22] step 20/44: loss=7.8336 
[epoch 22] step 22/44: loss=7.9285 
[epoch 22] step 24/44: loss=7.9398 
[epoch 22] step 26/44: loss=7.9224 
[epoch 22] step 28/44: loss=7.8951 
[epoch 22] step 30/44: loss=7.9113 
[epoch 22] step 32/44: loss=7.8931 
[epoch 22] step 34/44: loss=7.8588 
[epoch 22] step 36/44: loss=7.8293 
[epoch 22] step 38/44: loss=7.8458 
[epoch 22] step 40/44: loss=7.7946 
[epoch 22] step 42/44: loss=7.8240 
[epoch 22] step 44/44: loss=7.8623 
[epoch 22] train_loss(avg per step)=15.7245 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=10.0981 qwk=('0.6148', '0.5980', '0.5700') averageQWK=0.5943 macroEMD=0.3616 tailR0=('0.2247', '0.0917', '0.1000') tailR0avg=0.1388
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    1    1    0
     2   19   28    6    0
     1   12   77   33    3
     0    1   21   90    4
     0    0    2   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     0   11   37    5    0
     0    4   85   29    1
     0    1   26  107    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   24   43    2    0
     0   11  111   29    0
     0    1   37   64    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=8.7166 
[epoch 23] step 4/44: loss=8.5928 
[epoch 23] step 6/44: loss=8.2682 
[epoch 23] step 8/44: loss=8.0842 
[epoch 23] step 10/44: loss=7.8484 
[epoch 23] step 12/44: loss=7.6993 
[epoch 23] step 14/44: loss=7.8153 
[epoch 23] step 16/44: loss=7.7848 
[epoch 23] step 18/44: loss=7.8430 
[epoch 23] step 20/44: loss=7.8500 
[epoch 23] step 22/44: loss=7.8833 
[epoch 23] step 24/44: loss=7.9289 
[epoch 23] step 26/44: loss=7.9587 
[epoch 23] step 28/44: loss=7.9341 
[epoch 23] step 30/44: loss=7.9115 
[epoch 23] step 32/44: loss=7.8438 
[epoch 23] step 34/44: loss=7.8063 
[epoch 23] step 36/44: loss=7.7831 
[epoch 23] step 38/44: loss=7.7904 
[epoch 23] step 40/44: loss=7.7952 
[epoch 23] step 42/44: loss=7.8254 
[epoch 23] step 44/44: loss=7.8595 
[epoch 23] train_loss(avg per step)=15.7191 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=10.2619 qwk=('0.6490', '0.6287', '0.5832') averageQWK=0.6203 macroEMD=0.3613 tailR0=('0.2702', '0.0000', '0.0000') tailR0avg=0.0901
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    7    0    0    0
     3   24   21    7    0
     1   27   60   36    2
     0    2   17   90    7
     0    0    2   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   32   15    6    0
     0   23   53   43    0
     0    5   14  114    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   39   23    7    0
     0   29   79   43    0
     0    3   22   77    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=8.1969 
[epoch 24] step 4/44: loss=8.4532 
[epoch 24] step 6/44: loss=8.8470 
[epoch 24] step 8/44: loss=8.8974 
[epoch 24] step 10/44: loss=8.7541 
[epoch 24] step 12/44: loss=8.4719 
[epoch 24] step 14/44: loss=8.3538 
[epoch 24] step 16/44: loss=8.1560 
[epoch 24] step 18/44: loss=7.9667 
[epoch 24] step 20/44: loss=7.8831 
[epoch 24] step 22/44: loss=7.8459 
[epoch 24] step 24/44: loss=7.8064 
[epoch 24] step 26/44: loss=7.8093 
[epoch 24] step 28/44: loss=7.9049 
[epoch 24] step 30/44: loss=7.9879 
[epoch 24] step 32/44: loss=8.0089 
[epoch 24] step 34/44: loss=8.0405 
[epoch 24] step 36/44: loss=8.0532 
[epoch 24] step 38/44: loss=8.0409 
[epoch 24] step 40/44: loss=8.0037 
[epoch 24] step 42/44: loss=7.9779 
[epoch 24] step 44/44: loss=7.9183 
[epoch 24] train_loss(avg per step)=15.8365 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=10.3339 qwk=('0.6416', '0.6001', '0.5579') averageQWK=0.5999 macroEMD=0.3646 tailR0=('0.3157', '0.0000', '0.0000') tailR0avg=0.1052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     4   13   34    4    0
     1    8   91   24    2
     0    0   28   80    8
     0    0    3   10    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     2   16   29    6    0
     0   13   64   42    0
     0    3   17  114    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   26   38    5    0
     0   15  100   36    0
     0    1   30   71    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=7.6356 
[epoch 25] step 4/44: loss=8.0653 
[epoch 25] step 6/44: loss=8.1467 
[epoch 25] step 8/44: loss=8.3418 
[epoch 25] step 10/44: loss=8.3775 
[epoch 25] step 12/44: loss=8.3300 
[epoch 25] step 14/44: loss=8.2414 
[epoch 25] step 16/44: loss=8.1272 
[epoch 25] step 18/44: loss=7.9234 
[epoch 25] step 20/44: loss=7.8587 
[epoch 25] step 22/44: loss=7.7261 
[epoch 25] step 24/44: loss=7.6328 
[epoch 25] step 26/44: loss=7.6452 
[epoch 25] step 28/44: loss=7.7549 
[epoch 25] step 30/44: loss=7.8109 
[epoch 25] step 32/44: loss=7.8958 
[epoch 25] step 34/44: loss=7.9746 
[epoch 25] step 36/44: loss=8.0226 
[epoch 25] step 38/44: loss=8.0581 
[epoch 25] step 40/44: loss=8.0176 
[epoch 25] step 42/44: loss=7.9776 
[epoch 25] step 44/44: loss=7.9312 
[epoch 25] train_loss(avg per step)=15.8625 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=10.3925 qwk=('0.6253', '0.5866', '0.4924') averageQWK=0.5681 macroEMD=0.3639 tailR0=('0.4040', '0.1833', '0.1000') tailR0avg=0.2291
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    1    4    0    0
    10    9   31    5    0
     5    5   85   29    2
     0    0   29   79    8
     0    0    2   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    1    0
     2    8   38    5    0
     0    6   79   33    1
     0    2   21  108    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   11   50    7    0
     0    8  101   42    0
     0    1   26   75    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=6.9573 
[epoch 26] step 4/44: loss=6.6903 
[epoch 26] step 6/44: loss=6.9706 
[epoch 26] step 8/44: loss=7.2632 
[epoch 26] step 10/44: loss=7.5433 
[epoch 26] step 12/44: loss=7.7512 
[epoch 26] step 14/44: loss=7.7778 
[epoch 26] step 16/44: loss=7.8597 
[epoch 26] step 18/44: loss=7.8428 
[epoch 26] step 20/44: loss=7.9018 
[epoch 26] step 22/44: loss=7.9303 
[epoch 26] step 24/44: loss=7.8840 
[epoch 26] step 26/44: loss=7.8552 
[epoch 26] step 28/44: loss=7.8864 
[epoch 26] step 30/44: loss=7.8364 
[epoch 26] step 32/44: loss=7.7978 
[epoch 26] step 34/44: loss=7.8278 
[epoch 26] step 36/44: loss=7.8339 
[epoch 26] step 38/44: loss=7.8142 
[epoch 26] step 40/44: loss=7.8170 
[epoch 26] step 42/44: loss=7.8157 
[epoch 26] step 44/44: loss=7.7404 
[epoch 26] train_loss(avg per step)=15.4807 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=10.1882 qwk=('0.5990', '0.5767', '0.6068') averageQWK=0.5942 macroEMD=0.3653 tailR0=('0.3384', '0.1833', '0.1000') tailR0avg=0.2072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     3   22   20    9    1
     2   16   72   33    3
     0    1   24   79   12
     0    0    3    9   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    1    0
     2    8   38    5    0
     1    3   76   38    1
     0    1   20  111    2
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     1   29   36    3    0
     0   12  100   39    0
     0    2   27   73    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=7.4277 
[epoch 27] step 4/44: loss=7.3255 
[epoch 27] step 6/44: loss=7.3049 
[epoch 27] step 8/44: loss=7.5016 
[epoch 27] step 10/44: loss=7.5934 
[epoch 27] step 12/44: loss=7.7078 
[epoch 27] step 14/44: loss=7.8484 
[epoch 27] step 16/44: loss=7.8795 
[epoch 27] step 18/44: loss=7.9379 
[epoch 27] step 20/44: loss=7.9514 
[epoch 27] step 22/44: loss=7.9459 
[epoch 27] step 24/44: loss=7.9057 
[epoch 27] step 26/44: loss=7.9187 
[epoch 27] step 28/44: loss=7.9076 
[epoch 27] step 30/44: loss=7.9253 
[epoch 27] step 32/44: loss=7.9908 
[epoch 27] step 34/44: loss=8.0079 
[epoch 27] step 36/44: loss=7.9527 
[epoch 27] step 38/44: loss=7.9362 
[epoch 27] step 40/44: loss=7.9124 
[epoch 27] step 42/44: loss=7.8509 
[epoch 27] step 44/44: loss=7.8573 
[epoch 27] train_loss(avg per step)=15.7146 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=10.2118 qwk=('0.6317', '0.6110', '0.6141') averageQWK=0.6189 macroEMD=0.3638 tailR0=('0.2374', '0.1333', '0.1000') tailR0avg=0.1569
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     3   22   27    3    0
     1   19   84   19    3
     0    1   32   69   14
     0    0    4   10    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    1    1    0
     1   19   27    6    0
     0   13   63   43    0
     0    4   17  113    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   34   31    4    0
     0   16   97   38    0
     0    1   29   72    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=8.4420 
[epoch 28] step 4/44: loss=8.2739 
[epoch 28] step 6/44: loss=8.3954 
[epoch 28] step 8/44: loss=7.9731 
[epoch 28] step 10/44: loss=7.8043 
[epoch 28] step 12/44: loss=7.8706 
[epoch 28] step 14/44: loss=7.8561 
[epoch 28] step 16/44: loss=7.8688 
[epoch 28] step 18/44: loss=7.8932 
[epoch 28] step 20/44: loss=7.8685 
[epoch 28] step 22/44: loss=7.9030 
[epoch 28] step 24/44: loss=7.8632 
[epoch 28] step 26/44: loss=7.9191 
[epoch 28] step 28/44: loss=7.8749 
[epoch 28] step 30/44: loss=7.8576 
[epoch 28] step 32/44: loss=7.8508 
[epoch 28] step 34/44: loss=7.9003 
[epoch 28] step 36/44: loss=7.9161 
[epoch 28] step 38/44: loss=7.9552 
[epoch 28] step 40/44: loss=7.9656 
[epoch 28] step 42/44: loss=7.9811 
[epoch 28] step 44/44: loss=7.9728 
[epoch 28] train_loss(avg per step)=15.9456 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=10.5021 qwk=('0.5727', '0.6246', '0.5880') averageQWK=0.5951 macroEMD=0.3660 tailR0=('0.2374', '0.1333', '0.0000') tailR0avg=0.1236
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     5   13   35    2    0
     2    8   97   16    3
     0    1   43   65    7
     0    0    7    7    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    1    1    0
     1   19   28    5    0
     0   10   77   31    1
     0    3   24  101    6
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   33   32    4    0
     0   18   96   37    0
     0    2   30   70    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=7.7813 
[epoch 29] step 4/44: loss=7.7640 
[epoch 29] step 6/44: loss=7.8937 
[epoch 29] step 8/44: loss=7.7994 
[epoch 29] step 10/44: loss=7.7103 
[epoch 29] step 12/44: loss=7.7697 
[epoch 29] step 14/44: loss=7.8252 
[epoch 29] step 16/44: loss=7.8296 
[epoch 29] step 18/44: loss=7.8673 
[epoch 29] step 20/44: loss=7.7941 
[epoch 29] step 22/44: loss=7.8227 
[epoch 29] step 24/44: loss=7.8325 
[epoch 29] step 26/44: loss=7.8106 
[epoch 29] step 28/44: loss=7.7771 
[epoch 29] step 30/44: loss=7.7712 
[epoch 29] step 32/44: loss=7.7650 
[epoch 29] step 34/44: loss=7.7907 
[epoch 29] step 36/44: loss=7.8287 
[epoch 29] step 38/44: loss=7.8577 
[epoch 29] step 40/44: loss=7.8676 
[epoch 29] step 42/44: loss=7.8686 
[epoch 29] step 44/44: loss=7.8261 
[epoch 29] train_loss(avg per step)=15.6522 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=10.3296 qwk=('0.6359', '0.6333', '0.5803') averageQWK=0.6165 macroEMD=0.3658 tailR0=('0.2475', '0.0917', '0.0000') tailR0avg=0.1130
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    1    0    0
     5   29   14    7    0
     4   32   58   30    2
     0    2   25   83    6
     0    0    2   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    1    1    0
     3   19   26    5    0
     2   10   75   32    0
     0    1   27  106    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   31   36    2    0
     0   15  114   22    0
     0    2   42   58    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=7.2511 
[epoch 30] step 4/44: loss=7.5689 
[epoch 30] step 6/44: loss=7.6580 
[epoch 30] step 8/44: loss=7.5426 
[epoch 30] step 10/44: loss=7.5855 
[epoch 30] step 12/44: loss=7.7623 
[epoch 30] step 14/44: loss=7.8311 
[epoch 30] step 16/44: loss=7.8635 
[epoch 30] step 18/44: loss=7.9286 
[epoch 30] step 20/44: loss=7.9348 
[epoch 30] step 22/44: loss=8.0050 
[epoch 30] step 24/44: loss=7.9817 
[epoch 30] step 26/44: loss=8.0423 
[epoch 30] step 28/44: loss=8.0461 
[epoch 30] step 30/44: loss=7.9914 
[epoch 30] step 32/44: loss=8.0294 
[epoch 30] step 34/44: loss=8.0299 
[epoch 30] step 36/44: loss=7.9885 
[epoch 30] step 38/44: loss=7.9504 
[epoch 30] step 40/44: loss=7.9202 
[epoch 30] step 42/44: loss=7.9124 
[epoch 30] step 44/44: loss=7.8487 
[epoch 30] train_loss(avg per step)=15.6974 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=10.3596 qwk=('0.5968', '0.6056', '0.5539') averageQWK=0.5854 macroEMD=0.3650 tailR0=('0.2702', '0.1833', '0.1000') tailR0avg=0.1845
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    1    0    0
     1   22   22    9    1
     1   22   64   37    2
     0    2   19   88    7
     0    0    3   12    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    1    0
     2   13   32    6    0
     2    7   71   39    0
     0    1   22  111    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     1   19   45    4    0
     0    8  103   40    0
     0    1   29   72    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=6.9665 
[epoch 31] step 4/44: loss=7.5377 
[epoch 31] step 6/44: loss=7.6999 
[epoch 31] step 8/44: loss=7.7405 
[epoch 31] step 10/44: loss=7.8444 
[epoch 31] step 12/44: loss=8.0315 
[epoch 31] step 14/44: loss=8.1020 
[epoch 31] step 16/44: loss=8.0719 
[epoch 31] step 18/44: loss=8.0186 
[epoch 31] step 20/44: loss=8.0116 
[epoch 31] step 22/44: loss=7.9932 
[epoch 31] step 24/44: loss=8.0152 
[epoch 31] step 26/44: loss=8.0603 
[epoch 31] step 28/44: loss=8.0434 
[epoch 31] step 30/44: loss=8.0862 
[epoch 31] step 32/44: loss=8.0915 
[epoch 31] step 34/44: loss=8.0402 
[epoch 31] step 36/44: loss=8.0310 
[epoch 31] step 38/44: loss=8.0162 
[epoch 31] step 40/44: loss=8.0147 
[epoch 31] step 42/44: loss=8.0048 
[epoch 31] step 44/44: loss=8.0073 
[epoch 31] train_loss(avg per step)=16.0147 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=10.5842 qwk=('0.5686', '0.6056', '0.5866') averageQWK=0.5869 macroEMD=0.3654 tailR0=('0.1919', '0.1333', '0.0000') tailR0avg=0.1084
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     3   18   25    9    0
     2   10   74   38    2
     0    2   23   84    7
     0    0    3   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     0   19   28    6    0
     0   10   67   42    0
     0    3   19  111    1
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   30   34    5    0
     0   13   97   41    0
     0    1   28   73    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=7.6740 
[epoch 32] step 4/44: loss=7.2399 
[epoch 32] step 6/44: loss=7.5648 
[epoch 32] step 8/44: loss=7.6489 
[epoch 32] step 10/44: loss=7.6588 
[epoch 32] step 12/44: loss=7.7158 
[epoch 32] step 14/44: loss=7.7061 
[epoch 32] step 16/44: loss=7.8459 
[epoch 32] step 18/44: loss=7.8209 
[epoch 32] step 20/44: loss=7.8149 
[epoch 32] step 22/44: loss=7.8168 
[epoch 32] step 24/44: loss=7.8799 
[epoch 32] step 26/44: loss=7.8605 
[epoch 32] step 28/44: loss=7.8822 
[epoch 32] step 30/44: loss=7.8161 
[epoch 32] step 32/44: loss=7.7857 
[epoch 32] step 34/44: loss=7.7692 
[epoch 32] step 36/44: loss=7.7798 
[epoch 32] step 38/44: loss=7.7886 
[epoch 32] step 40/44: loss=7.7488 
[epoch 32] step 42/44: loss=7.7871 
[epoch 32] step 44/44: loss=7.7970 
[epoch 32] train_loss(avg per step)=15.5940 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=10.2079 qwk=('0.6030', '0.6059', '0.5823') averageQWK=0.5971 macroEMD=0.3644 tailR0=('0.2146', '0.0917', '0.1000') tailR0avg=0.1354
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    0    0
     2   21   23    9    0
     1   23   66   34    2
     0    2   19   85   10
     0    0    3   12    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     0   16   31    6    0
     0    7   75   37    0
     0    1   21  112    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     1   20   45    3    0
     0   10  112   29    0
     0    1   32   69    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=7.6567 
[epoch 33] step 4/44: loss=7.8974 
[epoch 33] step 6/44: loss=8.0144 
[epoch 33] step 8/44: loss=8.0714 
[epoch 33] step 10/44: loss=8.2216 
[epoch 33] step 12/44: loss=8.1865 
[epoch 33] step 14/44: loss=8.1483 
[epoch 33] step 16/44: loss=8.1678 
[epoch 33] step 18/44: loss=8.1731 
[epoch 33] step 20/44: loss=8.1577 
[epoch 33] step 22/44: loss=8.1097 
[epoch 33] step 24/44: loss=8.1880 
[epoch 33] step 26/44: loss=8.2888 
[epoch 33] step 28/44: loss=8.2627 
[epoch 33] step 30/44: loss=8.2571 
[epoch 33] step 32/44: loss=8.2289 
[epoch 33] step 34/44: loss=8.1889 
[epoch 33] step 36/44: loss=8.1533 
[epoch 33] step 38/44: loss=8.1780 
[epoch 33] step 40/44: loss=8.1712 
[epoch 33] step 42/44: loss=8.1595 
[epoch 33] step 44/44: loss=8.1429 
[epoch 33] train_loss(avg per step)=16.2859 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=10.8070 qwk=('0.6360', '0.6113', '0.6074') averageQWK=0.6182 macroEMD=0.3674 tailR0=('0.3384', '0.1333', '0.1000') tailR0avg=0.1906
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    1    0    0
     2   23   25    4    1
     3   19   78   23    3
     0    2   26   75   13
     0    0    3    9   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     0   18   29    6    0
     1   10   69   39    0
     0    2   19  113    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   28   38    3    0
     0   13  109   29    0
     0    1   32   69    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=7.4880 
[epoch 34] step 4/44: loss=7.1561 
[epoch 34] step 6/44: loss=7.4167 
[epoch 34] step 8/44: loss=7.3993 
[epoch 34] step 10/44: loss=7.4886 
[epoch 34] step 12/44: loss=7.4792 
[epoch 34] step 14/44: loss=7.4570 
[epoch 34] step 16/44: loss=7.5370 
[epoch 34] step 18/44: loss=7.5640 
[epoch 34] step 20/44: loss=7.5939 
[epoch 34] step 22/44: loss=7.5991 
[epoch 34] step 24/44: loss=7.6553 
[epoch 34] step 26/44: loss=7.6743 
[epoch 34] step 28/44: loss=7.6866 
[epoch 34] step 30/44: loss=7.6504 
[epoch 34] step 32/44: loss=7.7022 
[epoch 34] step 34/44: loss=7.7270 
[epoch 34] step 36/44: loss=7.7502 
[epoch 34] step 38/44: loss=7.7638 
[epoch 34] step 40/44: loss=7.7802 
[epoch 34] step 42/44: loss=7.7956 
[epoch 34] step 44/44: loss=7.7965 
[epoch 34] train_loss(avg per step)=15.5931 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=10.2675 qwk=('0.6270', '0.6174', '0.6056') averageQWK=0.6167 macroEMD=0.3661 tailR0=('0.2828', '0.1333', '0.1000') tailR0avg=0.1721
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     4   16   30    5    0
     1    9   90   23    3
     0    0   30   77    9
     0    0    3    9   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     0   17   31    5    0
     0    9   74   36    0
     0    2   22  110    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   30   36    3    0
     0   16  105   30    0
     0    2   30   70    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=8.0175 
[epoch 35] step 4/44: loss=8.1674 
[epoch 35] step 6/44: loss=7.8865 
[epoch 35] step 8/44: loss=7.8727 
[epoch 35] step 10/44: loss=7.8146 
[epoch 35] step 12/44: loss=7.7219 
[epoch 35] step 14/44: loss=7.8242 
[epoch 35] step 16/44: loss=7.8934 
[epoch 35] step 18/44: loss=7.9459 
[epoch 35] step 20/44: loss=7.9182 
[epoch 35] step 22/44: loss=7.9333 
[epoch 35] step 24/44: loss=7.8868 
[epoch 35] step 26/44: loss=7.8859 
[epoch 35] step 28/44: loss=7.8923 
[epoch 35] step 30/44: loss=7.8859 
[epoch 35] step 32/44: loss=7.8625 
[epoch 35] step 34/44: loss=7.8322 
[epoch 35] step 36/44: loss=7.7967 
[epoch 35] step 38/44: loss=7.7865 
[epoch 35] step 40/44: loss=7.7706 
[epoch 35] step 42/44: loss=7.7873 
[epoch 35] step 44/44: loss=7.8241 
[epoch 35] train_loss(avg per step)=15.6481 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=10.3031 qwk=('0.6198', '0.6095', '0.6081') averageQWK=0.6125 macroEMD=0.3659 tailR0=('0.3157', '0.1333', '0.1000') tailR0avg=0.1830
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    2    0    0
     3   23   23    6    0
     3   19   70   31    3
     0    3   23   82    8
     0    0    3   10    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    1    0
     0   18   30    5    0
     1   10   69   39    0
     0    2   22  110    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    0    0
     0   29   37    3    0
     0   14  107   30    0
     0    1   32   69    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-1-reassignment-1/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-1-reassignment-1/fold3/metrics.json
Done.
