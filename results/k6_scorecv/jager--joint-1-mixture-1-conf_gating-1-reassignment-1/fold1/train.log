[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.2541 
[epoch 1] step 4/44: loss=5.9641 
[epoch 1] step 6/44: loss=5.9877 
[epoch 1] step 8/44: loss=5.9517 
[epoch 1] step 10/44: loss=5.9710 
[epoch 1] step 12/44: loss=5.8101 
[epoch 1] step 14/44: loss=5.8616 
[epoch 1] step 16/44: loss=5.8517 
[epoch 1] step 18/44: loss=5.9058 
[epoch 1] step 20/44: loss=5.8883 
[epoch 1] step 22/44: loss=5.8933 
[epoch 1] step 24/44: loss=5.9315 
[epoch 1] step 26/44: loss=5.9041 
[epoch 1] step 28/44: loss=5.9468 
[epoch 1] step 30/44: loss=5.9469 
[epoch 1] step 32/44: loss=5.9959 
[epoch 1] step 34/44: loss=6.0306 
[epoch 1] step 36/44: loss=6.0798 
[epoch 1] step 38/44: loss=6.1212 
[epoch 1] step 40/44: loss=6.1423 
[epoch 1] step 42/44: loss=6.1777 
[epoch 1] step 44/44: loss=6.2242 
[epoch 1] train_loss(avg per step)=12.4485 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=5.7607 qwk=('0.1255', '0.2165', '0.0016') averageQWK=0.1146 macroEMD=0.3722 tailR0=('0.0000', '0.1111', '0.0000') tailR0avg=0.0370
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    5    0
     0   13    0   41    0
     0   34    0   92    0
     0   23    0   93    0
     0    1    0   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    2    5    0
     9    0   19   24    0
    15    0   45   62    0
     6    0   32   95    0
     0    0    4    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    1   67    0    0
     0    0  152    0    0
     0    2   98    1    0
     0    0    2    0    0
[epoch 2] step 2/44: loss=8.8577 
[epoch 2] step 4/44: loss=9.2528 
[epoch 2] step 6/44: loss=9.7019 
[epoch 2] step 8/44: loss=9.6704 
[epoch 2] step 10/44: loss=9.8417 
[epoch 2] step 12/44: loss=9.8681 
[epoch 2] step 14/44: loss=9.9391 
[epoch 2] step 16/44: loss=10.0043 
[epoch 2] step 18/44: loss=10.1638 
[epoch 2] step 20/44: loss=10.2165 
[epoch 2] step 22/44: loss=10.3229 
[epoch 2] step 24/44: loss=10.4333 
[epoch 2] step 26/44: loss=10.5344 
[epoch 2] step 28/44: loss=10.6668 
[epoch 2] step 30/44: loss=10.8217 
[epoch 2] step 32/44: loss=10.8963 
[epoch 2] step 34/44: loss=10.9981 
[epoch 2] step 36/44: loss=11.0819 
[epoch 2] step 38/44: loss=11.1720 
[epoch 2] step 40/44: loss=11.2333 
[epoch 2] step 42/44: loss=11.3054 
[epoch 2] step 44/44: loss=11.3796 
[epoch 2] train_loss(avg per step)=22.7593 lambda[min,max]=[0.501002,1.000000]
[epoch 2] val_loss=13.5407 qwk=('0.0902', '0.0523', '0.2170') averageQWK=0.1198 macroEMD=0.3905 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    7    1
     1    7    0   45    1
     0    2    3  121    0
     0    0    2  114    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    8    0
     0    0    6   46    0
     0    0    4  118    0
     0    0    0  133    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0    1   32   35    0
     0    0   35  117    0
     0    0    4   97    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=13.0315 
[epoch 3] step 4/44: loss=13.4495 
[epoch 3] step 6/44: loss=13.4495 
[epoch 3] step 8/44: loss=13.1838 
[epoch 3] step 10/44: loss=13.1513 
[epoch 3] step 12/44: loss=12.9879 
[epoch 3] step 14/44: loss=12.8933 
[epoch 3] step 16/44: loss=12.9333 
[epoch 3] step 18/44: loss=13.0140 
[epoch 3] step 20/44: loss=13.1741 
[epoch 3] step 22/44: loss=13.2191 
[epoch 3] step 24/44: loss=13.1848 
[epoch 3] step 26/44: loss=13.2173 
[epoch 3] step 28/44: loss=13.2008 
[epoch 3] step 30/44: loss=13.1722 
[epoch 3] step 32/44: loss=13.1344 
[epoch 3] step 34/44: loss=13.0907 
[epoch 3] step 36/44: loss=13.1168 
[epoch 3] step 38/44: loss=13.0710 
[epoch 3] step 40/44: loss=13.0606 
[epoch 3] step 42/44: loss=13.0288 
[epoch 3] step 44/44: loss=13.0206 
[epoch 3] train_loss(avg per step)=26.0413 lambda[min,max]=[0.516966,1.000000]
[epoch 3] val_loss=15.0203 qwk=('0.1823', '0.0000', '0.2458') averageQWK=0.1427 macroEMD=0.3936 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    0    0
     4   50    0    0    0
     3  113    5    5    0
     0   80    5   30    1
     0   16    3    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   52    0    0
     0    0  122    0    0
     0    0  133    0    0
     0    0   12    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   38   30    0    0
     0   58   94    0    0
     0   32   49   20    0
     0    0    2    0    0
[epoch 4] step 2/44: loss=11.3098 
[epoch 4] step 4/44: loss=11.6561 
[epoch 4] step 6/44: loss=11.7841 
[epoch 4] step 8/44: loss=11.9514 
[epoch 4] step 10/44: loss=11.9613 
[epoch 4] step 12/44: loss=12.0559 
[epoch 4] step 14/44: loss=11.9947 
[epoch 4] step 16/44: loss=11.8741 
[epoch 4] step 18/44: loss=11.7796 
[epoch 4] step 20/44: loss=11.7122 
[epoch 4] step 22/44: loss=11.7770 
[epoch 4] step 24/44: loss=11.7586 
[epoch 4] step 26/44: loss=11.8165 
[epoch 4] step 28/44: loss=11.7681 
[epoch 4] step 30/44: loss=11.7537 
[epoch 4] step 32/44: loss=11.7070 
[epoch 4] step 34/44: loss=11.7608 
[epoch 4] step 36/44: loss=11.7194 
[epoch 4] step 38/44: loss=11.7280 
[epoch 4] step 40/44: loss=11.7028 
[epoch 4] step 42/44: loss=11.6559 
[epoch 4] step 44/44: loss=11.6114 
[epoch 4] train_loss(avg per step)=23.2227 lambda[min,max]=[0.504271,1.000000]
[epoch 4] val_loss=13.0879 qwk=('0.4156', '0.1854', '0.2408') averageQWK=0.2806 macroEMD=0.3870 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    4    0
     0   28    0   26    0
     0   26    3   97    0
     0    2    0  114    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    5    0
     0    0   18   34    0
     0    0   23   99    0
     0    0    1  132    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    3    0
     0   14   12   42    0
     0    4   22  126    0
     0    0    0  101    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=11.9741 
[epoch 5] step 4/44: loss=11.0635 
[epoch 5] step 6/44: loss=10.9926 
[epoch 5] step 8/44: loss=10.6916 
[epoch 5] step 10/44: loss=10.6376 
[epoch 5] step 12/44: loss=10.7689 
[epoch 5] step 14/44: loss=10.6596 
[epoch 5] step 16/44: loss=10.6507 
[epoch 5] step 18/44: loss=10.6032 
[epoch 5] step 20/44: loss=10.6287 
[epoch 5] step 22/44: loss=10.7008 
[epoch 5] step 24/44: loss=10.6761 
[epoch 5] step 26/44: loss=10.5771 
[epoch 5] step 28/44: loss=10.4718 
[epoch 5] step 30/44: loss=10.4059 
[epoch 5] step 32/44: loss=10.3698 
[epoch 5] step 34/44: loss=10.3552 
[epoch 5] step 36/44: loss=10.3082 
[epoch 5] step 38/44: loss=10.2686 
[epoch 5] step 40/44: loss=10.2797 
[epoch 5] step 42/44: loss=10.2973 
[epoch 5] step 44/44: loss=10.1999 
[epoch 5] train_loss(avg per step)=20.3999 lambda[min,max]=[0.500339,1.000000]
[epoch 5] val_loss=11.8954 qwk=('0.4587', '0.3545', '0.3698') averageQWK=0.3944 macroEMD=0.3815 tailR0=('0.1111', '0.0000', '0.0000') tailR0avg=0.0370
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    4    3    0
     3    3   34   14    0
     0    1   65   60    0
     0    0    9  107    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    3    0
     0    0   34   18    0
     0    0   60   62    0
     0    0    9  124    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0    2   49   17    0
     0    0   66   86    0
     0    0    3   98    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=10.9355 
[epoch 6] step 4/44: loss=10.4510 
[epoch 6] step 6/44: loss=9.9398 
[epoch 6] step 8/44: loss=9.6997 
[epoch 6] step 10/44: loss=9.3996 
[epoch 6] step 12/44: loss=9.2870 
[epoch 6] step 14/44: loss=9.2331 
[epoch 6] step 16/44: loss=9.3999 
[epoch 6] step 18/44: loss=9.4166 
[epoch 6] step 20/44: loss=9.4577 
[epoch 6] step 22/44: loss=9.3528 
[epoch 6] step 24/44: loss=9.3320 
[epoch 6] step 26/44: loss=9.3383 
[epoch 6] step 28/44: loss=9.2578 
[epoch 6] step 30/44: loss=9.2148 
[epoch 6] step 32/44: loss=9.1554 
[epoch 6] step 34/44: loss=9.1085 
[epoch 6] step 36/44: loss=9.1366 
[epoch 6] step 38/44: loss=9.1706 
[epoch 6] step 40/44: loss=9.1325 
[epoch 6] step 42/44: loss=9.1103 
[epoch 6] step 44/44: loss=9.0864 
[epoch 6] train_loss(avg per step)=18.1729 lambda[min,max]=[0.500069,1.000000]
[epoch 6] val_loss=10.7560 qwk=('0.3789', '0.4265', '0.5664') averageQWK=0.4573 macroEMD=0.3815 tailR0=('0.4565', '0.0556', '0.0000') tailR0avg=0.1707
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    0    2
     0   17   23    0   14
     0    4   80    4   38
     0    1   37   26   52
     0    0    0    2   21
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    5    3    0
     3    0   39   10    0
     3    0   66   53    0
     0    0   20  113    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   54   10    4    0
     0   80   49   23    0
     0    9   21   71    0
     0    0    1    1    0
[epoch 7] step 2/44: loss=8.2173 
[epoch 7] step 4/44: loss=8.7926 
[epoch 7] step 6/44: loss=9.1028 
[epoch 7] step 8/44: loss=9.1554 
[epoch 7] step 10/44: loss=8.8698 
[epoch 7] step 12/44: loss=8.4268 
[epoch 7] step 14/44: loss=8.1786 
[epoch 7] step 16/44: loss=8.1940 
[epoch 7] step 18/44: loss=8.3903 
[epoch 7] step 20/44: loss=8.4878 
[epoch 7] step 22/44: loss=8.5327 
[epoch 7] step 24/44: loss=8.6300 
[epoch 7] step 26/44: loss=8.6691 
[epoch 7] step 28/44: loss=8.6425 
[epoch 7] step 30/44: loss=8.6278 
[epoch 7] step 32/44: loss=8.5755 
[epoch 7] step 34/44: loss=8.4987 
[epoch 7] step 36/44: loss=8.4251 
[epoch 7] step 38/44: loss=8.4135 
[epoch 7] step 40/44: loss=8.4328 
[epoch 7] step 42/44: loss=8.5099 
[epoch 7] step 44/44: loss=8.5515 
[epoch 7] train_loss(avg per step)=17.1029 lambda[min,max]=[0.500002,1.000000]
[epoch 7] val_loss=9.9740 qwk=('0.4990', '0.5537', '0.5695') averageQWK=0.5408 macroEMD=0.3726 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    4   47    3    0
     0    0  102   24    0
     0    0   33   83    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   13   32    7    0
     0    9   74   39    0
     0    0   24  109    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   18   50    0    0
     0    6  142    4    0
     0    0   42   59    0
     0    0    2    0    0
[epoch 8] step 2/44: loss=9.1391 
[epoch 8] step 4/44: loss=8.6245 
[epoch 8] step 6/44: loss=8.1274 
[epoch 8] step 8/44: loss=7.9175 
[epoch 8] step 10/44: loss=7.6804 
[epoch 8] step 12/44: loss=7.8988 
[epoch 8] step 14/44: loss=8.0208 
[epoch 8] step 16/44: loss=8.0469 
[epoch 8] step 18/44: loss=7.9817 
[epoch 8] step 20/44: loss=7.9186 
[epoch 8] step 22/44: loss=7.9398 
[epoch 8] step 24/44: loss=7.9701 
[epoch 8] step 26/44: loss=8.0039 
[epoch 8] step 28/44: loss=8.0609 
[epoch 8] step 30/44: loss=8.1775 
[epoch 8] step 32/44: loss=8.2161 
[epoch 8] step 34/44: loss=8.1584 
[epoch 8] step 36/44: loss=8.0704 
[epoch 8] step 38/44: loss=8.0505 
[epoch 8] step 40/44: loss=8.0677 
[epoch 8] step 42/44: loss=8.0451 
[epoch 8] step 44/44: loss=8.0153 
[epoch 8] train_loss(avg per step)=16.0305 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=9.7691 qwk=('0.6207', '0.4777', '0.5630') averageQWK=0.5538 macroEMD=0.3724 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    0    2    0
     0   37    8    9    0
     0   31   47   47    1
     0    2    9  102    3
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    0
     0    5   46    1    0
     0    3  100   19    0
     0    2   49   82    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   17   50    1    0
     0    3  127   22    0
     0    0   33   68    0
     0    0    2    0    0
[epoch 9] step 2/44: loss=8.4835 
[epoch 9] step 4/44: loss=8.1799 
[epoch 9] step 6/44: loss=8.2393 
[epoch 9] step 8/44: loss=8.2546 
[epoch 9] step 10/44: loss=8.1788 
[epoch 9] step 12/44: loss=8.1664 
[epoch 9] step 14/44: loss=8.2688 
[epoch 9] step 16/44: loss=8.2359 
[epoch 9] step 18/44: loss=8.3173 
[epoch 9] step 20/44: loss=8.2864 
[epoch 9] step 22/44: loss=8.2141 
[epoch 9] step 24/44: loss=8.1258 
[epoch 9] step 26/44: loss=8.0437 
[epoch 9] step 28/44: loss=8.0223 
[epoch 9] step 30/44: loss=8.1144 
[epoch 9] step 32/44: loss=8.2315 
[epoch 9] step 34/44: loss=8.2700 
[epoch 9] step 36/44: loss=8.2719 
[epoch 9] step 38/44: loss=8.2301 
[epoch 9] step 40/44: loss=8.1725 
[epoch 9] step 42/44: loss=8.1061 
[epoch 9] step 44/44: loss=8.0455 
[epoch 9] train_loss(avg per step)=16.0910 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=10.0729 qwk=('0.4557', '0.2343', '0.4418') averageQWK=0.3773 macroEMD=0.3748 tailR0=('0.0870', '0.0000', '0.0000') tailR0avg=0.0290
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    3    0
     0   15   20   19    0
     0    7   41   76    2
     0    0    6  105    5
     0    0    0   19    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    5    0
     0    5   11   36    0
     0    1   24   97    0
     0    0    4  129    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    2    0
     0   23   25   20    0
     0    7   48   97    0
     0    0    2   99    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=7.4291 
[epoch 10] step 4/44: loss=7.6752 
[epoch 10] step 6/44: loss=8.0456 
[epoch 10] step 8/44: loss=8.5174 
[epoch 10] step 10/44: loss=8.5690 
[epoch 10] step 12/44: loss=8.3968 
[epoch 10] step 14/44: loss=8.2970 
[epoch 10] step 16/44: loss=8.0360 
[epoch 10] step 18/44: loss=7.9239 
[epoch 10] step 20/44: loss=7.8779 
[epoch 10] step 22/44: loss=7.8817 
[epoch 10] step 24/44: loss=7.9165 
[epoch 10] step 26/44: loss=8.0246 
[epoch 10] step 28/44: loss=8.0984 
[epoch 10] step 30/44: loss=8.0658 
[epoch 10] step 32/44: loss=7.9919 
[epoch 10] step 34/44: loss=7.9291 
[epoch 10] step 36/44: loss=7.9404 
[epoch 10] step 38/44: loss=7.9930 
[epoch 10] step 40/44: loss=8.0138 
[epoch 10] step 42/44: loss=8.0168 
[epoch 10] step 44/44: loss=8.0206 
[epoch 10] train_loss(avg per step)=16.0411 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=9.8694 qwk=('0.6584', '0.5351', '0.5722') averageQWK=0.5886 macroEMD=0.3681 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   24   25    5    0
     0    8   89   29    0
     0    0   22   92    2
     0    0    0   21    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   19   25    8    0
     0   14   57   51    0
     1    2   11  119    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   34   23   11    0
     0   26   65   61    0
     0    1    8   92    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=7.7927 
[epoch 11] step 4/44: loss=7.4106 
[epoch 11] step 6/44: loss=7.6287 
[epoch 11] step 8/44: loss=7.8434 
[epoch 11] step 10/44: loss=7.6514 
[epoch 11] step 12/44: loss=7.5553 
[epoch 11] step 14/44: loss=7.5406 
[epoch 11] step 16/44: loss=7.6365 
[epoch 11] step 18/44: loss=7.8160 
[epoch 11] step 20/44: loss=7.8957 
[epoch 11] step 22/44: loss=7.9411 
[epoch 11] step 24/44: loss=7.9533 
[epoch 11] step 26/44: loss=7.8376 
[epoch 11] step 28/44: loss=7.7888 
[epoch 11] step 30/44: loss=7.8398 
[epoch 11] step 32/44: loss=7.8497 
[epoch 11] step 34/44: loss=7.8719 
[epoch 11] step 36/44: loss=7.8697 
[epoch 11] step 38/44: loss=7.8431 
[epoch 11] step 40/44: loss=7.8042 
[epoch 11] step 42/44: loss=7.8148 
[epoch 11] step 44/44: loss=7.7985 
[epoch 11] train_loss(avg per step)=15.5970 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=9.7224 qwk=('0.6499', '0.4527', '0.4945') averageQWK=0.5324 macroEMD=0.3654 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   31   16    6    1
     0   24   66   34    2
     0    0   18   91    7
     0    0    0   20    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0    2   37   13    0
     0    0   71   51    0
     0    0   17  116    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   14   39   15    0
     0    7   74   71    0
     0    0    5   96    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=8.2530 
[epoch 12] step 4/44: loss=8.4846 
[epoch 12] step 6/44: loss=8.1640 
[epoch 12] step 8/44: loss=7.9898 
[epoch 12] step 10/44: loss=7.9436 
[epoch 12] step 12/44: loss=8.0976 
[epoch 12] step 14/44: loss=8.0174 
[epoch 12] step 16/44: loss=7.9848 
[epoch 12] step 18/44: loss=7.9502 
[epoch 12] step 20/44: loss=7.8585 
[epoch 12] step 22/44: loss=7.8561 
[epoch 12] step 24/44: loss=7.8719 
[epoch 12] step 26/44: loss=7.9773 
[epoch 12] step 28/44: loss=8.0360 
[epoch 12] step 30/44: loss=8.0611 
[epoch 12] step 32/44: loss=7.9719 
[epoch 12] step 34/44: loss=7.8942 
[epoch 12] step 36/44: loss=7.9286 
[epoch 12] step 38/44: loss=7.9063 
[epoch 12] step 40/44: loss=7.8840 
[epoch 12] step 42/44: loss=7.8840 
[epoch 12] step 44/44: loss=7.9031 
[epoch 12] train_loss(avg per step)=15.8062 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=9.8577 qwk=('0.6301', '0.5584', '0.6438') averageQWK=0.6108 macroEMD=0.3678 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   24   24    6    0
     0   10   83   33    0
     0    0   18   96    2
     0    0    1   21    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   21   23    8    0
     0   17   73   32    0
     0    3   32   98    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   34    2    0
     0   24   97   31    0
     0    2   16   83    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=7.2525 
[epoch 13] step 4/44: loss=7.5912 
[epoch 13] step 6/44: loss=7.7490 
[epoch 13] step 8/44: loss=7.8692 
[epoch 13] step 10/44: loss=8.0534 
[epoch 13] step 12/44: loss=8.1506 
[epoch 13] step 14/44: loss=8.0837 
[epoch 13] step 16/44: loss=7.9222 
[epoch 13] step 18/44: loss=7.7342 
[epoch 13] step 20/44: loss=7.7071 
[epoch 13] step 22/44: loss=7.7234 
[epoch 13] step 24/44: loss=7.7551 
[epoch 13] step 26/44: loss=7.7902 
[epoch 13] step 28/44: loss=7.8136 
[epoch 13] step 30/44: loss=7.8316 
[epoch 13] step 32/44: loss=7.7532 
[epoch 13] step 34/44: loss=7.7438 
[epoch 13] step 36/44: loss=7.7754 
[epoch 13] step 38/44: loss=7.8057 
[epoch 13] step 40/44: loss=7.7732 
[epoch 13] step 42/44: loss=7.8066 
[epoch 13] step 44/44: loss=7.7847 
[epoch 13] train_loss(avg per step)=15.5693 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=9.8880 qwk=('0.6308', '0.5796', '0.6160') averageQWK=0.6088 macroEMD=0.3706 tailR0=('0.1522', '0.0417', '0.0000') tailR0avg=0.0646
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     1   33   18    2    0
     0   36   73   14    3
     0    4   37   65   10
     0    0    5   11    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   31   17    4    0
     0   33   60   29    0
     0    9   28   96    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   37   28    3    0
     1   31   84   36    0
     0    3   17   81    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=6.5224 
[epoch 14] step 4/44: loss=6.7702 
[epoch 14] step 6/44: loss=7.0989 
[epoch 14] step 8/44: loss=7.6529 
[epoch 14] step 10/44: loss=7.7939 
[epoch 14] step 12/44: loss=8.0215 
[epoch 14] step 14/44: loss=7.9548 
[epoch 14] step 16/44: loss=7.9129 
[epoch 14] step 18/44: loss=7.8284 
[epoch 14] step 20/44: loss=7.7911 
[epoch 14] step 22/44: loss=7.8422 
[epoch 14] step 24/44: loss=7.8813 
[epoch 14] step 26/44: loss=7.9001 
[epoch 14] step 28/44: loss=7.9288 
[epoch 14] step 30/44: loss=7.9297 
[epoch 14] step 32/44: loss=7.8856 
[epoch 14] step 34/44: loss=7.8436 
[epoch 14] step 36/44: loss=7.7951 
[epoch 14] step 38/44: loss=7.7684 
[epoch 14] step 40/44: loss=7.7813 
[epoch 14] step 42/44: loss=7.7672 
[epoch 14] step 44/44: loss=7.7222 
[epoch 14] train_loss(avg per step)=15.4444 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=9.8493 qwk=('0.6227', '0.5506', '0.6673') averageQWK=0.6135 macroEMD=0.3676 tailR0=('0.2391', '0.0833', '0.0000') tailR0avg=0.1075
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   26   26    2    0
     0   19   97    7    3
     0    0   50   48   18
     0    0    6    6   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   14   34    4    0
     0    9   91   22    0
     0    2   46   85    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   41   26    1    0
     0   30  100   22    0
     0    2   26   73    0
     0    0    0    2    0
[epoch 15] step 2/44: loss=7.6205 
[epoch 15] step 4/44: loss=8.0958 
[epoch 15] step 6/44: loss=8.2683 
[epoch 15] step 8/44: loss=8.3543 
[epoch 15] step 10/44: loss=8.3794 
[epoch 15] step 12/44: loss=8.2380 
[epoch 15] step 14/44: loss=8.0207 
[epoch 15] step 16/44: loss=7.9186 
[epoch 15] step 18/44: loss=7.8925 
[epoch 15] step 20/44: loss=7.7290 
[epoch 15] step 22/44: loss=7.7162 
[epoch 15] step 24/44: loss=7.6720 
[epoch 15] step 26/44: loss=7.6671 
[epoch 15] step 28/44: loss=7.7431 
[epoch 15] step 30/44: loss=7.8225 
[epoch 15] step 32/44: loss=7.8737 
[epoch 15] step 34/44: loss=7.9101 
[epoch 15] step 36/44: loss=7.9039 
[epoch 15] step 38/44: loss=7.8727 
[epoch 15] step 40/44: loss=7.8451 
[epoch 15] step 42/44: loss=7.8257 
[epoch 15] step 44/44: loss=7.7987 
[epoch 15] train_loss(avg per step)=15.5974 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=9.8514 qwk=('0.5971', '0.6095', '0.5746') averageQWK=0.5937 macroEMD=0.3669 tailR0=('0.1304', '0.0417', '0.0000') tailR0avg=0.0574
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   14   35    4    1
     0    4  102   20    0
     0    0   33   71   12
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   30   16    6    0
     1   21   67   33    0
     0    8   20  104    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   19   47    2    0
     1   11  128   12    0
     0    1   33   67    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=7.5124 
[epoch 16] step 4/44: loss=7.5146 
[epoch 16] step 6/44: loss=7.5355 
[epoch 16] step 8/44: loss=7.6715 
[epoch 16] step 10/44: loss=7.7287 
[epoch 16] step 12/44: loss=7.9023 
[epoch 16] step 14/44: loss=8.1013 
[epoch 16] step 16/44: loss=8.2860 
[epoch 16] step 18/44: loss=8.2489 
[epoch 16] step 20/44: loss=8.1441 
[epoch 16] step 22/44: loss=7.9892 
[epoch 16] step 24/44: loss=7.9378 
[epoch 16] step 26/44: loss=7.9552 
[epoch 16] step 28/44: loss=8.0097 
[epoch 16] step 30/44: loss=8.0380 
[epoch 16] step 32/44: loss=7.9925 
[epoch 16] step 34/44: loss=7.9124 
[epoch 16] step 36/44: loss=7.8987 
[epoch 16] step 38/44: loss=7.9236 
[epoch 16] step 40/44: loss=7.9628 
[epoch 16] step 42/44: loss=7.9839 
[epoch 16] step 44/44: loss=8.0089 
[epoch 16] train_loss(avg per step)=16.0179 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=10.1830 qwk=('0.6002', '0.5559', '0.5658') averageQWK=0.5740 macroEMD=0.3673 tailR0=('0.2391', '0.2083', '0.0000') tailR0avg=0.1492
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    0    0
     0    7   41    6    0
     0    4   94   26    2
     0    0   22   86    8
     0    0    0   12   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0    9   38    5    0
     0    3   90   28    1
     0    1   36   91    5
     0    0    0    7    5
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   14   52    2    0
     0    6  119   27    0
     0    2   23   76    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=7.1819 
[epoch 17] step 4/44: loss=6.8154 
[epoch 17] step 6/44: loss=6.8041 
[epoch 17] step 8/44: loss=6.9529 
[epoch 17] step 10/44: loss=7.1841 
[epoch 17] step 12/44: loss=7.3882 
[epoch 17] step 14/44: loss=7.7257 
[epoch 17] step 16/44: loss=7.8220 
[epoch 17] step 18/44: loss=7.8576 
[epoch 17] step 20/44: loss=7.8881 
[epoch 17] step 22/44: loss=7.8195 
[epoch 17] step 24/44: loss=7.7613 
[epoch 17] step 26/44: loss=7.7133 
[epoch 17] step 28/44: loss=7.6977 
[epoch 17] step 30/44: loss=7.6883 
[epoch 17] step 32/44: loss=7.6885 
[epoch 17] step 34/44: loss=7.7522 
[epoch 17] step 36/44: loss=7.7966 
[epoch 17] step 38/44: loss=7.8415 
[epoch 17] step 40/44: loss=7.8503 
[epoch 17] step 42/44: loss=7.8292 
[epoch 17] step 44/44: loss=7.8009 
[epoch 17] train_loss(avg per step)=15.6019 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=10.0040 qwk=('0.6325', '0.5332', '0.6489') averageQWK=0.6048 macroEMD=0.3660 tailR0=('0.4372', '0.0833', '0.0000') tailR0avg=0.1735
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    1    0    0
     2   29   17    4    2
     3   19   80   13   11
     1    0   30   63   22
     0    0    1    7   15
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   29   11   12    0
     0   35   35   52    0
     0    7    9  116    1
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   38   29    1    0
     0   33   97   22    0
     0    1   27   73    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=7.5353 
[epoch 18] step 4/44: loss=7.6467 
[epoch 18] step 6/44: loss=7.7441 
[epoch 18] step 8/44: loss=7.8359 
[epoch 18] step 10/44: loss=8.0451 
[epoch 18] step 12/44: loss=8.1073 
[epoch 18] step 14/44: loss=8.0391 
[epoch 18] step 16/44: loss=7.9610 
[epoch 18] step 18/44: loss=7.8952 
[epoch 18] step 20/44: loss=7.8596 
[epoch 18] step 22/44: loss=7.9615 
[epoch 18] step 24/44: loss=8.0092 
[epoch 18] step 26/44: loss=8.0443 
[epoch 18] step 28/44: loss=8.0715 
[epoch 18] step 30/44: loss=8.0188 
[epoch 18] step 32/44: loss=7.9614 
[epoch 18] step 34/44: loss=7.9413 
[epoch 18] step 36/44: loss=7.9631 
[epoch 18] step 38/44: loss=7.9705 
[epoch 18] step 40/44: loss=7.9566 
[epoch 18] step 42/44: loss=7.9434 
[epoch 18] step 44/44: loss=7.8799 
[epoch 18] train_loss(avg per step)=15.7597 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=10.2958 qwk=('0.5777', '0.5453', '0.5997') averageQWK=0.5742 macroEMD=0.3651 tailR0=('0.2174', '0.1250', '0.0000') tailR0avg=0.1141
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     1   37    6    9    1
     1   43   27   49    6
     0    6    8   88   14
     0    0    0   13   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   21   18   13    0
     0   22   50   50    0
     0    6   11  113    3
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   33   26    9    0
     1   24   76   51    0
     0    0   12   89    0
     0    0    0    2    0
[epoch 19] step 2/44: loss=7.5648 
[epoch 19] step 4/44: loss=7.5005 
[epoch 19] step 6/44: loss=7.4853 
[epoch 19] step 8/44: loss=7.5988 
[epoch 19] step 10/44: loss=7.7334 
[epoch 19] step 12/44: loss=7.9248 
[epoch 19] step 14/44: loss=7.9461 
[epoch 19] step 16/44: loss=8.0213 
[epoch 19] step 18/44: loss=8.0199 
[epoch 19] step 20/44: loss=7.9123 
[epoch 19] step 22/44: loss=7.8084 
[epoch 19] step 24/44: loss=7.7626 
[epoch 19] step 26/44: loss=7.6962 
[epoch 19] step 28/44: loss=7.7233 
[epoch 19] step 30/44: loss=7.7388 
[epoch 19] step 32/44: loss=7.7396 
[epoch 19] step 34/44: loss=7.7684 
[epoch 19] step 36/44: loss=7.8182 
[epoch 19] step 38/44: loss=7.8748 
[epoch 19] step 40/44: loss=7.9260 
[epoch 19] step 42/44: loss=7.9344 
[epoch 19] step 44/44: loss=7.8581 
[epoch 19] train_loss(avg per step)=15.7162 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=10.2176 qwk=('0.5139', '0.5346', '0.5997') averageQWK=0.5494 macroEMD=0.3683 tailR0=('0.2391', '0.2083', '0.0000') tailR0avg=0.1492
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    3    1
     1   15   28    7    3
     2    5   76   37    6
     0    0   14   84   18
     0    0    0   12   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   13   30    9    0
     2    6   70   41    3
     0    3   21  100    9
     0    0    0    7    5
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   28   32    8    0
     0   23   84   45    0
     0    0   11   90    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=6.6168 
[epoch 20] step 4/44: loss=6.6445 
[epoch 20] step 6/44: loss=7.0583 
[epoch 20] step 8/44: loss=7.3334 
[epoch 20] step 10/44: loss=7.6100 
[epoch 20] step 12/44: loss=7.5837 
[epoch 20] step 14/44: loss=7.6005 
[epoch 20] step 16/44: loss=7.6773 
[epoch 20] step 18/44: loss=7.6979 
[epoch 20] step 20/44: loss=7.7202 
[epoch 20] step 22/44: loss=7.6897 
[epoch 20] step 24/44: loss=7.6440 
[epoch 20] step 26/44: loss=7.6413 
[epoch 20] step 28/44: loss=7.6242 
[epoch 20] step 30/44: loss=7.6761 
[epoch 20] step 32/44: loss=7.7326 
[epoch 20] step 34/44: loss=7.7932 
[epoch 20] step 36/44: loss=7.8438 
[epoch 20] step 38/44: loss=7.8462 
[epoch 20] step 40/44: loss=7.8523 
[epoch 20] step 42/44: loss=7.8585 
[epoch 20] step 44/44: loss=7.8524 
[epoch 20] train_loss(avg per step)=15.7049 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=10.2125 qwk=('0.6276', '0.5469', '0.5602') averageQWK=0.5783 macroEMD=0.3708 tailR0=('0.2391', '0.0833', '0.0000') tailR0avg=0.1075
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   20   27    6    0
     2   15   77   27    5
     0    0   24   80   12
     0    0    0   12   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0    6   40    6    0
     0    3   90   28    1
     0    0   33   96    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   20   40    8    0
     0   15   91   46    0
     0    0   13   88    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=6.9156 
[epoch 21] step 4/44: loss=6.6913 
[epoch 21] step 6/44: loss=6.6980 
[epoch 21] step 8/44: loss=6.8190 
[epoch 21] step 10/44: loss=7.0475 
[epoch 21] step 12/44: loss=7.2691 
[epoch 21] step 14/44: loss=7.5572 
[epoch 21] step 16/44: loss=7.7914 
[epoch 21] step 18/44: loss=7.8152 
[epoch 21] step 20/44: loss=7.9488 
[epoch 21] step 22/44: loss=7.8944 
[epoch 21] step 24/44: loss=7.8847 
[epoch 21] step 26/44: loss=7.7935 
[epoch 21] step 28/44: loss=7.7486 
[epoch 21] step 30/44: loss=7.6888 
[epoch 21] step 32/44: loss=7.6786 
[epoch 21] step 34/44: loss=7.7120 
[epoch 21] step 36/44: loss=7.7433 
[epoch 21] step 38/44: loss=7.7788 
[epoch 21] step 40/44: loss=7.8144 
[epoch 21] step 42/44: loss=7.8282 
[epoch 21] step 44/44: loss=7.8445 
[epoch 21] train_loss(avg per step)=15.6890 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=10.2628 qwk=('0.5912', '0.5182', '0.5623') averageQWK=0.5572 macroEMD=0.3636 tailR0=('0.1739', '0.0833', '0.0000') tailR0avg=0.0857
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   17   29    6    2
     0    8   88   28    2
     0    0   22   83   11
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   15   27   10    0
     2   13   62   43    2
     0    4   17  108    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   40   14   14    0
     1   39   42   70    0
     0    1    4   96    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=8.6998 
[epoch 22] step 4/44: loss=8.2606 
[epoch 22] step 6/44: loss=7.8523 
[epoch 22] step 8/44: loss=7.7753 
[epoch 22] step 10/44: loss=7.8049 
[epoch 22] step 12/44: loss=7.7751 
[epoch 22] step 14/44: loss=7.6867 
[epoch 22] step 16/44: loss=7.7174 
[epoch 22] step 18/44: loss=7.7621 
[epoch 22] step 20/44: loss=7.7664 
[epoch 22] step 22/44: loss=7.7626 
[epoch 22] step 24/44: loss=7.7068 
[epoch 22] step 26/44: loss=7.7418 
[epoch 22] step 28/44: loss=7.8311 
[epoch 22] step 30/44: loss=7.8944 
[epoch 22] step 32/44: loss=7.9739 
[epoch 22] step 34/44: loss=7.9625 
[epoch 22] step 36/44: loss=7.9434 
[epoch 22] step 38/44: loss=7.9236 
[epoch 22] step 40/44: loss=7.8992 
[epoch 22] step 42/44: loss=7.8938 
[epoch 22] step 44/44: loss=7.8251 
[epoch 22] train_loss(avg per step)=15.6502 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=10.2622 qwk=('0.5683', '0.4878', '0.6167') averageQWK=0.5576 macroEMD=0.3689 tailR0=('0.1957', '0.0833', '0.0000') tailR0avg=0.0930
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     1   15   33    4    1
     1    7   94   21    3
     2    0   33   69   12
     0    0    1   13    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   11   31   10    0
     2    6   71   41    2
     0    3   24  103    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   43   16    9    0
     0   39   67   46    0
     0    1   13   86    1
     0    0    0    2    0
[epoch 23] step 2/44: loss=7.4970 
[epoch 23] step 4/44: loss=7.5996 
[epoch 23] step 6/44: loss=7.9032 
[epoch 23] step 8/44: loss=7.9584 
[epoch 23] step 10/44: loss=7.9694 
[epoch 23] step 12/44: loss=7.9997 
[epoch 23] step 14/44: loss=7.9987 
[epoch 23] step 16/44: loss=7.9421 
[epoch 23] step 18/44: loss=7.9070 
[epoch 23] step 20/44: loss=7.9017 
[epoch 23] step 22/44: loss=7.8452 
[epoch 23] step 24/44: loss=7.9230 
[epoch 23] step 26/44: loss=7.9473 
[epoch 23] step 28/44: loss=7.9579 
[epoch 23] step 30/44: loss=7.9385 
[epoch 23] step 32/44: loss=7.9497 
[epoch 23] step 34/44: loss=7.9629 
[epoch 23] step 36/44: loss=7.9806 
[epoch 23] step 38/44: loss=7.9264 
[epoch 23] step 40/44: loss=7.8802 
[epoch 23] step 42/44: loss=7.8619 
[epoch 23] step 44/44: loss=7.8234 
[epoch 23] train_loss(avg per step)=15.6468 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=10.3373 qwk=('0.5264', '0.4801', '0.5780') averageQWK=0.5282 macroEMD=0.3672 tailR0=('0.1957', '0.0833', '0.0000') tailR0avg=0.0930
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    3    0
     0   18   26    9    1
     1   11   56   53    5
     0    0   13   94    9
     0    0    0   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   11   29   12    0
     1   10   60   49    2
     0    4   18  108    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   34    9    0
     0   17   91   44    0
     0    0   12   89    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=8.1558 
[epoch 24] step 4/44: loss=8.2437 
[epoch 24] step 6/44: loss=8.1848 
[epoch 24] step 8/44: loss=8.1231 
[epoch 24] step 10/44: loss=8.0170 
[epoch 24] step 12/44: loss=8.1323 
[epoch 24] step 14/44: loss=8.1363 
[epoch 24] step 16/44: loss=8.0620 
[epoch 24] step 18/44: loss=8.0751 
[epoch 24] step 20/44: loss=8.1184 
[epoch 24] step 22/44: loss=8.0974 
[epoch 24] step 24/44: loss=8.0973 
[epoch 24] step 26/44: loss=8.1449 
[epoch 24] step 28/44: loss=8.1142 
[epoch 24] step 30/44: loss=8.0292 
[epoch 24] step 32/44: loss=8.0000 
[epoch 24] step 34/44: loss=7.9950 
[epoch 24] step 36/44: loss=8.0107 
[epoch 24] step 38/44: loss=7.9841 
[epoch 24] step 40/44: loss=7.9781 
[epoch 24] step 42/44: loss=7.9589 
[epoch 24] step 44/44: loss=7.9860 
[epoch 24] train_loss(avg per step)=15.9720 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=10.5373 qwk=('0.5729', '0.5137', '0.6069') averageQWK=0.5645 macroEMD=0.3678 tailR0=('0.2947', '0.0833', '0.0000') tailR0avg=0.1260
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    2    0
     0   22   21   11    0
     2   12   68   38    6
     0    0   22   79   15
     0    0    0   12   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   16   28    8    0
     0   11   66   44    1
     0    4   23  101    5
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   40   19    9    0
     0   42   61   49    0
     0    1   10   90    0
     0    0    0    2    0
[epoch 25] step 2/44: loss=7.1979 
[epoch 25] step 4/44: loss=7.0915 
[epoch 25] step 6/44: loss=7.3906 
[epoch 25] step 8/44: loss=7.5860 
[epoch 25] step 10/44: loss=7.6312 
[epoch 25] step 12/44: loss=7.6691 
[epoch 25] step 14/44: loss=7.7171 
[epoch 25] step 16/44: loss=7.7782 
[epoch 25] step 18/44: loss=7.7648 
[epoch 25] step 20/44: loss=7.7793 
[epoch 25] step 22/44: loss=7.8502 
[epoch 25] step 24/44: loss=7.8950 
[epoch 25] step 26/44: loss=7.9053 
[epoch 25] step 28/44: loss=7.9177 
[epoch 25] step 30/44: loss=7.8618 
[epoch 25] step 32/44: loss=7.8226 
[epoch 25] step 34/44: loss=7.7522 
[epoch 25] step 36/44: loss=7.7281 
[epoch 25] step 38/44: loss=7.6884 
[epoch 25] step 40/44: loss=7.7095 
[epoch 25] step 42/44: loss=7.7057 
[epoch 25] step 44/44: loss=7.7440 
[epoch 25] train_loss(avg per step)=15.4879 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=10.1570 qwk=('0.6062', '0.5257', '0.6198') averageQWK=0.5839 macroEMD=0.3672 tailR0=('0.1087', '0.0417', '0.0000') tailR0avg=0.0501
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   21   26    7    0
     0   14   82   28    2
     0    2   24   85    5
     0    0    0   18    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     1    9   36    6    0
     0    7   86   28    1
     0    2   34   95    2
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   36   25    7    0
     0   38   78   36    0
     0    0   17   82    2
     0    0    0    2    0
[epoch 26] step 2/44: loss=8.6491 
[epoch 26] step 4/44: loss=8.4442 
[epoch 26] step 6/44: loss=8.4929 
[epoch 26] step 8/44: loss=8.6802 
[epoch 26] step 10/44: loss=8.6363 
[epoch 26] step 12/44: loss=8.5432 
[epoch 26] step 14/44: loss=8.2301 
[epoch 26] step 16/44: loss=8.0822 
[epoch 26] step 18/44: loss=7.9282 
[epoch 26] step 20/44: loss=7.8612 
[epoch 26] step 22/44: loss=7.8819 
[epoch 26] step 24/44: loss=7.8953 
[epoch 26] step 26/44: loss=7.9715 
[epoch 26] step 28/44: loss=7.9711 
[epoch 26] step 30/44: loss=8.0326 
[epoch 26] step 32/44: loss=8.0303 
[epoch 26] step 34/44: loss=8.0033 
[epoch 26] step 36/44: loss=8.0153 
[epoch 26] step 38/44: loss=7.9494 
[epoch 26] step 40/44: loss=7.9577 
[epoch 26] step 42/44: loss=7.9231 
[epoch 26] step 44/44: loss=7.8720 
[epoch 26] train_loss(avg per step)=15.7440 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=10.3514 qwk=('0.5271', '0.5135', '0.5845') averageQWK=0.5417 macroEMD=0.3690 tailR0=('0.1739', '0.0833', '0.0000') tailR0avg=0.0857
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     1   16   31    6    0
     0    9   87   24    6
     3    0   30   68   15
     0    0    1   14    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     1    9   34    8    0
     1    7   72   41    1
     0    2   26  101    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   21   42    5    0
     0   15  108   29    0
     0    0   22   77    2
     0    0    0    2    0
[epoch 27] step 2/44: loss=7.6060 
[epoch 27] step 4/44: loss=8.0370 
[epoch 27] step 6/44: loss=8.0022 
[epoch 27] step 8/44: loss=8.0076 
[epoch 27] step 10/44: loss=8.1574 
[epoch 27] step 12/44: loss=8.0663 
[epoch 27] step 14/44: loss=8.2083 
[epoch 27] step 16/44: loss=8.2026 
[epoch 27] step 18/44: loss=8.2526 
[epoch 27] step 20/44: loss=8.1995 
[epoch 27] step 22/44: loss=8.1676 
[epoch 27] step 24/44: loss=8.1400 
[epoch 27] step 26/44: loss=8.1435 
[epoch 27] step 28/44: loss=8.0471 
[epoch 27] step 30/44: loss=7.9914 
[epoch 27] step 32/44: loss=7.9678 
[epoch 27] step 34/44: loss=7.9267 
[epoch 27] step 36/44: loss=7.8645 
[epoch 27] step 38/44: loss=7.8373 
[epoch 27] step 40/44: loss=7.8446 
[epoch 27] step 42/44: loss=7.8695 
[epoch 27] step 44/44: loss=7.9289 
[epoch 27] train_loss(avg per step)=15.8578 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=10.5261 qwk=('0.5354', '0.4913', '0.5934') averageQWK=0.5400 macroEMD=0.3666 tailR0=('0.2174', '0.0417', '0.0000') tailR0avg=0.0864
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   13   34    5    2
     0    8   77   35    6
     0    0   28   72   16
     0    0    0   13   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   11   32    9    0
     1    9   67   43    2
     0    3   20  105    5
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   35   23   10    0
     0   35   71   46    0
     0    0   14   86    1
     0    0    0    2    0
[epoch 28] step 2/44: loss=8.6193 
[epoch 28] step 4/44: loss=8.4934 
[epoch 28] step 6/44: loss=8.4331 
[epoch 28] step 8/44: loss=8.2298 
[epoch 28] step 10/44: loss=8.1688 
[epoch 28] step 12/44: loss=7.9760 
[epoch 28] step 14/44: loss=7.9014 
[epoch 28] step 16/44: loss=7.8632 
[epoch 28] step 18/44: loss=7.7244 
[epoch 28] step 20/44: loss=7.6649 
[epoch 28] step 22/44: loss=7.7229 
[epoch 28] step 24/44: loss=7.7270 
[epoch 28] step 26/44: loss=7.7812 
[epoch 28] step 28/44: loss=7.8238 
[epoch 28] step 30/44: loss=7.8619 
[epoch 28] step 32/44: loss=7.9010 
[epoch 28] step 34/44: loss=7.9287 
[epoch 28] step 36/44: loss=7.9310 
[epoch 28] step 38/44: loss=7.9240 
[epoch 28] step 40/44: loss=7.8782 
[epoch 28] step 42/44: loss=7.8702 
[epoch 28] step 44/44: loss=7.8264 
[epoch 28] train_loss(avg per step)=15.6529 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=10.3089 qwk=('0.5282', '0.5192', '0.5832') averageQWK=0.5435 macroEMD=0.3688 tailR0=('0.1304', '0.0833', '0.0000') tailR0avg=0.0713
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    3    0
     0   17   29    8    0
     0    8   74   42    2
     1    0   23   85    7
     0    0    0   17    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   15   30    7    0
     1   12   65   43    1
     0    4   24  101    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   24   36    8    0
     0   21   96   35    0
     0    0   17   83    1
     0    0    0    2    0
[epoch 29] step 2/44: loss=8.0335 
[epoch 29] step 4/44: loss=7.9871 
[epoch 29] step 6/44: loss=8.0033 
[epoch 29] step 8/44: loss=7.8950 
[epoch 29] step 10/44: loss=7.8190 
[epoch 29] step 12/44: loss=7.8697 
[epoch 29] step 14/44: loss=7.8781 
[epoch 29] step 16/44: loss=7.8829 
[epoch 29] step 18/44: loss=7.7444 
[epoch 29] step 20/44: loss=7.7737 
[epoch 29] step 22/44: loss=7.8008 
[epoch 29] step 24/44: loss=7.7934 
[epoch 29] step 26/44: loss=7.8184 
[epoch 29] step 28/44: loss=7.7605 
[epoch 29] step 30/44: loss=7.7825 
[epoch 29] step 32/44: loss=7.8152 
[epoch 29] step 34/44: loss=7.8671 
[epoch 29] step 36/44: loss=7.8757 
[epoch 29] step 38/44: loss=7.8611 
[epoch 29] step 40/44: loss=7.8572 
[epoch 29] step 42/44: loss=7.8798 
[epoch 29] step 44/44: loss=7.8565 
[epoch 29] train_loss(avg per step)=15.7131 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=10.4103 qwk=('0.5613', '0.4949', '0.6164') averageQWK=0.5575 macroEMD=0.3691 tailR0=('0.1522', '0.0417', '0.0000') tailR0avg=0.0646
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    3    0
     1   21   24    8    0
     1   11   77   35    2
     1    0   25   83    7
     0    0    0   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   14   28   10    0
     2   11   65   43    1
     0    4   21  106    2
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   40   20    8    0
     0   39   79   34    0
     0    1   18   81    1
     0    0    0    2    0
[epoch 30] step 2/44: loss=7.5648 
[epoch 30] step 4/44: loss=7.7776 
[epoch 30] step 6/44: loss=8.0245 
[epoch 30] step 8/44: loss=7.9066 
[epoch 30] step 10/44: loss=7.9080 
[epoch 30] step 12/44: loss=7.8695 
[epoch 30] step 14/44: loss=7.8064 
[epoch 30] step 16/44: loss=7.7993 
[epoch 30] step 18/44: loss=7.8106 
[epoch 30] step 20/44: loss=7.7748 
[epoch 30] step 22/44: loss=7.7560 
[epoch 30] step 24/44: loss=7.7466 
[epoch 30] step 26/44: loss=7.8241 
[epoch 30] step 28/44: loss=7.8852 
[epoch 30] step 30/44: loss=7.9155 
[epoch 30] step 32/44: loss=7.9037 
[epoch 30] step 34/44: loss=7.9051 
[epoch 30] step 36/44: loss=7.9154 
[epoch 30] step 38/44: loss=7.9457 
[epoch 30] step 40/44: loss=7.9190 
[epoch 30] step 42/44: loss=7.9030 
[epoch 30] step 44/44: loss=7.9071 
[epoch 30] train_loss(avg per step)=15.8142 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=10.4307 qwk=('0.6111', '0.4828', '0.5787') averageQWK=0.5575 macroEMD=0.3690 tailR0=('0.2174', '0.0417', '0.0000') tailR0avg=0.0864
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     1   17   30    6    0
     1    9   86   27    3
     0    0   30   74   12
     0    0    0   13   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     1    6   37    8    0
     2    6   77   36    1
     0    2   32   95    4
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   28    9    0
     0   29   86   37    0
     0    1   17   83    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=7.5112 
[epoch 31] step 4/44: loss=7.4355 
[epoch 31] step 6/44: loss=7.5564 
[epoch 31] step 8/44: loss=7.7535 
[epoch 31] step 10/44: loss=7.7388 
[epoch 31] step 12/44: loss=7.7286 
[epoch 31] step 14/44: loss=7.8772 
[epoch 31] step 16/44: loss=7.8944 
[epoch 31] step 18/44: loss=7.9314 
[epoch 31] step 20/44: loss=8.0017 
[epoch 31] step 22/44: loss=8.1007 
[epoch 31] step 24/44: loss=8.1226 
[epoch 31] step 26/44: loss=8.0915 
[epoch 31] step 28/44: loss=8.0395 
[epoch 31] step 30/44: loss=8.0129 
[epoch 31] step 32/44: loss=7.9754 
[epoch 31] step 34/44: loss=7.9395 
[epoch 31] step 36/44: loss=7.9008 
[epoch 31] step 38/44: loss=7.9100 
[epoch 31] step 40/44: loss=7.9148 
[epoch 31] step 42/44: loss=7.9021 
[epoch 31] step 44/44: loss=7.8540 
[epoch 31] train_loss(avg per step)=15.7081 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=10.4659 qwk=('0.5473', '0.4670', '0.5207') averageQWK=0.5117 macroEMD=0.3694 tailR0=('0.1739', '0.0417', '0.0000') tailR0avg=0.0719
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    3    0
     0   20   24   10    0
     0    9   70   44    3
     0    0   21   85   10
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     1    9   32   10    0
     2    9   64   46    1
     0    4   21  105    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   17   42    9    0
     0   14  103   35    0
     0    0   21   78    2
     0    0    0    2    0
[epoch 32] step 2/44: loss=7.8821 
[epoch 32] step 4/44: loss=7.8040 
[epoch 32] step 6/44: loss=8.1594 
[epoch 32] step 8/44: loss=8.1948 
[epoch 32] step 10/44: loss=8.0875 
[epoch 32] step 12/44: loss=8.0554 
[epoch 32] step 14/44: loss=7.9989 
[epoch 32] step 16/44: loss=7.9762 
[epoch 32] step 18/44: loss=7.8878 
[epoch 32] step 20/44: loss=7.9992 
[epoch 32] step 22/44: loss=7.9347 
[epoch 32] step 24/44: loss=7.9624 
[epoch 32] step 26/44: loss=7.9949 
[epoch 32] step 28/44: loss=7.9747 
[epoch 32] step 30/44: loss=8.0156 
[epoch 32] step 32/44: loss=8.0597 
[epoch 32] step 34/44: loss=8.0782 
[epoch 32] step 36/44: loss=8.1023 
[epoch 32] step 38/44: loss=8.0799 
[epoch 32] step 40/44: loss=8.0810 
[epoch 32] step 42/44: loss=8.0521 
[epoch 32] step 44/44: loss=8.0078 
[epoch 32] train_loss(avg per step)=16.0156 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=10.7475 qwk=('0.5453', '0.4840', '0.5462') averageQWK=0.5252 macroEMD=0.3697 tailR0=('0.1739', '0.0417', '0.0000') tailR0avg=0.0719
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    4    0
     0   21   24    9    0
     0    8   77   38    3
     1    0   23   83    9
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   15   27   10    0
     2   12   62   44    2
     0    4   24  100    5
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   26   30   12    0
     1   26   74   51    0
     0    0   11   89    1
     0    0    0    2    0
[epoch 33] step 2/44: loss=7.5017 
[epoch 33] step 4/44: loss=7.2297 
[epoch 33] step 6/44: loss=7.2381 
[epoch 33] step 8/44: loss=7.4907 
[epoch 33] step 10/44: loss=7.5622 
[epoch 33] step 12/44: loss=7.6346 
[epoch 33] step 14/44: loss=7.7040 
[epoch 33] step 16/44: loss=7.7135 
[epoch 33] step 18/44: loss=7.7586 
[epoch 33] step 20/44: loss=7.8152 
[epoch 33] step 22/44: loss=7.7848 
[epoch 33] step 24/44: loss=7.7757 
[epoch 33] step 26/44: loss=7.8291 
[epoch 33] step 28/44: loss=7.8134 
[epoch 33] step 30/44: loss=7.8208 
[epoch 33] step 32/44: loss=7.8332 
[epoch 33] step 34/44: loss=7.7963 
[epoch 33] step 36/44: loss=7.7861 
[epoch 33] step 38/44: loss=7.7848 
[epoch 33] step 40/44: loss=7.7909 
[epoch 33] step 42/44: loss=7.7567 
[epoch 33] step 44/44: loss=7.7840 
[epoch 33] train_loss(avg per step)=15.5680 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=10.2871 qwk=('0.5756', '0.4671', '0.5708') averageQWK=0.5379 macroEMD=0.3690 tailR0=('0.1957', '0.0417', '0.0000') tailR0avg=0.0791
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    2    0
     0   17   30    7    0
     0    6   89   28    3
     0    0   30   75   11
     0    0    0   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     1    9   33    9    0
     2    8   72   39    1
     0    4   28   96    5
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   26   33    9    0
     0   25   90   37    0
     0    0   18   83    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=7.8695 
[epoch 34] step 4/44: loss=8.0633 
[epoch 34] step 6/44: loss=7.9825 
[epoch 34] step 8/44: loss=7.9666 
[epoch 34] step 10/44: loss=8.0185 
[epoch 34] step 12/44: loss=7.9752 
[epoch 34] step 14/44: loss=7.9736 
[epoch 34] step 16/44: loss=8.0598 
[epoch 34] step 18/44: loss=8.0053 
[epoch 34] step 20/44: loss=7.9741 
[epoch 34] step 22/44: loss=7.9434 
[epoch 34] step 24/44: loss=7.9455 
[epoch 34] step 26/44: loss=7.9413 
[epoch 34] step 28/44: loss=7.9729 
[epoch 34] step 30/44: loss=7.9598 
[epoch 34] step 32/44: loss=7.9877 
[epoch 34] step 34/44: loss=7.9775 
[epoch 34] step 36/44: loss=7.9468 
[epoch 34] step 38/44: loss=7.9411 
[epoch 34] step 40/44: loss=7.9672 
[epoch 34] step 42/44: loss=7.9700 
[epoch 34] step 44/44: loss=7.9370 
[epoch 34] train_loss(avg per step)=15.8739 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=10.5496 qwk=('0.5544', '0.4791', '0.5737') averageQWK=0.5357 macroEMD=0.3699 tailR0=('0.1957', '0.0417', '0.0000') tailR0avg=0.0791
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    3    0
     0   17   28    9    0
     0    8   84   31    3
     0    0   27   78   11
     0    0    0   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   12   31    9    0
     2    8   72   39    1
     0    4   26   99    4
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   27   32    9    0
     0   25   89   38    0
     0    0   18   82    1
     0    0    0    2    0
[epoch 35] step 2/44: loss=8.6518 
[epoch 35] step 4/44: loss=8.2735 
[epoch 35] step 6/44: loss=8.3518 
[epoch 35] step 8/44: loss=8.2989 
[epoch 35] step 10/44: loss=8.2006 
[epoch 35] step 12/44: loss=8.1752 
[epoch 35] step 14/44: loss=8.1151 
[epoch 35] step 16/44: loss=8.1097 
[epoch 35] step 18/44: loss=8.0525 
[epoch 35] step 20/44: loss=7.9913 
[epoch 35] step 22/44: loss=7.9208 
[epoch 35] step 24/44: loss=7.9160 
[epoch 35] step 26/44: loss=7.9140 
[epoch 35] step 28/44: loss=7.8777 
[epoch 35] step 30/44: loss=7.8708 
[epoch 35] step 32/44: loss=7.8628 
[epoch 35] step 34/44: loss=7.8376 
[epoch 35] step 36/44: loss=7.7964 
[epoch 35] step 38/44: loss=7.8245 
[epoch 35] step 40/44: loss=7.8396 
[epoch 35] step 42/44: loss=7.8782 
[epoch 35] step 44/44: loss=7.8549 
[epoch 35] train_loss(avg per step)=15.7098 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=10.4867 qwk=('0.5892', '0.4860', '0.5542') averageQWK=0.5432 macroEMD=0.3697 tailR0=('0.1957', '0.0417', '0.0000') tailR0avg=0.0791
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   20   25    9    0
     0    8   86   29    3
     1    0   27   78   10
     0    0    0   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   13   30    9    0
     2   10   70   39    1
     0    4   25   99    5
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   24   35    9    0
     0   25   92   35    0
     0    0   19   80    2
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-1-reassignment-1/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-1-conf_gating-1-reassignment-1/fold1/metrics.json
Done.
