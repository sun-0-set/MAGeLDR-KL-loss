[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.9080 
[epoch 1] step 4/44: loss=0.8935 
[epoch 1] step 6/44: loss=0.8922 
[epoch 1] step 8/44: loss=0.8930 
[epoch 1] step 10/44: loss=0.8909 
[epoch 1] step 12/44: loss=0.8882 
[epoch 1] step 14/44: loss=0.8882 
[epoch 1] step 16/44: loss=0.8845 
[epoch 1] step 18/44: loss=0.8824 
[epoch 1] step 20/44: loss=0.8819 
[epoch 1] step 22/44: loss=0.8803 
[epoch 1] step 24/44: loss=0.8811 
[epoch 1] step 26/44: loss=0.8789 
[epoch 1] step 28/44: loss=0.8779 
[epoch 1] step 30/44: loss=0.8776 
[epoch 1] step 32/44: loss=0.8774 
[epoch 1] step 34/44: loss=0.8754 
[epoch 1] step 36/44: loss=0.8744 
[epoch 1] step 38/44: loss=0.8729 
[epoch 1] step 40/44: loss=0.8709 
[epoch 1] step 42/44: loss=0.8684 
[epoch 1] step 44/44: loss=0.8649 
[epoch 1] train_loss(avg per step)=1.7298 lambda[min,max]=[0.915444,1.000000]
[epoch 1] val_loss=1.5356 qwk=('0.0642', '0.0354', '0.2250') averageQWK=0.1082 macroEMD=0.3725 tailR0=('0.0000', '0.0556', '0.5000') tailR0avg=0.1852
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    7    0
     0   18    0   36    0
     0   51    2   72    0
     0   35    3   78    0
     0    2    5   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    0    0
    20    0   31    2    0
    42    0   76    3    0
    43    0   82    8    0
     1    0   10    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   37   31    0    1
     0   62   73    4   12
     0   32   48   11   10
     0    0    0    0    2
[epoch 2] step 2/44: loss=0.7569 
[epoch 2] step 4/44: loss=0.7634 
[epoch 2] step 6/44: loss=0.7514 
[epoch 2] step 8/44: loss=0.7460 
[epoch 2] step 10/44: loss=0.7392 
[epoch 2] step 12/44: loss=0.7340 
[epoch 2] step 14/44: loss=0.7316 
[epoch 2] step 16/44: loss=0.7264 
[epoch 2] step 18/44: loss=0.7179 
[epoch 2] step 20/44: loss=0.7106 
[epoch 2] step 22/44: loss=0.7032 
[epoch 2] step 24/44: loss=0.6955 
[epoch 2] step 26/44: loss=0.6886 
[epoch 2] step 28/44: loss=0.6791 
[epoch 2] step 30/44: loss=0.6737 
[epoch 2] step 32/44: loss=0.6683 
[epoch 2] step 34/44: loss=0.6633 
[epoch 2] step 36/44: loss=0.6605 
[epoch 2] step 38/44: loss=0.6576 
[epoch 2] step 40/44: loss=0.6544 
[epoch 2] step 42/44: loss=0.6511 
[epoch 2] step 44/44: loss=0.6482 
[epoch 2] train_loss(avg per step)=1.2964 lambda[min,max]=[0.811961,1.000000]
[epoch 2] val_loss=1.1215 qwk=('0.3021', '0.2326', '0.2938') averageQWK=0.2761 macroEMD=0.3095 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    0   54    0    0
     0    0  110   15    0
     0    0   62   54    0
     0    0   14    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   53    0    0
     0    0  116    5    0
     0    0   97   36    0
     0    0    7    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    0   69    0    0
     0    0  148    3    0
     0    0   66   35    0
     0    0    1    1    0
[epoch 3] step 2/44: loss=0.5363 
[epoch 3] step 4/44: loss=0.5468 
[epoch 3] step 6/44: loss=0.5419 
[epoch 3] step 8/44: loss=0.5377 
[epoch 3] step 10/44: loss=0.5344 
[epoch 3] step 12/44: loss=0.5344 
[epoch 3] step 14/44: loss=0.5332 
[epoch 3] step 16/44: loss=0.5311 
[epoch 3] step 18/44: loss=0.5309 
[epoch 3] step 20/44: loss=0.5267 
[epoch 3] step 22/44: loss=0.5287 
[epoch 3] step 24/44: loss=0.5268 
[epoch 3] step 26/44: loss=0.5269 
[epoch 3] step 28/44: loss=0.5244 
[epoch 3] step 30/44: loss=0.5223 
[epoch 3] step 32/44: loss=0.5234 
[epoch 3] step 34/44: loss=0.5225 
[epoch 3] step 36/44: loss=0.5176 
[epoch 3] step 38/44: loss=0.5175 
[epoch 3] step 40/44: loss=0.5148 
[epoch 3] step 42/44: loss=0.5121 
[epoch 3] step 44/44: loss=0.5154 
[epoch 3] train_loss(avg per step)=1.0308 lambda[min,max]=[0.704178,1.000000]
[epoch 3] val_loss=0.9153 qwk=('0.5053', '0.4391', '0.5664') averageQWK=0.5036 macroEMD=0.2489 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    4   46    4    0
     0    3   86   36    0
     0    0   21   95    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   40   13    0
     0    0   79   42    0
     0    0   18  115    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   36   26    7    0
     0   23   90   38    0
     0    3   23   75    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=0.4366 
[epoch 4] step 4/44: loss=0.4486 
[epoch 4] step 6/44: loss=0.4646 
[epoch 4] step 8/44: loss=0.4592 
[epoch 4] step 10/44: loss=0.4493 
[epoch 4] step 12/44: loss=0.4485 
[epoch 4] step 14/44: loss=0.4499 
[epoch 4] step 16/44: loss=0.4470 
[epoch 4] step 18/44: loss=0.4448 
[epoch 4] step 20/44: loss=0.4468 
[epoch 4] step 22/44: loss=0.4465 
[epoch 4] step 24/44: loss=0.4493 
[epoch 4] step 26/44: loss=0.4482 
[epoch 4] step 28/44: loss=0.4437 
[epoch 4] step 30/44: loss=0.4422 
[epoch 4] step 32/44: loss=0.4424 
[epoch 4] step 34/44: loss=0.4393 
[epoch 4] step 36/44: loss=0.4400 
[epoch 4] step 38/44: loss=0.4376 
[epoch 4] step 40/44: loss=0.4378 
[epoch 4] step 42/44: loss=0.4362 
[epoch 4] step 44/44: loss=0.4350 
[epoch 4] train_loss(avg per step)=0.8700 lambda[min,max]=[0.638089,1.000000]
[epoch 4] val_loss=0.8775 qwk=('0.5477', '0.5096', '0.5794') averageQWK=0.5456 macroEMD=0.2376 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    0    0
     0    7   43    4    0
     0    8   73   44    0
     0    0   17   99    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    0    0
     0    4   42    7    0
     0    4   75   42    0
     0    0   22  111    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   30   34    5    0
     0   23   90   38    0
     0    1   25   75    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=0.3891 
[epoch 5] step 4/44: loss=0.3859 
[epoch 5] step 6/44: loss=0.3767 
[epoch 5] step 8/44: loss=0.3671 
[epoch 5] step 10/44: loss=0.3782 
[epoch 5] step 12/44: loss=0.3761 
[epoch 5] step 14/44: loss=0.3787 
[epoch 5] step 16/44: loss=0.3800 
[epoch 5] step 18/44: loss=0.3815 
[epoch 5] step 20/44: loss=0.3786 
[epoch 5] step 22/44: loss=0.3782 
[epoch 5] step 24/44: loss=0.3785 
[epoch 5] step 26/44: loss=0.3758 
[epoch 5] step 28/44: loss=0.3773 
[epoch 5] step 30/44: loss=0.3748 
[epoch 5] step 32/44: loss=0.3747 
[epoch 5] step 34/44: loss=0.3748 
[epoch 5] step 36/44: loss=0.3768 
[epoch 5] step 38/44: loss=0.3788 
[epoch 5] step 40/44: loss=0.3792 
[epoch 5] step 42/44: loss=0.3793 
[epoch 5] step 44/44: loss=0.3744 
[epoch 5] train_loss(avg per step)=0.7488 lambda[min,max]=[0.603985,1.000000]
[epoch 5] val_loss=0.8509 qwk=('0.6069', '0.5594', '0.5692') averageQWK=0.5785 macroEMD=0.2229 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   14   38    2    0
     0   11   74   40    0
     0    0   19   97    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   16   27   10    0
     0   17   51   53    0
     0    1   12  120    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   18   49    2    0
     0    5  113   33    0
     0    0   27   74    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=0.3043 
[epoch 6] step 4/44: loss=0.3005 
[epoch 6] step 6/44: loss=0.3138 
[epoch 6] step 8/44: loss=0.3237 
[epoch 6] step 10/44: loss=0.3284 
[epoch 6] step 12/44: loss=0.3159 
[epoch 6] step 14/44: loss=0.3123 
[epoch 6] step 16/44: loss=0.3152 
[epoch 6] step 18/44: loss=0.3260 
[epoch 6] step 20/44: loss=0.3279 
[epoch 6] step 22/44: loss=0.3271 
[epoch 6] step 24/44: loss=0.3301 
[epoch 6] step 26/44: loss=0.3282 
[epoch 6] step 28/44: loss=0.3316 
[epoch 6] step 30/44: loss=0.3324 
[epoch 6] step 32/44: loss=0.3343 
[epoch 6] step 34/44: loss=0.3353 
[epoch 6] step 36/44: loss=0.3342 
[epoch 6] step 38/44: loss=0.3373 
[epoch 6] step 40/44: loss=0.3366 
[epoch 6] step 42/44: loss=0.3364 
[epoch 6] step 44/44: loss=0.3373 
[epoch 6] train_loss(avg per step)=0.6746 lambda[min,max]=[0.575014,1.000000]
[epoch 6] val_loss=0.8289 qwk=('0.6089', '0.5496', '0.5896') averageQWK=0.5827 macroEMD=0.2190 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0    9   43    2    0
     0    7   84   34    0
     0    0   20   96    0
     0    0    2   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   11   33    9    0
     0   10   65   46    0
     0    0   20  113    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   31    7    0
     0   12  104   35    0
     0    0   28   73    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=0.2451 
[epoch 7] step 4/44: loss=0.2748 
[epoch 7] step 6/44: loss=0.3028 
[epoch 7] step 8/44: loss=0.2957 
[epoch 7] step 10/44: loss=0.3051 
[epoch 7] step 12/44: loss=0.3012 
[epoch 7] step 14/44: loss=0.3005 
[epoch 7] step 16/44: loss=0.3071 
[epoch 7] step 18/44: loss=0.3037 
[epoch 7] step 20/44: loss=0.3007 
[epoch 7] step 22/44: loss=0.3002 
[epoch 7] step 24/44: loss=0.3026 
[epoch 7] step 26/44: loss=0.2993 
[epoch 7] step 28/44: loss=0.3007 
[epoch 7] step 30/44: loss=0.3020 
[epoch 7] step 32/44: loss=0.3034 
[epoch 7] step 34/44: loss=0.3007 
[epoch 7] step 36/44: loss=0.3004 
[epoch 7] step 38/44: loss=0.3048 
[epoch 7] step 40/44: loss=0.3067 
[epoch 7] step 42/44: loss=0.3045 
[epoch 7] step 44/44: loss=0.3042 
[epoch 7] train_loss(avg per step)=0.6085 lambda[min,max]=[0.560711,1.000000]
[epoch 7] val_loss=0.8843 qwk=('0.4894', '0.4765', '0.5014') averageQWK=0.4891 macroEMD=0.2312 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    0    0
     0    4   40   10    0
     0    1   69   55    0
     0    0   13  103    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0    6   32   15    0
     0    3   54   64    0
     0    0   10  123    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   12   48    9    0
     0    3   88   60    0
     0    0   15   86    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=0.2838 
[epoch 8] step 4/44: loss=0.3041 
[epoch 8] step 6/44: loss=0.2950 
[epoch 8] step 8/44: loss=0.2963 
[epoch 8] step 10/44: loss=0.3022 
[epoch 8] step 12/44: loss=0.3039 
[epoch 8] step 14/44: loss=0.3051 
[epoch 8] step 16/44: loss=0.3044 
[epoch 8] step 18/44: loss=0.3013 
[epoch 8] step 20/44: loss=0.2996 
[epoch 8] step 22/44: loss=0.2956 
[epoch 8] step 24/44: loss=0.2921 
[epoch 8] step 26/44: loss=0.2918 
[epoch 8] step 28/44: loss=0.2904 
[epoch 8] step 30/44: loss=0.2945 
[epoch 8] step 32/44: loss=0.2925 
[epoch 8] step 34/44: loss=0.2897 
[epoch 8] step 36/44: loss=0.2868 
[epoch 8] step 38/44: loss=0.2859 
[epoch 8] step 40/44: loss=0.2835 
[epoch 8] step 42/44: loss=0.2801 
[epoch 8] step 44/44: loss=0.2789 
[epoch 8] train_loss(avg per step)=0.5579 lambda[min,max]=[0.544083,1.000000]
[epoch 8] val_loss=0.7922 qwk=('0.6592', '0.6029', '0.6264') averageQWK=0.6295 macroEMD=0.2012 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    1    0    0
     0   23   31    0    0
     0   19   81   25    0
     0    0   33   83    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   21   29    3    0
     0   26   68   27    0
     0    2   35   96    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   45   22    2    0
     0   29  106   16    0
     0    3   40   58    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=0.2373 
[epoch 9] step 4/44: loss=0.2142 
[epoch 9] step 6/44: loss=0.2289 
[epoch 9] step 8/44: loss=0.2282 
[epoch 9] step 10/44: loss=0.2361 
[epoch 9] step 12/44: loss=0.2262 
[epoch 9] step 14/44: loss=0.2190 
[epoch 9] step 16/44: loss=0.2159 
[epoch 9] step 18/44: loss=0.2158 
[epoch 9] step 20/44: loss=0.2233 
[epoch 9] step 22/44: loss=0.2253 
[epoch 9] step 24/44: loss=0.2219 
[epoch 9] step 26/44: loss=0.2229 
[epoch 9] step 28/44: loss=0.2209 
[epoch 9] step 30/44: loss=0.2225 
[epoch 9] step 32/44: loss=0.2188 
[epoch 9] step 34/44: loss=0.2208 
[epoch 9] step 36/44: loss=0.2215 
[epoch 9] step 38/44: loss=0.2227 
[epoch 9] step 40/44: loss=0.2214 
[epoch 9] step 42/44: loss=0.2213 
[epoch 9] step 44/44: loss=0.2234 
[epoch 9] train_loss(avg per step)=0.4467 lambda[min,max]=[0.531851,1.000000]
[epoch 9] val_loss=0.8356 qwk=('0.6094', '0.5680', '0.5872') averageQWK=0.5882 macroEMD=0.2069 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   22   32    0    0
     0   21   89   15    0
     0    0   47   69    0
     0    0    5   17    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   17   34    2    0
     0   22   84   15    0
     0    2   50   81    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   43   26    0    0
     0   28  118    5    0
     0    4   55   42    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=0.1920 
[epoch 10] step 4/44: loss=0.1911 
[epoch 10] step 6/44: loss=0.1922 
[epoch 10] step 8/44: loss=0.1908 
[epoch 10] step 10/44: loss=0.1910 
[epoch 10] step 12/44: loss=0.1894 
[epoch 10] step 14/44: loss=0.1896 
[epoch 10] step 16/44: loss=0.1899 
[epoch 10] step 18/44: loss=0.1867 
[epoch 10] step 20/44: loss=0.1852 
[epoch 10] step 22/44: loss=0.1849 
[epoch 10] step 24/44: loss=0.1802 
[epoch 10] step 26/44: loss=0.1806 
[epoch 10] step 28/44: loss=0.1788 
[epoch 10] step 30/44: loss=0.1780 
[epoch 10] step 32/44: loss=0.1776 
[epoch 10] step 34/44: loss=0.1766 
[epoch 10] step 36/44: loss=0.1767 
[epoch 10] step 38/44: loss=0.1767 
[epoch 10] step 40/44: loss=0.1782 
[epoch 10] step 42/44: loss=0.1796 
[epoch 10] step 44/44: loss=0.1802 
[epoch 10] train_loss(avg per step)=0.3604 lambda[min,max]=[0.516590,1.000000]
[epoch 10] val_loss=0.8491 qwk=('0.6158', '0.5596', '0.5983') averageQWK=0.5912 macroEMD=0.1959 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    1    0    0
     0   23   31    0    0
     0   25   86   14    0
     0    0   50   66    0
     0    0    5   16    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   22   28    3    0
     0   25   78   18    0
     0    3   52   78    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   45   23    1    0
     0   34  104   13    0
     0    3   49   49    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.1865 
[epoch 11] step 4/44: loss=0.1668 
[epoch 11] step 6/44: loss=0.1679 
[epoch 11] step 8/44: loss=0.1643 
[epoch 11] step 10/44: loss=0.1524 
[epoch 11] step 12/44: loss=0.1574 
[epoch 11] step 14/44: loss=0.1671 
[epoch 11] step 16/44: loss=0.1603 
[epoch 11] step 18/44: loss=0.1545 
[epoch 11] step 20/44: loss=0.1545 
[epoch 11] step 22/44: loss=0.1563 
[epoch 11] step 24/44: loss=0.1586 
[epoch 11] step 26/44: loss=0.1596 
[epoch 11] step 28/44: loss=0.1562 
[epoch 11] step 30/44: loss=0.1545 
[epoch 11] step 32/44: loss=0.1573 
[epoch 11] step 34/44: loss=0.1556 
[epoch 11] step 36/44: loss=0.1551 
[epoch 11] step 38/44: loss=0.1543 
[epoch 11] step 40/44: loss=0.1543 
[epoch 11] step 42/44: loss=0.1530 
[epoch 11] step 44/44: loss=0.1553 
[epoch 11] train_loss(avg per step)=0.3106 lambda[min,max]=[0.512839,1.000000]
[epoch 11] val_loss=0.7987 qwk=('0.6263', '0.5666', '0.6279') averageQWK=0.6069 macroEMD=0.1990 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   13   36    5    0
     0   11   75   39    0
     0    0   18   97    1
     0    0    2   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   18   26    9    0
     0   14   64   43    0
     0    1   22  110    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   37   29    3    0
     0   15  114   22    0
     0    0   38   63    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=0.1146 
[epoch 12] step 4/44: loss=0.1211 
[epoch 12] step 6/44: loss=0.1273 
[epoch 12] step 8/44: loss=0.1234 
[epoch 12] step 10/44: loss=0.1242 
[epoch 12] step 12/44: loss=0.1197 
[epoch 12] step 14/44: loss=0.1238 
[epoch 12] step 16/44: loss=0.1239 
[epoch 12] step 18/44: loss=0.1248 
[epoch 12] step 20/44: loss=0.1211 
[epoch 12] step 22/44: loss=0.1243 
[epoch 12] step 24/44: loss=0.1280 
[epoch 12] step 26/44: loss=0.1271 
[epoch 12] step 28/44: loss=0.1238 
[epoch 12] step 30/44: loss=0.1249 
[epoch 12] step 32/44: loss=0.1220 
[epoch 12] step 34/44: loss=0.1215 
[epoch 12] step 36/44: loss=0.1219 
[epoch 12] step 38/44: loss=0.1204 
[epoch 12] step 40/44: loss=0.1187 
[epoch 12] step 42/44: loss=0.1188 
[epoch 12] step 44/44: loss=0.1181 
[epoch 12] train_loss(avg per step)=0.2361 lambda[min,max]=[0.507470,1.000000]
[epoch 12] val_loss=0.7983 qwk=('0.6372', '0.5425', '0.6114') averageQWK=0.5970 macroEMD=0.1999 tailR0=('0.1739', '0.0000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   13   39    2    0
     0    8   87   29    1
     0    0   26   89    1
     0    0    3   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   13   30   10    0
     0   12   68   41    0
     0    1   20  112    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   35   32    2    0
     0   15  113   23    0
     0    1   36   64    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.0883 
[epoch 13] step 4/44: loss=0.0568 
[epoch 13] step 6/44: loss=0.0520 
[epoch 13] step 8/44: loss=0.0614 
[epoch 13] step 10/44: loss=0.0662 
[epoch 13] step 12/44: loss=0.0703 
[epoch 13] step 14/44: loss=0.0779 
[epoch 13] step 16/44: loss=0.0784 
[epoch 13] step 18/44: loss=0.0788 
[epoch 13] step 20/44: loss=0.0795 
[epoch 13] step 22/44: loss=0.0783 
[epoch 13] step 24/44: loss=0.0812 
[epoch 13] step 26/44: loss=0.0813 
[epoch 13] step 28/44: loss=0.0818 
[epoch 13] step 30/44: loss=0.0838 
[epoch 13] step 32/44: loss=0.0815 
[epoch 13] step 34/44: loss=0.0817 
[epoch 13] step 36/44: loss=0.0827 
[epoch 13] step 38/44: loss=0.0821 
[epoch 13] step 40/44: loss=0.0829 
[epoch 13] step 42/44: loss=0.0831 
[epoch 13] step 44/44: loss=0.0840 
[epoch 13] train_loss(avg per step)=0.1680 lambda[min,max]=[0.504211,1.000000]
[epoch 13] val_loss=0.8207 qwk=('0.6191', '0.5551', '0.6513') averageQWK=0.6085 macroEMD=0.1901 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   17   34    3    0
     0   14   74   37    0
     0    0   26   88    2
     0    0    4   12    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   17   30    6    0
     0   17   67   37    0
     0    2   32   99    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   47   19    3    0
     0   26   97   28    0
     0    2   31   68    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.1057 
[epoch 14] step 4/44: loss=0.0916 
[epoch 14] step 6/44: loss=0.0792 
[epoch 14] step 8/44: loss=0.0666 
[epoch 14] step 10/44: loss=0.0783 
[epoch 14] step 12/44: loss=0.0832 
[epoch 14] step 14/44: loss=0.0815 
[epoch 14] step 16/44: loss=0.0830 
[epoch 14] step 18/44: loss=0.0796 
[epoch 14] step 20/44: loss=0.0731 
[epoch 14] step 22/44: loss=0.0698 
[epoch 14] step 24/44: loss=0.0693 
[epoch 14] step 26/44: loss=0.0716 
[epoch 14] step 28/44: loss=0.0696 
[epoch 14] step 30/44: loss=0.0672 
[epoch 14] step 32/44: loss=0.0644 
[epoch 14] step 34/44: loss=0.0614 
[epoch 14] step 36/44: loss=0.0571 
[epoch 14] step 38/44: loss=0.0567 
[epoch 14] step 40/44: loss=0.0554 
[epoch 14] step 42/44: loss=0.0554 
[epoch 14] step 44/44: loss=0.0555 
[epoch 14] train_loss(avg per step)=0.1110 lambda[min,max]=[0.504120,1.000000]
[epoch 14] val_loss=0.8245 qwk=('0.6324', '0.5703', '0.6136') averageQWK=0.6055 macroEMD=0.1947 tailR0=('0.1522', '0.0417', '0.0000') tailR0avg=0.0646
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   18   30    6    0
     0   18   69   37    1
     0    0   22   90    4
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   18   30    5    0
     0   13   81   27    0
     0    1   43   88    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   31    3    0
     0   14  113   24    0
     0    2   33   66    0
     0    0    0    2    0
[epoch 15] step 2/44: loss=0.0715 
[epoch 15] step 4/44: loss=0.0640 
[epoch 15] step 6/44: loss=0.0554 
[epoch 15] step 8/44: loss=0.0520 
[epoch 15] step 10/44: loss=0.0514 
[epoch 15] step 12/44: loss=0.0446 
[epoch 15] step 14/44: loss=0.0384 
[epoch 15] step 16/44: loss=0.0327 
[epoch 15] step 18/44: loss=0.0283 
[epoch 15] step 20/44: loss=0.0253 
[epoch 15] step 22/44: loss=0.0313 
[epoch 15] step 24/44: loss=0.0302 
[epoch 15] step 26/44: loss=0.0282 
[epoch 15] step 28/44: loss=0.0285 
[epoch 15] step 30/44: loss=0.0279 
[epoch 15] step 32/44: loss=0.0296 
[epoch 15] step 34/44: loss=0.0279 
[epoch 15] step 36/44: loss=0.0292 
[epoch 15] step 38/44: loss=0.0294 
[epoch 15] step 40/44: loss=0.0283 
[epoch 15] step 42/44: loss=0.0253 
[epoch 15] step 44/44: loss=0.0271 
[epoch 15] train_loss(avg per step)=0.0542 lambda[min,max]=[0.502943,1.000000]
[epoch 15] val_loss=0.8244 qwk=('0.5780', '0.5857', '0.6181') averageQWK=0.5939 macroEMD=0.1978 tailR0=('0.0652', '0.0417', '0.0000') tailR0avg=0.0356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0    9   43    2    0
     0    5   89   30    1
     0    0   31   85    0
     0    0    4   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   14   31    8    0
     0   11   73   37    0
     0    0   25  107    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   34   34    1    0
     0   11  123   17    0
     0    1   40   60    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=0.0144 
[epoch 16] step 4/44: loss=0.0173 
[epoch 16] step 6/44: loss=0.0249 
[epoch 16] step 8/44: loss=0.0127 
[epoch 16] step 10/44: loss=0.0139 
[epoch 16] step 12/44: loss=0.0144 
[epoch 16] step 14/44: loss=0.0113 
[epoch 16] step 16/44: loss=0.0096 
[epoch 16] step 18/44: loss=0.0065 
[epoch 16] step 20/44: loss=0.0021 
[epoch 16] step 22/44: loss=0.0012 
[epoch 16] step 24/44: loss=0.0011 
[epoch 16] step 26/44: loss=0.0034 
[epoch 16] step 28/44: loss=0.0024 
[epoch 16] step 30/44: loss=0.0027 
[epoch 16] step 32/44: loss=0.0033 
[epoch 16] step 34/44: loss=0.0033 
[epoch 16] step 36/44: loss=0.0036 
[epoch 16] step 38/44: loss=0.0046 
[epoch 16] step 40/44: loss=0.0050 
[epoch 16] step 42/44: loss=0.0050 
[epoch 16] step 44/44: loss=0.0072 
[epoch 16] train_loss(avg per step)=0.0144 lambda[min,max]=[0.502670,1.000000]
[epoch 16] val_loss=0.8441 qwk=('0.6155', '0.5493', '0.6120') averageQWK=0.5923 macroEMD=0.1973 tailR0=('0.1087', '0.0417', '0.0000') tailR0avg=0.0501
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   14   35    5    0
     0   10   68   46    1
     0    0   16   98    2
     0    0    1   17    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   16   27   10    0
     0   13   59   49    0
     0    0   16  116    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   39   26    4    0
     0   19  106   26    0
     0    1   33   67    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=-0.0064 
[epoch 17] step 4/44: loss=-0.0166 
[epoch 17] step 6/44: loss=-0.0300 
[epoch 17] step 8/44: loss=-0.0206 
[epoch 17] step 10/44: loss=-0.0234 
[epoch 17] step 12/44: loss=-0.0200 
[epoch 17] step 14/44: loss=-0.0167 
[epoch 17] step 16/44: loss=-0.0212 
[epoch 17] step 18/44: loss=-0.0184 
[epoch 17] step 20/44: loss=-0.0169 
[epoch 17] step 22/44: loss=-0.0191 
[epoch 17] step 24/44: loss=-0.0188 
[epoch 17] step 26/44: loss=-0.0189 
[epoch 17] step 28/44: loss=-0.0213 
[epoch 17] step 30/44: loss=-0.0224 
[epoch 17] step 32/44: loss=-0.0216 
[epoch 17] step 34/44: loss=-0.0218 
[epoch 17] step 36/44: loss=-0.0242 
[epoch 17] step 38/44: loss=-0.0252 
[epoch 17] step 40/44: loss=-0.0252 
[epoch 17] step 42/44: loss=-0.0258 
[epoch 17] step 44/44: loss=-0.0264 
[epoch 17] train_loss(avg per step)=-0.0528 lambda[min,max]=[0.502231,1.000000]
[epoch 17] val_loss=0.8913 qwk=('0.5926', '0.5626', '0.5151') averageQWK=0.5568 macroEMD=0.2025 tailR0=('0.0435', '0.0417', '0.0000') tailR0avg=0.0284
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   12   39    3    0
     0    7   80   38    0
     0    0   25   91    0
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   15   32    6    0
     0   14   76   31    0
     0    0   36   97    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   18   51    0    0
     0    5  129   17    0
     0    1   47   53    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=-0.0462 
[epoch 18] step 4/44: loss=-0.0497 
[epoch 18] step 6/44: loss=-0.0498 
[epoch 18] step 8/44: loss=-0.0534 
[epoch 18] step 10/44: loss=-0.0574 
[epoch 18] step 12/44: loss=-0.0579 
[epoch 18] step 14/44: loss=-0.0567 
[epoch 18] step 16/44: loss=-0.0553 
[epoch 18] step 18/44: loss=-0.0531 
[epoch 18] step 20/44: loss=-0.0555 
[epoch 18] step 22/44: loss=-0.0552 
[epoch 18] step 24/44: loss=-0.0568 
[epoch 18] step 26/44: loss=-0.0573 
[epoch 18] step 28/44: loss=-0.0571 
[epoch 18] step 30/44: loss=-0.0561 
[epoch 18] step 32/44: loss=-0.0565 
[epoch 18] step 34/44: loss=-0.0557 
[epoch 18] step 36/44: loss=-0.0547 
[epoch 18] step 38/44: loss=-0.0552 
[epoch 18] step 40/44: loss=-0.0550 
[epoch 18] step 42/44: loss=-0.0545 
[epoch 18] step 44/44: loss=-0.0549 
[epoch 18] train_loss(avg per step)=-0.1098 lambda[min,max]=[0.501879,1.000000]
[epoch 18] val_loss=0.8915 qwk=('0.6095', '0.5584', '0.5807') averageQWK=0.5829 macroEMD=0.1963 tailR0=('0.0652', '0.0417', '0.0000') tailR0avg=0.0356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   16   34    4    0
     0   14   71   39    1
     0    0   24   92    0
     0    0    2   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   13   34    6    0
     0    8   80   33    0
     0    0   35   97    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   35   29    5    0
     0   14  105   32    0
     0    2   31   68    0
     0    0    0    2    0
[epoch 19] step 2/44: loss=-0.0707 
[epoch 19] step 4/44: loss=-0.0492 
[epoch 19] step 6/44: loss=-0.0507 
[epoch 19] step 8/44: loss=-0.0547 
[epoch 19] step 10/44: loss=-0.0630 
[epoch 19] step 12/44: loss=-0.0623 
[epoch 19] step 14/44: loss=-0.0650 
[epoch 19] step 16/44: loss=-0.0680 
[epoch 19] step 18/44: loss=-0.0706 
[epoch 19] step 20/44: loss=-0.0716 
[epoch 19] step 22/44: loss=-0.0723 
[epoch 19] step 24/44: loss=-0.0706 
[epoch 19] step 26/44: loss=-0.0698 
[epoch 19] step 28/44: loss=-0.0723 
[epoch 19] step 30/44: loss=-0.0726 
[epoch 19] step 32/44: loss=-0.0717 
[epoch 19] step 34/44: loss=-0.0718 
[epoch 19] step 36/44: loss=-0.0719 
[epoch 19] step 38/44: loss=-0.0721 
[epoch 19] step 40/44: loss=-0.0726 
[epoch 19] step 42/44: loss=-0.0733 
[epoch 19] step 44/44: loss=-0.0755 
[epoch 19] train_loss(avg per step)=-0.1510 lambda[min,max]=[0.501705,1.000000]
[epoch 19] val_loss=0.9005 qwk=('0.6068', '0.5567', '0.6094') averageQWK=0.5910 macroEMD=0.1954 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   17   35    2    0
     0   13   81   31    0
     0    0   32   84    0
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   13   35    5    0
     0    7   85   29    0
     0    1   36   96    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   41   28    0    0
     0   24  111   16    0
     0    2   44   55    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=-0.1087 
[epoch 20] step 4/44: loss=-0.1158 
[epoch 20] step 6/44: loss=-0.1074 
[epoch 20] step 8/44: loss=-0.1035 
[epoch 20] step 10/44: loss=-0.0976 
[epoch 20] step 12/44: loss=-0.0992 
[epoch 20] step 14/44: loss=-0.0974 
[epoch 20] step 16/44: loss=-0.0982 
[epoch 20] step 18/44: loss=-0.0950 
[epoch 20] step 20/44: loss=-0.0938 
[epoch 20] step 22/44: loss=-0.0931 
[epoch 20] step 24/44: loss=-0.0932 
[epoch 20] step 26/44: loss=-0.0950 
[epoch 20] step 28/44: loss=-0.0953 
[epoch 20] step 30/44: loss=-0.0966 
[epoch 20] step 32/44: loss=-0.0970 
[epoch 20] step 34/44: loss=-0.0958 
[epoch 20] step 36/44: loss=-0.0966 
[epoch 20] step 38/44: loss=-0.0968 
[epoch 20] step 40/44: loss=-0.0966 
[epoch 20] step 42/44: loss=-0.0964 
[epoch 20] step 44/44: loss=-0.0971 
[epoch 20] train_loss(avg per step)=-0.1942 lambda[min,max]=[0.501566,1.000000]
[epoch 20] val_loss=0.9382 qwk=('0.6003', '0.5809', '0.5649') averageQWK=0.5820 macroEMD=0.1955 tailR0=('0.0435', '0.0417', '0.0000') tailR0avg=0.0284
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   15   35    4    0
     0   16   68   40    1
     0    0   20   96    0
     0    0    2   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   18   28    7    0
     0   17   67   37    0
     0    1   27  103    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   36   30    3    0
     0   17  112   22    0
     0    2   41   58    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=-0.1037 
[epoch 21] step 4/44: loss=-0.1180 
[epoch 21] step 6/44: loss=-0.1187 
[epoch 21] step 8/44: loss=-0.1169 
[epoch 21] step 10/44: loss=-0.1201 
[epoch 21] step 12/44: loss=-0.1219 
[epoch 21] step 14/44: loss=-0.1225 
[epoch 21] step 16/44: loss=-0.1220 
[epoch 21] step 18/44: loss=-0.1200 
[epoch 21] step 20/44: loss=-0.1207 
[epoch 21] step 22/44: loss=-0.1209 
[epoch 21] step 24/44: loss=-0.1182 
[epoch 21] step 26/44: loss=-0.1177 
[epoch 21] step 28/44: loss=-0.1168 
[epoch 21] step 30/44: loss=-0.1165 
[epoch 21] step 32/44: loss=-0.1165 
[epoch 21] step 34/44: loss=-0.1155 
[epoch 21] step 36/44: loss=-0.1155 
[epoch 21] step 38/44: loss=-0.1151 
[epoch 21] step 40/44: loss=-0.1152 
[epoch 21] step 42/44: loss=-0.1147 
[epoch 21] step 44/44: loss=-0.1161 
[epoch 21] train_loss(avg per step)=-0.2321 lambda[min,max]=[0.501588,1.000000]
[epoch 21] val_loss=0.9632 qwk=('0.5934', '0.5542', '0.5887') averageQWK=0.5788 macroEMD=0.2009 tailR0=('0.0870', '0.0417', '0.0000') tailR0avg=0.0429
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   15   37    2    0
     0   13   78   33    1
     0    0   28   87    1
     0    0    4   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   17   26   10    0
     0   10   69   42    0
     0    1   22  110    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   35   33    1    0
     0   15  119   17    0
     0    1   44   56    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=-0.1397 
[epoch 22] step 4/44: loss=-0.1448 
[epoch 22] step 6/44: loss=-0.1394 
[epoch 22] step 8/44: loss=-0.1358 
[epoch 22] step 10/44: loss=-0.1347 
[epoch 22] step 12/44: loss=-0.1293 
[epoch 22] step 14/44: loss=-0.1274 
[epoch 22] step 16/44: loss=-0.1265 
[epoch 22] step 18/44: loss=-0.1285 
[epoch 22] step 20/44: loss=-0.1301 
[epoch 22] step 22/44: loss=-0.1295 
[epoch 22] step 24/44: loss=-0.1266 
[epoch 22] step 26/44: loss=-0.1282 
[epoch 22] step 28/44: loss=-0.1277 
[epoch 22] step 30/44: loss=-0.1282 
[epoch 22] step 32/44: loss=-0.1277 
[epoch 22] step 34/44: loss=-0.1276 
[epoch 22] step 36/44: loss=-0.1269 
[epoch 22] step 38/44: loss=-0.1278 
[epoch 22] step 40/44: loss=-0.1278 
[epoch 22] step 42/44: loss=-0.1282 
[epoch 22] step 44/44: loss=-0.1285 
[epoch 22] train_loss(avg per step)=-0.2570 lambda[min,max]=[0.501305,1.000000]
[epoch 22] val_loss=0.9754 qwk=('0.6019', '0.5999', '0.5886') averageQWK=0.5968 macroEMD=0.1960 tailR0=('0.0870', '0.0417', '0.0000') tailR0avg=0.0429
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   16   36    2    0
     0   14   79   32    0
     0    0   29   86    1
     0    0    4   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   18   28    7    0
     0   16   66   39    0
     0    0   25  107    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   36   33    0    0
     0   17  119   15    0
     0    2   47   52    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=-0.1495 
[epoch 23] step 4/44: loss=-0.1489 
[epoch 23] step 6/44: loss=-0.1447 
[epoch 23] step 8/44: loss=-0.1436 
[epoch 23] step 10/44: loss=-0.1406 
[epoch 23] step 12/44: loss=-0.1402 
[epoch 23] step 14/44: loss=-0.1406 
[epoch 23] step 16/44: loss=-0.1397 
[epoch 23] step 18/44: loss=-0.1393 
[epoch 23] step 20/44: loss=-0.1400 
[epoch 23] step 22/44: loss=-0.1381 
[epoch 23] step 24/44: loss=-0.1366 
[epoch 23] step 26/44: loss=-0.1376 
[epoch 23] step 28/44: loss=-0.1380 
[epoch 23] step 30/44: loss=-0.1392 
[epoch 23] step 32/44: loss=-0.1392 
[epoch 23] step 34/44: loss=-0.1391 
[epoch 23] step 36/44: loss=-0.1389 
[epoch 23] step 38/44: loss=-0.1397 
[epoch 23] step 40/44: loss=-0.1405 
[epoch 23] step 42/44: loss=-0.1398 
[epoch 23] step 44/44: loss=-0.1402 
[epoch 23] train_loss(avg per step)=-0.2804 lambda[min,max]=[0.501082,1.000000]
[epoch 23] val_loss=0.9959 qwk=('0.6139', '0.5937', '0.6238') averageQWK=0.6105 macroEMD=0.1858 tailR0=('0.1587', '0.1389', '0.0000') tailR0avg=0.0992
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    4    0    0
     1   17   34    2    0
     0   15   70   40    0
     0    0   28   87    1
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     1   18   26    8    0
     0   20   65   36    0
     0    2   25  103    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   43   26    0    0
     0   31  100   20    0
     0    2   40   59    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=-0.1498 
[epoch 24] step 4/44: loss=-0.1479 
[epoch 24] step 6/44: loss=-0.1431 
[epoch 24] step 8/44: loss=-0.1448 
[epoch 24] step 10/44: loss=-0.1441 
[epoch 24] step 12/44: loss=-0.1463 
[epoch 24] step 14/44: loss=-0.1469 
[epoch 24] step 16/44: loss=-0.1468 
[epoch 24] step 18/44: loss=-0.1476 
[epoch 24] step 20/44: loss=-0.1456 
[epoch 24] step 22/44: loss=-0.1459 
[epoch 24] step 24/44: loss=-0.1458 
[epoch 24] step 26/44: loss=-0.1461 
[epoch 24] step 28/44: loss=-0.1462 
[epoch 24] step 30/44: loss=-0.1469 
[epoch 24] step 32/44: loss=-0.1456 
[epoch 24] step 34/44: loss=-0.1459 
[epoch 24] step 36/44: loss=-0.1467 
[epoch 24] step 38/44: loss=-0.1452 
[epoch 24] step 40/44: loss=-0.1453 
[epoch 24] step 42/44: loss=-0.1453 
[epoch 24] step 44/44: loss=-0.1443 
[epoch 24] train_loss(avg per step)=-0.2886 lambda[min,max]=[0.501268,1.000000]
[epoch 24] val_loss=1.0255 qwk=('0.5606', '0.5513', '0.5647') averageQWK=0.5589 macroEMD=0.2067 tailR0=('0.0652', '0.0417', '0.0000') tailR0avg=0.0356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0    9   43    2    0
     0    8   85   31    1
     0    0   32   84    0
     0    0    3   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   12   32    9    0
     0   10   70   41    0
     0    0   26  105    2
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   28   39    2    0
     0   10  120   21    0
     0    1   40   60    0
     0    0    0    2    0
[epoch 25] step 2/44: loss=-0.1138 
[epoch 25] step 4/44: loss=-0.1367 
[epoch 25] step 6/44: loss=-0.1364 
[epoch 25] step 8/44: loss=-0.1418 
[epoch 25] step 10/44: loss=-0.1450 
[epoch 25] step 12/44: loss=-0.1471 
[epoch 25] step 14/44: loss=-0.1485 
[epoch 25] step 16/44: loss=-0.1500 
[epoch 25] step 18/44: loss=-0.1498 
[epoch 25] step 20/44: loss=-0.1485 
[epoch 25] step 22/44: loss=-0.1485 
[epoch 25] step 24/44: loss=-0.1478 
[epoch 25] step 26/44: loss=-0.1481 
[epoch 25] step 28/44: loss=-0.1470 
[epoch 25] step 30/44: loss=-0.1472 
[epoch 25] step 32/44: loss=-0.1472 
[epoch 25] step 34/44: loss=-0.1473 
[epoch 25] step 36/44: loss=-0.1483 
[epoch 25] step 38/44: loss=-0.1492 
[epoch 25] step 40/44: loss=-0.1493 
[epoch 25] step 42/44: loss=-0.1505 
[epoch 25] step 44/44: loss=-0.1501 
[epoch 25] train_loss(avg per step)=-0.3003 lambda[min,max]=[0.501202,1.000000]
[epoch 25] val_loss=1.0458 qwk=('0.6193', '0.5844', '0.6181') averageQWK=0.6073 macroEMD=0.1914 tailR0=('0.0435', '0.0417', '0.0000') tailR0avg=0.0284
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   24   25    5    0
     0   24   56   45    0
     0    0   16  100    0
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   18   26    9    0
     0   15   64   42    0
     0    1   21  110    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   39   30    0    0
     0   22  115   14    0
     0    1   47   53    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=-0.1697 
[epoch 26] step 4/44: loss=-0.1649 
[epoch 26] step 6/44: loss=-0.1648 
[epoch 26] step 8/44: loss=-0.1593 
[epoch 26] step 10/44: loss=-0.1580 
[epoch 26] step 12/44: loss=-0.1596 
[epoch 26] step 14/44: loss=-0.1615 
[epoch 26] step 16/44: loss=-0.1622 
[epoch 26] step 18/44: loss=-0.1615 
[epoch 26] step 20/44: loss=-0.1615 
[epoch 26] step 22/44: loss=-0.1615 
[epoch 26] step 24/44: loss=-0.1601 
[epoch 26] step 26/44: loss=-0.1587 
[epoch 26] step 28/44: loss=-0.1588 
[epoch 26] step 30/44: loss=-0.1579 
[epoch 26] step 32/44: loss=-0.1580 
[epoch 26] step 34/44: loss=-0.1574 
[epoch 26] step 36/44: loss=-0.1571 
[epoch 26] step 38/44: loss=-0.1576 
[epoch 26] step 40/44: loss=-0.1565 
[epoch 26] step 42/44: loss=-0.1564 
[epoch 26] step 44/44: loss=-0.1572 
[epoch 26] train_loss(avg per step)=-0.3145 lambda[min,max]=[0.501021,1.000000]
[epoch 26] val_loss=1.0303 qwk=('0.5833', '0.5942', '0.5971') averageQWK=0.5916 macroEMD=0.1924 tailR0=('0.0652', '0.0972', '0.0000') tailR0avg=0.0541
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   16   36    2    0
     0   13   81   31    0
     0    0   35   81    0
     0    0    4   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     1   17   28    7    0
     0   14   68   39    0
     0    0   30  101    2
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   40   28    1    0
     0   23  103   25    0
     0    2   40   59    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=-0.1737 
[epoch 27] step 4/44: loss=-0.1673 
[epoch 27] step 6/44: loss=-0.1609 
[epoch 27] step 8/44: loss=-0.1642 
[epoch 27] step 10/44: loss=-0.1655 
[epoch 27] step 12/44: loss=-0.1634 
[epoch 27] step 14/44: loss=-0.1642 
[epoch 27] step 16/44: loss=-0.1647 
[epoch 27] step 18/44: loss=-0.1659 
[epoch 27] step 20/44: loss=-0.1669 
[epoch 27] step 22/44: loss=-0.1671 
[epoch 27] step 24/44: loss=-0.1670 
[epoch 27] step 26/44: loss=-0.1670 
[epoch 27] step 28/44: loss=-0.1666 
[epoch 27] step 30/44: loss=-0.1661 
[epoch 27] step 32/44: loss=-0.1655 
[epoch 27] step 34/44: loss=-0.1643 
[epoch 27] step 36/44: loss=-0.1640 
[epoch 27] step 38/44: loss=-0.1641 
[epoch 27] step 40/44: loss=-0.1638 
[epoch 27] step 42/44: loss=-0.1643 
[epoch 27] step 44/44: loss=-0.1648 
[epoch 27] train_loss(avg per step)=-0.3297 lambda[min,max]=[0.501177,1.000000]
[epoch 27] val_loss=1.0355 qwk=('0.5809', '0.5838', '0.6154') averageQWK=0.5934 macroEMD=0.1924 tailR0=('0.0217', '0.0417', '0.0000') tailR0avg=0.0211
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   15   37    2    0
     0   12   76   37    0
     0    0   30   86    0
     0    0    3   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   19   30    4    0
     0   15   72   34    0
     0    1   37   92    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   39   30    0    0
     0   20  110   21    0
     0    2   42   57    0
     0    0    0    2    0
[epoch 28] step 2/44: loss=-0.1713 
[epoch 28] step 4/44: loss=-0.1736 
[epoch 28] step 6/44: loss=-0.1679 
[epoch 28] step 8/44: loss=-0.1659 
[epoch 28] step 10/44: loss=-0.1674 
[epoch 28] step 12/44: loss=-0.1672 
[epoch 28] step 14/44: loss=-0.1671 
[epoch 28] step 16/44: loss=-0.1673 
[epoch 28] step 18/44: loss=-0.1668 
[epoch 28] step 20/44: loss=-0.1673 
[epoch 28] step 22/44: loss=-0.1675 
[epoch 28] step 24/44: loss=-0.1674 
[epoch 28] step 26/44: loss=-0.1665 
[epoch 28] step 28/44: loss=-0.1670 
[epoch 28] step 30/44: loss=-0.1669 
[epoch 28] step 32/44: loss=-0.1674 
[epoch 28] step 34/44: loss=-0.1670 
[epoch 28] step 36/44: loss=-0.1668 
[epoch 28] step 38/44: loss=-0.1663 
[epoch 28] step 40/44: loss=-0.1668 
[epoch 28] step 42/44: loss=-0.1672 
[epoch 28] step 44/44: loss=-0.1677 
[epoch 28] train_loss(avg per step)=-0.3354 lambda[min,max]=[0.501129,1.000000]
[epoch 28] val_loss=1.0280 qwk=('0.6064', '0.5808', '0.5973') averageQWK=0.5948 macroEMD=0.1924 tailR0=('0.0652', '0.0972', '0.0000') tailR0avg=0.0541
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   20   32    2    0
     0   18   70   37    0
     0    0   29   87    0
     0    0    3   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     0   18   29    6    0
     0   16   67   38    0
     0    0   27  104    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   39   30    0    0
     0   20  114   17    0
     0    2   46   53    0
     0    0    0    2    0
[epoch 29] step 2/44: loss=-0.1755 
[epoch 29] step 4/44: loss=-0.1797 
[epoch 29] step 6/44: loss=-0.1786 
[epoch 29] step 8/44: loss=-0.1786 
[epoch 29] step 10/44: loss=-0.1747 
[epoch 29] step 12/44: loss=-0.1727 
[epoch 29] step 14/44: loss=-0.1738 
[epoch 29] step 16/44: loss=-0.1737 
[epoch 29] step 18/44: loss=-0.1742 
[epoch 29] step 20/44: loss=-0.1725 
[epoch 29] step 22/44: loss=-0.1725 
[epoch 29] step 24/44: loss=-0.1712 
[epoch 29] step 26/44: loss=-0.1705 
[epoch 29] step 28/44: loss=-0.1701 
[epoch 29] step 30/44: loss=-0.1710 
[epoch 29] step 32/44: loss=-0.1716 
[epoch 29] step 34/44: loss=-0.1718 
[epoch 29] step 36/44: loss=-0.1722 
[epoch 29] step 38/44: loss=-0.1717 
[epoch 29] step 40/44: loss=-0.1723 
[epoch 29] step 42/44: loss=-0.1729 
[epoch 29] step 44/44: loss=-0.1722 
[epoch 29] train_loss(avg per step)=-0.3445 lambda[min,max]=[0.500984,1.000000]
[epoch 29] val_loss=1.0511 qwk=('0.5893', '0.5783', '0.6276') averageQWK=0.5984 macroEMD=0.1957 tailR0=('0.0652', '0.0417', '0.0000') tailR0avg=0.0356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   14   38    2    0
     0   11   75   39    0
     0    0   28   88    0
     0    0    3   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   17   28    8    0
     0   13   59   49    0
     0    0   16  115    2
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   44   25    0    0
     0   24  108   19    0
     0    2   41   58    0
     0    0    0    2    0
[epoch 30] step 2/44: loss=-0.1731 
[epoch 30] step 4/44: loss=-0.1764 
[epoch 30] step 6/44: loss=-0.1759 
[epoch 30] step 8/44: loss=-0.1756 
[epoch 30] step 10/44: loss=-0.1772 
[epoch 30] step 12/44: loss=-0.1776 
[epoch 30] step 14/44: loss=-0.1785 
[epoch 30] step 16/44: loss=-0.1788 
[epoch 30] step 18/44: loss=-0.1780 
[epoch 30] step 20/44: loss=-0.1771 
[epoch 30] step 22/44: loss=-0.1775 
[epoch 30] step 24/44: loss=-0.1765 
[epoch 30] step 26/44: loss=-0.1764 
[epoch 30] step 28/44: loss=-0.1763 
[epoch 30] step 30/44: loss=-0.1764 
[epoch 30] step 32/44: loss=-0.1766 
[epoch 30] step 34/44: loss=-0.1767 
[epoch 30] step 36/44: loss=-0.1766 
[epoch 30] step 38/44: loss=-0.1763 
[epoch 30] step 40/44: loss=-0.1767 
[epoch 30] step 42/44: loss=-0.1757 
[epoch 30] step 44/44: loss=-0.1759 
[epoch 30] train_loss(avg per step)=-0.3518 lambda[min,max]=[0.501079,1.000000]
[epoch 30] val_loss=1.0725 qwk=('0.5952', '0.5603', '0.6023') averageQWK=0.5860 macroEMD=0.1954 tailR0=('0.0435', '0.0417', '0.0000') tailR0avg=0.0284
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   18   33    3    0
     0   16   69   40    0
     0    0   25   91    0
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   18   30    5    0
     0   14   74   33    0
     0    0   38   94    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   41   28    0    0
     0   26  111   14    0
     0    2   46   53    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=-0.1701 
[epoch 31] step 4/44: loss=-0.1742 
[epoch 31] step 6/44: loss=-0.1774 
[epoch 31] step 8/44: loss=-0.1773 
[epoch 31] step 10/44: loss=-0.1777 
[epoch 31] step 12/44: loss=-0.1778 
[epoch 31] step 14/44: loss=-0.1770 
[epoch 31] step 16/44: loss=-0.1777 
[epoch 31] step 18/44: loss=-0.1769 
[epoch 31] step 20/44: loss=-0.1773 
[epoch 31] step 22/44: loss=-0.1771 
[epoch 31] step 24/44: loss=-0.1768 
[epoch 31] step 26/44: loss=-0.1774 
[epoch 31] step 28/44: loss=-0.1777 
[epoch 31] step 30/44: loss=-0.1781 
[epoch 31] step 32/44: loss=-0.1783 
[epoch 31] step 34/44: loss=-0.1784 
[epoch 31] step 36/44: loss=-0.1785 
[epoch 31] step 38/44: loss=-0.1782 
[epoch 31] step 40/44: loss=-0.1786 
[epoch 31] step 42/44: loss=-0.1783 
[epoch 31] step 44/44: loss=-0.1764 
[epoch 31] train_loss(avg per step)=-0.3529 lambda[min,max]=[0.501094,1.000000]
[epoch 31] val_loss=1.0810 qwk=('0.5950', '0.5485', '0.6143') averageQWK=0.5860 macroEMD=0.1917 tailR0=('0.0870', '0.0417', '0.0000') tailR0avg=0.0429
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   20   32    2    0
     0   20   70   35    0
     0    0   33   83    0
     0    0    4   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   19   27    7    0
     0   18   64   39    0
     0    2   28  102    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   45   24    0    0
     0   29  104   18    0
     0    2   44   55    0
     0    0    0    2    0
[epoch 32] step 2/44: loss=-0.1772 
[epoch 32] step 4/44: loss=-0.1795 
[epoch 32] step 6/44: loss=-0.1772 
[epoch 32] step 8/44: loss=-0.1773 
[epoch 32] step 10/44: loss=-0.1793 
[epoch 32] step 12/44: loss=-0.1804 
[epoch 32] step 14/44: loss=-0.1810 
[epoch 32] step 16/44: loss=-0.1815 
[epoch 32] step 18/44: loss=-0.1816 
[epoch 32] step 20/44: loss=-0.1801 
[epoch 32] step 22/44: loss=-0.1790 
[epoch 32] step 24/44: loss=-0.1798 
[epoch 32] step 26/44: loss=-0.1792 
[epoch 32] step 28/44: loss=-0.1794 
[epoch 32] step 30/44: loss=-0.1797 
[epoch 32] step 32/44: loss=-0.1800 
[epoch 32] step 34/44: loss=-0.1805 
[epoch 32] step 36/44: loss=-0.1801 
[epoch 32] step 38/44: loss=-0.1802 
[epoch 32] step 40/44: loss=-0.1795 
[epoch 32] step 42/44: loss=-0.1796 
[epoch 32] step 44/44: loss=-0.1795 
[epoch 32] train_loss(avg per step)=-0.3590 lambda[min,max]=[0.501060,1.000000]
[epoch 32] val_loss=1.0725 qwk=('0.5979', '0.5650', '0.5622') averageQWK=0.5751 macroEMD=0.1990 tailR0=('0.0435', '0.0417', '0.0000') tailR0avg=0.0284
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   18   34    2    0
     0   16   67   42    0
     0    0   25   91    0
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   17   31    5    0
     0   11   74   36    0
     0    0   34   97    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   33   34    2    0
     0   16  112   23    0
     0    1   43   57    0
     0    0    0    2    0
[epoch 33] step 2/44: loss=-0.1845 
[epoch 33] step 4/44: loss=-0.1844 
[epoch 33] step 6/44: loss=-0.1842 
[epoch 33] step 8/44: loss=-0.1845 
[epoch 33] step 10/44: loss=-0.1820 
[epoch 33] step 12/44: loss=-0.1818 
[epoch 33] step 14/44: loss=-0.1820 
[epoch 33] step 16/44: loss=-0.1825 
[epoch 33] step 18/44: loss=-0.1832 
[epoch 33] step 20/44: loss=-0.1822 
[epoch 33] step 22/44: loss=-0.1825 
[epoch 33] step 24/44: loss=-0.1821 
[epoch 33] step 26/44: loss=-0.1824 
[epoch 33] step 28/44: loss=-0.1818 
[epoch 33] step 30/44: loss=-0.1816 
[epoch 33] step 32/44: loss=-0.1820 
[epoch 33] step 34/44: loss=-0.1823 
[epoch 33] step 36/44: loss=-0.1822 
[epoch 33] step 38/44: loss=-0.1818 
[epoch 33] step 40/44: loss=-0.1817 
[epoch 33] step 42/44: loss=-0.1819 
[epoch 33] step 44/44: loss=-0.1820 
[epoch 33] train_loss(avg per step)=-0.3640 lambda[min,max]=[0.501022,1.000000]
[epoch 33] val_loss=1.0806 qwk=('0.5959', '0.5670', '0.6058') averageQWK=0.5895 macroEMD=0.1960 tailR0=('0.0435', '0.0417', '0.0000') tailR0avg=0.0284
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   16   36    2    0
     0   12   72   41    0
     0    0   25   91    0
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   19   27    7    0
     0   15   65   41    0
     0    0   27  105    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   37   32    0    0
     0   19  115   17    0
     0    1   45   55    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=-0.1862 
[epoch 34] step 4/44: loss=-0.1862 
[epoch 34] step 6/44: loss=-0.1858 
[epoch 34] step 8/44: loss=-0.1838 
[epoch 34] step 10/44: loss=-0.1822 
[epoch 34] step 12/44: loss=-0.1831 
[epoch 34] step 14/44: loss=-0.1831 
[epoch 34] step 16/44: loss=-0.1831 
[epoch 34] step 18/44: loss=-0.1833 
[epoch 34] step 20/44: loss=-0.1835 
[epoch 34] step 22/44: loss=-0.1837 
[epoch 34] step 24/44: loss=-0.1835 
[epoch 34] step 26/44: loss=-0.1833 
[epoch 34] step 28/44: loss=-0.1826 
[epoch 34] step 30/44: loss=-0.1829 
[epoch 34] step 32/44: loss=-0.1827 
[epoch 34] step 34/44: loss=-0.1831 
[epoch 34] step 36/44: loss=-0.1834 
[epoch 34] step 38/44: loss=-0.1836 
[epoch 34] step 40/44: loss=-0.1838 
[epoch 34] step 42/44: loss=-0.1836 
[epoch 34] step 44/44: loss=-0.1835 
[epoch 34] train_loss(avg per step)=-0.3670 lambda[min,max]=[0.501086,1.000000]
[epoch 34] val_loss=1.0795 qwk=('0.5868', '0.5814', '0.6050') averageQWK=0.5911 macroEMD=0.1965 tailR0=('0.0435', '0.0417', '0.0000') tailR0avg=0.0284
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   17   35    2    0
     0   13   72   40    0
     0    0   30   86    0
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   19   28    6    0
     0   14   71   36    0
     0    0   28  104    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   36   33    0    0
     0   18  117   16    0
     0    1   45   55    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=-0.1891 
[epoch 35] step 4/44: loss=-0.1841 
[epoch 35] step 6/44: loss=-0.1830 
[epoch 35] step 8/44: loss=-0.1843 
[epoch 35] step 10/44: loss=-0.1851 
[epoch 35] step 12/44: loss=-0.1851 
[epoch 35] step 14/44: loss=-0.1847 
[epoch 35] step 16/44: loss=-0.1850 
[epoch 35] step 18/44: loss=-0.1839 
[epoch 35] step 20/44: loss=-0.1844 
[epoch 35] step 22/44: loss=-0.1844 
[epoch 35] step 24/44: loss=-0.1846 
[epoch 35] step 26/44: loss=-0.1848 
[epoch 35] step 28/44: loss=-0.1846 
[epoch 35] step 30/44: loss=-0.1849 
[epoch 35] step 32/44: loss=-0.1849 
[epoch 35] step 34/44: loss=-0.1848 
[epoch 35] step 36/44: loss=-0.1847 
[epoch 35] step 38/44: loss=-0.1848 
[epoch 35] step 40/44: loss=-0.1842 
[epoch 35] step 42/44: loss=-0.1840 
[epoch 35] step 44/44: loss=-0.1842 
[epoch 35] train_loss(avg per step)=-0.3684 lambda[min,max]=[0.501033,1.000000]
[epoch 35] val_loss=1.0804 qwk=('0.5978', '0.5814', '0.6128') averageQWK=0.5973 macroEMD=0.1969 tailR0=('0.0435', '0.0417', '0.0000') tailR0avg=0.0284
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   17   35    2    0
     0   14   70   41    0
     0    0   25   91    0
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   19   28    6    0
     0   14   71   36    0
     0    0   28  104    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   36   33    0    0
     0   17  117   17    0
     0    1   43   57    0
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-0-conf_gating-0-reassignment-0/fold2/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-0-conf_gating-0-reassignment-0/fold2/metrics.json
Done.
