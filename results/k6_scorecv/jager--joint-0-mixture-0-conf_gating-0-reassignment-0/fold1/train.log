[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.8987 
[epoch 1] step 4/44: loss=0.8895 
[epoch 1] step 6/44: loss=0.8906 
[epoch 1] step 8/44: loss=0.8893 
[epoch 1] step 10/44: loss=0.8892 
[epoch 1] step 12/44: loss=0.8839 
[epoch 1] step 14/44: loss=0.8845 
[epoch 1] step 16/44: loss=0.8837 
[epoch 1] step 18/44: loss=0.8860 
[epoch 1] step 20/44: loss=0.8845 
[epoch 1] step 22/44: loss=0.8844 
[epoch 1] step 24/44: loss=0.8847 
[epoch 1] step 26/44: loss=0.8825 
[epoch 1] step 28/44: loss=0.8823 
[epoch 1] step 30/44: loss=0.8803 
[epoch 1] step 32/44: loss=0.8794 
[epoch 1] step 34/44: loss=0.8783 
[epoch 1] step 36/44: loss=0.8765 
[epoch 1] step 38/44: loss=0.8735 
[epoch 1] step 40/44: loss=0.8690 
[epoch 1] step 42/44: loss=0.8644 
[epoch 1] step 44/44: loss=0.8601 
[epoch 1] train_loss(avg per step)=1.7202 lambda[min,max]=[0.893714,1.000000]
[epoch 1] val_loss=1.4451 qwk=('0.1878', '0.1869', '0.0005') averageQWK=0.1251 macroEMD=0.3637 tailR0=('0.0000', '0.1667', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    4    0
     0   15    0   39    0
     0   42    0   84    0
     0   23    0   93    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    4    2    0
    15    0   23   14    0
    35    0   47   40    0
    22    0   44   67    0
     0    0    5    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   20   48    0    0
     0   33  119    0    0
     0   31   70    0    0
     0    0    2    0    0
[epoch 2] step 2/44: loss=0.7386 
[epoch 2] step 4/44: loss=0.7385 
[epoch 2] step 6/44: loss=0.7413 
[epoch 2] step 8/44: loss=0.7197 
[epoch 2] step 10/44: loss=0.7099 
[epoch 2] step 12/44: loss=0.6980 
[epoch 2] step 14/44: loss=0.6890 
[epoch 2] step 16/44: loss=0.6815 
[epoch 2] step 18/44: loss=0.6738 
[epoch 2] step 20/44: loss=0.6693 
[epoch 2] step 22/44: loss=0.6633 
[epoch 2] step 24/44: loss=0.6573 
[epoch 2] step 26/44: loss=0.6503 
[epoch 2] step 28/44: loss=0.6455 
[epoch 2] step 30/44: loss=0.6437 
[epoch 2] step 32/44: loss=0.6413 
[epoch 2] step 34/44: loss=0.6385 
[epoch 2] step 36/44: loss=0.6366 
[epoch 2] step 38/44: loss=0.6356 
[epoch 2] step 40/44: loss=0.6336 
[epoch 2] step 42/44: loss=0.6306 
[epoch 2] step 44/44: loss=0.6273 
[epoch 2] train_loss(avg per step)=1.2545 lambda[min,max]=[0.819257,1.000000]
[epoch 2] val_loss=1.1199 qwk=('0.3603', '0.2025', '0.3605') averageQWK=0.3078 macroEMD=0.3158 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    3    0
     0    0   45    9    0
     0    0   73   53    0
     0    0   22   94    0
     0    0    4   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    5    0
     0    0   22   30    0
     0    0   26   96    0
     0    0    5  128    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    0   51   17    0
     0    0   73   79    0
     0    0    8   93    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=0.5318 
[epoch 3] step 4/44: loss=0.5307 
[epoch 3] step 6/44: loss=0.5538 
[epoch 3] step 8/44: loss=0.5460 
[epoch 3] step 10/44: loss=0.5547 
[epoch 3] step 12/44: loss=0.5511 
[epoch 3] step 14/44: loss=0.5458 
[epoch 3] step 16/44: loss=0.5370 
[epoch 3] step 18/44: loss=0.5381 
[epoch 3] step 20/44: loss=0.5365 
[epoch 3] step 22/44: loss=0.5347 
[epoch 3] step 24/44: loss=0.5306 
[epoch 3] step 26/44: loss=0.5263 
[epoch 3] step 28/44: loss=0.5260 
[epoch 3] step 30/44: loss=0.5245 
[epoch 3] step 32/44: loss=0.5177 
[epoch 3] step 34/44: loss=0.5146 
[epoch 3] step 36/44: loss=0.5097 
[epoch 3] step 38/44: loss=0.5108 
[epoch 3] step 40/44: loss=0.5098 
[epoch 3] step 42/44: loss=0.5074 
[epoch 3] step 44/44: loss=0.5081 
[epoch 3] train_loss(avg per step)=1.0162 lambda[min,max]=[0.726718,1.000000]
[epoch 3] val_loss=0.9152 qwk=('0.5601', '0.4675', '0.5684') averageQWK=0.5320 macroEMD=0.2554 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    2    0
     0   11   40    3    0
     0    1   93   32    0
     0    0   23   93    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    0   51    1    0
     0    0   84   38    0
     0    0   31  102    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   37   20   11    0
     0   38   55   59    0
     0    1    9   91    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=0.4255 
[epoch 4] step 4/44: loss=0.4095 
[epoch 4] step 6/44: loss=0.4215 
[epoch 4] step 8/44: loss=0.4244 
[epoch 4] step 10/44: loss=0.4310 
[epoch 4] step 12/44: loss=0.4264 
[epoch 4] step 14/44: loss=0.4271 
[epoch 4] step 16/44: loss=0.4229 
[epoch 4] step 18/44: loss=0.4215 
[epoch 4] step 20/44: loss=0.4194 
[epoch 4] step 22/44: loss=0.4169 
[epoch 4] step 24/44: loss=0.4189 
[epoch 4] step 26/44: loss=0.4210 
[epoch 4] step 28/44: loss=0.4193 
[epoch 4] step 30/44: loss=0.4163 
[epoch 4] step 32/44: loss=0.4173 
[epoch 4] step 34/44: loss=0.4166 
[epoch 4] step 36/44: loss=0.4178 
[epoch 4] step 38/44: loss=0.4187 
[epoch 4] step 40/44: loss=0.4206 
[epoch 4] step 42/44: loss=0.4232 
[epoch 4] step 44/44: loss=0.4224 
[epoch 4] train_loss(avg per step)=0.8449 lambda[min,max]=[0.619240,1.000000]
[epoch 4] val_loss=0.9629 qwk=('0.4009', '0.3593', '0.4856') averageQWK=0.4153 macroEMD=0.2628 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    3    0
     0    7   32   15    0
     0    1   44   81    0
     0    0    8  108    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    3    0
     0    5   29   18    0
     0    2   37   83    0
     0    0    7  126    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   11   45   12    0
     0    4   74   74    0
     0    0    4   97    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=0.3589 
[epoch 5] step 4/44: loss=0.3763 
[epoch 5] step 6/44: loss=0.3695 
[epoch 5] step 8/44: loss=0.3915 
[epoch 5] step 10/44: loss=0.3916 
[epoch 5] step 12/44: loss=0.3921 
[epoch 5] step 14/44: loss=0.3887 
[epoch 5] step 16/44: loss=0.3867 
[epoch 5] step 18/44: loss=0.3835 
[epoch 5] step 20/44: loss=0.3786 
[epoch 5] step 22/44: loss=0.3759 
[epoch 5] step 24/44: loss=0.3781 
[epoch 5] step 26/44: loss=0.3796 
[epoch 5] step 28/44: loss=0.3816 
[epoch 5] step 30/44: loss=0.3785 
[epoch 5] step 32/44: loss=0.3760 
[epoch 5] step 34/44: loss=0.3777 
[epoch 5] step 36/44: loss=0.3780 
[epoch 5] step 38/44: loss=0.3791 
[epoch 5] step 40/44: loss=0.3798 
[epoch 5] step 42/44: loss=0.3801 
[epoch 5] step 44/44: loss=0.3795 
[epoch 5] train_loss(avg per step)=0.7589 lambda[min,max]=[0.571068,1.000000]
[epoch 5] val_loss=0.8352 qwk=('0.6265', '0.5614', '0.6020') averageQWK=0.5967 macroEMD=0.2367 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   26   25    3    0
     0   13   86   27    0
     0    0   31   85    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    2    0
     0   11   40    1    0
     0    5   92   25    0
     0    0   39   94    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   43    0    0
     0   13  128   11    0
     0    0   39   62    0
     0    0    1    1    0
[epoch 6] step 2/44: loss=0.3406 
[epoch 6] step 4/44: loss=0.3405 
[epoch 6] step 6/44: loss=0.3395 
[epoch 6] step 8/44: loss=0.3485 
[epoch 6] step 10/44: loss=0.3481 
[epoch 6] step 12/44: loss=0.3537 
[epoch 6] step 14/44: loss=0.3517 
[epoch 6] step 16/44: loss=0.3528 
[epoch 6] step 18/44: loss=0.3496 
[epoch 6] step 20/44: loss=0.3461 
[epoch 6] step 22/44: loss=0.3435 
[epoch 6] step 24/44: loss=0.3410 
[epoch 6] step 26/44: loss=0.3442 
[epoch 6] step 28/44: loss=0.3407 
[epoch 6] step 30/44: loss=0.3401 
[epoch 6] step 32/44: loss=0.3395 
[epoch 6] step 34/44: loss=0.3399 
[epoch 6] step 36/44: loss=0.3388 
[epoch 6] step 38/44: loss=0.3378 
[epoch 6] step 40/44: loss=0.3381 
[epoch 6] step 42/44: loss=0.3393 
[epoch 6] step 44/44: loss=0.3389 
[epoch 6] train_loss(avg per step)=0.6777 lambda[min,max]=[0.557186,1.000000]
[epoch 6] val_loss=0.8179 qwk=('0.5949', '0.4742', '0.5801') averageQWK=0.5497 macroEMD=0.2316 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   14   36    4    0
     0    2   85   39    0
     0    0   19   93    4
     0    0    0   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0    8   33   11    0
     0    4   61   57    0
     0    0   18  115    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   13   49    6    0
     0    5  110   37    0
     0    0   12   89    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=0.2505 
[epoch 7] step 4/44: loss=0.3000 
[epoch 7] step 6/44: loss=0.3044 
[epoch 7] step 8/44: loss=0.3079 
[epoch 7] step 10/44: loss=0.3198 
[epoch 7] step 12/44: loss=0.3164 
[epoch 7] step 14/44: loss=0.3197 
[epoch 7] step 16/44: loss=0.3092 
[epoch 7] step 18/44: loss=0.3033 
[epoch 7] step 20/44: loss=0.3032 
[epoch 7] step 22/44: loss=0.3013 
[epoch 7] step 24/44: loss=0.2971 
[epoch 7] step 26/44: loss=0.2936 
[epoch 7] step 28/44: loss=0.2914 
[epoch 7] step 30/44: loss=0.2927 
[epoch 7] step 32/44: loss=0.2891 
[epoch 7] step 34/44: loss=0.2902 
[epoch 7] step 36/44: loss=0.2913 
[epoch 7] step 38/44: loss=0.2909 
[epoch 7] step 40/44: loss=0.2915 
[epoch 7] step 42/44: loss=0.2912 
[epoch 7] step 44/44: loss=0.2915 
[epoch 7] train_loss(avg per step)=0.5830 lambda[min,max]=[0.541869,1.000000]
[epoch 7] val_loss=0.7688 qwk=('0.6364', '0.5807', '0.6588') averageQWK=0.6253 macroEMD=0.2137 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   21   31    2    0
     0    6   88   32    0
     0    0   26   85    5
     0    0    0   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   15   35    2    0
     0    7   74   41    0
     0    0   28  105    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   36   31    1    0
     0   20  108   24    0
     0    0   30   71    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=0.2278 
[epoch 8] step 4/44: loss=0.2307 
[epoch 8] step 6/44: loss=0.2209 
[epoch 8] step 8/44: loss=0.2335 
[epoch 8] step 10/44: loss=0.2360 
[epoch 8] step 12/44: loss=0.2396 
[epoch 8] step 14/44: loss=0.2482 
[epoch 8] step 16/44: loss=0.2476 
[epoch 8] step 18/44: loss=0.2425 
[epoch 8] step 20/44: loss=0.2452 
[epoch 8] step 22/44: loss=0.2528 
[epoch 8] step 24/44: loss=0.2485 
[epoch 8] step 26/44: loss=0.2480 
[epoch 8] step 28/44: loss=0.2492 
[epoch 8] step 30/44: loss=0.2515 
[epoch 8] step 32/44: loss=0.2504 
[epoch 8] step 34/44: loss=0.2503 
[epoch 8] step 36/44: loss=0.2507 
[epoch 8] step 38/44: loss=0.2519 
[epoch 8] step 40/44: loss=0.2509 
[epoch 8] step 42/44: loss=0.2508 
[epoch 8] step 44/44: loss=0.2481 
[epoch 8] train_loss(avg per step)=0.4963 lambda[min,max]=[0.532487,1.000000]
[epoch 8] val_loss=0.7751 qwk=('0.6728', '0.5551', '0.6486') averageQWK=0.6255 macroEMD=0.2047 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   29   23    2    0
     0   16   77   32    1
     0    0   24   79   13
     0    0    0   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0   15   31    6    0
     0   13   61   48    0
     0    2   18  113    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   34   29    5    0
     0   23   95   34    0
     0    1   15   85    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=0.2046 
[epoch 9] step 4/44: loss=0.2112 
[epoch 9] step 6/44: loss=0.2122 
[epoch 9] step 8/44: loss=0.2129 
[epoch 9] step 10/44: loss=0.2211 
[epoch 9] step 12/44: loss=0.2106 
[epoch 9] step 14/44: loss=0.2111 
[epoch 9] step 16/44: loss=0.2066 
[epoch 9] step 18/44: loss=0.2044 
[epoch 9] step 20/44: loss=0.2062 
[epoch 9] step 22/44: loss=0.2056 
[epoch 9] step 24/44: loss=0.2035 
[epoch 9] step 26/44: loss=0.2006 
[epoch 9] step 28/44: loss=0.2000 
[epoch 9] step 30/44: loss=0.1968 
[epoch 9] step 32/44: loss=0.1974 
[epoch 9] step 34/44: loss=0.1963 
[epoch 9] step 36/44: loss=0.1952 
[epoch 9] step 38/44: loss=0.1980 
[epoch 9] step 40/44: loss=0.1988 
[epoch 9] step 42/44: loss=0.1991 
[epoch 9] step 44/44: loss=0.1987 
[epoch 9] train_loss(avg per step)=0.3973 lambda[min,max]=[0.517277,1.000000]
[epoch 9] val_loss=0.7886 qwk=('0.6406', '0.5397', '0.6735') averageQWK=0.6179 macroEMD=0.2105 tailR0=('0.3696', '0.0000', '0.0000') tailR0avg=0.1232
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   15   34    4    1
     0    3   83   37    3
     0    0   20   78   18
     0    0    0    6   17
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   12   34    6    0
     0    8   66   48    0
     0    0   19  114    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   30   37    1    0
     0   13  110   29    0
     0    0   20   81    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=0.1966 
[epoch 10] step 4/44: loss=0.1816 
[epoch 10] step 6/44: loss=0.1791 
[epoch 10] step 8/44: loss=0.1804 
[epoch 10] step 10/44: loss=0.1740 
[epoch 10] step 12/44: loss=0.1687 
[epoch 10] step 14/44: loss=0.1697 
[epoch 10] step 16/44: loss=0.1678 
[epoch 10] step 18/44: loss=0.1633 
[epoch 10] step 20/44: loss=0.1641 
[epoch 10] step 22/44: loss=0.1656 
[epoch 10] step 24/44: loss=0.1657 
[epoch 10] step 26/44: loss=0.1640 
[epoch 10] step 28/44: loss=0.1633 
[epoch 10] step 30/44: loss=0.1626 
[epoch 10] step 32/44: loss=0.1622 
[epoch 10] step 34/44: loss=0.1594 
[epoch 10] step 36/44: loss=0.1582 
[epoch 10] step 38/44: loss=0.1596 
[epoch 10] step 40/44: loss=0.1616 
[epoch 10] step 42/44: loss=0.1604 
[epoch 10] step 44/44: loss=0.1644 
[epoch 10] train_loss(avg per step)=0.3289 lambda[min,max]=[0.511442,1.000000]
[epoch 10] val_loss=0.8207 qwk=('0.5429', '0.5051', '0.6467') averageQWK=0.5649 macroEMD=0.2130 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   16   30    8    0
     0    3   58   64    1
     0    0   11  103    2
     0    0    0   20    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0    9   34    9    0
     0    7   65   50    0
     0    1   19  113    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   30   35    3    0
     0   16  104   32    0
     0    0   20   81    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.1573 
[epoch 11] step 4/44: loss=0.1442 
[epoch 11] step 6/44: loss=0.1505 
[epoch 11] step 8/44: loss=0.1542 
[epoch 11] step 10/44: loss=0.1491 
[epoch 11] step 12/44: loss=0.1453 
[epoch 11] step 14/44: loss=0.1452 
[epoch 11] step 16/44: loss=0.1412 
[epoch 11] step 18/44: loss=0.1327 
[epoch 11] step 20/44: loss=0.1337 
[epoch 11] step 22/44: loss=0.1365 
[epoch 11] step 24/44: loss=0.1375 
[epoch 11] step 26/44: loss=0.1390 
[epoch 11] step 28/44: loss=0.1368 
[epoch 11] step 30/44: loss=0.1336 
[epoch 11] step 32/44: loss=0.1320 
[epoch 11] step 34/44: loss=0.1316 
[epoch 11] step 36/44: loss=0.1309 
[epoch 11] step 38/44: loss=0.1306 
[epoch 11] step 40/44: loss=0.1308 
[epoch 11] step 42/44: loss=0.1288 
[epoch 11] step 44/44: loss=0.1309 
[epoch 11] train_loss(avg per step)=0.2617 lambda[min,max]=[0.506700,1.000000]
[epoch 11] val_loss=0.8381 qwk=('0.6450', '0.5551', '0.5890') averageQWK=0.5964 macroEMD=0.2021 tailR0=('0.3261', '0.0833', '0.0000') tailR0avg=0.1365
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   23   26    4    1
     0    8   76   39    3
     0    0   18   80   18
     0    0    0    8   15
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   17   28    7    0
     0   13   58   51    0
     0    2   16  115    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   24   37    7    0
     0   13   86   53    0
     0    0    9   92    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=0.1684 
[epoch 12] step 4/44: loss=0.1415 
[epoch 12] step 6/44: loss=0.1337 
[epoch 12] step 8/44: loss=0.1196 
[epoch 12] step 10/44: loss=0.1103 
[epoch 12] step 12/44: loss=0.1059 
[epoch 12] step 14/44: loss=0.1043 
[epoch 12] step 16/44: loss=0.1044 
[epoch 12] step 18/44: loss=0.1004 
[epoch 12] step 20/44: loss=0.1002 
[epoch 12] step 22/44: loss=0.1021 
[epoch 12] step 24/44: loss=0.1002 
[epoch 12] step 26/44: loss=0.1020 
[epoch 12] step 28/44: loss=0.1028 
[epoch 12] step 30/44: loss=0.1016 
[epoch 12] step 32/44: loss=0.1006 
[epoch 12] step 34/44: loss=0.0963 
[epoch 12] step 36/44: loss=0.0962 
[epoch 12] step 38/44: loss=0.0940 
[epoch 12] step 40/44: loss=0.0931 
[epoch 12] step 42/44: loss=0.0917 
[epoch 12] step 44/44: loss=0.0947 
[epoch 12] train_loss(avg per step)=0.1894 lambda[min,max]=[0.506356,1.000000]
[epoch 12] val_loss=0.8017 qwk=('0.6484', '0.5513', '0.6130') averageQWK=0.6043 macroEMD=0.1991 tailR0=('0.3043', '0.0833', '0.0000') tailR0avg=0.1292
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   19   32    3    0
     0    6   85   32    3
     0    0   24   75   17
     0    0    0    9   14
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   13   32    7    0
     0   10   69   42    1
     0    1   20  112    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   32    4    0
     0   31   94   27    0
     0    0   23   78    0
     0    0    1    1    0
[epoch 13] step 2/44: loss=0.0376 
[epoch 13] step 4/44: loss=0.0364 
[epoch 13] step 6/44: loss=0.0363 
[epoch 13] step 8/44: loss=0.0516 
[epoch 13] step 10/44: loss=0.0426 
[epoch 13] step 12/44: loss=0.0446 
[epoch 13] step 14/44: loss=0.0479 
[epoch 13] step 16/44: loss=0.0453 
[epoch 13] step 18/44: loss=0.0493 
[epoch 13] step 20/44: loss=0.0479 
[epoch 13] step 22/44: loss=0.0477 
[epoch 13] step 24/44: loss=0.0488 
[epoch 13] step 26/44: loss=0.0497 
[epoch 13] step 28/44: loss=0.0510 
[epoch 13] step 30/44: loss=0.0548 
[epoch 13] step 32/44: loss=0.0564 
[epoch 13] step 34/44: loss=0.0552 
[epoch 13] step 36/44: loss=0.0555 
[epoch 13] step 38/44: loss=0.0526 
[epoch 13] step 40/44: loss=0.0524 
[epoch 13] step 42/44: loss=0.0515 
[epoch 13] step 44/44: loss=0.0529 
[epoch 13] train_loss(avg per step)=0.1058 lambda[min,max]=[0.503919,1.000000]
[epoch 13] val_loss=0.7816 qwk=('0.6464', '0.6004', '0.5955') averageQWK=0.6141 macroEMD=0.1908 tailR0=('0.2077', '0.1250', '0.0000') tailR0avg=0.1109
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     0   22   29    3    0
     0    8   91   24    3
     0    0   30   80    6
     0    0    0   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0   18   30    4    0
     0   14   71   35    2
     0    1   23  106    3
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   23   39    6    0
     0   13   98   41    0
     0    0   14   87    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.0382 
[epoch 14] step 4/44: loss=0.0495 
[epoch 14] step 6/44: loss=0.0343 
[epoch 14] step 8/44: loss=0.0365 
[epoch 14] step 10/44: loss=0.0385 
[epoch 14] step 12/44: loss=0.0311 
[epoch 14] step 14/44: loss=0.0281 
[epoch 14] step 16/44: loss=0.0264 
[epoch 14] step 18/44: loss=0.0289 
[epoch 14] step 20/44: loss=0.0260 
[epoch 14] step 22/44: loss=0.0224 
[epoch 14] step 24/44: loss=0.0202 
[epoch 14] step 26/44: loss=0.0192 
[epoch 14] step 28/44: loss=0.0188 
[epoch 14] step 30/44: loss=0.0187 
[epoch 14] step 32/44: loss=0.0174 
[epoch 14] step 34/44: loss=0.0160 
[epoch 14] step 36/44: loss=0.0167 
[epoch 14] step 38/44: loss=0.0188 
[epoch 14] step 40/44: loss=0.0215 
[epoch 14] step 42/44: loss=0.0212 
[epoch 14] step 44/44: loss=0.0206 
[epoch 14] train_loss(avg per step)=0.0412 lambda[min,max]=[0.502976,1.000000]
[epoch 14] val_loss=0.8654 qwk=('0.6382', '0.5105', '0.6163') averageQWK=0.5883 macroEMD=0.2076 tailR0=('0.2609', '0.1250', '0.0000') tailR0avg=0.1286
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   18   32    4    0
     0    7   77   39    3
     0    0   20   78   18
     0    0    0   11   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   14   28   10    0
     0    7   58   56    1
     0    3   13  112    5
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   27   36    5    0
     0   18  105   29    0
     0    0   19   82    0
     0    0    1    1    0
[epoch 15] step 2/44: loss=-0.0129 
[epoch 15] step 4/44: loss=0.0006 
[epoch 15] step 6/44: loss=-0.0097 
[epoch 15] step 8/44: loss=-0.0130 
[epoch 15] step 10/44: loss=-0.0097 
[epoch 15] step 12/44: loss=-0.0099 
[epoch 15] step 14/44: loss=-0.0065 
[epoch 15] step 16/44: loss=-0.0101 
[epoch 15] step 18/44: loss=-0.0107 
[epoch 15] step 20/44: loss=-0.0124 
[epoch 15] step 22/44: loss=-0.0115 
[epoch 15] step 24/44: loss=-0.0161 
[epoch 15] step 26/44: loss=-0.0170 
[epoch 15] step 28/44: loss=-0.0138 
[epoch 15] step 30/44: loss=-0.0132 
[epoch 15] step 32/44: loss=-0.0106 
[epoch 15] step 34/44: loss=-0.0124 
[epoch 15] step 36/44: loss=-0.0150 
[epoch 15] step 38/44: loss=-0.0140 
[epoch 15] step 40/44: loss=-0.0147 
[epoch 15] step 42/44: loss=-0.0159 
[epoch 15] step 44/44: loss=-0.0155 
[epoch 15] train_loss(avg per step)=-0.0310 lambda[min,max]=[0.502278,1.000000]
[epoch 15] val_loss=0.8322 qwk=('0.6368', '0.5911', '0.6434') averageQWK=0.6238 macroEMD=0.1931 tailR0=('0.1739', '0.1250', '0.0000') tailR0avg=0.0996
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   21   30    3    0
     0    7   90   26    3
     0    0   30   69   17
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   16   31    5    0
     0   14   74   33    1
     0    2   26   99    6
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   44   24    0    0
     0   40   91   21    0
     0    0   35   66    0
     0    0    1    1    0
[epoch 16] step 2/44: loss=-0.0159 
[epoch 16] step 4/44: loss=-0.0277 
[epoch 16] step 6/44: loss=-0.0274 
[epoch 16] step 8/44: loss=-0.0324 
[epoch 16] step 10/44: loss=-0.0307 
[epoch 16] step 12/44: loss=-0.0333 
[epoch 16] step 14/44: loss=-0.0312 
[epoch 16] step 16/44: loss=-0.0351 
[epoch 16] step 18/44: loss=-0.0399 
[epoch 16] step 20/44: loss=-0.0386 
[epoch 16] step 22/44: loss=-0.0387 
[epoch 16] step 24/44: loss=-0.0388 
[epoch 16] step 26/44: loss=-0.0395 
[epoch 16] step 28/44: loss=-0.0405 
[epoch 16] step 30/44: loss=-0.0397 
[epoch 16] step 32/44: loss=-0.0388 
[epoch 16] step 34/44: loss=-0.0392 
[epoch 16] step 36/44: loss=-0.0412 
[epoch 16] step 38/44: loss=-0.0409 
[epoch 16] step 40/44: loss=-0.0401 
[epoch 16] step 42/44: loss=-0.0394 
[epoch 16] step 44/44: loss=-0.0385 
[epoch 16] train_loss(avg per step)=-0.0769 lambda[min,max]=[0.501844,1.000000]
[epoch 16] val_loss=0.8908 qwk=('0.6527', '0.5833', '0.6134') averageQWK=0.6165 macroEMD=0.1918 tailR0=('0.3816', '0.1250', '0.0000') tailR0avg=0.1689
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     0   20   31    3    0
     0   10   87   25    4
     0    0   32   66   18
     0    0    0    8   15
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   16   32    4    0
     0   13   70   38    1
     0    2   20  106    5
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   29   33    6    0
     0   26   87   39    0
     0    0   14   87    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=-0.0271 
[epoch 17] step 4/44: loss=-0.0360 
[epoch 17] step 6/44: loss=-0.0517 
[epoch 17] step 8/44: loss=-0.0438 
[epoch 17] step 10/44: loss=-0.0511 
[epoch 17] step 12/44: loss=-0.0571 
[epoch 17] step 14/44: loss=-0.0608 
[epoch 17] step 16/44: loss=-0.0626 
[epoch 17] step 18/44: loss=-0.0651 
[epoch 17] step 20/44: loss=-0.0659 
[epoch 17] step 22/44: loss=-0.0681 
[epoch 17] step 24/44: loss=-0.0691 
[epoch 17] step 26/44: loss=-0.0688 
[epoch 17] step 28/44: loss=-0.0682 
[epoch 17] step 30/44: loss=-0.0695 
[epoch 17] step 32/44: loss=-0.0672 
[epoch 17] step 34/44: loss=-0.0676 
[epoch 17] step 36/44: loss=-0.0675 
[epoch 17] step 38/44: loss=-0.0691 
[epoch 17] step 40/44: loss=-0.0691 
[epoch 17] step 42/44: loss=-0.0697 
[epoch 17] step 44/44: loss=-0.0707 
[epoch 17] train_loss(avg per step)=-0.1413 lambda[min,max]=[0.501819,1.000000]
[epoch 17] val_loss=0.8747 qwk=('0.6199', '0.5738', '0.6456') averageQWK=0.6131 macroEMD=0.1976 tailR0=('0.2077', '0.0417', '0.0000') tailR0avg=0.0831
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    1    0
     0   17   34    3    0
     0   11   82   31    2
     0    0   30   79    7
     0    0    0   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   20   26    6    0
     0   16   72   34    0
     0    2   30  101    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   37   31    0    0
     0   30  106   16    0
     0    0   34   67    0
     0    0    1    1    0
[epoch 18] step 2/44: loss=-0.0973 
[epoch 18] step 4/44: loss=-0.0900 
[epoch 18] step 6/44: loss=-0.0919 
[epoch 18] step 8/44: loss=-0.0920 
[epoch 18] step 10/44: loss=-0.0893 
[epoch 18] step 12/44: loss=-0.0926 
[epoch 18] step 14/44: loss=-0.0953 
[epoch 18] step 16/44: loss=-0.0966 
[epoch 18] step 18/44: loss=-0.0955 
[epoch 18] step 20/44: loss=-0.0958 
[epoch 18] step 22/44: loss=-0.0950 
[epoch 18] step 24/44: loss=-0.0937 
[epoch 18] step 26/44: loss=-0.0926 
[epoch 18] step 28/44: loss=-0.0921 
[epoch 18] step 30/44: loss=-0.0936 
[epoch 18] step 32/44: loss=-0.0935 
[epoch 18] step 34/44: loss=-0.0929 
[epoch 18] step 36/44: loss=-0.0933 
[epoch 18] step 38/44: loss=-0.0938 
[epoch 18] step 40/44: loss=-0.0929 
[epoch 18] step 42/44: loss=-0.0915 
[epoch 18] step 44/44: loss=-0.0901 
[epoch 18] train_loss(avg per step)=-0.1803 lambda[min,max]=[0.501523,1.000000]
[epoch 18] val_loss=0.9287 qwk=('0.6084', '0.5877', '0.6156') averageQWK=0.6039 macroEMD=0.2023 tailR0=('0.2174', '0.1250', '0.0000') tailR0avg=0.1141
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    2    0
     0   14   37    3    0
     0    4   90   30    2
     0    0   29   74   13
     0    0    0   13   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   14   35    3    0
     0    9   73   38    2
     0    0   31   95    7
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   27   39    2    0
     0   21  105   26    0
     0    0   23   77    1
     0    0    1    1    0
[epoch 19] step 2/44: loss=-0.1069 
[epoch 19] step 4/44: loss=-0.0976 
[epoch 19] step 6/44: loss=-0.1052 
[epoch 19] step 8/44: loss=-0.1102 
[epoch 19] step 10/44: loss=-0.1083 
[epoch 19] step 12/44: loss=-0.1105 
[epoch 19] step 14/44: loss=-0.1097 
[epoch 19] step 16/44: loss=-0.1116 
[epoch 19] step 18/44: loss=-0.1129 
[epoch 19] step 20/44: loss=-0.1138 
[epoch 19] step 22/44: loss=-0.1134 
[epoch 19] step 24/44: loss=-0.1135 
[epoch 19] step 26/44: loss=-0.1121 
[epoch 19] step 28/44: loss=-0.1104 
[epoch 19] step 30/44: loss=-0.1097 
[epoch 19] step 32/44: loss=-0.1086 
[epoch 19] step 34/44: loss=-0.1083 
[epoch 19] step 36/44: loss=-0.1090 
[epoch 19] step 38/44: loss=-0.1089 
[epoch 19] step 40/44: loss=-0.1086 
[epoch 19] step 42/44: loss=-0.1082 
[epoch 19] step 44/44: loss=-0.1091 
[epoch 19] train_loss(avg per step)=-0.2181 lambda[min,max]=[0.501246,1.000000]
[epoch 19] val_loss=0.9585 qwk=('0.6049', '0.5200', '0.5787') averageQWK=0.5679 macroEMD=0.2084 tailR0=('0.1304', '0.0833', '0.0000') tailR0avg=0.0713
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   13   38    3    0
     0    3   81   40    2
     0    0   20   92    4
     0    0    0   17    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   12   32    8    0
     0    8   62   51    1
     0    1   21  108    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   20   42    6    0
     0    8  112   32    0
     0    0   19   81    1
     0    0    1    1    0
[epoch 20] step 2/44: loss=-0.1274 
[epoch 20] step 4/44: loss=-0.1200 
[epoch 20] step 6/44: loss=-0.1231 
[epoch 20] step 8/44: loss=-0.1213 
[epoch 20] step 10/44: loss=-0.1231 
[epoch 20] step 12/44: loss=-0.1230 
[epoch 20] step 14/44: loss=-0.1220 
[epoch 20] step 16/44: loss=-0.1212 
[epoch 20] step 18/44: loss=-0.1187 
[epoch 20] step 20/44: loss=-0.1164 
[epoch 20] step 22/44: loss=-0.1179 
[epoch 20] step 24/44: loss=-0.1183 
[epoch 20] step 26/44: loss=-0.1179 
[epoch 20] step 28/44: loss=-0.1188 
[epoch 20] step 30/44: loss=-0.1185 
[epoch 20] step 32/44: loss=-0.1183 
[epoch 20] step 34/44: loss=-0.1196 
[epoch 20] step 36/44: loss=-0.1209 
[epoch 20] step 38/44: loss=-0.1215 
[epoch 20] step 40/44: loss=-0.1200 
[epoch 20] step 42/44: loss=-0.1194 
[epoch 20] step 44/44: loss=-0.1206 
[epoch 20] train_loss(avg per step)=-0.2413 lambda[min,max]=[0.501366,1.000000]
[epoch 20] val_loss=0.9751 qwk=('0.5827', '0.5827', '0.6259') averageQWK=0.5971 macroEMD=0.2042 tailR0=('0.1739', '0.0833', '0.0000') tailR0avg=0.0857
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    3    0
     0   16   34    4    0
     0    4   78   41    3
     0    0   22   83   11
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   15   32    5    0
     0    8   80   32    2
     0    0   29   98    6
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   34   31    3    0
     0   29   95   28    0
     0    0   24   76    1
     0    0    1    1    0
[epoch 21] step 2/44: loss=-0.1310 
[epoch 21] step 4/44: loss=-0.1395 
[epoch 21] step 6/44: loss=-0.1341 
[epoch 21] step 8/44: loss=-0.1323 
[epoch 21] step 10/44: loss=-0.1291 
[epoch 21] step 12/44: loss=-0.1283 
[epoch 21] step 14/44: loss=-0.1269 
[epoch 21] step 16/44: loss=-0.1276 
[epoch 21] step 18/44: loss=-0.1268 
[epoch 21] step 20/44: loss=-0.1263 
[epoch 21] step 22/44: loss=-0.1278 
[epoch 21] step 24/44: loss=-0.1277 
[epoch 21] step 26/44: loss=-0.1287 
[epoch 21] step 28/44: loss=-0.1283 
[epoch 21] step 30/44: loss=-0.1292 
[epoch 21] step 32/44: loss=-0.1291 
[epoch 21] step 34/44: loss=-0.1290 
[epoch 21] step 36/44: loss=-0.1285 
[epoch 21] step 38/44: loss=-0.1293 
[epoch 21] step 40/44: loss=-0.1297 
[epoch 21] step 42/44: loss=-0.1309 
[epoch 21] step 44/44: loss=-0.1305 
[epoch 21] train_loss(avg per step)=-0.2609 lambda[min,max]=[0.501182,1.000000]
[epoch 21] val_loss=0.9376 qwk=('0.6355', '0.5662', '0.6306') averageQWK=0.6107 macroEMD=0.1930 tailR0=('0.1304', '0.1250', '0.0000') tailR0avg=0.0851
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   17   34    3    0
     0    5   94   25    2
     0    0   28   82    6
     0    0    0   17    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   17   31    4    0
     0   17   78   25    2
     0    2   38   88    5
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   26   41    1    0
     0   19  108   25    0
     0    0   24   76    1
     0    0    1    1    0
[epoch 22] step 2/44: loss=-0.1600 
[epoch 22] step 4/44: loss=-0.1470 
[epoch 22] step 6/44: loss=-0.1445 
[epoch 22] step 8/44: loss=-0.1483 
[epoch 22] step 10/44: loss=-0.1466 
[epoch 22] step 12/44: loss=-0.1461 
[epoch 22] step 14/44: loss=-0.1448 
[epoch 22] step 16/44: loss=-0.1445 
[epoch 22] step 18/44: loss=-0.1438 
[epoch 22] step 20/44: loss=-0.1428 
[epoch 22] step 22/44: loss=-0.1431 
[epoch 22] step 24/44: loss=-0.1427 
[epoch 22] step 26/44: loss=-0.1429 
[epoch 22] step 28/44: loss=-0.1436 
[epoch 22] step 30/44: loss=-0.1434 
[epoch 22] step 32/44: loss=-0.1415 
[epoch 22] step 34/44: loss=-0.1427 
[epoch 22] step 36/44: loss=-0.1436 
[epoch 22] step 38/44: loss=-0.1433 
[epoch 22] step 40/44: loss=-0.1415 
[epoch 22] step 42/44: loss=-0.1421 
[epoch 22] step 44/44: loss=-0.1428 
[epoch 22] train_loss(avg per step)=-0.2857 lambda[min,max]=[0.501156,1.000000]
[epoch 22] val_loss=0.9850 qwk=('0.6310', '0.5339', '0.6319') averageQWK=0.5989 macroEMD=0.1972 tailR0=('0.2077', '0.0417', '0.0000') tailR0avg=0.0831
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   19   32    3    0
     0    6   88   29    3
     0    0   30   77    9
     0    0    0   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   14   31    7    0
     0   11   56   54    1
     0    2   14  115    2
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   34    3    0
     0   22   97   33    0
     0    0   22   77    2
     0    0    0    2    0
[epoch 23] step 2/44: loss=-0.1629 
[epoch 23] step 4/44: loss=-0.1580 
[epoch 23] step 6/44: loss=-0.1588 
[epoch 23] step 8/44: loss=-0.1545 
[epoch 23] step 10/44: loss=-0.1576 
[epoch 23] step 12/44: loss=-0.1584 
[epoch 23] step 14/44: loss=-0.1557 
[epoch 23] step 16/44: loss=-0.1550 
[epoch 23] step 18/44: loss=-0.1537 
[epoch 23] step 20/44: loss=-0.1529 
[epoch 23] step 22/44: loss=-0.1530 
[epoch 23] step 24/44: loss=-0.1524 
[epoch 23] step 26/44: loss=-0.1528 
[epoch 23] step 28/44: loss=-0.1523 
[epoch 23] step 30/44: loss=-0.1514 
[epoch 23] step 32/44: loss=-0.1507 
[epoch 23] step 34/44: loss=-0.1507 
[epoch 23] step 36/44: loss=-0.1502 
[epoch 23] step 38/44: loss=-0.1501 
[epoch 23] step 40/44: loss=-0.1510 
[epoch 23] step 42/44: loss=-0.1505 
[epoch 23] step 44/44: loss=-0.1500 
[epoch 23] train_loss(avg per step)=-0.2999 lambda[min,max]=[0.501153,1.000000]
[epoch 23] val_loss=1.0152 qwk=('0.6389', '0.5505', '0.6176') averageQWK=0.6023 macroEMD=0.1901 tailR0=('0.4034', '0.1250', '0.2000') tailR0avg=0.2428
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    3    2    0
     0   18   33    3    0
     0    5   84   33    4
     0    0   26   73   17
     0    0    0    7   16
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   16   31    5    0
     0   13   72   34    3
     0    2   28   92   11
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    2    0    0
     0   28   34    6    0
     0   24   94   34    0
     0    0   16   83    2
     0    0    0    2    0
[epoch 24] step 2/44: loss=-0.1576 
[epoch 24] step 4/44: loss=-0.1580 
[epoch 24] step 6/44: loss=-0.1599 
[epoch 24] step 8/44: loss=-0.1550 
[epoch 24] step 10/44: loss=-0.1582 
[epoch 24] step 12/44: loss=-0.1565 
[epoch 24] step 14/44: loss=-0.1547 
[epoch 24] step 16/44: loss=-0.1545 
[epoch 24] step 18/44: loss=-0.1553 
[epoch 24] step 20/44: loss=-0.1556 
[epoch 24] step 22/44: loss=-0.1549 
[epoch 24] step 24/44: loss=-0.1537 
[epoch 24] step 26/44: loss=-0.1524 
[epoch 24] step 28/44: loss=-0.1519 
[epoch 24] step 30/44: loss=-0.1521 
[epoch 24] step 32/44: loss=-0.1517 
[epoch 24] step 34/44: loss=-0.1524 
[epoch 24] step 36/44: loss=-0.1523 
[epoch 24] step 38/44: loss=-0.1530 
[epoch 24] step 40/44: loss=-0.1531 
[epoch 24] step 42/44: loss=-0.1532 
[epoch 24] step 44/44: loss=-0.1547 
[epoch 24] train_loss(avg per step)=-0.3094 lambda[min,max]=[0.501130,1.000000]
[epoch 24] val_loss=0.9897 qwk=('0.6162', '0.5624', '0.5838') averageQWK=0.5875 macroEMD=0.2004 tailR0=('0.2174', '0.0833', '0.0000') tailR0avg=0.1002
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   14   37    3    0
     0    4   88   31    3
     0    0   27   78   11
     0    0    0   13   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   14   35    3    0
     0    7   88   26    1
     0    0   39   88    6
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   26   39    3    0
     0   18  105   29    0
     0    0   28   71    2
     0    0    1    1    0
[epoch 25] step 2/44: loss=-0.1747 
[epoch 25] step 4/44: loss=-0.1709 
[epoch 25] step 6/44: loss=-0.1645 
[epoch 25] step 8/44: loss=-0.1630 
[epoch 25] step 10/44: loss=-0.1654 
[epoch 25] step 12/44: loss=-0.1652 
[epoch 25] step 14/44: loss=-0.1661 
[epoch 25] step 16/44: loss=-0.1680 
[epoch 25] step 18/44: loss=-0.1688 
[epoch 25] step 20/44: loss=-0.1686 
[epoch 25] step 22/44: loss=-0.1669 
[epoch 25] step 24/44: loss=-0.1663 
[epoch 25] step 26/44: loss=-0.1672 
[epoch 25] step 28/44: loss=-0.1671 
[epoch 25] step 30/44: loss=-0.1663 
[epoch 25] step 32/44: loss=-0.1664 
[epoch 25] step 34/44: loss=-0.1660 
[epoch 25] step 36/44: loss=-0.1654 
[epoch 25] step 38/44: loss=-0.1650 
[epoch 25] step 40/44: loss=-0.1651 
[epoch 25] step 42/44: loss=-0.1648 
[epoch 25] step 44/44: loss=-0.1650 
[epoch 25] train_loss(avg per step)=-0.3300 lambda[min,max]=[0.501074,1.000000]
[epoch 25] val_loss=1.0581 qwk=('0.5580', '0.5402', '0.6096') averageQWK=0.5693 macroEMD=0.2091 tailR0=('0.1739', '0.0833', '0.0000') tailR0avg=0.0857
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    3    0
     0   12   37    5    0
     0    4   72   48    2
     0    0   21   87    8
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   11   37    4    0
     0    3   82   34    3
     0    1   27   99    6
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   28   35    5    0
     0   19  104   29    0
     0    0   19   80    2
     0    0    1    1    0
[epoch 26] step 2/44: loss=-0.1697 
[epoch 26] step 4/44: loss=-0.1650 
[epoch 26] step 6/44: loss=-0.1654 
[epoch 26] step 8/44: loss=-0.1677 
[epoch 26] step 10/44: loss=-0.1693 
[epoch 26] step 12/44: loss=-0.1682 
[epoch 26] step 14/44: loss=-0.1684 
[epoch 26] step 16/44: loss=-0.1678 
[epoch 26] step 18/44: loss=-0.1663 
[epoch 26] step 20/44: loss=-0.1664 
[epoch 26] step 22/44: loss=-0.1674 
[epoch 26] step 24/44: loss=-0.1678 
[epoch 26] step 26/44: loss=-0.1687 
[epoch 26] step 28/44: loss=-0.1692 
[epoch 26] step 30/44: loss=-0.1688 
[epoch 26] step 32/44: loss=-0.1680 
[epoch 26] step 34/44: loss=-0.1687 
[epoch 26] step 36/44: loss=-0.1686 
[epoch 26] step 38/44: loss=-0.1674 
[epoch 26] step 40/44: loss=-0.1677 
[epoch 26] step 42/44: loss=-0.1679 
[epoch 26] step 44/44: loss=-0.1683 
[epoch 26] train_loss(avg per step)=-0.3366 lambda[min,max]=[0.501056,1.000000]
[epoch 26] val_loss=1.0211 qwk=('0.6204', '0.5557', '0.6304') averageQWK=0.6021 macroEMD=0.1957 tailR0=('0.2512', '0.0833', '0.1000') tailR0avg=0.1448
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   12   39    3    0
     0    3   90   31    2
     0    0   30   76   10
     0    0    0   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   13   37    2    0
     0   10   85   25    2
     0    2   33   92    6
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   28   36    4    0
     0   18  105   29    0
     0    0   20   79    2
     0    0    0    2    0
[epoch 27] step 2/44: loss=-0.1730 
[epoch 27] step 4/44: loss=-0.1730 
[epoch 27] step 6/44: loss=-0.1743 
[epoch 27] step 8/44: loss=-0.1759 
[epoch 27] step 10/44: loss=-0.1776 
[epoch 27] step 12/44: loss=-0.1778 
[epoch 27] step 14/44: loss=-0.1740 
[epoch 27] step 16/44: loss=-0.1736 
[epoch 27] step 18/44: loss=-0.1721 
[epoch 27] step 20/44: loss=-0.1723 
[epoch 27] step 22/44: loss=-0.1718 
[epoch 27] step 24/44: loss=-0.1726 
[epoch 27] step 26/44: loss=-0.1731 
[epoch 27] step 28/44: loss=-0.1735 
[epoch 27] step 30/44: loss=-0.1739 
[epoch 27] step 32/44: loss=-0.1744 
[epoch 27] step 34/44: loss=-0.1743 
[epoch 27] step 36/44: loss=-0.1741 
[epoch 27] step 38/44: loss=-0.1738 
[epoch 27] step 40/44: loss=-0.1737 
[epoch 27] step 42/44: loss=-0.1740 
[epoch 27] step 44/44: loss=-0.1740 
[epoch 27] train_loss(avg per step)=-0.3481 lambda[min,max]=[0.500982,1.000000]
[epoch 27] val_loss=1.0501 qwk=('0.6355', '0.5384', '0.6203') averageQWK=0.5981 macroEMD=0.1977 tailR0=('0.3068', '0.0833', '0.1000') tailR0avg=0.1634
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
     1   18   32    3    0
     0    4   92   26    4
     0    0   34   72   10
     0    0    0   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   15   30    7    0
     0   13   63   45    1
     0    2   21  107    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   22   43    3    0
     0   15  109   28    0
     0    0   20   79    2
     0    0    0    2    0
[epoch 28] step 2/44: loss=-0.1745 
[epoch 28] step 4/44: loss=-0.1741 
[epoch 28] step 6/44: loss=-0.1737 
[epoch 28] step 8/44: loss=-0.1751 
[epoch 28] step 10/44: loss=-0.1766 
[epoch 28] step 12/44: loss=-0.1765 
[epoch 28] step 14/44: loss=-0.1755 
[epoch 28] step 16/44: loss=-0.1754 
[epoch 28] step 18/44: loss=-0.1747 
[epoch 28] step 20/44: loss=-0.1752 
[epoch 28] step 22/44: loss=-0.1758 
[epoch 28] step 24/44: loss=-0.1758 
[epoch 28] step 26/44: loss=-0.1758 
[epoch 28] step 28/44: loss=-0.1755 
[epoch 28] step 30/44: loss=-0.1756 
[epoch 28] step 32/44: loss=-0.1760 
[epoch 28] step 34/44: loss=-0.1758 
[epoch 28] step 36/44: loss=-0.1759 
[epoch 28] step 38/44: loss=-0.1759 
[epoch 28] step 40/44: loss=-0.1763 
[epoch 28] step 42/44: loss=-0.1758 
[epoch 28] step 44/44: loss=-0.1764 
[epoch 28] train_loss(avg per step)=-0.3527 lambda[min,max]=[0.501111,1.000000]
[epoch 28] val_loss=1.0164 qwk=('0.6128', '0.5714', '0.6249') averageQWK=0.6030 macroEMD=0.1991 tailR0=('0.1739', '0.0417', '0.1000') tailR0avg=0.1052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    2    0
     0   19   32    3    0
     0    6   86   32    2
     0    0   29   81    6
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   14   36    2    0
     0   10   80   31    1
     0    1   28  102    2
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   30   38    0    0
     0   26  103   23    0
     0    0   29   71    1
     0    0    1    1    0
[epoch 29] step 2/44: loss=-0.1815 
[epoch 29] step 4/44: loss=-0.1804 
[epoch 29] step 6/44: loss=-0.1803 
[epoch 29] step 8/44: loss=-0.1810 
[epoch 29] step 10/44: loss=-0.1814 
[epoch 29] step 12/44: loss=-0.1818 
[epoch 29] step 14/44: loss=-0.1814 
[epoch 29] step 16/44: loss=-0.1808 
[epoch 29] step 18/44: loss=-0.1803 
[epoch 29] step 20/44: loss=-0.1808 
[epoch 29] step 22/44: loss=-0.1815 
[epoch 29] step 24/44: loss=-0.1817 
[epoch 29] step 26/44: loss=-0.1820 
[epoch 29] step 28/44: loss=-0.1815 
[epoch 29] step 30/44: loss=-0.1817 
[epoch 29] step 32/44: loss=-0.1819 
[epoch 29] step 34/44: loss=-0.1814 
[epoch 29] step 36/44: loss=-0.1807 
[epoch 29] step 38/44: loss=-0.1807 
[epoch 29] step 40/44: loss=-0.1808 
[epoch 29] step 42/44: loss=-0.1801 
[epoch 29] step 44/44: loss=-0.1799 
[epoch 29] train_loss(avg per step)=-0.3598 lambda[min,max]=[0.501026,1.000000]
[epoch 29] val_loss=1.0279 qwk=('0.6099', '0.5473', '0.6114') averageQWK=0.5895 macroEMD=0.2029 tailR0=('0.1739', '0.0417', '0.0000') tailR0avg=0.0719
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   11   40    3    0
     0    2   96   26    2
     0    0   33   78    5
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   14   30    8    0
     0   11   74   37    0
     0    1   23  109    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   29   36    3    0
     0   23  100   29    0
     0    0   22   77    2
     0    0    1    1    0
[epoch 30] step 2/44: loss=-0.1881 
[epoch 30] step 4/44: loss=-0.1841 
[epoch 30] step 6/44: loss=-0.1830 
[epoch 30] step 8/44: loss=-0.1833 
[epoch 30] step 10/44: loss=-0.1808 
[epoch 30] step 12/44: loss=-0.1824 
[epoch 30] step 14/44: loss=-0.1833 
[epoch 30] step 16/44: loss=-0.1838 
[epoch 30] step 18/44: loss=-0.1841 
[epoch 30] step 20/44: loss=-0.1833 
[epoch 30] step 22/44: loss=-0.1835 
[epoch 30] step 24/44: loss=-0.1836 
[epoch 30] step 26/44: loss=-0.1833 
[epoch 30] step 28/44: loss=-0.1836 
[epoch 30] step 30/44: loss=-0.1837 
[epoch 30] step 32/44: loss=-0.1841 
[epoch 30] step 34/44: loss=-0.1842 
[epoch 30] step 36/44: loss=-0.1843 
[epoch 30] step 38/44: loss=-0.1844 
[epoch 30] step 40/44: loss=-0.1841 
[epoch 30] step 42/44: loss=-0.1841 
[epoch 30] step 44/44: loss=-0.1842 
[epoch 30] train_loss(avg per step)=-0.3684 lambda[min,max]=[0.501042,1.000000]
[epoch 30] val_loss=1.0419 qwk=('0.6362', '0.5598', '0.6201') averageQWK=0.6054 macroEMD=0.1984 tailR0=('0.1957', '0.0833', '0.1000') tailR0avg=0.1263
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   17   34    3    0
     0    4   84   36    2
     0    0   25   84    7
     0    0    0   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   13   36    3    0
     0    8   82   30    2
     0    1   29   98    5
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   26   38    4    0
     0   17  104   31    0
     0    0   20   79    2
     0    0    0    2    0
[epoch 31] step 2/44: loss=-0.1890 
[epoch 31] step 4/44: loss=-0.1901 
[epoch 31] step 6/44: loss=-0.1895 
[epoch 31] step 8/44: loss=-0.1899 
[epoch 31] step 10/44: loss=-0.1875 
[epoch 31] step 12/44: loss=-0.1875 
[epoch 31] step 14/44: loss=-0.1880 
[epoch 31] step 16/44: loss=-0.1884 
[epoch 31] step 18/44: loss=-0.1880 
[epoch 31] step 20/44: loss=-0.1878 
[epoch 31] step 22/44: loss=-0.1880 
[epoch 31] step 24/44: loss=-0.1870 
[epoch 31] step 26/44: loss=-0.1867 
[epoch 31] step 28/44: loss=-0.1869 
[epoch 31] step 30/44: loss=-0.1866 
[epoch 31] step 32/44: loss=-0.1867 
[epoch 31] step 34/44: loss=-0.1868 
[epoch 31] step 36/44: loss=-0.1867 
[epoch 31] step 38/44: loss=-0.1868 
[epoch 31] step 40/44: loss=-0.1867 
[epoch 31] step 42/44: loss=-0.1868 
[epoch 31] step 44/44: loss=-0.1860 
[epoch 31] train_loss(avg per step)=-0.3721 lambda[min,max]=[0.501032,1.000000]
[epoch 31] val_loss=1.0360 qwk=('0.6310', '0.5566', '0.6431') averageQWK=0.6103 macroEMD=0.1969 tailR0=('0.1522', '0.0833', '0.1000') tailR0avg=0.1118
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   18   33    3    0
     0    7   85   32    2
     0    0   27   84    5
     0    0    0   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   15   33    4    0
     0   11   78   31    2
     0    1   29   99    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   31   36    1    0
     0   25  100   27    0
     0    0   24   75    2
     0    0    1    1    0
[epoch 32] step 2/44: loss=-0.1899 
[epoch 32] step 4/44: loss=-0.1882 
[epoch 32] step 6/44: loss=-0.1892 
[epoch 32] step 8/44: loss=-0.1884 
[epoch 32] step 10/44: loss=-0.1881 
[epoch 32] step 12/44: loss=-0.1873 
[epoch 32] step 14/44: loss=-0.1875 
[epoch 32] step 16/44: loss=-0.1860 
[epoch 32] step 18/44: loss=-0.1867 
[epoch 32] step 20/44: loss=-0.1869 
[epoch 32] step 22/44: loss=-0.1874 
[epoch 32] step 24/44: loss=-0.1875 
[epoch 32] step 26/44: loss=-0.1877 
[epoch 32] step 28/44: loss=-0.1874 
[epoch 32] step 30/44: loss=-0.1876 
[epoch 32] step 32/44: loss=-0.1878 
[epoch 32] step 34/44: loss=-0.1882 
[epoch 32] step 36/44: loss=-0.1885 
[epoch 32] step 38/44: loss=-0.1878 
[epoch 32] step 40/44: loss=-0.1878 
[epoch 32] step 42/44: loss=-0.1878 
[epoch 32] step 44/44: loss=-0.1879 
[epoch 32] train_loss(avg per step)=-0.3757 lambda[min,max]=[0.501035,1.000000]
[epoch 32] val_loss=1.0388 qwk=('0.6422', '0.5718', '0.6296') averageQWK=0.6145 macroEMD=0.1914 tailR0=('0.2295', '0.0833', '0.1000') tailR0avg=0.1376
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   20   31    3    0
     0    7   91   26    2
     0    0   33   75    8
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    3    0
     0   18   31    3    0
     0   16   73   31    2
     0    3   26  100    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   27   38    3    0
     0   22   99   31    0
     0    0   21   78    2
     0    0    0    2    0
[epoch 33] step 2/44: loss=-0.1862 
[epoch 33] step 4/44: loss=-0.1895 
[epoch 33] step 6/44: loss=-0.1898 
[epoch 33] step 8/44: loss=-0.1892 
[epoch 33] step 10/44: loss=-0.1879 
[epoch 33] step 12/44: loss=-0.1887 
[epoch 33] step 14/44: loss=-0.1890 
[epoch 33] step 16/44: loss=-0.1885 
[epoch 33] step 18/44: loss=-0.1888 
[epoch 33] step 20/44: loss=-0.1892 
[epoch 33] step 22/44: loss=-0.1894 
[epoch 33] step 24/44: loss=-0.1891 
[epoch 33] step 26/44: loss=-0.1893 
[epoch 33] step 28/44: loss=-0.1894 
[epoch 33] step 30/44: loss=-0.1896 
[epoch 33] step 32/44: loss=-0.1897 
[epoch 33] step 34/44: loss=-0.1898 
[epoch 33] step 36/44: loss=-0.1896 
[epoch 33] step 38/44: loss=-0.1897 
[epoch 33] step 40/44: loss=-0.1893 
[epoch 33] step 42/44: loss=-0.1892 
[epoch 33] step 44/44: loss=-0.1893 
[epoch 33] train_loss(avg per step)=-0.3786 lambda[min,max]=[0.501002,1.000000]
[epoch 33] val_loss=1.0521 qwk=('0.6354', '0.5410', '0.6255') averageQWK=0.6006 macroEMD=0.1987 tailR0=('0.1739', '0.0833', '0.1000') tailR0avg=0.1191
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   17   34    3    0
     0    4   87   33    2
     0    0   26   85    5
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   12   34    6    0
     0   10   78   32    2
     0    1   25  104    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   27   40    1    0
     0   25   99   28    0
     0    0   24   75    2
     0    0    1    1    0
[epoch 34] step 2/44: loss=-0.1924 
[epoch 34] step 4/44: loss=-0.1872 
[epoch 34] step 6/44: loss=-0.1896 
[epoch 34] step 8/44: loss=-0.1878 
[epoch 34] step 10/44: loss=-0.1885 
[epoch 34] step 12/44: loss=-0.1889 
[epoch 34] step 14/44: loss=-0.1894 
[epoch 34] step 16/44: loss=-0.1896 
[epoch 34] step 18/44: loss=-0.1894 
[epoch 34] step 20/44: loss=-0.1896 
[epoch 34] step 22/44: loss=-0.1889 
[epoch 34] step 24/44: loss=-0.1882 
[epoch 34] step 26/44: loss=-0.1885 
[epoch 34] step 28/44: loss=-0.1884 
[epoch 34] step 30/44: loss=-0.1886 
[epoch 34] step 32/44: loss=-0.1889 
[epoch 34] step 34/44: loss=-0.1892 
[epoch 34] step 36/44: loss=-0.1893 
[epoch 34] step 38/44: loss=-0.1892 
[epoch 34] step 40/44: loss=-0.1893 
[epoch 34] step 42/44: loss=-0.1894 
[epoch 34] step 44/44: loss=-0.1895 
[epoch 34] train_loss(avg per step)=-0.3791 lambda[min,max]=[0.500996,1.000000]
[epoch 34] val_loss=1.0551 qwk=('0.6182', '0.5415', '0.6330') averageQWK=0.5975 macroEMD=0.2004 tailR0=('0.1739', '0.0833', '0.1000') tailR0avg=0.1191
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   12   39    3    0
     0    3   88   33    2
     0    0   26   84    6
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   13   33    6    0
     0    9   75   36    2
     0    1   24  104    4
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   26   40    2    0
     0   21  101   30    0
     0    0   22   77    2
     0    0    0    2    0
[epoch 35] step 2/44: loss=-0.1906 
[epoch 35] step 4/44: loss=-0.1908 
[epoch 35] step 6/44: loss=-0.1897 
[epoch 35] step 8/44: loss=-0.1891 
[epoch 35] step 10/44: loss=-0.1880 
[epoch 35] step 12/44: loss=-0.1886 
[epoch 35] step 14/44: loss=-0.1891 
[epoch 35] step 16/44: loss=-0.1894 
[epoch 35] step 18/44: loss=-0.1894 
[epoch 35] step 20/44: loss=-0.1895 
[epoch 35] step 22/44: loss=-0.1898 
[epoch 35] step 24/44: loss=-0.1900 
[epoch 35] step 26/44: loss=-0.1898 
[epoch 35] step 28/44: loss=-0.1900 
[epoch 35] step 30/44: loss=-0.1901 
[epoch 35] step 32/44: loss=-0.1902 
[epoch 35] step 34/44: loss=-0.1901 
[epoch 35] step 36/44: loss=-0.1903 
[epoch 35] step 38/44: loss=-0.1905 
[epoch 35] step 40/44: loss=-0.1903 
[epoch 35] step 42/44: loss=-0.1904 
[epoch 35] step 44/44: loss=-0.1893 
[epoch 35] train_loss(avg per step)=-0.3787 lambda[min,max]=[0.500949,1.000000]
[epoch 35] val_loss=1.0498 qwk=('0.6281', '0.5465', '0.6294') averageQWK=0.6013 macroEMD=0.1980 tailR0=('0.1739', '0.0833', '0.1000') tailR0avg=0.1191
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   16   35    3    0
     0    5   86   33    2
     0    0   27   83    6
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   14   32    6    0
     0   10   75   35    2
     0    1   24  105    3
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   28   39    1    0
     0   25   99   28    0
     0    0   24   75    2
     0    0    1    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-0-conf_gating-0-reassignment-0/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-0-conf_gating-0-reassignment-0/fold1/metrics.json
Done.
