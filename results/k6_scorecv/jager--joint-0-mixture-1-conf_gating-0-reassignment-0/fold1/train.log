[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.7254 
[epoch 1] step 4/44: loss=0.7209 
[epoch 1] step 6/44: loss=0.7260 
[epoch 1] step 8/44: loss=0.7250 
[epoch 1] step 10/44: loss=0.7236 
[epoch 1] step 12/44: loss=0.7162 
[epoch 1] step 14/44: loss=0.7173 
[epoch 1] step 16/44: loss=0.7148 
[epoch 1] step 18/44: loss=0.7160 
[epoch 1] step 20/44: loss=0.7145 
[epoch 1] step 22/44: loss=0.7136 
[epoch 1] step 24/44: loss=0.7139 
[epoch 1] step 26/44: loss=0.7120 
[epoch 1] step 28/44: loss=0.7123 
[epoch 1] step 30/44: loss=0.7094 
[epoch 1] step 32/44: loss=0.7089 
[epoch 1] step 34/44: loss=0.7077 
[epoch 1] step 36/44: loss=0.7067 
[epoch 1] step 38/44: loss=0.7043 
[epoch 1] step 40/44: loss=0.7032 
[epoch 1] step 42/44: loss=0.7011 
[epoch 1] step 44/44: loss=0.7000 
[epoch 1] train_loss(avg per step)=1.3999 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.2973 qwk=('0.1569', '0.1896', '-0.0046') averageQWK=0.1140 macroEMD=0.3640 tailR0=('0.0000', '0.1111', '0.0000') tailR0avg=0.0370
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    5    0
     0   12    0   42    0
     0   33    0   93    0
     0   18    0   98    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    5    2    0
    10    0   30   12    0
    30    0   62   30    0
    15    0   59   59    0
     0    0    4    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    9   59    0    0
     0    9  143    0    0
     0   12   89    0    0
     0    0    2    0    0
[epoch 2] step 2/44: loss=0.6431 
[epoch 2] step 4/44: loss=0.6466 
[epoch 2] step 6/44: loss=0.6652 
[epoch 2] step 8/44: loss=0.6578 
[epoch 2] step 10/44: loss=0.6612 
[epoch 2] step 12/44: loss=0.6577 
[epoch 2] step 14/44: loss=0.6533 
[epoch 2] step 16/44: loss=0.6508 
[epoch 2] step 18/44: loss=0.6458 
[epoch 2] step 20/44: loss=0.6450 
[epoch 2] step 22/44: loss=0.6422 
[epoch 2] step 24/44: loss=0.6393 
[epoch 2] step 26/44: loss=0.6337 
[epoch 2] step 28/44: loss=0.6306 
[epoch 2] step 30/44: loss=0.6299 
[epoch 2] step 32/44: loss=0.6281 
[epoch 2] step 34/44: loss=0.6265 
[epoch 2] step 36/44: loss=0.6255 
[epoch 2] step 38/44: loss=0.6249 
[epoch 2] step 40/44: loss=0.6237 
[epoch 2] step 42/44: loss=0.6215 
[epoch 2] step 44/44: loss=0.6172 
[epoch 2] train_loss(avg per step)=1.2344 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.1365 qwk=('0.3267', '0.3057', '0.4127') averageQWK=0.3484 macroEMD=0.3162 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    3    0
     0    0   38   16    0
     0    0   47   79    0
     0    0   11  105    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    4    0
     0    0   33   19    0
     0    0   42   80    0
     0    0    8  125    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    8   47   13    0
     0    3   71   78    0
     0    0   11   90    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=0.5370 
[epoch 3] step 4/44: loss=0.5360 
[epoch 3] step 6/44: loss=0.5521 
[epoch 3] step 8/44: loss=0.5604 
[epoch 3] step 10/44: loss=0.5792 
[epoch 3] step 12/44: loss=0.5816 
[epoch 3] step 14/44: loss=0.5753 
[epoch 3] step 16/44: loss=0.5656 
[epoch 3] step 18/44: loss=0.5688 
[epoch 3] step 20/44: loss=0.5668 
[epoch 3] step 22/44: loss=0.5631 
[epoch 3] step 24/44: loss=0.5617 
[epoch 3] step 26/44: loss=0.5594 
[epoch 3] step 28/44: loss=0.5592 
[epoch 3] step 30/44: loss=0.5590 
[epoch 3] step 32/44: loss=0.5535 
[epoch 3] step 34/44: loss=0.5502 
[epoch 3] step 36/44: loss=0.5470 
[epoch 3] step 38/44: loss=0.5506 
[epoch 3] step 40/44: loss=0.5506 
[epoch 3] step 42/44: loss=0.5493 
[epoch 3] step 44/44: loss=0.5511 
[epoch 3] train_loss(avg per step)=1.1023 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=1.0510 qwk=('0.4864', '0.3955', '0.5530') averageQWK=0.4783 macroEMD=0.2841 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0    3   50    1    0
     0    0  107   19    0
     0    0   46   70    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   52    0    0
     0    0  104   18    0
     0    0   62   71    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   34    2    0
     0   33  108   11    0
     0    0   47   54    0
     0    0    2    0    0
[epoch 4] step 2/44: loss=0.4885 
[epoch 4] step 4/44: loss=0.4721 
[epoch 4] step 6/44: loss=0.4792 
[epoch 4] step 8/44: loss=0.4883 
[epoch 4] step 10/44: loss=0.4951 
[epoch 4] step 12/44: loss=0.4922 
[epoch 4] step 14/44: loss=0.4905 
[epoch 4] step 16/44: loss=0.4870 
[epoch 4] step 18/44: loss=0.4857 
[epoch 4] step 20/44: loss=0.4832 
[epoch 4] step 22/44: loss=0.4800 
[epoch 4] step 24/44: loss=0.4815 
[epoch 4] step 26/44: loss=0.4847 
[epoch 4] step 28/44: loss=0.4833 
[epoch 4] step 30/44: loss=0.4814 
[epoch 4] step 32/44: loss=0.4824 
[epoch 4] step 34/44: loss=0.4830 
[epoch 4] step 36/44: loss=0.4843 
[epoch 4] step 38/44: loss=0.4859 
[epoch 4] step 40/44: loss=0.4886 
[epoch 4] step 42/44: loss=0.4926 
[epoch 4] step 44/44: loss=0.4930 
[epoch 4] train_loss(avg per step)=0.9861 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=1.0594 qwk=('0.5061', '0.4305', '0.5645') averageQWK=0.5003 macroEMD=0.2602 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    2    0
     0   11   36    7    0
     0    2   79   45    0
     0    0   20   96    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    3    0
     0    6   32   14    0
     0    3   57   62    0
     0    0   10  123    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   20   40    8    0
     0    7   90   55    0
     0    0    8   93    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=0.4309 
[epoch 5] step 4/44: loss=0.4492 
[epoch 5] step 6/44: loss=0.4434 
[epoch 5] step 8/44: loss=0.4549 
[epoch 5] step 10/44: loss=0.4477 
[epoch 5] step 12/44: loss=0.4470 
[epoch 5] step 14/44: loss=0.4482 
[epoch 5] step 16/44: loss=0.4450 
[epoch 5] step 18/44: loss=0.4443 
[epoch 5] step 20/44: loss=0.4422 
[epoch 5] step 22/44: loss=0.4398 
[epoch 5] step 24/44: loss=0.4421 
[epoch 5] step 26/44: loss=0.4418 
[epoch 5] step 28/44: loss=0.4453 
[epoch 5] step 30/44: loss=0.4441 
[epoch 5] step 32/44: loss=0.4429 
[epoch 5] step 34/44: loss=0.4463 
[epoch 5] step 36/44: loss=0.4463 
[epoch 5] step 38/44: loss=0.4479 
[epoch 5] step 40/44: loss=0.4488 
[epoch 5] step 42/44: loss=0.4496 
[epoch 5] step 44/44: loss=0.4520 
[epoch 5] train_loss(avg per step)=0.9040 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=1.0130 qwk=('0.6148', '0.5741', '0.6340') averageQWK=0.6076 macroEMD=0.2616 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   45    7    2    0
     0   50   59   17    0
     0   11   27   77    1
     0    1    2   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   16   34    2    0
     0   14   87   21    0
     0    4   39   90    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   44   24    0    0
     0   37  108    7    0
     0    3   35   63    0
     0    0    2    0    0
[epoch 6] step 2/44: loss=0.4676 
[epoch 6] step 4/44: loss=0.4493 
[epoch 6] step 6/44: loss=0.4416 
[epoch 6] step 8/44: loss=0.4446 
[epoch 6] step 10/44: loss=0.4438 
[epoch 6] step 12/44: loss=0.4441 
[epoch 6] step 14/44: loss=0.4450 
[epoch 6] step 16/44: loss=0.4495 
[epoch 6] step 18/44: loss=0.4506 
[epoch 6] step 20/44: loss=0.4463 
[epoch 6] step 22/44: loss=0.4424 
[epoch 6] step 24/44: loss=0.4388 
[epoch 6] step 26/44: loss=0.4424 
[epoch 6] step 28/44: loss=0.4400 
[epoch 6] step 30/44: loss=0.4390 
[epoch 6] step 32/44: loss=0.4383 
[epoch 6] step 34/44: loss=0.4386 
[epoch 6] step 36/44: loss=0.4383 
[epoch 6] step 38/44: loss=0.4367 
[epoch 6] step 40/44: loss=0.4373 
[epoch 6] step 42/44: loss=0.4383 
[epoch 6] step 44/44: loss=0.4381 
[epoch 6] train_loss(avg per step)=0.8761 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=0.9536 qwk=('0.5950', '0.5151', '0.5756') averageQWK=0.5619 macroEMD=0.2392 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   22   27    5    0
     0    5   85   36    0
     0    0   23   93    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   11   31   10    0
     0    4   65   53    0
     0    0   18  115    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   16   50    2    0
     0    5  124   23    0
     0    0   31   70    0
     0    0    1    1    0
[epoch 7] step 2/44: loss=0.3181 
[epoch 7] step 4/44: loss=0.3626 
[epoch 7] step 6/44: loss=0.3827 
[epoch 7] step 8/44: loss=0.3911 
[epoch 7] step 10/44: loss=0.4101 
[epoch 7] step 12/44: loss=0.4112 
[epoch 7] step 14/44: loss=0.4149 
[epoch 7] step 16/44: loss=0.4049 
[epoch 7] step 18/44: loss=0.3984 
[epoch 7] step 20/44: loss=0.3991 
[epoch 7] step 22/44: loss=0.3980 
[epoch 7] step 24/44: loss=0.3976 
[epoch 7] step 26/44: loss=0.3983 
[epoch 7] step 28/44: loss=0.3957 
[epoch 7] step 30/44: loss=0.3971 
[epoch 7] step 32/44: loss=0.3947 
[epoch 7] step 34/44: loss=0.3951 
[epoch 7] step 36/44: loss=0.3948 
[epoch 7] step 38/44: loss=0.3939 
[epoch 7] step 40/44: loss=0.3966 
[epoch 7] step 42/44: loss=0.3950 
[epoch 7] step 44/44: loss=0.3954 
[epoch 7] train_loss(avg per step)=0.7909 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.0253 qwk=('0.5743', '0.5088', '0.6142') averageQWK=0.5658 macroEMD=0.2348 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   18   28    8    0
     0    4   69   51    2
     0    0   16   93    7
     0    0    0   18    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    2    0
     0   12   30   10    0
     0    7   64   51    0
     0    0   19  114    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   22   41    5    0
     0   13   97   42    0
     0    0   12   89    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=0.3491 
[epoch 8] step 4/44: loss=0.3304 
[epoch 8] step 6/44: loss=0.3174 
[epoch 8] step 8/44: loss=0.3365 
[epoch 8] step 10/44: loss=0.3513 
[epoch 8] step 12/44: loss=0.3620 
[epoch 8] step 14/44: loss=0.3645 
[epoch 8] step 16/44: loss=0.3614 
[epoch 8] step 18/44: loss=0.3512 
[epoch 8] step 20/44: loss=0.3482 
[epoch 8] step 22/44: loss=0.3550 
[epoch 8] step 24/44: loss=0.3484 
[epoch 8] step 26/44: loss=0.3477 
[epoch 8] step 28/44: loss=0.3468 
[epoch 8] step 30/44: loss=0.3471 
[epoch 8] step 32/44: loss=0.3468 
[epoch 8] step 34/44: loss=0.3465 
[epoch 8] step 36/44: loss=0.3438 
[epoch 8] step 38/44: loss=0.3451 
[epoch 8] step 40/44: loss=0.3438 
[epoch 8] step 42/44: loss=0.3444 
[epoch 8] step 44/44: loss=0.3408 
[epoch 8] train_loss(avg per step)=0.6816 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=0.9579 qwk=('0.6355', '0.6034', '0.6292') averageQWK=0.6227 macroEMD=0.2309 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   30   24    0    0
     0   18  101    7    0
     0    1   53   58    4
     0    0    3   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   20   31    1    0
     0   16   88   18    0
     0    2   45   86    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   40   28    0    0
     0   31  114    7    0
     0    1   43   57    0
     0    0    1    1    0
[epoch 9] step 2/44: loss=0.3194 
[epoch 9] step 4/44: loss=0.3172 
[epoch 9] step 6/44: loss=0.3111 
[epoch 9] step 8/44: loss=0.3149 
[epoch 9] step 10/44: loss=0.3316 
[epoch 9] step 12/44: loss=0.3274 
[epoch 9] step 14/44: loss=0.3240 
[epoch 9] step 16/44: loss=0.3177 
[epoch 9] step 18/44: loss=0.3169 
[epoch 9] step 20/44: loss=0.3228 
[epoch 9] step 22/44: loss=0.3232 
[epoch 9] step 24/44: loss=0.3196 
[epoch 9] step 26/44: loss=0.3147 
[epoch 9] step 28/44: loss=0.3158 
[epoch 9] step 30/44: loss=0.3108 
[epoch 9] step 32/44: loss=0.3121 
[epoch 9] step 34/44: loss=0.3110 
[epoch 9] step 36/44: loss=0.3077 
[epoch 9] step 38/44: loss=0.3070 
[epoch 9] step 40/44: loss=0.3059 
[epoch 9] step 42/44: loss=0.3068 
[epoch 9] step 44/44: loss=0.3060 
[epoch 9] train_loss(avg per step)=0.6120 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=0.9350 qwk=('0.6529', '0.5957', '0.6734') averageQWK=0.6407 macroEMD=0.2172 tailR0=('0.1957', '0.0000', '0.0000') tailR0avg=0.0652
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   23   28    2    1
     0   11   88   24    3
     0    0   25   83    8
     0    0    0   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   18   27    7    0
     0   16   70   36    0
     0    1   20  112    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   47   20    1    0
     0   41   86   25    0
     0    2   21   78    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=0.2832 
[epoch 10] step 4/44: loss=0.2694 
[epoch 10] step 6/44: loss=0.2535 
[epoch 10] step 8/44: loss=0.2591 
[epoch 10] step 10/44: loss=0.2529 
[epoch 10] step 12/44: loss=0.2456 
[epoch 10] step 14/44: loss=0.2500 
[epoch 10] step 16/44: loss=0.2495 
[epoch 10] step 18/44: loss=0.2483 
[epoch 10] step 20/44: loss=0.2525 
[epoch 10] step 22/44: loss=0.2573 
[epoch 10] step 24/44: loss=0.2586 
[epoch 10] step 26/44: loss=0.2573 
[epoch 10] step 28/44: loss=0.2576 
[epoch 10] step 30/44: loss=0.2566 
[epoch 10] step 32/44: loss=0.2563 
[epoch 10] step 34/44: loss=0.2553 
[epoch 10] step 36/44: loss=0.2566 
[epoch 10] step 38/44: loss=0.2581 
[epoch 10] step 40/44: loss=0.2595 
[epoch 10] step 42/44: loss=0.2588 
[epoch 10] step 44/44: loss=0.2653 
[epoch 10] train_loss(avg per step)=0.5307 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.0043 qwk=('0.5509', '0.5248', '0.5921') averageQWK=0.5559 macroEMD=0.2274 tailR0=('0.1957', '0.0000', '0.0000') tailR0avg=0.0652
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    3    0
     0   12   36    5    1
     0    4   79   40    3
     0    0   23   84    9
     0    0    0   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   12   31    9    0
     0   10   73   39    0
     0    0   27  106    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   24   39    5    0
     0   17  101   34    0
     0    1   17   83    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.2313 
[epoch 11] step 4/44: loss=0.2447 
[epoch 11] step 6/44: loss=0.2614 
[epoch 11] step 8/44: loss=0.2644 
[epoch 11] step 10/44: loss=0.2569 
[epoch 11] step 12/44: loss=0.2567 
[epoch 11] step 14/44: loss=0.2530 
[epoch 11] step 16/44: loss=0.2487 
[epoch 11] step 18/44: loss=0.2383 
[epoch 11] step 20/44: loss=0.2377 
[epoch 11] step 22/44: loss=0.2350 
[epoch 11] step 24/44: loss=0.2349 
[epoch 11] step 26/44: loss=0.2344 
[epoch 11] step 28/44: loss=0.2320 
[epoch 11] step 30/44: loss=0.2277 
[epoch 11] step 32/44: loss=0.2246 
[epoch 11] step 34/44: loss=0.2228 
[epoch 11] step 36/44: loss=0.2215 
[epoch 11] step 38/44: loss=0.2195 
[epoch 11] step 40/44: loss=0.2182 
[epoch 11] step 42/44: loss=0.2172 
[epoch 11] step 44/44: loss=0.2200 
[epoch 11] train_loss(avg per step)=0.4400 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=0.9734 qwk=('0.6200', '0.5187', '0.6578') averageQWK=0.5988 macroEMD=0.2199 tailR0=('0.3043', '0.0000', '0.0000') tailR0avg=0.1014
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   11   39    3    1
     0    1  102   19    4
     0    0   32   68   16
     0    0    0    9   14
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0    9   34    9    0
     0   10   75   37    0
     0    0   29  104    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   26   39    3    0
     0   13  107   32    0
     0    0   14   87    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=0.2292 
[epoch 12] step 4/44: loss=0.2288 
[epoch 12] step 6/44: loss=0.2248 
[epoch 12] step 8/44: loss=0.2064 
[epoch 12] step 10/44: loss=0.1996 
[epoch 12] step 12/44: loss=0.1926 
[epoch 12] step 14/44: loss=0.1935 
[epoch 12] step 16/44: loss=0.1921 
[epoch 12] step 18/44: loss=0.1871 
[epoch 12] step 20/44: loss=0.1870 
[epoch 12] step 22/44: loss=0.1906 
[epoch 12] step 24/44: loss=0.1887 
[epoch 12] step 26/44: loss=0.1889 
[epoch 12] step 28/44: loss=0.1885 
[epoch 12] step 30/44: loss=0.1861 
[epoch 12] step 32/44: loss=0.1836 
[epoch 12] step 34/44: loss=0.1782 
[epoch 12] step 36/44: loss=0.1789 
[epoch 12] step 38/44: loss=0.1770 
[epoch 12] step 40/44: loss=0.1744 
[epoch 12] step 42/44: loss=0.1732 
[epoch 12] step 44/44: loss=0.1754 
[epoch 12] train_loss(avg per step)=0.3508 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=0.9913 qwk=('0.5893', '0.5099', '0.6300') averageQWK=0.5764 macroEMD=0.2234 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   10   39    5    0
     0    5   84   36    1
     0    0   22   92    2
     0    0    0   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0    6   38    8    0
     0    5   72   45    0
     0    1   19  113    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   30   37    1    0
     0   24  110   18    0
     0    0   30   71    0
     0    0    1    1    0
[epoch 13] step 2/44: loss=0.1210 
[epoch 13] step 4/44: loss=0.1193 
[epoch 13] step 6/44: loss=0.1071 
[epoch 13] step 8/44: loss=0.1165 
[epoch 13] step 10/44: loss=0.1091 
[epoch 13] step 12/44: loss=0.1076 
[epoch 13] step 14/44: loss=0.1150 
[epoch 13] step 16/44: loss=0.1146 
[epoch 13] step 18/44: loss=0.1198 
[epoch 13] step 20/44: loss=0.1196 
[epoch 13] step 22/44: loss=0.1206 
[epoch 13] step 24/44: loss=0.1227 
[epoch 13] step 26/44: loss=0.1207 
[epoch 13] step 28/44: loss=0.1224 
[epoch 13] step 30/44: loss=0.1281 
[epoch 13] step 32/44: loss=0.1318 
[epoch 13] step 34/44: loss=0.1325 
[epoch 13] step 36/44: loss=0.1343 
[epoch 13] step 38/44: loss=0.1329 
[epoch 13] step 40/44: loss=0.1336 
[epoch 13] step 42/44: loss=0.1323 
[epoch 13] step 44/44: loss=0.1308 
[epoch 13] train_loss(avg per step)=0.2616 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=1.1140 qwk=('0.5494', '0.4968', '0.5938') averageQWK=0.5467 macroEMD=0.2257 tailR0=('0.2391', '0.1250', '0.0000') tailR0avg=0.1214
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    4    0
     0   12   35    6    1
     0    5   61   56    4
     0    0   11   93   12
     0    0    0   12   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   10   30   12    0
     0    9   63   50    0
     0    1   22  107    3
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   18   47    3    0
     0   10  104   38    0
     0    0   15   86    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.1436 
[epoch 14] step 4/44: loss=0.1478 
[epoch 14] step 6/44: loss=0.1245 
[epoch 14] step 8/44: loss=0.1261 
[epoch 14] step 10/44: loss=0.1305 
[epoch 14] step 12/44: loss=0.1166 
[epoch 14] step 14/44: loss=0.1087 
[epoch 14] step 16/44: loss=0.1062 
[epoch 14] step 18/44: loss=0.1088 
[epoch 14] step 20/44: loss=0.1053 
[epoch 14] step 22/44: loss=0.1025 
[epoch 14] step 24/44: loss=0.1022 
[epoch 14] step 26/44: loss=0.1027 
[epoch 14] step 28/44: loss=0.1014 
[epoch 14] step 30/44: loss=0.0997 
[epoch 14] step 32/44: loss=0.0977 
[epoch 14] step 34/44: loss=0.0962 
[epoch 14] step 36/44: loss=0.0977 
[epoch 14] step 38/44: loss=0.0996 
[epoch 14] step 40/44: loss=0.1024 
[epoch 14] step 42/44: loss=0.1004 
[epoch 14] step 44/44: loss=0.1004 
[epoch 14] train_loss(avg per step)=0.2009 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=1.0793 qwk=('0.5677', '0.5314', '0.6422') averageQWK=0.5804 macroEMD=0.2202 tailR0=('0.3696', '0.2500', '0.0000') tailR0avg=0.2065
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0    4   46    3    1
     0    3   98   19    6
     0    0   41   54   21
     0    0    0    6   17
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   13   27   12    0
     0    5   69   46    2
     0    1   20  102   10
     0    0    0    6    6
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   31   36    1    0
     0   22  107   23    0
     0    0   26   75    0
     0    0    0    2    0
[epoch 15] step 2/44: loss=0.0955 
[epoch 15] step 4/44: loss=0.0935 
[epoch 15] step 6/44: loss=0.0888 
[epoch 15] step 8/44: loss=0.0824 
[epoch 15] step 10/44: loss=0.0763 
[epoch 15] step 12/44: loss=0.0811 
[epoch 15] step 14/44: loss=0.0894 
[epoch 15] step 16/44: loss=0.0903 
[epoch 15] step 18/44: loss=0.0880 
[epoch 15] step 20/44: loss=0.0828 
[epoch 15] step 22/44: loss=0.0812 
[epoch 15] step 24/44: loss=0.0742 
[epoch 15] step 26/44: loss=0.0747 
[epoch 15] step 28/44: loss=0.0777 
[epoch 15] step 30/44: loss=0.0780 
[epoch 15] step 32/44: loss=0.0787 
[epoch 15] step 34/44: loss=0.0783 
[epoch 15] step 36/44: loss=0.0762 
[epoch 15] step 38/44: loss=0.0779 
[epoch 15] step 40/44: loss=0.0771 
[epoch 15] step 42/44: loss=0.0750 
[epoch 15] step 44/44: loss=0.0737 
[epoch 15] train_loss(avg per step)=0.1473 lambda[min,max]=[0.487480,1.000000]
[epoch 15] val_loss=1.0841 qwk=('0.6307', '0.5271', '0.6510') averageQWK=0.6030 macroEMD=0.2141 tailR0=('0.3261', '0.0833', '0.0000') tailR0avg=0.1365
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   14   37    3    0
     0    5   96   21    4
     0    0   37   53   26
     0    0    1    7   15
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   12   32    8    0
     0    9   68   45    0
     0    1   21  110    1
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   31   36    1    0
     0   20  108   24    0
     0    1   21   79    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=0.0856 
[epoch 16] step 4/44: loss=0.0748 
[epoch 16] step 6/44: loss=0.0733 
[epoch 16] step 8/44: loss=0.0627 
[epoch 16] step 10/44: loss=0.0572 
[epoch 16] step 12/44: loss=0.0548 
[epoch 16] step 14/44: loss=0.0592 
[epoch 16] step 16/44: loss=0.0540 
[epoch 16] step 18/44: loss=0.0511 
[epoch 16] step 20/44: loss=0.0522 
[epoch 16] step 22/44: loss=0.0528 
[epoch 16] step 24/44: loss=0.0497 
[epoch 16] step 26/44: loss=0.0490 
[epoch 16] step 28/44: loss=0.0479 
[epoch 16] step 30/44: loss=0.0484 
[epoch 16] step 32/44: loss=0.0497 
[epoch 16] step 34/44: loss=0.0500 
[epoch 16] step 36/44: loss=0.0482 
[epoch 16] step 38/44: loss=0.0479 
[epoch 16] step 40/44: loss=0.0477 
[epoch 16] step 42/44: loss=0.0484 
[epoch 16] step 44/44: loss=0.0491 
[epoch 16] train_loss(avg per step)=0.0981 lambda[min,max]=[0.465445,1.000000]
[epoch 16] val_loss=1.1171 qwk=('0.6198', '0.5482', '0.6095') averageQWK=0.5925 macroEMD=0.2117 tailR0=('0.3043', '0.0833', '0.0000') tailR0avg=0.1292
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   15   35    4    0
     0    6   80   36    4
     0    0   23   76   17
     0    0    0    9   14
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0    7   39    6    0
     0    3   83   36    0
     0    1   27  103    2
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   22   43    3    0
     0   11  109   32    0
     0    0   18   83    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=0.0537 
[epoch 17] step 4/44: loss=0.0433 
[epoch 17] step 6/44: loss=0.0419 
[epoch 17] step 8/44: loss=0.0523 
[epoch 17] step 10/44: loss=0.0481 
[epoch 17] step 12/44: loss=0.0379 
[epoch 17] step 14/44: loss=0.0356 
[epoch 17] step 16/44: loss=0.0390 
[epoch 17] step 18/44: loss=0.0362 
[epoch 17] step 20/44: loss=0.0353 
[epoch 17] step 22/44: loss=0.0348 
[epoch 17] step 24/44: loss=0.0346 
[epoch 17] step 26/44: loss=0.0340 
[epoch 17] step 28/44: loss=0.0328 
[epoch 17] step 30/44: loss=0.0303 
[epoch 17] step 32/44: loss=0.0333 
[epoch 17] step 34/44: loss=0.0315 
[epoch 17] step 36/44: loss=0.0308 
[epoch 17] step 38/44: loss=0.0287 
[epoch 17] step 40/44: loss=0.0278 
[epoch 17] step 42/44: loss=0.0258 
[epoch 17] step 44/44: loss=0.0253 
[epoch 17] train_loss(avg per step)=0.0507 lambda[min,max]=[0.494061,1.000000]
[epoch 17] val_loss=1.1391 qwk=('0.6228', '0.5131', '0.6273') averageQWK=0.5877 macroEMD=0.2095 tailR0=('0.2826', '0.0000', '0.0000') tailR0avg=0.0942
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   17   32    5    0
     0   10   76   37    3
     0    0   21   82   13
     0    0    0   10   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   14   30    8    0
     0   11   64   47    0
     0    1   23  109    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   33   31    4    0
     0   25   90   37    0
     0    1   17   83    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=-0.0035 
[epoch 18] step 4/44: loss=-0.0032 
[epoch 18] step 6/44: loss=-0.0064 
[epoch 18] step 8/44: loss=-0.0105 
[epoch 18] step 10/44: loss=-0.0132 
[epoch 18] step 12/44: loss=-0.0150 
[epoch 18] step 14/44: loss=-0.0179 
[epoch 18] step 16/44: loss=-0.0187 
[epoch 18] step 18/44: loss=-0.0191 
[epoch 18] step 20/44: loss=-0.0197 
[epoch 18] step 22/44: loss=-0.0210 
[epoch 18] step 24/44: loss=-0.0192 
[epoch 18] step 26/44: loss=-0.0168 
[epoch 18] step 28/44: loss=-0.0166 
[epoch 18] step 30/44: loss=-0.0168 
[epoch 18] step 32/44: loss=-0.0157 
[epoch 18] step 34/44: loss=-0.0148 
[epoch 18] step 36/44: loss=-0.0138 
[epoch 18] step 38/44: loss=-0.0112 
[epoch 18] step 40/44: loss=-0.0095 
[epoch 18] step 42/44: loss=-0.0073 
[epoch 18] step 44/44: loss=-0.0034 
[epoch 18] train_loss(avg per step)=-0.0068 lambda[min,max]=[0.447856,1.000000]
[epoch 18] val_loss=1.0943 qwk=('0.5726', '0.6156', '0.5724') averageQWK=0.5869 macroEMD=0.2171 tailR0=('0.1522', '0.0833', '0.0000') tailR0avg=0.0785
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    2    0
     0   11   40    3    0
     0    8   93   23    2
     0    0   34   79    3
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   21   27    4    0
     0   14   77   31    0
     0    1   29  101    2
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   25   42    1    0
     0   16  128    8    0
     0    0   39   62    0
     0    0    2    0    0
[epoch 19] step 2/44: loss=-0.0069 
[epoch 19] step 4/44: loss=-0.0102 
[epoch 19] step 6/44: loss=-0.0100 
[epoch 19] step 8/44: loss=-0.0207 
[epoch 19] step 10/44: loss=-0.0190 
[epoch 19] step 12/44: loss=-0.0158 
[epoch 19] step 14/44: loss=-0.0106 
[epoch 19] step 16/44: loss=-0.0109 
[epoch 19] step 18/44: loss=-0.0112 
[epoch 19] step 20/44: loss=-0.0121 
[epoch 19] step 22/44: loss=-0.0109 
[epoch 19] step 24/44: loss=-0.0123 
[epoch 19] step 26/44: loss=-0.0122 
[epoch 19] step 28/44: loss=-0.0109 
[epoch 19] step 30/44: loss=-0.0128 
[epoch 19] step 32/44: loss=-0.0126 
[epoch 19] step 34/44: loss=-0.0119 
[epoch 19] step 36/44: loss=-0.0137 
[epoch 19] step 38/44: loss=-0.0148 
[epoch 19] step 40/44: loss=-0.0160 
[epoch 19] step 42/44: loss=-0.0164 
[epoch 19] step 44/44: loss=-0.0173 
[epoch 19] train_loss(avg per step)=-0.0347 lambda[min,max]=[0.372682,1.000000]
[epoch 19] val_loss=1.1423 qwk=('0.5810', '0.5868', '0.6168') averageQWK=0.5949 macroEMD=0.2118 tailR0=('0.1860', '0.0417', '0.0000') tailR0avg=0.0759
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    1    0
     1    9   39    5    0
     0    3   85   36    2
     0    0   25   90    1
     0    0    0   17    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   16   31    5    0
     0   11   77   34    0
     0    1   27  101    4
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   21   46    1    0
     0   13  117   22    0
     0    0   26   75    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=-0.0373 
[epoch 20] step 4/44: loss=-0.0035 
[epoch 20] step 6/44: loss=-0.0091 
[epoch 20] step 8/44: loss=-0.0158 
[epoch 20] step 10/44: loss=-0.0251 
[epoch 20] step 12/44: loss=-0.0283 
[epoch 20] step 14/44: loss=-0.0315 
[epoch 20] step 16/44: loss=-0.0301 
[epoch 20] step 18/44: loss=-0.0290 
[epoch 20] step 20/44: loss=-0.0322 
[epoch 20] step 22/44: loss=-0.0342 
[epoch 20] step 24/44: loss=-0.0349 
[epoch 20] step 26/44: loss=-0.0350 
[epoch 20] step 28/44: loss=-0.0365 
[epoch 20] step 30/44: loss=-0.0370 
[epoch 20] step 32/44: loss=-0.0367 
[epoch 20] step 34/44: loss=-0.0375 
[epoch 20] step 36/44: loss=-0.0368 
[epoch 20] step 38/44: loss=-0.0367 
[epoch 20] step 40/44: loss=-0.0357 
[epoch 20] step 42/44: loss=-0.0360 
[epoch 20] step 44/44: loss=-0.0378 
[epoch 20] train_loss(avg per step)=-0.0756 lambda[min,max]=[0.380147,1.000000]
[epoch 20] val_loss=1.2682 qwk=('0.5578', '0.4391', '0.5526') averageQWK=0.5165 macroEMD=0.2236 tailR0=('0.2609', '0.0417', '0.0000') tailR0avg=0.1008
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    2    0
     0    4   46    4    0
     0    2   82   39    3
     0    0   22   81   13
     0    0    1   10   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    3    0
     0    6   33   13    0
     0    2   68   52    0
     0    1   22  106    4
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   14   49    5    0
     0    8  109   35    0
     0    0   19   82    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=-0.0485 
[epoch 21] step 4/44: loss=-0.0507 
[epoch 21] step 6/44: loss=-0.0481 
[epoch 21] step 8/44: loss=-0.0475 
[epoch 21] step 10/44: loss=-0.0414 
[epoch 21] step 12/44: loss=-0.0411 
[epoch 21] step 14/44: loss=-0.0410 
[epoch 21] step 16/44: loss=-0.0450 
[epoch 21] step 18/44: loss=-0.0435 
[epoch 21] step 20/44: loss=-0.0439 
[epoch 21] step 22/44: loss=-0.0459 
[epoch 21] step 24/44: loss=-0.0467 
[epoch 21] step 26/44: loss=-0.0484 
[epoch 21] step 28/44: loss=-0.0473 
[epoch 21] step 30/44: loss=-0.0481 
[epoch 21] step 32/44: loss=-0.0481 
[epoch 21] step 34/44: loss=-0.0479 
[epoch 21] step 36/44: loss=-0.0479 
[epoch 21] step 38/44: loss=-0.0482 
[epoch 21] step 40/44: loss=-0.0485 
[epoch 21] step 42/44: loss=-0.0501 
[epoch 21] step 44/44: loss=-0.0503 
[epoch 21] train_loss(avg per step)=-0.1006 lambda[min,max]=[0.385703,1.000000]
[epoch 21] val_loss=1.1338 qwk=('0.6146', '0.5632', '0.6309') averageQWK=0.6029 macroEMD=0.2036 tailR0=('0.2174', '0.0417', '0.0000') tailR0avg=0.0864
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   14   37    3    0
     0    6   97   21    2
     0    0   37   72    7
     0    0    1   12   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   18   28    6    0
     0   15   77   30    0
     0    2   31   96    4
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     1   27   38    2    0
     0   18  110   24    0
     0    0   25   76    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=-0.0870 
[epoch 22] step 4/44: loss=-0.0610 
[epoch 22] step 6/44: loss=-0.0587 
[epoch 22] step 8/44: loss=-0.0635 
[epoch 22] step 10/44: loss=-0.0661 
[epoch 22] step 12/44: loss=-0.0657 
[epoch 22] step 14/44: loss=-0.0636 
[epoch 22] step 16/44: loss=-0.0600 
[epoch 22] step 18/44: loss=-0.0606 
[epoch 22] step 20/44: loss=-0.0610 
[epoch 22] step 22/44: loss=-0.0614 
[epoch 22] step 24/44: loss=-0.0599 
[epoch 22] step 26/44: loss=-0.0605 
[epoch 22] step 28/44: loss=-0.0617 
[epoch 22] step 30/44: loss=-0.0626 
[epoch 22] step 32/44: loss=-0.0602 
[epoch 22] step 34/44: loss=-0.0607 
[epoch 22] step 36/44: loss=-0.0617 
[epoch 22] step 38/44: loss=-0.0621 
[epoch 22] step 40/44: loss=-0.0600 
[epoch 22] step 42/44: loss=-0.0611 
[epoch 22] step 44/44: loss=-0.0616 
[epoch 22] train_loss(avg per step)=-0.1232 lambda[min,max]=[0.381656,1.000000]
[epoch 22] val_loss=1.1778 qwk=('0.5852', '0.4927', '0.6419') averageQWK=0.5732 macroEMD=0.2110 tailR0=('0.2077', '0.0417', '0.0000') tailR0avg=0.0831
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    5    1    0
     0   10   41    3    0
     0    2   95   28    1
     0    0   32   77    7
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   11   28   13    0
     0    7   71   44    0
     0    1   23  106    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   36    1    0
     0   25  107   20    0
     0    1   26   74    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=-0.0752 
[epoch 23] step 4/44: loss=-0.0754 
[epoch 23] step 6/44: loss=-0.0760 
[epoch 23] step 8/44: loss=-0.0752 
[epoch 23] step 10/44: loss=-0.0758 
[epoch 23] step 12/44: loss=-0.0768 
[epoch 23] step 14/44: loss=-0.0747 
[epoch 23] step 16/44: loss=-0.0746 
[epoch 23] step 18/44: loss=-0.0736 
[epoch 23] step 20/44: loss=-0.0721 
[epoch 23] step 22/44: loss=-0.0713 
[epoch 23] step 24/44: loss=-0.0697 
[epoch 23] step 26/44: loss=-0.0697 
[epoch 23] step 28/44: loss=-0.0693 
[epoch 23] step 30/44: loss=-0.0690 
[epoch 23] step 32/44: loss=-0.0684 
[epoch 23] step 34/44: loss=-0.0686 
[epoch 23] step 36/44: loss=-0.0690 
[epoch 23] step 38/44: loss=-0.0689 
[epoch 23] step 40/44: loss=-0.0687 
[epoch 23] step 42/44: loss=-0.0675 
[epoch 23] step 44/44: loss=-0.0668 
[epoch 23] train_loss(avg per step)=-0.1337 lambda[min,max]=[0.352996,1.000000]
[epoch 23] val_loss=1.1632 qwk=('0.5863', '0.5576', '0.6211') averageQWK=0.5883 macroEMD=0.2095 tailR0=('0.2295', '0.0833', '0.0000') tailR0avg=0.1043
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    1    0
     1   11   39    3    0
     0    6   95   22    3
     0    0   35   74    7
     0    0    2   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   17   31    4    0
     0   11   76   34    1
     0    1   29  100    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   30   37    1    0
     0   19  121   12    0
     0    0   35   65    1
     0    0    1    1    0
[epoch 24] step 2/44: loss=-0.0813 
[epoch 24] step 4/44: loss=-0.0836 
[epoch 24] step 6/44: loss=-0.0827 
[epoch 24] step 8/44: loss=-0.0764 
[epoch 24] step 10/44: loss=-0.0788 
[epoch 24] step 12/44: loss=-0.0783 
[epoch 24] step 14/44: loss=-0.0789 
[epoch 24] step 16/44: loss=-0.0794 
[epoch 24] step 18/44: loss=-0.0803 
[epoch 24] step 20/44: loss=-0.0807 
[epoch 24] step 22/44: loss=-0.0791 
[epoch 24] step 24/44: loss=-0.0776 
[epoch 24] step 26/44: loss=-0.0764 
[epoch 24] step 28/44: loss=-0.0760 
[epoch 24] step 30/44: loss=-0.0760 
[epoch 24] step 32/44: loss=-0.0747 
[epoch 24] step 34/44: loss=-0.0746 
[epoch 24] step 36/44: loss=-0.0749 
[epoch 24] step 38/44: loss=-0.0750 
[epoch 24] step 40/44: loss=-0.0756 
[epoch 24] step 42/44: loss=-0.0756 
[epoch 24] step 44/44: loss=-0.0767 
[epoch 24] train_loss(avg per step)=-0.1534 lambda[min,max]=[0.367708,1.000000]
[epoch 24] val_loss=1.1989 qwk=('0.5843', '0.5607', '0.5962') averageQWK=0.5804 macroEMD=0.2122 tailR0=('0.1522', '0.0417', '0.0000') tailR0avg=0.0646
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0    7   44    3    0
     0    2   92   31    1
     0    0   24   87    5
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0    9   39    4    0
     0    5   87   29    1
     0    1   28  101    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   18   49    1    0
     0   15  119   18    0
     0    0   29   71    1
     0    0    0    2    0
[epoch 25] step 2/44: loss=-0.0980 
[epoch 25] step 4/44: loss=-0.0898 
[epoch 25] step 6/44: loss=-0.0795 
[epoch 25] step 8/44: loss=-0.0769 
[epoch 25] step 10/44: loss=-0.0800 
[epoch 25] step 12/44: loss=-0.0785 
[epoch 25] step 14/44: loss=-0.0800 
[epoch 25] step 16/44: loss=-0.0812 
[epoch 25] step 18/44: loss=-0.0824 
[epoch 25] step 20/44: loss=-0.0816 
[epoch 25] step 22/44: loss=-0.0797 
[epoch 25] step 24/44: loss=-0.0788 
[epoch 25] step 26/44: loss=-0.0787 
[epoch 25] step 28/44: loss=-0.0786 
[epoch 25] step 30/44: loss=-0.0781 
[epoch 25] step 32/44: loss=-0.0783 
[epoch 25] step 34/44: loss=-0.0781 
[epoch 25] step 36/44: loss=-0.0778 
[epoch 25] step 38/44: loss=-0.0777 
[epoch 25] step 40/44: loss=-0.0782 
[epoch 25] step 42/44: loss=-0.0777 
[epoch 25] step 44/44: loss=-0.0781 
[epoch 25] train_loss(avg per step)=-0.1563 lambda[min,max]=[0.354661,1.000000]
[epoch 25] val_loss=1.2143 qwk=('0.6242', '0.5069', '0.6488') averageQWK=0.5933 macroEMD=0.2033 tailR0=('0.2729', '0.0417', '0.0000') tailR0avg=0.1049
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    5    1    0
     0   13   38    3    0
     0    4   90   30    2
     0    0   25   85    6
     0    0    0   13   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    3    0
     0   10   33    9    0
     0    8   68   45    1
     0    1   19  111    2
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     1   38   27    2    0
     0   32   97   23    0
     0    2   23   76    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=-0.0736 
[epoch 26] step 4/44: loss=-0.0700 
[epoch 26] step 6/44: loss=-0.0735 
[epoch 26] step 8/44: loss=-0.0759 
[epoch 26] step 10/44: loss=-0.0768 
[epoch 26] step 12/44: loss=-0.0769 
[epoch 26] step 14/44: loss=-0.0774 
[epoch 26] step 16/44: loss=-0.0792 
[epoch 26] step 18/44: loss=-0.0805 
[epoch 26] step 20/44: loss=-0.0814 
[epoch 26] step 22/44: loss=-0.0820 
[epoch 26] step 24/44: loss=-0.0817 
[epoch 26] step 26/44: loss=-0.0825 
[epoch 26] step 28/44: loss=-0.0831 
[epoch 26] step 30/44: loss=-0.0830 
[epoch 26] step 32/44: loss=-0.0822 
[epoch 26] step 34/44: loss=-0.0826 
[epoch 26] step 36/44: loss=-0.0825 
[epoch 26] step 38/44: loss=-0.0819 
[epoch 26] step 40/44: loss=-0.0828 
[epoch 26] step 42/44: loss=-0.0833 
[epoch 26] step 44/44: loss=-0.0839 
[epoch 26] train_loss(avg per step)=-0.1678 lambda[min,max]=[0.388916,1.000000]
[epoch 26] val_loss=1.1942 qwk=('0.6202', '0.5783', '0.6377') averageQWK=0.6121 macroEMD=0.2012 tailR0=('0.2947', '0.0833', '0.0000') tailR0avg=0.1260
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    1    0
     0   13   38    3    0
     0    6   94   23    3
     0    0   30   75   11
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   12   38    2    0
     0    8   81   32    1
     0    1   30   98    4
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     1   28   38    1    0
     0   17  115   20    0
     0    1   26   73    1
     0    0    0    2    0
[epoch 27] step 2/44: loss=-0.0749 
[epoch 27] step 4/44: loss=-0.0790 
[epoch 27] step 6/44: loss=-0.0849 
[epoch 27] step 8/44: loss=-0.0859 
[epoch 27] step 10/44: loss=-0.0899 
[epoch 27] step 12/44: loss=-0.0897 
[epoch 27] step 14/44: loss=-0.0876 
[epoch 27] step 16/44: loss=-0.0858 
[epoch 27] step 18/44: loss=-0.0844 
[epoch 27] step 20/44: loss=-0.0853 
[epoch 27] step 22/44: loss=-0.0852 
[epoch 27] step 24/44: loss=-0.0855 
[epoch 27] step 26/44: loss=-0.0868 
[epoch 27] step 28/44: loss=-0.0866 
[epoch 27] step 30/44: loss=-0.0871 
[epoch 27] step 32/44: loss=-0.0875 
[epoch 27] step 34/44: loss=-0.0881 
[epoch 27] step 36/44: loss=-0.0876 
[epoch 27] step 38/44: loss=-0.0875 
[epoch 27] step 40/44: loss=-0.0874 
[epoch 27] step 42/44: loss=-0.0876 
[epoch 27] step 44/44: loss=-0.0882 
[epoch 27] train_loss(avg per step)=-0.1763 lambda[min,max]=[0.406177,1.000000]
[epoch 27] val_loss=1.2124 qwk=('0.6366', '0.5852', '0.6404') averageQWK=0.6208 macroEMD=0.2008 tailR0=('0.2947', '0.0833', '0.0000') tailR0avg=0.1260
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     0   14   37    3    0
     0    7   96   20    3
     0    0   31   73   12
     0    0    2   10   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   16   34    2    0
     0   11   78   32    1
     0    3   29   96    5
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     1   29   36    2    0
     0   19  116   17    0
     0    0   28   72    1
     0    0    0    2    0
[epoch 28] step 2/44: loss=-0.0898 
[epoch 28] step 4/44: loss=-0.0932 
[epoch 28] step 6/44: loss=-0.0861 
[epoch 28] step 8/44: loss=-0.0873 
[epoch 28] step 10/44: loss=-0.0887 
[epoch 28] step 12/44: loss=-0.0900 
[epoch 28] step 14/44: loss=-0.0897 
[epoch 28] step 16/44: loss=-0.0905 
[epoch 28] step 18/44: loss=-0.0885 
[epoch 28] step 20/44: loss=-0.0895 
[epoch 28] step 22/44: loss=-0.0909 
[epoch 28] step 24/44: loss=-0.0913 
[epoch 28] step 26/44: loss=-0.0910 
[epoch 28] step 28/44: loss=-0.0910 
[epoch 28] step 30/44: loss=-0.0912 
[epoch 28] step 32/44: loss=-0.0918 
[epoch 28] step 34/44: loss=-0.0920 
[epoch 28] step 36/44: loss=-0.0922 
[epoch 28] step 38/44: loss=-0.0923 
[epoch 28] step 40/44: loss=-0.0925 
[epoch 28] step 42/44: loss=-0.0924 
[epoch 28] step 44/44: loss=-0.0926 
[epoch 28] train_loss(avg per step)=-0.1852 lambda[min,max]=[0.379472,1.000000]
[epoch 28] val_loss=1.2735 qwk=('0.6039', '0.5068', '0.6084') averageQWK=0.5731 macroEMD=0.2066 tailR0=('0.2729', '0.0417', '0.0000') tailR0avg=0.1049
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    1    0
     0   11   38    5    0
     0    6   87   30    3
     0    0   25   81   10
     0    0    0   13   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   15   25   12    0
     0    7   69   45    1
     0    2   21  106    4
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   21   44    3    0
     0   13  113   26    0
     0    0   22   79    0
     0    0    0    2    0
[epoch 29] step 2/44: loss=-0.0934 
[epoch 29] step 4/44: loss=-0.0922 
[epoch 29] step 6/44: loss=-0.0936 
[epoch 29] step 8/44: loss=-0.0930 
[epoch 29] step 10/44: loss=-0.0943 
[epoch 29] step 12/44: loss=-0.0949 
[epoch 29] step 14/44: loss=-0.0943 
[epoch 29] step 16/44: loss=-0.0935 
[epoch 29] step 18/44: loss=-0.0936 
[epoch 29] step 20/44: loss=-0.0939 
[epoch 29] step 22/44: loss=-0.0946 
[epoch 29] step 24/44: loss=-0.0954 
[epoch 29] step 26/44: loss=-0.0950 
[epoch 29] step 28/44: loss=-0.0950 
[epoch 29] step 30/44: loss=-0.0953 
[epoch 29] step 32/44: loss=-0.0957 
[epoch 29] step 34/44: loss=-0.0956 
[epoch 29] step 36/44: loss=-0.0953 
[epoch 29] step 38/44: loss=-0.0954 
[epoch 29] step 40/44: loss=-0.0954 
[epoch 29] step 42/44: loss=-0.0952 
[epoch 29] step 44/44: loss=-0.0953 
[epoch 29] train_loss(avg per step)=-0.1906 lambda[min,max]=[0.433316,1.000000]
[epoch 29] val_loss=1.2046 qwk=('0.5743', '0.5845', '0.6606') averageQWK=0.6065 macroEMD=0.2073 tailR0=('0.2512', '0.0417', '0.0000') tailR0avg=0.0976
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    0    0
     0   11   40    3    0
     0    6   99   18    3
     0    0   43   67    6
     0    0    2   12    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   15   35    2    0
     0    7   83   32    0
     0    2   30   98    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     1   36   30    1    0
     0   29  110   13    0
     0    0   30   71    0
     0    0    1    1    0
[epoch 30] step 2/44: loss=-0.1038 
[epoch 30] step 4/44: loss=-0.0971 
[epoch 30] step 6/44: loss=-0.0951 
[epoch 30] step 8/44: loss=-0.0947 
[epoch 30] step 10/44: loss=-0.0939 
[epoch 30] step 12/44: loss=-0.0955 
[epoch 30] step 14/44: loss=-0.0960 
[epoch 30] step 16/44: loss=-0.0965 
[epoch 30] step 18/44: loss=-0.0970 
[epoch 30] step 20/44: loss=-0.0964 
[epoch 30] step 22/44: loss=-0.0964 
[epoch 30] step 24/44: loss=-0.0962 
[epoch 30] step 26/44: loss=-0.0958 
[epoch 30] step 28/44: loss=-0.0965 
[epoch 30] step 30/44: loss=-0.0966 
[epoch 30] step 32/44: loss=-0.0971 
[epoch 30] step 34/44: loss=-0.0973 
[epoch 30] step 36/44: loss=-0.0973 
[epoch 30] step 38/44: loss=-0.0973 
[epoch 30] step 40/44: loss=-0.0970 
[epoch 30] step 42/44: loss=-0.0970 
[epoch 30] step 44/44: loss=-0.0971 
[epoch 30] train_loss(avg per step)=-0.1941 lambda[min,max]=[0.381165,1.000000]
[epoch 30] val_loss=1.2518 qwk=('0.5654', '0.4993', '0.6284') averageQWK=0.5644 macroEMD=0.2110 tailR0=('0.1739', '0.0417', '0.0000') tailR0avg=0.0719
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0    9   42    3    0
     0    2   96   25    3
     0    0   36   73    7
     0    0    2   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0    6   38    8    0
     0    6   79   36    1
     0    2   25  104    2
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   30   36    2    0
     0   20  114   18    0
     0    0   30   71    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=-0.1026 
[epoch 31] step 4/44: loss=-0.1017 
[epoch 31] step 6/44: loss=-0.1018 
[epoch 31] step 8/44: loss=-0.1027 
[epoch 31] step 10/44: loss=-0.1022 
[epoch 31] step 12/44: loss=-0.1015 
[epoch 31] step 14/44: loss=-0.1015 
[epoch 31] step 16/44: loss=-0.1021 
[epoch 31] step 18/44: loss=-0.1019 
[epoch 31] step 20/44: loss=-0.1016 
[epoch 31] step 22/44: loss=-0.1013 
[epoch 31] step 24/44: loss=-0.1004 
[epoch 31] step 26/44: loss=-0.1006 
[epoch 31] step 28/44: loss=-0.1002 
[epoch 31] step 30/44: loss=-0.0999 
[epoch 31] step 32/44: loss=-0.1001 
[epoch 31] step 34/44: loss=-0.1002 
[epoch 31] step 36/44: loss=-0.0994 
[epoch 31] step 38/44: loss=-0.0997 
[epoch 31] step 40/44: loss=-0.0995 
[epoch 31] step 42/44: loss=-0.0996 
[epoch 31] step 44/44: loss=-0.0988 
[epoch 31] train_loss(avg per step)=-0.1976 lambda[min,max]=[0.396572,1.000000]
[epoch 31] val_loss=1.2732 qwk=('0.5891', '0.5018', '0.6127') averageQWK=0.5679 macroEMD=0.2098 tailR0=('0.1739', '0.0417', '0.0000') tailR0avg=0.0719
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   13   36    5    0
     0    5   89   30    2
     0    0   28   83    5
     0    0    1   14    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0    8   36    8    0
     0    7   76   38    1
     0    1   26  103    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     1   21   43    3    0
     0   16  114   22    0
     0    0   23   78    0
     0    0    0    2    0
[epoch 32] step 2/44: loss=-0.1039 
[epoch 32] step 4/44: loss=-0.1042 
[epoch 32] step 6/44: loss=-0.1048 
[epoch 32] step 8/44: loss=-0.1043 
[epoch 32] step 10/44: loss=-0.1034 
[epoch 32] step 12/44: loss=-0.1017 
[epoch 32] step 14/44: loss=-0.1024 
[epoch 32] step 16/44: loss=-0.1009 
[epoch 32] step 18/44: loss=-0.1014 
[epoch 32] step 20/44: loss=-0.1017 
[epoch 32] step 22/44: loss=-0.1018 
[epoch 32] step 24/44: loss=-0.1016 
[epoch 32] step 26/44: loss=-0.1015 
[epoch 32] step 28/44: loss=-0.1013 
[epoch 32] step 30/44: loss=-0.1011 
[epoch 32] step 32/44: loss=-0.1013 
[epoch 32] step 34/44: loss=-0.1019 
[epoch 32] step 36/44: loss=-0.1023 
[epoch 32] step 38/44: loss=-0.1017 
[epoch 32] step 40/44: loss=-0.1018 
[epoch 32] step 42/44: loss=-0.1018 
[epoch 32] step 44/44: loss=-0.1018 
[epoch 32] train_loss(avg per step)=-0.2037 lambda[min,max]=[0.370298,1.000000]
[epoch 32] val_loss=1.2578 qwk=('0.6057', '0.5352', '0.6246') averageQWK=0.5885 macroEMD=0.2070 tailR0=('0.2729', '0.0417', '0.1000') tailR0avg=0.1382
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    1    0
     0   13   37    4    0
     0    9   90   24    3
     0    0   30   79    7
     0    0    1   12   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   12   33    7    0
     0    9   75   37    1
     0    1   26  103    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   24   40    3    0
     0   17  114   21    0
     0    0   25   76    0
     0    0    0    2    0
[epoch 33] step 2/44: loss=-0.1069 
[epoch 33] step 4/44: loss=-0.1059 
[epoch 33] step 6/44: loss=-0.1036 
[epoch 33] step 8/44: loss=-0.1042 
[epoch 33] step 10/44: loss=-0.1026 
[epoch 33] step 12/44: loss=-0.1035 
[epoch 33] step 14/44: loss=-0.1036 
[epoch 33] step 16/44: loss=-0.1027 
[epoch 33] step 18/44: loss=-0.1022 
[epoch 33] step 20/44: loss=-0.1027 
[epoch 33] step 22/44: loss=-0.1026 
[epoch 33] step 24/44: loss=-0.1026 
[epoch 33] step 26/44: loss=-0.1032 
[epoch 33] step 28/44: loss=-0.1027 
[epoch 33] step 30/44: loss=-0.1028 
[epoch 33] step 32/44: loss=-0.1029 
[epoch 33] step 34/44: loss=-0.1027 
[epoch 33] step 36/44: loss=-0.1024 
[epoch 33] step 38/44: loss=-0.1025 
[epoch 33] step 40/44: loss=-0.1022 
[epoch 33] step 42/44: loss=-0.1019 
[epoch 33] step 44/44: loss=-0.1020 
[epoch 33] train_loss(avg per step)=-0.2041 lambda[min,max]=[0.380545,1.000000]
[epoch 33] val_loss=1.2604 qwk=('0.6212', '0.5023', '0.6187') averageQWK=0.5807 macroEMD=0.2064 tailR0=('0.3164', '0.0417', '0.0000') tailR0avg=0.1194
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    1    0
     0   13   37    4    0
     0    6   93   24    3
     0    0   31   77    8
     0    0    0   11   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0    7   37    8    0
     0    8   72   41    1
     0    1   25  104    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     1   25   39    3    0
     0   18  112   22    0
     0    0   25   76    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=-0.1044 
[epoch 34] step 4/44: loss=-0.1007 
[epoch 34] step 6/44: loss=-0.1027 
[epoch 34] step 8/44: loss=-0.1027 
[epoch 34] step 10/44: loss=-0.1026 
[epoch 34] step 12/44: loss=-0.1034 
[epoch 34] step 14/44: loss=-0.1037 
[epoch 34] step 16/44: loss=-0.1033 
[epoch 34] step 18/44: loss=-0.1034 
[epoch 34] step 20/44: loss=-0.1027 
[epoch 34] step 22/44: loss=-0.1026 
[epoch 34] step 24/44: loss=-0.1017 
[epoch 34] step 26/44: loss=-0.1020 
[epoch 34] step 28/44: loss=-0.1021 
[epoch 34] step 30/44: loss=-0.1021 
[epoch 34] step 32/44: loss=-0.1023 
[epoch 34] step 34/44: loss=-0.1026 
[epoch 34] step 36/44: loss=-0.1029 
[epoch 34] step 38/44: loss=-0.1027 
[epoch 34] step 40/44: loss=-0.1029 
[epoch 34] step 42/44: loss=-0.1030 
[epoch 34] step 44/44: loss=-0.1033 
[epoch 34] train_loss(avg per step)=-0.2066 lambda[min,max]=[0.376939,1.000000]
[epoch 34] val_loss=1.2633 qwk=('0.6018', '0.5081', '0.6079') averageQWK=0.5726 macroEMD=0.2090 tailR0=('0.2947', '0.0417', '0.0000') tailR0avg=0.1121
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    5    1    0
     0   13   37    4    0
     0    3   93   27    3
     0    0   30   80    6
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0    8   36    8    0
     0    8   73   40    1
     0    1   25  105    2
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     1   23   41    3    0
     0   17  115   20    0
     0    0   27   74    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=-0.1068 
[epoch 35] step 4/44: loss=-0.1045 
[epoch 35] step 6/44: loss=-0.1032 
[epoch 35] step 8/44: loss=-0.1026 
[epoch 35] step 10/44: loss=-0.1004 
[epoch 35] step 12/44: loss=-0.1018 
[epoch 35] step 14/44: loss=-0.1023 
[epoch 35] step 16/44: loss=-0.1023 
[epoch 35] step 18/44: loss=-0.1025 
[epoch 35] step 20/44: loss=-0.1029 
[epoch 35] step 22/44: loss=-0.1032 
[epoch 35] step 24/44: loss=-0.1031 
[epoch 35] step 26/44: loss=-0.1029 
[epoch 35] step 28/44: loss=-0.1032 
[epoch 35] step 30/44: loss=-0.1033 
[epoch 35] step 32/44: loss=-0.1036 
[epoch 35] step 34/44: loss=-0.1037 
[epoch 35] step 36/44: loss=-0.1039 
[epoch 35] step 38/44: loss=-0.1040 
[epoch 35] step 40/44: loss=-0.1041 
[epoch 35] step 42/44: loss=-0.1042 
[epoch 35] step 44/44: loss=-0.1034 
[epoch 35] train_loss(avg per step)=-0.2069 lambda[min,max]=[0.364972,1.000000]
[epoch 35] val_loss=1.2546 qwk=('0.6100', '0.5187', '0.6146') averageQWK=0.5811 macroEMD=0.2059 tailR0=('0.2947', '0.0417', '0.0000') tailR0avg=0.1121
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    5    1    0
     0   13   38    3    0
     0    7   92   24    3
     0    0   30   78    8
     0    0    1   11   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    2    0
     0   10   35    7    0
     0    8   73   40    1
     0    2   24  104    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     1   24   40    3    0
     0   18  114   20    0
     0    0   26   75    0
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold1/metrics.json
Done.
