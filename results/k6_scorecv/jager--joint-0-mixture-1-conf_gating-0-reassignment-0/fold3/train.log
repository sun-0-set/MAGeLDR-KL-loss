[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.7258 
[epoch 1] step 4/44: loss=0.7249 
[epoch 1] step 6/44: loss=0.7282 
[epoch 1] step 8/44: loss=0.7250 
[epoch 1] step 10/44: loss=0.7203 
[epoch 1] step 12/44: loss=0.7179 
[epoch 1] step 14/44: loss=0.7190 
[epoch 1] step 16/44: loss=0.7176 
[epoch 1] step 18/44: loss=0.7178 
[epoch 1] step 20/44: loss=0.7164 
[epoch 1] step 22/44: loss=0.7145 
[epoch 1] step 24/44: loss=0.7140 
[epoch 1] step 26/44: loss=0.7132 
[epoch 1] step 28/44: loss=0.7113 
[epoch 1] step 30/44: loss=0.7111 
[epoch 1] step 32/44: loss=0.7116 
[epoch 1] step 34/44: loss=0.7107 
[epoch 1] step 36/44: loss=0.7090 
[epoch 1] step 38/44: loss=0.7073 
[epoch 1] step 40/44: loss=0.7061 
[epoch 1] step 42/44: loss=0.7040 
[epoch 1] step 44/44: loss=0.7025 
[epoch 1] train_loss(avg per step)=1.4050 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.3255 qwk=('0.0537', '0.0962', '0.1565') averageQWK=0.1022 macroEMD=0.3662 tailR0=('0.0000', '0.1000', '0.5000') tailR0avg=0.2000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    5    0
     0   16    1   38    0
     0   35    9   82    0
     0   33    8   75    0
     0    1    5   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    8    0    0
    15    0   38    0    0
    41    0   69    9    0
    29    0   91   14    0
     0    0   11    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0   21   46    0    2
     0   25  111    1   14
     0   13   78    2    9
     0    0    0    0    1
[epoch 2] step 2/44: loss=0.6599 
[epoch 2] step 4/44: loss=0.6576 
[epoch 2] step 6/44: loss=0.6583 
[epoch 2] step 8/44: loss=0.6527 
[epoch 2] step 10/44: loss=0.6505 
[epoch 2] step 12/44: loss=0.6530 
[epoch 2] step 14/44: loss=0.6570 
[epoch 2] step 16/44: loss=0.6532 
[epoch 2] step 18/44: loss=0.6493 
[epoch 2] step 20/44: loss=0.6483 
[epoch 2] step 22/44: loss=0.6454 
[epoch 2] step 24/44: loss=0.6411 
[epoch 2] step 26/44: loss=0.6383 
[epoch 2] step 28/44: loss=0.6360 
[epoch 2] step 30/44: loss=0.6354 
[epoch 2] step 32/44: loss=0.6339 
[epoch 2] step 34/44: loss=0.6344 
[epoch 2] step 36/44: loss=0.6326 
[epoch 2] step 38/44: loss=0.6306 
[epoch 2] step 40/44: loss=0.6278 
[epoch 2] step 42/44: loss=0.6268 
[epoch 2] step 44/44: loss=0.6255 
[epoch 2] train_loss(avg per step)=1.2510 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.2273 qwk=('0.3085', '0.2818', '0.1264') averageQWK=0.2389 macroEMD=0.3253 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0    9   45    1    0
     0    7  110    9    0
     0    3   76   37    0
     0    0   18    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    0   53    0    0
     0    0  108   11    0
     0    0   86   48    0
     0    0    6    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    3   66    0    0
     0    0  149    2    0
     0    0   91   11    0
     0    0    1    0    0
[epoch 3] step 2/44: loss=0.6164 
[epoch 3] step 4/44: loss=0.6148 
[epoch 3] step 6/44: loss=0.6076 
[epoch 3] step 8/44: loss=0.5917 
[epoch 3] step 10/44: loss=0.5895 
[epoch 3] step 12/44: loss=0.5806 
[epoch 3] step 14/44: loss=0.5769 
[epoch 3] step 16/44: loss=0.5736 
[epoch 3] step 18/44: loss=0.5728 
[epoch 3] step 20/44: loss=0.5699 
[epoch 3] step 22/44: loss=0.5626 
[epoch 3] step 24/44: loss=0.5593 
[epoch 3] step 26/44: loss=0.5552 
[epoch 3] step 28/44: loss=0.5550 
[epoch 3] step 30/44: loss=0.5513 
[epoch 3] step 32/44: loss=0.5487 
[epoch 3] step 34/44: loss=0.5438 
[epoch 3] step 36/44: loss=0.5391 
[epoch 3] step 38/44: loss=0.5387 
[epoch 3] step 40/44: loss=0.5376 
[epoch 3] step 42/44: loss=0.5365 
[epoch 3] step 44/44: loss=0.5345 
[epoch 3] train_loss(avg per step)=1.0690 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=1.0465 qwk=('0.5560', '0.4213', '0.5279') averageQWK=0.5017 macroEMD=0.2622 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   10   38    7    0
     0    3   89   34    0
     0    0   25   91    0
     0    0    1   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    1    0
     0    0   44    9    0
     0    0   67   52    0
     0    0   22  112    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   14   51    4    0
     0    6  104   41    0
     0    0   27   75    0
     0    0    0    1    0
[epoch 4] step 2/44: loss=0.5324 
[epoch 4] step 4/44: loss=0.4982 
[epoch 4] step 6/44: loss=0.4982 
[epoch 4] step 8/44: loss=0.4904 
[epoch 4] step 10/44: loss=0.4807 
[epoch 4] step 12/44: loss=0.4884 
[epoch 4] step 14/44: loss=0.4860 
[epoch 4] step 16/44: loss=0.4870 
[epoch 4] step 18/44: loss=0.4867 
[epoch 4] step 20/44: loss=0.4846 
[epoch 4] step 22/44: loss=0.4838 
[epoch 4] step 24/44: loss=0.4784 
[epoch 4] step 26/44: loss=0.4798 
[epoch 4] step 28/44: loss=0.4818 
[epoch 4] step 30/44: loss=0.4798 
[epoch 4] step 32/44: loss=0.4837 
[epoch 4] step 34/44: loss=0.4804 
[epoch 4] step 36/44: loss=0.4832 
[epoch 4] step 38/44: loss=0.4858 
[epoch 4] step 40/44: loss=0.4876 
[epoch 4] step 42/44: loss=0.4878 
[epoch 4] step 44/44: loss=0.4853 
[epoch 4] train_loss(avg per step)=0.9706 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=1.0356 qwk=('0.5629', '0.5339', '0.4907') averageQWK=0.5292 macroEMD=0.2474 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   20   24   11    0
     0   15   60   51    0
     0    2   13  101    0
     0    0    1   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0    5   42    6    0
     0    1   81   37    0
     0    0   24  110    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0    9   52    8    0
     0    2   92   57    0
     0    0   15   87    0
     0    0    0    1    0
[epoch 5] step 2/44: loss=0.4426 
[epoch 5] step 4/44: loss=0.4693 
[epoch 5] step 6/44: loss=0.4818 
[epoch 5] step 8/44: loss=0.4746 
[epoch 5] step 10/44: loss=0.4758 
[epoch 5] step 12/44: loss=0.4789 
[epoch 5] step 14/44: loss=0.4740 
[epoch 5] step 16/44: loss=0.4712 
[epoch 5] step 18/44: loss=0.4708 
[epoch 5] step 20/44: loss=0.4724 
[epoch 5] step 22/44: loss=0.4727 
[epoch 5] step 24/44: loss=0.4722 
[epoch 5] step 26/44: loss=0.4692 
[epoch 5] step 28/44: loss=0.4720 
[epoch 5] step 30/44: loss=0.4693 
[epoch 5] step 32/44: loss=0.4705 
[epoch 5] step 34/44: loss=0.4672 
[epoch 5] step 36/44: loss=0.4683 
[epoch 5] step 38/44: loss=0.4711 
[epoch 5] step 40/44: loss=0.4705 
[epoch 5] step 42/44: loss=0.4672 
[epoch 5] step 44/44: loss=0.4628 
[epoch 5] train_loss(avg per step)=0.9256 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=0.9929 qwk=('0.5887', '0.5490', '0.5173') averageQWK=0.5517 macroEMD=0.2529 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   20   32    3    0
     0   14   93   19    0
     0    2   36   78    0
     0    0    4   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0    6   46    1    0
     0    1  102   16    0
     0    0   47   87    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   30   39    0    0
     0   22  123    6    0
     0    3   56   43    0
     0    0    1    0    0
[epoch 6] step 2/44: loss=0.4687 
[epoch 6] step 4/44: loss=0.4551 
[epoch 6] step 6/44: loss=0.4600 
[epoch 6] step 8/44: loss=0.4380 
[epoch 6] step 10/44: loss=0.4457 
[epoch 6] step 12/44: loss=0.4398 
[epoch 6] step 14/44: loss=0.4331 
[epoch 6] step 16/44: loss=0.4435 
[epoch 6] step 18/44: loss=0.4405 
[epoch 6] step 20/44: loss=0.4383 
[epoch 6] step 22/44: loss=0.4373 
[epoch 6] step 24/44: loss=0.4297 
[epoch 6] step 26/44: loss=0.4234 
[epoch 6] step 28/44: loss=0.4268 
[epoch 6] step 30/44: loss=0.4255 
[epoch 6] step 32/44: loss=0.4258 
[epoch 6] step 34/44: loss=0.4274 
[epoch 6] step 36/44: loss=0.4291 
[epoch 6] step 38/44: loss=0.4311 
[epoch 6] step 40/44: loss=0.4318 
[epoch 6] step 42/44: loss=0.4319 
[epoch 6] step 44/44: loss=0.4269 
[epoch 6] train_loss(avg per step)=0.8538 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=0.9882 qwk=('0.5981', '0.5710', '0.5123') averageQWK=0.5605 macroEMD=0.2301 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   11   38    6    0
     0    1   86   39    0
     0    0   18   98    0
     0    0    1   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0    8   38    7    0
     0    1   84   34    0
     0    0   19  115    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   11   53    5    0
     0   10   91   50    0
     0    2   15   85    0
     0    0    0    1    0
[epoch 7] step 2/44: loss=0.4177 
[epoch 7] step 4/44: loss=0.3887 
[epoch 7] step 6/44: loss=0.3862 
[epoch 7] step 8/44: loss=0.3821 
[epoch 7] step 10/44: loss=0.3907 
[epoch 7] step 12/44: loss=0.3886 
[epoch 7] step 14/44: loss=0.3850 
[epoch 7] step 16/44: loss=0.3842 
[epoch 7] step 18/44: loss=0.3814 
[epoch 7] step 20/44: loss=0.3802 
[epoch 7] step 22/44: loss=0.3780 
[epoch 7] step 24/44: loss=0.3810 
[epoch 7] step 26/44: loss=0.3855 
[epoch 7] step 28/44: loss=0.3884 
[epoch 7] step 30/44: loss=0.3955 
[epoch 7] step 32/44: loss=0.3952 
[epoch 7] step 34/44: loss=0.3949 
[epoch 7] step 36/44: loss=0.3973 
[epoch 7] step 38/44: loss=0.3998 
[epoch 7] step 40/44: loss=0.3977 
[epoch 7] step 42/44: loss=0.3944 
[epoch 7] step 44/44: loss=0.3923 
[epoch 7] train_loss(avg per step)=0.7847 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=0.9950 qwk=('0.5898', '0.6139', '0.6058') averageQWK=0.6032 macroEMD=0.2306 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   28   21    6    0
     0   26   72   27    1
     0    3   25   88    0
     0    0    4   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   20   27    6    0
     0   10   77   32    0
     0    2   25  107    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   41   25    3    0
     0   33   83   35    0
     0    4   25   73    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=0.3192 
[epoch 8] step 4/44: loss=0.3312 
[epoch 8] step 6/44: loss=0.3244 
[epoch 8] step 8/44: loss=0.3392 
[epoch 8] step 10/44: loss=0.3402 
[epoch 8] step 12/44: loss=0.3442 
[epoch 8] step 14/44: loss=0.3432 
[epoch 8] step 16/44: loss=0.3427 
[epoch 8] step 18/44: loss=0.3400 
[epoch 8] step 20/44: loss=0.3377 
[epoch 8] step 22/44: loss=0.3402 
[epoch 8] step 24/44: loss=0.3440 
[epoch 8] step 26/44: loss=0.3395 
[epoch 8] step 28/44: loss=0.3396 
[epoch 8] step 30/44: loss=0.3390 
[epoch 8] step 32/44: loss=0.3393 
[epoch 8] step 34/44: loss=0.3378 
[epoch 8] step 36/44: loss=0.3352 
[epoch 8] step 38/44: loss=0.3349 
[epoch 8] step 40/44: loss=0.3349 
[epoch 8] step 42/44: loss=0.3320 
[epoch 8] step 44/44: loss=0.3315 
[epoch 8] train_loss(avg per step)=0.6631 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=0.9323 qwk=('0.6595', '0.6766', '0.5962') averageQWK=0.6441 macroEMD=0.2114 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   28   25    2    0
     0   12   96   15    3
     0    1   32   82    1
     0    0    2   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   27   24    2    0
     0   15   83   21    0
     0    1   32  101    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   32    2    0
     0   20  101   30    0
     0    2   34   66    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=0.2847 
[epoch 9] step 4/44: loss=0.3073 
[epoch 9] step 6/44: loss=0.3026 
[epoch 9] step 8/44: loss=0.3050 
[epoch 9] step 10/44: loss=0.3042 
[epoch 9] step 12/44: loss=0.2998 
[epoch 9] step 14/44: loss=0.2934 
[epoch 9] step 16/44: loss=0.2916 
[epoch 9] step 18/44: loss=0.2968 
[epoch 9] step 20/44: loss=0.2998 
[epoch 9] step 22/44: loss=0.3049 
[epoch 9] step 24/44: loss=0.3014 
[epoch 9] step 26/44: loss=0.3022 
[epoch 9] step 28/44: loss=0.3056 
[epoch 9] step 30/44: loss=0.3036 
[epoch 9] step 32/44: loss=0.3077 
[epoch 9] step 34/44: loss=0.3070 
[epoch 9] step 36/44: loss=0.3087 
[epoch 9] step 38/44: loss=0.3089 
[epoch 9] step 40/44: loss=0.3083 
[epoch 9] step 42/44: loss=0.3092 
[epoch 9] step 44/44: loss=0.3106 
[epoch 9] train_loss(avg per step)=0.6212 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=0.9432 qwk=('0.6255', '0.6464', '0.6368') averageQWK=0.6362 macroEMD=0.2028 tailR0=('0.0682', '0.0000', '0.0000') tailR0avg=0.0227
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   18   34    2    1
     0    9   95   19    3
     0    1   31   78    6
     0    0    1   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   23   25    5    0
     0   14   79   26    0
     0    1   23  110    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   37   29    3    0
     0   26   87   38    0
     0    2   19   81    0
     0    0    0    1    0
[epoch 10] step 2/44: loss=0.3063 
[epoch 10] step 4/44: loss=0.3328 
[epoch 10] step 6/44: loss=0.3090 
[epoch 10] step 8/44: loss=0.3055 
[epoch 10] step 10/44: loss=0.3037 
[epoch 10] step 12/44: loss=0.3038 
[epoch 10] step 14/44: loss=0.2937 
[epoch 10] step 16/44: loss=0.2896 
[epoch 10] step 18/44: loss=0.2835 
[epoch 10] step 20/44: loss=0.2798 
[epoch 10] step 22/44: loss=0.2786 
[epoch 10] step 24/44: loss=0.2794 
[epoch 10] step 26/44: loss=0.2751 
[epoch 10] step 28/44: loss=0.2725 
[epoch 10] step 30/44: loss=0.2736 
[epoch 10] step 32/44: loss=0.2719 
[epoch 10] step 34/44: loss=0.2718 
[epoch 10] step 36/44: loss=0.2687 
[epoch 10] step 38/44: loss=0.2684 
[epoch 10] step 40/44: loss=0.2700 
[epoch 10] step 42/44: loss=0.2700 
[epoch 10] step 44/44: loss=0.2717 
[epoch 10] train_loss(avg per step)=0.5433 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=0.9946 qwk=('0.6314', '0.6354', '0.6139') averageQWK=0.6269 macroEMD=0.2018 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   30   23    2    0
     0   28   81   16    1
     0    2   35   78    1
     0    0    4   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   30   21    2    0
     0   22   83   14    0
     0    3   44   87    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   40   28    1    0
     0   32   96   23    0
     0    3   35   64    0
     0    0    0    1    0
[epoch 11] step 2/44: loss=0.3002 
[epoch 11] step 4/44: loss=0.3000 
[epoch 11] step 6/44: loss=0.2527 
[epoch 11] step 8/44: loss=0.2399 
[epoch 11] step 10/44: loss=0.2429 
[epoch 11] step 12/44: loss=0.2399 
[epoch 11] step 14/44: loss=0.2375 
[epoch 11] step 16/44: loss=0.2356 
[epoch 11] step 18/44: loss=0.2341 
[epoch 11] step 20/44: loss=0.2355 
[epoch 11] step 22/44: loss=0.2389 
[epoch 11] step 24/44: loss=0.2401 
[epoch 11] step 26/44: loss=0.2429 
[epoch 11] step 28/44: loss=0.2446 
[epoch 11] step 30/44: loss=0.2460 
[epoch 11] step 32/44: loss=0.2400 
[epoch 11] step 34/44: loss=0.2405 
[epoch 11] step 36/44: loss=0.2382 
[epoch 11] step 38/44: loss=0.2357 
[epoch 11] step 40/44: loss=0.2362 
[epoch 11] step 42/44: loss=0.2332 
[epoch 11] step 44/44: loss=0.2341 
[epoch 11] train_loss(avg per step)=0.4682 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=1.0047 qwk=('0.6021', '0.5911', '0.5804') averageQWK=0.5912 macroEMD=0.2060 tailR0=('0.0455', '0.0000', '0.0000') tailR0avg=0.0152
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   15   34    6    0
     0    3   80   43    0
     0    0   22   93    1
     0    0    1   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    2    0
     0   20   24    9    0
     0    8   65   46    0
     0    0   13  121    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   23   45    1    0
     0   12  107   32    0
     0    2   29   71    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=0.2121 
[epoch 12] step 4/44: loss=0.2086 
[epoch 12] step 6/44: loss=0.2207 
[epoch 12] step 8/44: loss=0.2128 
[epoch 12] step 10/44: loss=0.2089 
[epoch 12] step 12/44: loss=0.2000 
[epoch 12] step 14/44: loss=0.2009 
[epoch 12] step 16/44: loss=0.1993 
[epoch 12] step 18/44: loss=0.1992 
[epoch 12] step 20/44: loss=0.1947 
[epoch 12] step 22/44: loss=0.1950 
[epoch 12] step 24/44: loss=0.1930 
[epoch 12] step 26/44: loss=0.1933 
[epoch 12] step 28/44: loss=0.1913 
[epoch 12] step 30/44: loss=0.1943 
[epoch 12] step 32/44: loss=0.1934 
[epoch 12] step 34/44: loss=0.1904 
[epoch 12] step 36/44: loss=0.1889 
[epoch 12] step 38/44: loss=0.1887 
[epoch 12] step 40/44: loss=0.1878 
[epoch 12] step 42/44: loss=0.1876 
[epoch 12] step 44/44: loss=0.1875 
[epoch 12] train_loss(avg per step)=0.3750 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=0.9852 qwk=('0.6267', '0.6087', '0.6208') averageQWK=0.6187 macroEMD=0.2029 tailR0=('0.1364', '0.0000', '0.0000') tailR0avg=0.0455
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   15   36    4    0
     0    3   93   27    3
     0    0   25   85    6
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    2    0
     0   17   29    7    0
     0    5   76   38    0
     0    1   14  119    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   25   43    1    0
     0   12  105   34    0
     0    2   20   80    0
     0    0    0    1    0
[epoch 13] step 2/44: loss=0.1708 
[epoch 13] step 4/44: loss=0.1462 
[epoch 13] step 6/44: loss=0.1640 
[epoch 13] step 8/44: loss=0.1749 
[epoch 13] step 10/44: loss=0.1759 
[epoch 13] step 12/44: loss=0.1789 
[epoch 13] step 14/44: loss=0.1889 
[epoch 13] step 16/44: loss=0.1822 
[epoch 13] step 18/44: loss=0.1856 
[epoch 13] step 20/44: loss=0.1837 
[epoch 13] step 22/44: loss=0.1776 
[epoch 13] step 24/44: loss=0.1759 
[epoch 13] step 26/44: loss=0.1747 
[epoch 13] step 28/44: loss=0.1736 
[epoch 13] step 30/44: loss=0.1711 
[epoch 13] step 32/44: loss=0.1688 
[epoch 13] step 34/44: loss=0.1664 
[epoch 13] step 36/44: loss=0.1662 
[epoch 13] step 38/44: loss=0.1664 
[epoch 13] step 40/44: loss=0.1648 
[epoch 13] step 42/44: loss=0.1682 
[epoch 13] step 44/44: loss=0.1656 
[epoch 13] train_loss(avg per step)=0.3313 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=1.0055 qwk=('0.6231', '0.6036', '0.6228') averageQWK=0.6165 macroEMD=0.2036 tailR0=('0.1692', '0.0000', '0.0000') tailR0avg=0.0564
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    0    1    0
     1   21   27    5    1
     0    5   83   33    5
     0    0   21   84   11
     0    0    1   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   17   28    8    0
     0    4   71   43    1
     0    0   15  119    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   36   32    1    0
     0   19  101   31    0
     0    2   30   70    0
     0    0    0    1    0
[epoch 14] step 2/44: loss=0.1370 
[epoch 14] step 4/44: loss=0.1333 
[epoch 14] step 6/44: loss=0.1309 
[epoch 14] step 8/44: loss=0.1312 
[epoch 14] step 10/44: loss=0.1340 
[epoch 14] step 12/44: loss=0.1373 
[epoch 14] step 14/44: loss=0.1379 
[epoch 14] step 16/44: loss=0.1397 
[epoch 14] step 18/44: loss=0.1414 
[epoch 14] step 20/44: loss=0.1415 
[epoch 14] step 22/44: loss=0.1367 
[epoch 14] step 24/44: loss=0.1371 
[epoch 14] step 26/44: loss=0.1360 
[epoch 14] step 28/44: loss=0.1357 
[epoch 14] step 30/44: loss=0.1366 
[epoch 14] step 32/44: loss=0.1380 
[epoch 14] step 34/44: loss=0.1354 
[epoch 14] step 36/44: loss=0.1344 
[epoch 14] step 38/44: loss=0.1357 
[epoch 14] step 40/44: loss=0.1363 
[epoch 14] step 42/44: loss=0.1377 
[epoch 14] step 44/44: loss=0.1358 
[epoch 14] train_loss(avg per step)=0.2715 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=1.0101 qwk=('0.6128', '0.6031', '0.5750') averageQWK=0.5970 macroEMD=0.2065 tailR0=('0.1591', '0.0000', '0.0000') tailR0avg=0.0530
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   18   34    3    0
     0    9   89   23    5
     0    1   31   76    8
     0    0    1   14    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   17   30    6    0
     0    4   83   32    0
     0    0   24  110    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   39   29    1    0
     0   25  109   17    0
     0    2   50   50    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=0.1325 
[epoch 15] step 4/44: loss=0.1444 
[epoch 15] step 6/44: loss=0.1349 
[epoch 15] step 8/44: loss=0.1220 
[epoch 15] step 10/44: loss=0.1260 
[epoch 15] step 12/44: loss=0.1267 
[epoch 15] step 14/44: loss=0.1296 
[epoch 15] step 16/44: loss=0.1349 
[epoch 15] step 18/44: loss=0.1381 
[epoch 15] step 20/44: loss=0.1350 
[epoch 15] step 22/44: loss=0.1340 
[epoch 15] step 24/44: loss=0.1361 
[epoch 15] step 26/44: loss=0.1367 
[epoch 15] step 28/44: loss=0.1329 
[epoch 15] step 30/44: loss=0.1331 
[epoch 15] step 32/44: loss=0.1323 
[epoch 15] step 34/44: loss=0.1313 
[epoch 15] step 36/44: loss=0.1303 
[epoch 15] step 38/44: loss=0.1278 
[epoch 15] step 40/44: loss=0.1257 
[epoch 15] step 42/44: loss=0.1223 
[epoch 15] step 44/44: loss=0.1172 
[epoch 15] train_loss(avg per step)=0.2344 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=1.0389 qwk=('0.6001', '0.6110', '0.5948') averageQWK=0.6020 macroEMD=0.2033 tailR0=('0.0682', '0.0833', '0.0000') tailR0avg=0.0505
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     1   20   27    7    0
     0    8   75   39    4
     0    0   19   94    3
     0    0    1   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   15   31    7    0
     0    5   82   32    0
     0    0   22  112    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   37    1    0
     0   16  112   23    0
     0    2   37   63    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=0.0827 
[epoch 16] step 4/44: loss=0.0670 
[epoch 16] step 6/44: loss=0.0819 
[epoch 16] step 8/44: loss=0.0817 
[epoch 16] step 10/44: loss=0.0730 
[epoch 16] step 12/44: loss=0.0707 
[epoch 16] step 14/44: loss=0.0779 
[epoch 16] step 16/44: loss=0.0754 
[epoch 16] step 18/44: loss=0.0687 
[epoch 16] step 20/44: loss=0.0682 
[epoch 16] step 22/44: loss=0.0675 
[epoch 16] step 24/44: loss=0.0687 
[epoch 16] step 26/44: loss=0.0653 
[epoch 16] step 28/44: loss=0.0646 
[epoch 16] step 30/44: loss=0.0680 
[epoch 16] step 32/44: loss=0.0662 
[epoch 16] step 34/44: loss=0.0702 
[epoch 16] step 36/44: loss=0.0718 
[epoch 16] step 38/44: loss=0.0727 
[epoch 16] step 40/44: loss=0.0728 
[epoch 16] step 42/44: loss=0.0741 
[epoch 16] step 44/44: loss=0.0720 
[epoch 16] train_loss(avg per step)=0.1439 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=1.0386 qwk=('0.6303', '0.5986', '0.5741') averageQWK=0.6010 macroEMD=0.2080 tailR0=('0.1237', '0.0833', '0.0000') tailR0avg=0.0690
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    0    1    0
     1   23   28    3    0
     0   19   86   21    0
     0    2   33   80    1
     0    0    3   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   18   29    6    0
     0   14   82   23    0
     0    2   30  102    0
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   37    0    0
     0   24  106   21    0
     0    2   43   57    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=0.0645 
[epoch 17] step 4/44: loss=0.0643 
[epoch 17] step 6/44: loss=0.0635 
[epoch 17] step 8/44: loss=0.0515 
[epoch 17] step 10/44: loss=0.0498 
[epoch 17] step 12/44: loss=0.0416 
[epoch 17] step 14/44: loss=0.0429 
[epoch 17] step 16/44: loss=0.0432 
[epoch 17] step 18/44: loss=0.0434 
[epoch 17] step 20/44: loss=0.0429 
[epoch 17] step 22/44: loss=0.0423 
[epoch 17] step 24/44: loss=0.0426 
[epoch 17] step 26/44: loss=0.0419 
[epoch 17] step 28/44: loss=0.0407 
[epoch 17] step 30/44: loss=0.0405 
[epoch 17] step 32/44: loss=0.0415 
[epoch 17] step 34/44: loss=0.0417 
[epoch 17] step 36/44: loss=0.0424 
[epoch 17] step 38/44: loss=0.0429 
[epoch 17] step 40/44: loss=0.0432 
[epoch 17] step 42/44: loss=0.0458 
[epoch 17] step 44/44: loss=0.0449 
[epoch 17] train_loss(avg per step)=0.0898 lambda[min,max]=[0.498279,1.000000]
[epoch 17] val_loss=1.0750 qwk=('0.6105', '0.5793', '0.6002') averageQWK=0.5967 macroEMD=0.2083 tailR0=('0.0455', '0.0417', '0.0000') tailR0avg=0.0290
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   20   28    7    0
     0   12   77   35    2
     0    0   21   94    1
     0    0    1   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   17   29    7    0
     0    9   83   27    0
     0    1   30  103    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   36   32    1    0
     0   20  107   24    0
     0    2   39   61    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=-0.0159 
[epoch 18] step 4/44: loss=0.0129 
[epoch 18] step 6/44: loss=0.0215 
[epoch 18] step 8/44: loss=0.0310 
[epoch 18] step 10/44: loss=0.0319 
[epoch 18] step 12/44: loss=0.0317 
[epoch 18] step 14/44: loss=0.0309 
[epoch 18] step 16/44: loss=0.0271 
[epoch 18] step 18/44: loss=0.0251 
[epoch 18] step 20/44: loss=0.0253 
[epoch 18] step 22/44: loss=0.0242 
[epoch 18] step 24/44: loss=0.0221 
[epoch 18] step 26/44: loss=0.0204 
[epoch 18] step 28/44: loss=0.0223 
[epoch 18] step 30/44: loss=0.0242 
[epoch 18] step 32/44: loss=0.0235 
[epoch 18] step 34/44: loss=0.0238 
[epoch 18] step 36/44: loss=0.0268 
[epoch 18] step 38/44: loss=0.0251 
[epoch 18] step 40/44: loss=0.0265 
[epoch 18] step 42/44: loss=0.0279 
[epoch 18] step 44/44: loss=0.0275 
[epoch 18] train_loss(avg per step)=0.0551 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=1.0789 qwk=('0.6174', '0.5846', '0.6075') averageQWK=0.6032 macroEMD=0.2074 tailR0=('0.1818', '0.0833', '0.0000') tailR0avg=0.0884
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   18   34    3    0
     0    9   94   17    6
     0    0   40   67    9
     0    0    2   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    0    0
     0   12   39    2    0
     0    0   96   22    1
     0    0   37   91    6
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   37   30    2    0
     0   23  104   24    0
     0    2   35   65    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=0.0353 
[epoch 19] step 4/44: loss=0.0404 
[epoch 19] step 6/44: loss=0.0259 
[epoch 19] step 8/44: loss=0.0190 
[epoch 19] step 10/44: loss=0.0119 
[epoch 19] step 12/44: loss=0.0079 
[epoch 19] step 14/44: loss=0.0090 
[epoch 19] step 16/44: loss=0.0087 
[epoch 19] step 18/44: loss=0.0074 
[epoch 19] step 20/44: loss=0.0043 
[epoch 19] step 22/44: loss=0.0072 
[epoch 19] step 24/44: loss=0.0052 
[epoch 19] step 26/44: loss=0.0050 
[epoch 19] step 28/44: loss=0.0026 
[epoch 19] step 30/44: loss=0.0017 
[epoch 19] step 32/44: loss=0.0037 
[epoch 19] step 34/44: loss=0.0037 
[epoch 19] step 36/44: loss=0.0036 
[epoch 19] step 38/44: loss=0.0050 
[epoch 19] step 40/44: loss=0.0066 
[epoch 19] step 42/44: loss=0.0061 
[epoch 19] step 44/44: loss=0.0045 
[epoch 19] train_loss(avg per step)=0.0090 lambda[min,max]=[0.412149,1.000000]
[epoch 19] val_loss=1.1117 qwk=('0.6298', '0.5809', '0.5245') averageQWK=0.5784 macroEMD=0.2117 tailR0=('0.2374', '0.1333', '0.0000') tailR0avg=0.1236
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    1    0    0
     1   21   30    3    0
     0   15   86   20    5
     0    1   38   71    6
     0    0    2   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    1    0
     2   13   34    4    0
     0    7   89   23    0
     0    1   36   93    4
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   29   39    1    0
     0   17  119   15    0
     0    2   52   48    0
     0    0    1    0    0
[epoch 20] step 2/44: loss=-0.0283 
[epoch 20] step 4/44: loss=-0.0237 
[epoch 20] step 6/44: loss=-0.0222 
[epoch 20] step 8/44: loss=-0.0264 
[epoch 20] step 10/44: loss=-0.0232 
[epoch 20] step 12/44: loss=-0.0196 
[epoch 20] step 14/44: loss=-0.0205 
[epoch 20] step 16/44: loss=-0.0194 
[epoch 20] step 18/44: loss=-0.0162 
[epoch 20] step 20/44: loss=-0.0179 
[epoch 20] step 22/44: loss=-0.0184 
[epoch 20] step 24/44: loss=-0.0163 
[epoch 20] step 26/44: loss=-0.0140 
[epoch 20] step 28/44: loss=-0.0141 
[epoch 20] step 30/44: loss=-0.0133 
[epoch 20] step 32/44: loss=-0.0123 
[epoch 20] step 34/44: loss=-0.0127 
[epoch 20] step 36/44: loss=-0.0129 
[epoch 20] step 38/44: loss=-0.0139 
[epoch 20] step 40/44: loss=-0.0150 
[epoch 20] step 42/44: loss=-0.0155 
[epoch 20] step 44/44: loss=-0.0146 
[epoch 20] train_loss(avg per step)=-0.0292 lambda[min,max]=[0.417299,1.000000]
[epoch 20] val_loss=1.1153 qwk=('0.6140', '0.5927', '0.5901') averageQWK=0.5989 macroEMD=0.2041 tailR0=('0.2146', '0.0833', '0.0000') tailR0avg=0.0993
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    0    1    0
     2   17   31    5    0
     0   13   90   19    4
     0    0   37   73    6
     0    0    2   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   20   27    6    0
     0   11   85   23    0
     0    1   33   99    1
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   33    1    0
     0   17  119   15    0
     0    2   46   54    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=-0.0270 
[epoch 21] step 4/44: loss=-0.0229 
[epoch 21] step 6/44: loss=-0.0191 
[epoch 21] step 8/44: loss=-0.0165 
[epoch 21] step 10/44: loss=-0.0148 
[epoch 21] step 12/44: loss=-0.0202 
[epoch 21] step 14/44: loss=-0.0235 
[epoch 21] step 16/44: loss=-0.0268 
[epoch 21] step 18/44: loss=-0.0285 
[epoch 21] step 20/44: loss=-0.0263 
[epoch 21] step 22/44: loss=-0.0288 
[epoch 21] step 24/44: loss=-0.0295 
[epoch 21] step 26/44: loss=-0.0310 
[epoch 21] step 28/44: loss=-0.0312 
[epoch 21] step 30/44: loss=-0.0324 
[epoch 21] step 32/44: loss=-0.0341 
[epoch 21] step 34/44: loss=-0.0342 
[epoch 21] step 36/44: loss=-0.0339 
[epoch 21] step 38/44: loss=-0.0341 
[epoch 21] step 40/44: loss=-0.0339 
[epoch 21] step 42/44: loss=-0.0338 
[epoch 21] step 44/44: loss=-0.0322 
[epoch 21] train_loss(avg per step)=-0.0645 lambda[min,max]=[0.409745,1.000000]
[epoch 21] val_loss=1.1430 qwk=('0.6233', '0.5790', '0.5999') averageQWK=0.6007 macroEMD=0.2031 tailR0=('0.1818', '0.0833', '0.0000') tailR0avg=0.0884
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   18   31    6    0
     0   10   88   23    5
     0    0   27   80    9
     0    0    1   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     0   17   31    5    0
     0   10   87   22    0
     0    2   28   99    5
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   30   37    2    0
     0   14  107   30    0
     0    2   30   70    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=-0.0558 
[epoch 22] step 4/44: loss=-0.0475 
[epoch 22] step 6/44: loss=-0.0421 
[epoch 22] step 8/44: loss=-0.0442 
[epoch 22] step 10/44: loss=-0.0468 
[epoch 22] step 12/44: loss=-0.0432 
[epoch 22] step 14/44: loss=-0.0456 
[epoch 22] step 16/44: loss=-0.0469 
[epoch 22] step 18/44: loss=-0.0470 
[epoch 22] step 20/44: loss=-0.0479 
[epoch 22] step 22/44: loss=-0.0500 
[epoch 22] step 24/44: loss=-0.0492 
[epoch 22] step 26/44: loss=-0.0496 
[epoch 22] step 28/44: loss=-0.0484 
[epoch 22] step 30/44: loss=-0.0481 
[epoch 22] step 32/44: loss=-0.0451 
[epoch 22] step 34/44: loss=-0.0446 
[epoch 22] step 36/44: loss=-0.0451 
[epoch 22] step 38/44: loss=-0.0463 
[epoch 22] step 40/44: loss=-0.0456 
[epoch 22] step 42/44: loss=-0.0457 
[epoch 22] step 44/44: loss=-0.0429 
[epoch 22] train_loss(avg per step)=-0.0859 lambda[min,max]=[0.456357,1.000000]
[epoch 22] val_loss=1.1469 qwk=('0.6383', '0.5641', '0.5762') averageQWK=0.5928 macroEMD=0.2015 tailR0=('0.0909', '0.0417', '0.0000') tailR0avg=0.0442
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   21   30    4    0
     0    9   93   20    4
     0    0   33   80    3
     0    0    1   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     0   19   27    7    0
     0   12   79   28    0
     0    0   28  104    2
     0    0    3    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   36    2    0
     0   23  103   25    0
     0    2   36   64    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=-0.0557 
[epoch 23] step 4/44: loss=-0.0497 
[epoch 23] step 6/44: loss=-0.0497 
[epoch 23] step 8/44: loss=-0.0495 
[epoch 23] step 10/44: loss=-0.0477 
[epoch 23] step 12/44: loss=-0.0478 
[epoch 23] step 14/44: loss=-0.0490 
[epoch 23] step 16/44: loss=-0.0519 
[epoch 23] step 18/44: loss=-0.0537 
[epoch 23] step 20/44: loss=-0.0531 
[epoch 23] step 22/44: loss=-0.0544 
[epoch 23] step 24/44: loss=-0.0549 
[epoch 23] step 26/44: loss=-0.0554 
[epoch 23] step 28/44: loss=-0.0548 
[epoch 23] step 30/44: loss=-0.0553 
[epoch 23] step 32/44: loss=-0.0549 
[epoch 23] step 34/44: loss=-0.0553 
[epoch 23] step 36/44: loss=-0.0553 
[epoch 23] step 38/44: loss=-0.0553 
[epoch 23] step 40/44: loss=-0.0559 
[epoch 23] step 42/44: loss=-0.0565 
[epoch 23] step 44/44: loss=-0.0581 
[epoch 23] train_loss(avg per step)=-0.1161 lambda[min,max]=[0.440989,1.000000]
[epoch 23] val_loss=1.1738 qwk=('0.5859', '0.5621', '0.5890') averageQWK=0.5790 macroEMD=0.2031 tailR0=('0.1364', '0.1333', '0.0000') tailR0avg=0.0899
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   12   37    6    0
     0    5   92   24    5
     0    0   31   79    6
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    2    0
     3   15   25   10    0
     0    9   73   37    0
     0    1   19  111    3
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   34   32    3    0
     0   22  101   28    0
     0    2   33   67    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=-0.0855 
[epoch 24] step 4/44: loss=-0.0775 
[epoch 24] step 6/44: loss=-0.0732 
[epoch 24] step 8/44: loss=-0.0711 
[epoch 24] step 10/44: loss=-0.0692 
[epoch 24] step 12/44: loss=-0.0691 
[epoch 24] step 14/44: loss=-0.0696 
[epoch 24] step 16/44: loss=-0.0688 
[epoch 24] step 18/44: loss=-0.0701 
[epoch 24] step 20/44: loss=-0.0702 
[epoch 24] step 22/44: loss=-0.0690 
[epoch 24] step 24/44: loss=-0.0698 
[epoch 24] step 26/44: loss=-0.0693 
[epoch 24] step 28/44: loss=-0.0706 
[epoch 24] step 30/44: loss=-0.0706 
[epoch 24] step 32/44: loss=-0.0699 
[epoch 24] step 34/44: loss=-0.0689 
[epoch 24] step 36/44: loss=-0.0676 
[epoch 24] step 38/44: loss=-0.0680 
[epoch 24] step 40/44: loss=-0.0670 
[epoch 24] step 42/44: loss=-0.0669 
[epoch 24] step 44/44: loss=-0.0669 
[epoch 24] train_loss(avg per step)=-0.1338 lambda[min,max]=[0.443761,1.000000]
[epoch 24] val_loss=1.2229 qwk=('0.6216', '0.5607', '0.5886') averageQWK=0.5903 macroEMD=0.2004 tailR0=('0.2045', '0.0417', '0.0000') tailR0avg=0.0821
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   20   30    5    0
     0   13   83   24    6
     0    0   30   74   12
     0    0    1   12    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     1   16   30    6    0
     0   10   84   25    0
     0    2   26  101    5
     0    0    3    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   33   34    2    0
     0   21  102   27    1
     0    2   33   67    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=-0.0784 
[epoch 25] step 4/44: loss=-0.0806 
[epoch 25] step 6/44: loss=-0.0765 
[epoch 25] step 8/44: loss=-0.0741 
[epoch 25] step 10/44: loss=-0.0738 
[epoch 25] step 12/44: loss=-0.0770 
[epoch 25] step 14/44: loss=-0.0763 
[epoch 25] step 16/44: loss=-0.0766 
[epoch 25] step 18/44: loss=-0.0776 
[epoch 25] step 20/44: loss=-0.0784 
[epoch 25] step 22/44: loss=-0.0782 
[epoch 25] step 24/44: loss=-0.0786 
[epoch 25] step 26/44: loss=-0.0792 
[epoch 25] step 28/44: loss=-0.0788 
[epoch 25] step 30/44: loss=-0.0790 
[epoch 25] step 32/44: loss=-0.0793 
[epoch 25] step 34/44: loss=-0.0778 
[epoch 25] step 36/44: loss=-0.0784 
[epoch 25] step 38/44: loss=-0.0781 
[epoch 25] step 40/44: loss=-0.0774 
[epoch 25] step 42/44: loss=-0.0773 
[epoch 25] step 44/44: loss=-0.0768 
[epoch 25] train_loss(avg per step)=-0.1535 lambda[min,max]=[0.375753,1.000000]
[epoch 25] val_loss=1.2254 qwk=('0.6334', '0.5774', '0.5790') averageQWK=0.5966 macroEMD=0.1967 tailR0=('0.2475', '0.0417', '0.0000') tailR0avg=0.0964
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    0    1    0
     2   19   29    5    0
     0   13   80   28    5
     0    0   26   83    7
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     3   17   26    7    0
     0   16   78   24    1
     0    1   25  104    4
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   33    4    0
     0   19   95   36    1
     0    2   27   73    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=-0.0874 
[epoch 26] step 4/44: loss=-0.0876 
[epoch 26] step 6/44: loss=-0.0846 
[epoch 26] step 8/44: loss=-0.0850 
[epoch 26] step 10/44: loss=-0.0853 
[epoch 26] step 12/44: loss=-0.0841 
[epoch 26] step 14/44: loss=-0.0825 
[epoch 26] step 16/44: loss=-0.0814 
[epoch 26] step 18/44: loss=-0.0826 
[epoch 26] step 20/44: loss=-0.0835 
[epoch 26] step 22/44: loss=-0.0827 
[epoch 26] step 24/44: loss=-0.0822 
[epoch 26] step 26/44: loss=-0.0819 
[epoch 26] step 28/44: loss=-0.0815 
[epoch 26] step 30/44: loss=-0.0807 
[epoch 26] step 32/44: loss=-0.0803 
[epoch 26] step 34/44: loss=-0.0803 
[epoch 26] step 36/44: loss=-0.0806 
[epoch 26] step 38/44: loss=-0.0788 
[epoch 26] step 40/44: loss=-0.0785 
[epoch 26] step 42/44: loss=-0.0787 
[epoch 26] step 44/44: loss=-0.0782 
[epoch 26] train_loss(avg per step)=-0.1564 lambda[min,max]=[0.388506,1.000000]
[epoch 26] val_loss=1.2500 qwk=('0.6037', '0.5613', '0.5996') averageQWK=0.5882 macroEMD=0.2010 tailR0=('0.2702', '0.0917', '0.0000') tailR0avg=0.1206
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    0    1    0
     2   14   34    5    0
     0   10   90   22    4
     0    0   38   74    4
     0    0    2   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    2    0
     3   16   23   11    0
     0   14   70   35    0
     0    1   17  112    4
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   36   31    2    0
     0   23  100   28    0
     0    2   34   66    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=-0.0847 
[epoch 27] step 4/44: loss=-0.0806 
[epoch 27] step 6/44: loss=-0.0849 
[epoch 27] step 8/44: loss=-0.0853 
[epoch 27] step 10/44: loss=-0.0853 
[epoch 27] step 12/44: loss=-0.0849 
[epoch 27] step 14/44: loss=-0.0857 
[epoch 27] step 16/44: loss=-0.0848 
[epoch 27] step 18/44: loss=-0.0844 
[epoch 27] step 20/44: loss=-0.0848 
[epoch 27] step 22/44: loss=-0.0849 
[epoch 27] step 24/44: loss=-0.0859 
[epoch 27] step 26/44: loss=-0.0855 
[epoch 27] step 28/44: loss=-0.0852 
[epoch 27] step 30/44: loss=-0.0849 
[epoch 27] step 32/44: loss=-0.0842 
[epoch 27] step 34/44: loss=-0.0839 
[epoch 27] step 36/44: loss=-0.0842 
[epoch 27] step 38/44: loss=-0.0842 
[epoch 27] step 40/44: loss=-0.0850 
[epoch 27] step 42/44: loss=-0.0854 
[epoch 27] step 44/44: loss=-0.0857 
[epoch 27] train_loss(avg per step)=-0.1714 lambda[min,max]=[0.346200,1.000000]
[epoch 27] val_loss=1.2299 qwk=('0.6355', '0.5839', '0.5899') averageQWK=0.6031 macroEMD=0.1959 tailR0=('0.0909', '0.0000', '0.0000') tailR0avg=0.0303
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     1   22   27    5    0
     0   11   86   26    3
     0    0   28   86    2
     0    0    1   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   21   26    6    0
     0   12   84   23    0
     0    1   31  101    1
     0    0    3    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   30   37    2    0
     0   15  114   22    0
     0    2   36   64    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=-0.0826 
[epoch 28] step 4/44: loss=-0.0830 
[epoch 28] step 6/44: loss=-0.0850 
[epoch 28] step 8/44: loss=-0.0822 
[epoch 28] step 10/44: loss=-0.0789 
[epoch 28] step 12/44: loss=-0.0792 
[epoch 28] step 14/44: loss=-0.0805 
[epoch 28] step 16/44: loss=-0.0802 
[epoch 28] step 18/44: loss=-0.0812 
[epoch 28] step 20/44: loss=-0.0816 
[epoch 28] step 22/44: loss=-0.0824 
[epoch 28] step 24/44: loss=-0.0835 
[epoch 28] step 26/44: loss=-0.0838 
[epoch 28] step 28/44: loss=-0.0838 
[epoch 28] step 30/44: loss=-0.0835 
[epoch 28] step 32/44: loss=-0.0832 
[epoch 28] step 34/44: loss=-0.0838 
[epoch 28] step 36/44: loss=-0.0846 
[epoch 28] step 38/44: loss=-0.0850 
[epoch 28] step 40/44: loss=-0.0853 
[epoch 28] step 42/44: loss=-0.0860 
[epoch 28] step 44/44: loss=-0.0860 
[epoch 28] train_loss(avg per step)=-0.1720 lambda[min,max]=[0.352511,1.000000]
[epoch 28] val_loss=1.2368 qwk=('0.6264', '0.5763', '0.5838') averageQWK=0.5955 macroEMD=0.1975 tailR0=('0.3030', '0.0500', '0.0000') tailR0avg=0.1177
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    5    0    1    0
     3   16   31    5    0
     0   12   87   23    4
     0    0   35   77    4
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    1    0
     2   16   29    6    0
     0   11   84   24    0
     0    1   29  102    2
     0    0    3    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   35    2    0
     0   18  112   21    0
     0    2   39   61    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=-0.0981 
[epoch 29] step 4/44: loss=-0.0947 
[epoch 29] step 6/44: loss=-0.0924 
[epoch 29] step 8/44: loss=-0.0942 
[epoch 29] step 10/44: loss=-0.0929 
[epoch 29] step 12/44: loss=-0.0934 
[epoch 29] step 14/44: loss=-0.0936 
[epoch 29] step 16/44: loss=-0.0925 
[epoch 29] step 18/44: loss=-0.0930 
[epoch 29] step 20/44: loss=-0.0916 
[epoch 29] step 22/44: loss=-0.0913 
[epoch 29] step 24/44: loss=-0.0917 
[epoch 29] step 26/44: loss=-0.0920 
[epoch 29] step 28/44: loss=-0.0925 
[epoch 29] step 30/44: loss=-0.0924 
[epoch 29] step 32/44: loss=-0.0924 
[epoch 29] step 34/44: loss=-0.0919 
[epoch 29] step 36/44: loss=-0.0925 
[epoch 29] step 38/44: loss=-0.0924 
[epoch 29] step 40/44: loss=-0.0924 
[epoch 29] step 42/44: loss=-0.0926 
[epoch 29] step 44/44: loss=-0.0929 
[epoch 29] train_loss(avg per step)=-0.1859 lambda[min,max]=[0.415740,1.000000]
[epoch 29] val_loss=1.2727 qwk=('0.5978', '0.5535', '0.5560') averageQWK=0.5691 macroEMD=0.2004 tailR0=('0.1136', '0.0417', '0.0000') tailR0avg=0.0518
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   15   35    5    0
     0   10   83   28    5
     0    0   27   83    6
     0    0    1   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    2    0
     2   16   28    7    0
     0    8   79   31    1
     0    1   24  105    4
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   24   42    3    0
     0   15  106   30    0
     0    2   32   68    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=-0.0985 
[epoch 30] step 4/44: loss=-0.0917 
[epoch 30] step 6/44: loss=-0.0901 
[epoch 30] step 8/44: loss=-0.0926 
[epoch 30] step 10/44: loss=-0.0926 
[epoch 30] step 12/44: loss=-0.0940 
[epoch 30] step 14/44: loss=-0.0942 
[epoch 30] step 16/44: loss=-0.0953 
[epoch 30] step 18/44: loss=-0.0951 
[epoch 30] step 20/44: loss=-0.0955 
[epoch 30] step 22/44: loss=-0.0958 
[epoch 30] step 24/44: loss=-0.0957 
[epoch 30] step 26/44: loss=-0.0958 
[epoch 30] step 28/44: loss=-0.0962 
[epoch 30] step 30/44: loss=-0.0960 
[epoch 30] step 32/44: loss=-0.0965 
[epoch 30] step 34/44: loss=-0.0962 
[epoch 30] step 36/44: loss=-0.0963 
[epoch 30] step 38/44: loss=-0.0964 
[epoch 30] step 40/44: loss=-0.0965 
[epoch 30] step 42/44: loss=-0.0963 
[epoch 30] step 44/44: loss=-0.0965 
[epoch 30] train_loss(avg per step)=-0.1931 lambda[min,max]=[0.425447,1.000000]
[epoch 30] val_loss=1.2745 qwk=('0.6032', '0.5681', '0.5582') averageQWK=0.5765 macroEMD=0.2004 tailR0=('0.1136', '0.0417', '0.0000') tailR0avg=0.0518
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   19   31    5    0
     0   12   81   27    6
     0    0   28   84    4
     0    0    1   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     0   18   29    6    0
     0    9   87   23    0
     0    1   29   98    6
     0    0    3    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   25   42    2    0
     0   14  114   23    0
     0    2   38   62    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=-0.0891 
[epoch 31] step 4/44: loss=-0.0942 
[epoch 31] step 6/44: loss=-0.0965 
[epoch 31] step 8/44: loss=-0.0956 
[epoch 31] step 10/44: loss=-0.0974 
[epoch 31] step 12/44: loss=-0.0966 
[epoch 31] step 14/44: loss=-0.0963 
[epoch 31] step 16/44: loss=-0.0969 
[epoch 31] step 18/44: loss=-0.0960 
[epoch 31] step 20/44: loss=-0.0963 
[epoch 31] step 22/44: loss=-0.0970 
[epoch 31] step 24/44: loss=-0.0968 
[epoch 31] step 26/44: loss=-0.0976 
[epoch 31] step 28/44: loss=-0.0979 
[epoch 31] step 30/44: loss=-0.0981 
[epoch 31] step 32/44: loss=-0.0981 
[epoch 31] step 34/44: loss=-0.0979 
[epoch 31] step 36/44: loss=-0.0982 
[epoch 31] step 38/44: loss=-0.0983 
[epoch 31] step 40/44: loss=-0.0986 
[epoch 31] step 42/44: loss=-0.0985 
[epoch 31] step 44/44: loss=-0.0983 
[epoch 31] train_loss(avg per step)=-0.1967 lambda[min,max]=[0.397901,1.000000]
[epoch 31] val_loss=1.2655 qwk=('0.6077', '0.5688', '0.5975') averageQWK=0.5914 macroEMD=0.1972 tailR0=('0.1591', '0.0417', '0.0000') tailR0avg=0.0669
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     1   19   30    5    0
     0   13   89   18    6
     0    0   37   71    8
     0    0    1   14    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     0   19   28    6    0
     0   11   81   26    1
     0    2   25  102    5
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   36   31    2    0
     0   23  105   23    0
     0    2   37   63    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=-0.1048 
[epoch 32] step 4/44: loss=-0.1029 
[epoch 32] step 6/44: loss=-0.0989 
[epoch 32] step 8/44: loss=-0.0999 
[epoch 32] step 10/44: loss=-0.1003 
[epoch 32] step 12/44: loss=-0.1003 
[epoch 32] step 14/44: loss=-0.0992 
[epoch 32] step 16/44: loss=-0.0991 
[epoch 32] step 18/44: loss=-0.0981 
[epoch 32] step 20/44: loss=-0.0982 
[epoch 32] step 22/44: loss=-0.0983 
[epoch 32] step 24/44: loss=-0.0988 
[epoch 32] step 26/44: loss=-0.0996 
[epoch 32] step 28/44: loss=-0.0998 
[epoch 32] step 30/44: loss=-0.1002 
[epoch 32] step 32/44: loss=-0.1003 
[epoch 32] step 34/44: loss=-0.1003 
[epoch 32] step 36/44: loss=-0.1005 
[epoch 32] step 38/44: loss=-0.1004 
[epoch 32] step 40/44: loss=-0.1001 
[epoch 32] step 42/44: loss=-0.1001 
[epoch 32] step 44/44: loss=-0.1002 
[epoch 32] train_loss(avg per step)=-0.2003 lambda[min,max]=[0.456360,1.000000]
[epoch 32] val_loss=1.2773 qwk=('0.5945', '0.5480', '0.5860') averageQWK=0.5762 macroEMD=0.1976 tailR0=('0.1364', '0.0417', '0.0000') tailR0avg=0.0593
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   15   35    5    0
     0   10   90   20    6
     0    0   33   78    5
     0    0    1   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    2    0
     0   18   27    8    0
     0   12   76   31    0
     0    2   21  106    5
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   36    2    0
     0   18  105   28    0
     0    2   34   66    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=-0.1064 
[epoch 33] step 4/44: loss=-0.1075 
[epoch 33] step 6/44: loss=-0.1076 
[epoch 33] step 8/44: loss=-0.1071 
[epoch 33] step 10/44: loss=-0.1064 
[epoch 33] step 12/44: loss=-0.1039 
[epoch 33] step 14/44: loss=-0.1038 
[epoch 33] step 16/44: loss=-0.1033 
[epoch 33] step 18/44: loss=-0.1030 
[epoch 33] step 20/44: loss=-0.1029 
[epoch 33] step 22/44: loss=-0.1032 
[epoch 33] step 24/44: loss=-0.1036 
[epoch 33] step 26/44: loss=-0.1032 
[epoch 33] step 28/44: loss=-0.1030 
[epoch 33] step 30/44: loss=-0.1031 
[epoch 33] step 32/44: loss=-0.1031 
[epoch 33] step 34/44: loss=-0.1021 
[epoch 33] step 36/44: loss=-0.1020 
[epoch 33] step 38/44: loss=-0.1020 
[epoch 33] step 40/44: loss=-0.1021 
[epoch 33] step 42/44: loss=-0.1020 
[epoch 33] step 44/44: loss=-0.1017 
[epoch 33] train_loss(avg per step)=-0.2034 lambda[min,max]=[0.434870,1.000000]
[epoch 33] val_loss=1.2761 qwk=('0.6183', '0.5692', '0.5992') averageQWK=0.5956 macroEMD=0.1949 tailR0=('0.1136', '0.1417', '0.0000') tailR0avg=0.0851
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     1   20   29    5    0
     0   13   84   25    4
     0    0   31   81    4
     0    0    1   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    2    0
     1   17   26    9    0
     0   12   75   32    0
     0    1   21  110    2
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   35   32    2    0
     0   23  102   26    0
     0    2   34   66    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=-0.1026 
[epoch 34] step 4/44: loss=-0.1033 
[epoch 34] step 6/44: loss=-0.1014 
[epoch 34] step 8/44: loss=-0.1026 
[epoch 34] step 10/44: loss=-0.1031 
[epoch 34] step 12/44: loss=-0.1041 
[epoch 34] step 14/44: loss=-0.1035 
[epoch 34] step 16/44: loss=-0.1035 
[epoch 34] step 18/44: loss=-0.1038 
[epoch 34] step 20/44: loss=-0.1034 
[epoch 34] step 22/44: loss=-0.1036 
[epoch 34] step 24/44: loss=-0.1036 
[epoch 34] step 26/44: loss=-0.1035 
[epoch 34] step 28/44: loss=-0.1036 
[epoch 34] step 30/44: loss=-0.1035 
[epoch 34] step 32/44: loss=-0.1033 
[epoch 34] step 34/44: loss=-0.1028 
[epoch 34] step 36/44: loss=-0.1029 
[epoch 34] step 38/44: loss=-0.1028 
[epoch 34] step 40/44: loss=-0.1026 
[epoch 34] step 42/44: loss=-0.1028 
[epoch 34] step 44/44: loss=-0.1025 
[epoch 34] train_loss(avg per step)=-0.2050 lambda[min,max]=[0.354791,1.000000]
[epoch 34] val_loss=1.2833 qwk=('0.6080', '0.5621', '0.5684') averageQWK=0.5795 macroEMD=0.1966 tailR0=('0.1136', '0.0417', '0.0000') tailR0avg=0.0518
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     0   18   32    5    0
     0   13   83   26    4
     0    0   30   84    2
     0    0    1   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    2    0
     1   17   27    8    0
     0   12   77   30    0
     0    1   23  107    3
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   36    2    0
     0   21  110   20    0
     0    2   41   59    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=-0.1044 
[epoch 35] step 4/44: loss=-0.1056 
[epoch 35] step 6/44: loss=-0.1035 
[epoch 35] step 8/44: loss=-0.1037 
[epoch 35] step 10/44: loss=-0.1029 
[epoch 35] step 12/44: loss=-0.1031 
[epoch 35] step 14/44: loss=-0.1036 
[epoch 35] step 16/44: loss=-0.1036 
[epoch 35] step 18/44: loss=-0.1036 
[epoch 35] step 20/44: loss=-0.1039 
[epoch 35] step 22/44: loss=-0.1039 
[epoch 35] step 24/44: loss=-0.1034 
[epoch 35] step 26/44: loss=-0.1034 
[epoch 35] step 28/44: loss=-0.1037 
[epoch 35] step 30/44: loss=-0.1038 
[epoch 35] step 32/44: loss=-0.1036 
[epoch 35] step 34/44: loss=-0.1038 
[epoch 35] step 36/44: loss=-0.1036 
[epoch 35] step 38/44: loss=-0.1038 
[epoch 35] step 40/44: loss=-0.1035 
[epoch 35] step 42/44: loss=-0.1035 
[epoch 35] step 44/44: loss=-0.1036 
[epoch 35] train_loss(avg per step)=-0.2071 lambda[min,max]=[0.382021,1.000000]
[epoch 35] val_loss=1.2831 qwk=('0.6105', '0.5583', '0.5830') averageQWK=0.5839 macroEMD=0.1966 tailR0=('0.1136', '0.0417', '0.0000') tailR0avg=0.0518
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    1    0
     1   18   31    5    0
     0   13   82   27    4
     0    0   30   83    3
     0    0    1   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    2    0
     2   16   27    8    0
     0   10   80   29    0
     0    1   23  106    4
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   36    2    0
     0   21  107   23    0
     0    2   36   64    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold3/metrics.json
Done.
