[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.7657 
[epoch 1] step 4/44: loss=0.7409 
[epoch 1] step 6/44: loss=0.7273 
[epoch 1] step 8/44: loss=0.7186 
[epoch 1] step 10/44: loss=0.7143 
[epoch 1] step 12/44: loss=0.7123 
[epoch 1] step 14/44: loss=0.7111 
[epoch 1] step 16/44: loss=0.7113 
[epoch 1] step 18/44: loss=0.7131 
[epoch 1] step 20/44: loss=0.7131 
[epoch 1] step 22/44: loss=0.7136 
[epoch 1] step 24/44: loss=0.7151 
[epoch 1] step 26/44: loss=0.7124 
[epoch 1] step 28/44: loss=0.7104 
[epoch 1] step 30/44: loss=0.7097 
[epoch 1] step 32/44: loss=0.7084 
[epoch 1] step 34/44: loss=0.7078 
[epoch 1] step 36/44: loss=0.7079 
[epoch 1] step 38/44: loss=0.7062 
[epoch 1] step 40/44: loss=0.7053 
[epoch 1] step 42/44: loss=0.7031 
[epoch 1] step 44/44: loss=0.7041 
[epoch 1] train_loss(avg per step)=1.4083 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.3123 qwk=('0.1005', '0.0668', '0.1135') averageQWK=0.0936 macroEMD=0.3738 tailR0=('0.0000', '0.1111', '0.2500') tailR0avg=0.1204
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    4    0
     0   20    0   35    0
     0   57    1   67    0
     0   41    7   68    0
     0    1    3   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    7    0    0
    19    0   32    1    0
    50    0   62    9    0
    44    0   67   23    0
     2    0    8    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    1
     0   27   40    1    1
     0   35  108    1    7
     0   26   66    1    8
     0    1    0    0    1
[epoch 2] step 2/44: loss=0.6903 
[epoch 2] step 4/44: loss=0.6663 
[epoch 2] step 6/44: loss=0.6719 
[epoch 2] step 8/44: loss=0.6699 
[epoch 2] step 10/44: loss=0.6722 
[epoch 2] step 12/44: loss=0.6627 
[epoch 2] step 14/44: loss=0.6608 
[epoch 2] step 16/44: loss=0.6579 
[epoch 2] step 18/44: loss=0.6540 
[epoch 2] step 20/44: loss=0.6531 
[epoch 2] step 22/44: loss=0.6525 
[epoch 2] step 24/44: loss=0.6500 
[epoch 2] step 26/44: loss=0.6480 
[epoch 2] step 28/44: loss=0.6463 
[epoch 2] step 30/44: loss=0.6441 
[epoch 2] step 32/44: loss=0.6416 
[epoch 2] step 34/44: loss=0.6388 
[epoch 2] step 36/44: loss=0.6340 
[epoch 2] step 38/44: loss=0.6320 
[epoch 2] step 40/44: loss=0.6316 
[epoch 2] step 42/44: loss=0.6282 
[epoch 2] step 44/44: loss=0.6261 
[epoch 2] train_loss(avg per step)=1.2523 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.1719 qwk=('0.3263', '0.4632', '0.3939') averageQWK=0.3945 macroEMD=0.3241 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   54    1    0
     0    0  102   23    0
     0    0   55   61    0
     0    0   12   11    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   48    4    0
     0    0   92   29    0
     0    0   31  103    0
     0    0    3    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   36   33    0    0
     0   34  113    4    0
     0    5   79   17    0
     0    0    1    1    0
[epoch 3] step 2/44: loss=0.5808 
[epoch 3] step 4/44: loss=0.5684 
[epoch 3] step 6/44: loss=0.5755 
[epoch 3] step 8/44: loss=0.5702 
[epoch 3] step 10/44: loss=0.5711 
[epoch 3] step 12/44: loss=0.5710 
[epoch 3] step 14/44: loss=0.5687 
[epoch 3] step 16/44: loss=0.5633 
[epoch 3] step 18/44: loss=0.5632 
[epoch 3] step 20/44: loss=0.5606 
[epoch 3] step 22/44: loss=0.5596 
[epoch 3] step 24/44: loss=0.5638 
[epoch 3] step 26/44: loss=0.5615 
[epoch 3] step 28/44: loss=0.5593 
[epoch 3] step 30/44: loss=0.5580 
[epoch 3] step 32/44: loss=0.5575 
[epoch 3] step 34/44: loss=0.5555 
[epoch 3] step 36/44: loss=0.5539 
[epoch 3] step 38/44: loss=0.5555 
[epoch 3] step 40/44: loss=0.5526 
[epoch 3] step 42/44: loss=0.5487 
[epoch 3] step 44/44: loss=0.5464 
[epoch 3] train_loss(avg per step)=1.0929 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=0.9364 qwk=('0.4535', '0.5780', '0.4967') averageQWK=0.5094 macroEMD=0.2706 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    0
     0    9   45    1    0
     0    2  110   13    0
     0    0   50   66    0
     0    0    9   14    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0    7   44    1    0
     0    4   91   26    0
     0    0   28  106    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   12   56    1    0
     0    5  123   23    0
     0    0   40   61    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=0.5227 
[epoch 4] step 4/44: loss=0.4601 
[epoch 4] step 6/44: loss=0.4725 
[epoch 4] step 8/44: loss=0.4804 
[epoch 4] step 10/44: loss=0.4817 
[epoch 4] step 12/44: loss=0.4874 
[epoch 4] step 14/44: loss=0.4892 
[epoch 4] step 16/44: loss=0.4960 
[epoch 4] step 18/44: loss=0.5015 
[epoch 4] step 20/44: loss=0.5017 
[epoch 4] step 22/44: loss=0.5039 
[epoch 4] step 24/44: loss=0.5089 
[epoch 4] step 26/44: loss=0.5124 
[epoch 4] step 28/44: loss=0.5129 
[epoch 4] step 30/44: loss=0.5094 
[epoch 4] step 32/44: loss=0.5090 
[epoch 4] step 34/44: loss=0.5087 
[epoch 4] step 36/44: loss=0.5084 
[epoch 4] step 38/44: loss=0.5107 
[epoch 4] step 40/44: loss=0.5119 
[epoch 4] step 42/44: loss=0.5122 
[epoch 4] step 44/44: loss=0.5095 
[epoch 4] train_loss(avg per step)=1.0191 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=0.9703 qwk=('0.4839', '0.5226', '0.5529') averageQWK=0.5198 macroEMD=0.2590 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    1   50    4    0
     0    1   94   30    0
     0    0   20   96    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    2   46    4    0
     0    1   80   40    0
     0    0   12  122    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0    9   59    1    0
     0    2  123   26    0
     0    0   27   74    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=0.5063 
[epoch 5] step 4/44: loss=0.5056 
[epoch 5] step 6/44: loss=0.4772 
[epoch 5] step 8/44: loss=0.4821 
[epoch 5] step 10/44: loss=0.4942 
[epoch 5] step 12/44: loss=0.4863 
[epoch 5] step 14/44: loss=0.4798 
[epoch 5] step 16/44: loss=0.4723 
[epoch 5] step 18/44: loss=0.4765 
[epoch 5] step 20/44: loss=0.4756 
[epoch 5] step 22/44: loss=0.4758 
[epoch 5] step 24/44: loss=0.4723 
[epoch 5] step 26/44: loss=0.4697 
[epoch 5] step 28/44: loss=0.4707 
[epoch 5] step 30/44: loss=0.4698 
[epoch 5] step 32/44: loss=0.4673 
[epoch 5] step 34/44: loss=0.4675 
[epoch 5] step 36/44: loss=0.4675 
[epoch 5] step 38/44: loss=0.4683 
[epoch 5] step 40/44: loss=0.4705 
[epoch 5] step 42/44: loss=0.4692 
[epoch 5] step 44/44: loss=0.4680 
[epoch 5] train_loss(avg per step)=0.9361 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=0.9592 qwk=('0.6515', '0.6318', '0.6332') averageQWK=0.6388 macroEMD=0.2367 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   41   14    0    0
     0   36   73   16    0
     0    0   38   78    0
     0    0    6   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   17   34    1    0
     0   12   90   19    0
     0    0   33  101    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   48   21    0    0
     0   46   92   13    0
     0    3   37   61    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=0.4252 
[epoch 6] step 4/44: loss=0.4029 
[epoch 6] step 6/44: loss=0.4090 
[epoch 6] step 8/44: loss=0.4182 
[epoch 6] step 10/44: loss=0.4263 
[epoch 6] step 12/44: loss=0.4201 
[epoch 6] step 14/44: loss=0.4280 
[epoch 6] step 16/44: loss=0.4308 
[epoch 6] step 18/44: loss=0.4323 
[epoch 6] step 20/44: loss=0.4301 
[epoch 6] step 22/44: loss=0.4306 
[epoch 6] step 24/44: loss=0.4333 
[epoch 6] step 26/44: loss=0.4329 
[epoch 6] step 28/44: loss=0.4345 
[epoch 6] step 30/44: loss=0.4381 
[epoch 6] step 32/44: loss=0.4427 
[epoch 6] step 34/44: loss=0.4464 
[epoch 6] step 36/44: loss=0.4425 
[epoch 6] step 38/44: loss=0.4401 
[epoch 6] step 40/44: loss=0.4379 
[epoch 6] step 42/44: loss=0.4419 
[epoch 6] step 44/44: loss=0.4456 
[epoch 6] train_loss(avg per step)=0.8912 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=1.1026 qwk=('0.5599', '0.6227', '0.5324') averageQWK=0.5717 macroEMD=0.2415 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   46    9    0    0
     0   58   59    8    0
     0    9   51   56    0
     0    2    6   15    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   38   14    0    0
     0   31   82    8    0
     0    2   56   76    0
     0    0    4    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   58   11    0    0
     0   79   68    4    0
     0   11   44   46    0
     0    0    1    1    0
[epoch 7] step 2/44: loss=0.5102 
[epoch 7] step 4/44: loss=0.4807 
[epoch 7] step 6/44: loss=0.4435 
[epoch 7] step 8/44: loss=0.4353 
[epoch 7] step 10/44: loss=0.4337 
[epoch 7] step 12/44: loss=0.4250 
[epoch 7] step 14/44: loss=0.4199 
[epoch 7] step 16/44: loss=0.4239 
[epoch 7] step 18/44: loss=0.4259 
[epoch 7] step 20/44: loss=0.4216 
[epoch 7] step 22/44: loss=0.4164 
[epoch 7] step 24/44: loss=0.4165 
[epoch 7] step 26/44: loss=0.4120 
[epoch 7] step 28/44: loss=0.4093 
[epoch 7] step 30/44: loss=0.4074 
[epoch 7] step 32/44: loss=0.4068 
[epoch 7] step 34/44: loss=0.4047 
[epoch 7] step 36/44: loss=0.4025 
[epoch 7] step 38/44: loss=0.4011 
[epoch 7] step 40/44: loss=0.4006 
[epoch 7] step 42/44: loss=0.3991 
[epoch 7] step 44/44: loss=0.3960 
[epoch 7] train_loss(avg per step)=0.7920 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=0.9069 qwk=('0.6321', '0.6782', '0.6710') averageQWK=0.6604 macroEMD=0.2212 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   31   22    1    1
     0   24   81   20    0
     0    0   28   87    1
     0    0    4   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   36   13    3    0
     0   28   66   27    0
     0    2   21  111    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   41   28    0    0
     0   28  110   13    0
     0    2   30   69    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=0.3012 
[epoch 8] step 4/44: loss=0.2988 
[epoch 8] step 6/44: loss=0.2885 
[epoch 8] step 8/44: loss=0.3201 
[epoch 8] step 10/44: loss=0.3243 
[epoch 8] step 12/44: loss=0.3301 
[epoch 8] step 14/44: loss=0.3334 
[epoch 8] step 16/44: loss=0.3356 
[epoch 8] step 18/44: loss=0.3361 
[epoch 8] step 20/44: loss=0.3362 
[epoch 8] step 22/44: loss=0.3402 
[epoch 8] step 24/44: loss=0.3388 
[epoch 8] step 26/44: loss=0.3366 
[epoch 8] step 28/44: loss=0.3397 
[epoch 8] step 30/44: loss=0.3396 
[epoch 8] step 32/44: loss=0.3412 
[epoch 8] step 34/44: loss=0.3378 
[epoch 8] step 36/44: loss=0.3365 
[epoch 8] step 38/44: loss=0.3354 
[epoch 8] step 40/44: loss=0.3355 
[epoch 8] step 42/44: loss=0.3358 
[epoch 8] step 44/44: loss=0.3405 
[epoch 8] train_loss(avg per step)=0.6811 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=0.9308 qwk=('0.6415', '0.6825', '0.6596') averageQWK=0.6612 macroEMD=0.2113 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   35   20    0    0
     0   29   82   14    0
     0    1   35   76    4
     0    0    7   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   41    9    2    0
     0   45   55   21    0
     0    3   25  106    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   40   28    1    0
     0   27  103   21    0
     0    1   29   71    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=0.2908 
[epoch 9] step 4/44: loss=0.2896 
[epoch 9] step 6/44: loss=0.2900 
[epoch 9] step 8/44: loss=0.2834 
[epoch 9] step 10/44: loss=0.2960 
[epoch 9] step 12/44: loss=0.2957 
[epoch 9] step 14/44: loss=0.2961 
[epoch 9] step 16/44: loss=0.2954 
[epoch 9] step 18/44: loss=0.2973 
[epoch 9] step 20/44: loss=0.2984 
[epoch 9] step 22/44: loss=0.3014 
[epoch 9] step 24/44: loss=0.3076 
[epoch 9] step 26/44: loss=0.3110 
[epoch 9] step 28/44: loss=0.3079 
[epoch 9] step 30/44: loss=0.3091 
[epoch 9] step 32/44: loss=0.3085 
[epoch 9] step 34/44: loss=0.3071 
[epoch 9] step 36/44: loss=0.3037 
[epoch 9] step 38/44: loss=0.3047 
[epoch 9] step 40/44: loss=0.3039 
[epoch 9] step 42/44: loss=0.3067 
[epoch 9] step 44/44: loss=0.3040 
[epoch 9] train_loss(avg per step)=0.6081 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=0.8809 qwk=('0.6739', '0.6658', '0.6281') averageQWK=0.6560 macroEMD=0.2120 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   26   29    0    0
     0   14   88   23    0
     0    0   26   84    6
     0    0    5   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   19   30    3    0
     0   17   78   26    0
     0    0   21  113    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   29   39    1    0
     0   21   99   31    0
     0    0   26   75    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=0.1989 
[epoch 10] step 4/44: loss=0.2208 
[epoch 10] step 6/44: loss=0.2241 
[epoch 10] step 8/44: loss=0.2272 
[epoch 10] step 10/44: loss=0.2330 
[epoch 10] step 12/44: loss=0.2401 
[epoch 10] step 14/44: loss=0.2467 
[epoch 10] step 16/44: loss=0.2532 
[epoch 10] step 18/44: loss=0.2550 
[epoch 10] step 20/44: loss=0.2595 
[epoch 10] step 22/44: loss=0.2607 
[epoch 10] step 24/44: loss=0.2626 
[epoch 10] step 26/44: loss=0.2656 
[epoch 10] step 28/44: loss=0.2620 
[epoch 10] step 30/44: loss=0.2618 
[epoch 10] step 32/44: loss=0.2596 
[epoch 10] step 34/44: loss=0.2591 
[epoch 10] step 36/44: loss=0.2584 
[epoch 10] step 38/44: loss=0.2569 
[epoch 10] step 40/44: loss=0.2581 
[epoch 10] step 42/44: loss=0.2592 
[epoch 10] step 44/44: loss=0.2645 
[epoch 10] train_loss(avg per step)=0.5291 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=0.9732 qwk=('0.6510', '0.6600', '0.6415') averageQWK=0.6508 macroEMD=0.2102 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   40   15    0    0
     0   34   82    7    2
     0    1   41   66    8
     0    1    6   10    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   38   12    2    0
     0   43   59   19    0
     0    1   39   94    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   45   24    0    0
     0   40   98   13    0
     0    2   37   62    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.2593 
[epoch 11] step 4/44: loss=0.2336 
[epoch 11] step 6/44: loss=0.2332 
[epoch 11] step 8/44: loss=0.2362 
[epoch 11] step 10/44: loss=0.2368 
[epoch 11] step 12/44: loss=0.2309 
[epoch 11] step 14/44: loss=0.2376 
[epoch 11] step 16/44: loss=0.2445 
[epoch 11] step 18/44: loss=0.2408 
[epoch 11] step 20/44: loss=0.2503 
[epoch 11] step 22/44: loss=0.2531 
[epoch 11] step 24/44: loss=0.2496 
[epoch 11] step 26/44: loss=0.2526 
[epoch 11] step 28/44: loss=0.2548 
[epoch 11] step 30/44: loss=0.2544 
[epoch 11] step 32/44: loss=0.2516 
[epoch 11] step 34/44: loss=0.2498 
[epoch 11] step 36/44: loss=0.2489 
[epoch 11] step 38/44: loss=0.2438 
[epoch 11] step 40/44: loss=0.2442 
[epoch 11] step 42/44: loss=0.2446 
[epoch 11] step 44/44: loss=0.2462 
[epoch 11] train_loss(avg per step)=0.4923 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=0.9348 qwk=('0.6565', '0.6310', '0.6193') averageQWK=0.6356 macroEMD=0.2114 tailR0=('0.2609', '0.0000', '0.0000') tailR0avg=0.0870
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   29   22    2    2
     0   14   73   34    4
     0    0   17   85   14
     0    0    3    8   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   22   20   10    0
     0   13   56   52    0
     0    0    6  128    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   25   43    1    0
     0   21   99   31    0
     0    0   24   77    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=0.2418 
[epoch 12] step 4/44: loss=0.2222 
[epoch 12] step 6/44: loss=0.2120 
[epoch 12] step 8/44: loss=0.2059 
[epoch 12] step 10/44: loss=0.2075 
[epoch 12] step 12/44: loss=0.2018 
[epoch 12] step 14/44: loss=0.2057 
[epoch 12] step 16/44: loss=0.2042 
[epoch 12] step 18/44: loss=0.2028 
[epoch 12] step 20/44: loss=0.2035 
[epoch 12] step 22/44: loss=0.2117 
[epoch 12] step 24/44: loss=0.2168 
[epoch 12] step 26/44: loss=0.2157 
[epoch 12] step 28/44: loss=0.2181 
[epoch 12] step 30/44: loss=0.2183 
[epoch 12] step 32/44: loss=0.2153 
[epoch 12] step 34/44: loss=0.2154 
[epoch 12] step 36/44: loss=0.2168 
[epoch 12] step 38/44: loss=0.2158 
[epoch 12] step 40/44: loss=0.2139 
[epoch 12] step 42/44: loss=0.2122 
[epoch 12] step 44/44: loss=0.2106 
[epoch 12] train_loss(avg per step)=0.4212 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=0.9006 qwk=('0.6234', '0.6718', '0.6222') averageQWK=0.6391 macroEMD=0.2078 tailR0=('0.1957', '0.0000', '0.0000') tailR0avg=0.0652
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   24   29    1    1
     0   13   98   11    3
     0    0   34   73    9
     0    0    7    7    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   27   19    6    0
     0   16   69   36    0
     0    0   15  119    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   33   36    0    0
     0   24  110   17    0
     0    1   37   63    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.1756 
[epoch 13] step 4/44: loss=0.1748 
[epoch 13] step 6/44: loss=0.1750 
[epoch 13] step 8/44: loss=0.1770 
[epoch 13] step 10/44: loss=0.1743 
[epoch 13] step 12/44: loss=0.1657 
[epoch 13] step 14/44: loss=0.1712 
[epoch 13] step 16/44: loss=0.1658 
[epoch 13] step 18/44: loss=0.1671 
[epoch 13] step 20/44: loss=0.1671 
[epoch 13] step 22/44: loss=0.1670 
[epoch 13] step 24/44: loss=0.1679 
[epoch 13] step 26/44: loss=0.1678 
[epoch 13] step 28/44: loss=0.1678 
[epoch 13] step 30/44: loss=0.1696 
[epoch 13] step 32/44: loss=0.1722 
[epoch 13] step 34/44: loss=0.1701 
[epoch 13] step 36/44: loss=0.1684 
[epoch 13] step 38/44: loss=0.1674 
[epoch 13] step 40/44: loss=0.1652 
[epoch 13] step 42/44: loss=0.1627 
[epoch 13] step 44/44: loss=0.1616 
[epoch 13] train_loss(avg per step)=0.3232 lambda[min,max]=[0.498851,1.000000]
[epoch 13] val_loss=0.9113 qwk=('0.6475', '0.6909', '0.5948') averageQWK=0.6444 macroEMD=0.2039 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   31   20    4    0
     0   16   79   29    1
     0    0   22   89    5
     0    0    4   18    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   30   19    3    0
     0   22   76   23    0
     0    0   26  107    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   26   43    0    0
     0   14  121   16    0
     0    0   41   60    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.1470 
[epoch 14] step 4/44: loss=0.1140 
[epoch 14] step 6/44: loss=0.1326 
[epoch 14] step 8/44: loss=0.1285 
[epoch 14] step 10/44: loss=0.1366 
[epoch 14] step 12/44: loss=0.1303 
[epoch 14] step 14/44: loss=0.1314 
[epoch 14] step 16/44: loss=0.1274 
[epoch 14] step 18/44: loss=0.1309 
[epoch 14] step 20/44: loss=0.1289 
[epoch 14] step 22/44: loss=0.1259 
[epoch 14] step 24/44: loss=0.1222 
[epoch 14] step 26/44: loss=0.1212 
[epoch 14] step 28/44: loss=0.1198 
[epoch 14] step 30/44: loss=0.1203 
[epoch 14] step 32/44: loss=0.1218 
[epoch 14] step 34/44: loss=0.1205 
[epoch 14] step 36/44: loss=0.1196 
[epoch 14] step 38/44: loss=0.1165 
[epoch 14] step 40/44: loss=0.1157 
[epoch 14] step 42/44: loss=0.1175 
[epoch 14] step 44/44: loss=0.1182 
[epoch 14] train_loss(avg per step)=0.2363 lambda[min,max]=[0.479296,1.000000]
[epoch 14] val_loss=0.9741 qwk=('0.6201', '0.7024', '0.5931') averageQWK=0.6385 macroEMD=0.2076 tailR0=('0.2729', '0.0556', '0.0000') tailR0avg=0.1095
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     0   27   28    0    0
     0   18  100    3    4
     0    1   50   56    9
     0    0    8    5   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    0    0
     2   27   19    4    0
     1   17   84   19    0
     0    0   23  110    1
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   39   30    0    0
     0   37  101   13    0
     0    3   42   56    0
     0    0    0    2    0
[epoch 15] step 2/44: loss=0.1370 
[epoch 15] step 4/44: loss=0.1195 
[epoch 15] step 6/44: loss=0.0960 
[epoch 15] step 8/44: loss=0.0927 
[epoch 15] step 10/44: loss=0.0941 
[epoch 15] step 12/44: loss=0.0945 
[epoch 15] step 14/44: loss=0.0993 
[epoch 15] step 16/44: loss=0.1000 
[epoch 15] step 18/44: loss=0.1015 
[epoch 15] step 20/44: loss=0.0958 
[epoch 15] step 22/44: loss=0.0987 
[epoch 15] step 24/44: loss=0.0950 
[epoch 15] step 26/44: loss=0.0955 
[epoch 15] step 28/44: loss=0.0957 
[epoch 15] step 30/44: loss=0.0938 
[epoch 15] step 32/44: loss=0.0937 
[epoch 15] step 34/44: loss=0.0912 
[epoch 15] step 36/44: loss=0.0892 
[epoch 15] step 38/44: loss=0.0900 
[epoch 15] step 40/44: loss=0.0886 
[epoch 15] step 42/44: loss=0.0877 
[epoch 15] step 44/44: loss=0.0872 
[epoch 15] train_loss(avg per step)=0.1743 lambda[min,max]=[0.476093,1.000000]
[epoch 15] val_loss=0.9644 qwk=('0.6417', '0.6538', '0.5842') averageQWK=0.6266 macroEMD=0.2049 tailR0=('0.2295', '0.0556', '0.0000') tailR0avg=0.0950
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     0   29   21    4    1
     0   20   78   24    3
     0    3   19   86    8
     0    0    3   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    0    0
     0   30   18    4    0
     1   18   85   17    0
     1    1   33   92    7
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   32   36    1    0
     0   23  114   14    0
     0    3   37   61    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=0.1281 
[epoch 16] step 4/44: loss=0.1123 
[epoch 16] step 6/44: loss=0.0899 
[epoch 16] step 8/44: loss=0.0812 
[epoch 16] step 10/44: loss=0.0808 
[epoch 16] step 12/44: loss=0.0751 
[epoch 16] step 14/44: loss=0.0766 
[epoch 16] step 16/44: loss=0.0737 
[epoch 16] step 18/44: loss=0.0708 
[epoch 16] step 20/44: loss=0.0651 
[epoch 16] step 22/44: loss=0.0665 
[epoch 16] step 24/44: loss=0.0696 
[epoch 16] step 26/44: loss=0.0674 
[epoch 16] step 28/44: loss=0.0658 
[epoch 16] step 30/44: loss=0.0665 
[epoch 16] step 32/44: loss=0.0657 
[epoch 16] step 34/44: loss=0.0667 
[epoch 16] step 36/44: loss=0.0683 
[epoch 16] step 38/44: loss=0.0664 
[epoch 16] step 40/44: loss=0.0642 
[epoch 16] step 42/44: loss=0.0631 
[epoch 16] step 44/44: loss=0.0639 
[epoch 16] train_loss(avg per step)=0.1278 lambda[min,max]=[0.472925,1.000000]
[epoch 16] val_loss=0.9878 qwk=('0.5768', '0.6479', '0.5805') averageQWK=0.6017 macroEMD=0.2098 tailR0=('0.1425', '0.1111', '0.0000') tailR0avg=0.0845
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   22   28    4    1
     1   12   81   28    3
     0    3   22   84    7
     0    0    3   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     1   20   26    4    1
     0   14   83   24    0
     0    0   24  100   10
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     0   20   48    1    0
     0   10  119   22    0
     0    0   31   70    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=0.0542 
[epoch 17] step 4/44: loss=0.0406 
[epoch 17] step 6/44: loss=0.0346 
[epoch 17] step 8/44: loss=0.0348 
[epoch 17] step 10/44: loss=0.0370 
[epoch 17] step 12/44: loss=0.0364 
[epoch 17] step 14/44: loss=0.0383 
[epoch 17] step 16/44: loss=0.0328 
[epoch 17] step 18/44: loss=0.0342 
[epoch 17] step 20/44: loss=0.0328 
[epoch 17] step 22/44: loss=0.0313 
[epoch 17] step 24/44: loss=0.0285 
[epoch 17] step 26/44: loss=0.0288 
[epoch 17] step 28/44: loss=0.0306 
[epoch 17] step 30/44: loss=0.0316 
[epoch 17] step 32/44: loss=0.0315 
[epoch 17] step 34/44: loss=0.0308 
[epoch 17] step 36/44: loss=0.0306 
[epoch 17] step 38/44: loss=0.0306 
[epoch 17] step 40/44: loss=0.0297 
[epoch 17] step 42/44: loss=0.0310 
[epoch 17] step 44/44: loss=0.0302 
[epoch 17] train_loss(avg per step)=0.0604 lambda[min,max]=[0.385771,1.000000]
[epoch 17] val_loss=0.9680 qwk=('0.6290', '0.6396', '0.5966') averageQWK=0.6218 macroEMD=0.2047 tailR0=('0.1860', '0.0556', '0.0000') tailR0avg=0.0805
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     0   28   23    4    0
     0   16   81   25    3
     0    3   24   83    6
     0    0    4   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   19   28    5    0
     0   15   83   23    0
     0    0   18  113    3
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   26   43    0    0
     0   22  114   15    0
     0    1   35   65    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=0.0093 
[epoch 18] step 4/44: loss=-0.0056 
[epoch 18] step 6/44: loss=0.0143 
[epoch 18] step 8/44: loss=0.0185 
[epoch 18] step 10/44: loss=0.0168 
[epoch 18] step 12/44: loss=0.0177 
[epoch 18] step 14/44: loss=0.0159 
[epoch 18] step 16/44: loss=0.0138 
[epoch 18] step 18/44: loss=0.0097 
[epoch 18] step 20/44: loss=0.0074 
[epoch 18] step 22/44: loss=0.0104 
[epoch 18] step 24/44: loss=0.0106 
[epoch 18] step 26/44: loss=0.0102 
[epoch 18] step 28/44: loss=0.0098 
[epoch 18] step 30/44: loss=0.0117 
[epoch 18] step 32/44: loss=0.0110 
[epoch 18] step 34/44: loss=0.0100 
[epoch 18] step 36/44: loss=0.0095 
[epoch 18] step 38/44: loss=0.0093 
[epoch 18] step 40/44: loss=0.0089 
[epoch 18] step 42/44: loss=0.0087 
[epoch 18] step 44/44: loss=0.0103 
[epoch 18] train_loss(avg per step)=0.0205 lambda[min,max]=[0.435072,1.000000]
[epoch 18] val_loss=0.9815 qwk=('0.6553', '0.6876', '0.6020') averageQWK=0.6483 macroEMD=0.2017 tailR0=('0.2415', '0.0972', '0.0000') tailR0avg=0.1129
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     1   31   22    1    0
     0   15   97    9    4
     0    0   41   68    7
     0    0    6   11    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     1   26   21    4    0
     0   20   79   21    1
     0    0   20  108    6
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     1   25   43    0    0
     0   19  113   19    0
     0    0   36   65    0
     0    0    0    2    0
[epoch 19] step 2/44: loss=-0.0401 
[epoch 19] step 4/44: loss=-0.0335 
[epoch 19] step 6/44: loss=-0.0272 
[epoch 19] step 8/44: loss=-0.0273 
[epoch 19] step 10/44: loss=-0.0230 
[epoch 19] step 12/44: loss=-0.0209 
[epoch 19] step 14/44: loss=-0.0208 
[epoch 19] step 16/44: loss=-0.0232 
[epoch 19] step 18/44: loss=-0.0163 
[epoch 19] step 20/44: loss=-0.0149 
[epoch 19] step 22/44: loss=-0.0093 
[epoch 19] step 24/44: loss=-0.0104 
[epoch 19] step 26/44: loss=-0.0106 
[epoch 19] step 28/44: loss=-0.0076 
[epoch 19] step 30/44: loss=-0.0053 
[epoch 19] step 32/44: loss=-0.0070 
[epoch 19] step 34/44: loss=-0.0068 
[epoch 19] step 36/44: loss=-0.0050 
[epoch 19] step 38/44: loss=-0.0046 
[epoch 19] step 40/44: loss=-0.0052 
[epoch 19] step 42/44: loss=-0.0051 
[epoch 19] step 44/44: loss=-0.0057 
[epoch 19] train_loss(avg per step)=-0.0114 lambda[min,max]=[0.420163,1.000000]
[epoch 19] val_loss=0.9989 qwk=('0.6316', '0.6785', '0.6415') averageQWK=0.6505 macroEMD=0.2000 tailR0=('0.1981', '0.0972', '0.1000') tailR0avg=0.1318
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     2   25   23    4    1
     1   13   83   25    3
     0    0   23   86    7
     0    0    3   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     3   28   18    3    0
     1   16   85   17    2
     0    0   28   96   10
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   27   42    0    0
     0   17  114   20    0
     0    0   29   72    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=-0.0393 
[epoch 20] step 4/44: loss=-0.0280 
[epoch 20] step 6/44: loss=-0.0295 
[epoch 20] step 8/44: loss=-0.0253 
[epoch 20] step 10/44: loss=-0.0256 
[epoch 20] step 12/44: loss=-0.0254 
[epoch 20] step 14/44: loss=-0.0247 
[epoch 20] step 16/44: loss=-0.0208 
[epoch 20] step 18/44: loss=-0.0169 
[epoch 20] step 20/44: loss=-0.0174 
[epoch 20] step 22/44: loss=-0.0210 
[epoch 20] step 24/44: loss=-0.0220 
[epoch 20] step 26/44: loss=-0.0224 
[epoch 20] step 28/44: loss=-0.0221 
[epoch 20] step 30/44: loss=-0.0224 
[epoch 20] step 32/44: loss=-0.0239 
[epoch 20] step 34/44: loss=-0.0237 
[epoch 20] step 36/44: loss=-0.0235 
[epoch 20] step 38/44: loss=-0.0235 
[epoch 20] step 40/44: loss=-0.0223 
[epoch 20] step 42/44: loss=-0.0239 
[epoch 20] step 44/44: loss=-0.0238 
[epoch 20] train_loss(avg per step)=-0.0475 lambda[min,max]=[0.363062,1.000000]
[epoch 20] val_loss=1.0233 qwk=('0.6203', '0.6648', '0.6312') averageQWK=0.6388 macroEMD=0.1977 tailR0=('0.2536', '0.1528', '0.0000') tailR0avg=0.1355
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    3    0    0
     2   24   26    2    1
     1   12   89   20    3
     0    0   32   77    7
     0    0    6   13    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     3   24   19    5    1
     1   19   69   32    0
     0    0   16  115    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   31   38    0    0
     0   17  119   15    0
     0    1   34   66    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=-0.0285 
[epoch 21] step 4/44: loss=-0.0385 
[epoch 21] step 6/44: loss=-0.0334 
[epoch 21] step 8/44: loss=-0.0301 
[epoch 21] step 10/44: loss=-0.0325 
[epoch 21] step 12/44: loss=-0.0303 
[epoch 21] step 14/44: loss=-0.0329 
[epoch 21] step 16/44: loss=-0.0351 
[epoch 21] step 18/44: loss=-0.0356 
[epoch 21] step 20/44: loss=-0.0370 
[epoch 21] step 22/44: loss=-0.0385 
[epoch 21] step 24/44: loss=-0.0369 
[epoch 21] step 26/44: loss=-0.0361 
[epoch 21] step 28/44: loss=-0.0354 
[epoch 21] step 30/44: loss=-0.0337 
[epoch 21] step 32/44: loss=-0.0317 
[epoch 21] step 34/44: loss=-0.0329 
[epoch 21] step 36/44: loss=-0.0339 
[epoch 21] step 38/44: loss=-0.0340 
[epoch 21] step 40/44: loss=-0.0361 
[epoch 21] step 42/44: loss=-0.0371 
[epoch 21] step 44/44: loss=-0.0373 
[epoch 21] train_loss(avg per step)=-0.0745 lambda[min,max]=[0.351770,1.000000]
[epoch 21] val_loss=1.0980 qwk=('0.5918', '0.6646', '0.5957') averageQWK=0.6173 macroEMD=0.2069 tailR0=('0.3285', '0.0972', '0.1000') tailR0avg=0.1752
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     2   17   36    0    0
     1    9  106    6    3
     0    0   52   54   10
     0    0    9    4   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     2   29   16    4    1
     1   25   71   23    1
     0    0   20  108    6
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   24   44    0    0
     0   18  121   12    0
     0    0   42   59    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=-0.0302 
[epoch 22] step 4/44: loss=-0.0358 
[epoch 22] step 6/44: loss=-0.0391 
[epoch 22] step 8/44: loss=-0.0420 
[epoch 22] step 10/44: loss=-0.0396 
[epoch 22] step 12/44: loss=-0.0416 
[epoch 22] step 14/44: loss=-0.0417 
[epoch 22] step 16/44: loss=-0.0419 
[epoch 22] step 18/44: loss=-0.0447 
[epoch 22] step 20/44: loss=-0.0450 
[epoch 22] step 22/44: loss=-0.0440 
[epoch 22] step 24/44: loss=-0.0437 
[epoch 22] step 26/44: loss=-0.0433 
[epoch 22] step 28/44: loss=-0.0441 
[epoch 22] step 30/44: loss=-0.0437 
[epoch 22] step 32/44: loss=-0.0447 
[epoch 22] step 34/44: loss=-0.0457 
[epoch 22] step 36/44: loss=-0.0444 
[epoch 22] step 38/44: loss=-0.0452 
[epoch 22] step 40/44: loss=-0.0441 
[epoch 22] step 42/44: loss=-0.0434 
[epoch 22] step 44/44: loss=-0.0427 
[epoch 22] train_loss(avg per step)=-0.0855 lambda[min,max]=[0.370370,1.000000]
[epoch 22] val_loss=1.0423 qwk=('0.6636', '0.6912', '0.6331') averageQWK=0.6627 macroEMD=0.1960 tailR0=('0.3285', '0.0972', '0.1000') tailR0avg=0.1752
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    0    0
     0   31   20    3    1
     0   19   84   19    3
     0    1   27   79    9
     0    0    4    9   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     1   30   17    3    1
     0   21   69   31    0
     0    0   15  114    5
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   32   36    0    0
     0   23  100   28    0
     0    2   25   74    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=-0.0855 
[epoch 23] step 4/44: loss=-0.0722 
[epoch 23] step 6/44: loss=-0.0569 
[epoch 23] step 8/44: loss=-0.0568 
[epoch 23] step 10/44: loss=-0.0577 
[epoch 23] step 12/44: loss=-0.0579 
[epoch 23] step 14/44: loss=-0.0571 
[epoch 23] step 16/44: loss=-0.0574 
[epoch 23] step 18/44: loss=-0.0577 
[epoch 23] step 20/44: loss=-0.0583 
[epoch 23] step 22/44: loss=-0.0585 
[epoch 23] step 24/44: loss=-0.0583 
[epoch 23] step 26/44: loss=-0.0582 
[epoch 23] step 28/44: loss=-0.0569 
[epoch 23] step 30/44: loss=-0.0575 
[epoch 23] step 32/44: loss=-0.0558 
[epoch 23] step 34/44: loss=-0.0559 
[epoch 23] step 36/44: loss=-0.0565 
[epoch 23] step 38/44: loss=-0.0552 
[epoch 23] step 40/44: loss=-0.0550 
[epoch 23] step 42/44: loss=-0.0549 
[epoch 23] step 44/44: loss=-0.0562 
[epoch 23] train_loss(avg per step)=-0.1123 lambda[min,max]=[0.423932,1.000000]
[epoch 23] val_loss=1.0546 qwk=('0.6410', '0.6760', '0.5981') averageQWK=0.6384 macroEMD=0.2012 tailR0=('0.1860', '0.0000', '0.1000') tailR0avg=0.0953
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     0   28   26    1    0
     0   16   96   12    1
     0    0   39   73    4
     0    0    7   10    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   36   13    3    0
     0   30   68   22    1
     0    2   21  105    6
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   29   40    0    0
     0   22  119   10    0
     0    0   45   56    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=-0.0656 
[epoch 24] step 4/44: loss=-0.0716 
[epoch 24] step 6/44: loss=-0.0719 
[epoch 24] step 8/44: loss=-0.0763 
[epoch 24] step 10/44: loss=-0.0751 
[epoch 24] step 12/44: loss=-0.0730 
[epoch 24] step 14/44: loss=-0.0686 
[epoch 24] step 16/44: loss=-0.0680 
[epoch 24] step 18/44: loss=-0.0675 
[epoch 24] step 20/44: loss=-0.0675 
[epoch 24] step 22/44: loss=-0.0649 
[epoch 24] step 24/44: loss=-0.0655 
[epoch 24] step 26/44: loss=-0.0661 
[epoch 24] step 28/44: loss=-0.0647 
[epoch 24] step 30/44: loss=-0.0635 
[epoch 24] step 32/44: loss=-0.0637 
[epoch 24] step 34/44: loss=-0.0638 
[epoch 24] step 36/44: loss=-0.0639 
[epoch 24] step 38/44: loss=-0.0644 
[epoch 24] step 40/44: loss=-0.0635 
[epoch 24] step 42/44: loss=-0.0631 
[epoch 24] step 44/44: loss=-0.0623 
[epoch 24] train_loss(avg per step)=-0.1246 lambda[min,max]=[0.391430,1.000000]
[epoch 24] val_loss=1.0605 qwk=('0.6175', '0.6668', '0.6328') averageQWK=0.6391 macroEMD=0.1992 tailR0=('0.1860', '0.0556', '0.1000') tailR0avg=0.1138
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     2   23   25    4    1
     1   13   90   18    3
     0    0   27   82    7
     0    0    5   12    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   29   19    4    0
     1   19   76   25    0
     0    0   21  107    6
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   32   36    0    0
     0   25  109   17    0
     0    2   30   69    0
     0    0    0    2    0
[epoch 25] step 2/44: loss=-0.0576 
[epoch 25] step 4/44: loss=-0.0596 
[epoch 25] step 6/44: loss=-0.0653 
[epoch 25] step 8/44: loss=-0.0679 
[epoch 25] step 10/44: loss=-0.0724 
[epoch 25] step 12/44: loss=-0.0737 
[epoch 25] step 14/44: loss=-0.0712 
[epoch 25] step 16/44: loss=-0.0709 
[epoch 25] step 18/44: loss=-0.0715 
[epoch 25] step 20/44: loss=-0.0734 
[epoch 25] step 22/44: loss=-0.0737 
[epoch 25] step 24/44: loss=-0.0726 
[epoch 25] step 26/44: loss=-0.0715 
[epoch 25] step 28/44: loss=-0.0693 
[epoch 25] step 30/44: loss=-0.0698 
[epoch 25] step 32/44: loss=-0.0697 
[epoch 25] step 34/44: loss=-0.0696 
[epoch 25] step 36/44: loss=-0.0708 
[epoch 25] step 38/44: loss=-0.0715 
[epoch 25] step 40/44: loss=-0.0714 
[epoch 25] step 42/44: loss=-0.0721 
[epoch 25] step 44/44: loss=-0.0723 
[epoch 25] train_loss(avg per step)=-0.1446 lambda[min,max]=[0.370157,1.000000]
[epoch 25] val_loss=1.0804 qwk=('0.6082', '0.6784', '0.6348') averageQWK=0.6405 macroEMD=0.1956 tailR0=('0.2198', '0.0556', '0.1000') tailR0avg=0.1251
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     1   23   28    2    1
     0   13   96   12    4
     0    0   35   73    8
     0    0    6   12    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     0   31   15    6    0
     0   24   58   39    0
     0    0   13  118    3
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   29   40    0    0
     0   17  118   16    0
     0    0   35   66    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=-0.0846 
[epoch 26] step 4/44: loss=-0.0834 
[epoch 26] step 6/44: loss=-0.0812 
[epoch 26] step 8/44: loss=-0.0802 
[epoch 26] step 10/44: loss=-0.0803 
[epoch 26] step 12/44: loss=-0.0794 
[epoch 26] step 14/44: loss=-0.0755 
[epoch 26] step 16/44: loss=-0.0763 
[epoch 26] step 18/44: loss=-0.0752 
[epoch 26] step 20/44: loss=-0.0735 
[epoch 26] step 22/44: loss=-0.0730 
[epoch 26] step 24/44: loss=-0.0733 
[epoch 26] step 26/44: loss=-0.0739 
[epoch 26] step 28/44: loss=-0.0745 
[epoch 26] step 30/44: loss=-0.0750 
[epoch 26] step 32/44: loss=-0.0757 
[epoch 26] step 34/44: loss=-0.0761 
[epoch 26] step 36/44: loss=-0.0761 
[epoch 26] step 38/44: loss=-0.0760 
[epoch 26] step 40/44: loss=-0.0768 
[epoch 26] step 42/44: loss=-0.0775 
[epoch 26] step 44/44: loss=-0.0783 
[epoch 26] train_loss(avg per step)=-0.1566 lambda[min,max]=[0.359978,1.000000]
[epoch 26] val_loss=1.0839 qwk=('0.5763', '0.6339', '0.6434') averageQWK=0.6179 macroEMD=0.2026 tailR0=('0.1763', '0.0556', '0.1000') tailR0avg=0.1106
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    7    0    0
     2   15   36    1    1
     0    6  101   15    3
     0    0   33   77    6
     0    0    5   15    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   18   27    6    0
     0   11   80   30    0
     0    0   17  113    4
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   30   39    0    0
     0   16  109   26    0
     0    0   29   72    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=-0.0779 
[epoch 27] step 4/44: loss=-0.0823 
[epoch 27] step 6/44: loss=-0.0815 
[epoch 27] step 8/44: loss=-0.0826 
[epoch 27] step 10/44: loss=-0.0832 
[epoch 27] step 12/44: loss=-0.0851 
[epoch 27] step 14/44: loss=-0.0838 
[epoch 27] step 16/44: loss=-0.0844 
[epoch 27] step 18/44: loss=-0.0839 
[epoch 27] step 20/44: loss=-0.0831 
[epoch 27] step 22/44: loss=-0.0827 
[epoch 27] step 24/44: loss=-0.0840 
[epoch 27] step 26/44: loss=-0.0845 
[epoch 27] step 28/44: loss=-0.0844 
[epoch 27] step 30/44: loss=-0.0841 
[epoch 27] step 32/44: loss=-0.0832 
[epoch 27] step 34/44: loss=-0.0823 
[epoch 27] step 36/44: loss=-0.0815 
[epoch 27] step 38/44: loss=-0.0816 
[epoch 27] step 40/44: loss=-0.0810 
[epoch 27] step 42/44: loss=-0.0807 
[epoch 27] step 44/44: loss=-0.0810 
[epoch 27] train_loss(avg per step)=-0.1620 lambda[min,max]=[0.400623,1.000000]
[epoch 27] val_loss=1.1023 qwk=('0.5986', '0.6682', '0.6357') averageQWK=0.6341 macroEMD=0.2003 tailR0=('0.2319', '0.0000', '0.1000') tailR0avg=0.1106
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    6    0    0
     3    9   40    3    0
     1    4   97   22    1
     0    0   26   83    7
     0    0    4   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   29   17    6    0
     0   23   60   38    0
     0    0   11  120    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   30   39    0    0
     0   17  122   12    0
     0    0   38   63    0
     0    0    0    2    0
[epoch 28] step 2/44: loss=-0.0835 
[epoch 28] step 4/44: loss=-0.0825 
[epoch 28] step 6/44: loss=-0.0789 
[epoch 28] step 8/44: loss=-0.0807 
[epoch 28] step 10/44: loss=-0.0800 
[epoch 28] step 12/44: loss=-0.0815 
[epoch 28] step 14/44: loss=-0.0827 
[epoch 28] step 16/44: loss=-0.0810 
[epoch 28] step 18/44: loss=-0.0817 
[epoch 28] step 20/44: loss=-0.0827 
[epoch 28] step 22/44: loss=-0.0824 
[epoch 28] step 24/44: loss=-0.0811 
[epoch 28] step 26/44: loss=-0.0808 
[epoch 28] step 28/44: loss=-0.0805 
[epoch 28] step 30/44: loss=-0.0809 
[epoch 28] step 32/44: loss=-0.0812 
[epoch 28] step 34/44: loss=-0.0810 
[epoch 28] step 36/44: loss=-0.0813 
[epoch 28] step 38/44: loss=-0.0819 
[epoch 28] step 40/44: loss=-0.0822 
[epoch 28] step 42/44: loss=-0.0825 
[epoch 28] step 44/44: loss=-0.0830 
[epoch 28] train_loss(avg per step)=-0.1660 lambda[min,max]=[0.391948,1.000000]
[epoch 28] val_loss=1.0704 qwk=('0.6160', '0.7057', '0.6370') averageQWK=0.6529 macroEMD=0.1940 tailR0=('0.2319', '0.1389', '0.1000') tailR0avg=0.1569
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    4    0    0
     1   21   28    4    1
     2   10   86   25    2
     0    0   22   90    4
     0    0    4   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     1   29   19    3    0
     0   21   78   22    0
     0    0   20  110    4
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   28   40    0    0
     1   15  116   19    0
     0    0   32   69    0
     0    0    0    2    0
[epoch 29] step 2/44: loss=-0.0743 
[epoch 29] step 4/44: loss=-0.0827 
[epoch 29] step 6/44: loss=-0.0838 
[epoch 29] step 8/44: loss=-0.0829 
[epoch 29] step 10/44: loss=-0.0831 
[epoch 29] step 12/44: loss=-0.0843 
[epoch 29] step 14/44: loss=-0.0852 
[epoch 29] step 16/44: loss=-0.0868 
[epoch 29] step 18/44: loss=-0.0874 
[epoch 29] step 20/44: loss=-0.0879 
[epoch 29] step 22/44: loss=-0.0868 
[epoch 29] step 24/44: loss=-0.0880 
[epoch 29] step 26/44: loss=-0.0885 
[epoch 29] step 28/44: loss=-0.0890 
[epoch 29] step 30/44: loss=-0.0888 
[epoch 29] step 32/44: loss=-0.0887 
[epoch 29] step 34/44: loss=-0.0898 
[epoch 29] step 36/44: loss=-0.0900 
[epoch 29] step 38/44: loss=-0.0900 
[epoch 29] step 40/44: loss=-0.0897 
[epoch 29] step 42/44: loss=-0.0898 
[epoch 29] step 44/44: loss=-0.0898 
[epoch 29] train_loss(avg per step)=-0.1797 lambda[min,max]=[0.389375,1.000000]
[epoch 29] val_loss=1.0974 qwk=('0.6385', '0.6867', '0.6419') averageQWK=0.6557 macroEMD=0.1961 tailR0=('0.2633', '0.0972', '0.1000') tailR0avg=0.1535
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     1   22   31    1    0
     1   13   91   16    4
     0    0   31   77    8
     0    0    5   11    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     0   27   22    3    0
     0   22   74   25    0
     0    0   19  110    5
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   26   43    0    0
     0   15  124   12    0
     0    0   33   68    0
     0    0    0    2    0
[epoch 30] step 2/44: loss=-0.0680 
[epoch 30] step 4/44: loss=-0.0848 
[epoch 30] step 6/44: loss=-0.0862 
[epoch 30] step 8/44: loss=-0.0882 
[epoch 30] step 10/44: loss=-0.0900 
[epoch 30] step 12/44: loss=-0.0918 
[epoch 30] step 14/44: loss=-0.0912 
[epoch 30] step 16/44: loss=-0.0921 
[epoch 30] step 18/44: loss=-0.0931 
[epoch 30] step 20/44: loss=-0.0933 
[epoch 30] step 22/44: loss=-0.0941 
[epoch 30] step 24/44: loss=-0.0933 
[epoch 30] step 26/44: loss=-0.0924 
[epoch 30] step 28/44: loss=-0.0926 
[epoch 30] step 30/44: loss=-0.0929 
[epoch 30] step 32/44: loss=-0.0921 
[epoch 30] step 34/44: loss=-0.0915 
[epoch 30] step 36/44: loss=-0.0916 
[epoch 30] step 38/44: loss=-0.0917 
[epoch 30] step 40/44: loss=-0.0917 
[epoch 30] step 42/44: loss=-0.0916 
[epoch 30] step 44/44: loss=-0.0920 
[epoch 30] train_loss(avg per step)=-0.1840 lambda[min,max]=[0.431056,1.000000]
[epoch 30] val_loss=1.0842 qwk=('0.6000', '0.6457', '0.6251') averageQWK=0.6236 macroEMD=0.2002 tailR0=('0.1981', '0.0556', '0.1000') tailR0avg=0.1179
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    5    0    0
     1   18   32    3    1
     0    8   98   17    2
     0    0   30   81    5
     0    0    5   14    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   20   28    4    0
     0   14   84   23    0
     0    0   20  111    3
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   32   37    0    0
     0   19  122   10    0
     0    1   40   60    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=-0.1002 
[epoch 31] step 4/44: loss=-0.0999 
[epoch 31] step 6/44: loss=-0.1004 
[epoch 31] step 8/44: loss=-0.0987 
[epoch 31] step 10/44: loss=-0.0993 
[epoch 31] step 12/44: loss=-0.0989 
[epoch 31] step 14/44: loss=-0.0974 
[epoch 31] step 16/44: loss=-0.0956 
[epoch 31] step 18/44: loss=-0.0936 
[epoch 31] step 20/44: loss=-0.0937 
[epoch 31] step 22/44: loss=-0.0941 
[epoch 31] step 24/44: loss=-0.0947 
[epoch 31] step 26/44: loss=-0.0949 
[epoch 31] step 28/44: loss=-0.0945 
[epoch 31] step 30/44: loss=-0.0949 
[epoch 31] step 32/44: loss=-0.0934 
[epoch 31] step 34/44: loss=-0.0937 
[epoch 31] step 36/44: loss=-0.0938 
[epoch 31] step 38/44: loss=-0.0940 
[epoch 31] step 40/44: loss=-0.0940 
[epoch 31] step 42/44: loss=-0.0939 
[epoch 31] step 44/44: loss=-0.0939 
[epoch 31] train_loss(avg per step)=-0.1878 lambda[min,max]=[0.369754,1.000000]
[epoch 31] val_loss=1.0937 qwk=('0.6308', '0.6287', '0.6266') averageQWK=0.6287 macroEMD=0.1979 tailR0=('0.2754', '0.0556', '0.1000') tailR0avg=0.1436
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    1    5    0    0
     1   18   34    2    0
     0    8   98   17    2
     0    0   30   78    8
     0    0    5   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   18   28    4    1
     0   13   82   26    0
     0    0   17  111    6
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   26   43    0    0
     0   15  113   23    0
     0    0   31   70    0
     0    0    0    2    0
[epoch 32] step 2/44: loss=-0.0787 
[epoch 32] step 4/44: loss=-0.0900 
[epoch 32] step 6/44: loss=-0.0937 
[epoch 32] step 8/44: loss=-0.0925 
[epoch 32] step 10/44: loss=-0.0936 
[epoch 32] step 12/44: loss=-0.0945 
[epoch 32] step 14/44: loss=-0.0960 
[epoch 32] step 16/44: loss=-0.0958 
[epoch 32] step 18/44: loss=-0.0967 
[epoch 32] step 20/44: loss=-0.0970 
[epoch 32] step 22/44: loss=-0.0958 
[epoch 32] step 24/44: loss=-0.0958 
[epoch 32] step 26/44: loss=-0.0957 
[epoch 32] step 28/44: loss=-0.0959 
[epoch 32] step 30/44: loss=-0.0964 
[epoch 32] step 32/44: loss=-0.0963 
[epoch 32] step 34/44: loss=-0.0964 
[epoch 32] step 36/44: loss=-0.0963 
[epoch 32] step 38/44: loss=-0.0954 
[epoch 32] step 40/44: loss=-0.0956 
[epoch 32] step 42/44: loss=-0.0959 
[epoch 32] step 44/44: loss=-0.0964 
[epoch 32] train_loss(avg per step)=-0.1927 lambda[min,max]=[0.420660,1.000000]
[epoch 32] val_loss=1.0795 qwk=('0.6312', '0.6552', '0.6386') averageQWK=0.6417 macroEMD=0.1953 tailR0=('0.2198', '0.0972', '0.1000') tailR0avg=0.1390
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     1   23   26    4    1
     0   13   91   20    1
     0    1   25   82    8
     0    0    4   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   21   27    2    1
     0   14   87   20    0
     0    0   22  108    4
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   29   40    0    0
     0   15  122   14    0
     0    0   36   65    0
     0    0    0    2    0
[epoch 33] step 2/44: loss=-0.0996 
[epoch 33] step 4/44: loss=-0.0992 
[epoch 33] step 6/44: loss=-0.0968 
[epoch 33] step 8/44: loss=-0.0973 
[epoch 33] step 10/44: loss=-0.0969 
[epoch 33] step 12/44: loss=-0.0982 
[epoch 33] step 14/44: loss=-0.0992 
[epoch 33] step 16/44: loss=-0.0987 
[epoch 33] step 18/44: loss=-0.0995 
[epoch 33] step 20/44: loss=-0.1001 
[epoch 33] step 22/44: loss=-0.0988 
[epoch 33] step 24/44: loss=-0.0994 
[epoch 33] step 26/44: loss=-0.0993 
[epoch 33] step 28/44: loss=-0.0994 
[epoch 33] step 30/44: loss=-0.0992 
[epoch 33] step 32/44: loss=-0.0988 
[epoch 33] step 34/44: loss=-0.0975 
[epoch 33] step 36/44: loss=-0.0981 
[epoch 33] step 38/44: loss=-0.0981 
[epoch 33] step 40/44: loss=-0.0982 
[epoch 33] step 42/44: loss=-0.0984 
[epoch 33] step 44/44: loss=-0.0982 
[epoch 33] train_loss(avg per step)=-0.1965 lambda[min,max]=[0.387113,1.000000]
[epoch 33] val_loss=1.0855 qwk=('0.6444', '0.6635', '0.6325') averageQWK=0.6468 macroEMD=0.1936 tailR0=('0.1981', '0.0556', '0.1000') tailR0avg=0.1179
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     1   27   23    4    0
     1   15   88   20    1
     0    1   27   83    5
     0    0    4   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     1   25   22    3    1
     0   17   87   17    0
     0    0   24  105    5
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   28   41    0    0
     0   15  125   11    0
     0    0   38   63    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=-0.0993 
[epoch 34] step 4/44: loss=-0.0987 
[epoch 34] step 6/44: loss=-0.0990 
[epoch 34] step 8/44: loss=-0.0992 
[epoch 34] step 10/44: loss=-0.0993 
[epoch 34] step 12/44: loss=-0.1000 
[epoch 34] step 14/44: loss=-0.1004 
[epoch 34] step 16/44: loss=-0.1014 
[epoch 34] step 18/44: loss=-0.1002 
[epoch 34] step 20/44: loss=-0.0992 
[epoch 34] step 22/44: loss=-0.0995 
[epoch 34] step 24/44: loss=-0.1002 
[epoch 34] step 26/44: loss=-0.0996 
[epoch 34] step 28/44: loss=-0.0989 
[epoch 34] step 30/44: loss=-0.0986 
[epoch 34] step 32/44: loss=-0.0988 
[epoch 34] step 34/44: loss=-0.0986 
[epoch 34] step 36/44: loss=-0.0983 
[epoch 34] step 38/44: loss=-0.0980 
[epoch 34] step 40/44: loss=-0.0976 
[epoch 34] step 42/44: loss=-0.0980 
[epoch 34] step 44/44: loss=-0.0982 
[epoch 34] train_loss(avg per step)=-0.1964 lambda[min,max]=[0.374383,1.000000]
[epoch 34] val_loss=1.1065 qwk=('0.6406', '0.6645', '0.6342') averageQWK=0.6464 macroEMD=0.1956 tailR0=('0.3309', '0.0556', '0.1000') tailR0avg=0.1622
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    1    4    0    0
     1   19   32    3    0
     0   10   97   15    3
     0    0   28   78   10
     0    0    5   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   23   23    5    0
     0   15   71   35    0
     0    0   10  122    2
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   31   38    0    0
     0   19  117   15    0
     0    1   34   66    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=-0.0957 
[epoch 35] step 4/44: loss=-0.0957 
[epoch 35] step 6/44: loss=-0.0985 
[epoch 35] step 8/44: loss=-0.0970 
[epoch 35] step 10/44: loss=-0.0974 
[epoch 35] step 12/44: loss=-0.0974 
[epoch 35] step 14/44: loss=-0.0954 
[epoch 35] step 16/44: loss=-0.0967 
[epoch 35] step 18/44: loss=-0.0970 
[epoch 35] step 20/44: loss=-0.0980 
[epoch 35] step 22/44: loss=-0.0988 
[epoch 35] step 24/44: loss=-0.0993 
[epoch 35] step 26/44: loss=-0.0988 
[epoch 35] step 28/44: loss=-0.0983 
[epoch 35] step 30/44: loss=-0.0984 
[epoch 35] step 32/44: loss=-0.0979 
[epoch 35] step 34/44: loss=-0.0984 
[epoch 35] step 36/44: loss=-0.0988 
[epoch 35] step 38/44: loss=-0.0993 
[epoch 35] step 40/44: loss=-0.0984 
[epoch 35] step 42/44: loss=-0.0988 
[epoch 35] step 44/44: loss=-0.0987 
[epoch 35] train_loss(avg per step)=-0.1973 lambda[min,max]=[0.356260,1.000000]
[epoch 35] val_loss=1.0847 qwk=('0.6348', '0.6502', '0.6366') averageQWK=0.6405 macroEMD=0.1943 tailR0=('0.2319', '0.0556', '0.1000') tailR0avg=0.1291
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    4    0    0
     1   19   31    4    0
     0   12   94   18    1
     0    0   28   83    5
     0    0    4   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   24   22    4    1
     0   16   79   26    0
     0    0   19  112    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     0   28   41    0    0
     0   17  119   15    0
     0    0   34   67    0
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold0/metrics.json
Done.
