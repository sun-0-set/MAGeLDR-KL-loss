[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.7331 
[epoch 1] step 4/44: loss=0.7374 
[epoch 1] step 6/44: loss=0.7292 
[epoch 1] step 8/44: loss=0.7292 
[epoch 1] step 10/44: loss=0.7276 
[epoch 1] step 12/44: loss=0.7275 
[epoch 1] step 14/44: loss=0.7266 
[epoch 1] step 16/44: loss=0.7227 
[epoch 1] step 18/44: loss=0.7186 
[epoch 1] step 20/44: loss=0.7184 
[epoch 1] step 22/44: loss=0.7162 
[epoch 1] step 24/44: loss=0.7152 
[epoch 1] step 26/44: loss=0.7137 
[epoch 1] step 28/44: loss=0.7129 
[epoch 1] step 30/44: loss=0.7123 
[epoch 1] step 32/44: loss=0.7119 
[epoch 1] step 34/44: loss=0.7113 
[epoch 1] step 36/44: loss=0.7103 
[epoch 1] step 38/44: loss=0.7073 
[epoch 1] step 40/44: loss=0.7048 
[epoch 1] step 42/44: loss=0.7043 
[epoch 1] step 44/44: loss=0.7030 
[epoch 1] train_loss(avg per step)=1.4060 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.3053 qwk=('0.0513', '0.0552', '0.1741') averageQWK=0.0935 macroEMD=0.3805 tailR0=('0.0000', '0.1111', '0.2500') tailR0avg=0.1204
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    8    0
     0   28    4   23    0
     0   57    8   60    0
     0   41   17   58    0
     0    4    9   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    7    0    0
    24    0   27    2    0
    56    0   64    2    0
    44    0   82    7    0
     3    0    9    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0   18   44    2    5
     0   36   99    1   16
     0   19   50   14   19
     0    1    0    0    1
[epoch 2] step 2/44: loss=0.6499 
[epoch 2] step 4/44: loss=0.6543 
[epoch 2] step 6/44: loss=0.6507 
[epoch 2] step 8/44: loss=0.6484 
[epoch 2] step 10/44: loss=0.6449 
[epoch 2] step 12/44: loss=0.6448 
[epoch 2] step 14/44: loss=0.6444 
[epoch 2] step 16/44: loss=0.6489 
[epoch 2] step 18/44: loss=0.6505 
[epoch 2] step 20/44: loss=0.6476 
[epoch 2] step 22/44: loss=0.6457 
[epoch 2] step 24/44: loss=0.6432 
[epoch 2] step 26/44: loss=0.6423 
[epoch 2] step 28/44: loss=0.6437 
[epoch 2] step 30/44: loss=0.6426 
[epoch 2] step 32/44: loss=0.6418 
[epoch 2] step 34/44: loss=0.6407 
[epoch 2] step 36/44: loss=0.6384 
[epoch 2] step 38/44: loss=0.6400 
[epoch 2] step 40/44: loss=0.6376 
[epoch 2] step 42/44: loss=0.6355 
[epoch 2] step 44/44: loss=0.6333 
[epoch 2] train_loss(avg per step)=1.2665 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.1724 qwk=('0.2218', '0.1874', '0.3733') averageQWK=0.2609 macroEMD=0.3283 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    4    0
     0    0   28   27    0
     0    0   27   98    0
     0    0   10  106    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    5    0
     0    0   22   31    0
     0    0    9  113    0
     0    0    1  132    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    0   63    6    0
     0    0  115   37    0
     0    0   37   65    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=0.5861 
[epoch 3] step 4/44: loss=0.5703 
[epoch 3] step 6/44: loss=0.5614 
[epoch 3] step 8/44: loss=0.5663 
[epoch 3] step 10/44: loss=0.5770 
[epoch 3] step 12/44: loss=0.5719 
[epoch 3] step 14/44: loss=0.5671 
[epoch 3] step 16/44: loss=0.5681 
[epoch 3] step 18/44: loss=0.5668 
[epoch 3] step 20/44: loss=0.5625 
[epoch 3] step 22/44: loss=0.5579 
[epoch 3] step 24/44: loss=0.5528 
[epoch 3] step 26/44: loss=0.5546 
[epoch 3] step 28/44: loss=0.5517 
[epoch 3] step 30/44: loss=0.5516 
[epoch 3] step 32/44: loss=0.5523 
[epoch 3] step 34/44: loss=0.5499 
[epoch 3] step 36/44: loss=0.5436 
[epoch 3] step 38/44: loss=0.5437 
[epoch 3] step 40/44: loss=0.5442 
[epoch 3] step 42/44: loss=0.5425 
[epoch 3] step 44/44: loss=0.5390 
[epoch 3] train_loss(avg per step)=1.0779 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=1.0757 qwk=('0.4020', '0.3906', '0.3652') averageQWK=0.3859 macroEMD=0.2818 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    0    0
     0    1   52    2    0
     0    0  113   12    0
     0    0   56   60    0
     0    0    8   15    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   51    2    0
     0    0  111   11    0
     0    0   64   69    0
     0    0    3    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    7   62    0    0
     0    1  144    7    0
     0    0   68   34    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=0.5223 
[epoch 4] step 4/44: loss=0.5163 
[epoch 4] step 6/44: loss=0.5146 
[epoch 4] step 8/44: loss=0.5367 
[epoch 4] step 10/44: loss=0.5314 
[epoch 4] step 12/44: loss=0.5274 
[epoch 4] step 14/44: loss=0.5319 
[epoch 4] step 16/44: loss=0.5292 
[epoch 4] step 18/44: loss=0.5237 
[epoch 4] step 20/44: loss=0.5221 
[epoch 4] step 22/44: loss=0.5223 
[epoch 4] step 24/44: loss=0.5216 
[epoch 4] step 26/44: loss=0.5164 
[epoch 4] step 28/44: loss=0.5118 
[epoch 4] step 30/44: loss=0.5129 
[epoch 4] step 32/44: loss=0.5153 
[epoch 4] step 34/44: loss=0.5122 
[epoch 4] step 36/44: loss=0.5120 
[epoch 4] step 38/44: loss=0.5123 
[epoch 4] step 40/44: loss=0.5137 
[epoch 4] step 42/44: loss=0.5127 
[epoch 4] step 44/44: loss=0.5096 
[epoch 4] train_loss(avg per step)=1.0193 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=1.0065 qwk=('0.5432', '0.5303', '0.4269') averageQWK=0.5001 macroEMD=0.2582 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0    7   44    4    0
     0   11   85   29    0
     0    1   28   87    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    0
     0    4   44    5    0
     0    2   94   26    0
     0    0   28  105    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    9   60    0    0
     0    2  132   18    0
     0    0   56   46    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=0.4336 
[epoch 5] step 4/44: loss=0.4544 
[epoch 5] step 6/44: loss=0.4805 
[epoch 5] step 8/44: loss=0.4709 
[epoch 5] step 10/44: loss=0.4726 
[epoch 5] step 12/44: loss=0.4739 
[epoch 5] step 14/44: loss=0.4762 
[epoch 5] step 16/44: loss=0.4776 
[epoch 5] step 18/44: loss=0.4862 
[epoch 5] step 20/44: loss=0.4857 
[epoch 5] step 22/44: loss=0.4799 
[epoch 5] step 24/44: loss=0.4905 
[epoch 5] step 26/44: loss=0.4971 
[epoch 5] step 28/44: loss=0.4945 
[epoch 5] step 30/44: loss=0.4948 
[epoch 5] step 32/44: loss=0.4920 
[epoch 5] step 34/44: loss=0.4927 
[epoch 5] step 36/44: loss=0.4934 
[epoch 5] step 38/44: loss=0.4933 
[epoch 5] step 40/44: loss=0.4918 
[epoch 5] step 42/44: loss=0.4894 
[epoch 5] step 44/44: loss=0.4845 
[epoch 5] train_loss(avg per step)=0.9690 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=0.9862 qwk=('0.5159', '0.5289', '0.5102') averageQWK=0.5184 macroEMD=0.2450 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    0    0
     0    3   48    4    0
     0    1   93   31    0
     0    0   29   87    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0    5   43    5    0
     0    3   84   35    0
     0    0   23  110    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    9   56    4    0
     0    3  113   36    0
     0    0   25   77    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=0.4029 
[epoch 6] step 4/44: loss=0.4454 
[epoch 6] step 6/44: loss=0.4571 
[epoch 6] step 8/44: loss=0.4592 
[epoch 6] step 10/44: loss=0.4581 
[epoch 6] step 12/44: loss=0.4648 
[epoch 6] step 14/44: loss=0.4655 
[epoch 6] step 16/44: loss=0.4601 
[epoch 6] step 18/44: loss=0.4599 
[epoch 6] step 20/44: loss=0.4600 
[epoch 6] step 22/44: loss=0.4627 
[epoch 6] step 24/44: loss=0.4588 
[epoch 6] step 26/44: loss=0.4557 
[epoch 6] step 28/44: loss=0.4498 
[epoch 6] step 30/44: loss=0.4503 
[epoch 6] step 32/44: loss=0.4500 
[epoch 6] step 34/44: loss=0.4450 
[epoch 6] step 36/44: loss=0.4446 
[epoch 6] step 38/44: loss=0.4445 
[epoch 6] step 40/44: loss=0.4455 
[epoch 6] step 42/44: loss=0.4445 
[epoch 6] step 44/44: loss=0.4441 
[epoch 6] train_loss(avg per step)=0.8881 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=0.9432 qwk=('0.6396', '0.5762', '0.5974') averageQWK=0.6044 macroEMD=0.2278 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   25   27    3    0
     0   18   73   34    0
     0    1   26   89    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0    4   46    3    0
     0    1   94   27    0
     0    0   27  106    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   24   44    1    0
     0   11  114   27    0
     0    0   34   68    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=0.3547 
[epoch 7] step 4/44: loss=0.3702 
[epoch 7] step 6/44: loss=0.3737 
[epoch 7] step 8/44: loss=0.3728 
[epoch 7] step 10/44: loss=0.3802 
[epoch 7] step 12/44: loss=0.3759 
[epoch 7] step 14/44: loss=0.3820 
[epoch 7] step 16/44: loss=0.3850 
[epoch 7] step 18/44: loss=0.3873 
[epoch 7] step 20/44: loss=0.3860 
[epoch 7] step 22/44: loss=0.3875 
[epoch 7] step 24/44: loss=0.3933 
[epoch 7] step 26/44: loss=0.3918 
[epoch 7] step 28/44: loss=0.3962 
[epoch 7] step 30/44: loss=0.3988 
[epoch 7] step 32/44: loss=0.3954 
[epoch 7] step 34/44: loss=0.3946 
[epoch 7] step 36/44: loss=0.3988 
[epoch 7] step 38/44: loss=0.4026 
[epoch 7] step 40/44: loss=0.4016 
[epoch 7] step 42/44: loss=0.4028 
[epoch 7] step 44/44: loss=0.4007 
[epoch 7] train_loss(avg per step)=0.8013 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=0.9613 qwk=('0.6130', '0.6542', '0.5527') averageQWK=0.6067 macroEMD=0.2257 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   22   29    4    0
     0   10   81   33    1
     0    1   22   93    0
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   28   22    3    0
     0   15   75   32    0
     0    3   22  108    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   22   46    1    0
     0   14  114   24    0
     0    0   40   62    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=0.3653 
[epoch 8] step 4/44: loss=0.3634 
[epoch 8] step 6/44: loss=0.3837 
[epoch 8] step 8/44: loss=0.3679 
[epoch 8] step 10/44: loss=0.3624 
[epoch 8] step 12/44: loss=0.3742 
[epoch 8] step 14/44: loss=0.3702 
[epoch 8] step 16/44: loss=0.3652 
[epoch 8] step 18/44: loss=0.3716 
[epoch 8] step 20/44: loss=0.3758 
[epoch 8] step 22/44: loss=0.3742 
[epoch 8] step 24/44: loss=0.3778 
[epoch 8] step 26/44: loss=0.3779 
[epoch 8] step 28/44: loss=0.3736 
[epoch 8] step 30/44: loss=0.3734 
[epoch 8] step 32/44: loss=0.3793 
[epoch 8] step 34/44: loss=0.3837 
[epoch 8] step 36/44: loss=0.3836 
[epoch 8] step 38/44: loss=0.3801 
[epoch 8] step 40/44: loss=0.3757 
[epoch 8] step 42/44: loss=0.3749 
[epoch 8] step 44/44: loss=0.3774 
[epoch 8] train_loss(avg per step)=0.7549 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=0.9439 qwk=('0.5927', '0.6309', '0.6245') averageQWK=0.6160 macroEMD=0.2184 tailR0=('0.0870', '0.0000', '0.0000') tailR0avg=0.0290
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   17   36    2    0
     0   12   96   16    1
     0    1   40   68    7
     0    0    5   14    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   22   29    2    0
     0   13   86   23    0
     0    2   35   96    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   43   26    0    0
     0   29  108   15    0
     0    0   49   53    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=0.3256 
[epoch 9] step 4/44: loss=0.3328 
[epoch 9] step 6/44: loss=0.3285 
[epoch 9] step 8/44: loss=0.3329 
[epoch 9] step 10/44: loss=0.3268 
[epoch 9] step 12/44: loss=0.3336 
[epoch 9] step 14/44: loss=0.3430 
[epoch 9] step 16/44: loss=0.3423 
[epoch 9] step 18/44: loss=0.3443 
[epoch 9] step 20/44: loss=0.3386 
[epoch 9] step 22/44: loss=0.3351 
[epoch 9] step 24/44: loss=0.3346 
[epoch 9] step 26/44: loss=0.3334 
[epoch 9] step 28/44: loss=0.3326 
[epoch 9] step 30/44: loss=0.3330 
[epoch 9] step 32/44: loss=0.3315 
[epoch 9] step 34/44: loss=0.3289 
[epoch 9] step 36/44: loss=0.3245 
[epoch 9] step 38/44: loss=0.3241 
[epoch 9] step 40/44: loss=0.3233 
[epoch 9] step 42/44: loss=0.3239 
[epoch 9] step 44/44: loss=0.3189 
[epoch 9] train_loss(avg per step)=0.6378 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=0.9514 qwk=('0.5900', '0.6399', '0.6137') averageQWK=0.6145 macroEMD=0.2144 tailR0=('0.0870', '0.0000', '0.0000') tailR0avg=0.0290
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   14   38    3    0
     0    8   84   32    1
     0    1   29   80    6
     0    0    2   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   21   29    3    0
     0   13   87   22    0
     0    2   33   98    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   34   34    1    0
     0   16  116   20    0
     0    0   40   62    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=0.2515 
[epoch 10] step 4/44: loss=0.2636 
[epoch 10] step 6/44: loss=0.2672 
[epoch 10] step 8/44: loss=0.2759 
[epoch 10] step 10/44: loss=0.2871 
[epoch 10] step 12/44: loss=0.2850 
[epoch 10] step 14/44: loss=0.2858 
[epoch 10] step 16/44: loss=0.2797 
[epoch 10] step 18/44: loss=0.2795 
[epoch 10] step 20/44: loss=0.2780 
[epoch 10] step 22/44: loss=0.2769 
[epoch 10] step 24/44: loss=0.2734 
[epoch 10] step 26/44: loss=0.2738 
[epoch 10] step 28/44: loss=0.2724 
[epoch 10] step 30/44: loss=0.2727 
[epoch 10] step 32/44: loss=0.2730 
[epoch 10] step 34/44: loss=0.2729 
[epoch 10] step 36/44: loss=0.2716 
[epoch 10] step 38/44: loss=0.2725 
[epoch 10] step 40/44: loss=0.2744 
[epoch 10] step 42/44: loss=0.2715 
[epoch 10] step 44/44: loss=0.2732 
[epoch 10] train_loss(avg per step)=0.5463 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=0.9764 qwk=('0.5677', '0.6208', '0.5822') averageQWK=0.5902 macroEMD=0.2165 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   24   28    3    0
     0   11   93   21    0
     0    1   45   68    2
     0    1    4   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   25   23    5    0
     0   13   80   29    0
     0    4   25  104    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   45   23    1    0
     0   28  111   13    0
     0    2   53   47    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.1663 
[epoch 11] step 4/44: loss=0.2040 
[epoch 11] step 6/44: loss=0.2265 
[epoch 11] step 8/44: loss=0.2150 
[epoch 11] step 10/44: loss=0.2235 
[epoch 11] step 12/44: loss=0.2210 
[epoch 11] step 14/44: loss=0.2300 
[epoch 11] step 16/44: loss=0.2364 
[epoch 11] step 18/44: loss=0.2392 
[epoch 11] step 20/44: loss=0.2390 
[epoch 11] step 22/44: loss=0.2407 
[epoch 11] step 24/44: loss=0.2384 
[epoch 11] step 26/44: loss=0.2368 
[epoch 11] step 28/44: loss=0.2336 
[epoch 11] step 30/44: loss=0.2368 
[epoch 11] step 32/44: loss=0.2369 
[epoch 11] step 34/44: loss=0.2362 
[epoch 11] step 36/44: loss=0.2378 
[epoch 11] step 38/44: loss=0.2370 
[epoch 11] step 40/44: loss=0.2364 
[epoch 11] step 42/44: loss=0.2369 
[epoch 11] step 44/44: loss=0.2378 
[epoch 11] train_loss(avg per step)=0.4756 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=0.9851 qwk=('0.5749', '0.5895', '0.5248') averageQWK=0.5631 macroEMD=0.2222 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   21   30    4    0
     0   13   87   25    0
     0    1   35   79    1
     0    1    2   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   17   34    2    0
     0    8   91   23    0
     0    2   45   86    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   33   35    1    0
     0   22  116   14    0
     0    0   63   39    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=0.2481 
[epoch 12] step 4/44: loss=0.2406 
[epoch 12] step 6/44: loss=0.2262 
[epoch 12] step 8/44: loss=0.2118 
[epoch 12] step 10/44: loss=0.1990 
[epoch 12] step 12/44: loss=0.2033 
[epoch 12] step 14/44: loss=0.2006 
[epoch 12] step 16/44: loss=0.2021 
[epoch 12] step 18/44: loss=0.2045 
[epoch 12] step 20/44: loss=0.1989 
[epoch 12] step 22/44: loss=0.1986 
[epoch 12] step 24/44: loss=0.1990 
[epoch 12] step 26/44: loss=0.1974 
[epoch 12] step 28/44: loss=0.1978 
[epoch 12] step 30/44: loss=0.1957 
[epoch 12] step 32/44: loss=0.1988 
[epoch 12] step 34/44: loss=0.1957 
[epoch 12] step 36/44: loss=0.1957 
[epoch 12] step 38/44: loss=0.1987 
[epoch 12] step 40/44: loss=0.1973 
[epoch 12] step 42/44: loss=0.1936 
[epoch 12] step 44/44: loss=0.1905 
[epoch 12] train_loss(avg per step)=0.3810 lambda[min,max]=[0.495050,1.000000]
[epoch 12] val_loss=1.0244 qwk=('0.6156', '0.5784', '0.5737') averageQWK=0.5892 macroEMD=0.2132 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   21   30    4    0
     0   11   75   39    0
     0    1   21   90    4
     0    0    1   19    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    0    2    0
     0   21   25    7    0
     0   14   62   46    0
     0    4   14  115    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   29   39    1    0
     0   17  101   34    0
     0    0   37   65    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.1781 
[epoch 13] step 4/44: loss=0.1945 
[epoch 13] step 6/44: loss=0.1890 
[epoch 13] step 8/44: loss=0.1912 
[epoch 13] step 10/44: loss=0.1723 
[epoch 13] step 12/44: loss=0.1774 
[epoch 13] step 14/44: loss=0.1795 
[epoch 13] step 16/44: loss=0.1739 
[epoch 13] step 18/44: loss=0.1709 
[epoch 13] step 20/44: loss=0.1718 
[epoch 13] step 22/44: loss=0.1712 
[epoch 13] step 24/44: loss=0.1730 
[epoch 13] step 26/44: loss=0.1687 
[epoch 13] step 28/44: loss=0.1664 
[epoch 13] step 30/44: loss=0.1659 
[epoch 13] step 32/44: loss=0.1640 
[epoch 13] step 34/44: loss=0.1621 
[epoch 13] step 36/44: loss=0.1608 
[epoch 13] step 38/44: loss=0.1600 
[epoch 13] step 40/44: loss=0.1628 
[epoch 13] step 42/44: loss=0.1628 
[epoch 13] step 44/44: loss=0.1637 
[epoch 13] train_loss(avg per step)=0.3273 lambda[min,max]=[0.483127,1.000000]
[epoch 13] val_loss=0.9994 qwk=('0.6034', '0.6183', '0.5447') averageQWK=0.5888 macroEMD=0.2110 tailR0=('0.2391', '0.0417', '0.0000') tailR0avg=0.0936
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   23   28    4    0
     0    8   87   26    4
     0    1   36   71    8
     0    1    2    9   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   20   30    3    0
     0    9   89   23    1
     0    2   32   96    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   27   40    2    0
     0   15  110   27    0
     0    1   41   60    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.1394 
[epoch 14] step 4/44: loss=0.1311 
[epoch 14] step 6/44: loss=0.1366 
[epoch 14] step 8/44: loss=0.1379 
[epoch 14] step 10/44: loss=0.1376 
[epoch 14] step 12/44: loss=0.1353 
[epoch 14] step 14/44: loss=0.1345 
[epoch 14] step 16/44: loss=0.1322 
[epoch 14] step 18/44: loss=0.1316 
[epoch 14] step 20/44: loss=0.1272 
[epoch 14] step 22/44: loss=0.1300 
[epoch 14] step 24/44: loss=0.1312 
[epoch 14] step 26/44: loss=0.1325 
[epoch 14] step 28/44: loss=0.1309 
[epoch 14] step 30/44: loss=0.1307 
[epoch 14] step 32/44: loss=0.1315 
[epoch 14] step 34/44: loss=0.1303 
[epoch 14] step 36/44: loss=0.1323 
[epoch 14] step 38/44: loss=0.1340 
[epoch 14] step 40/44: loss=0.1358 
[epoch 14] step 42/44: loss=0.1365 
[epoch 14] step 44/44: loss=0.1364 
[epoch 14] train_loss(avg per step)=0.2727 lambda[min,max]=[0.484449,1.000000]
[epoch 14] val_loss=1.0517 qwk=('0.5697', '0.6178', '0.5226') averageQWK=0.5700 macroEMD=0.2256 tailR0=('0.1739', '0.0417', '0.0000') tailR0avg=0.0719
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   21   32    2    0
     0    7  102   14    2
     0    0   56   51    9
     0    0    7    8    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   22   27    4    0
     0   14   82   26    0
     0    5   26   99    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   32   37    0    0
     0   17  127    8    0
     0    0   66   36    0
     0    0    1    1    0
[epoch 15] step 2/44: loss=0.1634 
[epoch 15] step 4/44: loss=0.1654 
[epoch 15] step 6/44: loss=0.1676 
[epoch 15] step 8/44: loss=0.1502 
[epoch 15] step 10/44: loss=0.1463 
[epoch 15] step 12/44: loss=0.1398 
[epoch 15] step 14/44: loss=0.1354 
[epoch 15] step 16/44: loss=0.1349 
[epoch 15] step 18/44: loss=0.1370 
[epoch 15] step 20/44: loss=0.1358 
[epoch 15] step 22/44: loss=0.1331 
[epoch 15] step 24/44: loss=0.1297 
[epoch 15] step 26/44: loss=0.1332 
[epoch 15] step 28/44: loss=0.1277 
[epoch 15] step 30/44: loss=0.1271 
[epoch 15] step 32/44: loss=0.1271 
[epoch 15] step 34/44: loss=0.1248 
[epoch 15] step 36/44: loss=0.1225 
[epoch 15] step 38/44: loss=0.1234 
[epoch 15] step 40/44: loss=0.1224 
[epoch 15] step 42/44: loss=0.1226 
[epoch 15] step 44/44: loss=0.1211 
[epoch 15] train_loss(avg per step)=0.2422 lambda[min,max]=[0.491439,1.000000]
[epoch 15] val_loss=1.0516 qwk=('0.5921', '0.6079', '0.5683') averageQWK=0.5894 macroEMD=0.2087 tailR0=('0.0435', '0.0417', '0.0000') tailR0avg=0.0284
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   24   29    2    0
     0   14   86   25    0
     0    1   41   72    2
     0    1    3   17    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   24   26    3    0
     0   17   81   24    0
     0    5   35   93    0
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   42   26    1    0
     0   31  110   11    0
     0    1   61   40    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=0.1482 
[epoch 16] step 4/44: loss=0.1416 
[epoch 16] step 6/44: loss=0.1241 
[epoch 16] step 8/44: loss=0.1142 
[epoch 16] step 10/44: loss=0.1100 
[epoch 16] step 12/44: loss=0.1054 
[epoch 16] step 14/44: loss=0.1063 
[epoch 16] step 16/44: loss=0.1057 
[epoch 16] step 18/44: loss=0.0998 
[epoch 16] step 20/44: loss=0.0959 
[epoch 16] step 22/44: loss=0.0953 
[epoch 16] step 24/44: loss=0.0930 
[epoch 16] step 26/44: loss=0.0903 
[epoch 16] step 28/44: loss=0.0895 
[epoch 16] step 30/44: loss=0.0866 
[epoch 16] step 32/44: loss=0.0852 
[epoch 16] step 34/44: loss=0.0831 
[epoch 16] step 36/44: loss=0.0832 
[epoch 16] step 38/44: loss=0.0813 
[epoch 16] step 40/44: loss=0.0811 
[epoch 16] step 42/44: loss=0.0821 
[epoch 16] step 44/44: loss=0.0818 
[epoch 16] train_loss(avg per step)=0.1636 lambda[min,max]=[0.475796,1.000000]
[epoch 16] val_loss=1.0706 qwk=('0.5585', '0.6226', '0.5693') averageQWK=0.5835 macroEMD=0.2165 tailR0=('0.0935', '0.1111', '0.0000') tailR0avg=0.0682
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    5    0    0
     2   17   32    4    0
     1    7   91   26    0
     0    0   45   68    3
     0    0    4   17    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    1    0
     0   22   28    3    0
     0    9   87   26    0
     0    2   33   98    0
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   41   28    0    0
     0   30  110   12    0
     0    1   59   42    0
     0    0    1    1    0
[epoch 17] step 2/44: loss=0.0624 
[epoch 17] step 4/44: loss=0.0584 
[epoch 17] step 6/44: loss=0.0602 
[epoch 17] step 8/44: loss=0.0598 
[epoch 17] step 10/44: loss=0.0608 
[epoch 17] step 12/44: loss=0.0618 
[epoch 17] step 14/44: loss=0.0620 
[epoch 17] step 16/44: loss=0.0608 
[epoch 17] step 18/44: loss=0.0595 
[epoch 17] step 20/44: loss=0.0594 
[epoch 17] step 22/44: loss=0.0567 
[epoch 17] step 24/44: loss=0.0547 
[epoch 17] step 26/44: loss=0.0556 
[epoch 17] step 28/44: loss=0.0552 
[epoch 17] step 30/44: loss=0.0558 
[epoch 17] step 32/44: loss=0.0547 
[epoch 17] step 34/44: loss=0.0534 
[epoch 17] step 36/44: loss=0.0523 
[epoch 17] step 38/44: loss=0.0525 
[epoch 17] step 40/44: loss=0.0538 
[epoch 17] step 42/44: loss=0.0538 
[epoch 17] step 44/44: loss=0.0516 
[epoch 17] train_loss(avg per step)=0.1032 lambda[min,max]=[0.447683,1.000000]
[epoch 17] val_loss=1.0919 qwk=('0.5837', '0.5893', '0.5637') averageQWK=0.5789 macroEMD=0.2125 tailR0=('0.1370', '0.1528', '0.0000') tailR0avg=0.0966
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    1    0
     3   18   30    4    0
     0   15   72   37    1
     0    1   27   80    8
     0    1    2   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    1    2    0
     1   14   33    5    0
     0    7   87   28    0
     0    1   33   99    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     2   26   39    2    0
     0   17  107   28    0
     0    1   37   64    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=0.0575 
[epoch 18] step 4/44: loss=0.0697 
[epoch 18] step 6/44: loss=0.0608 
[epoch 18] step 8/44: loss=0.0618 
[epoch 18] step 10/44: loss=0.0471 
[epoch 18] step 12/44: loss=0.0392 
[epoch 18] step 14/44: loss=0.0383 
[epoch 18] step 16/44: loss=0.0355 
[epoch 18] step 18/44: loss=0.0393 
[epoch 18] step 20/44: loss=0.0397 
[epoch 18] step 22/44: loss=0.0396 
[epoch 18] step 24/44: loss=0.0361 
[epoch 18] step 26/44: loss=0.0332 
[epoch 18] step 28/44: loss=0.0339 
[epoch 18] step 30/44: loss=0.0329 
[epoch 18] step 32/44: loss=0.0321 
[epoch 18] step 34/44: loss=0.0319 
[epoch 18] step 36/44: loss=0.0313 
[epoch 18] step 38/44: loss=0.0316 
[epoch 18] step 40/44: loss=0.0311 
[epoch 18] step 42/44: loss=0.0315 
[epoch 18] step 44/44: loss=0.0306 
[epoch 18] train_loss(avg per step)=0.0612 lambda[min,max]=[0.389893,1.000000]
[epoch 18] val_loss=1.1251 qwk=('0.5852', '0.5716', '0.5307') averageQWK=0.5625 macroEMD=0.2137 tailR0=('0.1804', '0.1111', '0.0000') tailR0avg=0.0972
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    5    0    0
     2   19   31    3    0
     0    9   91   22    3
     0    0   43   65    8
     0    1    2   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    1    2    0
     0   19   28    6    0
     0   14   77   31    0
     0    4   27  102    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     2   33   32    2    0
     0   24  110   18    0
     0    1   55   46    0
     0    0    0    2    0
[epoch 19] step 2/44: loss=0.0117 
[epoch 19] step 4/44: loss=-0.0018 
[epoch 19] step 6/44: loss=0.0037 
[epoch 19] step 8/44: loss=0.0008 
[epoch 19] step 10/44: loss=-0.0015 
[epoch 19] step 12/44: loss=-0.0028 
[epoch 19] step 14/44: loss=0.0021 
[epoch 19] step 16/44: loss=0.0017 
[epoch 19] step 18/44: loss=-0.0013 
[epoch 19] step 20/44: loss=0.0003 
[epoch 19] step 22/44: loss=-0.0010 
[epoch 19] step 24/44: loss=0.0001 
[epoch 19] step 26/44: loss=0.0024 
[epoch 19] step 28/44: loss=0.0025 
[epoch 19] step 30/44: loss=0.0030 
[epoch 19] step 32/44: loss=0.0033 
[epoch 19] step 34/44: loss=0.0028 
[epoch 19] step 36/44: loss=0.0029 
[epoch 19] step 38/44: loss=0.0032 
[epoch 19] step 40/44: loss=0.0012 
[epoch 19] step 42/44: loss=0.0019 
[epoch 19] step 44/44: loss=0.0006 
[epoch 19] train_loss(avg per step)=0.0012 lambda[min,max]=[0.356957,1.000000]
[epoch 19] val_loss=1.1526 qwk=('0.5411', '0.5728', '0.5443') averageQWK=0.5527 macroEMD=0.2123 tailR0=('0.1152', '0.1111', '0.1250') tailR0avg=0.1171
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    4    0    0
     4   15   33    3    0
     0   11   88   24    2
     0    0   43   66    7
     0    1    7   12    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    1    2    0
     0   16   28    9    0
     0   12   79   31    0
     0    2   22  109    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     2   32   34    1    0
     0   19  116   17    0
     0    1   54   47    0
     0    0    1    1    0
[epoch 20] step 2/44: loss=-0.0137 
[epoch 20] step 4/44: loss=-0.0018 
[epoch 20] step 6/44: loss=-0.0004 
[epoch 20] step 8/44: loss=0.0010 
[epoch 20] step 10/44: loss=-0.0035 
[epoch 20] step 12/44: loss=-0.0052 
[epoch 20] step 14/44: loss=-0.0074 
[epoch 20] step 16/44: loss=-0.0094 
[epoch 20] step 18/44: loss=-0.0119 
[epoch 20] step 20/44: loss=-0.0112 
[epoch 20] step 22/44: loss=-0.0126 
[epoch 20] step 24/44: loss=-0.0132 
[epoch 20] step 26/44: loss=-0.0140 
[epoch 20] step 28/44: loss=-0.0142 
[epoch 20] step 30/44: loss=-0.0150 
[epoch 20] step 32/44: loss=-0.0141 
[epoch 20] step 34/44: loss=-0.0138 
[epoch 20] step 36/44: loss=-0.0157 
[epoch 20] step 38/44: loss=-0.0144 
[epoch 20] step 40/44: loss=-0.0141 
[epoch 20] step 42/44: loss=-0.0144 
[epoch 20] step 44/44: loss=-0.0155 
[epoch 20] train_loss(avg per step)=-0.0309 lambda[min,max]=[0.435074,1.000000]
[epoch 20] val_loss=1.1718 qwk=('0.5778', '0.5851', '0.5263') averageQWK=0.5631 macroEMD=0.2105 tailR0=('0.1370', '0.1111', '0.0000') tailR0avg=0.0827
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    5    0    0
     4   15   34    2    0
     0   10   88   27    0
     0    0   39   71    6
     0    0    7   12    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    1    2    0
     0   13   36    4    0
     0    9   80   33    0
     0    2   25  106    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     2   24   41    2    0
     0   16  110   26    0
     0    1   45   56    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=-0.0359 
[epoch 21] step 4/44: loss=-0.0333 
[epoch 21] step 6/44: loss=-0.0248 
[epoch 21] step 8/44: loss=-0.0263 
[epoch 21] step 10/44: loss=-0.0276 
[epoch 21] step 12/44: loss=-0.0276 
[epoch 21] step 14/44: loss=-0.0314 
[epoch 21] step 16/44: loss=-0.0302 
[epoch 21] step 18/44: loss=-0.0279 
[epoch 21] step 20/44: loss=-0.0293 
[epoch 21] step 22/44: loss=-0.0297 
[epoch 21] step 24/44: loss=-0.0286 
[epoch 21] step 26/44: loss=-0.0263 
[epoch 21] step 28/44: loss=-0.0259 
[epoch 21] step 30/44: loss=-0.0269 
[epoch 21] step 32/44: loss=-0.0286 
[epoch 21] step 34/44: loss=-0.0282 
[epoch 21] step 36/44: loss=-0.0259 
[epoch 21] step 38/44: loss=-0.0254 
[epoch 21] step 40/44: loss=-0.0257 
[epoch 21] step 42/44: loss=-0.0261 
[epoch 21] step 44/44: loss=-0.0261 
[epoch 21] train_loss(avg per step)=-0.0521 lambda[min,max]=[0.439824,1.000000]
[epoch 21] val_loss=1.1816 qwk=('0.5955', '0.5960', '0.5711') averageQWK=0.5875 macroEMD=0.2084 tailR0=('0.2457', '0.2083', '0.0000') tailR0avg=0.1513
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    1    0
     3   11   37    4    0
     0    6   86   32    1
     0    0   30   78    8
     0    1    1   12    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    1    2    0
     0   17   28    8    0
     0   11   70   41    0
     0    2   15  116    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     2   26   40    1    0
     0   13  114   25    0
     0    1   40   61    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=-0.0255 
[epoch 22] step 4/44: loss=-0.0403 
[epoch 22] step 6/44: loss=-0.0490 
[epoch 22] step 8/44: loss=-0.0446 
[epoch 22] step 10/44: loss=-0.0447 
[epoch 22] step 12/44: loss=-0.0431 
[epoch 22] step 14/44: loss=-0.0441 
[epoch 22] step 16/44: loss=-0.0431 
[epoch 22] step 18/44: loss=-0.0429 
[epoch 22] step 20/44: loss=-0.0401 
[epoch 22] step 22/44: loss=-0.0409 
[epoch 22] step 24/44: loss=-0.0395 
[epoch 22] step 26/44: loss=-0.0401 
[epoch 22] step 28/44: loss=-0.0402 
[epoch 22] step 30/44: loss=-0.0411 
[epoch 22] step 32/44: loss=-0.0407 
[epoch 22] step 34/44: loss=-0.0425 
[epoch 22] step 36/44: loss=-0.0423 
[epoch 22] step 38/44: loss=-0.0423 
[epoch 22] step 40/44: loss=-0.0415 
[epoch 22] step 42/44: loss=-0.0414 
[epoch 22] step 44/44: loss=-0.0402 
[epoch 22] train_loss(avg per step)=-0.0804 lambda[min,max]=[0.415335,1.000000]
[epoch 22] val_loss=1.1996 qwk=('0.5790', '0.5795', '0.5812') averageQWK=0.5799 macroEMD=0.2095 tailR0=('0.1587', '0.1111', '0.0000') tailR0avg=0.0899
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    1    0
     1   19   31    4    0
     0   13   83   28    1
     0    1   35   74    6
     0    1    2   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    1    2    0
     0   15   30    8    0
     1   10   67   44    0
     0    0   17  116    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     2   29   35    3    0
     0   16  102   34    0
     0    1   34   67    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=-0.0447 
[epoch 23] step 4/44: loss=-0.0461 
[epoch 23] step 6/44: loss=-0.0482 
[epoch 23] step 8/44: loss=-0.0537 
[epoch 23] step 10/44: loss=-0.0544 
[epoch 23] step 12/44: loss=-0.0535 
[epoch 23] step 14/44: loss=-0.0517 
[epoch 23] step 16/44: loss=-0.0527 
[epoch 23] step 18/44: loss=-0.0531 
[epoch 23] step 20/44: loss=-0.0535 
[epoch 23] step 22/44: loss=-0.0531 
[epoch 23] step 24/44: loss=-0.0532 
[epoch 23] step 26/44: loss=-0.0537 
[epoch 23] step 28/44: loss=-0.0547 
[epoch 23] step 30/44: loss=-0.0545 
[epoch 23] step 32/44: loss=-0.0546 
[epoch 23] step 34/44: loss=-0.0541 
[epoch 23] step 36/44: loss=-0.0546 
[epoch 23] step 38/44: loss=-0.0541 
[epoch 23] step 40/44: loss=-0.0543 
[epoch 23] step 42/44: loss=-0.0545 
[epoch 23] step 44/44: loss=-0.0551 
[epoch 23] train_loss(avg per step)=-0.1102 lambda[min,max]=[0.376217,1.000000]
[epoch 23] val_loss=1.2046 qwk=('0.5706', '0.5924', '0.6203') averageQWK=0.5945 macroEMD=0.2037 tailR0=('0.1370', '0.2500', '0.0000') tailR0avg=0.1290
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    1    0
     4   15   34    2    0
     0    9   87   27    2
     0    0   38   69    9
     0    1    3   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    1    2    0
     1   13   31    8    0
     1    9   81   31    0
     0    0   26  106    1
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     1   38   28    2    0
     0   23  100   29    0
     0    1   34   67    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=-0.0661 
[epoch 24] step 4/44: loss=-0.0649 
[epoch 24] step 6/44: loss=-0.0680 
[epoch 24] step 8/44: loss=-0.0635 
[epoch 24] step 10/44: loss=-0.0662 
[epoch 24] step 12/44: loss=-0.0669 
[epoch 24] step 14/44: loss=-0.0658 
[epoch 24] step 16/44: loss=-0.0653 
[epoch 24] step 18/44: loss=-0.0666 
[epoch 24] step 20/44: loss=-0.0675 
[epoch 24] step 22/44: loss=-0.0650 
[epoch 24] step 24/44: loss=-0.0646 
[epoch 24] step 26/44: loss=-0.0642 
[epoch 24] step 28/44: loss=-0.0627 
[epoch 24] step 30/44: loss=-0.0631 
[epoch 24] step 32/44: loss=-0.0637 
[epoch 24] step 34/44: loss=-0.0636 
[epoch 24] step 36/44: loss=-0.0637 
[epoch 24] step 38/44: loss=-0.0636 
[epoch 24] step 40/44: loss=-0.0628 
[epoch 24] step 42/44: loss=-0.0630 
[epoch 24] step 44/44: loss=-0.0642 
[epoch 24] train_loss(avg per step)=-0.1284 lambda[min,max]=[0.382155,1.000000]
[epoch 24] val_loss=1.2433 qwk=('0.5845', '0.5746', '0.5504') averageQWK=0.5698 macroEMD=0.2115 tailR0=('0.2022', '0.0000', '0.0000') tailR0avg=0.0674
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    1    0
     1   16   34    4    0
     0    9   82   32    2
     0    0   31   76    9
     0    1    1   14    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    2    0
     0   15   30    8    0
     0    8   72   42    0
     0    0   18  115    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     1   29   39    0    0
     0   19  114   19    0
     0    1   47   54    0
     0    0    1    1    0
[epoch 25] step 2/44: loss=-0.0675 
[epoch 25] step 4/44: loss=-0.0709 
[epoch 25] step 6/44: loss=-0.0740 
[epoch 25] step 8/44: loss=-0.0708 
[epoch 25] step 10/44: loss=-0.0711 
[epoch 25] step 12/44: loss=-0.0708 
[epoch 25] step 14/44: loss=-0.0706 
[epoch 25] step 16/44: loss=-0.0712 
[epoch 25] step 18/44: loss=-0.0716 
[epoch 25] step 20/44: loss=-0.0720 
[epoch 25] step 22/44: loss=-0.0720 
[epoch 25] step 24/44: loss=-0.0726 
[epoch 25] step 26/44: loss=-0.0728 
[epoch 25] step 28/44: loss=-0.0736 
[epoch 25] step 30/44: loss=-0.0731 
[epoch 25] step 32/44: loss=-0.0724 
[epoch 25] step 34/44: loss=-0.0726 
[epoch 25] step 36/44: loss=-0.0728 
[epoch 25] step 38/44: loss=-0.0723 
[epoch 25] step 40/44: loss=-0.0723 
[epoch 25] step 42/44: loss=-0.0722 
[epoch 25] step 44/44: loss=-0.0723 
[epoch 25] train_loss(avg per step)=-0.1447 lambda[min,max]=[0.406900,1.000000]
[epoch 25] val_loss=1.2358 qwk=('0.5464', '0.5917', '0.5511') averageQWK=0.5631 macroEMD=0.2110 tailR0=('0.1587', '0.2500', '0.0000') tailR0avg=0.1362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    5    0    0
     2   17   33    3    0
     0    9   87   26    3
     0    0   40   70    6
     0    1    6   11    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    2    1    0
     0   15   33    5    0
     1   10   84   27    0
     0    0   38   94    1
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     1   37   31    0    0
     0   29  107   15    1
     0    1   55   46    0
     0    0    1    1    0
[epoch 26] step 2/44: loss=-0.0698 
[epoch 26] step 4/44: loss=-0.0710 
[epoch 26] step 6/44: loss=-0.0754 
[epoch 26] step 8/44: loss=-0.0760 
[epoch 26] step 10/44: loss=-0.0765 
[epoch 26] step 12/44: loss=-0.0779 
[epoch 26] step 14/44: loss=-0.0795 
[epoch 26] step 16/44: loss=-0.0808 
[epoch 26] step 18/44: loss=-0.0824 
[epoch 26] step 20/44: loss=-0.0813 
[epoch 26] step 22/44: loss=-0.0814 
[epoch 26] step 24/44: loss=-0.0813 
[epoch 26] step 26/44: loss=-0.0812 
[epoch 26] step 28/44: loss=-0.0814 
[epoch 26] step 30/44: loss=-0.0811 
[epoch 26] step 32/44: loss=-0.0806 
[epoch 26] step 34/44: loss=-0.0810 
[epoch 26] step 36/44: loss=-0.0807 
[epoch 26] step 38/44: loss=-0.0799 
[epoch 26] step 40/44: loss=-0.0804 
[epoch 26] step 42/44: loss=-0.0800 
[epoch 26] step 44/44: loss=-0.0809 
[epoch 26] train_loss(avg per step)=-0.1617 lambda[min,max]=[0.361203,1.000000]
[epoch 26] val_loss=1.2470 qwk=('0.5667', '0.6334', '0.5314') averageQWK=0.5772 macroEMD=0.2077 tailR0=('0.1152', '0.1667', '0.1250') tailR0avg=0.1356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    4    0    0
     2   17   34    2    0
     0   12   92   21    0
     0    0   46   66    4
     0    1    5   14    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    1    1    0
     0   19   29    5    0
     0   14   80   28    0
     0    1   28  104    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     2   21   45    1    0
     0   14  117   21    0
     0    1   47   54    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=-0.0843 
[epoch 27] step 4/44: loss=-0.0856 
[epoch 27] step 6/44: loss=-0.0847 
[epoch 27] step 8/44: loss=-0.0877 
[epoch 27] step 10/44: loss=-0.0873 
[epoch 27] step 12/44: loss=-0.0879 
[epoch 27] step 14/44: loss=-0.0874 
[epoch 27] step 16/44: loss=-0.0872 
[epoch 27] step 18/44: loss=-0.0857 
[epoch 27] step 20/44: loss=-0.0850 
[epoch 27] step 22/44: loss=-0.0845 
[epoch 27] step 24/44: loss=-0.0848 
[epoch 27] step 26/44: loss=-0.0852 
[epoch 27] step 28/44: loss=-0.0844 
[epoch 27] step 30/44: loss=-0.0848 
[epoch 27] step 32/44: loss=-0.0855 
[epoch 27] step 34/44: loss=-0.0855 
[epoch 27] step 36/44: loss=-0.0852 
[epoch 27] step 38/44: loss=-0.0842 
[epoch 27] step 40/44: loss=-0.0837 
[epoch 27] step 42/44: loss=-0.0835 
[epoch 27] step 44/44: loss=-0.0840 
[epoch 27] train_loss(avg per step)=-0.1680 lambda[min,max]=[0.396305,1.000000]
[epoch 27] val_loss=1.2751 qwk=('0.5867', '0.5883', '0.5116') averageQWK=0.5622 macroEMD=0.2087 tailR0=('0.1587', '0.1528', '0.1250') tailR0avg=0.1455
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    1    0
     4   15   32    4    0
     0   10   82   32    1
     0    1   30   79    6
     0    1    2   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    1    0
     0   15   32    6    0
     1    7   83   31    0
     0    0   34   99    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     3   18   46    2    0
     0    9  120   23    0
     0    1   46   55    0
     0    0    1    1    0
[epoch 28] step 2/44: loss=-0.0736 
[epoch 28] step 4/44: loss=-0.0810 
[epoch 28] step 6/44: loss=-0.0798 
[epoch 28] step 8/44: loss=-0.0816 
[epoch 28] step 10/44: loss=-0.0846 
[epoch 28] step 12/44: loss=-0.0849 
[epoch 28] step 14/44: loss=-0.0824 
[epoch 28] step 16/44: loss=-0.0827 
[epoch 28] step 18/44: loss=-0.0835 
[epoch 28] step 20/44: loss=-0.0832 
[epoch 28] step 22/44: loss=-0.0835 
[epoch 28] step 24/44: loss=-0.0847 
[epoch 28] step 26/44: loss=-0.0849 
[epoch 28] step 28/44: loss=-0.0854 
[epoch 28] step 30/44: loss=-0.0860 
[epoch 28] step 32/44: loss=-0.0860 
[epoch 28] step 34/44: loss=-0.0862 
[epoch 28] step 36/44: loss=-0.0865 
[epoch 28] step 38/44: loss=-0.0868 
[epoch 28] step 40/44: loss=-0.0866 
[epoch 28] step 42/44: loss=-0.0868 
[epoch 28] step 44/44: loss=-0.0871 
[epoch 28] train_loss(avg per step)=-0.1742 lambda[min,max]=[0.392497,1.000000]
[epoch 28] val_loss=1.2625 qwk=('0.5939', '0.5703', '0.5691') averageQWK=0.5778 macroEMD=0.2054 tailR0=('0.2022', '0.1528', '0.0000') tailR0avg=0.1183
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    5    0    0
     4   11   36    4    0
     0    7   86   29    3
     0    0   31   77    8
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    1    2    0
     0   13   32    8    0
     1    7   79   35    0
     0    1   23  109    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   37   30    2    0
     0   24  107   21    0
     0    1   46   55    0
     0    0    1    1    0
[epoch 29] step 2/44: loss=-0.0948 
[epoch 29] step 4/44: loss=-0.0926 
[epoch 29] step 6/44: loss=-0.0905 
[epoch 29] step 8/44: loss=-0.0916 
[epoch 29] step 10/44: loss=-0.0921 
[epoch 29] step 12/44: loss=-0.0901 
[epoch 29] step 14/44: loss=-0.0888 
[epoch 29] step 16/44: loss=-0.0886 
[epoch 29] step 18/44: loss=-0.0880 
[epoch 29] step 20/44: loss=-0.0871 
[epoch 29] step 22/44: loss=-0.0874 
[epoch 29] step 24/44: loss=-0.0879 
[epoch 29] step 26/44: loss=-0.0874 
[epoch 29] step 28/44: loss=-0.0876 
[epoch 29] step 30/44: loss=-0.0882 
[epoch 29] step 32/44: loss=-0.0883 
[epoch 29] step 34/44: loss=-0.0890 
[epoch 29] step 36/44: loss=-0.0885 
[epoch 29] step 38/44: loss=-0.0888 
[epoch 29] step 40/44: loss=-0.0889 
[epoch 29] step 42/44: loss=-0.0892 
[epoch 29] step 44/44: loss=-0.0898 
[epoch 29] train_loss(avg per step)=-0.1795 lambda[min,max]=[0.369322,1.000000]
[epoch 29] val_loss=1.2996 qwk=('0.5758', '0.6023', '0.5205') averageQWK=0.5662 macroEMD=0.2094 tailR0=('0.1152', '0.1944', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    4    0    0
     3   13   36    3    0
     0   10   88   26    1
     0    0   37   73    6
     0    1    3   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    1    0
     0   15   33    5    0
     0    9   83   30    0
     0    1   32  100    0
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     1   29   39    0    0
     0   20  114   18    0
     0    1   54   47    0
     0    0    1    1    0
[epoch 30] step 2/44: loss=-0.0907 
[epoch 30] step 4/44: loss=-0.0857 
[epoch 30] step 6/44: loss=-0.0895 
[epoch 30] step 8/44: loss=-0.0914 
[epoch 30] step 10/44: loss=-0.0920 
[epoch 30] step 12/44: loss=-0.0939 
[epoch 30] step 14/44: loss=-0.0942 
[epoch 30] step 16/44: loss=-0.0929 
[epoch 30] step 18/44: loss=-0.0924 
[epoch 30] step 20/44: loss=-0.0905 
[epoch 30] step 22/44: loss=-0.0903 
[epoch 30] step 24/44: loss=-0.0904 
[epoch 30] step 26/44: loss=-0.0907 
[epoch 30] step 28/44: loss=-0.0916 
[epoch 30] step 30/44: loss=-0.0920 
[epoch 30] step 32/44: loss=-0.0928 
[epoch 30] step 34/44: loss=-0.0929 
[epoch 30] step 36/44: loss=-0.0933 
[epoch 30] step 38/44: loss=-0.0937 
[epoch 30] step 40/44: loss=-0.0935 
[epoch 30] step 42/44: loss=-0.0932 
[epoch 30] step 44/44: loss=-0.0934 
[epoch 30] train_loss(avg per step)=-0.1869 lambda[min,max]=[0.379492,1.000000]
[epoch 30] val_loss=1.2863 qwk=('0.5841', '0.6088', '0.5498') averageQWK=0.5809 macroEMD=0.2028 tailR0=('0.1152', '0.1111', '0.1250') tailR0avg=0.1171
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    4    0    0
     1   16   36    2    0
     0   11   84   30    0
     0    0   36   78    2
     0    1    3   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    1    1    0
     0   15   34    4    0
     0   11   85   26    0
     0    0   37   96    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     1   26   41    1    0
     0   18  114   20    0
     0    1   46   55    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=-0.0968 
[epoch 31] step 4/44: loss=-0.0974 
[epoch 31] step 6/44: loss=-0.0968 
[epoch 31] step 8/44: loss=-0.0948 
[epoch 31] step 10/44: loss=-0.0953 
[epoch 31] step 12/44: loss=-0.0968 
[epoch 31] step 14/44: loss=-0.0974 
[epoch 31] step 16/44: loss=-0.0977 
[epoch 31] step 18/44: loss=-0.0971 
[epoch 31] step 20/44: loss=-0.0974 
[epoch 31] step 22/44: loss=-0.0968 
[epoch 31] step 24/44: loss=-0.0971 
[epoch 31] step 26/44: loss=-0.0965 
[epoch 31] step 28/44: loss=-0.0967 
[epoch 31] step 30/44: loss=-0.0969 
[epoch 31] step 32/44: loss=-0.0969 
[epoch 31] step 34/44: loss=-0.0968 
[epoch 31] step 36/44: loss=-0.0966 
[epoch 31] step 38/44: loss=-0.0969 
[epoch 31] step 40/44: loss=-0.0972 
[epoch 31] step 42/44: loss=-0.0969 
[epoch 31] step 44/44: loss=-0.0968 
[epoch 31] train_loss(avg per step)=-0.1935 lambda[min,max]=[0.411881,1.000000]
[epoch 31] val_loss=1.2918 qwk=('0.5657', '0.5905', '0.5448') averageQWK=0.5670 macroEMD=0.2049 tailR0=('0.1587', '0.1667', '0.0000') tailR0avg=0.1085
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    1    0
     2   16   35    2    0
     0   12   85   27    1
     0    0   41   69    6
     0    1    4   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    2    1    0
     0   14   33    6    0
     0   13   81   28    0
     0    0   34   99    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     1   33   35    0    0
     0   21  114   17    0
     0    1   53   48    0
     0    0    1    1    0
[epoch 32] step 2/44: loss=-0.0918 
[epoch 32] step 4/44: loss=-0.0963 
[epoch 32] step 6/44: loss=-0.0971 
[epoch 32] step 8/44: loss=-0.0961 
[epoch 32] step 10/44: loss=-0.0979 
[epoch 32] step 12/44: loss=-0.0977 
[epoch 32] step 14/44: loss=-0.0977 
[epoch 32] step 16/44: loss=-0.0974 
[epoch 32] step 18/44: loss=-0.0981 
[epoch 32] step 20/44: loss=-0.0987 
[epoch 32] step 22/44: loss=-0.0985 
[epoch 32] step 24/44: loss=-0.0986 
[epoch 32] step 26/44: loss=-0.0987 
[epoch 32] step 28/44: loss=-0.0986 
[epoch 32] step 30/44: loss=-0.0986 
[epoch 32] step 32/44: loss=-0.0986 
[epoch 32] step 34/44: loss=-0.0989 
[epoch 32] step 36/44: loss=-0.0989 
[epoch 32] step 38/44: loss=-0.0989 
[epoch 32] step 40/44: loss=-0.0989 
[epoch 32] step 42/44: loss=-0.0987 
[epoch 32] step 44/44: loss=-0.0987 
[epoch 32] train_loss(avg per step)=-0.1973 lambda[min,max]=[0.368068,1.000000]
[epoch 32] val_loss=1.3092 qwk=('0.5710', '0.5953', '0.5147') averageQWK=0.5603 macroEMD=0.2081 tailR0=('0.1370', '0.2083', '0.1250') tailR0avg=0.1568
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    1    0
     2   16   34    3    0
     0   12   81   31    1
     0    1   32   77    6
     0    1    3   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    2    1    0
     0   13   34    6    0
     0   11   81   30    0
     0    0   32  101    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     1   26   41    1    0
     0   15  118   19    0
     0    1   53   48    0
     0    0    1    1    0
[epoch 33] step 2/44: loss=-0.1032 
[epoch 33] step 4/44: loss=-0.1013 
[epoch 33] step 6/44: loss=-0.0982 
[epoch 33] step 8/44: loss=-0.0996 
[epoch 33] step 10/44: loss=-0.0995 
[epoch 33] step 12/44: loss=-0.0997 
[epoch 33] step 14/44: loss=-0.1004 
[epoch 33] step 16/44: loss=-0.1004 
[epoch 33] step 18/44: loss=-0.1003 
[epoch 33] step 20/44: loss=-0.1006 
[epoch 33] step 22/44: loss=-0.1009 
[epoch 33] step 24/44: loss=-0.1009 
[epoch 33] step 26/44: loss=-0.1011 
[epoch 33] step 28/44: loss=-0.1008 
[epoch 33] step 30/44: loss=-0.1002 
[epoch 33] step 32/44: loss=-0.1007 
[epoch 33] step 34/44: loss=-0.1010 
[epoch 33] step 36/44: loss=-0.1012 
[epoch 33] step 38/44: loss=-0.1009 
[epoch 33] step 40/44: loss=-0.1006 
[epoch 33] step 42/44: loss=-0.1008 
[epoch 33] step 44/44: loss=-0.1010 
[epoch 33] train_loss(avg per step)=-0.2019 lambda[min,max]=[0.375306,1.000000]
[epoch 33] val_loss=1.3079 qwk=('0.5679', '0.5852', '0.5424') averageQWK=0.5651 macroEMD=0.2063 tailR0=('0.1370', '0.1667', '0.0000') tailR0avg=0.1012
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    1    0
     3   16   34    2    0
     0   13   85   26    1
     0    0   38   72    6
     0    1    5   13    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    2    1    0
     0   13   34    6    0
     0   10   85   27    0
     0    0   36   97    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     1   34   33    1    0
     0   21  111   20    0
     0    1   54   47    0
     0    0    1    1    0
[epoch 34] step 2/44: loss=-0.1044 
[epoch 34] step 4/44: loss=-0.1055 
[epoch 34] step 6/44: loss=-0.1048 
[epoch 34] step 8/44: loss=-0.1040 
[epoch 34] step 10/44: loss=-0.1039 
[epoch 34] step 12/44: loss=-0.1032 
[epoch 34] step 14/44: loss=-0.1029 
[epoch 34] step 16/44: loss=-0.1025 
[epoch 34] step 18/44: loss=-0.1029 
[epoch 34] step 20/44: loss=-0.1031 
[epoch 34] step 22/44: loss=-0.1031 
[epoch 34] step 24/44: loss=-0.1029 
[epoch 34] step 26/44: loss=-0.1028 
[epoch 34] step 28/44: loss=-0.1034 
[epoch 34] step 30/44: loss=-0.1028 
[epoch 34] step 32/44: loss=-0.1029 
[epoch 34] step 34/44: loss=-0.1027 
[epoch 34] step 36/44: loss=-0.1022 
[epoch 34] step 38/44: loss=-0.1019 
[epoch 34] step 40/44: loss=-0.1017 
[epoch 34] step 42/44: loss=-0.1019 
[epoch 34] step 44/44: loss=-0.1019 
[epoch 34] train_loss(avg per step)=-0.2038 lambda[min,max]=[0.401461,1.000000]
[epoch 34] val_loss=1.3174 qwk=('0.5752', '0.5996', '0.5273') averageQWK=0.5674 macroEMD=0.2066 tailR0=('0.1152', '0.2083', '0.1250') tailR0avg=0.1495
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    1    0
     3   15   35    2    0
     0   12   88   25    0
     0    0   38   72    6
     0    1    4   15    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    1    1    0
     0   16   31    6    0
     0   14   80   28    0
     0    2   32   99    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     1   29   39    0    0
     0   18  114   20    0
     0    1   54   47    0
     0    0    1    1    0
[epoch 35] step 2/44: loss=-0.1052 
[epoch 35] step 4/44: loss=-0.1068 
[epoch 35] step 6/44: loss=-0.1024 
[epoch 35] step 8/44: loss=-0.1031 
[epoch 35] step 10/44: loss=-0.1026 
[epoch 35] step 12/44: loss=-0.1015 
[epoch 35] step 14/44: loss=-0.1020 
[epoch 35] step 16/44: loss=-0.1017 
[epoch 35] step 18/44: loss=-0.1020 
[epoch 35] step 20/44: loss=-0.1021 
[epoch 35] step 22/44: loss=-0.1024 
[epoch 35] step 24/44: loss=-0.1018 
[epoch 35] step 26/44: loss=-0.1019 
[epoch 35] step 28/44: loss=-0.1019 
[epoch 35] step 30/44: loss=-0.1016 
[epoch 35] step 32/44: loss=-0.1011 
[epoch 35] step 34/44: loss=-0.1011 
[epoch 35] step 36/44: loss=-0.1013 
[epoch 35] step 38/44: loss=-0.1014 
[epoch 35] step 40/44: loss=-0.1014 
[epoch 35] step 42/44: loss=-0.1018 
[epoch 35] step 44/44: loss=-0.1017 
[epoch 35] train_loss(avg per step)=-0.2035 lambda[min,max]=[0.359276,1.000000]
[epoch 35] val_loss=1.3115 qwk=('0.5737', '0.5995', '0.5337') averageQWK=0.5690 macroEMD=0.2057 tailR0=('0.1152', '0.2083', '0.1250') tailR0avg=0.1495
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    1    0
     3   16   34    2    0
     0   12   86   26    1
     0    0   37   73    6
     0    1    4   15    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    2    1    0
     0   16   31    6    0
     0   14   80   28    0
     0    2   29  102    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     1   30   38    0    0
     0   20  112   20    0
     0    1   53   48    0
     0    0    1    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold4/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold4/metrics.json
Done.
