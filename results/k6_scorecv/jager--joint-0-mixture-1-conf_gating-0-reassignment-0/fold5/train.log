[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.7347 
[epoch 1] step 4/44: loss=0.7246 
[epoch 1] step 6/44: loss=0.7121 
[epoch 1] step 8/44: loss=0.7185 
[epoch 1] step 10/44: loss=0.7170 
[epoch 1] step 12/44: loss=0.7160 
[epoch 1] step 14/44: loss=0.7158 
[epoch 1] step 16/44: loss=0.7159 
[epoch 1] step 18/44: loss=0.7145 
[epoch 1] step 20/44: loss=0.7157 
[epoch 1] step 22/44: loss=0.7136 
[epoch 1] step 24/44: loss=0.7143 
[epoch 1] step 26/44: loss=0.7141 
[epoch 1] step 28/44: loss=0.7132 
[epoch 1] step 30/44: loss=0.7135 
[epoch 1] step 32/44: loss=0.7122 
[epoch 1] step 34/44: loss=0.7121 
[epoch 1] step 36/44: loss=0.7092 
[epoch 1] step 38/44: loss=0.7072 
[epoch 1] step 40/44: loss=0.7051 
[epoch 1] step 42/44: loss=0.7043 
[epoch 1] step 44/44: loss=0.7028 
[epoch 1] train_loss(avg per step)=1.4057 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.2820 qwk=('0.1706', '0.1374', '0.0393') averageQWK=0.1158 macroEMD=0.3661 tailR0=('0.0000', '0.2778', '0.0000') tailR0avg=0.0926
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    0    3    0
     0   23    0   32    0
     0   48    0   77    0
     0   37    1   78    0
     0    3    0   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     5    0    4    0    0
    23    0   30    0    0
    45    0   75    2    0
    36    0   91    6    0
     0    0   11    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0    5   64    0    0
     0    8  144    0    0
     0    6   94    0    1
     0    0    2    0    0
[epoch 2] step 2/44: loss=0.6640 
[epoch 2] step 4/44: loss=0.6570 
[epoch 2] step 6/44: loss=0.6539 
[epoch 2] step 8/44: loss=0.6555 
[epoch 2] step 10/44: loss=0.6547 
[epoch 2] step 12/44: loss=0.6606 
[epoch 2] step 14/44: loss=0.6620 
[epoch 2] step 16/44: loss=0.6633 
[epoch 2] step 18/44: loss=0.6638 
[epoch 2] step 20/44: loss=0.6578 
[epoch 2] step 22/44: loss=0.6548 
[epoch 2] step 24/44: loss=0.6496 
[epoch 2] step 26/44: loss=0.6413 
[epoch 2] step 28/44: loss=0.6377 
[epoch 2] step 30/44: loss=0.6325 
[epoch 2] step 32/44: loss=0.6296 
[epoch 2] step 34/44: loss=0.6288 
[epoch 2] step 36/44: loss=0.6275 
[epoch 2] step 38/44: loss=0.6253 
[epoch 2] step 40/44: loss=0.6242 
[epoch 2] step 42/44: loss=0.6223 
[epoch 2] step 44/44: loss=0.6201 
[epoch 2] train_loss(avg per step)=1.2402 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.1815 qwk=('0.2614', '0.3288', '0.3185') averageQWK=0.3029 macroEMD=0.3183 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    5    0
     0    0   32   23    0
     0    3   40   82    0
     0    0   10  106    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   32   21    0
     0    0   37   85    0
     0    0    6  127    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    1   52   16    0
     0    0   71   81    0
     0    0   20   81    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=0.5386 
[epoch 3] step 4/44: loss=0.5283 
[epoch 3] step 6/44: loss=0.5365 
[epoch 3] step 8/44: loss=0.5427 
[epoch 3] step 10/44: loss=0.5544 
[epoch 3] step 12/44: loss=0.5511 
[epoch 3] step 14/44: loss=0.5529 
[epoch 3] step 16/44: loss=0.5540 
[epoch 3] step 18/44: loss=0.5495 
[epoch 3] step 20/44: loss=0.5506 
[epoch 3] step 22/44: loss=0.5505 
[epoch 3] step 24/44: loss=0.5518 
[epoch 3] step 26/44: loss=0.5534 
[epoch 3] step 28/44: loss=0.5507 
[epoch 3] step 30/44: loss=0.5526 
[epoch 3] step 32/44: loss=0.5526 
[epoch 3] step 34/44: loss=0.5502 
[epoch 3] step 36/44: loss=0.5502 
[epoch 3] step 38/44: loss=0.5495 
[epoch 3] step 40/44: loss=0.5493 
[epoch 3] step 42/44: loss=0.5459 
[epoch 3] step 44/44: loss=0.5465 
[epoch 3] train_loss(avg per step)=1.0930 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=1.0904 qwk=('0.4429', '0.4057', '0.4456') averageQWK=0.4314 macroEMD=0.2795 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    3   42   10    0
     0    3   60   62    0
     0    0   12  104    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   39   14    0
     0    0   52   70    0
     0    0    6  127    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    2   65    2    0
     0    0  118   34    0
     0    0   32   69    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=0.5869 
[epoch 4] step 4/44: loss=0.5352 
[epoch 4] step 6/44: loss=0.5396 
[epoch 4] step 8/44: loss=0.5284 
[epoch 4] step 10/44: loss=0.5187 
[epoch 4] step 12/44: loss=0.5178 
[epoch 4] step 14/44: loss=0.5174 
[epoch 4] step 16/44: loss=0.5216 
[epoch 4] step 18/44: loss=0.5152 
[epoch 4] step 20/44: loss=0.5125 
[epoch 4] step 22/44: loss=0.5132 
[epoch 4] step 24/44: loss=0.5111 
[epoch 4] step 26/44: loss=0.5060 
[epoch 4] step 28/44: loss=0.5010 
[epoch 4] step 30/44: loss=0.5034 
[epoch 4] step 32/44: loss=0.5018 
[epoch 4] step 34/44: loss=0.5051 
[epoch 4] step 36/44: loss=0.5083 
[epoch 4] step 38/44: loss=0.5079 
[epoch 4] step 40/44: loss=0.5086 
[epoch 4] step 42/44: loss=0.5119 
[epoch 4] step 44/44: loss=0.5076 
[epoch 4] train_loss(avg per step)=1.0152 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=0.9885 qwk=('0.5434', '0.4871', '0.5900') averageQWK=0.5402 macroEMD=0.2544 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     0   12   38    5    0
     0    8   83   34    0
     0    0   23   93    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   50    3    0
     0    0   94   28    0
     0    0   35   98    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   23   46    0    0
     0   14  110   28    0
     0    0   33   68    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=0.4570 
[epoch 5] step 4/44: loss=0.4648 
[epoch 5] step 6/44: loss=0.4843 
[epoch 5] step 8/44: loss=0.4685 
[epoch 5] step 10/44: loss=0.4587 
[epoch 5] step 12/44: loss=0.4740 
[epoch 5] step 14/44: loss=0.4754 
[epoch 5] step 16/44: loss=0.4728 
[epoch 5] step 18/44: loss=0.4798 
[epoch 5] step 20/44: loss=0.4812 
[epoch 5] step 22/44: loss=0.4788 
[epoch 5] step 24/44: loss=0.4795 
[epoch 5] step 26/44: loss=0.4786 
[epoch 5] step 28/44: loss=0.4739 
[epoch 5] step 30/44: loss=0.4753 
[epoch 5] step 32/44: loss=0.4767 
[epoch 5] step 34/44: loss=0.4770 
[epoch 5] step 36/44: loss=0.4761 
[epoch 5] step 38/44: loss=0.4752 
[epoch 5] step 40/44: loss=0.4694 
[epoch 5] step 42/44: loss=0.4701 
[epoch 5] step 44/44: loss=0.4670 
[epoch 5] train_loss(avg per step)=0.9339 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=1.0191 qwk=('0.6317', '0.6129', '0.5833') averageQWK=0.6093 macroEMD=0.2438 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   37   13    5    0
     0   37   49   39    0
     0    2   17   97    0
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   22   26    5    0
     0   23   68   31    0
     0    0   25  108    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   28   41    0    0
     0   20   94   38    0
     0    0   33   68    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=0.3845 
[epoch 6] step 4/44: loss=0.4196 
[epoch 6] step 6/44: loss=0.4181 
[epoch 6] step 8/44: loss=0.4240 
[epoch 6] step 10/44: loss=0.4217 
[epoch 6] step 12/44: loss=0.4202 
[epoch 6] step 14/44: loss=0.4231 
[epoch 6] step 16/44: loss=0.4210 
[epoch 6] step 18/44: loss=0.4158 
[epoch 6] step 20/44: loss=0.4176 
[epoch 6] step 22/44: loss=0.4196 
[epoch 6] step 24/44: loss=0.4183 
[epoch 6] step 26/44: loss=0.4182 
[epoch 6] step 28/44: loss=0.4157 
[epoch 6] step 30/44: loss=0.4156 
[epoch 6] step 32/44: loss=0.4152 
[epoch 6] step 34/44: loss=0.4163 
[epoch 6] step 36/44: loss=0.4202 
[epoch 6] step 38/44: loss=0.4194 
[epoch 6] step 40/44: loss=0.4200 
[epoch 6] step 42/44: loss=0.4202 
[epoch 6] step 44/44: loss=0.4198 
[epoch 6] train_loss(avg per step)=0.8397 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=1.0235 qwk=('0.5570', '0.5331', '0.5696') averageQWK=0.5532 macroEMD=0.2393 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   13   33    9    0
     0    5   61   59    0
     0    0    9  107    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0    9   35    9    0
     0    5   76   41    0
     0    0   14  119    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   19   49    1    0
     0    4  110   38    0
     0    0   28   73    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=0.3211 
[epoch 7] step 4/44: loss=0.3480 
[epoch 7] step 6/44: loss=0.3433 
[epoch 7] step 8/44: loss=0.3482 
[epoch 7] step 10/44: loss=0.3578 
[epoch 7] step 12/44: loss=0.3616 
[epoch 7] step 14/44: loss=0.3743 
[epoch 7] step 16/44: loss=0.3742 
[epoch 7] step 18/44: loss=0.3802 
[epoch 7] step 20/44: loss=0.3759 
[epoch 7] step 22/44: loss=0.3723 
[epoch 7] step 24/44: loss=0.3689 
[epoch 7] step 26/44: loss=0.3683 
[epoch 7] step 28/44: loss=0.3639 
[epoch 7] step 30/44: loss=0.3662 
[epoch 7] step 32/44: loss=0.3670 
[epoch 7] step 34/44: loss=0.3668 
[epoch 7] step 36/44: loss=0.3658 
[epoch 7] step 38/44: loss=0.3695 
[epoch 7] step 40/44: loss=0.3695 
[epoch 7] step 42/44: loss=0.3728 
[epoch 7] step 44/44: loss=0.3751 
[epoch 7] train_loss(avg per step)=0.7501 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.0700 qwk=('0.6199', '0.6097', '0.5727') averageQWK=0.6007 macroEMD=0.2258 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   25   25    5    0
     0   14   65   45    1
     0    0   19   91    6
     0    0    1   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   25   17   11    0
     0   20   52   50    0
     0    0   10  123    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   29   32    8    0
     0   14   71   67    0
     0    0   15   86    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=0.3374 
[epoch 8] step 4/44: loss=0.3600 
[epoch 8] step 6/44: loss=0.3602 
[epoch 8] step 8/44: loss=0.3606 
[epoch 8] step 10/44: loss=0.3567 
[epoch 8] step 12/44: loss=0.3570 
[epoch 8] step 14/44: loss=0.3627 
[epoch 8] step 16/44: loss=0.3613 
[epoch 8] step 18/44: loss=0.3555 
[epoch 8] step 20/44: loss=0.3495 
[epoch 8] step 22/44: loss=0.3504 
[epoch 8] step 24/44: loss=0.3468 
[epoch 8] step 26/44: loss=0.3469 
[epoch 8] step 28/44: loss=0.3394 
[epoch 8] step 30/44: loss=0.3364 
[epoch 8] step 32/44: loss=0.3321 
[epoch 8] step 34/44: loss=0.3282 
[epoch 8] step 36/44: loss=0.3257 
[epoch 8] step 38/44: loss=0.3254 
[epoch 8] step 40/44: loss=0.3280 
[epoch 8] step 42/44: loss=0.3302 
[epoch 8] step 44/44: loss=0.3278 
[epoch 8] train_loss(avg per step)=0.6556 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.0223 qwk=('0.5804', '0.5819', '0.6460') averageQWK=0.6028 macroEMD=0.2174 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   15   38    2    0
     0   12   76   37    0
     0    0   31   84    1
     0    0    2   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   19   29    5    0
     0   17   72   33    0
     0    1   31  101    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   42   27    0    0
     0   30   93   29    0
     0    2   31   68    0
     0    0    0    2    0
[epoch 9] step 2/44: loss=0.2908 
[epoch 9] step 4/44: loss=0.2745 
[epoch 9] step 6/44: loss=0.2833 
[epoch 9] step 8/44: loss=0.2963 
[epoch 9] step 10/44: loss=0.2812 
[epoch 9] step 12/44: loss=0.2818 
[epoch 9] step 14/44: loss=0.2890 
[epoch 9] step 16/44: loss=0.2963 
[epoch 9] step 18/44: loss=0.2930 
[epoch 9] step 20/44: loss=0.2915 
[epoch 9] step 22/44: loss=0.2945 
[epoch 9] step 24/44: loss=0.2965 
[epoch 9] step 26/44: loss=0.2937 
[epoch 9] step 28/44: loss=0.2956 
[epoch 9] step 30/44: loss=0.2931 
[epoch 9] step 32/44: loss=0.2940 
[epoch 9] step 34/44: loss=0.2937 
[epoch 9] step 36/44: loss=0.2933 
[epoch 9] step 38/44: loss=0.2911 
[epoch 9] step 40/44: loss=0.2911 
[epoch 9] step 42/44: loss=0.2894 
[epoch 9] step 44/44: loss=0.2912 
[epoch 9] train_loss(avg per step)=0.5825 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.0456 qwk=('0.5827', '0.6371', '0.5930') averageQWK=0.6043 macroEMD=0.2185 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   23   31    1    0
     0   23   75   26    1
     0    1   39   74    2
     0    0    4   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   29   19    5    0
     0   30   63   29    0
     0    1   26  106    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   53   16    0    0
     0   46   86   20    0
     0    3   48   50    0
     0    0    2    0    0
[epoch 10] step 2/44: loss=0.2559 
[epoch 10] step 4/44: loss=0.2527 
[epoch 10] step 6/44: loss=0.2418 
[epoch 10] step 8/44: loss=0.2358 
[epoch 10] step 10/44: loss=0.2367 
[epoch 10] step 12/44: loss=0.2317 
[epoch 10] step 14/44: loss=0.2299 
[epoch 10] step 16/44: loss=0.2296 
[epoch 10] step 18/44: loss=0.2341 
[epoch 10] step 20/44: loss=0.2376 
[epoch 10] step 22/44: loss=0.2415 
[epoch 10] step 24/44: loss=0.2398 
[epoch 10] step 26/44: loss=0.2405 
[epoch 10] step 28/44: loss=0.2425 
[epoch 10] step 30/44: loss=0.2439 
[epoch 10] step 32/44: loss=0.2459 
[epoch 10] step 34/44: loss=0.2513 
[epoch 10] step 36/44: loss=0.2496 
[epoch 10] step 38/44: loss=0.2517 
[epoch 10] step 40/44: loss=0.2530 
[epoch 10] step 42/44: loss=0.2519 
[epoch 10] step 44/44: loss=0.2542 
[epoch 10] train_loss(avg per step)=0.5083 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.0688 qwk=('0.6219', '0.5871', '0.5811') averageQWK=0.5967 macroEMD=0.2171 tailR0=('0.2826', '0.0000', '0.0000') tailR0avg=0.0942
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   15   35    5    0
     0    9   72   41    3
     0    0   19   82   15
     0    0    1    9   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   20   21   12    0
     0   12   56   54    0
     0    0   10  123    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   26   41    2    0
     0   10   93   49    0
     0    0   26   75    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.2073 
[epoch 11] step 4/44: loss=0.2371 
[epoch 11] step 6/44: loss=0.2346 
[epoch 11] step 8/44: loss=0.2288 
[epoch 11] step 10/44: loss=0.2309 
[epoch 11] step 12/44: loss=0.2229 
[epoch 11] step 14/44: loss=0.2196 
[epoch 11] step 16/44: loss=0.2221 
[epoch 11] step 18/44: loss=0.2177 
[epoch 11] step 20/44: loss=0.2169 
[epoch 11] step 22/44: loss=0.2172 
[epoch 11] step 24/44: loss=0.2185 
[epoch 11] step 26/44: loss=0.2206 
[epoch 11] step 28/44: loss=0.2228 
[epoch 11] step 30/44: loss=0.2201 
[epoch 11] step 32/44: loss=0.2155 
[epoch 11] step 34/44: loss=0.2162 
[epoch 11] step 36/44: loss=0.2142 
[epoch 11] step 38/44: loss=0.2154 
[epoch 11] step 40/44: loss=0.2121 
[epoch 11] step 42/44: loss=0.2083 
[epoch 11] step 44/44: loss=0.2117 
[epoch 11] train_loss(avg per step)=0.4235 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=1.0726 qwk=('0.6291', '0.6172', '0.6053') averageQWK=0.6172 macroEMD=0.2161 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    1    0
     0   34   19    2    0
     0   31   65   29    0
     0    1   35   76    4
     0    0    3   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   32   16    5    0
     0   39   58   25    0
     0    2   34   97    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   44   25    0    0
     0   40   90   22    0
     0    2   44   55    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=0.1920 
[epoch 12] step 4/44: loss=0.2036 
[epoch 12] step 6/44: loss=0.2044 
[epoch 12] step 8/44: loss=0.1971 
[epoch 12] step 10/44: loss=0.1949 
[epoch 12] step 12/44: loss=0.1943 
[epoch 12] step 14/44: loss=0.1905 
[epoch 12] step 16/44: loss=0.1904 
[epoch 12] step 18/44: loss=0.1911 
[epoch 12] step 20/44: loss=0.1928 
[epoch 12] step 22/44: loss=0.1901 
[epoch 12] step 24/44: loss=0.1902 
[epoch 12] step 26/44: loss=0.1893 
[epoch 12] step 28/44: loss=0.1882 
[epoch 12] step 30/44: loss=0.1846 
[epoch 12] step 32/44: loss=0.1827 
[epoch 12] step 34/44: loss=0.1833 
[epoch 12] step 36/44: loss=0.1816 
[epoch 12] step 38/44: loss=0.1824 
[epoch 12] step 40/44: loss=0.1824 
[epoch 12] step 42/44: loss=0.1821 
[epoch 12] step 44/44: loss=0.1822 
[epoch 12] train_loss(avg per step)=0.3644 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=1.0734 qwk=('0.6171', '0.6520', '0.6056') averageQWK=0.6249 macroEMD=0.2119 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   27   25    3    0
     0   27   59   38    1
     0    1   27   80    8
     0    0    2   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   28   19    6    0
     0   29   58   35    0
     0    2   15  116    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   39   30    0    0
     0   30   94   28    0
     0    3   34   64    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.1598 
[epoch 13] step 4/44: loss=0.1687 
[epoch 13] step 6/44: loss=0.1633 
[epoch 13] step 8/44: loss=0.1632 
[epoch 13] step 10/44: loss=0.1486 
[epoch 13] step 12/44: loss=0.1399 
[epoch 13] step 14/44: loss=0.1395 
[epoch 13] step 16/44: loss=0.1405 
[epoch 13] step 18/44: loss=0.1444 
[epoch 13] step 20/44: loss=0.1474 
[epoch 13] step 22/44: loss=0.1462 
[epoch 13] step 24/44: loss=0.1472 
[epoch 13] step 26/44: loss=0.1457 
[epoch 13] step 28/44: loss=0.1471 
[epoch 13] step 30/44: loss=0.1440 
[epoch 13] step 32/44: loss=0.1418 
[epoch 13] step 34/44: loss=0.1415 
[epoch 13] step 36/44: loss=0.1440 
[epoch 13] step 38/44: loss=0.1431 
[epoch 13] step 40/44: loss=0.1444 
[epoch 13] step 42/44: loss=0.1442 
[epoch 13] step 44/44: loss=0.1492 
[epoch 13] train_loss(avg per step)=0.2985 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=1.0652 qwk=('0.5531', '0.6091', '0.6494') averageQWK=0.6039 macroEMD=0.2075 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   17   35    2    1
     0   11   75   37    2
     0    0   40   66   10
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   17   30    6    0
     0   13   78   31    0
     0    0   25  106    2
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   39   29    1    0
     0   20   86   46    0
     0    1   23   77    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.1469 
[epoch 14] step 4/44: loss=0.1389 
[epoch 14] step 6/44: loss=0.1380 
[epoch 14] step 8/44: loss=0.1264 
[epoch 14] step 10/44: loss=0.1248 
[epoch 14] step 12/44: loss=0.1196 
[epoch 14] step 14/44: loss=0.1179 
[epoch 14] step 16/44: loss=0.1137 
[epoch 14] step 18/44: loss=0.1133 
[epoch 14] step 20/44: loss=0.1169 
[epoch 14] step 22/44: loss=0.1121 
[epoch 14] step 24/44: loss=0.1106 
[epoch 14] step 26/44: loss=0.1119 
[epoch 14] step 28/44: loss=0.1087 
[epoch 14] step 30/44: loss=0.1100 
[epoch 14] step 32/44: loss=0.1127 
[epoch 14] step 34/44: loss=0.1115 
[epoch 14] step 36/44: loss=0.1121 
[epoch 14] step 38/44: loss=0.1135 
[epoch 14] step 40/44: loss=0.1135 
[epoch 14] step 42/44: loss=0.1119 
[epoch 14] step 44/44: loss=0.1097 
[epoch 14] train_loss(avg per step)=0.2194 lambda[min,max]=[0.491121,1.000000]
[epoch 14] val_loss=1.0642 qwk=('0.6111', '0.5978', '0.5790') averageQWK=0.5960 macroEMD=0.2119 tailR0=('0.1087', '0.0417', '0.0000') tailR0avg=0.0501
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   27   26    2    0
     0   20   76   28    1
     0    1   40   70    5
     0    0    4   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   21   26    6    0
     0   17   80   25    0
     0    1   33   97    2
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   37   32    0    0
     0   18  117   17    0
     0    1   52   48    0
     0    0    1    1    0
[epoch 15] step 2/44: loss=0.0735 
[epoch 15] step 4/44: loss=0.0693 
[epoch 15] step 6/44: loss=0.0762 
[epoch 15] step 8/44: loss=0.0677 
[epoch 15] step 10/44: loss=0.0644 
[epoch 15] step 12/44: loss=0.0635 
[epoch 15] step 14/44: loss=0.0642 
[epoch 15] step 16/44: loss=0.0616 
[epoch 15] step 18/44: loss=0.0650 
[epoch 15] step 20/44: loss=0.0693 
[epoch 15] step 22/44: loss=0.0706 
[epoch 15] step 24/44: loss=0.0697 
[epoch 15] step 26/44: loss=0.0715 
[epoch 15] step 28/44: loss=0.0720 
[epoch 15] step 30/44: loss=0.0711 
[epoch 15] step 32/44: loss=0.0747 
[epoch 15] step 34/44: loss=0.0750 
[epoch 15] step 36/44: loss=0.0738 
[epoch 15] step 38/44: loss=0.0735 
[epoch 15] step 40/44: loss=0.0734 
[epoch 15] step 42/44: loss=0.0733 
[epoch 15] step 44/44: loss=0.0717 
[epoch 15] train_loss(avg per step)=0.1433 lambda[min,max]=[0.499542,1.000000]
[epoch 15] val_loss=1.1109 qwk=('0.5677', '0.5911', '0.6239') averageQWK=0.5942 macroEMD=0.2064 tailR0=('0.1304', '0.0417', '0.0000') tailR0avg=0.0574
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   14   36    5    0
     1   10   71   41    2
     0    0   29   75   12
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     1   15   26   11    0
     0   12   68   41    1
     0    0   14  115    4
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   37   32    0    0
     0   22   98   32    0
     0    1   34   66    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=0.1013 
[epoch 16] step 4/44: loss=0.0852 
[epoch 16] step 6/44: loss=0.0686 
[epoch 16] step 8/44: loss=0.0572 
[epoch 16] step 10/44: loss=0.0497 
[epoch 16] step 12/44: loss=0.0522 
[epoch 16] step 14/44: loss=0.0516 
[epoch 16] step 16/44: loss=0.0507 
[epoch 16] step 18/44: loss=0.0528 
[epoch 16] step 20/44: loss=0.0537 
[epoch 16] step 22/44: loss=0.0548 
[epoch 16] step 24/44: loss=0.0535 
[epoch 16] step 26/44: loss=0.0520 
[epoch 16] step 28/44: loss=0.0513 
[epoch 16] step 30/44: loss=0.0492 
[epoch 16] step 32/44: loss=0.0487 
[epoch 16] step 34/44: loss=0.0488 
[epoch 16] step 36/44: loss=0.0473 
[epoch 16] step 38/44: loss=0.0461 
[epoch 16] step 40/44: loss=0.0467 
[epoch 16] step 42/44: loss=0.0465 
[epoch 16] step 44/44: loss=0.0480 
[epoch 16] train_loss(avg per step)=0.0961 lambda[min,max]=[0.446720,1.000000]
[epoch 16] val_loss=1.1535 qwk=('0.5771', '0.5741', '0.6036') averageQWK=0.5849 macroEMD=0.2085 tailR0=('0.1957', '0.0417', '0.0000') tailR0avg=0.0791
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   13   38    4    0
     0   10   64   48    3
     0    0   23   77   16
     0    0    2   12    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   15   27   11    0
     0    9   73   40    0
     0    0   19  111    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   31   37    1    0
     0   19  100   33    0
     0    1   29   71    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=-0.0013 
[epoch 17] step 4/44: loss=0.0163 
[epoch 17] step 6/44: loss=0.0290 
[epoch 17] step 8/44: loss=0.0266 
[epoch 17] step 10/44: loss=0.0221 
[epoch 17] step 12/44: loss=0.0202 
[epoch 17] step 14/44: loss=0.0121 
[epoch 17] step 16/44: loss=0.0110 
[epoch 17] step 18/44: loss=0.0077 
[epoch 17] step 20/44: loss=0.0106 
[epoch 17] step 22/44: loss=0.0119 
[epoch 17] step 24/44: loss=0.0108 
[epoch 17] step 26/44: loss=0.0103 
[epoch 17] step 28/44: loss=0.0117 
[epoch 17] step 30/44: loss=0.0125 
[epoch 17] step 32/44: loss=0.0122 
[epoch 17] step 34/44: loss=0.0144 
[epoch 17] step 36/44: loss=0.0153 
[epoch 17] step 38/44: loss=0.0151 
[epoch 17] step 40/44: loss=0.0166 
[epoch 17] step 42/44: loss=0.0175 
[epoch 17] step 44/44: loss=0.0172 
[epoch 17] train_loss(avg per step)=0.0344 lambda[min,max]=[0.481047,1.000000]
[epoch 17] val_loss=1.1157 qwk=('0.6052', '0.5864', '0.6165') averageQWK=0.6027 macroEMD=0.2068 tailR0=('0.1522', '0.0000', '0.0000') tailR0avg=0.0507
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   19   33    3    0
     0   13   80   31    1
     0    0   34   73    9
     0    0    2   14    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     1   15   29    8    0
     0   12   80   30    0
     0    1   25  105    2
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   36   33    0    0
     0   14  119   19    0
     0    2   42   57    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=-0.0024 
[epoch 18] step 4/44: loss=0.0271 
[epoch 18] step 6/44: loss=0.0172 
[epoch 18] step 8/44: loss=0.0087 
[epoch 18] step 10/44: loss=0.0015 
[epoch 18] step 12/44: loss=0.0023 
[epoch 18] step 14/44: loss=0.0020 
[epoch 18] step 16/44: loss=0.0025 
[epoch 18] step 18/44: loss=0.0018 
[epoch 18] step 20/44: loss=-0.0014 
[epoch 18] step 22/44: loss=0.0012 
[epoch 18] step 24/44: loss=0.0014 
[epoch 18] step 26/44: loss=0.0005 
[epoch 18] step 28/44: loss=-0.0003 
[epoch 18] step 30/44: loss=-0.0030 
[epoch 18] step 32/44: loss=-0.0043 
[epoch 18] step 34/44: loss=-0.0028 
[epoch 18] step 36/44: loss=-0.0020 
[epoch 18] step 38/44: loss=-0.0030 
[epoch 18] step 40/44: loss=-0.0023 
[epoch 18] step 42/44: loss=-0.0018 
[epoch 18] step 44/44: loss=-0.0034 
[epoch 18] train_loss(avg per step)=-0.0068 lambda[min,max]=[0.432607,1.000000]
[epoch 18] val_loss=1.1496 qwk=('0.5848', '0.5936', '0.6122') averageQWK=0.5968 macroEMD=0.2084 tailR0=('0.1304', '0.0417', '0.0000') tailR0avg=0.0574
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   20   30    5    0
     0   15   69   39    2
     0    0   29   80    7
     0    0    3   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     1   19   26    7    0
     0   14   70   35    3
     0    2   18  107    6
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   33   36    0    0
     0   18  109   25    0
     0    1   38   62    0
     0    0    0    2    0
[epoch 19] step 2/44: loss=-0.0294 
[epoch 19] step 4/44: loss=-0.0261 
[epoch 19] step 6/44: loss=-0.0313 
[epoch 19] step 8/44: loss=-0.0267 
[epoch 19] step 10/44: loss=-0.0236 
[epoch 19] step 12/44: loss=-0.0260 
[epoch 19] step 14/44: loss=-0.0250 
[epoch 19] step 16/44: loss=-0.0234 
[epoch 19] step 18/44: loss=-0.0221 
[epoch 19] step 20/44: loss=-0.0193 
[epoch 19] step 22/44: loss=-0.0175 
[epoch 19] step 24/44: loss=-0.0177 
[epoch 19] step 26/44: loss=-0.0182 
[epoch 19] step 28/44: loss=-0.0195 
[epoch 19] step 30/44: loss=-0.0179 
[epoch 19] step 32/44: loss=-0.0177 
[epoch 19] step 34/44: loss=-0.0176 
[epoch 19] step 36/44: loss=-0.0174 
[epoch 19] step 38/44: loss=-0.0171 
[epoch 19] step 40/44: loss=-0.0181 
[epoch 19] step 42/44: loss=-0.0190 
[epoch 19] step 44/44: loss=-0.0175 
[epoch 19] train_loss(avg per step)=-0.0351 lambda[min,max]=[0.452803,1.000000]
[epoch 19] val_loss=1.2557 qwk=('0.5393', '0.5460', '0.6299') averageQWK=0.5717 macroEMD=0.2122 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   12   36    7    0
     0    9   67   47    2
     0    0   23   82   11
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     1   21   15   16    0
     0   16   43   63    0
     0    1    5  125    2
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   38    0    0
     0   14  113   25    0
     0    1   33   67    0
     0    0    0    2    0
[epoch 20] step 2/44: loss=-0.0231 
[epoch 20] step 4/44: loss=-0.0158 
[epoch 20] step 6/44: loss=-0.0165 
[epoch 20] step 8/44: loss=-0.0208 
[epoch 20] step 10/44: loss=-0.0227 
[epoch 20] step 12/44: loss=-0.0246 
[epoch 20] step 14/44: loss=-0.0251 
[epoch 20] step 16/44: loss=-0.0226 
[epoch 20] step 18/44: loss=-0.0226 
[epoch 20] step 20/44: loss=-0.0237 
[epoch 20] step 22/44: loss=-0.0231 
[epoch 20] step 24/44: loss=-0.0233 
[epoch 20] step 26/44: loss=-0.0265 
[epoch 20] step 28/44: loss=-0.0277 
[epoch 20] step 30/44: loss=-0.0298 
[epoch 20] step 32/44: loss=-0.0300 
[epoch 20] step 34/44: loss=-0.0301 
[epoch 20] step 36/44: loss=-0.0316 
[epoch 20] step 38/44: loss=-0.0322 
[epoch 20] step 40/44: loss=-0.0317 
[epoch 20] step 42/44: loss=-0.0307 
[epoch 20] step 44/44: loss=-0.0312 
[epoch 20] train_loss(avg per step)=-0.0624 lambda[min,max]=[0.402560,1.000000]
[epoch 20] val_loss=1.1865 qwk=('0.5672', '0.5762', '0.6033') averageQWK=0.5822 macroEMD=0.2118 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   14   38    3    0
     0   10   86   27    2
     0    0   37   70    9
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     1   14   32    6    0
     0   11   82   28    1
     0    0   28  102    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   30   39    0    0
     0   13  116   23    0
     0    1   40   60    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=-0.0353 
[epoch 21] step 4/44: loss=-0.0458 
[epoch 21] step 6/44: loss=-0.0437 
[epoch 21] step 8/44: loss=-0.0453 
[epoch 21] step 10/44: loss=-0.0442 
[epoch 21] step 12/44: loss=-0.0394 
[epoch 21] step 14/44: loss=-0.0410 
[epoch 21] step 16/44: loss=-0.0371 
[epoch 21] step 18/44: loss=-0.0401 
[epoch 21] step 20/44: loss=-0.0401 
[epoch 21] step 22/44: loss=-0.0407 
[epoch 21] step 24/44: loss=-0.0418 
[epoch 21] step 26/44: loss=-0.0420 
[epoch 21] step 28/44: loss=-0.0418 
[epoch 21] step 30/44: loss=-0.0426 
[epoch 21] step 32/44: loss=-0.0434 
[epoch 21] step 34/44: loss=-0.0448 
[epoch 21] step 36/44: loss=-0.0449 
[epoch 21] step 38/44: loss=-0.0438 
[epoch 21] step 40/44: loss=-0.0430 
[epoch 21] step 42/44: loss=-0.0430 
[epoch 21] step 44/44: loss=-0.0431 
[epoch 21] train_loss(avg per step)=-0.0861 lambda[min,max]=[0.445562,1.000000]
[epoch 21] val_loss=1.2098 qwk=('0.5738', '0.6217', '0.6037') averageQWK=0.5997 macroEMD=0.2065 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   19   32    4    0
     0   17   70   38    0
     0    0   32   80    4
     0    0    3   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   21   26    6    0
     0   14   79   29    0
     0    0   27  103    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   33   35    1    0
     0   12  113   27    0
     0    1   37   63    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=-0.0433 
[epoch 22] step 4/44: loss=-0.0404 
[epoch 22] step 6/44: loss=-0.0519 
[epoch 22] step 8/44: loss=-0.0583 
[epoch 22] step 10/44: loss=-0.0601 
[epoch 22] step 12/44: loss=-0.0610 
[epoch 22] step 14/44: loss=-0.0570 
[epoch 22] step 16/44: loss=-0.0543 
[epoch 22] step 18/44: loss=-0.0560 
[epoch 22] step 20/44: loss=-0.0549 
[epoch 22] step 22/44: loss=-0.0543 
[epoch 22] step 24/44: loss=-0.0549 
[epoch 22] step 26/44: loss=-0.0546 
[epoch 22] step 28/44: loss=-0.0543 
[epoch 22] step 30/44: loss=-0.0532 
[epoch 22] step 32/44: loss=-0.0533 
[epoch 22] step 34/44: loss=-0.0534 
[epoch 22] step 36/44: loss=-0.0541 
[epoch 22] step 38/44: loss=-0.0545 
[epoch 22] step 40/44: loss=-0.0540 
[epoch 22] step 42/44: loss=-0.0535 
[epoch 22] step 44/44: loss=-0.0510 
[epoch 22] train_loss(avg per step)=-0.1021 lambda[min,max]=[0.437043,1.000000]
[epoch 22] val_loss=1.2114 qwk=('0.5734', '0.5822', '0.6133') averageQWK=0.5896 macroEMD=0.2071 tailR0=('0.1739', '0.0417', '0.0000') tailR0avg=0.0719
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   15   37    3    0
     0   11   80   32    2
     0    0   32   72   12
     0    0    4   11    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   16   30    7    0
     0   17   73   30    2
     0    0   27  101    5
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   39   30    0    0
     0   19  108   25    0
     0    3   38   60    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=-0.0634 
[epoch 23] step 4/44: loss=-0.0639 
[epoch 23] step 6/44: loss=-0.0669 
[epoch 23] step 8/44: loss=-0.0642 
[epoch 23] step 10/44: loss=-0.0629 
[epoch 23] step 12/44: loss=-0.0632 
[epoch 23] step 14/44: loss=-0.0638 
[epoch 23] step 16/44: loss=-0.0642 
[epoch 23] step 18/44: loss=-0.0650 
[epoch 23] step 20/44: loss=-0.0627 
[epoch 23] step 22/44: loss=-0.0634 
[epoch 23] step 24/44: loss=-0.0645 
[epoch 23] step 26/44: loss=-0.0645 
[epoch 23] step 28/44: loss=-0.0660 
[epoch 23] step 30/44: loss=-0.0659 
[epoch 23] step 32/44: loss=-0.0654 
[epoch 23] step 34/44: loss=-0.0639 
[epoch 23] step 36/44: loss=-0.0641 
[epoch 23] step 38/44: loss=-0.0643 
[epoch 23] step 40/44: loss=-0.0640 
[epoch 23] step 42/44: loss=-0.0625 
[epoch 23] step 44/44: loss=-0.0622 
[epoch 23] train_loss(avg per step)=-0.1244 lambda[min,max]=[0.390756,1.000000]
[epoch 23] val_loss=1.2455 qwk=('0.5681', '0.5891', '0.5453') averageQWK=0.5675 macroEMD=0.2075 tailR0=('0.0870', '0.0000', '0.0000') tailR0avg=0.0290
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     1   15   35    4    0
     0   11   80   32    2
     0    0   35   77    4
     0    0    3   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   23   22    8    0
     0   16   72   32    2
     0    1   22  106    4
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   27   42    0    0
     0   12  119   21    0
     0    1   49   51    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=-0.0580 
[epoch 24] step 4/44: loss=-0.0631 
[epoch 24] step 6/44: loss=-0.0650 
[epoch 24] step 8/44: loss=-0.0681 
[epoch 24] step 10/44: loss=-0.0687 
[epoch 24] step 12/44: loss=-0.0673 
[epoch 24] step 14/44: loss=-0.0675 
[epoch 24] step 16/44: loss=-0.0693 
[epoch 24] step 18/44: loss=-0.0689 
[epoch 24] step 20/44: loss=-0.0697 
[epoch 24] step 22/44: loss=-0.0703 
[epoch 24] step 24/44: loss=-0.0703 
[epoch 24] step 26/44: loss=-0.0694 
[epoch 24] step 28/44: loss=-0.0695 
[epoch 24] step 30/44: loss=-0.0692 
[epoch 24] step 32/44: loss=-0.0686 
[epoch 24] step 34/44: loss=-0.0693 
[epoch 24] step 36/44: loss=-0.0697 
[epoch 24] step 38/44: loss=-0.0707 
[epoch 24] step 40/44: loss=-0.0702 
[epoch 24] step 42/44: loss=-0.0701 
[epoch 24] step 44/44: loss=-0.0707 
[epoch 24] train_loss(avg per step)=-0.1415 lambda[min,max]=[0.373703,1.000000]
[epoch 24] val_loss=1.2314 qwk=('0.5905', '0.5848', '0.6184') averageQWK=0.5979 macroEMD=0.2030 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     1   19   31    4    0
     0   12   74   37    2
     0    0   27   82    7
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   23   23    7    0
     1   19   66   34    2
     0    0   25  104    4
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   41   28    0    0
     0   21  110   21    0
     0    2   43   56    0
     0    0    0    2    0
[epoch 25] step 2/44: loss=-0.0837 
[epoch 25] step 4/44: loss=-0.0843 
[epoch 25] step 6/44: loss=-0.0830 
[epoch 25] step 8/44: loss=-0.0819 
[epoch 25] step 10/44: loss=-0.0797 
[epoch 25] step 12/44: loss=-0.0806 
[epoch 25] step 14/44: loss=-0.0798 
[epoch 25] step 16/44: loss=-0.0788 
[epoch 25] step 18/44: loss=-0.0782 
[epoch 25] step 20/44: loss=-0.0787 
[epoch 25] step 22/44: loss=-0.0801 
[epoch 25] step 24/44: loss=-0.0798 
[epoch 25] step 26/44: loss=-0.0797 
[epoch 25] step 28/44: loss=-0.0782 
[epoch 25] step 30/44: loss=-0.0784 
[epoch 25] step 32/44: loss=-0.0787 
[epoch 25] step 34/44: loss=-0.0788 
[epoch 25] step 36/44: loss=-0.0781 
[epoch 25] step 38/44: loss=-0.0771 
[epoch 25] step 40/44: loss=-0.0771 
[epoch 25] step 42/44: loss=-0.0769 
[epoch 25] step 44/44: loss=-0.0764 
[epoch 25] train_loss(avg per step)=-0.1529 lambda[min,max]=[0.360750,1.000000]
[epoch 25] val_loss=1.2456 qwk=('0.5748', '0.6079', '0.5993') averageQWK=0.5940 macroEMD=0.2045 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   17   35    3    0
     0   12   83   30    0
     0    0   38   74    4
     0    0    4   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   19   28    6    0
     0   17   74   30    1
     0    0   25  104    4
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   31   37    1    0
     0   18  106   28    0
     0    1   33   67    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=-0.0838 
[epoch 26] step 4/44: loss=-0.0873 
[epoch 26] step 6/44: loss=-0.0801 
[epoch 26] step 8/44: loss=-0.0803 
[epoch 26] step 10/44: loss=-0.0786 
[epoch 26] step 12/44: loss=-0.0790 
[epoch 26] step 14/44: loss=-0.0809 
[epoch 26] step 16/44: loss=-0.0817 
[epoch 26] step 18/44: loss=-0.0827 
[epoch 26] step 20/44: loss=-0.0821 
[epoch 26] step 22/44: loss=-0.0807 
[epoch 26] step 24/44: loss=-0.0804 
[epoch 26] step 26/44: loss=-0.0798 
[epoch 26] step 28/44: loss=-0.0792 
[epoch 26] step 30/44: loss=-0.0787 
[epoch 26] step 32/44: loss=-0.0785 
[epoch 26] step 34/44: loss=-0.0793 
[epoch 26] step 36/44: loss=-0.0801 
[epoch 26] step 38/44: loss=-0.0803 
[epoch 26] step 40/44: loss=-0.0804 
[epoch 26] step 42/44: loss=-0.0804 
[epoch 26] step 44/44: loss=-0.0799 
[epoch 26] train_loss(avg per step)=-0.1598 lambda[min,max]=[0.437062,1.000000]
[epoch 26] val_loss=1.2425 qwk=('0.6042', '0.6084', '0.6083') averageQWK=0.6070 macroEMD=0.2020 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     1   19   32    3    0
     0   14   75   35    1
     0    0   27   81    8
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     1   21   24    7    0
     2   18   65   36    1
     0    1   19  111    2
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   39   30    0    0
     0   21  110   20    1
     0    2   42   57    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=-0.0915 
[epoch 27] step 4/44: loss=-0.0810 
[epoch 27] step 6/44: loss=-0.0810 
[epoch 27] step 8/44: loss=-0.0802 
[epoch 27] step 10/44: loss=-0.0788 
[epoch 27] step 12/44: loss=-0.0792 
[epoch 27] step 14/44: loss=-0.0819 
[epoch 27] step 16/44: loss=-0.0823 
[epoch 27] step 18/44: loss=-0.0839 
[epoch 27] step 20/44: loss=-0.0839 
[epoch 27] step 22/44: loss=-0.0834 
[epoch 27] step 24/44: loss=-0.0830 
[epoch 27] step 26/44: loss=-0.0833 
[epoch 27] step 28/44: loss=-0.0835 
[epoch 27] step 30/44: loss=-0.0838 
[epoch 27] step 32/44: loss=-0.0835 
[epoch 27] step 34/44: loss=-0.0837 
[epoch 27] step 36/44: loss=-0.0846 
[epoch 27] step 38/44: loss=-0.0842 
[epoch 27] step 40/44: loss=-0.0844 
[epoch 27] step 42/44: loss=-0.0843 
[epoch 27] step 44/44: loss=-0.0850 
[epoch 27] train_loss(avg per step)=-0.1699 lambda[min,max]=[0.392837,1.000000]
[epoch 27] val_loss=1.2629 qwk=('0.5529', '0.6036', '0.5630') averageQWK=0.5731 macroEMD=0.2054 tailR0=('0.1370', '0.0000', '0.0000') tailR0avg=0.0457
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    1    0
     1   16   36    2    0
     0   12   87   25    1
     0    0   44   67    5
     0    0    5   14    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   23   26    4    0
     1   16   74   31    0
     0    1   34   95    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   33   36    0    0
     0   18  116   18    0
     0    2   48   51    0
     0    0    0    2    0
[epoch 28] step 2/44: loss=-0.0974 
[epoch 28] step 4/44: loss=-0.0907 
[epoch 28] step 6/44: loss=-0.0862 
[epoch 28] step 8/44: loss=-0.0886 
[epoch 28] step 10/44: loss=-0.0879 
[epoch 28] step 12/44: loss=-0.0886 
[epoch 28] step 14/44: loss=-0.0884 
[epoch 28] step 16/44: loss=-0.0884 
[epoch 28] step 18/44: loss=-0.0892 
[epoch 28] step 20/44: loss=-0.0893 
[epoch 28] step 22/44: loss=-0.0888 
[epoch 28] step 24/44: loss=-0.0883 
[epoch 28] step 26/44: loss=-0.0884 
[epoch 28] step 28/44: loss=-0.0888 
[epoch 28] step 30/44: loss=-0.0895 
[epoch 28] step 32/44: loss=-0.0898 
[epoch 28] step 34/44: loss=-0.0896 
[epoch 28] step 36/44: loss=-0.0899 
[epoch 28] step 38/44: loss=-0.0901 
[epoch 28] step 40/44: loss=-0.0894 
[epoch 28] step 42/44: loss=-0.0897 
[epoch 28] step 44/44: loss=-0.0898 
[epoch 28] train_loss(avg per step)=-0.1797 lambda[min,max]=[0.425005,1.000000]
[epoch 28] val_loss=1.2766 qwk=('0.5600', '0.6039', '0.5709') averageQWK=0.5783 macroEMD=0.2066 tailR0=('0.0870', '0.0000', '0.0000') tailR0avg=0.0290
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   14   38    3    0
     0   12   84   28    1
     0    0   37   74    5
     0    0    4   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   21   24    8    0
     1   16   70   35    0
     0    0   22  108    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   44    0    0
     0   13  121   18    0
     0    1   42   58    0
     0    0    0    2    0
[epoch 29] step 2/44: loss=-0.0963 
[epoch 29] step 4/44: loss=-0.0891 
[epoch 29] step 6/44: loss=-0.0930 
[epoch 29] step 8/44: loss=-0.0950 
[epoch 29] step 10/44: loss=-0.0932 
[epoch 29] step 12/44: loss=-0.0934 
[epoch 29] step 14/44: loss=-0.0938 
[epoch 29] step 16/44: loss=-0.0945 
[epoch 29] step 18/44: loss=-0.0941 
[epoch 29] step 20/44: loss=-0.0931 
[epoch 29] step 22/44: loss=-0.0930 
[epoch 29] step 24/44: loss=-0.0929 
[epoch 29] step 26/44: loss=-0.0930 
[epoch 29] step 28/44: loss=-0.0923 
[epoch 29] step 30/44: loss=-0.0924 
[epoch 29] step 32/44: loss=-0.0931 
[epoch 29] step 34/44: loss=-0.0932 
[epoch 29] step 36/44: loss=-0.0932 
[epoch 29] step 38/44: loss=-0.0932 
[epoch 29] step 40/44: loss=-0.0932 
[epoch 29] step 42/44: loss=-0.0932 
[epoch 29] step 44/44: loss=-0.0931 
[epoch 29] train_loss(avg per step)=-0.1863 lambda[min,max]=[0.388016,1.000000]
[epoch 29] val_loss=1.2653 qwk=('0.5877', '0.5772', '0.6396') averageQWK=0.6015 macroEMD=0.2010 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   18   33    4    0
     0   13   71   40    1
     0    0   25   84    7
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   16   28    9    0
     1   15   73   33    0
     0    0   24  105    4
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   41   27    1    0
     0   16  112   24    0
     0    2   36   62    1
     0    0    0    2    0
[epoch 30] step 2/44: loss=-0.0952 
[epoch 30] step 4/44: loss=-0.0978 
[epoch 30] step 6/44: loss=-0.0938 
[epoch 30] step 8/44: loss=-0.0945 
[epoch 30] step 10/44: loss=-0.0948 
[epoch 30] step 12/44: loss=-0.0955 
[epoch 30] step 14/44: loss=-0.0939 
[epoch 30] step 16/44: loss=-0.0941 
[epoch 30] step 18/44: loss=-0.0948 
[epoch 30] step 20/44: loss=-0.0954 
[epoch 30] step 22/44: loss=-0.0948 
[epoch 30] step 24/44: loss=-0.0947 
[epoch 30] step 26/44: loss=-0.0953 
[epoch 30] step 28/44: loss=-0.0957 
[epoch 30] step 30/44: loss=-0.0955 
[epoch 30] step 32/44: loss=-0.0957 
[epoch 30] step 34/44: loss=-0.0958 
[epoch 30] step 36/44: loss=-0.0963 
[epoch 30] step 38/44: loss=-0.0967 
[epoch 30] step 40/44: loss=-0.0966 
[epoch 30] step 42/44: loss=-0.0967 
[epoch 30] step 44/44: loss=-0.0963 
[epoch 30] train_loss(avg per step)=-0.1925 lambda[min,max]=[0.411233,1.000000]
[epoch 30] val_loss=1.2915 qwk=('0.5567', '0.5568', '0.6231') averageQWK=0.5789 macroEMD=0.2041 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   17   32    6    0
     0   11   70   44    0
     0    0   27   85    4
     0    0    2   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   15   28   10    0
     1   11   72   38    0
     0    0   25  106    2
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   38   30    1    0
     0   17  112   22    1
     0    1   36   64    0
     0    0    0    2    0
[epoch 31] step 2/44: loss=-0.0902 
[epoch 31] step 4/44: loss=-0.0927 
[epoch 31] step 6/44: loss=-0.0962 
[epoch 31] step 8/44: loss=-0.0957 
[epoch 31] step 10/44: loss=-0.0971 
[epoch 31] step 12/44: loss=-0.0969 
[epoch 31] step 14/44: loss=-0.0966 
[epoch 31] step 16/44: loss=-0.0971 
[epoch 31] step 18/44: loss=-0.0974 
[epoch 31] step 20/44: loss=-0.0971 
[epoch 31] step 22/44: loss=-0.0976 
[epoch 31] step 24/44: loss=-0.0978 
[epoch 31] step 26/44: loss=-0.0978 
[epoch 31] step 28/44: loss=-0.0977 
[epoch 31] step 30/44: loss=-0.0982 
[epoch 31] step 32/44: loss=-0.0980 
[epoch 31] step 34/44: loss=-0.0983 
[epoch 31] step 36/44: loss=-0.0984 
[epoch 31] step 38/44: loss=-0.0982 
[epoch 31] step 40/44: loss=-0.0982 
[epoch 31] step 42/44: loss=-0.0981 
[epoch 31] step 44/44: loss=-0.0985 
[epoch 31] train_loss(avg per step)=-0.1969 lambda[min,max]=[0.344661,1.000000]
[epoch 31] val_loss=1.2869 qwk=('0.5851', '0.5986', '0.5998') averageQWK=0.5945 macroEMD=0.2019 tailR0=('0.0870', '0.0000', '0.0000') tailR0avg=0.0290
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   18   33    4    0
     1   11   81   32    0
     0    0   31   80    5
     0    0    3   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   23   23    7    0
     2   17   68   35    0
     0    1   27  102    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   36   33    0    0
     0   18  115   19    0
     0    2   42   56    1
     0    0    0    2    0
[epoch 32] step 2/44: loss=-0.1005 
[epoch 32] step 4/44: loss=-0.0952 
[epoch 32] step 6/44: loss=-0.0962 
[epoch 32] step 8/44: loss=-0.0965 
[epoch 32] step 10/44: loss=-0.0980 
[epoch 32] step 12/44: loss=-0.0980 
[epoch 32] step 14/44: loss=-0.0979 
[epoch 32] step 16/44: loss=-0.0986 
[epoch 32] step 18/44: loss=-0.0980 
[epoch 32] step 20/44: loss=-0.0986 
[epoch 32] step 22/44: loss=-0.0988 
[epoch 32] step 24/44: loss=-0.0991 
[epoch 32] step 26/44: loss=-0.0990 
[epoch 32] step 28/44: loss=-0.0992 
[epoch 32] step 30/44: loss=-0.0991 
[epoch 32] step 32/44: loss=-0.0995 
[epoch 32] step 34/44: loss=-0.0995 
[epoch 32] step 36/44: loss=-0.0999 
[epoch 32] step 38/44: loss=-0.0996 
[epoch 32] step 40/44: loss=-0.0996 
[epoch 32] step 42/44: loss=-0.0994 
[epoch 32] step 44/44: loss=-0.0997 
[epoch 32] train_loss(avg per step)=-0.1993 lambda[min,max]=[0.383839,1.000000]
[epoch 32] val_loss=1.3003 qwk=('0.5712', '0.5855', '0.5938') averageQWK=0.5835 macroEMD=0.2033 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   17   33    5    0
     0   12   76   35    2
     0    0   29   80    7
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   24   18   11    0
     1   16   64   40    1
     0    1   17  111    4
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   32   36    1    0
     0   14  118   20    0
     0    1   41   59    0
     0    0    0    2    0
[epoch 33] step 2/44: loss=-0.1022 
[epoch 33] step 4/44: loss=-0.1034 
[epoch 33] step 6/44: loss=-0.1036 
[epoch 33] step 8/44: loss=-0.1035 
[epoch 33] step 10/44: loss=-0.1041 
[epoch 33] step 12/44: loss=-0.1030 
[epoch 33] step 14/44: loss=-0.1031 
[epoch 33] step 16/44: loss=-0.1029 
[epoch 33] step 18/44: loss=-0.1029 
[epoch 33] step 20/44: loss=-0.1027 
[epoch 33] step 22/44: loss=-0.1029 
[epoch 33] step 24/44: loss=-0.1031 
[epoch 33] step 26/44: loss=-0.1024 
[epoch 33] step 28/44: loss=-0.1018 
[epoch 33] step 30/44: loss=-0.1019 
[epoch 33] step 32/44: loss=-0.1019 
[epoch 33] step 34/44: loss=-0.1020 
[epoch 33] step 36/44: loss=-0.1020 
[epoch 33] step 38/44: loss=-0.1017 
[epoch 33] step 40/44: loss=-0.1019 
[epoch 33] step 42/44: loss=-0.1020 
[epoch 33] step 44/44: loss=-0.1021 
[epoch 33] train_loss(avg per step)=-0.2043 lambda[min,max]=[0.403812,1.000000]
[epoch 33] val_loss=1.2914 qwk=('0.5580', '0.5666', '0.6168') averageQWK=0.5805 macroEMD=0.2035 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   14   37    4    0
     0   11   81   31    2
     0    0   35   75    6
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   16   29    8    0
     1   14   73   33    1
     0    0   28  101    4
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   34   34    1    0
     0   14  115   23    0
     0    1   36   64    0
     0    0    0    2    0
[epoch 34] step 2/44: loss=-0.1057 
[epoch 34] step 4/44: loss=-0.1054 
[epoch 34] step 6/44: loss=-0.1052 
[epoch 34] step 8/44: loss=-0.1042 
[epoch 34] step 10/44: loss=-0.1047 
[epoch 34] step 12/44: loss=-0.1048 
[epoch 34] step 14/44: loss=-0.1033 
[epoch 34] step 16/44: loss=-0.1040 
[epoch 34] step 18/44: loss=-0.1037 
[epoch 34] step 20/44: loss=-0.1037 
[epoch 34] step 22/44: loss=-0.1037 
[epoch 34] step 24/44: loss=-0.1039 
[epoch 34] step 26/44: loss=-0.1037 
[epoch 34] step 28/44: loss=-0.1039 
[epoch 34] step 30/44: loss=-0.1041 
[epoch 34] step 32/44: loss=-0.1041 
[epoch 34] step 34/44: loss=-0.1037 
[epoch 34] step 36/44: loss=-0.1037 
[epoch 34] step 38/44: loss=-0.1033 
[epoch 34] step 40/44: loss=-0.1025 
[epoch 34] step 42/44: loss=-0.1026 
[epoch 34] step 44/44: loss=-0.1027 
[epoch 34] train_loss(avg per step)=-0.2055 lambda[min,max]=[0.421557,1.000000]
[epoch 34] val_loss=1.2946 qwk=('0.5769', '0.5822', '0.6105') averageQWK=0.5899 macroEMD=0.2033 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   16   35    4    0
     0   11   76   37    1
     0    0   29   81    6
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   20   23   10    0
     1   15   68   38    0
     0    0   22  108    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   33   35    1    0
     0   14  118   20    0
     0    1   38   62    0
     0    0    0    2    0
[epoch 35] step 2/44: loss=-0.1049 
[epoch 35] step 4/44: loss=-0.1065 
[epoch 35] step 6/44: loss=-0.1038 
[epoch 35] step 8/44: loss=-0.1032 
[epoch 35] step 10/44: loss=-0.1030 
[epoch 35] step 12/44: loss=-0.1035 
[epoch 35] step 14/44: loss=-0.1040 
[epoch 35] step 16/44: loss=-0.1043 
[epoch 35] step 18/44: loss=-0.1045 
[epoch 35] step 20/44: loss=-0.1040 
[epoch 35] step 22/44: loss=-0.1043 
[epoch 35] step 24/44: loss=-0.1038 
[epoch 35] step 26/44: loss=-0.1036 
[epoch 35] step 28/44: loss=-0.1031 
[epoch 35] step 30/44: loss=-0.1033 
[epoch 35] step 32/44: loss=-0.1035 
[epoch 35] step 34/44: loss=-0.1034 
[epoch 35] step 36/44: loss=-0.1036 
[epoch 35] step 38/44: loss=-0.1036 
[epoch 35] step 40/44: loss=-0.1036 
[epoch 35] step 42/44: loss=-0.1034 
[epoch 35] step 44/44: loss=-0.1034 
[epoch 35] train_loss(avg per step)=-0.2068 lambda[min,max]=[0.376207,1.000000]
[epoch 35] val_loss=1.3016 qwk=('0.5732', '0.5670', '0.6061') averageQWK=0.5821 macroEMD=0.2044 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   15   36    4    0
     0   11   76   37    1
     0    0   29   81    6
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   18   25   10    0
     1   15   68   37    1
     0    0   23  107    3
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   32   36    1    0
     0   14  118   20    0
     0    1   38   62    0
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold5/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold5/metrics.json
Done.
