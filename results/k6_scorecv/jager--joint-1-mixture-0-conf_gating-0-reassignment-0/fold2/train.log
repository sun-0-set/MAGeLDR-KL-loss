[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.8038 
[epoch 1] step 4/44: loss=6.4769 
[epoch 1] step 6/44: loss=6.4450 
[epoch 1] step 8/44: loss=6.4404 
[epoch 1] step 10/44: loss=6.3582 
[epoch 1] step 12/44: loss=6.2908 
[epoch 1] step 14/44: loss=6.3001 
[epoch 1] step 16/44: loss=6.2065 
[epoch 1] step 18/44: loss=6.1494 
[epoch 1] step 20/44: loss=6.1505 
[epoch 1] step 22/44: loss=6.0985 
[epoch 1] step 24/44: loss=6.1146 
[epoch 1] step 26/44: loss=6.0419 
[epoch 1] step 28/44: loss=6.0147 
[epoch 1] step 30/44: loss=6.0068 
[epoch 1] step 32/44: loss=6.0005 
[epoch 1] step 34/44: loss=5.9676 
[epoch 1] step 36/44: loss=5.9348 
[epoch 1] step 38/44: loss=5.8888 
[epoch 1] step 40/44: loss=5.8452 
[epoch 1] step 42/44: loss=5.8038 
[epoch 1] step 44/44: loss=5.7511 
[epoch 1] train_loss(avg per step)=11.5022 lambda[min,max]=[0.534855,1.000000]
[epoch 1] val_loss=7.8239 qwk=('0.0474', '0.0341', '0.0895') averageQWK=0.0570 macroEMD=0.3834 tailR0=('0.0000', '0.1667', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    4    0
     0   25    0   29    0
     0   63    0   62    0
     0   56    0   60    0
     0    8    0   15    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    6    0    0
    24    0   27    2    0
    56    0   50   15    0
    62    0   45   26    0
     4    0    4    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0   15   54    0    0
     0   19  131    1    0
     0   10   90    1    0
     0    0    1    1    0
[epoch 2] step 2/44: loss=4.2540 
[epoch 2] step 4/44: loss=4.0608 
[epoch 2] step 6/44: loss=3.8924 
[epoch 2] step 8/44: loss=3.8642 
[epoch 2] step 10/44: loss=3.7178 
[epoch 2] step 12/44: loss=3.6227 
[epoch 2] step 14/44: loss=3.5180 
[epoch 2] step 16/44: loss=3.4106 
[epoch 2] step 18/44: loss=3.3176 
[epoch 2] step 20/44: loss=3.2369 
[epoch 2] step 22/44: loss=3.1601 
[epoch 2] step 24/44: loss=3.1068 
[epoch 2] step 26/44: loss=3.0615 
[epoch 2] step 28/44: loss=3.0180 
[epoch 2] step 30/44: loss=2.9730 
[epoch 2] step 32/44: loss=2.9184 
[epoch 2] step 34/44: loss=2.8663 
[epoch 2] step 36/44: loss=2.8374 
[epoch 2] step 38/44: loss=2.8034 
[epoch 2] step 40/44: loss=2.7762 
[epoch 2] step 42/44: loss=2.7530 
[epoch 2] step 44/44: loss=2.7081 
[epoch 2] train_loss(avg per step)=5.4163 lambda[min,max]=[0.506593,1.000000]
[epoch 2] val_loss=3.1178 qwk=('0.4152', '0.3768', '0.3990') averageQWK=0.3970 macroEMD=0.3788 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   25   29    0    0
     0   26   87   12    0
     0    6   72   38    0
     0    3    7   13    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   51    2    0
     0    0  103   18    0
     0    0   66   67    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    0   67    2    0
     0    0  127   24    0
     0    0   42   59    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=1.9129 
[epoch 3] step 4/44: loss=2.0488 
[epoch 3] step 6/44: loss=1.9938 
[epoch 3] step 8/44: loss=1.9605 
[epoch 3] step 10/44: loss=1.9450 
[epoch 3] step 12/44: loss=1.9275 
[epoch 3] step 14/44: loss=1.9133 
[epoch 3] step 16/44: loss=1.9050 
[epoch 3] step 18/44: loss=1.9421 
[epoch 3] step 20/44: loss=1.9318 
[epoch 3] step 22/44: loss=1.9447 
[epoch 3] step 24/44: loss=1.9323 
[epoch 3] step 26/44: loss=1.9170 
[epoch 3] step 28/44: loss=1.9182 
[epoch 3] step 30/44: loss=1.9142 
[epoch 3] step 32/44: loss=1.9149 
[epoch 3] step 34/44: loss=1.9100 
[epoch 3] step 36/44: loss=1.9018 
[epoch 3] step 38/44: loss=1.8938 
[epoch 3] step 40/44: loss=1.8789 
[epoch 3] step 42/44: loss=1.8703 
[epoch 3] step 44/44: loss=1.8610 
[epoch 3] train_loss(avg per step)=3.7220 lambda[min,max]=[0.505521,1.000000]
[epoch 3] val_loss=3.0879 qwk=('0.1505', '0.4076', '0.5065') averageQWK=0.3549 macroEMD=0.3634 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    1   53    0    0
     0    1  124    0    0
     0    0   95   21    0
     0    0   19    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   22   31    0    0
     0   40   78    3    0
     0    9   81   43    0
     0    0    4    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   56   13    0    0
     0   64   85    2    0
     0   10   60   31    0
     0    0    1    1    0
[epoch 4] step 2/44: loss=1.8667 
[epoch 4] step 4/44: loss=1.7924 
[epoch 4] step 6/44: loss=1.6637 
[epoch 4] step 8/44: loss=1.6743 
[epoch 4] step 10/44: loss=1.7188 
[epoch 4] step 12/44: loss=1.7142 
[epoch 4] step 14/44: loss=1.7231 
[epoch 4] step 16/44: loss=1.7397 
[epoch 4] step 18/44: loss=1.7664 
[epoch 4] step 20/44: loss=1.7630 
[epoch 4] step 22/44: loss=1.7597 
[epoch 4] step 24/44: loss=1.7833 
[epoch 4] step 26/44: loss=1.7684 
[epoch 4] step 28/44: loss=1.7431 
[epoch 4] step 30/44: loss=1.7352 
[epoch 4] step 32/44: loss=1.7340 
[epoch 4] step 34/44: loss=1.7165 
[epoch 4] step 36/44: loss=1.7138 
[epoch 4] step 38/44: loss=1.6891 
[epoch 4] step 40/44: loss=1.6768 
[epoch 4] step 42/44: loss=1.6650 
[epoch 4] step 44/44: loss=1.6658 
[epoch 4] train_loss(avg per step)=3.3317 lambda[min,max]=[0.504731,1.000000]
[epoch 4] val_loss=2.3739 qwk=('0.4901', '0.4349', '0.5420') averageQWK=0.4890 macroEMD=0.3481 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    0    0
     0    5   48    1    0
     0    2  101   22    0
     0    0   41   75    0
     0    0    6   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   52    1    0
     0    1  101   19    0
     0    0   53   80    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   16   50    3    0
     0    3  121   27    0
     0    0   30   71    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=1.3231 
[epoch 5] step 4/44: loss=1.3553 
[epoch 5] step 6/44: loss=1.3179 
[epoch 5] step 8/44: loss=1.2629 
[epoch 5] step 10/44: loss=1.2896 
[epoch 5] step 12/44: loss=1.3084 
[epoch 5] step 14/44: loss=1.3081 
[epoch 5] step 16/44: loss=1.3165 
[epoch 5] step 18/44: loss=1.3355 
[epoch 5] step 20/44: loss=1.3234 
[epoch 5] step 22/44: loss=1.3200 
[epoch 5] step 24/44: loss=1.3432 
[epoch 5] step 26/44: loss=1.3172 
[epoch 5] step 28/44: loss=1.3140 
[epoch 5] step 30/44: loss=1.3047 
[epoch 5] step 32/44: loss=1.3047 
[epoch 5] step 34/44: loss=1.3081 
[epoch 5] step 36/44: loss=1.3111 
[epoch 5] step 38/44: loss=1.3060 
[epoch 5] step 40/44: loss=1.3127 
[epoch 5] step 42/44: loss=1.3115 
[epoch 5] step 44/44: loss=1.2904 
[epoch 5] train_loss(avg per step)=2.5808 lambda[min,max]=[0.505840,1.000000]
[epoch 5] val_loss=2.3132 qwk=('0.5822', '0.5018', '0.5253') averageQWK=0.5364 macroEMD=0.3302 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   14   34    6    0
     0   15   52   58    0
     0    0   10  106    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    0    0
     2    4   39    8    0
     1    3   78   39    0
     0    0   27  106    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   22   47    0    0
     0    7  129   15    0
     0    1   47   53    0
     0    0    0    2    0
[epoch 6] step 2/44: loss=1.0218 
[epoch 6] step 4/44: loss=1.0316 
[epoch 6] step 6/44: loss=1.1052 
[epoch 6] step 8/44: loss=1.1164 
[epoch 6] step 10/44: loss=1.1241 
[epoch 6] step 12/44: loss=1.0977 
[epoch 6] step 14/44: loss=1.0949 
[epoch 6] step 16/44: loss=1.0975 
[epoch 6] step 18/44: loss=1.1170 
[epoch 6] step 20/44: loss=1.1353 
[epoch 6] step 22/44: loss=1.1466 
[epoch 6] step 24/44: loss=1.1667 
[epoch 6] step 26/44: loss=1.1650 
[epoch 6] step 28/44: loss=1.1793 
[epoch 6] step 30/44: loss=1.1672 
[epoch 6] step 32/44: loss=1.1548 
[epoch 6] step 34/44: loss=1.1581 
[epoch 6] step 36/44: loss=1.1513 
[epoch 6] step 38/44: loss=1.1541 
[epoch 6] step 40/44: loss=1.1466 
[epoch 6] step 42/44: loss=1.1455 
[epoch 6] step 44/44: loss=1.1547 
[epoch 6] train_loss(avg per step)=2.3095 lambda[min,max]=[0.503494,1.000000]
[epoch 6] val_loss=2.1960 qwk=('0.5789', '0.5496', '0.6268') averageQWK=0.5851 macroEMD=0.3218 tailR0=('0.0217', '0.0000', '0.0000') tailR0avg=0.0072
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0    9   44    1    0
     0    9   84   32    0
     0    0   26   90    0
     0    0    3   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    0    0
     2    9   34    8    0
     1    6   73   41    0
     0    0   17  116    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   32   34    3    0
     0   12  107   32    0
     0    2   23   76    0
     0    0    0    2    0
[epoch 7] step 2/44: loss=0.6930 
[epoch 7] step 4/44: loss=0.8735 
[epoch 7] step 6/44: loss=0.9776 
[epoch 7] step 8/44: loss=0.9457 
[epoch 7] step 10/44: loss=0.9564 
[epoch 7] step 12/44: loss=0.9792 
[epoch 7] step 14/44: loss=0.9758 
[epoch 7] step 16/44: loss=1.0122 
[epoch 7] step 18/44: loss=1.0064 
[epoch 7] step 20/44: loss=1.0121 
[epoch 7] step 22/44: loss=1.0093 
[epoch 7] step 24/44: loss=1.0018 
[epoch 7] step 26/44: loss=0.9876 
[epoch 7] step 28/44: loss=0.9818 
[epoch 7] step 30/44: loss=0.9916 
[epoch 7] step 32/44: loss=0.9891 
[epoch 7] step 34/44: loss=0.9872 
[epoch 7] step 36/44: loss=0.9817 
[epoch 7] step 38/44: loss=0.9794 
[epoch 7] step 40/44: loss=0.9911 
[epoch 7] step 42/44: loss=0.9843 
[epoch 7] step 44/44: loss=0.9827 
[epoch 7] train_loss(avg per step)=1.9655 lambda[min,max]=[0.503461,1.000000]
[epoch 7] val_loss=2.2695 qwk=('0.6349', '0.5677', '0.4838') averageQWK=0.5621 macroEMD=0.3107 tailR0=('0.0435', '0.0000', '0.0000') tailR0avg=0.0145
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   21   32    1    0
     0   18   86   21    0
     0    0   32   84    0
     0    0    4   17    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   10   40    3    0
     0    4  101   16    0
     0    0   42   91    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   28   41    0    0
     0   11  137    3    0
     0    1   66   34    0
     0    0    2    0    0
[epoch 8] step 2/44: loss=0.9798 
[epoch 8] step 4/44: loss=0.9656 
[epoch 8] step 6/44: loss=0.9183 
[epoch 8] step 8/44: loss=0.9248 
[epoch 8] step 10/44: loss=0.8833 
[epoch 8] step 12/44: loss=0.8630 
[epoch 8] step 14/44: loss=0.8512 
[epoch 8] step 16/44: loss=0.8364 
[epoch 8] step 18/44: loss=0.8148 
[epoch 8] step 20/44: loss=0.8082 
[epoch 8] step 22/44: loss=0.7956 
[epoch 8] step 24/44: loss=0.7914 
[epoch 8] step 26/44: loss=0.7843 
[epoch 8] step 28/44: loss=0.7858 
[epoch 8] step 30/44: loss=0.8089 
[epoch 8] step 32/44: loss=0.7996 
[epoch 8] step 34/44: loss=0.8180 
[epoch 8] step 36/44: loss=0.8456 
[epoch 8] step 38/44: loss=0.8534 
[epoch 8] step 40/44: loss=0.8484 
[epoch 8] step 42/44: loss=0.8459 
[epoch 8] step 44/44: loss=0.8396 
[epoch 8] train_loss(avg per step)=1.6791 lambda[min,max]=[0.505297,1.000000]
[epoch 8] val_loss=2.3795 qwk=('0.5015', '0.6007', '0.3476') averageQWK=0.4833 macroEMD=0.3064 tailR0=('0.0000', '0.0556', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    0    0
     0    4   50    0    0
     0    3  113    9    0
     0    0   52   64    0
     0    0    5   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     5   10   32    6    0
     2   11   67   41    0
     0    0   19  114    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   26   43    0    0
     0    9  142    0    0
     0    2   87   12    0
     0    0    2    0    0
[epoch 9] step 2/44: loss=0.8280 
[epoch 9] step 4/44: loss=0.8207 
[epoch 9] step 6/44: loss=0.8602 
[epoch 9] step 8/44: loss=0.8400 
[epoch 9] step 10/44: loss=0.8401 
[epoch 9] step 12/44: loss=0.7931 
[epoch 9] step 14/44: loss=0.7886 
[epoch 9] step 16/44: loss=0.7685 
[epoch 9] step 18/44: loss=0.7728 
[epoch 9] step 20/44: loss=0.7682 
[epoch 9] step 22/44: loss=0.7729 
[epoch 9] step 24/44: loss=0.7565 
[epoch 9] step 26/44: loss=0.7440 
[epoch 9] step 28/44: loss=0.7308 
[epoch 9] step 30/44: loss=0.7288 
[epoch 9] step 32/44: loss=0.7092 
[epoch 9] step 34/44: loss=0.7038 
[epoch 9] step 36/44: loss=0.6988 
[epoch 9] step 38/44: loss=0.6967 
[epoch 9] step 40/44: loss=0.6933 
[epoch 9] step 42/44: loss=0.6882 
[epoch 9] step 44/44: loss=0.6899 
[epoch 9] train_loss(avg per step)=1.3798 lambda[min,max]=[0.501449,1.000000]
[epoch 9] val_loss=2.1323 qwk=('0.6464', '0.6138', '0.6470') averageQWK=0.6357 macroEMD=0.2838 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   20   32    2    0
     0   19   67   39    0
     0    0   18   98    0
     0    0    3   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     1   22   23    7    0
     0   27   54   40    0
     0    1   21  111    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   40   28    1    0
     0   24   94   33    0
     0    2   27   72    0
     0    0    0    2    0
[epoch 10] step 2/44: loss=0.4993 
[epoch 10] step 4/44: loss=0.5567 
[epoch 10] step 6/44: loss=0.5861 
[epoch 10] step 8/44: loss=0.5696 
[epoch 10] step 10/44: loss=0.5777 
[epoch 10] step 12/44: loss=0.5617 
[epoch 10] step 14/44: loss=0.5723 
[epoch 10] step 16/44: loss=0.5751 
[epoch 10] step 18/44: loss=0.5583 
[epoch 10] step 20/44: loss=0.5508 
[epoch 10] step 22/44: loss=0.5416 
[epoch 10] step 24/44: loss=0.5286 
[epoch 10] step 26/44: loss=0.5188 
[epoch 10] step 28/44: loss=0.5098 
[epoch 10] step 30/44: loss=0.5132 
[epoch 10] step 32/44: loss=0.5242 
[epoch 10] step 34/44: loss=0.5198 
[epoch 10] step 36/44: loss=0.5411 
[epoch 10] step 38/44: loss=0.5508 
[epoch 10] step 40/44: loss=0.5422 
[epoch 10] step 42/44: loss=0.5527 
[epoch 10] step 44/44: loss=0.5596 
[epoch 10] train_loss(avg per step)=1.1192 lambda[min,max]=[0.500740,1.000000]
[epoch 10] val_loss=2.3440 qwk=('0.5903', '0.5661', '0.5619') averageQWK=0.5728 macroEMD=0.2950 tailR0=('0.2022', '0.1667', '0.0000') tailR0avg=0.1229
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    6    0    0
     0    4   47    3    0
     0    3   73   47    2
     0    0   12  101    3
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0    8   38    6    1
     0    7   75   38    1
     0    0   23  103    7
     0    0    0    8    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   14   53    2    0
     0    3  101   47    0
     0    0   16   85    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.7185 
[epoch 11] step 4/44: loss=0.6301 
[epoch 11] step 6/44: loss=0.6116 
[epoch 11] step 8/44: loss=0.6200 
[epoch 11] step 10/44: loss=0.6072 
[epoch 11] step 12/44: loss=0.5937 
[epoch 11] step 14/44: loss=0.6056 
[epoch 11] step 16/44: loss=0.5744 
[epoch 11] step 18/44: loss=0.5484 
[epoch 11] step 20/44: loss=0.5301 
[epoch 11] step 22/44: loss=0.5224 
[epoch 11] step 24/44: loss=0.5180 
[epoch 11] step 26/44: loss=0.5156 
[epoch 11] step 28/44: loss=0.4935 
[epoch 11] step 30/44: loss=0.4803 
[epoch 11] step 32/44: loss=0.4711 
[epoch 11] step 34/44: loss=0.4633 
[epoch 11] step 36/44: loss=0.4576 
[epoch 11] step 38/44: loss=0.4507 
[epoch 11] step 40/44: loss=0.4477 
[epoch 11] step 42/44: loss=0.4380 
[epoch 11] step 44/44: loss=0.4466 
[epoch 11] train_loss(avg per step)=0.8932 lambda[min,max]=[0.500148,1.000000]
[epoch 11] val_loss=2.1827 qwk=('0.6132', '0.6055', '0.6311') averageQWK=0.6166 macroEMD=0.2725 tailR0=('0.2239', '0.1667', '0.0000') tailR0avg=0.1302
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    6    0    0
     1    5   47    1    0
     0    5   88   30    2
     0    0   24   85    7
     0    0    1   14    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   20   26    6    1
     0   21   54   45    1
     0    1   13  112    7
     0    0    0    8    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   34   34    1    0
     0   16  108   27    0
     0    2   29   70    0
     0    0    0    2    0
[epoch 12] step 2/44: loss=0.2523 
[epoch 12] step 4/44: loss=0.2440 
[epoch 12] step 6/44: loss=0.2831 
[epoch 12] step 8/44: loss=0.2575 
[epoch 12] step 10/44: loss=0.2725 
[epoch 12] step 12/44: loss=0.2350 
[epoch 12] step 14/44: loss=0.2399 
[epoch 12] step 16/44: loss=0.2476 
[epoch 12] step 18/44: loss=0.2555 
[epoch 12] step 20/44: loss=0.2565 
[epoch 12] step 22/44: loss=0.2618 
[epoch 12] step 24/44: loss=0.2612 
[epoch 12] step 26/44: loss=0.2512 
[epoch 12] step 28/44: loss=0.2449 
[epoch 12] step 30/44: loss=0.2492 
[epoch 12] step 32/44: loss=0.2373 
[epoch 12] step 34/44: loss=0.2349 
[epoch 12] step 36/44: loss=0.2378 
[epoch 12] step 38/44: loss=0.2396 
[epoch 12] step 40/44: loss=0.2361 
[epoch 12] step 42/44: loss=0.2343 
[epoch 12] step 44/44: loss=0.2376 
[epoch 12] train_loss(avg per step)=0.4751 lambda[min,max]=[0.500356,1.000000]
[epoch 12] val_loss=2.3392 qwk=('0.6380', '0.5708', '0.6464') averageQWK=0.6184 macroEMD=0.2719 tailR0=('0.3739', '0.1667', '0.2000') tailR0avg=0.2469
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    5    1    0    0
     1   20   33    0    0
     2   19   89   13    2
     0    0   48   65    3
     0    0    6    9    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   21   29    2    1
     1   25   79   15    1
     0    3   49   73    8
     0    0    2    6    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   48   21    0    0
     1   41   86   23    0
     0    5   28   68    0
     0    0    0    2    0
[epoch 13] step 2/44: loss=0.2555 
[epoch 13] step 4/44: loss=0.1932 
[epoch 13] step 6/44: loss=0.2033 
[epoch 13] step 8/44: loss=0.2444 
[epoch 13] step 10/44: loss=0.2485 
[epoch 13] step 12/44: loss=0.2467 
[epoch 13] step 14/44: loss=0.2531 
[epoch 13] step 16/44: loss=0.2331 
[epoch 13] step 18/44: loss=0.2408 
[epoch 13] step 20/44: loss=0.2247 
[epoch 13] step 22/44: loss=0.2151 
[epoch 13] step 24/44: loss=0.2102 
[epoch 13] step 26/44: loss=0.2071 
[epoch 13] step 28/44: loss=0.2108 
[epoch 13] step 30/44: loss=0.2136 
[epoch 13] step 32/44: loss=0.2011 
[epoch 13] step 34/44: loss=0.2005 
[epoch 13] step 36/44: loss=0.1947 
[epoch 13] step 38/44: loss=0.1863 
[epoch 13] step 40/44: loss=0.1837 
[epoch 13] step 42/44: loss=0.1805 
[epoch 13] step 44/44: loss=0.1701 
[epoch 13] train_loss(avg per step)=0.3402 lambda[min,max]=[0.500116,1.000000]
[epoch 13] val_loss=2.1972 qwk=('0.6782', '0.6017', '0.6387') averageQWK=0.6395 macroEMD=0.2567 tailR0=('0.1652', '0.0417', '0.2000') tailR0avg=0.1356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    8    0    0    0
     0   22   31    1    0
     1   23   71   30    0
     0    0   31   83    2
     0    0    0   20    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    0    0
     0   20   30    3    0
     1   23   67   30    0
     0    2   36   90    5
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   43   25    1    0
     1   26  100   24    0
     0    4   32   65    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.1287 
[epoch 14] step 4/44: loss=0.1088 
[epoch 14] step 6/44: loss=0.1046 
[epoch 14] step 8/44: loss=0.0809 
[epoch 14] step 10/44: loss=0.1099 
[epoch 14] step 12/44: loss=0.0910 
[epoch 14] step 14/44: loss=0.0878 
[epoch 14] step 16/44: loss=0.0978 
[epoch 14] step 18/44: loss=0.0866 
[epoch 14] step 20/44: loss=0.0815 
[epoch 14] step 22/44: loss=0.0706 
[epoch 14] step 24/44: loss=0.0701 
[epoch 14] step 26/44: loss=0.0737 
[epoch 14] step 28/44: loss=0.0612 
[epoch 14] step 30/44: loss=0.0539 
[epoch 14] step 32/44: loss=0.0464 
[epoch 14] step 34/44: loss=0.0389 
[epoch 14] step 36/44: loss=0.0353 
[epoch 14] step 38/44: loss=0.0462 
[epoch 14] step 40/44: loss=0.0410 
[epoch 14] step 42/44: loss=0.0444 
[epoch 14] step 44/44: loss=0.0434 
[epoch 14] train_loss(avg per step)=0.0868 lambda[min,max]=[0.500182,1.000000]
[epoch 14] val_loss=2.3484 qwk=('0.6658', '0.6082', '0.6016') averageQWK=0.6252 macroEMD=0.2570 tailR0=('0.1739', '0.2361', '0.0000') tailR0avg=0.1367
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     0   19   33    2    0
     0   24   65   35    1
     0    0   20   92    4
     0    0    1   14    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     3   13   33    3    1
     1   14   77   29    0
     0    1   31   93    8
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   36   30    3    0
     1   14  100   36    0
     0    3   24   74    0
     0    0    0    2    0
[epoch 15] step 2/44: loss=0.0382 
[epoch 15] step 4/44: loss=0.0475 
[epoch 15] step 6/44: loss=0.0666 
[epoch 15] step 8/44: loss=0.0638 
[epoch 15] step 10/44: loss=0.0671 
[epoch 15] step 12/44: loss=0.0516 
[epoch 15] step 14/44: loss=0.0359 
[epoch 15] step 16/44: loss=0.0103 
[epoch 15] step 18/44: loss=-0.0044 
[epoch 15] step 20/44: loss=-0.0133 
[epoch 15] step 22/44: loss=-0.0057 
[epoch 15] step 24/44: loss=-0.0056 
[epoch 15] step 26/44: loss=-0.0124 
[epoch 15] step 28/44: loss=-0.0226 
[epoch 15] step 30/44: loss=-0.0202 
[epoch 15] step 32/44: loss=-0.0001 
[epoch 15] step 34/44: loss=-0.0015 
[epoch 15] step 36/44: loss=-0.0021 
[epoch 15] step 38/44: loss=-0.0038 
[epoch 15] step 40/44: loss=-0.0036 
[epoch 15] step 42/44: loss=-0.0131 
[epoch 15] step 44/44: loss=-0.0122 
[epoch 15] train_loss(avg per step)=-0.0245 lambda[min,max]=[0.500027,1.000000]
[epoch 15] val_loss=2.4457 qwk=('0.6467', '0.5999', '0.6647') averageQWK=0.6371 macroEMD=0.2505 tailR0=('0.3239', '0.2361', '0.2000') tailR0avg=0.2533
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    3    0    0
     0   21   33    0    0
     1   15   87   20    2
     0    0   37   73    6
     0    0    5   10    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    0    0
     2   13   36    2    0
     1   17   87   15    1
     0    2   41   80   10
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    0    0
     0   42   26    1    0
     1   24  105   21    0
     0    2   32   67    0
     0    0    0    2    0
[epoch 16] step 2/44: loss=-0.1688 
[epoch 16] step 4/44: loss=-0.0972 
[epoch 16] step 6/44: loss=-0.0803 
[epoch 16] step 8/44: loss=-0.1040 
[epoch 16] step 10/44: loss=-0.1086 
[epoch 16] step 12/44: loss=-0.1198 
[epoch 16] step 14/44: loss=-0.1176 
[epoch 16] step 16/44: loss=-0.1068 
[epoch 16] step 18/44: loss=-0.1043 
[epoch 16] step 20/44: loss=-0.1046 
[epoch 16] step 22/44: loss=-0.1171 
[epoch 16] step 24/44: loss=-0.1160 
[epoch 16] step 26/44: loss=-0.1181 
[epoch 16] step 28/44: loss=-0.1228 
[epoch 16] step 30/44: loss=-0.1255 
[epoch 16] step 32/44: loss=-0.1248 
[epoch 16] step 34/44: loss=-0.1184 
[epoch 16] step 36/44: loss=-0.1176 
[epoch 16] step 38/44: loss=-0.1129 
[epoch 16] step 40/44: loss=-0.1118 
[epoch 16] step 42/44: loss=-0.1076 
[epoch 16] step 44/44: loss=-0.1089 
[epoch 16] train_loss(avg per step)=-0.2178 lambda[min,max]=[0.500016,1.000000]
[epoch 16] val_loss=2.5335 qwk=('0.6559', '0.6084', '0.6160') averageQWK=0.6268 macroEMD=0.2521 tailR0=('0.2239', '0.1250', '0.0000') tailR0avg=0.1163
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    3    0    0
     0   15   37    2    0
     0   10   79   34    2
     0    0   24   86    6
     0    0    0   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   13   36    4    0
     0   14   70   36    1
     0    0   26  103    4
     0    0    0    9    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   29   40    0    0
     0   16  111   24    0
     0    1   34   66    0
     0    0    0    2    0
[epoch 17] step 2/44: loss=-0.1963 
[epoch 17] step 4/44: loss=-0.2010 
[epoch 17] step 6/44: loss=-0.2347 
[epoch 17] step 8/44: loss=-0.2042 
[epoch 17] step 10/44: loss=-0.2100 
[epoch 17] step 12/44: loss=-0.2089 
[epoch 17] step 14/44: loss=-0.2056 
[epoch 17] step 16/44: loss=-0.2095 
[epoch 17] step 18/44: loss=-0.1963 
[epoch 17] step 20/44: loss=-0.1971 
[epoch 17] step 22/44: loss=-0.2029 
[epoch 17] step 24/44: loss=-0.2020 
[epoch 17] step 26/44: loss=-0.2056 
[epoch 17] step 28/44: loss=-0.2121 
[epoch 17] step 30/44: loss=-0.2153 
[epoch 17] step 32/44: loss=-0.2166 
[epoch 17] step 34/44: loss=-0.2181 
[epoch 17] step 36/44: loss=-0.2234 
[epoch 17] step 38/44: loss=-0.2223 
[epoch 17] step 40/44: loss=-0.2228 
[epoch 17] step 42/44: loss=-0.2220 
[epoch 17] step 44/44: loss=-0.2245 
[epoch 17] train_loss(avg per step)=-0.4490 lambda[min,max]=[0.500031,1.000000]
[epoch 17] val_loss=2.8258 qwk=('0.6617', '0.6175', '0.6119') averageQWK=0.6304 macroEMD=0.2457 tailR0=('0.4022', '0.0972', '0.0000') tailR0avg=0.1665
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     5    2    3    0    0
     1   15   37    1    0
     1    9   83   32    0
     0    0   29   84    3
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     1   21   25    6    0
     0   22   59   40    0
     0    1   23  108    1
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   26   43    0    0
     0    9  122   20    0
     0    0   37   64    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=-0.2579 
[epoch 18] step 4/44: loss=-0.2506 
[epoch 18] step 6/44: loss=-0.2677 
[epoch 18] step 8/44: loss=-0.2732 
[epoch 18] step 10/44: loss=-0.2791 
[epoch 18] step 12/44: loss=-0.2873 
[epoch 18] step 14/44: loss=-0.2874 
[epoch 18] step 16/44: loss=-0.2866 
[epoch 18] step 18/44: loss=-0.2840 
[epoch 18] step 20/44: loss=-0.2934 
[epoch 18] step 22/44: loss=-0.3002 
[epoch 18] step 24/44: loss=-0.3026 
[epoch 18] step 26/44: loss=-0.3052 
[epoch 18] step 28/44: loss=-0.3000 
[epoch 18] step 30/44: loss=-0.2921 
[epoch 18] step 32/44: loss=-0.2965 
[epoch 18] step 34/44: loss=-0.2964 
[epoch 18] step 36/44: loss=-0.2966 
[epoch 18] step 38/44: loss=-0.2981 
[epoch 18] step 40/44: loss=-0.3002 
[epoch 18] step 42/44: loss=-0.3024 
[epoch 18] step 44/44: loss=-0.3052 
[epoch 18] train_loss(avg per step)=-0.6103 lambda[min,max]=[0.500005,1.000000]
[epoch 18] val_loss=2.8584 qwk=('0.6769', '0.5867', '0.6209') averageQWK=0.6282 macroEMD=0.2410 tailR0=('0.3022', '0.1389', '0.2000') tailR0avg=0.2137
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    6    1    0    0
     0   21   30    3    0
     0   21   68   34    2
     0    0   21   86    9
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     2   16   30    4    1
     1   16   75   28    1
     0    1   33   92    7
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    1    0    0
     0   31   35    3    0
     0   14  107   30    0
     0    1   30   69    1
     0    0    0    2    0
[epoch 19] step 2/44: loss=-0.4023 
[epoch 19] step 4/44: loss=-0.3498 
[epoch 19] step 6/44: loss=-0.3310 
[epoch 19] step 8/44: loss=-0.3104 
[epoch 19] step 10/44: loss=-0.3399 
[epoch 19] step 12/44: loss=-0.3374 
[epoch 19] step 14/44: loss=-0.3410 
[epoch 19] step 16/44: loss=-0.3471 
[epoch 19] step 18/44: loss=-0.3569 
[epoch 19] step 20/44: loss=-0.3579 
[epoch 19] step 22/44: loss=-0.3620 
[epoch 19] step 24/44: loss=-0.3638 
[epoch 19] step 26/44: loss=-0.3590 
[epoch 19] step 28/44: loss=-0.3584 
[epoch 19] step 30/44: loss=-0.3597 
[epoch 19] step 32/44: loss=-0.3639 
[epoch 19] step 34/44: loss=-0.3655 
[epoch 19] step 36/44: loss=-0.3613 
[epoch 19] step 38/44: loss=-0.3605 
[epoch 19] step 40/44: loss=-0.3585 
[epoch 19] step 42/44: loss=-0.3585 
[epoch 19] step 44/44: loss=-0.3621 
[epoch 19] train_loss(avg per step)=-0.7241 lambda[min,max]=[0.500001,1.000000]
[epoch 19] val_loss=3.1310 qwk=('0.6735', '0.5892', '0.5598') averageQWK=0.6075 macroEMD=0.2469 tailR0=('0.1152', '0.1389', '0.0000') tailR0avg=0.0847
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    2    0    0
     0   21   33    0    0
     0   18   74   33    0
     0    0   23   93    0
     0    0    2   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     2   10   37    4    0
     0    9   84   28    0
     0    0   36   93    4
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   31   38    0    0
     0   17  121   13    0
     0    1   47   53    0
     0    0    1    1    0
[epoch 20] step 2/44: loss=-0.4238 
[epoch 20] step 4/44: loss=-0.4302 
[epoch 20] step 6/44: loss=-0.4275 
[epoch 20] step 8/44: loss=-0.4308 
[epoch 20] step 10/44: loss=-0.4135 
[epoch 20] step 12/44: loss=-0.4069 
[epoch 20] step 14/44: loss=-0.4025 
[epoch 20] step 16/44: loss=-0.4067 
[epoch 20] step 18/44: loss=-0.4016 
[epoch 20] step 20/44: loss=-0.3953 
[epoch 20] step 22/44: loss=-0.3885 
[epoch 20] step 24/44: loss=-0.3932 
[epoch 20] step 26/44: loss=-0.3942 
[epoch 20] step 28/44: loss=-0.3927 
[epoch 20] step 30/44: loss=-0.3920 
[epoch 20] step 32/44: loss=-0.3947 
[epoch 20] step 34/44: loss=-0.3955 
[epoch 20] step 36/44: loss=-0.3967 
[epoch 20] step 38/44: loss=-0.3979 
[epoch 20] step 40/44: loss=-0.3987 
[epoch 20] step 42/44: loss=-0.3990 
[epoch 20] step 44/44: loss=-0.3991 
[epoch 20] train_loss(avg per step)=-0.7982 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=3.3447 qwk=('0.6669', '0.5979', '0.6079') averageQWK=0.6242 macroEMD=0.2312 tailR0=('0.1370', '0.1389', '0.0000') tailR0avg=0.0919
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    2    0    0
     0   18   34    2    0
     0   15   76   34    0
     0    0   24   90    2
     0    0    0   19    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     1   18   29    4    1
     0   15   65   39    2
     0    1   22  105    5
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   37   29    3    0
     0   23   92   36    0
     0    3   24   74    0
     0    0    0    2    0
[epoch 21] step 2/44: loss=-0.3965 
[epoch 21] step 4/44: loss=-0.4300 
[epoch 21] step 6/44: loss=-0.4376 
[epoch 21] step 8/44: loss=-0.4307 
[epoch 21] step 10/44: loss=-0.4458 
[epoch 21] step 12/44: loss=-0.4397 
[epoch 21] step 14/44: loss=-0.4412 
[epoch 21] step 16/44: loss=-0.4406 
[epoch 21] step 18/44: loss=-0.4382 
[epoch 21] step 20/44: loss=-0.4415 
[epoch 21] step 22/44: loss=-0.4443 
[epoch 21] step 24/44: loss=-0.4412 
[epoch 21] step 26/44: loss=-0.4445 
[epoch 21] step 28/44: loss=-0.4431 
[epoch 21] step 30/44: loss=-0.4443 
[epoch 21] step 32/44: loss=-0.4412 
[epoch 21] step 34/44: loss=-0.4404 
[epoch 21] step 36/44: loss=-0.4411 
[epoch 21] step 38/44: loss=-0.4402 
[epoch 21] step 40/44: loss=-0.4411 
[epoch 21] step 42/44: loss=-0.4409 
[epoch 21] step 44/44: loss=-0.4430 
[epoch 21] train_loss(avg per step)=-0.8859 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=3.8087 qwk=('0.6396', '0.5888', '0.5923') averageQWK=0.6069 macroEMD=0.2353 tailR0=('0.2239', '0.1250', '0.0000') tailR0avg=0.1163
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    3    0    0
     0   13   39    2    0
     0    9   79   36    1
     0    0   24   87    5
     0    0    2   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     2   13   34    4    0
     0   15   73   32    1
     0    1   30   96    6
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   34   32    3    0
     0   15   87   49    0
     0    1   25   75    0
     0    0    0    2    0
[epoch 22] step 2/44: loss=-0.4631 
[epoch 22] step 4/44: loss=-0.4670 
[epoch 22] step 6/44: loss=-0.4743 
[epoch 22] step 8/44: loss=-0.4391 
[epoch 22] step 10/44: loss=-0.4402 
[epoch 22] step 12/44: loss=-0.4451 
[epoch 22] step 14/44: loss=-0.4493 
[epoch 22] step 16/44: loss=-0.4544 
[epoch 22] step 18/44: loss=-0.4602 
[epoch 22] step 20/44: loss=-0.4586 
[epoch 22] step 22/44: loss=-0.4563 
[epoch 22] step 24/44: loss=-0.4507 
[epoch 22] step 26/44: loss=-0.4518 
[epoch 22] step 28/44: loss=-0.4517 
[epoch 22] step 30/44: loss=-0.4522 
[epoch 22] step 32/44: loss=-0.4508 
[epoch 22] step 34/44: loss=-0.4520 
[epoch 22] step 36/44: loss=-0.4460 
[epoch 22] step 38/44: loss=-0.4457 
[epoch 22] step 40/44: loss=-0.4452 
[epoch 22] step 42/44: loss=-0.4461 
[epoch 22] step 44/44: loss=-0.4489 
[epoch 22] train_loss(avg per step)=-0.8978 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=3.5508 qwk=('0.6125', '0.5731', '0.6317') averageQWK=0.6058 macroEMD=0.2381 tailR0=('0.1587', '0.2083', '0.0000') tailR0avg=0.1223
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    3    0    0
     0   16   33    5    0
     1   18   64   41    1
     0    1   15   94    6
     0    0    2   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     2    8   37    5    1
     0   13   72   32    4
     0    0   24   94   15
     0    0    0    7    5
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     1   38   29    1    0
     0   16  106   28    1
     0    2   32   64    3
     0    0    0    2    0
[epoch 23] step 2/44: loss=-0.4932 
[epoch 23] step 4/44: loss=-0.4639 
[epoch 23] step 6/44: loss=-0.4625 
[epoch 23] step 8/44: loss=-0.4633 
[epoch 23] step 10/44: loss=-0.4690 
[epoch 23] step 12/44: loss=-0.4716 
[epoch 23] step 14/44: loss=-0.4720 
[epoch 23] step 16/44: loss=-0.4694 
[epoch 23] step 18/44: loss=-0.4718 
[epoch 23] step 20/44: loss=-0.4728 
[epoch 23] step 22/44: loss=-0.4692 
[epoch 23] step 24/44: loss=-0.4710 
[epoch 23] step 26/44: loss=-0.4727 
[epoch 23] step 28/44: loss=-0.4755 
[epoch 23] step 30/44: loss=-0.4787 
[epoch 23] step 32/44: loss=-0.4793 
[epoch 23] step 34/44: loss=-0.4826 
[epoch 23] step 36/44: loss=-0.4841 
[epoch 23] step 38/44: loss=-0.4851 
[epoch 23] step 40/44: loss=-0.4849 
[epoch 23] step 42/44: loss=-0.4851 
[epoch 23] step 44/44: loss=-0.4831 
[epoch 23] train_loss(avg per step)=-0.9662 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=3.8035 qwk=('0.6136', '0.6128', '0.6085') averageQWK=0.6116 macroEMD=0.2348 tailR0=('0.0717', '0.0833', '0.0000') tailR0avg=0.0517
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    3    0    0
     0   18   30    6    0
     0   20   62   43    0
     0    0   19   97    0
     0    0    0   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   22   27    3    0
     0   18   88   15    0
     0    1   43   86    3
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   31   38    0    0
     0   17  114   20    0
     0    0   40   61    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=-0.5130 
[epoch 24] step 4/44: loss=-0.4995 
[epoch 24] step 6/44: loss=-0.4952 
[epoch 24] step 8/44: loss=-0.5040 
[epoch 24] step 10/44: loss=-0.5070 
[epoch 24] step 12/44: loss=-0.5117 
[epoch 24] step 14/44: loss=-0.5129 
[epoch 24] step 16/44: loss=-0.5125 
[epoch 24] step 18/44: loss=-0.5088 
[epoch 24] step 20/44: loss=-0.5033 
[epoch 24] step 22/44: loss=-0.5035 
[epoch 24] step 24/44: loss=-0.5042 
[epoch 24] step 26/44: loss=-0.5040 
[epoch 24] step 28/44: loss=-0.5021 
[epoch 24] step 30/44: loss=-0.5040 
[epoch 24] step 32/44: loss=-0.5057 
[epoch 24] step 34/44: loss=-0.5048 
[epoch 24] step 36/44: loss=-0.5056 
[epoch 24] step 38/44: loss=-0.5030 
[epoch 24] step 40/44: loss=-0.5007 
[epoch 24] step 42/44: loss=-0.5017 
[epoch 24] step 44/44: loss=-0.5002 
[epoch 24] train_loss(avg per step)=-1.0005 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=3.7090 qwk=('0.6397', '0.6077', '0.6342') averageQWK=0.6272 macroEMD=0.2332 tailR0=('0.1804', '0.0417', '0.0000') tailR0avg=0.0740
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    4    0    0
     1   15   36    2    0
     0   17   75   32    1
     0    0   22   92    2
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   17   30    5    0
     0   16   73   32    0
     0    2   23  105    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   36   33    0    0
     0   21  112   18    0
     0    1   38   61    1
     0    0    0    2    0
[epoch 25] step 2/44: loss=-0.5390 
[epoch 25] step 4/44: loss=-0.5439 
[epoch 25] step 6/44: loss=-0.5207 
[epoch 25] step 8/44: loss=-0.5131 
[epoch 25] step 10/44: loss=-0.5149 
[epoch 25] step 12/44: loss=-0.5156 
[epoch 25] step 14/44: loss=-0.5165 
[epoch 25] step 16/44: loss=-0.5202 
[epoch 25] step 18/44: loss=-0.5193 
[epoch 25] step 20/44: loss=-0.5178 
[epoch 25] step 22/44: loss=-0.5179 
[epoch 25] step 24/44: loss=-0.5160 
[epoch 25] step 26/44: loss=-0.5151 
[epoch 25] step 28/44: loss=-0.5157 
[epoch 25] step 30/44: loss=-0.5184 
[epoch 25] step 32/44: loss=-0.5179 
[epoch 25] step 34/44: loss=-0.5195 
[epoch 25] step 36/44: loss=-0.5204 
[epoch 25] step 38/44: loss=-0.5199 
[epoch 25] step 40/44: loss=-0.5182 
[epoch 25] step 42/44: loss=-0.5186 
[epoch 25] step 44/44: loss=-0.5188 
[epoch 25] train_loss(avg per step)=-1.0377 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=3.9673 qwk=('0.6839', '0.6315', '0.6152') averageQWK=0.6435 macroEMD=0.2218 tailR0=('0.3239', '0.0417', '0.0000') tailR0avg=0.1219
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    6    1    0    0
     2   24   27    1    0
     0   31   66   28    0
     0    1   28   79    8
     0    0    3   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    0    0
     1   25   20    7    0
     0   25   54   42    0
     0    3   19  108    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   38   30    1    0
     0   27  101   23    0
     0    2   35   64    0
     0    0    0    2    0
[epoch 26] step 2/44: loss=-0.5333 
[epoch 26] step 4/44: loss=-0.4856 
[epoch 26] step 6/44: loss=-0.5054 
[epoch 26] step 8/44: loss=-0.5101 
[epoch 26] step 10/44: loss=-0.5156 
[epoch 26] step 12/44: loss=-0.5255 
[epoch 26] step 14/44: loss=-0.5303 
[epoch 26] step 16/44: loss=-0.5307 
[epoch 26] step 18/44: loss=-0.5310 
[epoch 26] step 20/44: loss=-0.5300 
[epoch 26] step 22/44: loss=-0.5319 
[epoch 26] step 24/44: loss=-0.5286 
[epoch 26] step 26/44: loss=-0.5271 
[epoch 26] step 28/44: loss=-0.5281 
[epoch 26] step 30/44: loss=-0.5289 
[epoch 26] step 32/44: loss=-0.5301 
[epoch 26] step 34/44: loss=-0.5312 
[epoch 26] step 36/44: loss=-0.5273 
[epoch 26] step 38/44: loss=-0.5252 
[epoch 26] step 40/44: loss=-0.5230 
[epoch 26] step 42/44: loss=-0.5234 
[epoch 26] step 44/44: loss=-0.5243 
[epoch 26] train_loss(avg per step)=-1.0486 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=4.1149 qwk=('0.6638', '0.5978', '0.6226') averageQWK=0.6281 macroEMD=0.2257 tailR0=('0.2522', '0.0417', '0.0000') tailR0avg=0.0979
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    2    0    0
     1   17   34    2    0
     0   21   70   34    0
     0    0   21   91    4
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     2   15   33    3    0
     0   16   82   22    1
     0    1   38   90    4
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   45   24    0    0
     0   29  103   19    0
     0    4   38   59    0
     0    0    0    2    0
[epoch 27] step 2/44: loss=-0.5733 
[epoch 27] step 4/44: loss=-0.5555 
[epoch 27] step 6/44: loss=-0.5561 
[epoch 27] step 8/44: loss=-0.5467 
[epoch 27] step 10/44: loss=-0.5502 
[epoch 27] step 12/44: loss=-0.5526 
[epoch 27] step 14/44: loss=-0.5548 
[epoch 27] step 16/44: loss=-0.5550 
[epoch 27] step 18/44: loss=-0.5570 
[epoch 27] step 20/44: loss=-0.5577 
[epoch 27] step 22/44: loss=-0.5573 
[epoch 27] step 24/44: loss=-0.5552 
[epoch 27] step 26/44: loss=-0.5546 
[epoch 27] step 28/44: loss=-0.5551 
[epoch 27] step 30/44: loss=-0.5555 
[epoch 27] step 32/44: loss=-0.5544 
[epoch 27] step 34/44: loss=-0.5527 
[epoch 27] step 36/44: loss=-0.5514 
[epoch 27] step 38/44: loss=-0.5493 
[epoch 27] step 40/44: loss=-0.5480 
[epoch 27] step 42/44: loss=-0.5489 
[epoch 27] step 44/44: loss=-0.5505 
[epoch 27] train_loss(avg per step)=-1.1010 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=4.0980 qwk=('0.6505', '0.5552', '0.6293') averageQWK=0.6117 macroEMD=0.2293 tailR0=('0.2522', '0.1250', '0.1000') tailR0avg=0.1591
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    2    0    0
     0   16   37    1    0
     0   16   78   29    2
     0    0   26   81    9
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     2   11   34    5    1
     0   14   77   28    2
     0    1   32   93    7
     0    0    1    8    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     1   36   32    0    0
     0   19  114   18    0
     0    2   40   59    0
     0    0    0    2    0
[epoch 28] step 2/44: loss=-0.5661 
[epoch 28] step 4/44: loss=-0.5691 
[epoch 28] step 6/44: loss=-0.5680 
[epoch 28] step 8/44: loss=-0.5619 
[epoch 28] step 10/44: loss=-0.5574 
[epoch 28] step 12/44: loss=-0.5601 
[epoch 28] step 14/44: loss=-0.5567 
[epoch 28] step 16/44: loss=-0.5536 
[epoch 28] step 18/44: loss=-0.5483 
[epoch 28] step 20/44: loss=-0.5501 
[epoch 28] step 22/44: loss=-0.5500 
[epoch 28] step 24/44: loss=-0.5492 
[epoch 28] step 26/44: loss=-0.5499 
[epoch 28] step 28/44: loss=-0.5510 
[epoch 28] step 30/44: loss=-0.5495 
[epoch 28] step 32/44: loss=-0.5493 
[epoch 28] step 34/44: loss=-0.5480 
[epoch 28] step 36/44: loss=-0.5485 
[epoch 28] step 38/44: loss=-0.5496 
[epoch 28] step 40/44: loss=-0.5486 
[epoch 28] step 42/44: loss=-0.5496 
[epoch 28] step 44/44: loss=-0.5510 
[epoch 28] train_loss(avg per step)=-1.1021 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=4.4459 qwk=('0.6666', '0.5999', '0.6304') averageQWK=0.6323 macroEMD=0.2243 tailR0=('0.2022', '0.0417', '0.1000') tailR0avg=0.1146
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    2    0    0
     0   19   34    1    0
     0   23   75   27    0
     0    0   26   87    3
     0    0    3   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     1   20   29    3    0
     0   21   76   24    0
     0    3   33   92    5
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    0    0
     0   30   39    0    0
     0   11  127   13    0
     0    0   44   57    0
     0    0    0    2    0
[epoch 29] step 2/44: loss=-0.5526 
[epoch 29] step 4/44: loss=-0.5353 
[epoch 29] step 6/44: loss=-0.5412 
[epoch 29] step 8/44: loss=-0.5522 
[epoch 29] step 10/44: loss=-0.5576 
[epoch 29] step 12/44: loss=-0.5598 
[epoch 29] step 14/44: loss=-0.5630 
[epoch 29] step 16/44: loss=-0.5624 
[epoch 29] step 18/44: loss=-0.5606 
[epoch 29] step 20/44: loss=-0.5638 
[epoch 29] step 22/44: loss=-0.5636 
[epoch 29] step 24/44: loss=-0.5606 
[epoch 29] step 26/44: loss=-0.5609 
[epoch 29] step 28/44: loss=-0.5607 
[epoch 29] step 30/44: loss=-0.5617 
[epoch 29] step 32/44: loss=-0.5617 
[epoch 29] step 34/44: loss=-0.5616 
[epoch 29] step 36/44: loss=-0.5615 
[epoch 29] step 38/44: loss=-0.5624 
[epoch 29] step 40/44: loss=-0.5628 
[epoch 29] step 42/44: loss=-0.5628 
[epoch 29] step 44/44: loss=-0.5642 
[epoch 29] train_loss(avg per step)=-1.1284 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=4.5127 qwk=('0.6502', '0.6120', '0.5938') averageQWK=0.6187 macroEMD=0.2274 tailR0=('0.3022', '0.0833', '0.0000') tailR0avg=0.1285
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    5    2    0    0
     1   11   38    4    0
     0   10   75   40    0
     0    0   21   89    6
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   23   23    6    0
     0   21   60   38    2
     0    2   18  106    7
     0    0    0   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   26   42    1    0
     0   11  117   23    0
     0    0   37   64    0
     0    0    0    2    0
[epoch 30] step 2/44: loss=-0.5828 
[epoch 30] step 4/44: loss=-0.5765 
[epoch 30] step 6/44: loss=-0.5754 
[epoch 30] step 8/44: loss=-0.5720 
[epoch 30] step 10/44: loss=-0.5723 
[epoch 30] step 12/44: loss=-0.5720 
[epoch 30] step 14/44: loss=-0.5724 
[epoch 30] step 16/44: loss=-0.5721 
[epoch 30] step 18/44: loss=-0.5716 
[epoch 30] step 20/44: loss=-0.5726 
[epoch 30] step 22/44: loss=-0.5737 
[epoch 30] step 24/44: loss=-0.5728 
[epoch 30] step 26/44: loss=-0.5726 
[epoch 30] step 28/44: loss=-0.5705 
[epoch 30] step 30/44: loss=-0.5697 
[epoch 30] step 32/44: loss=-0.5689 
[epoch 30] step 34/44: loss=-0.5694 
[epoch 30] step 36/44: loss=-0.5699 
[epoch 30] step 38/44: loss=-0.5696 
[epoch 30] step 40/44: loss=-0.5706 
[epoch 30] step 42/44: loss=-0.5712 
[epoch 30] step 44/44: loss=-0.5709 
[epoch 30] train_loss(avg per step)=-1.1418 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=4.4718 qwk=('0.6634', '0.6251', '0.6187') averageQWK=0.6358 macroEMD=0.2199 tailR0=('0.2522', '0.1250', '0.2000') tailR0avg=0.1924
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    2    0    0
     0   19   33    2    0
     1   16   74   34    0
     0    0   25   86    5
     0    0    2   14    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     1   22   26    4    0
     0   22   69   29    1
     0    2   27   97    7
     0    0    2    7    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    1    0    0
     0   36   30    3    0
     0   19  108   24    0
     0    1   37   62    1
     0    0    0    2    0
[epoch 31] step 2/44: loss=-0.5748 
[epoch 31] step 4/44: loss=-0.5847 
[epoch 31] step 6/44: loss=-0.5873 
[epoch 31] step 8/44: loss=-0.5828 
[epoch 31] step 10/44: loss=-0.5814 
[epoch 31] step 12/44: loss=-0.5834 
[epoch 31] step 14/44: loss=-0.5824 
[epoch 31] step 16/44: loss=-0.5842 
[epoch 31] step 18/44: loss=-0.5832 
[epoch 31] step 20/44: loss=-0.5814 
[epoch 31] step 22/44: loss=-0.5780 
[epoch 31] step 24/44: loss=-0.5779 
[epoch 31] step 26/44: loss=-0.5787 
[epoch 31] step 28/44: loss=-0.5796 
[epoch 31] step 30/44: loss=-0.5802 
[epoch 31] step 32/44: loss=-0.5806 
[epoch 31] step 34/44: loss=-0.5797 
[epoch 31] step 36/44: loss=-0.5799 
[epoch 31] step 38/44: loss=-0.5794 
[epoch 31] step 40/44: loss=-0.5795 
[epoch 31] step 42/44: loss=-0.5797 
[epoch 31] step 44/44: loss=-0.5795 
[epoch 31] train_loss(avg per step)=-1.1589 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=4.6293 qwk=('0.6393', '0.6170', '0.5982') averageQWK=0.6182 macroEMD=0.2213 tailR0=('0.1652', '0.0833', '0.1000') tailR0avg=0.1162
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    2    0    0
     0   18   32    4    0
     1   15   67   42    0
     0    0   20   95    1
     0    0    1   19    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   21   28    4    0
     0   20   75   25    1
     0    2   26  100    5
     0    0    2    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    2    0    0
     1   35   33    0    0
     0   18  116   17    0
     1    1   40   58    1
     0    0    1    1    0
[epoch 32] step 2/44: loss=-0.5846 
[epoch 32] step 4/44: loss=-0.5876 
[epoch 32] step 6/44: loss=-0.5867 
[epoch 32] step 8/44: loss=-0.5831 
[epoch 32] step 10/44: loss=-0.5779 
[epoch 32] step 12/44: loss=-0.5781 
[epoch 32] step 14/44: loss=-0.5783 
[epoch 32] step 16/44: loss=-0.5798 
[epoch 32] step 18/44: loss=-0.5804 
[epoch 32] step 20/44: loss=-0.5813 
[epoch 32] step 22/44: loss=-0.5818 
[epoch 32] step 24/44: loss=-0.5798 
[epoch 32] step 26/44: loss=-0.5802 
[epoch 32] step 28/44: loss=-0.5805 
[epoch 32] step 30/44: loss=-0.5806 
[epoch 32] step 32/44: loss=-0.5815 
[epoch 32] step 34/44: loss=-0.5812 
[epoch 32] step 36/44: loss=-0.5812 
[epoch 32] step 38/44: loss=-0.5817 
[epoch 32] step 40/44: loss=-0.5815 
[epoch 32] step 42/44: loss=-0.5806 
[epoch 32] step 44/44: loss=-0.5803 
[epoch 32] train_loss(avg per step)=-1.1607 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=4.7666 qwk=('0.6885', '0.6039', '0.5715') averageQWK=0.6213 macroEMD=0.2218 tailR0=('0.1522', '0.0417', '0.0000') tailR0avg=0.0646
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    1    0    0
     0   24   29    1    0
     0   27   66   32    0
     0    0   24   86    6
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   19   30    4    0
     0   16   75   29    1
     0    1   25  102    5
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     1   28   39    1    0
     0   13  123   15    0
     1    0   41   58    1
     0    0    1    1    0
[epoch 33] step 2/44: loss=-0.5871 
[epoch 33] step 4/44: loss=-0.5861 
[epoch 33] step 6/44: loss=-0.5885 
[epoch 33] step 8/44: loss=-0.5897 
[epoch 33] step 10/44: loss=-0.5901 
[epoch 33] step 12/44: loss=-0.5901 
[epoch 33] step 14/44: loss=-0.5906 
[epoch 33] step 16/44: loss=-0.5912 
[epoch 33] step 18/44: loss=-0.5890 
[epoch 33] step 20/44: loss=-0.5878 
[epoch 33] step 22/44: loss=-0.5887 
[epoch 33] step 24/44: loss=-0.5891 
[epoch 33] step 26/44: loss=-0.5875 
[epoch 33] step 28/44: loss=-0.5864 
[epoch 33] step 30/44: loss=-0.5862 
[epoch 33] step 32/44: loss=-0.5862 
[epoch 33] step 34/44: loss=-0.5870 
[epoch 33] step 36/44: loss=-0.5866 
[epoch 33] step 38/44: loss=-0.5869 
[epoch 33] step 40/44: loss=-0.5873 
[epoch 33] step 42/44: loss=-0.5870 
[epoch 33] step 44/44: loss=-0.5872 
[epoch 33] train_loss(avg per step)=-1.1744 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=4.7557 qwk=('0.6681', '0.6048', '0.6171') averageQWK=0.6300 macroEMD=0.2223 tailR0=('0.2304', '0.0417', '0.0000') tailR0avg=0.0907
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    2    0    0
     0   16   37    1    0
     0   14   73   38    0
     0    0   23   90    3
     0    0    1   16    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   14   35    3    0
     0   16   75   29    1
     0    0   25  103    5
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   35   34    0    0
     0   17  119   15    0
     0    2   39   59    1
     0    0    0    2    0
[epoch 34] step 2/44: loss=-0.5698 
[epoch 34] step 4/44: loss=-0.5763 
[epoch 34] step 6/44: loss=-0.5813 
[epoch 34] step 8/44: loss=-0.5819 
[epoch 34] step 10/44: loss=-0.5814 
[epoch 34] step 12/44: loss=-0.5840 
[epoch 34] step 14/44: loss=-0.5822 
[epoch 34] step 16/44: loss=-0.5827 
[epoch 34] step 18/44: loss=-0.5841 
[epoch 34] step 20/44: loss=-0.5851 
[epoch 34] step 22/44: loss=-0.5864 
[epoch 34] step 24/44: loss=-0.5871 
[epoch 34] step 26/44: loss=-0.5880 
[epoch 34] step 28/44: loss=-0.5879 
[epoch 34] step 30/44: loss=-0.5876 
[epoch 34] step 32/44: loss=-0.5882 
[epoch 34] step 34/44: loss=-0.5889 
[epoch 34] step 36/44: loss=-0.5889 
[epoch 34] step 38/44: loss=-0.5894 
[epoch 34] step 40/44: loss=-0.5897 
[epoch 34] step 42/44: loss=-0.5896 
[epoch 34] step 44/44: loss=-0.5895 
[epoch 34] train_loss(avg per step)=-1.1789 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=4.7216 qwk=('0.6744', '0.5954', '0.6075') averageQWK=0.6258 macroEMD=0.2214 tailR0=('0.2022', '0.0417', '0.0000') tailR0avg=0.0813
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    2    0    0
     0   18   35    1    0
     0   14   74   37    0
     0    0   23   87    6
     0    0    1   15    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   15   33    4    0
     0   17   74   29    1
     0    1   24  102    6
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   33   35    1    0
     0   15  115   21    0
     0    2   35   63    1
     0    0    0    2    0
[epoch 35] step 2/44: loss=-0.5934 
[epoch 35] step 4/44: loss=-0.5861 
[epoch 35] step 6/44: loss=-0.5884 
[epoch 35] step 8/44: loss=-0.5892 
[epoch 35] step 10/44: loss=-0.5915 
[epoch 35] step 12/44: loss=-0.5917 
[epoch 35] step 14/44: loss=-0.5915 
[epoch 35] step 16/44: loss=-0.5914 
[epoch 35] step 18/44: loss=-0.5920 
[epoch 35] step 20/44: loss=-0.5923 
[epoch 35] step 22/44: loss=-0.5926 
[epoch 35] step 24/44: loss=-0.5928 
[epoch 35] step 26/44: loss=-0.5929 
[epoch 35] step 28/44: loss=-0.5927 
[epoch 35] step 30/44: loss=-0.5907 
[epoch 35] step 32/44: loss=-0.5899 
[epoch 35] step 34/44: loss=-0.5896 
[epoch 35] step 36/44: loss=-0.5899 
[epoch 35] step 38/44: loss=-0.5896 
[epoch 35] step 40/44: loss=-0.5895 
[epoch 35] step 42/44: loss=-0.5896 
[epoch 35] step 44/44: loss=-0.5901 
[epoch 35] train_loss(avg per step)=-1.1802 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=4.7439 qwk=('0.6706', '0.6030', '0.6093') averageQWK=0.6276 macroEMD=0.2208 tailR0=('0.1804', '0.0417', '0.0000') tailR0avg=0.0740
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    2    0    0
     0   18   35    1    0
     0   15   78   32    0
     0    0   24   89    3
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   18   30    4    0
     0   18   73   29    1
     0    1   25  102    5
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   34   35    0    0
     0   19  111   21    0
     0    2   36   62    1
     0    0    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-0-conf_gating-0-reassignment-0/fold2/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-0-conf_gating-0-reassignment-0/fold2/metrics.json
Done.
