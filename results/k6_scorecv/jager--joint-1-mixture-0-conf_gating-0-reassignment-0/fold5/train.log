[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.7439 
[epoch 1] step 4/44: loss=6.4222 
[epoch 1] step 6/44: loss=6.0987 
[epoch 1] step 8/44: loss=6.1795 
[epoch 1] step 10/44: loss=6.1816 
[epoch 1] step 12/44: loss=6.1958 
[epoch 1] step 14/44: loss=6.1957 
[epoch 1] step 16/44: loss=6.2457 
[epoch 1] step 18/44: loss=6.2143 
[epoch 1] step 20/44: loss=6.2352 
[epoch 1] step 22/44: loss=6.1983 
[epoch 1] step 24/44: loss=6.2146 
[epoch 1] step 26/44: loss=6.2076 
[epoch 1] step 28/44: loss=6.1849 
[epoch 1] step 30/44: loss=6.1701 
[epoch 1] step 32/44: loss=6.1480 
[epoch 1] step 34/44: loss=6.1476 
[epoch 1] step 36/44: loss=6.0766 
[epoch 1] step 38/44: loss=6.0008 
[epoch 1] step 40/44: loss=5.9094 
[epoch 1] step 42/44: loss=5.8517 
[epoch 1] step 44/44: loss=5.7704 
[epoch 1] train_loss(avg per step)=11.5407 lambda[min,max]=[0.514942,1.000000]
[epoch 1] val_loss=6.2613 qwk=('0.1799', '0.2337', '0.0123') averageQWK=0.1420 macroEMD=0.3688 tailR0=('0.0000', '0.2778', '0.0000') tailR0avg=0.0926
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    4    0
     0   21    0   34    0
     0   37    0   88    0
     0   29    0   87    0
     0    2    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     5    0    4    0    0
    18    0   32    3    0
    32    0   74   16    0
    22    0   69   42    0
     0    0    9    3    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    2   67    0    0
     0    0  152    0    0
     0    1  100    0    0
     0    0    2    0    0
[epoch 2] step 2/44: loss=3.5957 
[epoch 2] step 4/44: loss=3.6421 
[epoch 2] step 6/44: loss=3.5915 
[epoch 2] step 8/44: loss=3.5580 
[epoch 2] step 10/44: loss=3.4218 
[epoch 2] step 12/44: loss=3.4327 
[epoch 2] step 14/44: loss=3.3759 
[epoch 2] step 16/44: loss=3.3698 
[epoch 2] step 18/44: loss=3.3350 
[epoch 2] step 20/44: loss=3.2415 
[epoch 2] step 22/44: loss=3.1431 
[epoch 2] step 24/44: loss=3.0675 
[epoch 2] step 26/44: loss=2.9700 
[epoch 2] step 28/44: loss=2.9183 
[epoch 2] step 30/44: loss=2.8696 
[epoch 2] step 32/44: loss=2.8258 
[epoch 2] step 34/44: loss=2.7922 
[epoch 2] step 36/44: loss=2.7655 
[epoch 2] step 38/44: loss=2.7249 
[epoch 2] step 40/44: loss=2.7003 
[epoch 2] step 42/44: loss=2.6732 
[epoch 2] step 44/44: loss=2.6549 
[epoch 2] train_loss(avg per step)=5.3098 lambda[min,max]=[0.510295,1.000000]
[epoch 2] val_loss=3.3049 qwk=('0.3612', '0.1679', '0.2285') averageQWK=0.2525 macroEMD=0.3799 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    3    0
     0   27   10   18    0
     0   20   27   78    0
     0    9    5  102    0
     0    3    2   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    4    0
     0    0   15   38    0
     0    0   16  106    0
     0    0    0  133    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0    2   32   35    0
     0    0   40  112    0
     0    0    4   97    0
     0    0    0    2    0
[epoch 3] step 2/44: loss=1.9186 
[epoch 3] step 4/44: loss=1.8748 
[epoch 3] step 6/44: loss=1.9153 
[epoch 3] step 8/44: loss=1.8702 
[epoch 3] step 10/44: loss=1.9451 
[epoch 3] step 12/44: loss=1.9310 
[epoch 3] step 14/44: loss=1.9285 
[epoch 3] step 16/44: loss=1.9294 
[epoch 3] step 18/44: loss=1.9288 
[epoch 3] step 20/44: loss=1.9163 
[epoch 3] step 22/44: loss=1.9055 
[epoch 3] step 24/44: loss=1.9215 
[epoch 3] step 26/44: loss=1.9164 
[epoch 3] step 28/44: loss=1.9041 
[epoch 3] step 30/44: loss=1.9195 
[epoch 3] step 32/44: loss=1.9266 
[epoch 3] step 34/44: loss=1.9116 
[epoch 3] step 36/44: loss=1.9001 
[epoch 3] step 38/44: loss=1.8828 
[epoch 3] step 40/44: loss=1.8725 
[epoch 3] step 42/44: loss=1.8487 
[epoch 3] step 44/44: loss=1.8572 
[epoch 3] train_loss(avg per step)=3.7144 lambda[min,max]=[0.500164,1.000000]
[epoch 3] val_loss=2.5021 qwk=('0.5117', '0.3740', '0.5025') averageQWK=0.4628 macroEMD=0.3566 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     0    7   44    4    0
     0    5   81   39    0
     0    0   21   95    0
     0    0    5   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    0    0
     0    0   52    1    0
     0    0  110   12    0
     0    0   67   66    0
     0    0    4    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   12   56    1    0
     0    6  112   34    0
     0    0   34   67    0
     0    0    0    2    0
[epoch 4] step 2/44: loss=2.1447 
[epoch 4] step 4/44: loss=1.7581 
[epoch 4] step 6/44: loss=1.7583 
[epoch 4] step 8/44: loss=1.6789 
[epoch 4] step 10/44: loss=1.6471 
[epoch 4] step 12/44: loss=1.6153 
[epoch 4] step 14/44: loss=1.6001 
[epoch 4] step 16/44: loss=1.6007 
[epoch 4] step 18/44: loss=1.5698 
[epoch 4] step 20/44: loss=1.5751 
[epoch 4] step 22/44: loss=1.5574 
[epoch 4] step 24/44: loss=1.5487 
[epoch 4] step 26/44: loss=1.5572 
[epoch 4] step 28/44: loss=1.5425 
[epoch 4] step 30/44: loss=1.5680 
[epoch 4] step 32/44: loss=1.5949 
[epoch 4] step 34/44: loss=1.5830 
[epoch 4] step 36/44: loss=1.5744 
[epoch 4] step 38/44: loss=1.5873 
[epoch 4] step 40/44: loss=1.5851 
[epoch 4] step 42/44: loss=1.5782 
[epoch 4] step 44/44: loss=1.5626 
[epoch 4] train_loss(avg per step)=3.1252 lambda[min,max]=[0.504300,1.000000]
[epoch 4] val_loss=2.8752 qwk=('0.4593', '0.4770', '0.4721') averageQWK=0.4694 macroEMD=0.3440 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    2    0
     0   10   30   15    0
     0    7   47   71    0
     0    0    8  108    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0    4   37   12    0
     0    2   66   54    0
     0    0   10  123    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   25   19    0
     0   12   50   90    0
     0    0    5   96    0
     0    0    0    2    0
[epoch 5] step 2/44: loss=1.4291 
[epoch 5] step 4/44: loss=1.2528 
[epoch 5] step 6/44: loss=1.2826 
[epoch 5] step 8/44: loss=1.2515 
[epoch 5] step 10/44: loss=1.2339 
[epoch 5] step 12/44: loss=1.3043 
[epoch 5] step 14/44: loss=1.3085 
[epoch 5] step 16/44: loss=1.2951 
[epoch 5] step 18/44: loss=1.3254 
[epoch 5] step 20/44: loss=1.3226 
[epoch 5] step 22/44: loss=1.3154 
[epoch 5] step 24/44: loss=1.3030 
[epoch 5] step 26/44: loss=1.2966 
[epoch 5] step 28/44: loss=1.2699 
[epoch 5] step 30/44: loss=1.2682 
[epoch 5] step 32/44: loss=1.2749 
[epoch 5] step 34/44: loss=1.2862 
[epoch 5] step 36/44: loss=1.2813 
[epoch 5] step 38/44: loss=1.2858 
[epoch 5] step 40/44: loss=1.2675 
[epoch 5] step 42/44: loss=1.2708 
[epoch 5] step 44/44: loss=1.2633 
[epoch 5] train_loss(avg per step)=2.5266 lambda[min,max]=[0.504367,1.000000]
[epoch 5] val_loss=2.7644 qwk=('0.4412', '0.4434', '0.4316') averageQWK=0.4387 macroEMD=0.3356 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     0    7   31   17    0
     0    5   43   77    0
     0    0    6  110    0
     0    0    0   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     1    9   23   20    0
     0    7   39   76    0
     0    0    5  128    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    2   63    4    0
     0    0  101   51    0
     0    0   23   78    0
     0    0    1    1    0
[epoch 6] step 2/44: loss=1.1104 
[epoch 6] step 4/44: loss=1.2154 
[epoch 6] step 6/44: loss=1.2984 
[epoch 6] step 8/44: loss=1.3439 
[epoch 6] step 10/44: loss=1.3393 
[epoch 6] step 12/44: loss=1.3325 
[epoch 6] step 14/44: loss=1.3188 
[epoch 6] step 16/44: loss=1.2682 
[epoch 6] step 18/44: loss=1.2514 
[epoch 6] step 20/44: loss=1.2607 
[epoch 6] step 22/44: loss=1.2617 
[epoch 6] step 24/44: loss=1.2442 
[epoch 6] step 26/44: loss=1.2375 
[epoch 6] step 28/44: loss=1.2108 
[epoch 6] step 30/44: loss=1.2048 
[epoch 6] step 32/44: loss=1.1842 
[epoch 6] step 34/44: loss=1.1740 
[epoch 6] step 36/44: loss=1.1691 
[epoch 6] step 38/44: loss=1.1581 
[epoch 6] step 40/44: loss=1.1515 
[epoch 6] step 42/44: loss=1.1486 
[epoch 6] step 44/44: loss=1.1324 
[epoch 6] train_loss(avg per step)=2.2647 lambda[min,max]=[0.503528,1.000000]
[epoch 6] val_loss=2.3014 qwk=('0.4924', '0.5551', '0.5108') averageQWK=0.5194 macroEMD=0.3207 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0    2   47    6    0
     0    3   71   51    0
     0    0   13  103    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0    7   39    7    0
     0    2   81   39    0
     0    0   18  115    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   14   55    0    0
     0    5  121   26    0
     0    0   40   61    0
     0    0    1    1    0
[epoch 7] step 2/44: loss=0.7131 
[epoch 7] step 4/44: loss=0.7980 
[epoch 7] step 6/44: loss=0.8163 
[epoch 7] step 8/44: loss=0.8123 
[epoch 7] step 10/44: loss=0.8489 
[epoch 7] step 12/44: loss=0.8735 
[epoch 7] step 14/44: loss=0.9199 
[epoch 7] step 16/44: loss=0.9302 
[epoch 7] step 18/44: loss=0.9531 
[epoch 7] step 20/44: loss=0.9578 
[epoch 7] step 22/44: loss=0.9677 
[epoch 7] step 24/44: loss=0.9610 
[epoch 7] step 26/44: loss=0.9659 
[epoch 7] step 28/44: loss=0.9617 
[epoch 7] step 30/44: loss=0.9707 
[epoch 7] step 32/44: loss=0.9664 
[epoch 7] step 34/44: loss=0.9533 
[epoch 7] step 36/44: loss=0.9397 
[epoch 7] step 38/44: loss=0.9470 
[epoch 7] step 40/44: loss=0.9463 
[epoch 7] step 42/44: loss=0.9536 
[epoch 7] step 44/44: loss=0.9420 
[epoch 7] train_loss(avg per step)=1.8841 lambda[min,max]=[0.507235,1.000000]
[epoch 7] val_loss=2.3084 qwk=('0.6234', '0.5856', '0.5211') averageQWK=0.5767 macroEMD=0.3088 tailR0=('0.2174', '0.0417', '0.0000') tailR0avg=0.0864
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   14   36    5    0
     0    9   73   42    1
     0    0   16   86   14
     0    0    0   13   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   15   30    8    0
     0   10   71   41    0
     0    0   18  115    0
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   18   48    3    0
     0   12   86   54    0
     0    0   25   76    0
     0    0    0    2    0
[epoch 8] step 2/44: loss=0.7053 
[epoch 8] step 4/44: loss=0.7240 
[epoch 8] step 6/44: loss=0.7430 
[epoch 8] step 8/44: loss=0.7087 
[epoch 8] step 10/44: loss=0.7178 
[epoch 8] step 12/44: loss=0.7436 
[epoch 8] step 14/44: loss=0.7448 
[epoch 8] step 16/44: loss=0.7751 
[epoch 8] step 18/44: loss=0.7910 
[epoch 8] step 20/44: loss=0.7708 
[epoch 8] step 22/44: loss=0.7665 
[epoch 8] step 24/44: loss=0.7695 
[epoch 8] step 26/44: loss=0.7750 
[epoch 8] step 28/44: loss=0.7591 
[epoch 8] step 30/44: loss=0.7642 
[epoch 8] step 32/44: loss=0.7569 
[epoch 8] step 34/44: loss=0.7529 
[epoch 8] step 36/44: loss=0.7558 
[epoch 8] step 38/44: loss=0.7519 
[epoch 8] step 40/44: loss=0.7649 
[epoch 8] step 42/44: loss=0.7830 
[epoch 8] step 44/44: loss=0.7799 
[epoch 8] train_loss(avg per step)=1.5599 lambda[min,max]=[0.501290,1.000000]
[epoch 8] val_loss=2.1897 qwk=('0.5728', '0.6250', '0.5091') averageQWK=0.5690 macroEMD=0.3038 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0    8   43    4    0
     0    5   83   37    0
     0    0   17   99    0
     0    0    1   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   25   20    8    0
     0   16   62   44    0
     0    1   14  118    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   15   51    3    0
     0    3  106   43    0
     0    0   27   74    0
     0    0    1    1    0
[epoch 9] step 2/44: loss=0.6816 
[epoch 9] step 4/44: loss=0.6939 
[epoch 9] step 6/44: loss=0.7191 
[epoch 9] step 8/44: loss=0.7805 
[epoch 9] step 10/44: loss=0.7357 
[epoch 9] step 12/44: loss=0.7137 
[epoch 9] step 14/44: loss=0.7153 
[epoch 9] step 16/44: loss=0.7161 
[epoch 9] step 18/44: loss=0.7084 
[epoch 9] step 20/44: loss=0.6826 
[epoch 9] step 22/44: loss=0.6823 
[epoch 9] step 24/44: loss=0.6896 
[epoch 9] step 26/44: loss=0.6851 
[epoch 9] step 28/44: loss=0.6769 
[epoch 9] step 30/44: loss=0.6654 
[epoch 9] step 32/44: loss=0.6603 
[epoch 9] step 34/44: loss=0.6586 
[epoch 9] step 36/44: loss=0.6564 
[epoch 9] step 38/44: loss=0.6534 
[epoch 9] step 40/44: loss=0.6574 
[epoch 9] step 42/44: loss=0.6506 
[epoch 9] step 44/44: loss=0.6482 
[epoch 9] train_loss(avg per step)=1.2963 lambda[min,max]=[0.503470,1.000000]
[epoch 9] val_loss=2.2454 qwk=('0.5442', '0.6275', '0.5167') averageQWK=0.5628 macroEMD=0.2978 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   14   39    2    0
     0    9   91   25    0
     0    1   36   78    1
     0    0    5   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    1    0
     0   32   14    7    0
     0   23   52   47    0
     0    2   14  117    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   26   43    0    0
     0   18  112   22    0
     0    1   52   48    0
     0    0    1    1    0
[epoch 10] step 2/44: loss=0.5190 
[epoch 10] step 4/44: loss=0.5163 
[epoch 10] step 6/44: loss=0.5119 
[epoch 10] step 8/44: loss=0.5071 
[epoch 10] step 10/44: loss=0.5374 
[epoch 10] step 12/44: loss=0.5223 
[epoch 10] step 14/44: loss=0.4952 
[epoch 10] step 16/44: loss=0.5135 
[epoch 10] step 18/44: loss=0.5500 
[epoch 10] step 20/44: loss=0.5433 
[epoch 10] step 22/44: loss=0.5375 
[epoch 10] step 24/44: loss=0.5371 
[epoch 10] step 26/44: loss=0.5446 
[epoch 10] step 28/44: loss=0.5606 
[epoch 10] step 30/44: loss=0.5696 
[epoch 10] step 32/44: loss=0.5741 
[epoch 10] step 34/44: loss=0.5664 
[epoch 10] step 36/44: loss=0.5568 
[epoch 10] step 38/44: loss=0.5596 
[epoch 10] step 40/44: loss=0.5601 
[epoch 10] step 42/44: loss=0.5536 
[epoch 10] step 44/44: loss=0.5521 
[epoch 10] train_loss(avg per step)=1.1041 lambda[min,max]=[0.500847,1.000000]
[epoch 10] val_loss=2.4076 qwk=('0.5812', '0.6100', '0.5468') averageQWK=0.5793 macroEMD=0.2888 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0    9   45    1    0
     0    5   96   24    0
     0    0   35   73    8
     0    0    4   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     1   17   28    7    0
     2    9   63   48    0
     0    0   13  120    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   17   49    3    0
     0    9   88   55    0
     0    0   18   83    0
     0    0    0    2    0
[epoch 11] step 2/44: loss=0.3372 
[epoch 11] step 4/44: loss=0.3676 
[epoch 11] step 6/44: loss=0.3645 
[epoch 11] step 8/44: loss=0.3792 
[epoch 11] step 10/44: loss=0.3775 
[epoch 11] step 12/44: loss=0.3645 
[epoch 11] step 14/44: loss=0.3677 
[epoch 11] step 16/44: loss=0.3629 
[epoch 11] step 18/44: loss=0.3509 
[epoch 11] step 20/44: loss=0.3590 
[epoch 11] step 22/44: loss=0.3657 
[epoch 11] step 24/44: loss=0.3775 
[epoch 11] step 26/44: loss=0.3798 
[epoch 11] step 28/44: loss=0.3969 
[epoch 11] step 30/44: loss=0.3940 
[epoch 11] step 32/44: loss=0.3840 
[epoch 11] step 34/44: loss=0.3821 
[epoch 11] step 36/44: loss=0.3859 
[epoch 11] step 38/44: loss=0.3900 
[epoch 11] step 40/44: loss=0.3809 
[epoch 11] step 42/44: loss=0.3777 
[epoch 11] step 44/44: loss=0.3839 
[epoch 11] train_loss(avg per step)=0.7678 lambda[min,max]=[0.501009,1.000000]
[epoch 11] val_loss=2.1659 qwk=('0.6209', '0.6574', '0.6141') averageQWK=0.6308 macroEMD=0.2787 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   24   29    2    0
     0   21   80   24    0
     0    1   29   86    0
     0    0    4   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     1   31   16    5    0
     1   23   68   30    0
     0    1   28  104    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   47   22    0    0
     0   37   80   35    0
     0    3   34   64    0
     0    0    1    1    0
[epoch 12] step 2/44: loss=0.2700 
[epoch 12] step 4/44: loss=0.2453 
[epoch 12] step 6/44: loss=0.2812 
[epoch 12] step 8/44: loss=0.2694 
[epoch 12] step 10/44: loss=0.2753 
[epoch 12] step 12/44: loss=0.2860 
[epoch 12] step 14/44: loss=0.2663 
[epoch 12] step 16/44: loss=0.2639 
[epoch 12] step 18/44: loss=0.2775 
[epoch 12] step 20/44: loss=0.2805 
[epoch 12] step 22/44: loss=0.2731 
[epoch 12] step 24/44: loss=0.2794 
[epoch 12] step 26/44: loss=0.2721 
[epoch 12] step 28/44: loss=0.2705 
[epoch 12] step 30/44: loss=0.2634 
[epoch 12] step 32/44: loss=0.2630 
[epoch 12] step 34/44: loss=0.2657 
[epoch 12] step 36/44: loss=0.2599 
[epoch 12] step 38/44: loss=0.2616 
[epoch 12] step 40/44: loss=0.2588 
[epoch 12] step 42/44: loss=0.2598 
[epoch 12] step 44/44: loss=0.2718 
[epoch 12] train_loss(avg per step)=0.5435 lambda[min,max]=[0.500187,1.000000]
[epoch 12] val_loss=2.3389 qwk=('0.6148', '0.6213', '0.5289') averageQWK=0.5883 macroEMD=0.2742 tailR0=('0.1522', '0.0417', '0.0000') tailR0avg=0.0646
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   19   34    2    0
     0   13   86   24    2
     0    0   34   72   10
     0    0    5   11    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     2   22   25    4    0
     2   14   73   31    2
     0    1   31   98    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   24   45    0    0
     0    9  120   23    0
     0    1   47   53    0
     0    0    1    1    0
[epoch 13] step 2/44: loss=0.1360 
[epoch 13] step 4/44: loss=0.1470 
[epoch 13] step 6/44: loss=0.1528 
[epoch 13] step 8/44: loss=0.1487 
[epoch 13] step 10/44: loss=0.1322 
[epoch 13] step 12/44: loss=0.1155 
[epoch 13] step 14/44: loss=0.1206 
[epoch 13] step 16/44: loss=0.1348 
[epoch 13] step 18/44: loss=0.1359 
[epoch 13] step 20/44: loss=0.1470 
[epoch 13] step 22/44: loss=0.1361 
[epoch 13] step 24/44: loss=0.1340 
[epoch 13] step 26/44: loss=0.1301 
[epoch 13] step 28/44: loss=0.1320 
[epoch 13] step 30/44: loss=0.1185 
[epoch 13] step 32/44: loss=0.1132 
[epoch 13] step 34/44: loss=0.1191 
[epoch 13] step 36/44: loss=0.1246 
[epoch 13] step 38/44: loss=0.1256 
[epoch 13] step 40/44: loss=0.1270 
[epoch 13] step 42/44: loss=0.1358 
[epoch 13] step 44/44: loss=0.1431 
[epoch 13] train_loss(avg per step)=0.2861 lambda[min,max]=[0.500211,1.000000]
[epoch 13] val_loss=2.8072 qwk=('0.6270', '0.5699', '0.5159') averageQWK=0.5710 macroEMD=0.2764 tailR0=('0.2609', '0.1667', '0.0000') tailR0avg=0.1425
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   17   32    6    0
     0   10   68   44    3
     0    0   13   89   14
     0    0    1   10   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     1   18   26    8    0
     2    9   59   48    4
     0    1   16  103   13
     0    0    1    7    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   15   48    6    0
     0    9   75   68    0
     0    0   15   86    0
     0    0    0    2    0
[epoch 14] step 2/44: loss=0.1629 
[epoch 14] step 4/44: loss=0.1743 
[epoch 14] step 6/44: loss=0.1543 
[epoch 14] step 8/44: loss=0.1334 
[epoch 14] step 10/44: loss=0.1149 
[epoch 14] step 12/44: loss=0.0961 
[epoch 14] step 14/44: loss=0.0851 
[epoch 14] step 16/44: loss=0.0714 
[epoch 14] step 18/44: loss=0.0594 
[epoch 14] step 20/44: loss=0.0575 
[epoch 14] step 22/44: loss=0.0451 
[epoch 14] step 24/44: loss=0.0308 
[epoch 14] step 26/44: loss=0.0362 
[epoch 14] step 28/44: loss=0.0321 
[epoch 14] step 30/44: loss=0.0262 
[epoch 14] step 32/44: loss=0.0266 
[epoch 14] step 34/44: loss=0.0303 
[epoch 14] step 36/44: loss=0.0360 
[epoch 14] step 38/44: loss=0.0382 
[epoch 14] step 40/44: loss=0.0365 
[epoch 14] step 42/44: loss=0.0332 
[epoch 14] step 44/44: loss=0.0256 
[epoch 14] train_loss(avg per step)=0.0512 lambda[min,max]=[0.500142,1.000000]
[epoch 14] val_loss=2.4949 qwk=('0.5871', '0.6473', '0.5755') averageQWK=0.6033 macroEMD=0.2643 tailR0=('0.0652', '0.0000', '0.0000') tailR0avg=0.0217
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    2    0    0
     1   27   27    0    0
     0   19   90   16    0
     0    1   53   55    7
     0    0    9   11    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    0    0
     1   31   15    6    0
     2   20   75   25    0
     0    3   32   97    1
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   35   34    0    0
     0   20  115   17    0
     0    1   50   50    0
     0    0    2    0    0
[epoch 15] step 2/44: loss=0.0419 
[epoch 15] step 4/44: loss=0.0369 
[epoch 15] step 6/44: loss=0.0090 
[epoch 15] step 8/44: loss=-0.0192 
[epoch 15] step 10/44: loss=0.0036 
[epoch 15] step 12/44: loss=0.0043 
[epoch 15] step 14/44: loss=-0.0202 
[epoch 15] step 16/44: loss=-0.0094 
[epoch 15] step 18/44: loss=0.0202 
[epoch 15] step 20/44: loss=0.0293 
[epoch 15] step 22/44: loss=0.0244 
[epoch 15] step 24/44: loss=0.0275 
[epoch 15] step 26/44: loss=0.0361 
[epoch 15] step 28/44: loss=0.0344 
[epoch 15] step 30/44: loss=0.0261 
[epoch 15] step 32/44: loss=0.0309 
[epoch 15] step 34/44: loss=0.0275 
[epoch 15] step 36/44: loss=0.0284 
[epoch 15] step 38/44: loss=0.0239 
[epoch 15] step 40/44: loss=0.0199 
[epoch 15] step 42/44: loss=0.0166 
[epoch 15] step 44/44: loss=0.0111 
[epoch 15] train_loss(avg per step)=0.0223 lambda[min,max]=[0.500087,1.000000]
[epoch 15] val_loss=2.5774 qwk=('0.6124', '0.5360', '0.5221') averageQWK=0.5568 macroEMD=0.2721 tailR0=('0.0870', '0.0000', '0.0000') tailR0avg=0.0290
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   15   38    2    0
     0    7   85   33    0
     0    0   28   79    9
     0    0    4   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     1   16   33    3    0
     0   10   93   16    3
     0    1   44   82    6
     0    0    4    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   18   51    0    0
     0   11  110   31    0
     0    0   38   63    0
     0    0    1    1    0
[epoch 16] step 2/44: loss=0.0387 
[epoch 16] step 4/44: loss=-0.0372 
[epoch 16] step 6/44: loss=-0.0827 
[epoch 16] step 8/44: loss=-0.0962 
[epoch 16] step 10/44: loss=-0.1084 
[epoch 16] step 12/44: loss=-0.1067 
[epoch 16] step 14/44: loss=-0.1135 
[epoch 16] step 16/44: loss=-0.1292 
[epoch 16] step 18/44: loss=-0.1226 
[epoch 16] step 20/44: loss=-0.1200 
[epoch 16] step 22/44: loss=-0.1184 
[epoch 16] step 24/44: loss=-0.1206 
[epoch 16] step 26/44: loss=-0.1281 
[epoch 16] step 28/44: loss=-0.1323 
[epoch 16] step 30/44: loss=-0.1296 
[epoch 16] step 32/44: loss=-0.1279 
[epoch 16] step 34/44: loss=-0.1310 
[epoch 16] step 36/44: loss=-0.1316 
[epoch 16] step 38/44: loss=-0.1364 
[epoch 16] step 40/44: loss=-0.1328 
[epoch 16] step 42/44: loss=-0.1295 
[epoch 16] step 44/44: loss=-0.1287 
[epoch 16] train_loss(avg per step)=-0.2574 lambda[min,max]=[0.500044,1.000000]
[epoch 16] val_loss=2.8320 qwk=('0.5806', '0.5452', '0.5692') averageQWK=0.5650 macroEMD=0.2685 tailR0=('0.1957', '0.0417', '0.0000') tailR0avg=0.0791
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    1    0
     0   13   38    4    0
     1    4   83   35    2
     0    0   27   77   12
     0    0    3   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0    9   38    6    0
     1    2   85   32    2
     0    0   24  108    1
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   28   41    0    0
     0   18  110   24    0
     0    0   44   57    0
     0    0    1    1    0
[epoch 17] step 2/44: loss=-0.2129 
[epoch 17] step 4/44: loss=-0.2141 
[epoch 17] step 6/44: loss=-0.1864 
[epoch 17] step 8/44: loss=-0.1877 
[epoch 17] step 10/44: loss=-0.1917 
[epoch 17] step 12/44: loss=-0.1826 
[epoch 17] step 14/44: loss=-0.1873 
[epoch 17] step 16/44: loss=-0.1893 
[epoch 17] step 18/44: loss=-0.1942 
[epoch 17] step 20/44: loss=-0.1959 
[epoch 17] step 22/44: loss=-0.2011 
[epoch 17] step 24/44: loss=-0.2087 
[epoch 17] step 26/44: loss=-0.2067 
[epoch 17] step 28/44: loss=-0.2054 
[epoch 17] step 30/44: loss=-0.2062 
[epoch 17] step 32/44: loss=-0.2024 
[epoch 17] step 34/44: loss=-0.1999 
[epoch 17] step 36/44: loss=-0.1982 
[epoch 17] step 38/44: loss=-0.1951 
[epoch 17] step 40/44: loss=-0.1950 
[epoch 17] step 42/44: loss=-0.1953 
[epoch 17] step 44/44: loss=-0.1911 
[epoch 17] train_loss(avg per step)=-0.3822 lambda[min,max]=[0.500016,1.000000]
[epoch 17] val_loss=3.2056 qwk=('0.5859', '0.5721', '0.5807') averageQWK=0.5796 macroEMD=0.2570 tailR0=('0.2174', '0.2222', '0.0000') tailR0avg=0.1465
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    1    0
     0   19   24   12    0
     1    6   60   55    3
     0    0   11   94   11
     0    0    1   12   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   16   27    9    0
     1    7   66   42    6
     0    0   16  109    8
     0    0    0    8    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   25   41    3    0
     0   15   79   58    0
     0    1   14   86    0
     0    0    0    2    0
[epoch 18] step 2/44: loss=-0.1690 
[epoch 18] step 4/44: loss=-0.2102 
[epoch 18] step 6/44: loss=-0.1956 
[epoch 18] step 8/44: loss=-0.2040 
[epoch 18] step 10/44: loss=-0.2336 
[epoch 18] step 12/44: loss=-0.2459 
[epoch 18] step 14/44: loss=-0.2515 
[epoch 18] step 16/44: loss=-0.2583 
[epoch 18] step 18/44: loss=-0.2565 
[epoch 18] step 20/44: loss=-0.2650 
[epoch 18] step 22/44: loss=-0.2646 
[epoch 18] step 24/44: loss=-0.2627 
[epoch 18] step 26/44: loss=-0.2600 
[epoch 18] step 28/44: loss=-0.2607 
[epoch 18] step 30/44: loss=-0.2690 
[epoch 18] step 32/44: loss=-0.2764 
[epoch 18] step 34/44: loss=-0.2753 
[epoch 18] step 36/44: loss=-0.2757 
[epoch 18] step 38/44: loss=-0.2753 
[epoch 18] step 40/44: loss=-0.2670 
[epoch 18] step 42/44: loss=-0.2661 
[epoch 18] step 44/44: loss=-0.2711 
[epoch 18] train_loss(avg per step)=-0.5422 lambda[min,max]=[0.500004,1.000000]
[epoch 18] val_loss=2.7771 qwk=('0.6400', '0.6206', '0.5897') averageQWK=0.6167 macroEMD=0.2528 tailR0=('0.1957', '0.0833', '0.0000') tailR0avg=0.0930
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     1   21   32    1    0
     0   16   79   25    5
     0    0   29   69   18
     0    0    3   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     3   27   18    5    0
     3   19   66   31    3
     0    3   24  102    4
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     1   39   29    0    0
     0   32   90   30    0
     0    3   38   60    0
     0    0    1    1    0
[epoch 19] step 2/44: loss=-0.3188 
[epoch 19] step 4/44: loss=-0.1410 
[epoch 19] step 6/44: loss=-0.2053 
[epoch 19] step 8/44: loss=-0.2146 
[epoch 19] step 10/44: loss=-0.2095 
[epoch 19] step 12/44: loss=-0.2054 
[epoch 19] step 14/44: loss=-0.2166 
[epoch 19] step 16/44: loss=-0.2301 
[epoch 19] step 18/44: loss=-0.2385 
[epoch 19] step 20/44: loss=-0.2435 
[epoch 19] step 22/44: loss=-0.2513 
[epoch 19] step 24/44: loss=-0.2619 
[epoch 19] step 26/44: loss=-0.2675 
[epoch 19] step 28/44: loss=-0.2648 
[epoch 19] step 30/44: loss=-0.2610 
[epoch 19] step 32/44: loss=-0.2676 
[epoch 19] step 34/44: loss=-0.2693 
[epoch 19] step 36/44: loss=-0.2694 
[epoch 19] step 38/44: loss=-0.2727 
[epoch 19] step 40/44: loss=-0.2794 
[epoch 19] step 42/44: loss=-0.2791 
[epoch 19] step 44/44: loss=-0.2767 
[epoch 19] train_loss(avg per step)=-0.5533 lambda[min,max]=[0.500003,1.000000]
[epoch 19] val_loss=3.0084 qwk=('0.6086', '0.5975', '0.5563') averageQWK=0.5875 macroEMD=0.2582 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   21   32    2    0
     0   11   79   35    0
     0    1   25   89    1
     0    0    3   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     1   22   25    5    0
     1   10   78   32    1
     0    1   27  103    2
     0    0    1   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     1   24   44    0    0
     0    8  123   21    0
     0    1   41   59    0
     0    0    1    1    0
[epoch 20] step 2/44: loss=-0.3153 
[epoch 20] step 4/44: loss=-0.3377 
[epoch 20] step 6/44: loss=-0.2932 
[epoch 20] step 8/44: loss=-0.3085 
[epoch 20] step 10/44: loss=-0.3083 
[epoch 20] step 12/44: loss=-0.3165 
[epoch 20] step 14/44: loss=-0.3227 
[epoch 20] step 16/44: loss=-0.3193 
[epoch 20] step 18/44: loss=-0.3174 
[epoch 20] step 20/44: loss=-0.3096 
[epoch 20] step 22/44: loss=-0.3106 
[epoch 20] step 24/44: loss=-0.3169 
[epoch 20] step 26/44: loss=-0.3232 
[epoch 20] step 28/44: loss=-0.3284 
[epoch 20] step 30/44: loss=-0.3306 
[epoch 20] step 32/44: loss=-0.3234 
[epoch 20] step 34/44: loss=-0.3274 
[epoch 20] step 36/44: loss=-0.3281 
[epoch 20] step 38/44: loss=-0.3267 
[epoch 20] step 40/44: loss=-0.3254 
[epoch 20] step 42/44: loss=-0.3215 
[epoch 20] step 44/44: loss=-0.3205 
[epoch 20] train_loss(avg per step)=-0.6409 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=3.2901 qwk=('0.6300', '0.5682', '0.6000') averageQWK=0.5994 macroEMD=0.2491 tailR0=('0.2174', '0.0972', '0.0000') tailR0avg=0.1049
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   22   29    4    0
     1   12   70   36    6
     0    0   17   81   18
     0    0    3   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    0    0
     1   18   27    7    0
     2    9   76   31    4
     0    1   24  103    5
     0    0    2    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   31   36    2    0
     0   21   80   51    0
     0    2   18   80    1
     0    0    0    2    0
[epoch 21] step 2/44: loss=-0.3704 
[epoch 21] step 4/44: loss=-0.3273 
[epoch 21] step 6/44: loss=-0.3244 
[epoch 21] step 8/44: loss=-0.3194 
[epoch 21] step 10/44: loss=-0.3420 
[epoch 21] step 12/44: loss=-0.3388 
[epoch 21] step 14/44: loss=-0.3465 
[epoch 21] step 16/44: loss=-0.3544 
[epoch 21] step 18/44: loss=-0.3554 
[epoch 21] step 20/44: loss=-0.3555 
[epoch 21] step 22/44: loss=-0.3569 
[epoch 21] step 24/44: loss=-0.3422 
[epoch 21] step 26/44: loss=-0.3460 
[epoch 21] step 28/44: loss=-0.3543 
[epoch 21] step 30/44: loss=-0.3616 
[epoch 21] step 32/44: loss=-0.3670 
[epoch 21] step 34/44: loss=-0.3711 
[epoch 21] step 36/44: loss=-0.3715 
[epoch 21] step 38/44: loss=-0.3749 
[epoch 21] step 40/44: loss=-0.3758 
[epoch 21] step 42/44: loss=-0.3736 
[epoch 21] step 44/44: loss=-0.3759 
[epoch 21] train_loss(avg per step)=-0.7517 lambda[min,max]=[0.500001,1.000000]
[epoch 21] val_loss=3.4621 qwk=('0.6095', '0.6041', '0.5644') averageQWK=0.5927 macroEMD=0.2486 tailR0=('0.2457', '0.0972', '0.0000') tailR0avg=0.1143
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    3    0    0
     2   19   32    2    0
     2   11   81   26    5
     0    1   33   69   13
     0    0    4   10    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    3    0    0
     0   22   23    8    0
     1   15   57   47    2
     0    2   11  117    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   26   43    0    0
     0   18   99   35    0
     0    1   35   65    0
     0    0    1    1    0
[epoch 22] step 2/44: loss=-0.4792 
[epoch 22] step 4/44: loss=-0.4316 
[epoch 22] step 6/44: loss=-0.3922 
[epoch 22] step 8/44: loss=-0.4094 
[epoch 22] step 10/44: loss=-0.4088 
[epoch 22] step 12/44: loss=-0.4138 
[epoch 22] step 14/44: loss=-0.4179 
[epoch 22] step 16/44: loss=-0.4126 
[epoch 22] step 18/44: loss=-0.4222 
[epoch 22] step 20/44: loss=-0.4181 
[epoch 22] step 22/44: loss=-0.4131 
[epoch 22] step 24/44: loss=-0.4163 
[epoch 22] step 26/44: loss=-0.4208 
[epoch 22] step 28/44: loss=-0.4206 
[epoch 22] step 30/44: loss=-0.4187 
[epoch 22] step 32/44: loss=-0.4168 
[epoch 22] step 34/44: loss=-0.4076 
[epoch 22] step 36/44: loss=-0.4110 
[epoch 22] step 38/44: loss=-0.4065 
[epoch 22] step 40/44: loss=-0.4064 
[epoch 22] step 42/44: loss=-0.4070 
[epoch 22] step 44/44: loss=-0.4038 
[epoch 22] train_loss(avg per step)=-0.8075 lambda[min,max]=[0.500001,1.000000]
[epoch 22] val_loss=3.6454 qwk=('0.5877', '0.6083', '0.5907') averageQWK=0.5956 macroEMD=0.2498 tailR0=('0.2174', '0.0417', '0.0000') tailR0avg=0.0864
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    1    0
     0   13   36    6    0
     1    6   79   35    4
     0    0   19   80   17
     0    0    3   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   17   30    6    0
     1    8   77   34    2
     0    0   20  108    5
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   23   46    0    0
     0   13   98   41    0
     0    1   24   76    0
     0    0    0    2    0
[epoch 23] step 2/44: loss=-0.4485 
[epoch 23] step 4/44: loss=-0.4379 
[epoch 23] step 6/44: loss=-0.4584 
[epoch 23] step 8/44: loss=-0.4349 
[epoch 23] step 10/44: loss=-0.4292 
[epoch 23] step 12/44: loss=-0.4316 
[epoch 23] step 14/44: loss=-0.4294 
[epoch 23] step 16/44: loss=-0.4348 
[epoch 23] step 18/44: loss=-0.4302 
[epoch 23] step 20/44: loss=-0.4317 
[epoch 23] step 22/44: loss=-0.4343 
[epoch 23] step 24/44: loss=-0.4390 
[epoch 23] step 26/44: loss=-0.4423 
[epoch 23] step 28/44: loss=-0.4444 
[epoch 23] step 30/44: loss=-0.4423 
[epoch 23] step 32/44: loss=-0.4408 
[epoch 23] step 34/44: loss=-0.4432 
[epoch 23] step 36/44: loss=-0.4451 
[epoch 23] step 38/44: loss=-0.4448 
[epoch 23] step 40/44: loss=-0.4449 
[epoch 23] step 42/44: loss=-0.4437 
[epoch 23] step 44/44: loss=-0.4460 
[epoch 23] train_loss(avg per step)=-0.8920 lambda[min,max]=[0.500001,1.000000]
[epoch 23] val_loss=3.7377 qwk=('0.6375', '0.5932', '0.6071') averageQWK=0.6126 macroEMD=0.2469 tailR0=('0.2391', '0.0833', '0.0000') tailR0avg=0.1075
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     1   18   34    2    0
     0   11   75   35    4
     0    0   24   71   21
     0    0    3    9   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   18   29    6    0
     0   11   74   33    4
     0    0   22  106    5
     0    0    1    9    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   27   42    0    0
     0   16   96   40    0
     0    1   26   74    0
     0    0    0    2    0
[epoch 24] step 2/44: loss=-0.4162 
[epoch 24] step 4/44: loss=-0.4280 
[epoch 24] step 6/44: loss=-0.4274 
[epoch 24] step 8/44: loss=-0.4364 
[epoch 24] step 10/44: loss=-0.4477 
[epoch 24] step 12/44: loss=-0.4520 
[epoch 24] step 14/44: loss=-0.4516 
[epoch 24] step 16/44: loss=-0.4603 
[epoch 24] step 18/44: loss=-0.4619 
[epoch 24] step 20/44: loss=-0.4672 
[epoch 24] step 22/44: loss=-0.4704 
[epoch 24] step 24/44: loss=-0.4674 
[epoch 24] step 26/44: loss=-0.4587 
[epoch 24] step 28/44: loss=-0.4568 
[epoch 24] step 30/44: loss=-0.4586 
[epoch 24] step 32/44: loss=-0.4596 
[epoch 24] step 34/44: loss=-0.4597 
[epoch 24] step 36/44: loss=-0.4599 
[epoch 24] step 38/44: loss=-0.4639 
[epoch 24] step 40/44: loss=-0.4613 
[epoch 24] step 42/44: loss=-0.4622 
[epoch 24] step 44/44: loss=-0.4651 
[epoch 24] train_loss(avg per step)=-0.9301 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=3.6483 qwk=('0.6289', '0.5568', '0.5669') averageQWK=0.5842 macroEMD=0.2465 tailR0=('0.1304', '0.0972', '0.0000') tailR0avg=0.0759
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     1   19   33    2    0
     0   13   75   35    2
     0    1   23   83    9
     0    0    3   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     1   20   24    8    0
     2    9   75   33    3
     0    1   29  100    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   23   46    0    0
     0   16  107   29    0
     0    0   40   61    0
     0    0    1    1    0
[epoch 25] step 2/44: loss=-0.4816 
[epoch 25] step 4/44: loss=-0.4234 
[epoch 25] step 6/44: loss=-0.4653 
[epoch 25] step 8/44: loss=-0.4685 
[epoch 25] step 10/44: loss=-0.4749 
[epoch 25] step 12/44: loss=-0.4759 
[epoch 25] step 14/44: loss=-0.4747 
[epoch 25] step 16/44: loss=-0.4721 
[epoch 25] step 18/44: loss=-0.4772 
[epoch 25] step 20/44: loss=-0.4767 
[epoch 25] step 22/44: loss=-0.4800 
[epoch 25] step 24/44: loss=-0.4819 
[epoch 25] step 26/44: loss=-0.4823 
[epoch 25] step 28/44: loss=-0.4849 
[epoch 25] step 30/44: loss=-0.4839 
[epoch 25] step 32/44: loss=-0.4844 
[epoch 25] step 34/44: loss=-0.4796 
[epoch 25] step 36/44: loss=-0.4820 
[epoch 25] step 38/44: loss=-0.4815 
[epoch 25] step 40/44: loss=-0.4805 
[epoch 25] step 42/44: loss=-0.4779 
[epoch 25] step 44/44: loss=-0.4805 
[epoch 25] train_loss(avg per step)=-0.9611 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=3.9708 qwk=('0.6217', '0.5591', '0.6099') averageQWK=0.5969 macroEMD=0.2418 tailR0=('0.1304', '0.0417', '0.0000') tailR0avg=0.0574
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   17   35    3    0
     0   10   78   34    3
     0    1   21   80   14
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   18   29    6    0
     0   10   80   28    4
     0    1   30   96    6
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   33   36    0    0
     0   21  101   30    0
     0    2   32   67    0
     0    0    1    1    0
[epoch 26] step 2/44: loss=-0.4959 
[epoch 26] step 4/44: loss=-0.5083 
[epoch 26] step 6/44: loss=-0.5168 
[epoch 26] step 8/44: loss=-0.5053 
[epoch 26] step 10/44: loss=-0.5114 
[epoch 26] step 12/44: loss=-0.4956 
[epoch 26] step 14/44: loss=-0.4945 
[epoch 26] step 16/44: loss=-0.4943 
[epoch 26] step 18/44: loss=-0.4972 
[epoch 26] step 20/44: loss=-0.4951 
[epoch 26] step 22/44: loss=-0.4905 
[epoch 26] step 24/44: loss=-0.4899 
[epoch 26] step 26/44: loss=-0.4907 
[epoch 26] step 28/44: loss=-0.4903 
[epoch 26] step 30/44: loss=-0.4835 
[epoch 26] step 32/44: loss=-0.4831 
[epoch 26] step 34/44: loss=-0.4843 
[epoch 26] step 36/44: loss=-0.4865 
[epoch 26] step 38/44: loss=-0.4891 
[epoch 26] step 40/44: loss=-0.4917 
[epoch 26] step 42/44: loss=-0.4846 
[epoch 26] step 44/44: loss=-0.4881 
[epoch 26] train_loss(avg per step)=-0.9761 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=4.2670 qwk=('0.6389', '0.6379', '0.6123') averageQWK=0.6297 macroEMD=0.2394 tailR0=('0.1587', '0.0000', '0.0000') tailR0avg=0.0529
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    3    0    0
     0   22   32    1    0
     0   14   80   30    1
     0    1   27   79    9
     0    0    4   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    0    0
     0   24   22    7    0
     0   15   59   48    0
     0    1   12  120    0
     0    0    0   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   40   29    0    0
     0   25   98   29    0
     0    4   32   65    0
     0    0    1    1    0
[epoch 27] step 2/44: loss=-0.5200 
[epoch 27] step 4/44: loss=-0.4802 
[epoch 27] step 6/44: loss=-0.4874 
[epoch 27] step 8/44: loss=-0.5055 
[epoch 27] step 10/44: loss=-0.5031 
[epoch 27] step 12/44: loss=-0.4971 
[epoch 27] step 14/44: loss=-0.4980 
[epoch 27] step 16/44: loss=-0.5013 
[epoch 27] step 18/44: loss=-0.5033 
[epoch 27] step 20/44: loss=-0.5056 
[epoch 27] step 22/44: loss=-0.4997 
[epoch 27] step 24/44: loss=-0.4983 
[epoch 27] step 26/44: loss=-0.5007 
[epoch 27] step 28/44: loss=-0.5012 
[epoch 27] step 30/44: loss=-0.5049 
[epoch 27] step 32/44: loss=-0.5052 
[epoch 27] step 34/44: loss=-0.5035 
[epoch 27] step 36/44: loss=-0.5018 
[epoch 27] step 38/44: loss=-0.5020 
[epoch 27] step 40/44: loss=-0.5043 
[epoch 27] step 42/44: loss=-0.5007 
[epoch 27] step 44/44: loss=-0.5027 
[epoch 27] train_loss(avg per step)=-1.0054 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=4.3307 qwk=('0.6263', '0.5731', '0.5642') averageQWK=0.5879 macroEMD=0.2442 tailR0=('0.1304', '0.0000', '0.0000') tailR0avg=0.0435
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   16   37    2    0
     0   10   78   35    2
     0    0   25   77   14
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   19   28    6    0
     0   12   72   35    3
     0    1   22  108    2
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   23   46    0    0
     0   16  110   26    0
     0    0   37   64    0
     0    0    2    0    0
[epoch 28] step 2/44: loss=-0.5101 
[epoch 28] step 4/44: loss=-0.5340 
[epoch 28] step 6/44: loss=-0.5043 
[epoch 28] step 8/44: loss=-0.5016 
[epoch 28] step 10/44: loss=-0.4994 
[epoch 28] step 12/44: loss=-0.4961 
[epoch 28] step 14/44: loss=-0.5023 
[epoch 28] step 16/44: loss=-0.5048 
[epoch 28] step 18/44: loss=-0.5110 
[epoch 28] step 20/44: loss=-0.5138 
[epoch 28] step 22/44: loss=-0.5060 
[epoch 28] step 24/44: loss=-0.5076 
[epoch 28] step 26/44: loss=-0.5066 
[epoch 28] step 28/44: loss=-0.5094 
[epoch 28] step 30/44: loss=-0.5075 
[epoch 28] step 32/44: loss=-0.5099 
[epoch 28] step 34/44: loss=-0.5094 
[epoch 28] step 36/44: loss=-0.5039 
[epoch 28] step 38/44: loss=-0.5065 
[epoch 28] step 40/44: loss=-0.5080 
[epoch 28] step 42/44: loss=-0.5076 
[epoch 28] step 44/44: loss=-0.5095 
[epoch 28] train_loss(avg per step)=-1.0189 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=4.5176 qwk=('0.6029', '0.5818', '0.6219') averageQWK=0.6022 macroEMD=0.2387 tailR0=('0.1087', '0.0417', '0.0000') tailR0avg=0.0501
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   14   36    5    0
     0    8   82   33    2
     0    0   25   78   13
     0    0    2   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   16   31    6    0
     0    6   77   37    2
     0    1   16  113    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    0    0
     0   28   41    0    0
     0   18  103   31    0
     0    0   30   71    0
     0    0    1    1    0
[epoch 29] step 2/44: loss=-0.5060 
[epoch 29] step 4/44: loss=-0.5343 
[epoch 29] step 6/44: loss=-0.5361 
[epoch 29] step 8/44: loss=-0.5170 
[epoch 29] step 10/44: loss=-0.5166 
[epoch 29] step 12/44: loss=-0.5224 
[epoch 29] step 14/44: loss=-0.5268 
[epoch 29] step 16/44: loss=-0.5131 
[epoch 29] step 18/44: loss=-0.4984 
[epoch 29] step 20/44: loss=-0.4997 
[epoch 29] step 22/44: loss=-0.5030 
[epoch 29] step 24/44: loss=-0.5080 
[epoch 29] step 26/44: loss=-0.5103 
[epoch 29] step 28/44: loss=-0.5121 
[epoch 29] step 30/44: loss=-0.5157 
[epoch 29] step 32/44: loss=-0.5137 
[epoch 29] step 34/44: loss=-0.5176 
[epoch 29] step 36/44: loss=-0.5164 
[epoch 29] step 38/44: loss=-0.5191 
[epoch 29] step 40/44: loss=-0.5177 
[epoch 29] step 42/44: loss=-0.5161 
[epoch 29] step 44/44: loss=-0.5186 
[epoch 29] train_loss(avg per step)=-1.0371 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=4.4231 qwk=('0.6323', '0.5754', '0.5769') averageQWK=0.5949 macroEMD=0.2401 tailR0=('0.1087', '0.0000', '0.0000') tailR0avg=0.0362
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     1   17   35    2    0
     0    8   84   32    1
     0    0   27   82    7
     0    0    3   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    0    0
     0   20   27    6    0
     1   13   68   38    2
     0    1   24  108    0
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   28   41    0    0
     0   16  108   28    0
     0    0   41   60    0
     0    0    1    1    0
[epoch 30] step 2/44: loss=-0.5666 
[epoch 30] step 4/44: loss=-0.5336 
[epoch 30] step 6/44: loss=-0.5367 
[epoch 30] step 8/44: loss=-0.5316 
[epoch 30] step 10/44: loss=-0.5229 
[epoch 30] step 12/44: loss=-0.5248 
[epoch 30] step 14/44: loss=-0.5191 
[epoch 30] step 16/44: loss=-0.5250 
[epoch 30] step 18/44: loss=-0.5287 
[epoch 30] step 20/44: loss=-0.5246 
[epoch 30] step 22/44: loss=-0.5234 
[epoch 30] step 24/44: loss=-0.5196 
[epoch 30] step 26/44: loss=-0.5242 
[epoch 30] step 28/44: loss=-0.5278 
[epoch 30] step 30/44: loss=-0.5307 
[epoch 30] step 32/44: loss=-0.5282 
[epoch 30] step 34/44: loss=-0.5307 
[epoch 30] step 36/44: loss=-0.5313 
[epoch 30] step 38/44: loss=-0.5332 
[epoch 30] step 40/44: loss=-0.5315 
[epoch 30] step 42/44: loss=-0.5292 
[epoch 30] step 44/44: loss=-0.5279 
[epoch 30] train_loss(avg per step)=-1.0557 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=5.2250 qwk=('0.5686', '0.5656', '0.5664') averageQWK=0.5669 macroEMD=0.2431 tailR0=('0.1739', '0.0417', '0.0000') tailR0avg=0.0719
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   11   36    8    0
     0    7   77   36    5
     0    0   21   79   16
     0    0    2   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   16   28    9    0
     0    7   61   52    2
     0    0   10  120    3
     0    0    0   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   19   49    1    0
     0   12  100   40    0
     0    0   25   76    0
     0    0    1    1    0
[epoch 31] step 2/44: loss=-0.5320 
[epoch 31] step 4/44: loss=-0.5516 
[epoch 31] step 6/44: loss=-0.5447 
[epoch 31] step 8/44: loss=-0.5415 
[epoch 31] step 10/44: loss=-0.5385 
[epoch 31] step 12/44: loss=-0.5459 
[epoch 31] step 14/44: loss=-0.5502 
[epoch 31] step 16/44: loss=-0.5503 
[epoch 31] step 18/44: loss=-0.5456 
[epoch 31] step 20/44: loss=-0.5475 
[epoch 31] step 22/44: loss=-0.5499 
[epoch 31] step 24/44: loss=-0.5469 
[epoch 31] step 26/44: loss=-0.5407 
[epoch 31] step 28/44: loss=-0.5365 
[epoch 31] step 30/44: loss=-0.5370 
[epoch 31] step 32/44: loss=-0.5343 
[epoch 31] step 34/44: loss=-0.5371 
[epoch 31] step 36/44: loss=-0.5380 
[epoch 31] step 38/44: loss=-0.5409 
[epoch 31] step 40/44: loss=-0.5422 
[epoch 31] step 42/44: loss=-0.5378 
[epoch 31] step 44/44: loss=-0.5293 
[epoch 31] train_loss(avg per step)=-1.0587 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=4.7701 qwk=('0.6234', '0.5734', '0.5778') averageQWK=0.5915 macroEMD=0.2359 tailR0=('0.1304', '0.0417', '0.0000') tailR0avg=0.0574
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   18   35    2    0
     0    9   80   32    4
     0    0   21   81   14
     0    0    4   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   19   28    6    0
     0    9   71   40    2
     0    0   23  108    2
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   28   41    0    0
     0   20  101   31    0
     0    1   35   65    0
     0    0    1    1    0
[epoch 32] step 2/44: loss=-0.5777 
[epoch 32] step 4/44: loss=-0.5745 
[epoch 32] step 6/44: loss=-0.5765 
[epoch 32] step 8/44: loss=-0.5753 
[epoch 32] step 10/44: loss=-0.5738 
[epoch 32] step 12/44: loss=-0.5352 
[epoch 32] step 14/44: loss=-0.5312 
[epoch 32] step 16/44: loss=-0.5238 
[epoch 32] step 18/44: loss=-0.5257 
[epoch 32] step 20/44: loss=-0.5222 
[epoch 32] step 22/44: loss=-0.5274 
[epoch 32] step 24/44: loss=-0.5287 
[epoch 32] step 26/44: loss=-0.5301 
[epoch 32] step 28/44: loss=-0.5343 
[epoch 32] step 30/44: loss=-0.5298 
[epoch 32] step 32/44: loss=-0.5295 
[epoch 32] step 34/44: loss=-0.5306 
[epoch 32] step 36/44: loss=-0.5304 
[epoch 32] step 38/44: loss=-0.5305 
[epoch 32] step 40/44: loss=-0.5326 
[epoch 32] step 42/44: loss=-0.5348 
[epoch 32] step 44/44: loss=-0.5334 
[epoch 32] train_loss(avg per step)=-1.0667 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=4.8282 qwk=('0.6351', '0.5711', '0.5706') averageQWK=0.5923 macroEMD=0.2355 tailR0=('0.1087', '0.0556', '0.0000') tailR0avg=0.0548
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     1   15   37    2    0
     0   11   77   36    1
     0    0   22   87    7
     0    0    2   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    5    0    0
     0   20   27    6    0
     0   11   67   42    2
     0    1   21  110    1
     0    0    2   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   26   43    0    0
     0   16  107   29    0
     0    1   37   63    0
     0    0    1    1    0
[epoch 33] step 2/44: loss=-0.5901 
[epoch 33] step 4/44: loss=-0.5734 
[epoch 33] step 6/44: loss=-0.5669 
[epoch 33] step 8/44: loss=-0.5653 
[epoch 33] step 10/44: loss=-0.5628 
[epoch 33] step 12/44: loss=-0.5654 
[epoch 33] step 14/44: loss=-0.5482 
[epoch 33] step 16/44: loss=-0.5504 
[epoch 33] step 18/44: loss=-0.5462 
[epoch 33] step 20/44: loss=-0.5407 
[epoch 33] step 22/44: loss=-0.5401 
[epoch 33] step 24/44: loss=-0.5444 
[epoch 33] step 26/44: loss=-0.5418 
[epoch 33] step 28/44: loss=-0.5437 
[epoch 33] step 30/44: loss=-0.5393 
[epoch 33] step 32/44: loss=-0.5423 
[epoch 33] step 34/44: loss=-0.5397 
[epoch 33] step 36/44: loss=-0.5408 
[epoch 33] step 38/44: loss=-0.5435 
[epoch 33] step 40/44: loss=-0.5452 
[epoch 33] step 42/44: loss=-0.5426 
[epoch 33] step 44/44: loss=-0.5451 
[epoch 33] train_loss(avg per step)=-1.0901 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=4.8866 qwk=('0.6295', '0.5823', '0.5666') averageQWK=0.5928 macroEMD=0.2357 tailR0=('0.1304', '0.0417', '0.0000') tailR0avg=0.0574
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     0   15   38    2    0
     0    8   78   36    3
     0    0   20   83   13
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    0    0
     0   19   28    6    0
     0    9   71   40    2
     0    0   20  110    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   23   46    0    0
     0   15   99   37    1
     0    1   27   73    0
     0    0    1    1    0
[epoch 34] step 2/44: loss=-0.5795 
[epoch 34] step 4/44: loss=-0.5465 
[epoch 34] step 6/44: loss=-0.5488 
[epoch 34] step 8/44: loss=-0.5571 
[epoch 34] step 10/44: loss=-0.5532 
[epoch 34] step 12/44: loss=-0.5492 
[epoch 34] step 14/44: loss=-0.5454 
[epoch 34] step 16/44: loss=-0.5390 
[epoch 34] step 18/44: loss=-0.5379 
[epoch 34] step 20/44: loss=-0.5431 
[epoch 34] step 22/44: loss=-0.5346 
[epoch 34] step 24/44: loss=-0.5372 
[epoch 34] step 26/44: loss=-0.5346 
[epoch 34] step 28/44: loss=-0.5328 
[epoch 34] step 30/44: loss=-0.5334 
[epoch 34] step 32/44: loss=-0.5358 
[epoch 34] step 34/44: loss=-0.5387 
[epoch 34] step 36/44: loss=-0.5411 
[epoch 34] step 38/44: loss=-0.5436 
[epoch 34] step 40/44: loss=-0.5450 
[epoch 34] step 42/44: loss=-0.5425 
[epoch 34] step 44/44: loss=-0.5429 
[epoch 34] train_loss(avg per step)=-1.0858 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=4.9118 qwk=('0.6427', '0.6054', '0.5793') averageQWK=0.6091 macroEMD=0.2332 tailR0=('0.1304', '0.0417', '0.0000') tailR0avg=0.0574
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     2   15   36    2    0
     0    9   78   36    2
     0    0   20   85   11
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    0    0
     0   21   26    6    0
     0   10   68   42    2
     0    0   19  111    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    0    0
     0   28   41    0    0
     0   17  101   33    1
     0    1   33   67    0
     0    0    1    1    0
[epoch 35] step 2/44: loss=-0.5450 
[epoch 35] step 4/44: loss=-0.5626 
[epoch 35] step 6/44: loss=-0.5634 
[epoch 35] step 8/44: loss=-0.5713 
[epoch 35] step 10/44: loss=-0.5665 
[epoch 35] step 12/44: loss=-0.5515 
[epoch 35] step 14/44: loss=-0.5566 
[epoch 35] step 16/44: loss=-0.5535 
[epoch 35] step 18/44: loss=-0.5568 
[epoch 35] step 20/44: loss=-0.5603 
[epoch 35] step 22/44: loss=-0.5602 
[epoch 35] step 24/44: loss=-0.5608 
[epoch 35] step 26/44: loss=-0.5545 
[epoch 35] step 28/44: loss=-0.5513 
[epoch 35] step 30/44: loss=-0.5500 
[epoch 35] step 32/44: loss=-0.5503 
[epoch 35] step 34/44: loss=-0.5528 
[epoch 35] step 36/44: loss=-0.5495 
[epoch 35] step 38/44: loss=-0.5498 
[epoch 35] step 40/44: loss=-0.5486 
[epoch 35] step 42/44: loss=-0.5504 
[epoch 35] step 44/44: loss=-0.5486 
[epoch 35] train_loss(avg per step)=-1.0971 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=4.9200 qwk=('0.6455', '0.5891', '0.5428') averageQWK=0.5925 macroEMD=0.2342 tailR0=('0.1304', '0.0417', '0.0000') tailR0avg=0.0574
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    3    0    0
     2   16   35    2    0
     0   10   77   36    2
     0    0   20   87    9
     0    0    2   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    0    0
     0   19   28    6    0
     0    9   73   38    2
     0    0   22  108    3
     0    0    1   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   23   46    0    0
     0   15  106   30    1
     0    1   36   64    0
     0    0    1    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-0-conf_gating-0-reassignment-0/fold5/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/k6_scorecv/jager--joint-1-mixture-0-conf_gating-0-reassignment-0/fold5/metrics.json
Done.
