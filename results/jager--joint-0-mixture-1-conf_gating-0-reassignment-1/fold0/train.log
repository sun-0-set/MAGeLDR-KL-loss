[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.6910 
[epoch 1] step 4/44: loss=0.7010 
[epoch 1] step 6/44: loss=0.7038 
[epoch 1] step 8/44: loss=0.7075 
[epoch 1] step 10/44: loss=0.7135 
[epoch 1] step 12/44: loss=0.7147 
[epoch 1] step 14/44: loss=0.7126 
[epoch 1] step 16/44: loss=0.7114 
[epoch 1] step 18/44: loss=0.7113 
[epoch 1] step 20/44: loss=0.7092 
[epoch 1] step 22/44: loss=0.7077 
[epoch 1] step 24/44: loss=0.7065 
[epoch 1] step 26/44: loss=0.7062 
[epoch 1] step 28/44: loss=0.7044 
[epoch 1] step 30/44: loss=0.7046 
[epoch 1] step 32/44: loss=0.7036 
[epoch 1] step 34/44: loss=0.7027 
[epoch 1] step 36/44: loss=0.7028 
[epoch 1] step 38/44: loss=0.7056 
[epoch 1] step 40/44: loss=0.7102 
[epoch 1] step 42/44: loss=0.7134 
[epoch 1] step 44/44: loss=0.7177 
[epoch 1] train_loss(avg per step)=1.4353 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.8049 qwk=('0.0014', '-0.0010', '-0.0559') averageQWK=-0.0185 macroEMD=0.3661 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    4    0
     0    0    0   15    0
     0    2    0   76    0
     0    9    0  153    0
     0    0    0   64    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   16    0    0
     1    0   62    3    0
     5    0  188   12    0
     0    0   30    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   10   19    0    0
     0   39   72    0    0
     0   88   93    0    0
     0    0    1    0    0
[epoch 2] step 2/44: loss=0.9623 
[epoch 2] step 4/44: loss=0.9859 
[epoch 2] step 6/44: loss=1.0128 
[epoch 2] step 8/44: loss=1.0131 
[epoch 2] step 10/44: loss=0.9995 
[epoch 2] step 12/44: loss=0.9983 
[epoch 2] step 14/44: loss=0.9853 
[epoch 2] step 16/44: loss=0.9715 
[epoch 2] step 18/44: loss=0.9544 
[epoch 2] step 20/44: loss=0.9371 
[epoch 2] step 22/44: loss=0.9251 
[epoch 2] step 24/44: loss=0.9118 
[epoch 2] step 26/44: loss=0.9025 
[epoch 2] step 28/44: loss=0.8968 
[epoch 2] step 30/44: loss=0.8941 
[epoch 2] step 32/44: loss=0.8908 
[epoch 2] step 34/44: loss=0.8919 
[epoch 2] step 36/44: loss=0.8933 
[epoch 2] step 38/44: loss=0.8901 
[epoch 2] step 40/44: loss=0.8860 
[epoch 2] step 42/44: loss=0.8787 
[epoch 2] step 44/44: loss=0.8720 
[epoch 2] train_loss(avg per step)=1.7440 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.1215 qwk=('0.1433', '0.1903', '0.2071') averageQWK=0.1803 macroEMD=0.3549 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    1    0
     0    9    0    6    0
     0   16    4   58    0
     0   18   14  130    0
     0   13    7   44    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    1    0
     0    0    5   11    0
     0    0    6   60    0
     0    0   14  191    0
     0    0    1   29    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    6   22    1    0
     0    5   69   37    0
     0    6  107   68    0
     0    0    0    1    0
[epoch 3] step 2/44: loss=0.7584 
[epoch 3] step 4/44: loss=0.7399 
[epoch 3] step 6/44: loss=0.7370 
[epoch 3] step 8/44: loss=0.7516 
[epoch 3] step 10/44: loss=0.7551 
[epoch 3] step 12/44: loss=0.7558 
[epoch 3] step 14/44: loss=0.7688 
[epoch 3] step 16/44: loss=0.7788 
[epoch 3] step 18/44: loss=0.7830 
[epoch 3] step 20/44: loss=0.7880 
[epoch 3] step 22/44: loss=0.7884 
[epoch 3] step 24/44: loss=0.7906 
[epoch 3] step 26/44: loss=0.7887 
[epoch 3] step 28/44: loss=0.7920 
[epoch 3] step 30/44: loss=0.7948 
[epoch 3] step 32/44: loss=0.7970 
[epoch 3] step 34/44: loss=0.7984 
[epoch 3] step 36/44: loss=0.8002 
[epoch 3] step 38/44: loss=0.8028 
[epoch 3] step 40/44: loss=0.8030 
[epoch 3] step 42/44: loss=0.8033 
[epoch 3] step 44/44: loss=0.8047 
[epoch 3] train_loss(avg per step)=1.6093 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=1.6918 qwk=('0.1400', '0.1465', '0.1371') averageQWK=0.1412 macroEMD=0.3452 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    9    6    0    0
     0   17   50   11    0
     0   14  103   45    0
     0    6   50    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   16    0    0
     0    0   53   13    0
     0    0  142   63    0
     0    0   17   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26    3    0    0
     0   57   51    3    0
     0   77   83   21    0
     0    0    1    0    0
[epoch 4] step 2/44: loss=0.7980 
[epoch 4] step 4/44: loss=0.8226 
[epoch 4] step 6/44: loss=0.8277 
[epoch 4] step 8/44: loss=0.8358 
[epoch 4] step 10/44: loss=0.8461 
[epoch 4] step 12/44: loss=0.8552 
[epoch 4] step 14/44: loss=0.8611 
[epoch 4] step 16/44: loss=0.8574 
[epoch 4] step 18/44: loss=0.8479 
[epoch 4] step 20/44: loss=0.8400 
[epoch 4] step 22/44: loss=0.8339 
[epoch 4] step 24/44: loss=0.8291 
[epoch 4] step 26/44: loss=0.8269 
[epoch 4] step 28/44: loss=0.8243 
[epoch 4] step 30/44: loss=0.8229 
[epoch 4] step 32/44: loss=0.8227 
[epoch 4] step 34/44: loss=0.8193 
[epoch 4] step 36/44: loss=0.8200 
[epoch 4] step 38/44: loss=0.8171 
[epoch 4] step 40/44: loss=0.8144 
[epoch 4] step 42/44: loss=0.8146 
[epoch 4] step 44/44: loss=0.8170 
[epoch 4] train_loss(avg per step)=1.6340 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=1.6004 qwk=('0.1909', '0.1868', '0.2291') averageQWK=0.2023 macroEMD=0.3314 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    9    4    2    0
     0   15   40   23    0
     0   12   87   63    0
     0    5   34   25    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    1   12    3    0
     0    0   41   25    0
     0    0  112   93    0
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    9   20    0    0
     0    3  105    3    0
     0    3  149   29    0
     0    0    0    1    0
[epoch 5] step 2/44: loss=0.8188 
[epoch 5] step 4/44: loss=0.8451 
[epoch 5] step 6/44: loss=0.8474 
[epoch 5] step 8/44: loss=0.8439 
[epoch 5] step 10/44: loss=0.8372 
[epoch 5] step 12/44: loss=0.8324 
[epoch 5] step 14/44: loss=0.8284 
[epoch 5] step 16/44: loss=0.8277 
[epoch 5] step 18/44: loss=0.8298 
[epoch 5] step 20/44: loss=0.8263 
[epoch 5] step 22/44: loss=0.8275 
[epoch 5] step 24/44: loss=0.8270 
[epoch 5] step 26/44: loss=0.8294 
[epoch 5] step 28/44: loss=0.8280 
[epoch 5] step 30/44: loss=0.8268 
[epoch 5] step 32/44: loss=0.8240 
[epoch 5] step 34/44: loss=0.8236 
[epoch 5] step 36/44: loss=0.8222 
[epoch 5] step 38/44: loss=0.8193 
[epoch 5] step 40/44: loss=0.8186 
[epoch 5] step 42/44: loss=0.8172 
[epoch 5] step 44/44: loss=0.8151 
[epoch 5] train_loss(avg per step)=1.6303 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=1.4949 qwk=('0.2410', '0.1992', '0.3089') averageQWK=0.2497 macroEMD=0.3246 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    1   54   23    0
     0    0   75   87    0
     0    1   29   34    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   14    2    0
     0    0   43   23    0
     0    0  103  102    0
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   13   86   12    0
     0    9  127   45    0
     0    0    0    1    0
[epoch 6] step 2/44: loss=0.7655 
[epoch 6] step 4/44: loss=0.7670 
[epoch 6] step 6/44: loss=0.7733 
[epoch 6] step 8/44: loss=0.7680 
[epoch 6] step 10/44: loss=0.7632 
[epoch 6] step 12/44: loss=0.7603 
[epoch 6] step 14/44: loss=0.7594 
[epoch 6] step 16/44: loss=0.7644 
[epoch 6] step 18/44: loss=0.7708 
[epoch 6] step 20/44: loss=0.7748 
[epoch 6] step 22/44: loss=0.7820 
[epoch 6] step 24/44: loss=0.7918 
[epoch 6] step 26/44: loss=0.8002 
[epoch 6] step 28/44: loss=0.8063 
[epoch 6] step 30/44: loss=0.8105 
[epoch 6] step 32/44: loss=0.8151 
[epoch 6] step 34/44: loss=0.8115 
[epoch 6] step 36/44: loss=0.8090 
[epoch 6] step 38/44: loss=0.8047 
[epoch 6] step 40/44: loss=0.8036 
[epoch 6] step 42/44: loss=0.8013 
[epoch 6] step 44/44: loss=0.7987 
[epoch 6] train_loss(avg per step)=1.5974 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=1.5378 qwk=('0.1264', '0.2442', '0.2930') averageQWK=0.2212 macroEMD=0.3226 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    0   14    1    0
     0    0   49   29    0
     0    0   81   81    0
     0    1   37   26    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   13    3    0
     0    0   33   33    0
     0    0   76  129    0
     0    0    9   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    8   21    0    0
     0    3   87   21    0
     0    1  120   60    0
     0    0    0    1    0
[epoch 7] step 2/44: loss=0.8197 
[epoch 7] step 4/44: loss=0.8087 
[epoch 7] step 6/44: loss=0.7985 
[epoch 7] step 8/44: loss=0.7987 
[epoch 7] step 10/44: loss=0.7981 
[epoch 7] step 12/44: loss=0.7993 
[epoch 7] step 14/44: loss=0.8033 
[epoch 7] step 16/44: loss=0.8099 
[epoch 7] step 18/44: loss=0.8112 
[epoch 7] step 20/44: loss=0.8143 
[epoch 7] step 22/44: loss=0.8151 
[epoch 7] step 24/44: loss=0.8162 
[epoch 7] step 26/44: loss=0.8161 
[epoch 7] step 28/44: loss=0.8154 
[epoch 7] step 30/44: loss=0.8148 
[epoch 7] step 32/44: loss=0.8099 
[epoch 7] step 34/44: loss=0.8064 
[epoch 7] step 36/44: loss=0.8048 
[epoch 7] step 38/44: loss=0.8030 
[epoch 7] step 40/44: loss=0.8030 
[epoch 7] step 42/44: loss=0.8034 
[epoch 7] step 44/44: loss=0.8041 
[epoch 7] train_loss(avg per step)=1.6081 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.7597 qwk=('0.1973', '0.2311', '0.3075') averageQWK=0.2453 macroEMD=0.3107 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    1   14    0    0
     0    0   66   12    0
     0    0  106   56    0
     0    0   37   27    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    0   14    2    0
     0    0   46   20    0
     0    0  114   91    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    8   21    0    0
     0    3  104    4    0
     0    0  139   42    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=0.7416 
[epoch 8] step 4/44: loss=0.7465 
[epoch 8] step 6/44: loss=0.7561 
[epoch 8] step 8/44: loss=0.7539 
[epoch 8] step 10/44: loss=0.7489 
[epoch 8] step 12/44: loss=0.7466 
[epoch 8] step 14/44: loss=0.7444 
[epoch 8] step 16/44: loss=0.7511 
[epoch 8] step 18/44: loss=0.7488 
[epoch 8] step 20/44: loss=0.7496 
[epoch 8] step 22/44: loss=0.7552 
[epoch 8] step 24/44: loss=0.7597 
[epoch 8] step 26/44: loss=0.7592 
[epoch 8] step 28/44: loss=0.7627 
[epoch 8] step 30/44: loss=0.7632 
[epoch 8] step 32/44: loss=0.7666 
[epoch 8] step 34/44: loss=0.7688 
[epoch 8] step 36/44: loss=0.7712 
[epoch 8] step 38/44: loss=0.7751 
[epoch 8] step 40/44: loss=0.7784 
[epoch 8] step 42/44: loss=0.7786 
[epoch 8] step 44/44: loss=0.7774 
[epoch 8] train_loss(avg per step)=1.5549 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.6238 qwk=('0.2263', '0.2475', '0.3284') averageQWK=0.2674 macroEMD=0.3172 tailR0=('0.0625', '0.0000', '0.0000') tailR0avg=0.0208
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7    8    0    0
     0    9   57   10    2
     0    2  113   37   10
     0    1   46    9    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4    9    3    0
     0    8   38   20    0
     0    6  118   81    0
     0    1   13   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   12   88   11    0
     0    6  130   45    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=0.7466 
[epoch 9] step 4/44: loss=0.7516 
[epoch 9] step 6/44: loss=0.7479 
[epoch 9] step 8/44: loss=0.7409 
[epoch 9] step 10/44: loss=0.7396 
[epoch 9] step 12/44: loss=0.7367 
[epoch 9] step 14/44: loss=0.7390 
[epoch 9] step 16/44: loss=0.7411 
[epoch 9] step 18/44: loss=0.7457 
[epoch 9] step 20/44: loss=0.7495 
[epoch 9] step 22/44: loss=0.7504 
[epoch 9] step 24/44: loss=0.7524 
[epoch 9] step 26/44: loss=0.7568 
[epoch 9] step 28/44: loss=0.7566 
[epoch 9] step 30/44: loss=0.7570 
[epoch 9] step 32/44: loss=0.7560 
[epoch 9] step 34/44: loss=0.7552 
[epoch 9] step 36/44: loss=0.7545 
[epoch 9] step 38/44: loss=0.7533 
[epoch 9] step 40/44: loss=0.7532 
[epoch 9] step 42/44: loss=0.7559 
[epoch 9] step 44/44: loss=0.7567 
[epoch 9] train_loss(avg per step)=1.5135 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.8304 qwk=('0.2399', '0.2107', '0.2686') averageQWK=0.2397 macroEMD=0.3136 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    7    0    0
     0   10   58   10    0
     0    2  113   47    0
     0    2   39   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    4   12    0    0
     0    9   52    5    0
     0    2  159   44    0
     0    1   21    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0   12   97    2    0
     0    5  152   24    0
     0    0    1    0    0
[epoch 10] step 2/44: loss=0.8219 
[epoch 10] step 4/44: loss=0.8158 
[epoch 10] step 6/44: loss=0.8098 
[epoch 10] step 8/44: loss=0.8082 
[epoch 10] step 10/44: loss=0.8026 
[epoch 10] step 12/44: loss=0.7988 
[epoch 10] step 14/44: loss=0.7931 
[epoch 10] step 16/44: loss=0.7882 
[epoch 10] step 18/44: loss=0.7839 
[epoch 10] step 20/44: loss=0.7800 
[epoch 10] step 22/44: loss=0.7760 
[epoch 10] step 24/44: loss=0.7696 
[epoch 10] step 26/44: loss=0.7675 
[epoch 10] step 28/44: loss=0.7626 
[epoch 10] step 30/44: loss=0.7604 
[epoch 10] step 32/44: loss=0.7556 
[epoch 10] step 34/44: loss=0.7543 
[epoch 10] step 36/44: loss=0.7575 
[epoch 10] step 38/44: loss=0.7614 
[epoch 10] step 40/44: loss=0.7623 
[epoch 10] step 42/44: loss=0.7639 
[epoch 10] step 44/44: loss=0.7662 
[epoch 10] train_loss(avg per step)=1.5324 lambda[min,max]=[0.472997,1.000000]
[epoch 10] val_loss=1.7181 qwk=('0.2767', '0.3427', '0.3418') averageQWK=0.3204 macroEMD=0.3025 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    7    0    0
     0   12   45   21    0
     0    2   87   73    0
     0    1   35   27    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    6   10    0    0
     0    8   40   18    0
     0    1  114   90    0
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   15   87    9    0
     0    6  126   49    0
     0    0    1    0    0
[epoch 11] step 2/44: loss=0.7925 
[epoch 11] step 4/44: loss=0.7756 
[epoch 11] step 6/44: loss=0.7814 
[epoch 11] step 8/44: loss=0.7681 
[epoch 11] step 10/44: loss=0.7660 
[epoch 11] step 12/44: loss=0.7618 
[epoch 11] step 14/44: loss=0.7546 
[epoch 11] step 16/44: loss=0.7522 
[epoch 11] step 18/44: loss=0.7510 
[epoch 11] step 20/44: loss=0.7523 
[epoch 11] step 22/44: loss=0.7508 
[epoch 11] step 24/44: loss=0.7461 
[epoch 11] step 26/44: loss=0.7443 
[epoch 11] step 28/44: loss=0.7445 
[epoch 11] step 30/44: loss=0.7452 
[epoch 11] step 32/44: loss=0.7472 
[epoch 11] step 34/44: loss=0.7499 
[epoch 11] step 36/44: loss=0.7517 
[epoch 11] step 38/44: loss=0.7529 
[epoch 11] step 40/44: loss=0.7523 
[epoch 11] step 42/44: loss=0.7517 
[epoch 11] step 44/44: loss=0.7521 
[epoch 11] train_loss(avg per step)=1.5041 lambda[min,max]=[0.450866,1.000000]
[epoch 11] val_loss=1.7183 qwk=('0.2723', '0.2254', '0.3415') averageQWK=0.2797 macroEMD=0.3016 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7    7    1    0
     0    8   52   18    0
     0    2   99   60    1
     0    1   31   31    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    1   14    1    0
     0    4   47   15    0
     0    1  135   69    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   13    0    0
     0   23   84    4    0
     0    9  130   42    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=0.7392 
[epoch 12] step 4/44: loss=0.7468 
[epoch 12] step 6/44: loss=0.7383 
[epoch 12] step 8/44: loss=0.7284 
[epoch 12] step 10/44: loss=0.7255 
[epoch 12] step 12/44: loss=0.7284 
[epoch 12] step 14/44: loss=0.7289 
[epoch 12] step 16/44: loss=0.7286 
[epoch 12] step 18/44: loss=0.7252 
[epoch 12] step 20/44: loss=0.7185 
[epoch 12] step 22/44: loss=0.7170 
[epoch 12] step 24/44: loss=0.7176 
[epoch 12] step 26/44: loss=0.7190 
[epoch 12] step 28/44: loss=0.7212 
[epoch 12] step 30/44: loss=0.7238 
[epoch 12] step 32/44: loss=0.7255 
[epoch 12] step 34/44: loss=0.7253 
[epoch 12] step 36/44: loss=0.7254 
[epoch 12] step 38/44: loss=0.7268 
[epoch 12] step 40/44: loss=0.7266 
[epoch 12] step 42/44: loss=0.7268 
[epoch 12] step 44/44: loss=0.7302 
[epoch 12] train_loss(avg per step)=1.4604 lambda[min,max]=[0.452608,1.000000]
[epoch 12] val_loss=1.8209 qwk=('0.1991', '0.2085', '0.1928') averageQWK=0.2001 macroEMD=0.3157 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0   10   55   13    0
     0    1  107   54    0
     0    1   43   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    4   12    0    0
     0    7   49   10    0
     0    1  154   50    0
     0    0   22    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   22    0    0
     0    5  103    3    0
     0    0  158   23    0
     0    0    1    0    0
[epoch 13] step 2/44: loss=0.7592 
[epoch 13] step 4/44: loss=0.7395 
[epoch 13] step 6/44: loss=0.7257 
[epoch 13] step 8/44: loss=0.7235 
[epoch 13] step 10/44: loss=0.7213 
[epoch 13] step 12/44: loss=0.7123 
[epoch 13] step 14/44: loss=0.7094 
[epoch 13] step 16/44: loss=0.7023 
[epoch 13] step 18/44: loss=0.7005 
[epoch 13] step 20/44: loss=0.6983 
[epoch 13] step 22/44: loss=0.6999 
[epoch 13] step 24/44: loss=0.7035 
[epoch 13] step 26/44: loss=0.7079 
[epoch 13] step 28/44: loss=0.7097 
[epoch 13] step 30/44: loss=0.7118 
[epoch 13] step 32/44: loss=0.7116 
[epoch 13] step 34/44: loss=0.7125 
[epoch 13] step 36/44: loss=0.7155 
[epoch 13] step 38/44: loss=0.7159 
[epoch 13] step 40/44: loss=0.7157 
[epoch 13] step 42/44: loss=0.7135 
[epoch 13] step 44/44: loss=0.7116 
[epoch 13] train_loss(avg per step)=1.4232 lambda[min,max]=[0.418272,1.000000]
[epoch 13] val_loss=1.4893 qwk=('0.2653', '0.3838', '0.3685') averageQWK=0.3392 macroEMD=0.3103 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4    9    2    0
     0    7   39   31    1
     0    1   62   98    1
     0    2   22   39    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    4    9    3    0
     0    8   33   25    0
     0    1   78  126    0
     0    1    5   24    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0   13   93    5    0
     0    4  125   52    0
     0    0    1    0    0
[epoch 14] step 2/44: loss=0.6959 
[epoch 14] step 4/44: loss=0.6717 
[epoch 14] step 6/44: loss=0.6722 
[epoch 14] step 8/44: loss=0.6765 
[epoch 14] step 10/44: loss=0.6709 
[epoch 14] step 12/44: loss=0.6660 
[epoch 14] step 14/44: loss=0.6648 
[epoch 14] step 16/44: loss=0.6652 
[epoch 14] step 18/44: loss=0.6749 
[epoch 14] step 20/44: loss=0.6835 
[epoch 14] step 22/44: loss=0.6889 
[epoch 14] step 24/44: loss=0.6949 
[epoch 14] step 26/44: loss=0.6973 
[epoch 14] step 28/44: loss=0.6978 
[epoch 14] step 30/44: loss=0.7004 
[epoch 14] step 32/44: loss=0.7028 
[epoch 14] step 34/44: loss=0.7035 
[epoch 14] step 36/44: loss=0.7048 
[epoch 14] step 38/44: loss=0.7028 
[epoch 14] step 40/44: loss=0.7000 
[epoch 14] step 42/44: loss=0.6980 
[epoch 14] step 44/44: loss=0.6961 
[epoch 14] train_loss(avg per step)=1.3922 lambda[min,max]=[0.414855,1.000000]
[epoch 14] val_loss=1.5588 qwk=('0.1744', '0.3095', '0.3667') averageQWK=0.2835 macroEMD=0.3081 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5   10    0    0
     0   14   51   11    2
     0    4  111   44    3
     0    3   45   14    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    9    0    0
     0   10   40   16    0
     0    7  118   80    0
     0    1   13   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0   23   69   19    0
     0   12   96   73    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=0.7271 
[epoch 15] step 4/44: loss=0.7114 
[epoch 15] step 6/44: loss=0.7009 
[epoch 15] step 8/44: loss=0.7101 
[epoch 15] step 10/44: loss=0.7134 
[epoch 15] step 12/44: loss=0.7141 
[epoch 15] step 14/44: loss=0.7114 
[epoch 15] step 16/44: loss=0.7128 
[epoch 15] step 18/44: loss=0.7106 
[epoch 15] step 20/44: loss=0.7056 
[epoch 15] step 22/44: loss=0.7058 
[epoch 15] step 24/44: loss=0.7062 
[epoch 15] step 26/44: loss=0.7045 
[epoch 15] step 28/44: loss=0.7046 
[epoch 15] step 30/44: loss=0.7042 
[epoch 15] step 32/44: loss=0.7005 
[epoch 15] step 34/44: loss=0.6986 
[epoch 15] step 36/44: loss=0.6969 
[epoch 15] step 38/44: loss=0.6936 
[epoch 15] step 40/44: loss=0.6913 
[epoch 15] step 42/44: loss=0.6886 
[epoch 15] step 44/44: loss=0.6874 
[epoch 15] train_loss(avg per step)=1.3749 lambda[min,max]=[0.405781,1.000000]
[epoch 15] val_loss=1.6076 qwk=('0.2427', '0.3209', '0.2794') averageQWK=0.2810 macroEMD=0.3031 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7    7    1    0
     0   15   43   18    2
     0    2  108   49    3
     0    2   33   27    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    7    7    2    0
     0    9   35   22    0
     0    4  103   98    0
     0    1   10   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   23   84    4    0
     0   12  136   33    0
     0    0    1    0    0
[epoch 16] step 2/44: loss=0.7293 
[epoch 16] step 4/44: loss=0.7260 
[epoch 16] step 6/44: loss=0.7212 
[epoch 16] step 8/44: loss=0.7248 
[epoch 16] step 10/44: loss=0.7273 
[epoch 16] step 12/44: loss=0.7199 
[epoch 16] step 14/44: loss=0.7120 
[epoch 16] step 16/44: loss=0.7025 
[epoch 16] step 18/44: loss=0.6957 
[epoch 16] step 20/44: loss=0.6908 
[epoch 16] step 22/44: loss=0.6814 
[epoch 16] step 24/44: loss=0.6768 
[epoch 16] step 26/44: loss=0.6762 
[epoch 16] step 28/44: loss=0.6753 
[epoch 16] step 30/44: loss=0.6777 
[epoch 16] step 32/44: loss=0.6784 
[epoch 16] step 34/44: loss=0.6775 
[epoch 16] step 36/44: loss=0.6793 
[epoch 16] step 38/44: loss=0.6786 
[epoch 16] step 40/44: loss=0.6788 
[epoch 16] step 42/44: loss=0.6775 
[epoch 16] step 44/44: loss=0.6775 
[epoch 16] train_loss(avg per step)=1.3549 lambda[min,max]=[0.389603,1.000000]
[epoch 16] val_loss=1.5546 qwk=('0.1667', '0.3466', '0.2874') averageQWK=0.2669 macroEMD=0.3107 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    9   60    7    2
     0    2  117   40    3
     0    1   48   13    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    9    6    1    0
     0   13   32   21    0
     0   10   96   99    0
     0    1   10   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   10   19    0    0
     0    9   97    5    0
     0    3  139   39    0
     0    0    1    0    0
[epoch 17] step 2/44: loss=0.6924 
[epoch 17] step 4/44: loss=0.6918 
[epoch 17] step 6/44: loss=0.6958 
[epoch 17] step 8/44: loss=0.6863 
[epoch 17] step 10/44: loss=0.6853 
[epoch 17] step 12/44: loss=0.6750 
[epoch 17] step 14/44: loss=0.6738 
[epoch 17] step 16/44: loss=0.6689 
[epoch 17] step 18/44: loss=0.6671 
[epoch 17] step 20/44: loss=0.6624 
[epoch 17] step 22/44: loss=0.6628 
[epoch 17] step 24/44: loss=0.6592 
[epoch 17] step 26/44: loss=0.6620 
[epoch 17] step 28/44: loss=0.6656 
[epoch 17] step 30/44: loss=0.6628 
[epoch 17] step 32/44: loss=0.6630 
[epoch 17] step 34/44: loss=0.6642 
[epoch 17] step 36/44: loss=0.6641 
[epoch 17] step 38/44: loss=0.6652 
[epoch 17] step 40/44: loss=0.6664 
[epoch 17] step 42/44: loss=0.6664 
[epoch 17] step 44/44: loss=0.6653 
[epoch 17] train_loss(avg per step)=1.3306 lambda[min,max]=[0.386527,1.000000]
[epoch 17] val_loss=1.5033 qwk=('0.3262', '0.2970', '0.2852') averageQWK=0.3028 macroEMD=0.3140 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0   10   48   19    1
     0    1   75   84    2
     0    1   25   36    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    9    0    0
     0    9   38   19    0
     0    6  125   74    0
     0    1   12   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   17    0    0
     0   14   92    5    0
     0    3  146   32    0
     0    0    1    0    0
[epoch 18] step 2/44: loss=0.6071 
[epoch 18] step 4/44: loss=0.6315 
[epoch 18] step 6/44: loss=0.6532 
[epoch 18] step 8/44: loss=0.6610 
[epoch 18] step 10/44: loss=0.6599 
[epoch 18] step 12/44: loss=0.6608 
[epoch 18] step 14/44: loss=0.6581 
[epoch 18] step 16/44: loss=0.6547 
[epoch 18] step 18/44: loss=0.6530 
[epoch 18] step 20/44: loss=0.6517 
[epoch 18] step 22/44: loss=0.6471 
[epoch 18] step 24/44: loss=0.6462 
[epoch 18] step 26/44: loss=0.6431 
[epoch 18] step 28/44: loss=0.6438 
[epoch 18] step 30/44: loss=0.6436 
[epoch 18] step 32/44: loss=0.6466 
[epoch 18] step 34/44: loss=0.6498 
[epoch 18] step 36/44: loss=0.6518 
[epoch 18] step 38/44: loss=0.6520 
[epoch 18] step 40/44: loss=0.6504 
[epoch 18] step 42/44: loss=0.6493 
[epoch 18] step 44/44: loss=0.6493 
[epoch 18] train_loss(avg per step)=1.2985 lambda[min,max]=[0.366782,1.000000]
[epoch 18] val_loss=1.4262 qwk=('0.2921', '0.2803', '0.3394') averageQWK=0.3039 macroEMD=0.3076 tailR0=('0.0156', '0.0833', '0.0000') tailR0avg=0.0330
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    6    3    0
     0    9   31   37    1
     0    8   44  107    3
     0    2   18   42    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    1   13    2    0
     0    3   40   23    0
     0    1  107   95    2
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0   24   77   10    0
     0   12  113   56    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=0.6388 
[epoch 19] step 4/44: loss=0.6521 
[epoch 19] step 6/44: loss=0.6615 
[epoch 19] step 8/44: loss=0.6633 
[epoch 19] step 10/44: loss=0.6602 
[epoch 19] step 12/44: loss=0.6580 
[epoch 19] step 14/44: loss=0.6564 
[epoch 19] step 16/44: loss=0.6571 
[epoch 19] step 18/44: loss=0.6603 
[epoch 19] step 20/44: loss=0.6585 
[epoch 19] step 22/44: loss=0.6547 
[epoch 19] step 24/44: loss=0.6507 
[epoch 19] step 26/44: loss=0.6504 
[epoch 19] step 28/44: loss=0.6474 
[epoch 19] step 30/44: loss=0.6452 
[epoch 19] step 32/44: loss=0.6440 
[epoch 19] step 34/44: loss=0.6423 
[epoch 19] step 36/44: loss=0.6389 
[epoch 19] step 38/44: loss=0.6336 
[epoch 19] step 40/44: loss=0.6337 
[epoch 19] step 42/44: loss=0.6338 
[epoch 19] step 44/44: loss=0.6353 
[epoch 19] train_loss(avg per step)=1.2705 lambda[min,max]=[0.387528,1.000000]
[epoch 19] val_loss=1.4635 qwk=('0.2923', '0.2858', '0.3408') averageQWK=0.3063 macroEMD=0.3061 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    2   12    1    0
     0    5   51   22    0
     0    2   69   90    1
     0    0   26   36    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    2   12    2    0
     0    5   38   23    0
     0    1  101  103    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   11   18    0    0
     0   10   89   12    0
     0    8  111   62    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=0.6526 
[epoch 20] step 4/44: loss=0.6626 
[epoch 20] step 6/44: loss=0.6710 
[epoch 20] step 8/44: loss=0.6749 
[epoch 20] step 10/44: loss=0.6745 
[epoch 20] step 12/44: loss=0.6658 
[epoch 20] step 14/44: loss=0.6565 
[epoch 20] step 16/44: loss=0.6474 
[epoch 20] step 18/44: loss=0.6444 
[epoch 20] step 20/44: loss=0.6439 
[epoch 20] step 22/44: loss=0.6429 
[epoch 20] step 24/44: loss=0.6405 
[epoch 20] step 26/44: loss=0.6377 
[epoch 20] step 28/44: loss=0.6362 
[epoch 20] step 30/44: loss=0.6366 
[epoch 20] step 32/44: loss=0.6355 
[epoch 20] step 34/44: loss=0.6332 
[epoch 20] step 36/44: loss=0.6319 
[epoch 20] step 38/44: loss=0.6326 
[epoch 20] step 40/44: loss=0.6322 
[epoch 20] step 42/44: loss=0.6318 
[epoch 20] step 44/44: loss=0.6329 
[epoch 20] train_loss(avg per step)=1.2658 lambda[min,max]=[0.382495,1.000000]
[epoch 20] val_loss=1.5049 qwk=('0.3018', '0.2814', '0.2576') averageQWK=0.2803 macroEMD=0.3158 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    6    1    0
     0   13   45   19    1
     0    2   85   70    5
     0    2   29   30    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    4   12    0    0
     0    8   39   19    0
     0    5  121   78    1
     0    0   13   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   16    0    0
     0   17   89    5    0
     0    7  147   27    0
     0    0    1    0    0
[epoch 21] step 2/44: loss=0.6308 
[epoch 21] step 4/44: loss=0.6390 
[epoch 21] step 6/44: loss=0.6260 
[epoch 21] step 8/44: loss=0.6323 
[epoch 21] step 10/44: loss=0.6241 
[epoch 21] step 12/44: loss=0.6193 
[epoch 21] step 14/44: loss=0.6168 
[epoch 21] step 16/44: loss=0.6194 
[epoch 21] step 18/44: loss=0.6194 
[epoch 21] step 20/44: loss=0.6223 
[epoch 21] step 22/44: loss=0.6242 
[epoch 21] step 24/44: loss=0.6220 
[epoch 21] step 26/44: loss=0.6171 
[epoch 21] step 28/44: loss=0.6108 
[epoch 21] step 30/44: loss=0.6094 
[epoch 21] step 32/44: loss=0.6079 
[epoch 21] step 34/44: loss=0.6061 
[epoch 21] step 36/44: loss=0.6060 
[epoch 21] step 38/44: loss=0.6060 
[epoch 21] step 40/44: loss=0.6060 
[epoch 21] step 42/44: loss=0.6064 
[epoch 21] step 44/44: loss=0.6077 
[epoch 21] train_loss(avg per step)=1.2154 lambda[min,max]=[0.381627,1.000000]
[epoch 21] val_loss=1.4687 qwk=('0.2317', '0.2947', '0.3298') averageQWK=0.2854 macroEMD=0.3083 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    8   48   22    0
     0    2   86   71    3
     0    1   33   28    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2   13    1    0
     1    5   42   18    0
     0    1  120   84    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   11   18    0    0
     0    9   93    9    0
     0    4  127   50    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=0.6418 
[epoch 22] step 4/44: loss=0.6432 
[epoch 22] step 6/44: loss=0.6335 
[epoch 22] step 8/44: loss=0.6406 
[epoch 22] step 10/44: loss=0.6455 
[epoch 22] step 12/44: loss=0.6387 
[epoch 22] step 14/44: loss=0.6321 
[epoch 22] step 16/44: loss=0.6284 
[epoch 22] step 18/44: loss=0.6278 
[epoch 22] step 20/44: loss=0.6269 
[epoch 22] step 22/44: loss=0.6245 
[epoch 22] step 24/44: loss=0.6210 
[epoch 22] step 26/44: loss=0.6175 
[epoch 22] step 28/44: loss=0.6164 
[epoch 22] step 30/44: loss=0.6161 
[epoch 22] step 32/44: loss=0.6125 
[epoch 22] step 34/44: loss=0.6078 
[epoch 22] step 36/44: loss=0.6060 
[epoch 22] step 38/44: loss=0.6066 
[epoch 22] step 40/44: loss=0.6090 
[epoch 22] step 42/44: loss=0.6094 
[epoch 22] step 44/44: loss=0.6117 
[epoch 22] train_loss(avg per step)=1.2234 lambda[min,max]=[0.357138,1.000000]
[epoch 22] val_loss=1.4213 qwk=('0.1528', '0.3131', '0.2725') averageQWK=0.2462 macroEMD=0.3155 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    6   52   19    1
     0    3  106   51    2
     0    0   43   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2   12    2    0
     0    5   35   26    0
     0    2   94  109    0
     0    0    9   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   11   18    0    0
     0   18   87    6    0
     0   10  133   38    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=0.6720 
[epoch 23] step 4/44: loss=0.6347 
[epoch 23] step 6/44: loss=0.6197 
[epoch 23] step 8/44: loss=0.6219 
[epoch 23] step 10/44: loss=0.6248 
[epoch 23] step 12/44: loss=0.6240 
[epoch 23] step 14/44: loss=0.6284 
[epoch 23] step 16/44: loss=0.6241 
[epoch 23] step 18/44: loss=0.6207 
[epoch 23] step 20/44: loss=0.6135 
[epoch 23] step 22/44: loss=0.6099 
[epoch 23] step 24/44: loss=0.6069 
[epoch 23] step 26/44: loss=0.6053 
[epoch 23] step 28/44: loss=0.6062 
[epoch 23] step 30/44: loss=0.6070 
[epoch 23] step 32/44: loss=0.6069 
[epoch 23] step 34/44: loss=0.6065 
[epoch 23] step 36/44: loss=0.6035 
[epoch 23] step 38/44: loss=0.6035 
[epoch 23] step 40/44: loss=0.6064 
[epoch 23] step 42/44: loss=0.6060 
[epoch 23] step 44/44: loss=0.6055 
[epoch 23] train_loss(avg per step)=1.2111 lambda[min,max]=[0.368290,1.000000]
[epoch 23] val_loss=1.4485 qwk=('0.2070', '0.2739', '0.2869') averageQWK=0.2560 macroEMD=0.3160 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    5    9    1    0
     0   11   51   15    1
     0    4   96   59    3
     0    1   40   21    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2   14    0    0
     0    6   44   16    0
     0    3  126   75    1
     0    0   13   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   17    0    0
     0   19   86    6    0
     0   11  129   41    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=0.6272 
[epoch 24] step 4/44: loss=0.6198 
[epoch 24] step 6/44: loss=0.6051 
[epoch 24] step 8/44: loss=0.6049 
[epoch 24] step 10/44: loss=0.6117 
[epoch 24] step 12/44: loss=0.6061 
[epoch 24] step 14/44: loss=0.6002 
[epoch 24] step 16/44: loss=0.5960 
[epoch 24] step 18/44: loss=0.5930 
[epoch 24] step 20/44: loss=0.5956 
[epoch 24] step 22/44: loss=0.5991 
[epoch 24] step 24/44: loss=0.5970 
[epoch 24] step 26/44: loss=0.5982 
[epoch 24] step 28/44: loss=0.5968 
[epoch 24] step 30/44: loss=0.5954 
[epoch 24] step 32/44: loss=0.5963 
[epoch 24] step 34/44: loss=0.5952 
[epoch 24] step 36/44: loss=0.5931 
[epoch 24] step 38/44: loss=0.5939 
[epoch 24] step 40/44: loss=0.5934 
[epoch 24] step 42/44: loss=0.5956 
[epoch 24] step 44/44: loss=0.5974 
[epoch 24] train_loss(avg per step)=1.1947 lambda[min,max]=[0.359065,1.000000]
[epoch 24] val_loss=1.4190 qwk=('0.2112', '0.3222', '0.3182') averageQWK=0.2839 macroEMD=0.3116 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    8    1    0
     0   15   50   12    1
     0    5  103   52    2
     0    2   42   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   11    1    0
     0    9   38   19    0
     0    5  110   90    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0   20   85    6    0
     0   12  122   47    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=0.5817 
[epoch 25] step 4/44: loss=0.5707 
[epoch 25] step 6/44: loss=0.5734 
[epoch 25] step 8/44: loss=0.5687 
[epoch 25] step 10/44: loss=0.5680 
[epoch 25] step 12/44: loss=0.5617 
[epoch 25] step 14/44: loss=0.5667 
[epoch 25] step 16/44: loss=0.5709 
[epoch 25] step 18/44: loss=0.5763 
[epoch 25] step 20/44: loss=0.5769 
[epoch 25] step 22/44: loss=0.5823 
[epoch 25] step 24/44: loss=0.5799 
[epoch 25] step 26/44: loss=0.5795 
[epoch 25] step 28/44: loss=0.5816 
[epoch 25] step 30/44: loss=0.5807 
[epoch 25] step 32/44: loss=0.5814 
[epoch 25] step 34/44: loss=0.5842 
[epoch 25] step 36/44: loss=0.5858 
[epoch 25] step 38/44: loss=0.5873 
[epoch 25] step 40/44: loss=0.5892 
[epoch 25] step 42/44: loss=0.5887 
[epoch 25] step 44/44: loss=0.5876 
[epoch 25] train_loss(avg per step)=1.1752 lambda[min,max]=[0.378756,1.000000]
[epoch 25] val_loss=1.3369 qwk=('0.1243', '0.3362', '0.2720') averageQWK=0.2442 macroEMD=0.3270 tailR0=('0.0156', '0.0833', '0.0000') tailR0avg=0.0330
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    2   12    1    0
     1    2   62   12    1
     0    1  117   42    2
     0    0   49   13    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    2   13    1    0
     1    6   37   22    0
     0    3  103   99    0
     0    0   10   20    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   11   18    0    0
     0   14   94    3    0
     0    5  144   32    0
     0    0    1    0    0
[epoch 26] step 2/44: loss=0.5577 
[epoch 26] step 4/44: loss=0.5541 
[epoch 26] step 6/44: loss=0.5609 
[epoch 26] step 8/44: loss=0.5651 
[epoch 26] step 10/44: loss=0.5787 
[epoch 26] step 12/44: loss=0.5821 
[epoch 26] step 14/44: loss=0.5864 
[epoch 26] step 16/44: loss=0.5862 
[epoch 26] step 18/44: loss=0.5849 
[epoch 26] step 20/44: loss=0.5846 
[epoch 26] step 22/44: loss=0.5858 
[epoch 26] step 24/44: loss=0.5850 
[epoch 26] step 26/44: loss=0.5848 
[epoch 26] step 28/44: loss=0.5828 
[epoch 26] step 30/44: loss=0.5840 
[epoch 26] step 32/44: loss=0.5823 
[epoch 26] step 34/44: loss=0.5814 
[epoch 26] step 36/44: loss=0.5813 
[epoch 26] step 38/44: loss=0.5819 
[epoch 26] step 40/44: loss=0.5826 
[epoch 26] step 42/44: loss=0.5815 
[epoch 26] step 44/44: loss=0.5807 
[epoch 26] train_loss(avg per step)=1.1614 lambda[min,max]=[0.350658,1.000000]
[epoch 26] val_loss=1.4018 qwk=('0.1602', '0.3474', '0.2847') averageQWK=0.2641 macroEMD=0.3128 tailR0=('0.0156', '0.0833', '0.0000') tailR0avg=0.0330
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0   11   52   14    1
     0    4  112   43    3
     0    2   45   15    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    4   11    1    0
     0    7   38   21    0
     0    5   97  103    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   16    0    0
     0   19   84    8    0
     0   13  125   43    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=0.6221 
[epoch 27] step 4/44: loss=0.6108 
[epoch 27] step 6/44: loss=0.6152 
[epoch 27] step 8/44: loss=0.6037 
[epoch 27] step 10/44: loss=0.6030 
[epoch 27] step 12/44: loss=0.6049 
[epoch 27] step 14/44: loss=0.6030 
[epoch 27] step 16/44: loss=0.5981 
[epoch 27] step 18/44: loss=0.5958 
[epoch 27] step 20/44: loss=0.5894 
[epoch 27] step 22/44: loss=0.5908 
[epoch 27] step 24/44: loss=0.5906 
[epoch 27] step 26/44: loss=0.5886 
[epoch 27] step 28/44: loss=0.5854 
[epoch 27] step 30/44: loss=0.5828 
[epoch 27] step 32/44: loss=0.5796 
[epoch 27] step 34/44: loss=0.5802 
[epoch 27] step 36/44: loss=0.5793 
[epoch 27] step 38/44: loss=0.5780 
[epoch 27] step 40/44: loss=0.5767 
[epoch 27] step 42/44: loss=0.5745 
[epoch 27] step 44/44: loss=0.5754 
[epoch 27] train_loss(avg per step)=1.1508 lambda[min,max]=[0.357770,1.000000]
[epoch 27] val_loss=1.3609 qwk=('0.1756', '0.3291', '0.2973') averageQWK=0.2673 macroEMD=0.3176 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    9   51   17    1
     0    2  108   46    6
     0    2   42   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    3   11    2    0
     1    6   36   23    0
     0    2   97  105    1
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    9   20    0    0
     0   12   91    8    0
     0    9  120   52    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=0.5930 
[epoch 28] step 4/44: loss=0.5964 
[epoch 28] step 6/44: loss=0.5984 
[epoch 28] step 8/44: loss=0.6043 
[epoch 28] step 10/44: loss=0.6025 
[epoch 28] step 12/44: loss=0.5944 
[epoch 28] step 14/44: loss=0.5894 
[epoch 28] step 16/44: loss=0.5921 
[epoch 28] step 18/44: loss=0.5927 
[epoch 28] step 20/44: loss=0.5836 
[epoch 28] step 22/44: loss=0.5820 
[epoch 28] step 24/44: loss=0.5795 
[epoch 28] step 26/44: loss=0.5798 
[epoch 28] step 28/44: loss=0.5787 
[epoch 28] step 30/44: loss=0.5796 
[epoch 28] step 32/44: loss=0.5796 
[epoch 28] step 34/44: loss=0.5802 
[epoch 28] step 36/44: loss=0.5813 
[epoch 28] step 38/44: loss=0.5813 
[epoch 28] step 40/44: loss=0.5816 
[epoch 28] step 42/44: loss=0.5795 
[epoch 28] step 44/44: loss=0.5786 
[epoch 28] train_loss(avg per step)=1.1573 lambda[min,max]=[0.353791,1.000000]
[epoch 28] val_loss=1.3480 qwk=('0.1805', '0.3352', '0.2927') averageQWK=0.2695 macroEMD=0.3185 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   11    0    0
     0    9   54   14    1
     1    4  106   42    9
     0    1   45   15    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    3   11    2    0
     0    7   35   24    0
     0    2   96  106    1
     0    0   10   20    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   16    0    0
     0   19   86    6    0
     0   12  127   42    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=0.5539 
[epoch 29] step 4/44: loss=0.5645 
[epoch 29] step 6/44: loss=0.5578 
[epoch 29] step 8/44: loss=0.5571 
[epoch 29] step 10/44: loss=0.5569 
[epoch 29] step 12/44: loss=0.5631 
[epoch 29] step 14/44: loss=0.5661 
[epoch 29] step 16/44: loss=0.5697 
[epoch 29] step 18/44: loss=0.5748 
[epoch 29] step 20/44: loss=0.5773 
[epoch 29] step 22/44: loss=0.5728 
[epoch 29] step 24/44: loss=0.5718 
[epoch 29] step 26/44: loss=0.5703 
[epoch 29] step 28/44: loss=0.5706 
[epoch 29] step 30/44: loss=0.5727 
[epoch 29] step 32/44: loss=0.5734 
[epoch 29] step 34/44: loss=0.5748 
[epoch 29] step 36/44: loss=0.5748 
[epoch 29] step 38/44: loss=0.5743 
[epoch 29] step 40/44: loss=0.5737 
[epoch 29] step 42/44: loss=0.5721 
[epoch 29] step 44/44: loss=0.5738 
[epoch 29] train_loss(avg per step)=1.1476 lambda[min,max]=[0.374568,1.000000]
[epoch 29] val_loss=1.3328 qwk=('0.1766', '0.3177', '0.3044') averageQWK=0.2663 macroEMD=0.3190 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0   10   51   16    1
     0    4  103   48    7
     0    2   42   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4    9    3    0
     0    7   35   23    1
     0    5   96  103    1
     0    0    9   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   11   18    0    0
     0   11   92    8    0
     0    6  130   45    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=0.5480 
[epoch 30] step 4/44: loss=0.5489 
[epoch 30] step 6/44: loss=0.5526 
[epoch 30] step 8/44: loss=0.5472 
[epoch 30] step 10/44: loss=0.5468 
[epoch 30] step 12/44: loss=0.5512 
[epoch 30] step 14/44: loss=0.5577 
[epoch 30] step 16/44: loss=0.5631 
[epoch 30] step 18/44: loss=0.5669 
[epoch 30] step 20/44: loss=0.5681 
[epoch 30] step 22/44: loss=0.5686 
[epoch 30] step 24/44: loss=0.5669 
[epoch 30] step 26/44: loss=0.5657 
[epoch 30] step 28/44: loss=0.5645 
[epoch 30] step 30/44: loss=0.5645 
[epoch 30] step 32/44: loss=0.5649 
[epoch 30] step 34/44: loss=0.5663 
[epoch 30] step 36/44: loss=0.5659 
[epoch 30] step 38/44: loss=0.5628 
[epoch 30] step 40/44: loss=0.5634 
[epoch 30] step 42/44: loss=0.5662 
[epoch 30] step 44/44: loss=0.5690 
[epoch 30] train_loss(avg per step)=1.1380 lambda[min,max]=[0.382795,1.000000]
[epoch 30] val_loss=1.3504 qwk=('0.1513', '0.3374', '0.2785') averageQWK=0.2557 macroEMD=0.3200 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     1    6   56   14    1
     0    3  112   44    3
     0    1   45   16    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6    8    2    0
     0   10   35   21    0
     0    6   99  100    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   17    0    0
     0   14   91    6    0
     0   12  127   42    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=0.5621 
[epoch 31] step 4/44: loss=0.5567 
[epoch 31] step 6/44: loss=0.5599 
[epoch 31] step 8/44: loss=0.5549 
[epoch 31] step 10/44: loss=0.5599 
[epoch 31] step 12/44: loss=0.5602 
[epoch 31] step 14/44: loss=0.5665 
[epoch 31] step 16/44: loss=0.5631 
[epoch 31] step 18/44: loss=0.5640 
[epoch 31] step 20/44: loss=0.5657 
[epoch 31] step 22/44: loss=0.5668 
[epoch 31] step 24/44: loss=0.5701 
[epoch 31] step 26/44: loss=0.5693 
[epoch 31] step 28/44: loss=0.5713 
[epoch 31] step 30/44: loss=0.5726 
[epoch 31] step 32/44: loss=0.5698 
[epoch 31] step 34/44: loss=0.5680 
[epoch 31] step 36/44: loss=0.5659 
[epoch 31] step 38/44: loss=0.5668 
[epoch 31] step 40/44: loss=0.5667 
[epoch 31] step 42/44: loss=0.5647 
[epoch 31] step 44/44: loss=0.5631 
[epoch 31] train_loss(avg per step)=1.1262 lambda[min,max]=[0.376445,1.000000]
[epoch 31] val_loss=1.3260 qwk=('0.1739', '0.3055', '0.2734') averageQWK=0.2509 macroEMD=0.3223 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     1    7   52   17    1
     0    4  101   54    3
     0    1   41   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    3   12    1    0
     1    6   37   22    0
     0    4  103   98    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   17    0    0
     0   18   87    6    0
     0   12  130   39    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=0.5490 
[epoch 32] step 4/44: loss=0.5515 
[epoch 32] step 6/44: loss=0.5622 
[epoch 32] step 8/44: loss=0.5595 
[epoch 32] step 10/44: loss=0.5577 
[epoch 32] step 12/44: loss=0.5574 
[epoch 32] step 14/44: loss=0.5608 
[epoch 32] step 16/44: loss=0.5656 
[epoch 32] step 18/44: loss=0.5649 
[epoch 32] step 20/44: loss=0.5605 
[epoch 32] step 22/44: loss=0.5608 
[epoch 32] step 24/44: loss=0.5613 
[epoch 32] step 26/44: loss=0.5576 
[epoch 32] step 28/44: loss=0.5588 
[epoch 32] step 30/44: loss=0.5604 
[epoch 32] step 32/44: loss=0.5579 
[epoch 32] step 34/44: loss=0.5593 
[epoch 32] step 36/44: loss=0.5610 
[epoch 32] step 38/44: loss=0.5618 
[epoch 32] step 40/44: loss=0.5636 
[epoch 32] step 42/44: loss=0.5648 
[epoch 32] step 44/44: loss=0.5672 
[epoch 32] train_loss(avg per step)=1.1345 lambda[min,max]=[0.378579,1.000000]
[epoch 32] val_loss=1.3295 qwk=('0.1744', '0.2979', '0.2953') averageQWK=0.2559 macroEMD=0.3167 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    8   55   14    1
     0    4  106   48    4
     0    2   42   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    3   11    2    0
     0    8   35   23    0
     0    4  101   99    1
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   17    0    0
     0   13   90    8    0
     0   12  120   49    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=0.5750 
[epoch 33] step 4/44: loss=0.5736 
[epoch 33] step 6/44: loss=0.5691 
[epoch 33] step 8/44: loss=0.5707 
[epoch 33] step 10/44: loss=0.5665 
[epoch 33] step 12/44: loss=0.5685 
[epoch 33] step 14/44: loss=0.5674 
[epoch 33] step 16/44: loss=0.5663 
[epoch 33] step 18/44: loss=0.5680 
[epoch 33] step 20/44: loss=0.5655 
[epoch 33] step 22/44: loss=0.5661 
[epoch 33] step 24/44: loss=0.5623 
[epoch 33] step 26/44: loss=0.5595 
[epoch 33] step 28/44: loss=0.5593 
[epoch 33] step 30/44: loss=0.5607 
[epoch 33] step 32/44: loss=0.5608 
[epoch 33] step 34/44: loss=0.5599 
[epoch 33] step 36/44: loss=0.5599 
[epoch 33] step 38/44: loss=0.5613 
[epoch 33] step 40/44: loss=0.5619 
[epoch 33] step 42/44: loss=0.5601 
[epoch 33] step 44/44: loss=0.5587 
[epoch 33] train_loss(avg per step)=1.1173 lambda[min,max]=[0.361393,1.000000]
[epoch 33] val_loss=1.3175 qwk=('0.1791', '0.3029', '0.3024') averageQWK=0.2615 macroEMD=0.3180 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   11    1    0
     0    7   53   17    1
     0    4   98   56    4
     0    2   39   21    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2   13    1    0
     0    5   38   23    0
     0    3   99  102    1
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   17    0    0
     0   14   90    7    0
     0    9  127   45    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=0.5805 
[epoch 34] step 4/44: loss=0.5952 
[epoch 34] step 6/44: loss=0.5758 
[epoch 34] step 8/44: loss=0.5742 
[epoch 34] step 10/44: loss=0.5789 
[epoch 34] step 12/44: loss=0.5767 
[epoch 34] step 14/44: loss=0.5777 
[epoch 34] step 16/44: loss=0.5808 
[epoch 34] step 18/44: loss=0.5829 
[epoch 34] step 20/44: loss=0.5810 
[epoch 34] step 22/44: loss=0.5755 
[epoch 34] step 24/44: loss=0.5740 
[epoch 34] step 26/44: loss=0.5737 
[epoch 34] step 28/44: loss=0.5719 
[epoch 34] step 30/44: loss=0.5720 
[epoch 34] step 32/44: loss=0.5726 
[epoch 34] step 34/44: loss=0.5735 
[epoch 34] step 36/44: loss=0.5722 
[epoch 34] step 38/44: loss=0.5712 
[epoch 34] step 40/44: loss=0.5723 
[epoch 34] step 42/44: loss=0.5720 
[epoch 34] step 44/44: loss=0.5716 
[epoch 34] train_loss(avg per step)=1.1431 lambda[min,max]=[0.371003,1.000000]
[epoch 34] val_loss=1.3189 qwk=('0.1614', '0.3324', '0.2934') averageQWK=0.2624 macroEMD=0.3210 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    7   56   14    1
     0    4  108   47    3
     0    1   43   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    3   12    1    0
     0    8   37   21    0
     0    4   99  102    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   11   18    0    0
     0   13   91    7    0
     0    7  132   42    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=0.5371 
[epoch 35] step 4/44: loss=0.5204 
[epoch 35] step 6/44: loss=0.5113 
[epoch 35] step 8/44: loss=0.5170 
[epoch 35] step 10/44: loss=0.5189 
[epoch 35] step 12/44: loss=0.5228 
[epoch 35] step 14/44: loss=0.5279 
[epoch 35] step 16/44: loss=0.5329 
[epoch 35] step 18/44: loss=0.5330 
[epoch 35] step 20/44: loss=0.5309 
[epoch 35] step 22/44: loss=0.5322 
[epoch 35] step 24/44: loss=0.5367 
[epoch 35] step 26/44: loss=0.5382 
[epoch 35] step 28/44: loss=0.5369 
[epoch 35] step 30/44: loss=0.5373 
[epoch 35] step 32/44: loss=0.5379 
[epoch 35] step 34/44: loss=0.5400 
[epoch 35] step 36/44: loss=0.5376 
[epoch 35] step 38/44: loss=0.5391 
[epoch 35] step 40/44: loss=0.5408 
[epoch 35] step 42/44: loss=0.5424 
[epoch 35] step 44/44: loss=0.5438 
[epoch 35] train_loss(avg per step)=1.0877 lambda[min,max]=[0.366666,1.000000]
[epoch 35] val_loss=1.3222 qwk=('0.1712', '0.3148', '0.2934') averageQWK=0.2598 macroEMD=0.3205 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   11    1    0
     0    7   53   17    1
     0    4  100   55    3
     0    2   40   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    3   12    1    0
     1    6   39   20    0
     0    3  105   97    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   11   18    0    0
     0   13   91    7    0
     0    7  132   42    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-1/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-1/fold0/metrics.json
Done.
