[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.7137 
[epoch 1] step 4/44: loss=0.7173 
[epoch 1] step 6/44: loss=0.7124 
[epoch 1] step 8/44: loss=0.7073 
[epoch 1] step 10/44: loss=0.7110 
[epoch 1] step 12/44: loss=0.7116 
[epoch 1] step 14/44: loss=0.7102 
[epoch 1] step 16/44: loss=0.7116 
[epoch 1] step 18/44: loss=0.7142 
[epoch 1] step 20/44: loss=0.7174 
[epoch 1] step 22/44: loss=0.7186 
[epoch 1] step 24/44: loss=0.7183 
[epoch 1] step 26/44: loss=0.7180 
[epoch 1] step 28/44: loss=0.7163 
[epoch 1] step 30/44: loss=0.7145 
[epoch 1] step 32/44: loss=0.7136 
[epoch 1] step 34/44: loss=0.7122 
[epoch 1] step 36/44: loss=0.7119 
[epoch 1] step 38/44: loss=0.7103 
[epoch 1] step 40/44: loss=0.7107 
[epoch 1] step 42/44: loss=0.7139 
[epoch 1] step 44/44: loss=0.7196 
[epoch 1] train_loss(avg per step)=1.4393 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.7888 qwk=('-0.0059', '0.1284', '0.1105') averageQWK=0.0777 macroEMD=0.3658 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    8    0
     0    2    0   38    0
     0    8    0  120    0
     0   10    0  112    0
     0    0    0   27    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   42    6    0
     3    0   86   24    0
     3    0  105   40    0
     0    0    3    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    9   62    0    0
     0    4  147    0    0
     0    0   98    1    0
     0    0    3    0    0
[epoch 2] step 2/44: loss=0.8872 
[epoch 2] step 4/44: loss=0.9528 
[epoch 2] step 6/44: loss=0.9843 
[epoch 2] step 8/44: loss=0.9988 
[epoch 2] step 10/44: loss=1.0202 
[epoch 2] step 12/44: loss=1.0244 
[epoch 2] step 14/44: loss=1.0167 
[epoch 2] step 16/44: loss=0.9965 
[epoch 2] step 18/44: loss=0.9738 
[epoch 2] step 20/44: loss=0.9549 
[epoch 2] step 22/44: loss=0.9395 
[epoch 2] step 24/44: loss=0.9280 
[epoch 2] step 26/44: loss=0.9164 
[epoch 2] step 28/44: loss=0.9075 
[epoch 2] step 30/44: loss=0.9034 
[epoch 2] step 32/44: loss=0.9017 
[epoch 2] step 34/44: loss=0.8979 
[epoch 2] step 36/44: loss=0.8942 
[epoch 2] step 38/44: loss=0.8886 
[epoch 2] step 40/44: loss=0.8827 
[epoch 2] step 42/44: loss=0.8779 
[epoch 2] step 44/44: loss=0.8719 
[epoch 2] train_loss(avg per step)=1.7438 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.0917 qwk=('0.3614', '0.2071', '0.4373') averageQWK=0.3353 macroEMD=0.3459 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    0    1    0
     0   14    0   26    0
     0   15    0  113    0
     0    2    0  120    0
     0    0    0   27    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   15   33    0
     0    0   13  100    0
     0    0    2  146    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   42    6   23    0
     0   35   21   95    0
     0    4    4   91    0
     0    0    0    3    0
[epoch 3] step 2/44: loss=0.6910 
[epoch 3] step 4/44: loss=0.7122 
[epoch 3] step 6/44: loss=0.7197 
[epoch 3] step 8/44: loss=0.7213 
[epoch 3] step 10/44: loss=0.7340 
[epoch 3] step 12/44: loss=0.7492 
[epoch 3] step 14/44: loss=0.7614 
[epoch 3] step 16/44: loss=0.7709 
[epoch 3] step 18/44: loss=0.7755 
[epoch 3] step 20/44: loss=0.7785 
[epoch 3] step 22/44: loss=0.7770 
[epoch 3] step 24/44: loss=0.7865 
[epoch 3] step 26/44: loss=0.7890 
[epoch 3] step 28/44: loss=0.7903 
[epoch 3] step 30/44: loss=0.7915 
[epoch 3] step 32/44: loss=0.7928 
[epoch 3] step 34/44: loss=0.7952 
[epoch 3] step 36/44: loss=0.7959 
[epoch 3] step 38/44: loss=0.7978 
[epoch 3] step 40/44: loss=0.7987 
[epoch 3] step 42/44: loss=0.7961 
[epoch 3] step 44/44: loss=0.7940 
[epoch 3] train_loss(avg per step)=1.5880 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=1.4188 qwk=('0.5185', '0.4371', '0.5581') averageQWK=0.5046 macroEMD=0.3251 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   18   20    2    0
     0   20   91   17    0
     0    2   64   56    0
     0    0    6   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    4   37    7    0
     0    2   73   38    0
     0    2   41  105    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   38   32    1    0
     0   39   93   19    0
     0    2   40   57    0
     0    0    1    2    0
[epoch 4] step 2/44: loss=0.8179 
[epoch 4] step 4/44: loss=0.8248 
[epoch 4] step 6/44: loss=0.8315 
[epoch 4] step 8/44: loss=0.8430 
[epoch 4] step 10/44: loss=0.8416 
[epoch 4] step 12/44: loss=0.8447 
[epoch 4] step 14/44: loss=0.8376 
[epoch 4] step 16/44: loss=0.8272 
[epoch 4] step 18/44: loss=0.8202 
[epoch 4] step 20/44: loss=0.8241 
[epoch 4] step 22/44: loss=0.8239 
[epoch 4] step 24/44: loss=0.8216 
[epoch 4] step 26/44: loss=0.8203 
[epoch 4] step 28/44: loss=0.8193 
[epoch 4] step 30/44: loss=0.8237 
[epoch 4] step 32/44: loss=0.8244 
[epoch 4] step 34/44: loss=0.8241 
[epoch 4] step 36/44: loss=0.8263 
[epoch 4] step 38/44: loss=0.8280 
[epoch 4] step 40/44: loss=0.8265 
[epoch 4] step 42/44: loss=0.8266 
[epoch 4] step 44/44: loss=0.8240 
[epoch 4] train_loss(avg per step)=1.6480 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=1.5002 qwk=('0.4933', '0.3800', '0.5722') averageQWK=0.4819 macroEMD=0.3194 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    5   34    1    0
     0    3  106   19    0
     0    0   60   62    0
     0    0    6   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   39    9    0
     0    0   78   35    0
     0    0   49   99    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   30   40    1    0
     0   18  113   20    0
     0    1   40   58    0
     0    0    1    2    0
[epoch 5] step 2/44: loss=0.8195 
[epoch 5] step 4/44: loss=0.8040 
[epoch 5] step 6/44: loss=0.7897 
[epoch 5] step 8/44: loss=0.7876 
[epoch 5] step 10/44: loss=0.7903 
[epoch 5] step 12/44: loss=0.7902 
[epoch 5] step 14/44: loss=0.7938 
[epoch 5] step 16/44: loss=0.7937 
[epoch 5] step 18/44: loss=0.8009 
[epoch 5] step 20/44: loss=0.8089 
[epoch 5] step 22/44: loss=0.8068 
[epoch 5] step 24/44: loss=0.8085 
[epoch 5] step 26/44: loss=0.8048 
[epoch 5] step 28/44: loss=0.8011 
[epoch 5] step 30/44: loss=0.7963 
[epoch 5] step 32/44: loss=0.7950 
[epoch 5] step 34/44: loss=0.7949 
[epoch 5] step 36/44: loss=0.7956 
[epoch 5] step 38/44: loss=0.7956 
[epoch 5] step 40/44: loss=0.7968 
[epoch 5] step 42/44: loss=0.7984 
[epoch 5] step 44/44: loss=0.8004 
[epoch 5] train_loss(avg per step)=1.6008 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=1.4388 qwk=('0.4835', '0.4794', '0.5193') averageQWK=0.4940 macroEMD=0.3088 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    4   25   11    0
     0    2   60   66    0
     0    0   17  105    0
     0    0    0   27    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    8   25   15    0
     0    3   45   65    0
     0    0   16  132    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   49    6    0
     0    2   97   52    0
     0    0   20   79    0
     0    0    1    2    0
[epoch 6] step 2/44: loss=0.7950 
[epoch 6] step 4/44: loss=0.7853 
[epoch 6] step 6/44: loss=0.7978 
[epoch 6] step 8/44: loss=0.7918 
[epoch 6] step 10/44: loss=0.7891 
[epoch 6] step 12/44: loss=0.7898 
[epoch 6] step 14/44: loss=0.7973 
[epoch 6] step 16/44: loss=0.7999 
[epoch 6] step 18/44: loss=0.8000 
[epoch 6] step 20/44: loss=0.8040 
[epoch 6] step 22/44: loss=0.8095 
[epoch 6] step 24/44: loss=0.8153 
[epoch 6] step 26/44: loss=0.8204 
[epoch 6] step 28/44: loss=0.8200 
[epoch 6] step 30/44: loss=0.8183 
[epoch 6] step 32/44: loss=0.8154 
[epoch 6] step 34/44: loss=0.8128 
[epoch 6] step 36/44: loss=0.8114 
[epoch 6] step 38/44: loss=0.8081 
[epoch 6] step 40/44: loss=0.8080 
[epoch 6] step 42/44: loss=0.8075 
[epoch 6] step 44/44: loss=0.8042 
[epoch 6] train_loss(avg per step)=1.6085 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=1.4288 qwk=('0.4871', '0.4271', '0.5839') averageQWK=0.4994 macroEMD=0.3121 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    5   31    4    0
     0    3   97   28    0
     0    0   53   69    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    0   40    8    0
     0    0   81   32    0
     0    0   55   93    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   43   25    3    0
     0   34   89   28    0
     0    2   35   62    0
     0    0    1    2    0
[epoch 7] step 2/44: loss=0.7755 
[epoch 7] step 4/44: loss=0.7437 
[epoch 7] step 6/44: loss=0.7497 
[epoch 7] step 8/44: loss=0.7611 
[epoch 7] step 10/44: loss=0.7575 
[epoch 7] step 12/44: loss=0.7571 
[epoch 7] step 14/44: loss=0.7588 
[epoch 7] step 16/44: loss=0.7647 
[epoch 7] step 18/44: loss=0.7725 
[epoch 7] step 20/44: loss=0.7753 
[epoch 7] step 22/44: loss=0.7786 
[epoch 7] step 24/44: loss=0.7777 
[epoch 7] step 26/44: loss=0.7781 
[epoch 7] step 28/44: loss=0.7787 
[epoch 7] step 30/44: loss=0.7807 
[epoch 7] step 32/44: loss=0.7828 
[epoch 7] step 34/44: loss=0.7828 
[epoch 7] step 36/44: loss=0.7840 
[epoch 7] step 38/44: loss=0.7854 
[epoch 7] step 40/44: loss=0.7856 
[epoch 7] step 42/44: loss=0.7858 
[epoch 7] step 44/44: loss=0.7859 
[epoch 7] train_loss(avg per step)=1.5718 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.5275 qwk=('0.5119', '0.5461', '0.4635') averageQWK=0.5072 macroEMD=0.3049 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   10   28    2    0
     0   10   84   34    0
     0    2   47   73    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   11   32    5    0
     0    5   74   34    0
     0    0   50   98    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   21   50    0    0
     0    8  135    8    0
     0    0   65   34    0
     0    0    1    2    0
[epoch 8] step 2/44: loss=0.7971 
[epoch 8] step 4/44: loss=0.7819 
[epoch 8] step 6/44: loss=0.7744 
[epoch 8] step 8/44: loss=0.7770 
[epoch 8] step 10/44: loss=0.7692 
[epoch 8] step 12/44: loss=0.7670 
[epoch 8] step 14/44: loss=0.7711 
[epoch 8] step 16/44: loss=0.7678 
[epoch 8] step 18/44: loss=0.7700 
[epoch 8] step 20/44: loss=0.7747 
[epoch 8] step 22/44: loss=0.7751 
[epoch 8] step 24/44: loss=0.7736 
[epoch 8] step 26/44: loss=0.7758 
[epoch 8] step 28/44: loss=0.7764 
[epoch 8] step 30/44: loss=0.7764 
[epoch 8] step 32/44: loss=0.7779 
[epoch 8] step 34/44: loss=0.7777 
[epoch 8] step 36/44: loss=0.7757 
[epoch 8] step 38/44: loss=0.7747 
[epoch 8] step 40/44: loss=0.7742 
[epoch 8] step 42/44: loss=0.7751 
[epoch 8] step 44/44: loss=0.7759 
[epoch 8] train_loss(avg per step)=1.5518 lambda[min,max]=[0.482472,1.000000]
[epoch 8] val_loss=1.4575 qwk=('0.4591', '0.5499', '0.5780') averageQWK=0.5290 macroEMD=0.3002 tailR0=('0.0741', '0.0000', '0.0000') tailR0avg=0.0247
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    0    0
     0    5   33    2    0
     0    3  102   22    1
     0    0   65   54    3
     0    0    6   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   12   32    4    0
     0    2   80   31    0
     0    0   53   95    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   40    0    0
     0   16  114   21    0
     0    1   42   56    0
     0    0    1    2    0
[epoch 9] step 2/44: loss=0.7574 
[epoch 9] step 4/44: loss=0.7573 
[epoch 9] step 6/44: loss=0.7467 
[epoch 9] step 8/44: loss=0.7434 
[epoch 9] step 10/44: loss=0.7487 
[epoch 9] step 12/44: loss=0.7497 
[epoch 9] step 14/44: loss=0.7502 
[epoch 9] step 16/44: loss=0.7504 
[epoch 9] step 18/44: loss=0.7477 
[epoch 9] step 20/44: loss=0.7471 
[epoch 9] step 22/44: loss=0.7438 
[epoch 9] step 24/44: loss=0.7430 
[epoch 9] step 26/44: loss=0.7466 
[epoch 9] step 28/44: loss=0.7451 
[epoch 9] step 30/44: loss=0.7440 
[epoch 9] step 32/44: loss=0.7435 
[epoch 9] step 34/44: loss=0.7429 
[epoch 9] step 36/44: loss=0.7435 
[epoch 9] step 38/44: loss=0.7459 
[epoch 9] step 40/44: loss=0.7505 
[epoch 9] step 42/44: loss=0.7509 
[epoch 9] step 44/44: loss=0.7503 
[epoch 9] train_loss(avg per step)=1.5006 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.4333 qwk=('0.4781', '0.5024', '0.5139') averageQWK=0.4981 macroEMD=0.3041 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   18   19    3    0
     0   22   88   17    1
     0    3   63   56    0
     0    0   10   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   19   25    4    0
     0   15   75   23    0
     0    3   73   72    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   38   33    0    0
     0   26  115   10    0
     0    1   66   32    0
     0    0    1    2    0
[epoch 10] step 2/44: loss=0.7947 
[epoch 10] step 4/44: loss=0.7769 
[epoch 10] step 6/44: loss=0.7734 
[epoch 10] step 8/44: loss=0.7669 
[epoch 10] step 10/44: loss=0.7631 
[epoch 10] step 12/44: loss=0.7640 
[epoch 10] step 14/44: loss=0.7592 
[epoch 10] step 16/44: loss=0.7570 
[epoch 10] step 18/44: loss=0.7534 
[epoch 10] step 20/44: loss=0.7503 
[epoch 10] step 22/44: loss=0.7460 
[epoch 10] step 24/44: loss=0.7454 
[epoch 10] step 26/44: loss=0.7473 
[epoch 10] step 28/44: loss=0.7498 
[epoch 10] step 30/44: loss=0.7565 
[epoch 10] step 32/44: loss=0.7599 
[epoch 10] step 34/44: loss=0.7616 
[epoch 10] step 36/44: loss=0.7623 
[epoch 10] step 38/44: loss=0.7624 
[epoch 10] step 40/44: loss=0.7612 
[epoch 10] step 42/44: loss=0.7588 
[epoch 10] step 44/44: loss=0.7557 
[epoch 10] train_loss(avg per step)=1.5114 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.4274 qwk=('0.5080', '0.5061', '0.5620') averageQWK=0.5254 macroEMD=0.2934 tailR0=('0.0185', '0.0000', '0.0000') tailR0avg=0.0062
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   10   25    5    0
     0    7   82   39    0
     0    1   42   79    0
     0    0    4   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    9   31    8    0
     0    7   66   40    0
     0    1   44  103    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   34   36    1    0
     0   21  100   30    0
     0    1   41   57    0
     0    0    1    2    0
[epoch 11] step 2/44: loss=0.7289 
[epoch 11] step 4/44: loss=0.7233 
[epoch 11] step 6/44: loss=0.7244 
[epoch 11] step 8/44: loss=0.7298 
[epoch 11] step 10/44: loss=0.7356 
[epoch 11] step 12/44: loss=0.7312 
[epoch 11] step 14/44: loss=0.7314 
[epoch 11] step 16/44: loss=0.7320 
[epoch 11] step 18/44: loss=0.7368 
[epoch 11] step 20/44: loss=0.7390 
[epoch 11] step 22/44: loss=0.7390 
[epoch 11] step 24/44: loss=0.7410 
[epoch 11] step 26/44: loss=0.7420 
[epoch 11] step 28/44: loss=0.7381 
[epoch 11] step 30/44: loss=0.7376 
[epoch 11] step 32/44: loss=0.7369 
[epoch 11] step 34/44: loss=0.7353 
[epoch 11] step 36/44: loss=0.7330 
[epoch 11] step 38/44: loss=0.7310 
[epoch 11] step 40/44: loss=0.7321 
[epoch 11] step 42/44: loss=0.7326 
[epoch 11] step 44/44: loss=0.7355 
[epoch 11] train_loss(avg per step)=1.4709 lambda[min,max]=[0.422883,1.000000]
[epoch 11] val_loss=1.5249 qwk=('0.4765', '0.4652', '0.5090') averageQWK=0.4836 macroEMD=0.2927 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    0    0
     0    3   31    6    0
     0    2   79   47    0
     0    0   35   87    0
     0    0    1   26    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    2   36   10    0
     0    1   63   49    0
     0    0   34  114    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   55    1    0
     0    2  121   28    0
     0    0   41   58    0
     0    0    1    2    0
[epoch 12] step 2/44: loss=0.7532 
[epoch 12] step 4/44: loss=0.7371 
[epoch 12] step 6/44: loss=0.7216 
[epoch 12] step 8/44: loss=0.7272 
[epoch 12] step 10/44: loss=0.7242 
[epoch 12] step 12/44: loss=0.7265 
[epoch 12] step 14/44: loss=0.7259 
[epoch 12] step 16/44: loss=0.7247 
[epoch 12] step 18/44: loss=0.7243 
[epoch 12] step 20/44: loss=0.7258 
[epoch 12] step 22/44: loss=0.7312 
[epoch 12] step 24/44: loss=0.7318 
[epoch 12] step 26/44: loss=0.7324 
[epoch 12] step 28/44: loss=0.7326 
[epoch 12] step 30/44: loss=0.7317 
[epoch 12] step 32/44: loss=0.7307 
[epoch 12] step 34/44: loss=0.7265 
[epoch 12] step 36/44: loss=0.7238 
[epoch 12] step 38/44: loss=0.7213 
[epoch 12] step 40/44: loss=0.7204 
[epoch 12] step 42/44: loss=0.7218 
[epoch 12] step 44/44: loss=0.7227 
[epoch 12] train_loss(avg per step)=1.4455 lambda[min,max]=[0.476447,1.000000]
[epoch 12] val_loss=1.4909 qwk=('0.5590', '0.5508', '0.5198') averageQWK=0.5432 macroEMD=0.2857 tailR0=('0.0741', '0.0000', '0.0000') tailR0avg=0.0247
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   15   20    5    0
     0   16   77   34    1
     0    2   37   82    1
     0    0    3   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   17   25    6    0
     0   16   64   32    1
     0    2   46   99    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   21   50    0    0
     0   11  121   19    0
     0    1   46   52    0
     0    0    1    2    0
[epoch 13] step 2/44: loss=0.7541 
[epoch 13] step 4/44: loss=0.7409 
[epoch 13] step 6/44: loss=0.7303 
[epoch 13] step 8/44: loss=0.7387 
[epoch 13] step 10/44: loss=0.7362 
[epoch 13] step 12/44: loss=0.7307 
[epoch 13] step 14/44: loss=0.7188 
[epoch 13] step 16/44: loss=0.7034 
[epoch 13] step 18/44: loss=0.7024 
[epoch 13] step 20/44: loss=0.6978 
[epoch 13] step 22/44: loss=0.6970 
[epoch 13] step 24/44: loss=0.6945 
[epoch 13] step 26/44: loss=0.6972 
[epoch 13] step 28/44: loss=0.6950 
[epoch 13] step 30/44: loss=0.6937 
[epoch 13] step 32/44: loss=0.6938 
[epoch 13] step 34/44: loss=0.6956 
[epoch 13] step 36/44: loss=0.6979 
[epoch 13] step 38/44: loss=0.7014 
[epoch 13] step 40/44: loss=0.7051 
[epoch 13] step 42/44: loss=0.7051 
[epoch 13] step 44/44: loss=0.7065 
[epoch 13] train_loss(avg per step)=1.4129 lambda[min,max]=[0.430110,1.000000]
[epoch 13] val_loss=1.4493 qwk=('0.4956', '0.4804', '0.5165') averageQWK=0.4975 macroEMD=0.2960 tailR0=('0.0556', '0.0000', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    0    0
     0    5   29    6    0
     0    2   80   43    3
     0    0   34   86    2
     0    0    1   23    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    8   27   13    0
     0    2   52   59    0
     0    0   25  122    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   27   44    0    0
     0   10  123   18    0
     0    0   57   42    0
     0    0    1    2    0
[epoch 14] step 2/44: loss=0.7152 
[epoch 14] step 4/44: loss=0.7066 
[epoch 14] step 6/44: loss=0.7014 
[epoch 14] step 8/44: loss=0.6928 
[epoch 14] step 10/44: loss=0.6931 
[epoch 14] step 12/44: loss=0.6922 
[epoch 14] step 14/44: loss=0.6905 
[epoch 14] step 16/44: loss=0.6876 
[epoch 14] step 18/44: loss=0.6849 
[epoch 14] step 20/44: loss=0.6831 
[epoch 14] step 22/44: loss=0.6828 
[epoch 14] step 24/44: loss=0.6814 
[epoch 14] step 26/44: loss=0.6810 
[epoch 14] step 28/44: loss=0.6808 
[epoch 14] step 30/44: loss=0.6826 
[epoch 14] step 32/44: loss=0.6836 
[epoch 14] step 34/44: loss=0.6814 
[epoch 14] step 36/44: loss=0.6806 
[epoch 14] step 38/44: loss=0.6798 
[epoch 14] step 40/44: loss=0.6780 
[epoch 14] step 42/44: loss=0.6787 
[epoch 14] step 44/44: loss=0.6805 
[epoch 14] train_loss(avg per step)=1.3610 lambda[min,max]=[0.439937,1.000000]
[epoch 14] val_loss=1.3997 qwk=('0.5048', '0.4424', '0.5119') averageQWK=0.4863 macroEMD=0.2919 tailR0=('0.1111', '0.0000', '0.0000') tailR0avg=0.0370
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    0    0
     0    2   32    6    0
     0    3   63   59    3
     0    0   22   97    3
     0    0    0   21    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    2   31   15    0
     0    1   49   63    0
     0    0   19  129    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   48    5    0
     0    4   99   48    0
     0    0   27   72    0
     0    0    1    2    0
[epoch 15] step 2/44: loss=0.7085 
[epoch 15] step 4/44: loss=0.6987 
[epoch 15] step 6/44: loss=0.6850 
[epoch 15] step 8/44: loss=0.6875 
[epoch 15] step 10/44: loss=0.6887 
[epoch 15] step 12/44: loss=0.6936 
[epoch 15] step 14/44: loss=0.6885 
[epoch 15] step 16/44: loss=0.6842 
[epoch 15] step 18/44: loss=0.6812 
[epoch 15] step 20/44: loss=0.6795 
[epoch 15] step 22/44: loss=0.6829 
[epoch 15] step 24/44: loss=0.6812 
[epoch 15] step 26/44: loss=0.6809 
[epoch 15] step 28/44: loss=0.6817 
[epoch 15] step 30/44: loss=0.6802 
[epoch 15] step 32/44: loss=0.6820 
[epoch 15] step 34/44: loss=0.6811 
[epoch 15] step 36/44: loss=0.6790 
[epoch 15] step 38/44: loss=0.6768 
[epoch 15] step 40/44: loss=0.6763 
[epoch 15] step 42/44: loss=0.6747 
[epoch 15] step 44/44: loss=0.6769 
[epoch 15] train_loss(avg per step)=1.3538 lambda[min,max]=[0.377632,1.000000]
[epoch 15] val_loss=1.3822 qwk=('0.5366', '0.5046', '0.5378') averageQWK=0.5263 macroEMD=0.2897 tailR0=('0.1667', '0.0000', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    9   27    4    0
     0    5   94   24    5
     0    1   47   66    8
     0    0    3   15    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   11   28    9    0
     0    8   64   41    0
     0    0   44  103    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   43    2    0
     0   11  106   34    0
     0    0   40   59    0
     0    0    1    2    0
[epoch 16] step 2/44: loss=0.7245 
[epoch 16] step 4/44: loss=0.7091 
[epoch 16] step 6/44: loss=0.6924 
[epoch 16] step 8/44: loss=0.6828 
[epoch 16] step 10/44: loss=0.6736 
[epoch 16] step 12/44: loss=0.6685 
[epoch 16] step 14/44: loss=0.6704 
[epoch 16] step 16/44: loss=0.6680 
[epoch 16] step 18/44: loss=0.6618 
[epoch 16] step 20/44: loss=0.6617 
[epoch 16] step 22/44: loss=0.6587 
[epoch 16] step 24/44: loss=0.6573 
[epoch 16] step 26/44: loss=0.6551 
[epoch 16] step 28/44: loss=0.6544 
[epoch 16] step 30/44: loss=0.6552 
[epoch 16] step 32/44: loss=0.6571 
[epoch 16] step 34/44: loss=0.6581 
[epoch 16] step 36/44: loss=0.6589 
[epoch 16] step 38/44: loss=0.6602 
[epoch 16] step 40/44: loss=0.6608 
[epoch 16] step 42/44: loss=0.6596 
[epoch 16] step 44/44: loss=0.6585 
[epoch 16] train_loss(avg per step)=1.3170 lambda[min,max]=[0.379864,1.000000]
[epoch 16] val_loss=1.3285 qwk=('0.5266', '0.5023', '0.5374') averageQWK=0.5221 macroEMD=0.2930 tailR0=('0.1296', '0.0000', '0.0000') tailR0avg=0.0432
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   11   24    5    0
     0   12   82   29    5
     0    2   43   72    5
     0    0    3   17    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    9   31    8    0
     1    7   61   44    0
     0    1   38  108    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   33   37    1    0
     0   24  108   19    0
     0    2   47   50    0
     0    0    1    2    0
[epoch 17] step 2/44: loss=0.6275 
[epoch 17] step 4/44: loss=0.6379 
[epoch 17] step 6/44: loss=0.6538 
[epoch 17] step 8/44: loss=0.6545 
[epoch 17] step 10/44: loss=0.6500 
[epoch 17] step 12/44: loss=0.6554 
[epoch 17] step 14/44: loss=0.6593 
[epoch 17] step 16/44: loss=0.6605 
[epoch 17] step 18/44: loss=0.6560 
[epoch 17] step 20/44: loss=0.6557 
[epoch 17] step 22/44: loss=0.6516 
[epoch 17] step 24/44: loss=0.6489 
[epoch 17] step 26/44: loss=0.6459 
[epoch 17] step 28/44: loss=0.6415 
[epoch 17] step 30/44: loss=0.6430 
[epoch 17] step 32/44: loss=0.6436 
[epoch 17] step 34/44: loss=0.6455 
[epoch 17] step 36/44: loss=0.6446 
[epoch 17] step 38/44: loss=0.6433 
[epoch 17] step 40/44: loss=0.6424 
[epoch 17] step 42/44: loss=0.6417 
[epoch 17] step 44/44: loss=0.6418 
[epoch 17] train_loss(avg per step)=1.2835 lambda[min,max]=[0.396135,1.000000]
[epoch 17] val_loss=1.3165 qwk=('0.4700', '0.4714', '0.4911') averageQWK=0.4775 macroEMD=0.2922 tailR0=('0.1111', '0.1000', '0.0000') tailR0avg=0.0704
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    4   29    7    0
     0    4   78   38    8
     0    0   37   82    3
     0    0    2   19    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6   33    9    0
     1    5   66   37    4
     0    0   44   99    5
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   41    8    0
     0    7   82   62    0
     0    0   24   75    0
     0    0    1    2    0
[epoch 18] step 2/44: loss=0.6344 
[epoch 18] step 4/44: loss=0.6444 
[epoch 18] step 6/44: loss=0.6483 
[epoch 18] step 8/44: loss=0.6536 
[epoch 18] step 10/44: loss=0.6535 
[epoch 18] step 12/44: loss=0.6558 
[epoch 18] step 14/44: loss=0.6593 
[epoch 18] step 16/44: loss=0.6616 
[epoch 18] step 18/44: loss=0.6618 
[epoch 18] step 20/44: loss=0.6554 
[epoch 18] step 22/44: loss=0.6502 
[epoch 18] step 24/44: loss=0.6467 
[epoch 18] step 26/44: loss=0.6457 
[epoch 18] step 28/44: loss=0.6458 
[epoch 18] step 30/44: loss=0.6475 
[epoch 18] step 32/44: loss=0.6466 
[epoch 18] step 34/44: loss=0.6463 
[epoch 18] step 36/44: loss=0.6452 
[epoch 18] step 38/44: loss=0.6451 
[epoch 18] step 40/44: loss=0.6427 
[epoch 18] step 42/44: loss=0.6389 
[epoch 18] step 44/44: loss=0.6390 
[epoch 18] train_loss(avg per step)=1.2781 lambda[min,max]=[0.391232,1.000000]
[epoch 18] val_loss=1.2643 qwk=('0.4384', '0.4833', '0.5590') averageQWK=0.4936 macroEMD=0.2963 tailR0=('0.0185', '0.0000', '0.0000') tailR0avg=0.0062
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    5   31    4    0
     0    5   93   27    3
     0    0   47   75    0
     0    0    9   17    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    3   37    8    0
     1    1   70   41    0
     0    0   40  107    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   36   35    0    0
     0   19  115   17    0
     0    2   50   47    0
     0    0    1    2    0
[epoch 19] step 2/44: loss=0.6407 
[epoch 19] step 4/44: loss=0.6461 
[epoch 19] step 6/44: loss=0.6384 
[epoch 19] step 8/44: loss=0.6403 
[epoch 19] step 10/44: loss=0.6418 
[epoch 19] step 12/44: loss=0.6433 
[epoch 19] step 14/44: loss=0.6388 
[epoch 19] step 16/44: loss=0.6393 
[epoch 19] step 18/44: loss=0.6357 
[epoch 19] step 20/44: loss=0.6316 
[epoch 19] step 22/44: loss=0.6328 
[epoch 19] step 24/44: loss=0.6294 
[epoch 19] step 26/44: loss=0.6295 
[epoch 19] step 28/44: loss=0.6277 
[epoch 19] step 30/44: loss=0.6293 
[epoch 19] step 32/44: loss=0.6267 
[epoch 19] step 34/44: loss=0.6267 
[epoch 19] step 36/44: loss=0.6290 
[epoch 19] step 38/44: loss=0.6288 
[epoch 19] step 40/44: loss=0.6306 
[epoch 19] step 42/44: loss=0.6313 
[epoch 19] step 44/44: loss=0.6315 
[epoch 19] train_loss(avg per step)=1.2629 lambda[min,max]=[0.389913,1.000000]
[epoch 19] val_loss=1.3107 qwk=('0.5076', '0.5352', '0.4911') averageQWK=0.5113 macroEMD=0.2900 tailR0=('0.0926', '0.0000', '0.0000') tailR0avg=0.0309
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   11   24    5    0
     0    5   91   27    5
     0    0   49   70    3
     0    0    5   17    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     1   12   27    8    0
     1    7   71   34    0
     0    1   45  101    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   46    1    0
     0   10  118   23    0
     0    1   52   46    0
     0    0    1    2    0
[epoch 20] step 2/44: loss=0.5710 
[epoch 20] step 4/44: loss=0.5997 
[epoch 20] step 6/44: loss=0.6019 
[epoch 20] step 8/44: loss=0.6010 
[epoch 20] step 10/44: loss=0.5977 
[epoch 20] step 12/44: loss=0.5978 
[epoch 20] step 14/44: loss=0.5919 
[epoch 20] step 16/44: loss=0.5933 
[epoch 20] step 18/44: loss=0.5943 
[epoch 20] step 20/44: loss=0.5948 
[epoch 20] step 22/44: loss=0.5973 
[epoch 20] step 24/44: loss=0.5994 
[epoch 20] step 26/44: loss=0.6034 
[epoch 20] step 28/44: loss=0.6054 
[epoch 20] step 30/44: loss=0.6075 
[epoch 20] step 32/44: loss=0.6097 
[epoch 20] step 34/44: loss=0.6098 
[epoch 20] step 36/44: loss=0.6107 
[epoch 20] step 38/44: loss=0.6094 
[epoch 20] step 40/44: loss=0.6074 
[epoch 20] step 42/44: loss=0.6080 
[epoch 20] step 44/44: loss=0.6071 
[epoch 20] train_loss(avg per step)=1.2142 lambda[min,max]=[0.392738,1.000000]
[epoch 20] val_loss=1.2327 qwk=('0.5139', '0.5235', '0.5263') averageQWK=0.5212 macroEMD=0.2904 tailR0=('0.0370', '0.0000', '0.0000') tailR0avg=0.0123
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   12   21    7    0
     0   10   67   48    3
     0    3   25   94    0
     0    0    2   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     1   13   27    7    0
     2    7   71   33    0
     0    1   49   96    2
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   30   39    2    0
     0   14  106   31    0
     0    2   42   55    0
     0    0    1    2    0
[epoch 21] step 2/44: loss=0.5903 
[epoch 21] step 4/44: loss=0.5766 
[epoch 21] step 6/44: loss=0.5795 
[epoch 21] step 8/44: loss=0.5723 
[epoch 21] step 10/44: loss=0.5845 
[epoch 21] step 12/44: loss=0.5823 
[epoch 21] step 14/44: loss=0.5842 
[epoch 21] step 16/44: loss=0.5888 
[epoch 21] step 18/44: loss=0.5951 
[epoch 21] step 20/44: loss=0.5984 
[epoch 21] step 22/44: loss=0.5984 
[epoch 21] step 24/44: loss=0.6000 
[epoch 21] step 26/44: loss=0.5992 
[epoch 21] step 28/44: loss=0.5996 
[epoch 21] step 30/44: loss=0.6001 
[epoch 21] step 32/44: loss=0.6017 
[epoch 21] step 34/44: loss=0.6002 
[epoch 21] step 36/44: loss=0.6002 
[epoch 21] step 38/44: loss=0.6001 
[epoch 21] step 40/44: loss=0.6011 
[epoch 21] step 42/44: loss=0.6006 
[epoch 21] step 44/44: loss=0.6003 
[epoch 21] train_loss(avg per step)=1.2007 lambda[min,max]=[0.368702,1.000000]
[epoch 21] val_loss=1.2326 qwk=('0.4875', '0.5116', '0.5494') averageQWK=0.5162 macroEMD=0.2903 tailR0=('0.0995', '0.1667', '0.0000') tailR0avg=0.0887
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    8   24    8    0
     1    5   75   44    3
     0    1   30   91    0
     0    0    3   22    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     3    5   30   10    0
     2    1   59   51    0
     0    0   33  115    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   29   42    0    0
     0   10  122   19    0
     0    0   52   47    0
     0    0    1    2    0
[epoch 22] step 2/44: loss=0.5988 
[epoch 22] step 4/44: loss=0.5965 
[epoch 22] step 6/44: loss=0.5888 
[epoch 22] step 8/44: loss=0.5864 
[epoch 22] step 10/44: loss=0.5885 
[epoch 22] step 12/44: loss=0.5958 
[epoch 22] step 14/44: loss=0.5955 
[epoch 22] step 16/44: loss=0.5982 
[epoch 22] step 18/44: loss=0.5969 
[epoch 22] step 20/44: loss=0.5982 
[epoch 22] step 22/44: loss=0.5991 
[epoch 22] step 24/44: loss=0.5957 
[epoch 22] step 26/44: loss=0.5959 
[epoch 22] step 28/44: loss=0.5947 
[epoch 22] step 30/44: loss=0.5946 
[epoch 22] step 32/44: loss=0.5949 
[epoch 22] step 34/44: loss=0.5954 
[epoch 22] step 36/44: loss=0.5936 
[epoch 22] step 38/44: loss=0.5940 
[epoch 22] step 40/44: loss=0.5920 
[epoch 22] step 42/44: loss=0.5914 
[epoch 22] step 44/44: loss=0.5908 
[epoch 22] train_loss(avg per step)=1.1816 lambda[min,max]=[0.400018,1.000000]
[epoch 22] val_loss=1.2497 qwk=('0.5101', '0.4902', '0.5375') averageQWK=0.5126 macroEMD=0.2888 tailR0=('0.1551', '0.0000', '0.0000') tailR0avg=0.0517
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0   11   23    6    0
     0    8   82   33    5
     0    2   40   77    3
     0    0    4   18    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     2   10   23   13    0
     2    6   47   58    0
     0    1   25  121    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   30   38    3    0
     0   14  101   36    0
     0    1   38   60    0
     0    0    1    2    0
[epoch 23] step 2/44: loss=0.6436 
[epoch 23] step 4/44: loss=0.6349 
[epoch 23] step 6/44: loss=0.6205 
[epoch 23] step 8/44: loss=0.6018 
[epoch 23] step 10/44: loss=0.5990 
[epoch 23] step 12/44: loss=0.6033 
[epoch 23] step 14/44: loss=0.6008 
[epoch 23] step 16/44: loss=0.5965 
[epoch 23] step 18/44: loss=0.5933 
[epoch 23] step 20/44: loss=0.5856 
[epoch 23] step 22/44: loss=0.5851 
[epoch 23] step 24/44: loss=0.5846 
[epoch 23] step 26/44: loss=0.5842 
[epoch 23] step 28/44: loss=0.5825 
[epoch 23] step 30/44: loss=0.5827 
[epoch 23] step 32/44: loss=0.5799 
[epoch 23] step 34/44: loss=0.5805 
[epoch 23] step 36/44: loss=0.5811 
[epoch 23] step 38/44: loss=0.5836 
[epoch 23] step 40/44: loss=0.5848 
[epoch 23] step 42/44: loss=0.5856 
[epoch 23] step 44/44: loss=0.5860 
[epoch 23] train_loss(avg per step)=1.1719 lambda[min,max]=[0.394014,1.000000]
[epoch 23] val_loss=1.2473 qwk=('0.5067', '0.5060', '0.5240') averageQWK=0.5122 macroEMD=0.2890 tailR0=('0.1551', '0.1333', '0.0000') tailR0avg=0.0961
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    9   26    5    0
     1    5   84   35    3
     0    2   43   75    2
     0    0    4   18    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     4    5   33    6    0
     2    5   74   32    0
     0    1   54   90    3
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   43    2    0
     0   15  109   27    0
     0    1   39   59    0
     0    1    0    2    0
[epoch 24] step 2/44: loss=0.6265 
[epoch 24] step 4/44: loss=0.6119 
[epoch 24] step 6/44: loss=0.6056 
[epoch 24] step 8/44: loss=0.6096 
[epoch 24] step 10/44: loss=0.6160 
[epoch 24] step 12/44: loss=0.6162 
[epoch 24] step 14/44: loss=0.6066 
[epoch 24] step 16/44: loss=0.6002 
[epoch 24] step 18/44: loss=0.5890 
[epoch 24] step 20/44: loss=0.5830 
[epoch 24] step 22/44: loss=0.5800 
[epoch 24] step 24/44: loss=0.5765 
[epoch 24] step 26/44: loss=0.5777 
[epoch 24] step 28/44: loss=0.5774 
[epoch 24] step 30/44: loss=0.5772 
[epoch 24] step 32/44: loss=0.5770 
[epoch 24] step 34/44: loss=0.5785 
[epoch 24] step 36/44: loss=0.5806 
[epoch 24] step 38/44: loss=0.5827 
[epoch 24] step 40/44: loss=0.5835 
[epoch 24] step 42/44: loss=0.5839 
[epoch 24] step 44/44: loss=0.5854 
[epoch 24] train_loss(avg per step)=1.1708 lambda[min,max]=[0.368724,1.000000]
[epoch 24] val_loss=1.2353 qwk=('0.4954', '0.5177', '0.5004') averageQWK=0.5045 macroEMD=0.2877 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1   10   21    8    0
     1    4   70   50    3
     0    1   30   91    0
     0    0    3   23    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     2   10   28    8    0
     1    6   66   39    1
     0    2   41  104    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   15   53    2    0
     0    8  111   32    0
     0    0   39   60    0
     0    0    1    2    0
[epoch 25] step 2/44: loss=0.5960 
[epoch 25] step 4/44: loss=0.5973 
[epoch 25] step 6/44: loss=0.5980 
[epoch 25] step 8/44: loss=0.5913 
[epoch 25] step 10/44: loss=0.5876 
[epoch 25] step 12/44: loss=0.5795 
[epoch 25] step 14/44: loss=0.5721 
[epoch 25] step 16/44: loss=0.5708 
[epoch 25] step 18/44: loss=0.5674 
[epoch 25] step 20/44: loss=0.5703 
[epoch 25] step 22/44: loss=0.5737 
[epoch 25] step 24/44: loss=0.5753 
[epoch 25] step 26/44: loss=0.5754 
[epoch 25] step 28/44: loss=0.5774 
[epoch 25] step 30/44: loss=0.5748 
[epoch 25] step 32/44: loss=0.5758 
[epoch 25] step 34/44: loss=0.5760 
[epoch 25] step 36/44: loss=0.5767 
[epoch 25] step 38/44: loss=0.5765 
[epoch 25] step 40/44: loss=0.5748 
[epoch 25] step 42/44: loss=0.5725 
[epoch 25] step 44/44: loss=0.5716 
[epoch 25] train_loss(avg per step)=1.1431 lambda[min,max]=[0.378841,1.000000]
[epoch 25] val_loss=1.2436 qwk=('0.4554', '0.5303', '0.5213') averageQWK=0.5023 macroEMD=0.2928 tailR0=('0.1991', '0.0000', '0.0000') tailR0avg=0.0664
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    0    0
     1    7   29    3    0
     1    4   98   20    5
     0    0   57   61    4
     0    0   12   11    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     2   11   27    8    0
     2    7   66   38    0
     0    1   43  103    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   38    2    0
     0   12  115   24    0
     0    2   48   49    0
     0    0    1    2    0
[epoch 26] step 2/44: loss=0.5800 
[epoch 26] step 4/44: loss=0.6082 
[epoch 26] step 6/44: loss=0.6044 
[epoch 26] step 8/44: loss=0.6030 
[epoch 26] step 10/44: loss=0.5917 
[epoch 26] step 12/44: loss=0.5878 
[epoch 26] step 14/44: loss=0.5870 
[epoch 26] step 16/44: loss=0.5797 
[epoch 26] step 18/44: loss=0.5723 
[epoch 26] step 20/44: loss=0.5682 
[epoch 26] step 22/44: loss=0.5664 
[epoch 26] step 24/44: loss=0.5614 
[epoch 26] step 26/44: loss=0.5612 
[epoch 26] step 28/44: loss=0.5601 
[epoch 26] step 30/44: loss=0.5611 
[epoch 26] step 32/44: loss=0.5627 
[epoch 26] step 34/44: loss=0.5648 
[epoch 26] step 36/44: loss=0.5693 
[epoch 26] step 38/44: loss=0.5711 
[epoch 26] step 40/44: loss=0.5702 
[epoch 26] step 42/44: loss=0.5702 
[epoch 26] step 44/44: loss=0.5708 
[epoch 26] train_loss(avg per step)=1.1417 lambda[min,max]=[0.381497,1.000000]
[epoch 26] val_loss=1.2052 qwk=('0.4960', '0.4881', '0.5331') averageQWK=0.5057 macroEMD=0.2920 tailR0=('0.0995', '0.0000', '0.0000') tailR0avg=0.0332
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1    6   27    6    0
     0    5   80   40    3
     0    1   36   85    0
     0    0    4   21    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     3    5   31    9    0
     2    2   64   45    0
     0    0   39  108    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   30   39    2    0
     0   12  110   29    0
     0    2   42   55    0
     0    0    1    2    0
[epoch 27] step 2/44: loss=0.5460 
[epoch 27] step 4/44: loss=0.5506 
[epoch 27] step 6/44: loss=0.5502 
[epoch 27] step 8/44: loss=0.5603 
[epoch 27] step 10/44: loss=0.5609 
[epoch 27] step 12/44: loss=0.5530 
[epoch 27] step 14/44: loss=0.5469 
[epoch 27] step 16/44: loss=0.5473 
[epoch 27] step 18/44: loss=0.5468 
[epoch 27] step 20/44: loss=0.5498 
[epoch 27] step 22/44: loss=0.5502 
[epoch 27] step 24/44: loss=0.5537 
[epoch 27] step 26/44: loss=0.5587 
[epoch 27] step 28/44: loss=0.5609 
[epoch 27] step 30/44: loss=0.5632 
[epoch 27] step 32/44: loss=0.5654 
[epoch 27] step 34/44: loss=0.5661 
[epoch 27] step 36/44: loss=0.5674 
[epoch 27] step 38/44: loss=0.5678 
[epoch 27] step 40/44: loss=0.5673 
[epoch 27] step 42/44: loss=0.5686 
[epoch 27] step 44/44: loss=0.5677 
[epoch 27] train_loss(avg per step)=1.1354 lambda[min,max]=[0.385421,1.000000]
[epoch 27] val_loss=1.1958 qwk=('0.4584', '0.4704', '0.5444') averageQWK=0.4910 macroEMD=0.2948 tailR0=('0.0995', '0.0833', '0.0000') tailR0avg=0.0610
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    5   27    8    0
     1    4   72   47    4
     0    2   28   91    1
     0    0    3   22    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     2    3   35    8    0
     2    1   72   38    0
     0    0   49   97    2
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   45    0    0
     0   11  122   18    0
     0    1   47   51    0
     0    0    1    2    0
[epoch 28] step 2/44: loss=0.5882 
[epoch 28] step 4/44: loss=0.5672 
[epoch 28] step 6/44: loss=0.5646 
[epoch 28] step 8/44: loss=0.5559 
[epoch 28] step 10/44: loss=0.5575 
[epoch 28] step 12/44: loss=0.5554 
[epoch 28] step 14/44: loss=0.5512 
[epoch 28] step 16/44: loss=0.5510 
[epoch 28] step 18/44: loss=0.5537 
[epoch 28] step 20/44: loss=0.5537 
[epoch 28] step 22/44: loss=0.5592 
[epoch 28] step 24/44: loss=0.5608 
[epoch 28] step 26/44: loss=0.5598 
[epoch 28] step 28/44: loss=0.5580 
[epoch 28] step 30/44: loss=0.5573 
[epoch 28] step 32/44: loss=0.5554 
[epoch 28] step 34/44: loss=0.5554 
[epoch 28] step 36/44: loss=0.5589 
[epoch 28] step 38/44: loss=0.5604 
[epoch 28] step 40/44: loss=0.5591 
[epoch 28] step 42/44: loss=0.5609 
[epoch 28] step 44/44: loss=0.5636 
[epoch 28] train_loss(avg per step)=1.1272 lambda[min,max]=[0.357708,1.000000]
[epoch 28] val_loss=1.2025 qwk=('0.5026', '0.4882', '0.5085') averageQWK=0.4998 macroEMD=0.2932 tailR0=('0.1181', '0.0000', '0.0000') tailR0avg=0.0394
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0   11   23    6    0
     0    7   73   44    4
     0    3   30   88    1
     0    0    4   20    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     2    4   34    8    0
     2    2   69   40    0
     0    0   41  106    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   46    1    0
     0   11  119   21    0
     0    1   49   49    0
     0    0    1    2    0
[epoch 29] step 2/44: loss=0.5870 
[epoch 29] step 4/44: loss=0.5835 
[epoch 29] step 6/44: loss=0.5800 
[epoch 29] step 8/44: loss=0.5641 
[epoch 29] step 10/44: loss=0.5588 
[epoch 29] step 12/44: loss=0.5597 
[epoch 29] step 14/44: loss=0.5567 
[epoch 29] step 16/44: loss=0.5526 
[epoch 29] step 18/44: loss=0.5478 
[epoch 29] step 20/44: loss=0.5448 
[epoch 29] step 22/44: loss=0.5413 
[epoch 29] step 24/44: loss=0.5410 
[epoch 29] step 26/44: loss=0.5439 
[epoch 29] step 28/44: loss=0.5461 
[epoch 29] step 30/44: loss=0.5460 
[epoch 29] step 32/44: loss=0.5480 
[epoch 29] step 34/44: loss=0.5495 
[epoch 29] step 36/44: loss=0.5505 
[epoch 29] step 38/44: loss=0.5507 
[epoch 29] step 40/44: loss=0.5507 
[epoch 29] step 42/44: loss=0.5514 
[epoch 29] step 44/44: loss=0.5513 
[epoch 29] train_loss(avg per step)=1.1026 lambda[min,max]=[0.373555,1.000000]
[epoch 29] val_loss=1.2210 qwk=('0.4880', '0.4845', '0.5016') averageQWK=0.4914 macroEMD=0.2922 tailR0=('0.1620', '0.0000', '0.0000') tailR0avg=0.0540
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    0    0
     0    7   26    7    0
     1    4   74   45    4
     0    1   31   89    1
     0    0    4   21    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     2    4   34    8    0
     2    3   73   35    0
     0    0   49   97    2
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   46    1    0
     0   10  120   21    0
     0    2   48   49    0
     0    0    1    2    0
[epoch 30] step 2/44: loss=0.5781 
[epoch 30] step 4/44: loss=0.5759 
[epoch 30] step 6/44: loss=0.5715 
[epoch 30] step 8/44: loss=0.5697 
[epoch 30] step 10/44: loss=0.5629 
[epoch 30] step 12/44: loss=0.5680 
[epoch 30] step 14/44: loss=0.5689 
[epoch 30] step 16/44: loss=0.5643 
[epoch 30] step 18/44: loss=0.5625 
[epoch 30] step 20/44: loss=0.5622 
[epoch 30] step 22/44: loss=0.5609 
[epoch 30] step 24/44: loss=0.5572 
[epoch 30] step 26/44: loss=0.5548 
[epoch 30] step 28/44: loss=0.5528 
[epoch 30] step 30/44: loss=0.5524 
[epoch 30] step 32/44: loss=0.5541 
[epoch 30] step 34/44: loss=0.5517 
[epoch 30] step 36/44: loss=0.5502 
[epoch 30] step 38/44: loss=0.5507 
[epoch 30] step 40/44: loss=0.5520 
[epoch 30] step 42/44: loss=0.5549 
[epoch 30] step 44/44: loss=0.5551 
[epoch 30] train_loss(avg per step)=1.1102 lambda[min,max]=[0.380012,1.000000]
[epoch 30] val_loss=1.2179 qwk=('0.4924', '0.4966', '0.5134') averageQWK=0.5008 macroEMD=0.2945 tailR0=('0.1620', '0.0000', '0.0000') tailR0avg=0.0540
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    0    0
     0    7   27    6    0
     1    4   84   35    4
     0    1   37   82    2
     0    0    5   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     2    4   34    8    0
     1    2   73   37    0
     0    0   45  102    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   29   41    1    0
     0   17  115   19    0
     0    2   50   47    0
     0    0    1    2    0
[epoch 31] step 2/44: loss=0.5885 
[epoch 31] step 4/44: loss=0.5901 
[epoch 31] step 6/44: loss=0.5747 
[epoch 31] step 8/44: loss=0.5666 
[epoch 31] step 10/44: loss=0.5655 
[epoch 31] step 12/44: loss=0.5664 
[epoch 31] step 14/44: loss=0.5642 
[epoch 31] step 16/44: loss=0.5609 
[epoch 31] step 18/44: loss=0.5580 
[epoch 31] step 20/44: loss=0.5568 
[epoch 31] step 22/44: loss=0.5531 
[epoch 31] step 24/44: loss=0.5490 
[epoch 31] step 26/44: loss=0.5475 
[epoch 31] step 28/44: loss=0.5444 
[epoch 31] step 30/44: loss=0.5428 
[epoch 31] step 32/44: loss=0.5419 
[epoch 31] step 34/44: loss=0.5433 
[epoch 31] step 36/44: loss=0.5442 
[epoch 31] step 38/44: loss=0.5444 
[epoch 31] step 40/44: loss=0.5446 
[epoch 31] step 42/44: loss=0.5463 
[epoch 31] step 44/44: loss=0.5440 
[epoch 31] train_loss(avg per step)=1.0879 lambda[min,max]=[0.348896,1.000000]
[epoch 31] val_loss=1.2051 qwk=('0.4957', '0.5041', '0.4961') averageQWK=0.4986 macroEMD=0.2910 tailR0=('0.1806', '0.0000', '0.0000') tailR0avg=0.0602
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    0    0
     0    7   26    7    0
     1    4   80   39    4
     0    2   32   86    2
     0    0    4   20    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     2    6   33    7    0
     2    3   68   40    0
     0    0   45  101    2
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   49    2    0
     0    7  116   28    0
     0    0   46   53    0
     0    0    1    2    0
[epoch 32] step 2/44: loss=0.5795 
[epoch 32] step 4/44: loss=0.5834 
[epoch 32] step 6/44: loss=0.5923 
[epoch 32] step 8/44: loss=0.5937 
[epoch 32] step 10/44: loss=0.5866 
[epoch 32] step 12/44: loss=0.5864 
[epoch 32] step 14/44: loss=0.5836 
[epoch 32] step 16/44: loss=0.5799 
[epoch 32] step 18/44: loss=0.5797 
[epoch 32] step 20/44: loss=0.5775 
[epoch 32] step 22/44: loss=0.5723 
[epoch 32] step 24/44: loss=0.5695 
[epoch 32] step 26/44: loss=0.5662 
[epoch 32] step 28/44: loss=0.5653 
[epoch 32] step 30/44: loss=0.5609 
[epoch 32] step 32/44: loss=0.5580 
[epoch 32] step 34/44: loss=0.5571 
[epoch 32] step 36/44: loss=0.5567 
[epoch 32] step 38/44: loss=0.5538 
[epoch 32] step 40/44: loss=0.5542 
[epoch 32] step 42/44: loss=0.5547 
[epoch 32] step 44/44: loss=0.5518 
[epoch 32] train_loss(avg per step)=1.1036 lambda[min,max]=[0.370829,1.000000]
[epoch 32] val_loss=1.2028 qwk=('0.5040', '0.4897', '0.5140') averageQWK=0.5026 macroEMD=0.2943 tailR0=('0.1620', '0.0000', '0.0000') tailR0avg=0.0540
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    0    0
     0    8   27    5    0
     1    5   85   34    3
     0    2   37   83    0
     0    0    5   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     2    5   34    7    0
     2    3   71   37    0
     0    0   50   96    2
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   44    1    0
     0   10  123   18    0
     0    2   49   48    0
     0    0    1    2    0
[epoch 33] step 2/44: loss=0.5408 
[epoch 33] step 4/44: loss=0.5575 
[epoch 33] step 6/44: loss=0.5464 
[epoch 33] step 8/44: loss=0.5444 
[epoch 33] step 10/44: loss=0.5448 
[epoch 33] step 12/44: loss=0.5464 
[epoch 33] step 14/44: loss=0.5523 
[epoch 33] step 16/44: loss=0.5623 
[epoch 33] step 18/44: loss=0.5635 
[epoch 33] step 20/44: loss=0.5625 
[epoch 33] step 22/44: loss=0.5634 
[epoch 33] step 24/44: loss=0.5621 
[epoch 33] step 26/44: loss=0.5606 
[epoch 33] step 28/44: loss=0.5610 
[epoch 33] step 30/44: loss=0.5586 
[epoch 33] step 32/44: loss=0.5551 
[epoch 33] step 34/44: loss=0.5559 
[epoch 33] step 36/44: loss=0.5569 
[epoch 33] step 38/44: loss=0.5594 
[epoch 33] step 40/44: loss=0.5596 
[epoch 33] step 42/44: loss=0.5591 
[epoch 33] step 44/44: loss=0.5574 
[epoch 33] train_loss(avg per step)=1.1147 lambda[min,max]=[0.360481,1.000000]
[epoch 33] val_loss=1.1630 qwk=('0.5021', '0.4995', '0.5044') averageQWK=0.5020 macroEMD=0.2945 tailR0=('0.1620', '0.0000', '0.0000') tailR0avg=0.0540
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    0    0
     0    8   25    7    0
     1    5   72   47    3
     0    3   28   91    0
     0    0    2   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     3    3   34    8    0
     2    2   64   45    0
     0    0   38  109    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   47    2    0
     0    8  116   27    0
     0    1   44   54    0
     0    0    1    2    0
[epoch 34] step 2/44: loss=0.5597 
[epoch 34] step 4/44: loss=0.5371 
[epoch 34] step 6/44: loss=0.5311 
[epoch 34] step 8/44: loss=0.5242 
[epoch 34] step 10/44: loss=0.5243 
[epoch 34] step 12/44: loss=0.5240 
[epoch 34] step 14/44: loss=0.5257 
[epoch 34] step 16/44: loss=0.5280 
[epoch 34] step 18/44: loss=0.5333 
[epoch 34] step 20/44: loss=0.5343 
[epoch 34] step 22/44: loss=0.5352 
[epoch 34] step 24/44: loss=0.5346 
[epoch 34] step 26/44: loss=0.5343 
[epoch 34] step 28/44: loss=0.5369 
[epoch 34] step 30/44: loss=0.5387 
[epoch 34] step 32/44: loss=0.5392 
[epoch 34] step 34/44: loss=0.5407 
[epoch 34] step 36/44: loss=0.5402 
[epoch 34] step 38/44: loss=0.5423 
[epoch 34] step 40/44: loss=0.5429 
[epoch 34] step 42/44: loss=0.5434 
[epoch 34] step 44/44: loss=0.5426 
[epoch 34] train_loss(avg per step)=1.0853 lambda[min,max]=[0.359600,1.000000]
[epoch 34] val_loss=1.1786 qwk=('0.4977', '0.4962', '0.4740') averageQWK=0.4893 macroEMD=0.2931 tailR0=('0.1620', '0.0000', '0.0000') tailR0avg=0.0540
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    3    0    0
     0    7   26    7    0
     1    4   80   40    3
     0    1   33   88    0
     0    0    3   22    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     2    4   34    8    0
     2    2   69   40    0
     0    0   42  104    2
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   19   50    2    0
     0    8  114   29    0
     0    1   46   52    0
     0    0    1    2    0
[epoch 35] step 2/44: loss=0.5927 
[epoch 35] step 4/44: loss=0.5821 
[epoch 35] step 6/44: loss=0.5723 
[epoch 35] step 8/44: loss=0.5694 
[epoch 35] step 10/44: loss=0.5673 
[epoch 35] step 12/44: loss=0.5638 
[epoch 35] step 14/44: loss=0.5605 
[epoch 35] step 16/44: loss=0.5600 
[epoch 35] step 18/44: loss=0.5615 
[epoch 35] step 20/44: loss=0.5608 
[epoch 35] step 22/44: loss=0.5586 
[epoch 35] step 24/44: loss=0.5556 
[epoch 35] step 26/44: loss=0.5556 
[epoch 35] step 28/44: loss=0.5525 
[epoch 35] step 30/44: loss=0.5523 
[epoch 35] step 32/44: loss=0.5521 
[epoch 35] step 34/44: loss=0.5505 
[epoch 35] step 36/44: loss=0.5505 
[epoch 35] step 38/44: loss=0.5495 
[epoch 35] step 40/44: loss=0.5497 
[epoch 35] step 42/44: loss=0.5503 
[epoch 35] step 44/44: loss=0.5536 
[epoch 35] train_loss(avg per step)=1.1073 lambda[min,max]=[0.375274,1.000000]
[epoch 35] val_loss=1.1790 qwk=('0.4972', '0.5050', '0.5022') averageQWK=0.5015 macroEMD=0.2943 tailR0=('0.1620', '0.0000', '0.0000') tailR0avg=0.0540
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    0    0
     0    8   26    6    0
     1    5   85   34    3
     0    2   37   82    1
     0    0    5   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     3    5   32    8    0
     2    2   69   40    0
     0    0   43  104    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   25   44    2    0
     0   11  117   23    0
     0    2   46   51    0
     0    0    1    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-1/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-1/fold3/metrics.json
Done.
