[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.7108 
[epoch 1] step 4/44: loss=0.7158 
[epoch 1] step 6/44: loss=0.7195 
[epoch 1] step 8/44: loss=0.7229 
[epoch 1] step 10/44: loss=0.7216 
[epoch 1] step 12/44: loss=0.7220 
[epoch 1] step 14/44: loss=0.7222 
[epoch 1] step 16/44: loss=0.7216 
[epoch 1] step 18/44: loss=0.7221 
[epoch 1] step 20/44: loss=0.7238 
[epoch 1] step 22/44: loss=0.7232 
[epoch 1] step 24/44: loss=0.7253 
[epoch 1] step 26/44: loss=0.7242 
[epoch 1] step 28/44: loss=0.7228 
[epoch 1] step 30/44: loss=0.7230 
[epoch 1] step 32/44: loss=0.7218 
[epoch 1] step 34/44: loss=0.7196 
[epoch 1] step 36/44: loss=0.7195 
[epoch 1] step 38/44: loss=0.7185 
[epoch 1] step 40/44: loss=0.7181 
[epoch 1] step 42/44: loss=0.7201 
[epoch 1] step 44/44: loss=0.7204 
[epoch 1] train_loss(avg per step)=1.4409 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.7339 qwk=('-0.0696', '-0.0696', '0.1331') averageQWK=-0.0020 macroEMD=0.3648 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    6    0
     0    3    1   94    0
     0    4    1  150    0
     0    9    1   49    0
     0    1    1    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    1    0
     2    0   78    2    0
     2    0  155    9    0
     9    0   43    9    0
     0    0    2    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    1
     0   39   63    1    1
     0   42  129    2    7
     0    8   24    1    3
     0    0    0    0    0
[epoch 2] step 2/44: loss=0.8424 
[epoch 2] step 4/44: loss=0.8539 
[epoch 2] step 6/44: loss=0.8655 
[epoch 2] step 8/44: loss=0.8833 
[epoch 2] step 10/44: loss=0.9002 
[epoch 2] step 12/44: loss=0.9011 
[epoch 2] step 14/44: loss=0.8993 
[epoch 2] step 16/44: loss=0.9018 
[epoch 2] step 18/44: loss=0.8987 
[epoch 2] step 20/44: loss=0.8923 
[epoch 2] step 22/44: loss=0.8844 
[epoch 2] step 24/44: loss=0.8756 
[epoch 2] step 26/44: loss=0.8697 
[epoch 2] step 28/44: loss=0.8641 
[epoch 2] step 30/44: loss=0.8620 
[epoch 2] step 32/44: loss=0.8601 
[epoch 2] step 34/44: loss=0.8582 
[epoch 2] step 36/44: loss=0.8593 
[epoch 2] step 38/44: loss=0.8568 
[epoch 2] step 40/44: loss=0.8504 
[epoch 2] step 42/44: loss=0.8474 
[epoch 2] step 44/44: loss=0.8422 
[epoch 2] train_loss(avg per step)=1.6843 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.1879 qwk=('0.2560', '0.1824', '0.2460') averageQWK=0.2281 macroEMD=0.3463 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    5    0
     0   47    4   47    0
     0   34    6  115    0
     0    5    1   53    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    6    0
     0    0   46   36    0
     0    0   46  120    0
     0    0    3   58    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    3    2    0
     0   11   75   18    0
     0   16   79   85    0
     0    0    5   31    0
     0    0    0    0    0
[epoch 3] step 2/44: loss=0.7052 
[epoch 3] step 4/44: loss=0.7125 
[epoch 3] step 6/44: loss=0.7172 
[epoch 3] step 8/44: loss=0.7331 
[epoch 3] step 10/44: loss=0.7405 
[epoch 3] step 12/44: loss=0.7510 
[epoch 3] step 14/44: loss=0.7600 
[epoch 3] step 16/44: loss=0.7617 
[epoch 3] step 18/44: loss=0.7697 
[epoch 3] step 20/44: loss=0.7812 
[epoch 3] step 22/44: loss=0.7870 
[epoch 3] step 24/44: loss=0.7931 
[epoch 3] step 26/44: loss=0.8038 
[epoch 3] step 28/44: loss=0.8109 
[epoch 3] step 30/44: loss=0.8185 
[epoch 3] step 32/44: loss=0.8176 
[epoch 3] step 34/44: loss=0.8181 
[epoch 3] step 36/44: loss=0.8184 
[epoch 3] step 38/44: loss=0.8166 
[epoch 3] step 40/44: loss=0.8167 
[epoch 3] step 42/44: loss=0.8183 
[epoch 3] step 44/44: loss=0.8182 
[epoch 3] train_loss(avg per step)=1.6364 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=1.3804 qwk=('0.1970', '0.2369', '0.2526') averageQWK=0.2288 macroEMD=0.3313 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0   10   44   44    0
     0    4   48  103    0
     0    0    6   53    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    4    0
     0    0   70   12    0
     0    0  111   55    0
     0    0   17   44    0
     0    0    1    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0    1   93   10    0
     0    0  133   47    0
     0    0    9   27    0
     0    0    0    0    0
[epoch 4] step 2/44: loss=0.7866 
[epoch 4] step 4/44: loss=0.7899 
[epoch 4] step 6/44: loss=0.7982 
[epoch 4] step 8/44: loss=0.7928 
[epoch 4] step 10/44: loss=0.7925 
[epoch 4] step 12/44: loss=0.7999 
[epoch 4] step 14/44: loss=0.7983 
[epoch 4] step 16/44: loss=0.8000 
[epoch 4] step 18/44: loss=0.8000 
[epoch 4] step 20/44: loss=0.8007 
[epoch 4] step 22/44: loss=0.7973 
[epoch 4] step 24/44: loss=0.7952 
[epoch 4] step 26/44: loss=0.7969 
[epoch 4] step 28/44: loss=0.7983 
[epoch 4] step 30/44: loss=0.7983 
[epoch 4] step 32/44: loss=0.8026 
[epoch 4] step 34/44: loss=0.8043 
[epoch 4] step 36/44: loss=0.8072 
[epoch 4] step 38/44: loss=0.8098 
[epoch 4] step 40/44: loss=0.8117 
[epoch 4] step 42/44: loss=0.8114 
[epoch 4] step 44/44: loss=0.8117 
[epoch 4] train_loss(avg per step)=1.6234 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=1.5054 qwk=('0.2132', '0.1821', '0.2398') averageQWK=0.2117 macroEMD=0.3280 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0   19   34   45    0
     0   14   43   98    0
     0    1    4   54    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    7    0
     0    5   40   37    0
     0    4   55  107    0
     0    0    3   58    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   31   37   36    0
     0   23   54  103    0
     0    0    4   32    0
     0    0    0    0    0
[epoch 5] step 2/44: loss=0.8046 
[epoch 5] step 4/44: loss=0.7943 
[epoch 5] step 6/44: loss=0.7860 
[epoch 5] step 8/44: loss=0.7880 
[epoch 5] step 10/44: loss=0.7906 
[epoch 5] step 12/44: loss=0.7911 
[epoch 5] step 14/44: loss=0.7903 
[epoch 5] step 16/44: loss=0.7910 
[epoch 5] step 18/44: loss=0.7900 
[epoch 5] step 20/44: loss=0.7915 
[epoch 5] step 22/44: loss=0.7932 
[epoch 5] step 24/44: loss=0.7983 
[epoch 5] step 26/44: loss=0.7995 
[epoch 5] step 28/44: loss=0.8015 
[epoch 5] step 30/44: loss=0.7996 
[epoch 5] step 32/44: loss=0.8010 
[epoch 5] step 34/44: loss=0.8001 
[epoch 5] step 36/44: loss=0.7972 
[epoch 5] step 38/44: loss=0.7974 
[epoch 5] step 40/44: loss=0.7959 
[epoch 5] step 42/44: loss=0.7959 
[epoch 5] step 44/44: loss=0.7958 
[epoch 5] train_loss(avg per step)=1.5916 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=1.5479 qwk=('0.1966', '0.2068', '0.2383') averageQWK=0.2139 macroEMD=0.3195 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     0    5   56   37    0
     0    4   69   82    0
     0    0   11   48    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    6    0
     0    4   46   32    0
     0    0   66  100    0
     0    0    4   57    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   25   55   24    0
     0   10  108   62    0
     0    0   14   22    0
     0    0    0    0    0
[epoch 6] step 2/44: loss=0.8291 
[epoch 6] step 4/44: loss=0.8133 
[epoch 6] step 6/44: loss=0.8062 
[epoch 6] step 8/44: loss=0.8082 
[epoch 6] step 10/44: loss=0.8029 
[epoch 6] step 12/44: loss=0.8017 
[epoch 6] step 14/44: loss=0.7986 
[epoch 6] step 16/44: loss=0.7966 
[epoch 6] step 18/44: loss=0.7972 
[epoch 6] step 20/44: loss=0.8022 
[epoch 6] step 22/44: loss=0.8021 
[epoch 6] step 24/44: loss=0.8050 
[epoch 6] step 26/44: loss=0.8054 
[epoch 6] step 28/44: loss=0.8015 
[epoch 6] step 30/44: loss=0.7993 
[epoch 6] step 32/44: loss=0.7981 
[epoch 6] step 34/44: loss=0.7965 
[epoch 6] step 36/44: loss=0.7938 
[epoch 6] step 38/44: loss=0.7912 
[epoch 6] step 40/44: loss=0.7908 
[epoch 6] step 42/44: loss=0.7909 
[epoch 6] step 44/44: loss=0.7933 
[epoch 6] train_loss(avg per step)=1.5867 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=1.6562 qwk=('0.2280', '0.2142', '0.2017') averageQWK=0.2147 macroEMD=0.3178 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     0   29   21   48    0
     0   15   42   98    0
     0    1    7   51    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    6    0
     0   14   27   41    0
     0    7   53  106    0
     0    0    5   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    3    0
     0   29   43   32    0
     0   22   71   87    0
     0    0   11   25    0
     0    0    0    0    0
[epoch 7] step 2/44: loss=0.8364 
[epoch 7] step 4/44: loss=0.8300 
[epoch 7] step 6/44: loss=0.8274 
[epoch 7] step 8/44: loss=0.8235 
[epoch 7] step 10/44: loss=0.8234 
[epoch 7] step 12/44: loss=0.8128 
[epoch 7] step 14/44: loss=0.8063 
[epoch 7] step 16/44: loss=0.7999 
[epoch 7] step 18/44: loss=0.7967 
[epoch 7] step 20/44: loss=0.7981 
[epoch 7] step 22/44: loss=0.7962 
[epoch 7] step 24/44: loss=0.7972 
[epoch 7] step 26/44: loss=0.7963 
[epoch 7] step 28/44: loss=0.7932 
[epoch 7] step 30/44: loss=0.7945 
[epoch 7] step 32/44: loss=0.7948 
[epoch 7] step 34/44: loss=0.7947 
[epoch 7] step 36/44: loss=0.7923 
[epoch 7] step 38/44: loss=0.7911 
[epoch 7] step 40/44: loss=0.7897 
[epoch 7] step 42/44: loss=0.7895 
[epoch 7] step 44/44: loss=0.7900 
[epoch 7] train_loss(avg per step)=1.5799 lambda[min,max]=[0.492622,1.000000]
[epoch 7] val_loss=1.6046 qwk=('0.2926', '0.3073', '0.2284') averageQWK=0.2761 macroEMD=0.3123 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     0   23   47   28    0
     0   10   70   75    0
     0    1   10   48    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    6    0
     0   24   33   25    0
     0   23   53   90    0
     0    0    7   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   31   38   35    0
     0   22   63   95    0
     0    0    7   29    0
     0    0    0    0    0
[epoch 8] step 2/44: loss=0.8073 
[epoch 8] step 4/44: loss=0.7977 
[epoch 8] step 6/44: loss=0.7730 
[epoch 8] step 8/44: loss=0.7694 
[epoch 8] step 10/44: loss=0.7756 
[epoch 8] step 12/44: loss=0.7834 
[epoch 8] step 14/44: loss=0.7899 
[epoch 8] step 16/44: loss=0.7872 
[epoch 8] step 18/44: loss=0.7776 
[epoch 8] step 20/44: loss=0.7716 
[epoch 8] step 22/44: loss=0.7662 
[epoch 8] step 24/44: loss=0.7628 
[epoch 8] step 26/44: loss=0.7618 
[epoch 8] step 28/44: loss=0.7636 
[epoch 8] step 30/44: loss=0.7622 
[epoch 8] step 32/44: loss=0.7608 
[epoch 8] step 34/44: loss=0.7595 
[epoch 8] step 36/44: loss=0.7597 
[epoch 8] step 38/44: loss=0.7597 
[epoch 8] step 40/44: loss=0.7623 
[epoch 8] step 42/44: loss=0.7643 
[epoch 8] step 44/44: loss=0.7684 
[epoch 8] train_loss(avg per step)=1.5369 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.7192 qwk=('0.1822', '0.1739', '0.1821') averageQWK=0.1794 macroEMD=0.3194 tailR0=('0.2500', '0.0000', '0.0000') tailR0avg=0.0833
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0    8   40   49    1
     0    1   47  107    0
     0    0    7   52    0
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    7    0
     0    8   29   45    0
     0    3   42  121    0
     0    0    2   59    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    2    3    0
     0   17   45   42    0
     0    5   63  112    0
     0    0    4   32    0
     0    0    0    0    0
[epoch 9] step 2/44: loss=0.8679 
[epoch 9] step 4/44: loss=0.8512 
[epoch 9] step 6/44: loss=0.8123 
[epoch 9] step 8/44: loss=0.8044 
[epoch 9] step 10/44: loss=0.7969 
[epoch 9] step 12/44: loss=0.7939 
[epoch 9] step 14/44: loss=0.7919 
[epoch 9] step 16/44: loss=0.7885 
[epoch 9] step 18/44: loss=0.7887 
[epoch 9] step 20/44: loss=0.7839 
[epoch 9] step 22/44: loss=0.7763 
[epoch 9] step 24/44: loss=0.7732 
[epoch 9] step 26/44: loss=0.7693 
[epoch 9] step 28/44: loss=0.7661 
[epoch 9] step 30/44: loss=0.7648 
[epoch 9] step 32/44: loss=0.7655 
[epoch 9] step 34/44: loss=0.7626 
[epoch 9] step 36/44: loss=0.7607 
[epoch 9] step 38/44: loss=0.7614 
[epoch 9] step 40/44: loss=0.7613 
[epoch 9] step 42/44: loss=0.7618 
[epoch 9] step 44/44: loss=0.7646 
[epoch 9] train_loss(avg per step)=1.5292 lambda[min,max]=[0.495371,1.000000]
[epoch 9] val_loss=1.6176 qwk=('0.2956', '0.2951', '0.2805') averageQWK=0.2904 macroEMD=0.3061 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    4    0
     0   42   18   36    2
     0   24   45   86    0
     0    1   10   48    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    6    0
     0   27   26   29    0
     0   26   46   94    0
     0    0    7   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   41   41   22    0
     0   41   74   65    0
     0    0   10   26    0
     0    0    0    0    0
[epoch 10] step 2/44: loss=0.8132 
[epoch 10] step 4/44: loss=0.8026 
[epoch 10] step 6/44: loss=0.7963 
[epoch 10] step 8/44: loss=0.7892 
[epoch 10] step 10/44: loss=0.7768 
[epoch 10] step 12/44: loss=0.7740 
[epoch 10] step 14/44: loss=0.7653 
[epoch 10] step 16/44: loss=0.7621 
[epoch 10] step 18/44: loss=0.7565 
[epoch 10] step 20/44: loss=0.7521 
[epoch 10] step 22/44: loss=0.7517 
[epoch 10] step 24/44: loss=0.7507 
[epoch 10] step 26/44: loss=0.7545 
[epoch 10] step 28/44: loss=0.7579 
[epoch 10] step 30/44: loss=0.7594 
[epoch 10] step 32/44: loss=0.7598 
[epoch 10] step 34/44: loss=0.7601 
[epoch 10] step 36/44: loss=0.7608 
[epoch 10] step 38/44: loss=0.7625 
[epoch 10] step 40/44: loss=0.7614 
[epoch 10] step 42/44: loss=0.7600 
[epoch 10] step 44/44: loss=0.7599 
[epoch 10] train_loss(avg per step)=1.5197 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.5865 qwk=('0.3054', '0.2778', '0.2485') averageQWK=0.2773 macroEMD=0.3097 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    4    0
     0   41   18   39    0
     0   21   51   83    0
     0    2    7   50    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    6    0
     0   27   24   31    0
     0   26   44   96    0
     0    1    5   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   34   43   27    0
     0   30   69   81    0
     0    0    9   27    0
     0    0    0    0    0
[epoch 11] step 2/44: loss=0.7174 
[epoch 11] step 4/44: loss=0.7198 
[epoch 11] step 6/44: loss=0.7251 
[epoch 11] step 8/44: loss=0.7253 
[epoch 11] step 10/44: loss=0.7231 
[epoch 11] step 12/44: loss=0.7190 
[epoch 11] step 14/44: loss=0.7196 
[epoch 11] step 16/44: loss=0.7215 
[epoch 11] step 18/44: loss=0.7228 
[epoch 11] step 20/44: loss=0.7287 
[epoch 11] step 22/44: loss=0.7296 
[epoch 11] step 24/44: loss=0.7292 
[epoch 11] step 26/44: loss=0.7257 
[epoch 11] step 28/44: loss=0.7257 
[epoch 11] step 30/44: loss=0.7216 
[epoch 11] step 32/44: loss=0.7230 
[epoch 11] step 34/44: loss=0.7237 
[epoch 11] step 36/44: loss=0.7227 
[epoch 11] step 38/44: loss=0.7229 
[epoch 11] step 40/44: loss=0.7238 
[epoch 11] step 42/44: loss=0.7225 
[epoch 11] step 44/44: loss=0.7224 
[epoch 11] train_loss(avg per step)=1.4447 lambda[min,max]=[0.439722,1.000000]
[epoch 11] val_loss=1.6709 qwk=('0.2082', '0.2515', '0.2631') averageQWK=0.2409 macroEMD=0.3056 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0   21   35   39    3
     0   11   52   90    2
     0    1    9   48    1
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    7    0
     0   21   25   36    0
     0   16   45  105    0
     0    0    4   57    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   24   63   17    0
     0   19  103   58    0
     0    0   11   25    0
     0    0    0    0    0
[epoch 12] step 2/44: loss=0.7661 
[epoch 12] step 4/44: loss=0.7649 
[epoch 12] step 6/44: loss=0.7669 
[epoch 12] step 8/44: loss=0.7548 
[epoch 12] step 10/44: loss=0.7537 
[epoch 12] step 12/44: loss=0.7482 
[epoch 12] step 14/44: loss=0.7518 
[epoch 12] step 16/44: loss=0.7496 
[epoch 12] step 18/44: loss=0.7465 
[epoch 12] step 20/44: loss=0.7419 
[epoch 12] step 22/44: loss=0.7376 
[epoch 12] step 24/44: loss=0.7333 
[epoch 12] step 26/44: loss=0.7317 
[epoch 12] step 28/44: loss=0.7316 
[epoch 12] step 30/44: loss=0.7309 
[epoch 12] step 32/44: loss=0.7284 
[epoch 12] step 34/44: loss=0.7246 
[epoch 12] step 36/44: loss=0.7229 
[epoch 12] step 38/44: loss=0.7209 
[epoch 12] step 40/44: loss=0.7198 
[epoch 12] step 42/44: loss=0.7183 
[epoch 12] step 44/44: loss=0.7192 
[epoch 12] train_loss(avg per step)=1.4384 lambda[min,max]=[0.455052,1.000000]
[epoch 12] val_loss=1.6574 qwk=('0.2117', '0.2799', '0.2819') averageQWK=0.2578 macroEMD=0.3009 tailR0=('0.2500', '0.0000', '0.0000') tailR0avg=0.0833
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    3    1
     0   23   38   27   10
     0   13   52   80   10
     0    1    9   46    3
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    6    0
     0   28   20   34    0
     0   22   41  103    0
     0    0    5   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   39   38   27    0
     0   28   76   76    0
     0    0    8   28    0
     0    0    0    0    0
[epoch 13] step 2/44: loss=0.7650 
[epoch 13] step 4/44: loss=0.7397 
[epoch 13] step 6/44: loss=0.7286 
[epoch 13] step 8/44: loss=0.7289 
[epoch 13] step 10/44: loss=0.7253 
[epoch 13] step 12/44: loss=0.7242 
[epoch 13] step 14/44: loss=0.7285 
[epoch 13] step 16/44: loss=0.7244 
[epoch 13] step 18/44: loss=0.7232 
[epoch 13] step 20/44: loss=0.7169 
[epoch 13] step 22/44: loss=0.7140 
[epoch 13] step 24/44: loss=0.7128 
[epoch 13] step 26/44: loss=0.7139 
[epoch 13] step 28/44: loss=0.7154 
[epoch 13] step 30/44: loss=0.7173 
[epoch 13] step 32/44: loss=0.7195 
[epoch 13] step 34/44: loss=0.7195 
[epoch 13] step 36/44: loss=0.7164 
[epoch 13] step 38/44: loss=0.7135 
[epoch 13] step 40/44: loss=0.7103 
[epoch 13] step 42/44: loss=0.7096 
[epoch 13] step 44/44: loss=0.7072 
[epoch 13] train_loss(avg per step)=1.4143 lambda[min,max]=[0.435517,1.000000]
[epoch 13] val_loss=1.5756 qwk=('0.1503', '0.1936', '0.2201') averageQWK=0.1880 macroEMD=0.3135 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0   16   29   47    6
     0   10   40  101    4
     0    1    5   53    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    9    0
     0   19   13   50    0
     0   13   36  117    0
     0    0    0   61    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   22   48   34    0
     0   17   82   81    0
     0    0    4   32    0
     0    0    0    0    0
[epoch 14] step 2/44: loss=0.6732 
[epoch 14] step 4/44: loss=0.6763 
[epoch 14] step 6/44: loss=0.6745 
[epoch 14] step 8/44: loss=0.6817 
[epoch 14] step 10/44: loss=0.6900 
[epoch 14] step 12/44: loss=0.6886 
[epoch 14] step 14/44: loss=0.6999 
[epoch 14] step 16/44: loss=0.7013 
[epoch 14] step 18/44: loss=0.6979 
[epoch 14] step 20/44: loss=0.6930 
[epoch 14] step 22/44: loss=0.6899 
[epoch 14] step 24/44: loss=0.6894 
[epoch 14] step 26/44: loss=0.6892 
[epoch 14] step 28/44: loss=0.6876 
[epoch 14] step 30/44: loss=0.6882 
[epoch 14] step 32/44: loss=0.6907 
[epoch 14] step 34/44: loss=0.6948 
[epoch 14] step 36/44: loss=0.6966 
[epoch 14] step 38/44: loss=0.6974 
[epoch 14] step 40/44: loss=0.6982 
[epoch 14] step 42/44: loss=0.6986 
[epoch 14] step 44/44: loss=0.6986 
[epoch 14] train_loss(avg per step)=1.3971 lambda[min,max]=[0.435735,1.000000]
[epoch 14] val_loss=1.5035 qwk=('0.3771', '0.3515', '0.3267') averageQWK=0.3518 macroEMD=0.3005 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    4    0
     1   47   31   16    3
     0   35   60   59    1
     0    3   11   45    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    6    0
     0   44   15   23    0
     0   47   37   82    0
     0    4    4   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   59   28   17    0
     0   54   71   55    0
     0    1   12   23    0
     0    0    0    0    0
[epoch 15] step 2/44: loss=0.7049 
[epoch 15] step 4/44: loss=0.6941 
[epoch 15] step 6/44: loss=0.6853 
[epoch 15] step 8/44: loss=0.6857 
[epoch 15] step 10/44: loss=0.6838 
[epoch 15] step 12/44: loss=0.6822 
[epoch 15] step 14/44: loss=0.6831 
[epoch 15] step 16/44: loss=0.6852 
[epoch 15] step 18/44: loss=0.6849 
[epoch 15] step 20/44: loss=0.6889 
[epoch 15] step 22/44: loss=0.6873 
[epoch 15] step 24/44: loss=0.6870 
[epoch 15] step 26/44: loss=0.6829 
[epoch 15] step 28/44: loss=0.6804 
[epoch 15] step 30/44: loss=0.6793 
[epoch 15] step 32/44: loss=0.6789 
[epoch 15] step 34/44: loss=0.6798 
[epoch 15] step 36/44: loss=0.6816 
[epoch 15] step 38/44: loss=0.6853 
[epoch 15] step 40/44: loss=0.6856 
[epoch 15] step 42/44: loss=0.6869 
[epoch 15] step 44/44: loss=0.6863 
[epoch 15] train_loss(avg per step)=1.3726 lambda[min,max]=[0.393895,1.000000]
[epoch 15] val_loss=1.5515 qwk=('0.2724', '0.3106', '0.2912') averageQWK=0.2914 macroEMD=0.3022 tailR0=('0.1548', '0.0000', '0.0000') tailR0avg=0.0516
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    4    0
     9   18   39   26    6
     4   13   60   74    4
     0    1    8   50    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    6    0
     0   31   20   31    0
     0   25   44   97    0
     0    0    4   57    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   34   54   16    0
     0   27  105   48    0
     0    0   13   23    0
     0    0    0    0    0
[epoch 16] step 2/44: loss=0.6992 
[epoch 16] step 4/44: loss=0.6779 
[epoch 16] step 6/44: loss=0.6648 
[epoch 16] step 8/44: loss=0.6613 
[epoch 16] step 10/44: loss=0.6653 
[epoch 16] step 12/44: loss=0.6643 
[epoch 16] step 14/44: loss=0.6654 
[epoch 16] step 16/44: loss=0.6618 
[epoch 16] step 18/44: loss=0.6628 
[epoch 16] step 20/44: loss=0.6625 
[epoch 16] step 22/44: loss=0.6638 
[epoch 16] step 24/44: loss=0.6656 
[epoch 16] step 26/44: loss=0.6691 
[epoch 16] step 28/44: loss=0.6702 
[epoch 16] step 30/44: loss=0.6707 
[epoch 16] step 32/44: loss=0.6709 
[epoch 16] step 34/44: loss=0.6661 
[epoch 16] step 36/44: loss=0.6648 
[epoch 16] step 38/44: loss=0.6634 
[epoch 16] step 40/44: loss=0.6614 
[epoch 16] step 42/44: loss=0.6621 
[epoch 16] step 44/44: loss=0.6630 
[epoch 16] train_loss(avg per step)=1.3260 lambda[min,max]=[0.405430,1.000000]
[epoch 16] val_loss=1.5535 qwk=('0.2516', '0.2504', '0.2512') averageQWK=0.2511 macroEMD=0.3133 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    4    0
     1   29   27   38    3
     1   15   54   85    0
     0    1    7   51    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    8    0
     0   30    9   43    0
     0   25   25  116    0
     0    1    1   59    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   29   53   22    0
     0   29   89   62    0
     0    0    9   27    0
     0    0    0    0    0
[epoch 17] step 2/44: loss=0.6424 
[epoch 17] step 4/44: loss=0.6483 
[epoch 17] step 6/44: loss=0.6674 
[epoch 17] step 8/44: loss=0.6679 
[epoch 17] step 10/44: loss=0.6632 
[epoch 17] step 12/44: loss=0.6614 
[epoch 17] step 14/44: loss=0.6617 
[epoch 17] step 16/44: loss=0.6644 
[epoch 17] step 18/44: loss=0.6693 
[epoch 17] step 20/44: loss=0.6752 
[epoch 17] step 22/44: loss=0.6698 
[epoch 17] step 24/44: loss=0.6676 
[epoch 17] step 26/44: loss=0.6604 
[epoch 17] step 28/44: loss=0.6587 
[epoch 17] step 30/44: loss=0.6562 
[epoch 17] step 32/44: loss=0.6570 
[epoch 17] step 34/44: loss=0.6570 
[epoch 17] step 36/44: loss=0.6570 
[epoch 17] step 38/44: loss=0.6564 
[epoch 17] step 40/44: loss=0.6563 
[epoch 17] step 42/44: loss=0.6567 
[epoch 17] step 44/44: loss=0.6584 
[epoch 17] train_loss(avg per step)=1.3168 lambda[min,max]=[0.421089,1.000000]
[epoch 17] val_loss=1.5222 qwk=('0.3847', '0.3516', '0.2940') averageQWK=0.3434 macroEMD=0.2997 tailR0=('0.3810', '0.0000', '0.0000') tailR0avg=0.1270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    0    4    0
    25   19   37   11    6
    11   20   65   54    5
     0    3   12   40    4
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    6    0
     4   44    7   27    0
     5   42   21   98    0
     0    2    4   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   60   25   19    0
     0   68   55   57    0
     0    2   10   24    0
     0    0    0    0    0
[epoch 18] step 2/44: loss=0.6716 
[epoch 18] step 4/44: loss=0.6550 
[epoch 18] step 6/44: loss=0.6440 
[epoch 18] step 8/44: loss=0.6496 
[epoch 18] step 10/44: loss=0.6542 
[epoch 18] step 12/44: loss=0.6539 
[epoch 18] step 14/44: loss=0.6506 
[epoch 18] step 16/44: loss=0.6490 
[epoch 18] step 18/44: loss=0.6456 
[epoch 18] step 20/44: loss=0.6419 
[epoch 18] step 22/44: loss=0.6438 
[epoch 18] step 24/44: loss=0.6448 
[epoch 18] step 26/44: loss=0.6442 
[epoch 18] step 28/44: loss=0.6433 
[epoch 18] step 30/44: loss=0.6433 
[epoch 18] step 32/44: loss=0.6401 
[epoch 18] step 34/44: loss=0.6393 
[epoch 18] step 36/44: loss=0.6380 
[epoch 18] step 38/44: loss=0.6373 
[epoch 18] step 40/44: loss=0.6372 
[epoch 18] step 42/44: loss=0.6380 
[epoch 18] step 44/44: loss=0.6412 
[epoch 18] train_loss(avg per step)=1.2825 lambda[min,max]=[0.408912,1.000000]
[epoch 18] val_loss=1.5476 qwk=('0.3336', '0.2839', '0.2973') averageQWK=0.3049 macroEMD=0.2980 tailR0=('0.2381', '0.0000', '0.0000') tailR0avg=0.0794
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    4    0
    14   17   40   24    3
     6   12   65   70    2
     0    1    8   50    0
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    7    0
     1   34   13   34    0
     3   25   40   98    0
     0    2    4   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   47   37   20    0
     0   39   86   55    0
     0    1   11   24    0
     0    0    0    0    0
[epoch 19] step 2/44: loss=0.6842 
[epoch 19] step 4/44: loss=0.6993 
[epoch 19] step 6/44: loss=0.7125 
[epoch 19] step 8/44: loss=0.6997 
[epoch 19] step 10/44: loss=0.6929 
[epoch 19] step 12/44: loss=0.6776 
[epoch 19] step 14/44: loss=0.6620 
[epoch 19] step 16/44: loss=0.6460 
[epoch 19] step 18/44: loss=0.6401 
[epoch 19] step 20/44: loss=0.6322 
[epoch 19] step 22/44: loss=0.6292 
[epoch 19] step 24/44: loss=0.6345 
[epoch 19] step 26/44: loss=0.6384 
[epoch 19] step 28/44: loss=0.6406 
[epoch 19] step 30/44: loss=0.6437 
[epoch 19] step 32/44: loss=0.6467 
[epoch 19] step 34/44: loss=0.6463 
[epoch 19] step 36/44: loss=0.6479 
[epoch 19] step 38/44: loss=0.6475 
[epoch 19] step 40/44: loss=0.6439 
[epoch 19] step 42/44: loss=0.6416 
[epoch 19] step 44/44: loss=0.6396 
[epoch 19] train_loss(avg per step)=1.2792 lambda[min,max]=[0.403826,1.000000]
[epoch 19] val_loss=1.4114 qwk=('0.3710', '0.3499', '0.2547') averageQWK=0.3252 macroEMD=0.3054 tailR0=('0.1548', '0.0000', '0.0000') tailR0avg=0.0516
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    0    4    0
    12   25   35   26    0
     5   15   61   74    0
     0    2    8   49    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    6    0
     0   42   16   24    0
     0   34   47   85    0
     0    2    8   51    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   35   52   17    0
     0   33  107   40    0
     0    1   14   21    0
     0    0    0    0    0
[epoch 20] step 2/44: loss=0.5960 
[epoch 20] step 4/44: loss=0.5934 
[epoch 20] step 6/44: loss=0.5855 
[epoch 20] step 8/44: loss=0.5905 
[epoch 20] step 10/44: loss=0.6011 
[epoch 20] step 12/44: loss=0.6025 
[epoch 20] step 14/44: loss=0.6058 
[epoch 20] step 16/44: loss=0.6062 
[epoch 20] step 18/44: loss=0.6100 
[epoch 20] step 20/44: loss=0.6117 
[epoch 20] step 22/44: loss=0.6108 
[epoch 20] step 24/44: loss=0.6123 
[epoch 20] step 26/44: loss=0.6148 
[epoch 20] step 28/44: loss=0.6161 
[epoch 20] step 30/44: loss=0.6155 
[epoch 20] step 32/44: loss=0.6177 
[epoch 20] step 34/44: loss=0.6153 
[epoch 20] step 36/44: loss=0.6144 
[epoch 20] step 38/44: loss=0.6135 
[epoch 20] step 40/44: loss=0.6123 
[epoch 20] step 42/44: loss=0.6116 
[epoch 20] step 44/44: loss=0.6118 
[epoch 20] train_loss(avg per step)=1.2235 lambda[min,max]=[0.380946,1.000000]
[epoch 20] val_loss=1.4556 qwk=('0.3342', '0.2678', '0.2794') averageQWK=0.2938 macroEMD=0.3060 tailR0=('0.2262', '0.0000', '0.0000') tailR0avg=0.0754
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    1    4    0
    19   10   40   26    3
     7    9   65   73    1
     0    1    8   50    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    7    0
     0   35    8   39    0
     1   32   26  107    0
     0    2    2   57    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   41   41   22    0
     0   36   93   51    0
     0    1    9   26    0
     0    0    0    0    0
[epoch 21] step 2/44: loss=0.6423 
[epoch 21] step 4/44: loss=0.6383 
[epoch 21] step 6/44: loss=0.6381 
[epoch 21] step 8/44: loss=0.6391 
[epoch 21] step 10/44: loss=0.6378 
[epoch 21] step 12/44: loss=0.6343 
[epoch 21] step 14/44: loss=0.6336 
[epoch 21] step 16/44: loss=0.6295 
[epoch 21] step 18/44: loss=0.6201 
[epoch 21] step 20/44: loss=0.6152 
[epoch 21] step 22/44: loss=0.6079 
[epoch 21] step 24/44: loss=0.6082 
[epoch 21] step 26/44: loss=0.6087 
[epoch 21] step 28/44: loss=0.6090 
[epoch 21] step 30/44: loss=0.6093 
[epoch 21] step 32/44: loss=0.6113 
[epoch 21] step 34/44: loss=0.6090 
[epoch 21] step 36/44: loss=0.6072 
[epoch 21] step 38/44: loss=0.6095 
[epoch 21] step 40/44: loss=0.6119 
[epoch 21] step 42/44: loss=0.6121 
[epoch 21] step 44/44: loss=0.6115 
[epoch 21] train_loss(avg per step)=1.2230 lambda[min,max]=[0.371066,1.000000]
[epoch 21] val_loss=1.4438 qwk=('0.2863', '0.2469', '0.2432') averageQWK=0.2588 macroEMD=0.3090 tailR0=('0.2381', '0.0000', '0.0000') tailR0avg=0.0794
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    4    0
    12   14   44   21    7
     7    5   73   65    5
     0    1   10   47    1
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    7    0
     1   29   10   42    0
     1   24   31  110    0
     0    2    3   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   38   37   29    0
     0   30   80   70    0
     0    1    8   27    0
     0    0    0    0    0
[epoch 22] step 2/44: loss=0.5878 
[epoch 22] step 4/44: loss=0.5815 
[epoch 22] step 6/44: loss=0.5968 
[epoch 22] step 8/44: loss=0.5965 
[epoch 22] step 10/44: loss=0.5910 
[epoch 22] step 12/44: loss=0.5890 
[epoch 22] step 14/44: loss=0.5872 
[epoch 22] step 16/44: loss=0.5829 
[epoch 22] step 18/44: loss=0.5875 
[epoch 22] step 20/44: loss=0.5888 
[epoch 22] step 22/44: loss=0.5909 
[epoch 22] step 24/44: loss=0.5898 
[epoch 22] step 26/44: loss=0.5897 
[epoch 22] step 28/44: loss=0.5896 
[epoch 22] step 30/44: loss=0.5933 
[epoch 22] step 32/44: loss=0.5941 
[epoch 22] step 34/44: loss=0.5955 
[epoch 22] step 36/44: loss=0.5987 
[epoch 22] step 38/44: loss=0.5985 
[epoch 22] step 40/44: loss=0.5977 
[epoch 22] step 42/44: loss=0.5960 
[epoch 22] step 44/44: loss=0.5948 
[epoch 22] train_loss(avg per step)=1.1895 lambda[min,max]=[0.387844,1.000000]
[epoch 22] val_loss=1.3844 qwk=('0.3166', '0.2945', '0.2451') averageQWK=0.2854 macroEMD=0.3096 tailR0=('0.1548', '0.0000', '0.0000') tailR0avg=0.0516
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    4    0
    17    8   51   18    4
     9    6   75   62    3
     0    1   11   47    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    7    0
     3   36   10   33    0
     3   26   37  100    0
     0    2    6   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   44   35   25    0
     0   40   86   54    0
     0    1   13   22    0
     0    0    0    0    0
[epoch 23] step 2/44: loss=0.6180 
[epoch 23] step 4/44: loss=0.6153 
[epoch 23] step 6/44: loss=0.5926 
[epoch 23] step 8/44: loss=0.5905 
[epoch 23] step 10/44: loss=0.5806 
[epoch 23] step 12/44: loss=0.5840 
[epoch 23] step 14/44: loss=0.5816 
[epoch 23] step 16/44: loss=0.5828 
[epoch 23] step 18/44: loss=0.5830 
[epoch 23] step 20/44: loss=0.5853 
[epoch 23] step 22/44: loss=0.5861 
[epoch 23] step 24/44: loss=0.5877 
[epoch 23] step 26/44: loss=0.5892 
[epoch 23] step 28/44: loss=0.5894 
[epoch 23] step 30/44: loss=0.5899 
[epoch 23] step 32/44: loss=0.5916 
[epoch 23] step 34/44: loss=0.5925 
[epoch 23] step 36/44: loss=0.5925 
[epoch 23] step 38/44: loss=0.5911 
[epoch 23] step 40/44: loss=0.5902 
[epoch 23] step 42/44: loss=0.5890 
[epoch 23] step 44/44: loss=0.5905 
[epoch 23] train_loss(avg per step)=1.1810 lambda[min,max]=[0.363308,1.000000]
[epoch 23] val_loss=1.3896 qwk=('0.2875', '0.2684', '0.2344') averageQWK=0.2634 macroEMD=0.3089 tailR0=('0.2381', '0.0000', '0.0000') tailR0avg=0.0794
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
    14   12   41   26    5
     5   10   63   73    4
     0    1    9   47    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    7    0
     0   33   11   38    0
     1   22   43  100    0
     0    2    4   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   31   46   27    0
     0   29   85   66    0
     0    0    9   27    0
     0    0    0    0    0
[epoch 24] step 2/44: loss=0.5886 
[epoch 24] step 4/44: loss=0.5841 
[epoch 24] step 6/44: loss=0.5793 
[epoch 24] step 8/44: loss=0.5743 
[epoch 24] step 10/44: loss=0.5681 
[epoch 24] step 12/44: loss=0.5681 
[epoch 24] step 14/44: loss=0.5684 
[epoch 24] step 16/44: loss=0.5700 
[epoch 24] step 18/44: loss=0.5757 
[epoch 24] step 20/44: loss=0.5779 
[epoch 24] step 22/44: loss=0.5763 
[epoch 24] step 24/44: loss=0.5794 
[epoch 24] step 26/44: loss=0.5810 
[epoch 24] step 28/44: loss=0.5801 
[epoch 24] step 30/44: loss=0.5817 
[epoch 24] step 32/44: loss=0.5807 
[epoch 24] step 34/44: loss=0.5807 
[epoch 24] step 36/44: loss=0.5770 
[epoch 24] step 38/44: loss=0.5754 
[epoch 24] step 40/44: loss=0.5738 
[epoch 24] step 42/44: loss=0.5748 
[epoch 24] step 44/44: loss=0.5756 
[epoch 24] train_loss(avg per step)=1.1512 lambda[min,max]=[0.359361,1.000000]
[epoch 24] val_loss=1.3956 qwk=('0.2987', '0.2890', '0.2366') averageQWK=0.2748 macroEMD=0.3068 tailR0=('0.1548', '0.0000', '0.0000') tailR0avg=0.0516
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    4    0
    14   14   43   23    4
     7   11   62   72    3
     0    1   11   47    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    7    0
     1   31   17   33    0
     1   25   43   97    0
     0    2    3   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   44   32   28    0
     0   45   71   64    0
     0    1   11   24    0
     0    0    0    0    0
[epoch 25] step 2/44: loss=0.5750 
[epoch 25] step 4/44: loss=0.5914 
[epoch 25] step 6/44: loss=0.6003 
[epoch 25] step 8/44: loss=0.5999 
[epoch 25] step 10/44: loss=0.6036 
[epoch 25] step 12/44: loss=0.6042 
[epoch 25] step 14/44: loss=0.6043 
[epoch 25] step 16/44: loss=0.5992 
[epoch 25] step 18/44: loss=0.5969 
[epoch 25] step 20/44: loss=0.5892 
[epoch 25] step 22/44: loss=0.5870 
[epoch 25] step 24/44: loss=0.5849 
[epoch 25] step 26/44: loss=0.5811 
[epoch 25] step 28/44: loss=0.5805 
[epoch 25] step 30/44: loss=0.5800 
[epoch 25] step 32/44: loss=0.5779 
[epoch 25] step 34/44: loss=0.5773 
[epoch 25] step 36/44: loss=0.5767 
[epoch 25] step 38/44: loss=0.5767 
[epoch 25] step 40/44: loss=0.5766 
[epoch 25] step 42/44: loss=0.5764 
[epoch 25] step 44/44: loss=0.5786 
[epoch 25] train_loss(avg per step)=1.1573 lambda[min,max]=[0.363244,1.000000]
[epoch 25] val_loss=1.3502 qwk=('0.3074', '0.2654', '0.2592') averageQWK=0.2773 macroEMD=0.3066 tailR0=('0.1548', '0.0000', '0.0000') tailR0avg=0.0516
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
    16   10   48   19    5
     7    6   70   67    5
     0    1    9   48    1
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    8    0
     2   32   14   34    0
     3   24   40   99    0
     0    2    5   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   48   31   25    0
     0   52   68   60    0
     0    1   10   25    0
     0    0    0    0    0
[epoch 26] step 2/44: loss=0.5498 
[epoch 26] step 4/44: loss=0.5674 
[epoch 26] step 6/44: loss=0.5576 
[epoch 26] step 8/44: loss=0.5599 
[epoch 26] step 10/44: loss=0.5590 
[epoch 26] step 12/44: loss=0.5549 
[epoch 26] step 14/44: loss=0.5529 
[epoch 26] step 16/44: loss=0.5529 
[epoch 26] step 18/44: loss=0.5538 
[epoch 26] step 20/44: loss=0.5526 
[epoch 26] step 22/44: loss=0.5523 
[epoch 26] step 24/44: loss=0.5535 
[epoch 26] step 26/44: loss=0.5547 
[epoch 26] step 28/44: loss=0.5589 
[epoch 26] step 30/44: loss=0.5627 
[epoch 26] step 32/44: loss=0.5640 
[epoch 26] step 34/44: loss=0.5645 
[epoch 26] step 36/44: loss=0.5649 
[epoch 26] step 38/44: loss=0.5654 
[epoch 26] step 40/44: loss=0.5665 
[epoch 26] step 42/44: loss=0.5674 
[epoch 26] step 44/44: loss=0.5667 
[epoch 26] train_loss(avg per step)=1.1333 lambda[min,max]=[0.392348,1.000000]
[epoch 26] val_loss=1.3668 qwk=('0.3184', '0.2554', '0.2483') averageQWK=0.2740 macroEMD=0.3073 tailR0=('0.3095', '0.0357', '0.0000') tailR0avg=0.1151
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    1    4    0
    18    8   48   17    7
     8    6   78   58    5
     0    1   11   46    1
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    8    0
     2   30    9   41    0
     3   25   27  111    0
     0    1    2   58    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   43   34   27    0
     0   45   73   62    0
     0    1    9   26    0
     0    0    0    0    0
[epoch 27] step 2/44: loss=0.5800 
[epoch 27] step 4/44: loss=0.5673 
[epoch 27] step 6/44: loss=0.5694 
[epoch 27] step 8/44: loss=0.5717 
[epoch 27] step 10/44: loss=0.5636 
[epoch 27] step 12/44: loss=0.5599 
[epoch 27] step 14/44: loss=0.5591 
[epoch 27] step 16/44: loss=0.5570 
[epoch 27] step 18/44: loss=0.5571 
[epoch 27] step 20/44: loss=0.5582 
[epoch 27] step 22/44: loss=0.5599 
[epoch 27] step 24/44: loss=0.5582 
[epoch 27] step 26/44: loss=0.5584 
[epoch 27] step 28/44: loss=0.5625 
[epoch 27] step 30/44: loss=0.5630 
[epoch 27] step 32/44: loss=0.5628 
[epoch 27] step 34/44: loss=0.5611 
[epoch 27] step 36/44: loss=0.5613 
[epoch 27] step 38/44: loss=0.5615 
[epoch 27] step 40/44: loss=0.5621 
[epoch 27] step 42/44: loss=0.5607 
[epoch 27] step 44/44: loss=0.5590 
[epoch 27] train_loss(avg per step)=1.1180 lambda[min,max]=[0.367084,1.000000]
[epoch 27] val_loss=1.3622 qwk=('0.2952', '0.2457', '0.2328') averageQWK=0.2579 macroEMD=0.3085 tailR0=('0.1548', '0.0000', '0.0000') tailR0avg=0.0516
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
    17    9   47   19    6
     8    5   71   68    3
     0    1   10   48    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    8    0
     1   31   10   40    0
     2   27   30  107    0
     0    1    4   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   36   41   27    0
     0   36   81   63    0
     0    0   12   24    0
     0    0    0    0    0
[epoch 28] step 2/44: loss=0.5449 
[epoch 28] step 4/44: loss=0.5553 
[epoch 28] step 6/44: loss=0.5696 
[epoch 28] step 8/44: loss=0.5727 
[epoch 28] step 10/44: loss=0.5824 
[epoch 28] step 12/44: loss=0.5882 
[epoch 28] step 14/44: loss=0.5839 
[epoch 28] step 16/44: loss=0.5831 
[epoch 28] step 18/44: loss=0.5841 
[epoch 28] step 20/44: loss=0.5831 
[epoch 28] step 22/44: loss=0.5789 
[epoch 28] step 24/44: loss=0.5731 
[epoch 28] step 26/44: loss=0.5689 
[epoch 28] step 28/44: loss=0.5649 
[epoch 28] step 30/44: loss=0.5646 
[epoch 28] step 32/44: loss=0.5655 
[epoch 28] step 34/44: loss=0.5656 
[epoch 28] step 36/44: loss=0.5654 
[epoch 28] step 38/44: loss=0.5642 
[epoch 28] step 40/44: loss=0.5639 
[epoch 28] step 42/44: loss=0.5658 
[epoch 28] step 44/44: loss=0.5665 
[epoch 28] train_loss(avg per step)=1.1330 lambda[min,max]=[0.374231,1.000000]
[epoch 28] val_loss=1.3555 qwk=('0.2987', '0.2551', '0.2492') averageQWK=0.2677 macroEMD=0.3063 tailR0=('0.2381', '0.0000', '0.0000') tailR0avg=0.0794
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    4    0
    14    9   49   19    7
     7    5   74   64    5
     0    1    8   48    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    7    0
     1   31   11   39    0
     1   31   32  102    0
     0    2    4   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   45   31   28    0
     0   43   72   65    0
     0    1   10   25    0
     0    0    0    0    0
[epoch 29] step 2/44: loss=0.5448 
[epoch 29] step 4/44: loss=0.5454 
[epoch 29] step 6/44: loss=0.5523 
[epoch 29] step 8/44: loss=0.5432 
[epoch 29] step 10/44: loss=0.5449 
[epoch 29] step 12/44: loss=0.5477 
[epoch 29] step 14/44: loss=0.5458 
[epoch 29] step 16/44: loss=0.5439 
[epoch 29] step 18/44: loss=0.5449 
[epoch 29] step 20/44: loss=0.5490 
[epoch 29] step 22/44: loss=0.5527 
[epoch 29] step 24/44: loss=0.5515 
[epoch 29] step 26/44: loss=0.5504 
[epoch 29] step 28/44: loss=0.5534 
[epoch 29] step 30/44: loss=0.5545 
[epoch 29] step 32/44: loss=0.5563 
[epoch 29] step 34/44: loss=0.5591 
[epoch 29] step 36/44: loss=0.5616 
[epoch 29] step 38/44: loss=0.5633 
[epoch 29] step 40/44: loss=0.5626 
[epoch 29] step 42/44: loss=0.5629 
[epoch 29] step 44/44: loss=0.5640 
[epoch 29] train_loss(avg per step)=1.1281 lambda[min,max]=[0.381907,1.000000]
[epoch 29] val_loss=1.3200 qwk=('0.2947', '0.2881', '0.2478') averageQWK=0.2769 macroEMD=0.3068 tailR0=('0.1548', '0.0000', '0.0000') tailR0avg=0.0516
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
    17   11   45   19    6
     7    7   75   62    4
     0    1   12   46    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    7    0
     1   37    9   35    0
     0   34   28  104    0
     0    2    4   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   46   34   24    0
     0   43   81   56    0
     0    1   14   21    0
     0    0    0    0    0
[epoch 30] step 2/44: loss=0.5633 
[epoch 30] step 4/44: loss=0.5473 
[epoch 30] step 6/44: loss=0.5341 
[epoch 30] step 8/44: loss=0.5392 
[epoch 30] step 10/44: loss=0.5374 
[epoch 30] step 12/44: loss=0.5413 
[epoch 30] step 14/44: loss=0.5392 
[epoch 30] step 16/44: loss=0.5369 
[epoch 30] step 18/44: loss=0.5398 
[epoch 30] step 20/44: loss=0.5379 
[epoch 30] step 22/44: loss=0.5401 
[epoch 30] step 24/44: loss=0.5410 
[epoch 30] step 26/44: loss=0.5439 
[epoch 30] step 28/44: loss=0.5420 
[epoch 30] step 30/44: loss=0.5426 
[epoch 30] step 32/44: loss=0.5422 
[epoch 30] step 34/44: loss=0.5429 
[epoch 30] step 36/44: loss=0.5438 
[epoch 30] step 38/44: loss=0.5449 
[epoch 30] step 40/44: loss=0.5455 
[epoch 30] step 42/44: loss=0.5455 
[epoch 30] step 44/44: loss=0.5468 
[epoch 30] train_loss(avg per step)=1.0937 lambda[min,max]=[0.367298,1.000000]
[epoch 30] val_loss=1.3403 qwk=('0.3323', '0.2902', '0.2579') averageQWK=0.2935 macroEMD=0.3050 tailR0=('0.1548', '0.0000', '0.0000') tailR0avg=0.0516
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    4    0
    16   10   49   20    3
     7    6   77   64    1
     0    1   10   48    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    7    0
     1   37    9   35    0
     0   32   31  103    0
     0    2    4   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   43   33   28    0
     0   40   74   66    0
     0    1    8   27    0
     0    0    0    0    0
[epoch 31] step 2/44: loss=0.5839 
[epoch 31] step 4/44: loss=0.5835 
[epoch 31] step 6/44: loss=0.5788 
[epoch 31] step 8/44: loss=0.5633 
[epoch 31] step 10/44: loss=0.5548 
[epoch 31] step 12/44: loss=0.5490 
[epoch 31] step 14/44: loss=0.5449 
[epoch 31] step 16/44: loss=0.5445 
[epoch 31] step 18/44: loss=0.5471 
[epoch 31] step 20/44: loss=0.5450 
[epoch 31] step 22/44: loss=0.5462 
[epoch 31] step 24/44: loss=0.5454 
[epoch 31] step 26/44: loss=0.5456 
[epoch 31] step 28/44: loss=0.5450 
[epoch 31] step 30/44: loss=0.5435 
[epoch 31] step 32/44: loss=0.5425 
[epoch 31] step 34/44: loss=0.5404 
[epoch 31] step 36/44: loss=0.5387 
[epoch 31] step 38/44: loss=0.5389 
[epoch 31] step 40/44: loss=0.5382 
[epoch 31] step 42/44: loss=0.5397 
[epoch 31] step 44/44: loss=0.5398 
[epoch 31] train_loss(avg per step)=1.0796 lambda[min,max]=[0.356881,1.000000]
[epoch 31] val_loss=1.3434 qwk=('0.3419', '0.2681', '0.2474') averageQWK=0.2858 macroEMD=0.3041 tailR0=('0.1548', '0.0000', '0.0000') tailR0avg=0.0516
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    4    0
    17    8   52   18    3
     7    5   82   60    1
     0    1   10   48    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    7    0
     1   31   13   37    0
     0   28   33  105    0
     0    2    4   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   44   33   27    0
     0   44   76   60    0
     0    1   10   25    0
     0    0    0    0    0
[epoch 32] step 2/44: loss=0.5869 
[epoch 32] step 4/44: loss=0.5820 
[epoch 32] step 6/44: loss=0.5796 
[epoch 32] step 8/44: loss=0.5825 
[epoch 32] step 10/44: loss=0.5872 
[epoch 32] step 12/44: loss=0.5931 
[epoch 32] step 14/44: loss=0.5899 
[epoch 32] step 16/44: loss=0.5896 
[epoch 32] step 18/44: loss=0.5866 
[epoch 32] step 20/44: loss=0.5851 
[epoch 32] step 22/44: loss=0.5785 
[epoch 32] step 24/44: loss=0.5742 
[epoch 32] step 26/44: loss=0.5715 
[epoch 32] step 28/44: loss=0.5689 
[epoch 32] step 30/44: loss=0.5678 
[epoch 32] step 32/44: loss=0.5647 
[epoch 32] step 34/44: loss=0.5629 
[epoch 32] step 36/44: loss=0.5598 
[epoch 32] step 38/44: loss=0.5567 
[epoch 32] step 40/44: loss=0.5566 
[epoch 32] step 42/44: loss=0.5547 
[epoch 32] step 44/44: loss=0.5544 
[epoch 32] train_loss(avg per step)=1.1088 lambda[min,max]=[0.381786,1.000000]
[epoch 32] val_loss=1.3036 qwk=('0.3504', '0.2775', '0.2480') averageQWK=0.2920 macroEMD=0.3055 tailR0=('0.2262', '0.0000', '0.0000') tailR0avg=0.0754
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    1    4    0
    18    9   48   20    3
     7    6   76   65    1
     0    1   10   48    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    7    0
     1   33   13   35    0
     1   30   32  103    0
     0    2    4   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   41   35   28    0
     0   41   77   62    0
     0    1    8   27    0
     0    0    0    0    0
[epoch 33] step 2/44: loss=0.5485 
[epoch 33] step 4/44: loss=0.5449 
[epoch 33] step 6/44: loss=0.5491 
[epoch 33] step 8/44: loss=0.5597 
[epoch 33] step 10/44: loss=0.5608 
[epoch 33] step 12/44: loss=0.5645 
[epoch 33] step 14/44: loss=0.5638 
[epoch 33] step 16/44: loss=0.5594 
[epoch 33] step 18/44: loss=0.5584 
[epoch 33] step 20/44: loss=0.5590 
[epoch 33] step 22/44: loss=0.5604 
[epoch 33] step 24/44: loss=0.5584 
[epoch 33] step 26/44: loss=0.5583 
[epoch 33] step 28/44: loss=0.5551 
[epoch 33] step 30/44: loss=0.5540 
[epoch 33] step 32/44: loss=0.5525 
[epoch 33] step 34/44: loss=0.5522 
[epoch 33] step 36/44: loss=0.5530 
[epoch 33] step 38/44: loss=0.5525 
[epoch 33] step 40/44: loss=0.5516 
[epoch 33] step 42/44: loss=0.5502 
[epoch 33] step 44/44: loss=0.5498 
[epoch 33] train_loss(avg per step)=1.0997 lambda[min,max]=[0.377160,1.000000]
[epoch 33] val_loss=1.3026 qwk=('0.3389', '0.2370', '0.2492') averageQWK=0.2750 macroEMD=0.3075 tailR0=('0.2262', '0.0000', '0.0000') tailR0avg=0.0754
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    1    4    0
    18   10   46   20    4
     7    6   72   67    3
     0    1   10   48    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    8    0
     1   30   10   41    0
     1   27   31  107    0
     0    2    3   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   41   39   24    0
     0   41   84   55    0
     0    1   11   24    0
     0    0    0    0    0
[epoch 34] step 2/44: loss=0.5222 
[epoch 34] step 4/44: loss=0.5219 
[epoch 34] step 6/44: loss=0.5251 
[epoch 34] step 8/44: loss=0.5206 
[epoch 34] step 10/44: loss=0.5246 
[epoch 34] step 12/44: loss=0.5286 
[epoch 34] step 14/44: loss=0.5333 
[epoch 34] step 16/44: loss=0.5309 
[epoch 34] step 18/44: loss=0.5314 
[epoch 34] step 20/44: loss=0.5342 
[epoch 34] step 22/44: loss=0.5361 
[epoch 34] step 24/44: loss=0.5394 
[epoch 34] step 26/44: loss=0.5397 
[epoch 34] step 28/44: loss=0.5416 
[epoch 34] step 30/44: loss=0.5397 
[epoch 34] step 32/44: loss=0.5407 
[epoch 34] step 34/44: loss=0.5408 
[epoch 34] step 36/44: loss=0.5393 
[epoch 34] step 38/44: loss=0.5398 
[epoch 34] step 40/44: loss=0.5402 
[epoch 34] step 42/44: loss=0.5412 
[epoch 34] step 44/44: loss=0.5421 
[epoch 34] train_loss(avg per step)=1.0842 lambda[min,max]=[0.385015,1.000000]
[epoch 34] val_loss=1.3178 qwk=('0.3442', '0.2402', '0.2413') averageQWK=0.2752 macroEMD=0.3067 tailR0=('0.2262', '0.0000', '0.0000') tailR0avg=0.0754
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    1    4    0
    19    9   46   20    4
     7    6   73   66    3
     0    1    9   49    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    8    0
     1   30   12   39    0
     1   28   32  105    0
     0    2    4   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   41   37   26    0
     0   44   76   60    0
     0    1   10   25    0
     0    0    0    0    0
[epoch 35] step 2/44: loss=0.5725 
[epoch 35] step 4/44: loss=0.5768 
[epoch 35] step 6/44: loss=0.5731 
[epoch 35] step 8/44: loss=0.5678 
[epoch 35] step 10/44: loss=0.5574 
[epoch 35] step 12/44: loss=0.5577 
[epoch 35] step 14/44: loss=0.5554 
[epoch 35] step 16/44: loss=0.5553 
[epoch 35] step 18/44: loss=0.5555 
[epoch 35] step 20/44: loss=0.5563 
[epoch 35] step 22/44: loss=0.5571 
[epoch 35] step 24/44: loss=0.5553 
[epoch 35] step 26/44: loss=0.5554 
[epoch 35] step 28/44: loss=0.5546 
[epoch 35] step 30/44: loss=0.5525 
[epoch 35] step 32/44: loss=0.5513 
[epoch 35] step 34/44: loss=0.5506 
[epoch 35] step 36/44: loss=0.5508 
[epoch 35] step 38/44: loss=0.5489 
[epoch 35] step 40/44: loss=0.5476 
[epoch 35] step 42/44: loss=0.5489 
[epoch 35] step 44/44: loss=0.5482 
[epoch 35] train_loss(avg per step)=1.0964 lambda[min,max]=[0.361914,1.000000]
[epoch 35] val_loss=1.3147 qwk=('0.3426', '0.2506', '0.2462') averageQWK=0.2798 macroEMD=0.3071 tailR0=('0.2262', '0.0000', '0.0000') tailR0avg=0.0754
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    1    4    0
    20    8   46   20    4
     7    6   74   65    3
     0    1   10   48    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    8    0
     1   33    9   39    0
     0   29   30  107    0
     0    2    4   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   41   37   26    0
     0   41   79   60    0
     0    1   10   25    0
     0    0    0    0    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-1/fold2/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-1/fold2/metrics.json
Done.
