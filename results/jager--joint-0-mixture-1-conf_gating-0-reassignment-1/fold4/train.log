[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.7591 
[epoch 1] step 4/44: loss=0.7473 
[epoch 1] step 6/44: loss=0.7402 
[epoch 1] step 8/44: loss=0.7344 
[epoch 1] step 10/44: loss=0.7371 
[epoch 1] step 12/44: loss=0.7347 
[epoch 1] step 14/44: loss=0.7363 
[epoch 1] step 16/44: loss=0.7361 
[epoch 1] step 18/44: loss=0.7332 
[epoch 1] step 20/44: loss=0.7312 
[epoch 1] step 22/44: loss=0.7292 
[epoch 1] step 24/44: loss=0.7280 
[epoch 1] step 26/44: loss=0.7274 
[epoch 1] step 28/44: loss=0.7251 
[epoch 1] step 30/44: loss=0.7246 
[epoch 1] step 32/44: loss=0.7234 
[epoch 1] step 34/44: loss=0.7226 
[epoch 1] step 36/44: loss=0.7212 
[epoch 1] step 38/44: loss=0.7224 
[epoch 1] step 40/44: loss=0.7241 
[epoch 1] step 42/44: loss=0.7266 
[epoch 1] step 44/44: loss=0.7251 
[epoch 1] train_loss(avg per step)=1.4503 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.3005 qwk=('0.0961', '0.0784', '0.0469') averageQWK=0.0738 macroEMD=0.3857 tailR0=('0.0000', '0.2778', '0.0000') tailR0avg=0.0926
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    0    5    0
     0   61    0   21    0
     0  131    0   24    0
     0   47    0   26    0
     0    3    0    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     5    0    3    1    0
    56    0   17    3    0
   133    0   23    8    0
    51    0    9   20    0
     1    0    0    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    5   87    0    0
     0    2  164    0    0
     0    0   72    0    0
     0    0    1    0    0
[epoch 2] step 2/44: loss=0.9200 
[epoch 2] step 4/44: loss=0.9227 
[epoch 2] step 6/44: loss=0.9239 
[epoch 2] step 8/44: loss=0.9250 
[epoch 2] step 10/44: loss=0.9269 
[epoch 2] step 12/44: loss=0.9288 
[epoch 2] step 14/44: loss=0.9213 
[epoch 2] step 16/44: loss=0.9085 
[epoch 2] step 18/44: loss=0.8974 
[epoch 2] step 20/44: loss=0.8815 
[epoch 2] step 22/44: loss=0.8739 
[epoch 2] step 24/44: loss=0.8642 
[epoch 2] step 26/44: loss=0.8612 
[epoch 2] step 28/44: loss=0.8611 
[epoch 2] step 30/44: loss=0.8617 
[epoch 2] step 32/44: loss=0.8625 
[epoch 2] step 34/44: loss=0.8648 
[epoch 2] step 36/44: loss=0.8650 
[epoch 2] step 38/44: loss=0.8631 
[epoch 2] step 40/44: loss=0.8591 
[epoch 2] step 42/44: loss=0.8561 
[epoch 2] step 44/44: loss=0.8493 
[epoch 2] train_loss(avg per step)=1.6985 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.0367 qwk=('0.0060', '0.0181', '0.1009') averageQWK=0.0417 macroEMD=0.3629 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0   15    0
     0    1    0   81    0
     0    0    0  155    0
     0    0    0   73    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    8    0
     0    0    3   73    0
     0    0    2  162    0
     0    0    0   80    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    1   22   69    0
     0    0   26  140    0
     0    0    2   70    0
     0    0    0    1    0
[epoch 3] step 2/44: loss=0.6691 
[epoch 3] step 4/44: loss=0.6679 
[epoch 3] step 6/44: loss=0.6890 
[epoch 3] step 8/44: loss=0.6923 
[epoch 3] step 10/44: loss=0.6998 
[epoch 3] step 12/44: loss=0.7060 
[epoch 3] step 14/44: loss=0.7191 
[epoch 3] step 16/44: loss=0.7284 
[epoch 3] step 18/44: loss=0.7410 
[epoch 3] step 20/44: loss=0.7537 
[epoch 3] step 22/44: loss=0.7598 
[epoch 3] step 24/44: loss=0.7611 
[epoch 3] step 26/44: loss=0.7629 
[epoch 3] step 28/44: loss=0.7664 
[epoch 3] step 30/44: loss=0.7667 
[epoch 3] step 32/44: loss=0.7650 
[epoch 3] step 34/44: loss=0.7644 
[epoch 3] step 36/44: loss=0.7671 
[epoch 3] step 38/44: loss=0.7724 
[epoch 3] step 40/44: loss=0.7754 
[epoch 3] step 42/44: loss=0.7769 
[epoch 3] step 44/44: loss=0.7721 
[epoch 3] train_loss(avg per step)=1.5441 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=1.4665 qwk=('0.3694', '0.3245', '0.4223') averageQWK=0.3720 macroEMD=0.3234 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3   10    2    0
     0   13   52   17    0
     0    8   65   82    0
     0    0   11   62    0
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   58   18    0
     0    0   78   86    0
     0    0    8   72    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   40   30   22    0
     0   47   62   57    0
     0    0   13   59    0
     0    0    0    1    0
[epoch 4] step 2/44: loss=0.8156 
[epoch 4] step 4/44: loss=0.8277 
[epoch 4] step 6/44: loss=0.8340 
[epoch 4] step 8/44: loss=0.8384 
[epoch 4] step 10/44: loss=0.8368 
[epoch 4] step 12/44: loss=0.8361 
[epoch 4] step 14/44: loss=0.8318 
[epoch 4] step 16/44: loss=0.8327 
[epoch 4] step 18/44: loss=0.8316 
[epoch 4] step 20/44: loss=0.8305 
[epoch 4] step 22/44: loss=0.8269 
[epoch 4] step 24/44: loss=0.8274 
[epoch 4] step 26/44: loss=0.8285 
[epoch 4] step 28/44: loss=0.8213 
[epoch 4] step 30/44: loss=0.8185 
[epoch 4] step 32/44: loss=0.8197 
[epoch 4] step 34/44: loss=0.8192 
[epoch 4] step 36/44: loss=0.8182 
[epoch 4] step 38/44: loss=0.8185 
[epoch 4] step 40/44: loss=0.8183 
[epoch 4] step 42/44: loss=0.8207 
[epoch 4] step 44/44: loss=0.8200 
[epoch 4] train_loss(avg per step)=1.6399 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=1.6092 qwk=('0.2588', '0.2153', '0.3305') averageQWK=0.2682 macroEMD=0.3291 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    5    0
     0    0   50   32    0
     0    0   48  107    0
     0    0    0   73    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    0   37   39    0
     0    0   41  123    0
     0    0    0   80    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    0   77   15    0
     0    0  119   47    0
     0    0   15   57    0
     0    0    0    1    0
[epoch 5] step 2/44: loss=0.8366 
[epoch 5] step 4/44: loss=0.8563 
[epoch 5] step 6/44: loss=0.8673 
[epoch 5] step 8/44: loss=0.8728 
[epoch 5] step 10/44: loss=0.8610 
[epoch 5] step 12/44: loss=0.8452 
[epoch 5] step 14/44: loss=0.8332 
[epoch 5] step 16/44: loss=0.8280 
[epoch 5] step 18/44: loss=0.8209 
[epoch 5] step 20/44: loss=0.8167 
[epoch 5] step 22/44: loss=0.8180 
[epoch 5] step 24/44: loss=0.8191 
[epoch 5] step 26/44: loss=0.8207 
[epoch 5] step 28/44: loss=0.8200 
[epoch 5] step 30/44: loss=0.8190 
[epoch 5] step 32/44: loss=0.8194 
[epoch 5] step 34/44: loss=0.8184 
[epoch 5] step 36/44: loss=0.8199 
[epoch 5] step 38/44: loss=0.8200 
[epoch 5] step 40/44: loss=0.8197 
[epoch 5] step 42/44: loss=0.8196 
[epoch 5] step 44/44: loss=0.8157 
[epoch 5] train_loss(avg per step)=1.6314 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=1.6159 qwk=('0.3563', '0.3569', '0.3194') averageQWK=0.3442 macroEMD=0.3080 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   12    2    0
     0    6   59   17    0
     0    0   78   77    0
     0    0    9   64    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   62   14    0
     0    0   93   71    0
     0    0    9   71    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    7   62   23    0
     0    2  102   62    0
     0    0   13   59    0
     0    0    0    1    0
[epoch 6] step 2/44: loss=0.8313 
[epoch 6] step 4/44: loss=0.8316 
[epoch 6] step 6/44: loss=0.8249 
[epoch 6] step 8/44: loss=0.8086 
[epoch 6] step 10/44: loss=0.8018 
[epoch 6] step 12/44: loss=0.8017 
[epoch 6] step 14/44: loss=0.8004 
[epoch 6] step 16/44: loss=0.7957 
[epoch 6] step 18/44: loss=0.7920 
[epoch 6] step 20/44: loss=0.7903 
[epoch 6] step 22/44: loss=0.7913 
[epoch 6] step 24/44: loss=0.7861 
[epoch 6] step 26/44: loss=0.7861 
[epoch 6] step 28/44: loss=0.7848 
[epoch 6] step 30/44: loss=0.7860 
[epoch 6] step 32/44: loss=0.7852 
[epoch 6] step 34/44: loss=0.7869 
[epoch 6] step 36/44: loss=0.7863 
[epoch 6] step 38/44: loss=0.7868 
[epoch 6] step 40/44: loss=0.7852 
[epoch 6] step 42/44: loss=0.7863 
[epoch 6] step 44/44: loss=0.7850 
[epoch 6] train_loss(avg per step)=1.5701 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=1.6807 qwk=('0.2911', '0.2424', '0.3475') averageQWK=0.2937 macroEMD=0.3057 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    3    0
     0    2   52   28    0
     0    0   54  101    0
     0    0    3   70    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    1   40   35    0
     0    0   39  125    0
     0    0    1   79    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    5   74   13    0
     0    0  127   39    0
     0    0   22   50    0
     0    0    0    1    0
[epoch 7] step 2/44: loss=0.8235 
[epoch 7] step 4/44: loss=0.8150 
[epoch 7] step 6/44: loss=0.8283 
[epoch 7] step 8/44: loss=0.8222 
[epoch 7] step 10/44: loss=0.8207 
[epoch 7] step 12/44: loss=0.8240 
[epoch 7] step 14/44: loss=0.8264 
[epoch 7] step 16/44: loss=0.8231 
[epoch 7] step 18/44: loss=0.8150 
[epoch 7] step 20/44: loss=0.8143 
[epoch 7] step 22/44: loss=0.8101 
[epoch 7] step 24/44: loss=0.8095 
[epoch 7] step 26/44: loss=0.8094 
[epoch 7] step 28/44: loss=0.8079 
[epoch 7] step 30/44: loss=0.8081 
[epoch 7] step 32/44: loss=0.8098 
[epoch 7] step 34/44: loss=0.8097 
[epoch 7] step 36/44: loss=0.8080 
[epoch 7] step 38/44: loss=0.8098 
[epoch 7] step 40/44: loss=0.8091 
[epoch 7] step 42/44: loss=0.8056 
[epoch 7] step 44/44: loss=0.7993 
[epoch 7] train_loss(avg per step)=1.5985 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.4218 qwk=('0.5258', '0.4798', '0.3909') averageQWK=0.4655 macroEMD=0.2945 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    3    2    0
     0   32   39   11    0
     0   15   92   48    0
     0    0   14   59    0
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   20   43   13    0
     0   11  103   50    0
     0    0   12   68    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   10   72   10    0
     0    8  128   30    0
     0    0   24   48    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=0.7406 
[epoch 8] step 4/44: loss=0.7341 
[epoch 8] step 6/44: loss=0.7525 
[epoch 8] step 8/44: loss=0.7642 
[epoch 8] step 10/44: loss=0.7761 
[epoch 8] step 12/44: loss=0.7795 
[epoch 8] step 14/44: loss=0.7800 
[epoch 8] step 16/44: loss=0.7806 
[epoch 8] step 18/44: loss=0.7788 
[epoch 8] step 20/44: loss=0.7792 
[epoch 8] step 22/44: loss=0.7848 
[epoch 8] step 24/44: loss=0.7888 
[epoch 8] step 26/44: loss=0.7916 
[epoch 8] step 28/44: loss=0.7912 
[epoch 8] step 30/44: loss=0.7897 
[epoch 8] step 32/44: loss=0.7849 
[epoch 8] step 34/44: loss=0.7839 
[epoch 8] step 36/44: loss=0.7799 
[epoch 8] step 38/44: loss=0.7770 
[epoch 8] step 40/44: loss=0.7765 
[epoch 8] step 42/44: loss=0.7759 
[epoch 8] step 44/44: loss=0.7752 
[epoch 8] train_loss(avg per step)=1.5504 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.4854 qwk=('0.4300', '0.3851', '0.3901') averageQWK=0.4018 macroEMD=0.2977 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   11    2    0
     0   10   67    5    0
     0    2  112   39    2
     0    0   17   53    3
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    5   59   12    0
     0    5  105   54    0
     0    0   13   67    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   14   71    7    0
     0   21  126   19    0
     0    0   32   40    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=0.7576 
[epoch 9] step 4/44: loss=0.7557 
[epoch 9] step 6/44: loss=0.7611 
[epoch 9] step 8/44: loss=0.7659 
[epoch 9] step 10/44: loss=0.7733 
[epoch 9] step 12/44: loss=0.7818 
[epoch 9] step 14/44: loss=0.7881 
[epoch 9] step 16/44: loss=0.7914 
[epoch 9] step 18/44: loss=0.7967 
[epoch 9] step 20/44: loss=0.7997 
[epoch 9] step 22/44: loss=0.7947 
[epoch 9] step 24/44: loss=0.7920 
[epoch 9] step 26/44: loss=0.7869 
[epoch 9] step 28/44: loss=0.7836 
[epoch 9] step 30/44: loss=0.7797 
[epoch 9] step 32/44: loss=0.7766 
[epoch 9] step 34/44: loss=0.7731 
[epoch 9] step 36/44: loss=0.7728 
[epoch 9] step 38/44: loss=0.7723 
[epoch 9] step 40/44: loss=0.7707 
[epoch 9] step 42/44: loss=0.7688 
[epoch 9] step 44/44: loss=0.7632 
[epoch 9] train_loss(avg per step)=1.5265 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.4249 qwk=('0.4966', '0.5240', '0.3637') averageQWK=0.4614 macroEMD=0.2978 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    4    1    0
     0   35   40    7    0
     0   16  114   25    0
     0    0   29   44    0
     0    0    6    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    1    0
     0   37   31    8    0
     0   50   80   34    0
     0    2   19   59    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   18   69    5    0
     0   30  121   15    0
     0    2   36   34    0
     0    0    0    1    0
[epoch 10] step 2/44: loss=0.7363 
[epoch 10] step 4/44: loss=0.7516 
[epoch 10] step 6/44: loss=0.7491 
[epoch 10] step 8/44: loss=0.7587 
[epoch 10] step 10/44: loss=0.7722 
[epoch 10] step 12/44: loss=0.7795 
[epoch 10] step 14/44: loss=0.7720 
[epoch 10] step 16/44: loss=0.7751 
[epoch 10] step 18/44: loss=0.7718 
[epoch 10] step 20/44: loss=0.7681 
[epoch 10] step 22/44: loss=0.7680 
[epoch 10] step 24/44: loss=0.7685 
[epoch 10] step 26/44: loss=0.7677 
[epoch 10] step 28/44: loss=0.7696 
[epoch 10] step 30/44: loss=0.7711 
[epoch 10] step 32/44: loss=0.7712 
[epoch 10] step 34/44: loss=0.7716 
[epoch 10] step 36/44: loss=0.7701 
[epoch 10] step 38/44: loss=0.7681 
[epoch 10] step 40/44: loss=0.7663 
[epoch 10] step 42/44: loss=0.7666 
[epoch 10] step 44/44: loss=0.7704 
[epoch 10] train_loss(avg per step)=1.5407 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.6419 qwk=('0.3314', '0.3377', '0.3478') averageQWK=0.3390 macroEMD=0.2973 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    2    0
     0    3   60   19    0
     0    0   71   84    0
     0    0    7   66    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    4   51   21    0
     0    1   74   89    0
     0    0    6   74    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    5   79    8    0
     0    3  134   29    0
     0    0   29   43    0
     0    0    0    1    0
[epoch 11] step 2/44: loss=0.7988 
[epoch 11] step 4/44: loss=0.7736 
[epoch 11] step 6/44: loss=0.7685 
[epoch 11] step 8/44: loss=0.7631 
[epoch 11] step 10/44: loss=0.7564 
[epoch 11] step 12/44: loss=0.7443 
[epoch 11] step 14/44: loss=0.7417 
[epoch 11] step 16/44: loss=0.7402 
[epoch 11] step 18/44: loss=0.7438 
[epoch 11] step 20/44: loss=0.7415 
[epoch 11] step 22/44: loss=0.7400 
[epoch 11] step 24/44: loss=0.7414 
[epoch 11] step 26/44: loss=0.7429 
[epoch 11] step 28/44: loss=0.7428 
[epoch 11] step 30/44: loss=0.7405 
[epoch 11] step 32/44: loss=0.7408 
[epoch 11] step 34/44: loss=0.7409 
[epoch 11] step 36/44: loss=0.7381 
[epoch 11] step 38/44: loss=0.7368 
[epoch 11] step 40/44: loss=0.7360 
[epoch 11] step 42/44: loss=0.7333 
[epoch 11] step 44/44: loss=0.7344 
[epoch 11] train_loss(avg per step)=1.4689 lambda[min,max]=[0.489925,1.000000]
[epoch 11] val_loss=1.4404 qwk=('0.4783', '0.4392', '0.4102') averageQWK=0.4426 macroEMD=0.2896 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   16   59    7    0
     0    5  121   28    1
     0    0   19   52    2
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   11   53   12    0
     0    5  112   47    0
     0    0   15   65    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   11   74    7    0
     0   11  137   18    0
     0    0   29   43    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=0.6889 
[epoch 12] step 4/44: loss=0.7201 
[epoch 12] step 6/44: loss=0.7293 
[epoch 12] step 8/44: loss=0.7367 
[epoch 12] step 10/44: loss=0.7423 
[epoch 12] step 12/44: loss=0.7434 
[epoch 12] step 14/44: loss=0.7480 
[epoch 12] step 16/44: loss=0.7476 
[epoch 12] step 18/44: loss=0.7463 
[epoch 12] step 20/44: loss=0.7448 
[epoch 12] step 22/44: loss=0.7376 
[epoch 12] step 24/44: loss=0.7373 
[epoch 12] step 26/44: loss=0.7375 
[epoch 12] step 28/44: loss=0.7339 
[epoch 12] step 30/44: loss=0.7332 
[epoch 12] step 32/44: loss=0.7343 
[epoch 12] step 34/44: loss=0.7336 
[epoch 12] step 36/44: loss=0.7343 
[epoch 12] step 38/44: loss=0.7358 
[epoch 12] step 40/44: loss=0.7361 
[epoch 12] step 42/44: loss=0.7349 
[epoch 12] step 44/44: loss=0.7300 
[epoch 12] train_loss(avg per step)=1.4599 lambda[min,max]=[0.473958,1.000000]
[epoch 12] val_loss=1.5412 qwk=('0.3560', '0.3143', '0.3627') averageQWK=0.3443 macroEMD=0.3020 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   11    2    0
     0    7   55   20    0
     0    1   77   76    1
     0    0    9   61    3
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    6   44   26    0
     0    2   69   93    0
     0    0    6   74    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    7   69   16    0
     0    6  117   43    0
     0    0   17   55    0
     0    0    0    1    0
[epoch 13] step 2/44: loss=0.7488 
[epoch 13] step 4/44: loss=0.7588 
[epoch 13] step 6/44: loss=0.7500 
[epoch 13] step 8/44: loss=0.7397 
[epoch 13] step 10/44: loss=0.7326 
[epoch 13] step 12/44: loss=0.7250 
[epoch 13] step 14/44: loss=0.7221 
[epoch 13] step 16/44: loss=0.7181 
[epoch 13] step 18/44: loss=0.7165 
[epoch 13] step 20/44: loss=0.7143 
[epoch 13] step 22/44: loss=0.7132 
[epoch 13] step 24/44: loss=0.7108 
[epoch 13] step 26/44: loss=0.7124 
[epoch 13] step 28/44: loss=0.7106 
[epoch 13] step 30/44: loss=0.7131 
[epoch 13] step 32/44: loss=0.7118 
[epoch 13] step 34/44: loss=0.7095 
[epoch 13] step 36/44: loss=0.7089 
[epoch 13] step 38/44: loss=0.7068 
[epoch 13] step 40/44: loss=0.7054 
[epoch 13] step 42/44: loss=0.7052 
[epoch 13] step 44/44: loss=0.7089 
[epoch 13] train_loss(avg per step)=1.4179 lambda[min,max]=[0.442211,1.000000]
[epoch 13] val_loss=1.4814 qwk=('0.4264', '0.3519', '0.3489') averageQWK=0.3757 macroEMD=0.2985 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    2    0
     0   15   52   15    0
     0    8   76   71    0
     0    0   12   57    4
     0    0    0    9    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   10   46   20    0
     0    2   76   86    0
     0    0    8   72    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    5   72   15    0
     0    2  120   44    0
     0    0   20   52    0
     0    0    0    1    0
[epoch 14] step 2/44: loss=0.7303 
[epoch 14] step 4/44: loss=0.7167 
[epoch 14] step 6/44: loss=0.6980 
[epoch 14] step 8/44: loss=0.6869 
[epoch 14] step 10/44: loss=0.6873 
[epoch 14] step 12/44: loss=0.6873 
[epoch 14] step 14/44: loss=0.6847 
[epoch 14] step 16/44: loss=0.6887 
[epoch 14] step 18/44: loss=0.6896 
[epoch 14] step 20/44: loss=0.6884 
[epoch 14] step 22/44: loss=0.6899 
[epoch 14] step 24/44: loss=0.6928 
[epoch 14] step 26/44: loss=0.6941 
[epoch 14] step 28/44: loss=0.6960 
[epoch 14] step 30/44: loss=0.6948 
[epoch 14] step 32/44: loss=0.6971 
[epoch 14] step 34/44: loss=0.6979 
[epoch 14] step 36/44: loss=0.7012 
[epoch 14] step 38/44: loss=0.6994 
[epoch 14] step 40/44: loss=0.6989 
[epoch 14] step 42/44: loss=0.6976 
[epoch 14] step 44/44: loss=0.7013 
[epoch 14] train_loss(avg per step)=1.4027 lambda[min,max]=[0.458833,1.000000]
[epoch 14] val_loss=1.3982 qwk=('0.4093', '0.4231', '0.3209') averageQWK=0.3844 macroEMD=0.3106 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    2    0
     0   21   52    9    0
     0   11  112   32    0
     0    0   26   46    1
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   21   45   10    0
     0    8  121   35    0
     0    0   25   55    0
     0    0    3    3    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   10   74    8    0
     0   10  138   18    0
     0    1   39   32    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=0.6641 
[epoch 15] step 4/44: loss=0.6690 
[epoch 15] step 6/44: loss=0.6637 
[epoch 15] step 8/44: loss=0.6662 
[epoch 15] step 10/44: loss=0.6620 
[epoch 15] step 12/44: loss=0.6571 
[epoch 15] step 14/44: loss=0.6545 
[epoch 15] step 16/44: loss=0.6561 
[epoch 15] step 18/44: loss=0.6587 
[epoch 15] step 20/44: loss=0.6603 
[epoch 15] step 22/44: loss=0.6582 
[epoch 15] step 24/44: loss=0.6602 
[epoch 15] step 26/44: loss=0.6610 
[epoch 15] step 28/44: loss=0.6616 
[epoch 15] step 30/44: loss=0.6625 
[epoch 15] step 32/44: loss=0.6660 
[epoch 15] step 34/44: loss=0.6685 
[epoch 15] step 36/44: loss=0.6697 
[epoch 15] step 38/44: loss=0.6693 
[epoch 15] step 40/44: loss=0.6706 
[epoch 15] step 42/44: loss=0.6729 
[epoch 15] step 44/44: loss=0.6771 
[epoch 15] train_loss(avg per step)=1.3542 lambda[min,max]=[0.410677,1.000000]
[epoch 15] val_loss=1.4641 qwk=('0.4688', '0.4271', '0.3578') averageQWK=0.4179 macroEMD=0.3036 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    7    1    0
     0   24   51    7    0
     0   15  104   30    6
     0    0   23   43    7
     0    0    3    6    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   20   44   12    0
     0   13   94   57    0
     0    1   13   65    1
     0    0    2    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    9   73   10    0
     0   16  128   22    0
     0    0   30   42    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=0.6823 
[epoch 16] step 4/44: loss=0.6920 
[epoch 16] step 6/44: loss=0.6926 
[epoch 16] step 8/44: loss=0.6852 
[epoch 16] step 10/44: loss=0.6786 
[epoch 16] step 12/44: loss=0.6722 
[epoch 16] step 14/44: loss=0.6670 
[epoch 16] step 16/44: loss=0.6638 
[epoch 16] step 18/44: loss=0.6620 
[epoch 16] step 20/44: loss=0.6630 
[epoch 16] step 22/44: loss=0.6637 
[epoch 16] step 24/44: loss=0.6613 
[epoch 16] step 26/44: loss=0.6610 
[epoch 16] step 28/44: loss=0.6581 
[epoch 16] step 30/44: loss=0.6573 
[epoch 16] step 32/44: loss=0.6579 
[epoch 16] step 34/44: loss=0.6584 
[epoch 16] step 36/44: loss=0.6580 
[epoch 16] step 38/44: loss=0.6590 
[epoch 16] step 40/44: loss=0.6593 
[epoch 16] step 42/44: loss=0.6605 
[epoch 16] step 44/44: loss=0.6550 
[epoch 16] train_loss(avg per step)=1.3100 lambda[min,max]=[0.416334,1.000000]
[epoch 16] val_loss=1.3837 qwk=('0.4029', '0.3805', '0.3900') averageQWK=0.3911 macroEMD=0.3021 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    7    2    0
     0   21   39   22    0
     0    9   63   83    0
     0    0   10   63    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   13   44   19    0
     0    6   78   80    0
     0    0   10   70    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7   72   13    0
     0    2  127   37    0
     0    0   20   52    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=0.6873 
[epoch 17] step 4/44: loss=0.6990 
[epoch 17] step 6/44: loss=0.6912 
[epoch 17] step 8/44: loss=0.6777 
[epoch 17] step 10/44: loss=0.6703 
[epoch 17] step 12/44: loss=0.6619 
[epoch 17] step 14/44: loss=0.6569 
[epoch 17] step 16/44: loss=0.6564 
[epoch 17] step 18/44: loss=0.6538 
[epoch 17] step 20/44: loss=0.6573 
[epoch 17] step 22/44: loss=0.6563 
[epoch 17] step 24/44: loss=0.6551 
[epoch 17] step 26/44: loss=0.6544 
[epoch 17] step 28/44: loss=0.6538 
[epoch 17] step 30/44: loss=0.6551 
[epoch 17] step 32/44: loss=0.6531 
[epoch 17] step 34/44: loss=0.6526 
[epoch 17] step 36/44: loss=0.6520 
[epoch 17] step 38/44: loss=0.6525 
[epoch 17] step 40/44: loss=0.6501 
[epoch 17] step 42/44: loss=0.6505 
[epoch 17] step 44/44: loss=0.6543 
[epoch 17] train_loss(avg per step)=1.3086 lambda[min,max]=[0.391378,1.000000]
[epoch 17] val_loss=1.3036 qwk=('0.4994', '0.3902', '0.3733') averageQWK=0.4210 macroEMD=0.3073 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    7    1    0
     0   23   48   11    0
     0   11   87   57    0
     0    0   13   58    2
     0    0    0    9    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    2    0
     1   12   47   16    0
     0    5   98   61    0
     0    0   10   70    0
     0    0    2    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8   72   12    0
     0    6  131   29    0
     0    1   23   48    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=0.6309 
[epoch 18] step 4/44: loss=0.6206 
[epoch 18] step 6/44: loss=0.6165 
[epoch 18] step 8/44: loss=0.6156 
[epoch 18] step 10/44: loss=0.6218 
[epoch 18] step 12/44: loss=0.6249 
[epoch 18] step 14/44: loss=0.6236 
[epoch 18] step 16/44: loss=0.6187 
[epoch 18] step 18/44: loss=0.6175 
[epoch 18] step 20/44: loss=0.6237 
[epoch 18] step 22/44: loss=0.6212 
[epoch 18] step 24/44: loss=0.6219 
[epoch 18] step 26/44: loss=0.6267 
[epoch 18] step 28/44: loss=0.6292 
[epoch 18] step 30/44: loss=0.6311 
[epoch 18] step 32/44: loss=0.6331 
[epoch 18] step 34/44: loss=0.6357 
[epoch 18] step 36/44: loss=0.6335 
[epoch 18] step 38/44: loss=0.6342 
[epoch 18] step 40/44: loss=0.6353 
[epoch 18] step 42/44: loss=0.6338 
[epoch 18] step 44/44: loss=0.6351 
[epoch 18] train_loss(avg per step)=1.2702 lambda[min,max]=[0.397478,1.000000]
[epoch 18] val_loss=1.3882 qwk=('0.3532', '0.3152', '0.3428') averageQWK=0.3371 macroEMD=0.3145 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2   11    1    0
     0    7   60   14    1
     0    1   85   61    8
     0    0   16   46   11
     0    0    4    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    8   46   22    0
     0    3   77   84    0
     0    0    9   69    2
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    7   70   15    0
     0    5  119   42    0
     0    1   20   51    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=0.6278 
[epoch 19] step 4/44: loss=0.6300 
[epoch 19] step 6/44: loss=0.6160 
[epoch 19] step 8/44: loss=0.6169 
[epoch 19] step 10/44: loss=0.6177 
[epoch 19] step 12/44: loss=0.6196 
[epoch 19] step 14/44: loss=0.6282 
[epoch 19] step 16/44: loss=0.6324 
[epoch 19] step 18/44: loss=0.6375 
[epoch 19] step 20/44: loss=0.6366 
[epoch 19] step 22/44: loss=0.6363 
[epoch 19] step 24/44: loss=0.6329 
[epoch 19] step 26/44: loss=0.6298 
[epoch 19] step 28/44: loss=0.6261 
[epoch 19] step 30/44: loss=0.6230 
[epoch 19] step 32/44: loss=0.6190 
[epoch 19] step 34/44: loss=0.6178 
[epoch 19] step 36/44: loss=0.6201 
[epoch 19] step 38/44: loss=0.6198 
[epoch 19] step 40/44: loss=0.6211 
[epoch 19] step 42/44: loss=0.6218 
[epoch 19] step 44/44: loss=0.6191 
[epoch 19] train_loss(avg per step)=1.2382 lambda[min,max]=[0.370944,1.000000]
[epoch 19] val_loss=1.4085 qwk=('0.3880', '0.3140', '0.3341') averageQWK=0.3454 macroEMD=0.3114 tailR0=('0.1000', '0.0000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   13    1    0
     0    9   57   16    0
     0    3   90   56    6
     0    0   12   55    6
     0    0    0    8    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    2   56   18    0
     0    1   85   78    0
     0    0    9   71    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    5   70   17    0
     0    5  109   52    0
     0    1   16   55    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=0.6446 
[epoch 20] step 4/44: loss=0.6736 
[epoch 20] step 6/44: loss=0.6648 
[epoch 20] step 8/44: loss=0.6599 
[epoch 20] step 10/44: loss=0.6514 
[epoch 20] step 12/44: loss=0.6453 
[epoch 20] step 14/44: loss=0.6444 
[epoch 20] step 16/44: loss=0.6390 
[epoch 20] step 18/44: loss=0.6426 
[epoch 20] step 20/44: loss=0.6390 
[epoch 20] step 22/44: loss=0.6343 
[epoch 20] step 24/44: loss=0.6290 
[epoch 20] step 26/44: loss=0.6233 
[epoch 20] step 28/44: loss=0.6219 
[epoch 20] step 30/44: loss=0.6198 
[epoch 20] step 32/44: loss=0.6189 
[epoch 20] step 34/44: loss=0.6192 
[epoch 20] step 36/44: loss=0.6203 
[epoch 20] step 38/44: loss=0.6182 
[epoch 20] step 40/44: loss=0.6166 
[epoch 20] step 42/44: loss=0.6159 
[epoch 20] step 44/44: loss=0.6159 
[epoch 20] train_loss(avg per step)=1.2317 lambda[min,max]=[0.370218,1.000000]
[epoch 20] val_loss=1.3263 qwk=('0.4436', '0.3245', '0.3960') averageQWK=0.3880 macroEMD=0.3084 tailR0=('0.1333', '0.0000', '0.0000') tailR0avg=0.0444
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3   10    1    0
     0   13   55   14    0
     0    5   93   53    4
     0    0   12   56    5
     0    0    0    8    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    8   46   22    0
     0    4   63   97    0
     0    0    5   75    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    9   74    9    0
     0   13  119   34    0
     0    1   21   50    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=0.6172 
[epoch 21] step 4/44: loss=0.5963 
[epoch 21] step 6/44: loss=0.6044 
[epoch 21] step 8/44: loss=0.6163 
[epoch 21] step 10/44: loss=0.6234 
[epoch 21] step 12/44: loss=0.6169 
[epoch 21] step 14/44: loss=0.6129 
[epoch 21] step 16/44: loss=0.6066 
[epoch 21] step 18/44: loss=0.6063 
[epoch 21] step 20/44: loss=0.6079 
[epoch 21] step 22/44: loss=0.6108 
[epoch 21] step 24/44: loss=0.6141 
[epoch 21] step 26/44: loss=0.6153 
[epoch 21] step 28/44: loss=0.6161 
[epoch 21] step 30/44: loss=0.6155 
[epoch 21] step 32/44: loss=0.6150 
[epoch 21] step 34/44: loss=0.6139 
[epoch 21] step 36/44: loss=0.6129 
[epoch 21] step 38/44: loss=0.6111 
[epoch 21] step 40/44: loss=0.6103 
[epoch 21] step 42/44: loss=0.6102 
[epoch 21] step 44/44: loss=0.6109 
[epoch 21] train_loss(avg per step)=1.2218 lambda[min,max]=[0.373276,1.000000]
[epoch 21] val_loss=1.2995 qwk=('0.4386', '0.3267', '0.3860') averageQWK=0.3837 macroEMD=0.3137 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3   10    1    0
     0   12   56   14    0
     0    4   95   55    1
     0    0   11   58    4
     0    0    1    8    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    7   50   19    0
     0    3   82   79    0
     0    0    9   71    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7   77    8    0
     0    8  131   27    0
     0    1   25   46    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=0.5896 
[epoch 22] step 4/44: loss=0.5877 
[epoch 22] step 6/44: loss=0.5695 
[epoch 22] step 8/44: loss=0.5677 
[epoch 22] step 10/44: loss=0.5695 
[epoch 22] step 12/44: loss=0.5718 
[epoch 22] step 14/44: loss=0.5744 
[epoch 22] step 16/44: loss=0.5779 
[epoch 22] step 18/44: loss=0.5764 
[epoch 22] step 20/44: loss=0.5810 
[epoch 22] step 22/44: loss=0.5834 
[epoch 22] step 24/44: loss=0.5843 
[epoch 22] step 26/44: loss=0.5864 
[epoch 22] step 28/44: loss=0.5864 
[epoch 22] step 30/44: loss=0.5853 
[epoch 22] step 32/44: loss=0.5862 
[epoch 22] step 34/44: loss=0.5874 
[epoch 22] step 36/44: loss=0.5871 
[epoch 22] step 38/44: loss=0.5872 
[epoch 22] step 40/44: loss=0.5872 
[epoch 22] step 42/44: loss=0.5869 
[epoch 22] step 44/44: loss=0.5804 
[epoch 22] train_loss(avg per step)=1.1609 lambda[min,max]=[0.367584,1.000000]
[epoch 22] val_loss=1.3054 qwk=('0.4106', '0.3263', '0.3540') averageQWK=0.3636 macroEMD=0.3143 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   16   53   13    0
     0    4   98   48    5
     0    0   18   46    9
     0    0    3    6    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    7   48   21    0
     0    5   74   85    0
     0    0    7   73    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   11   69   12    0
     0   17  119   30    0
     0    1   26   45    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=0.6108 
[epoch 23] step 4/44: loss=0.5958 
[epoch 23] step 6/44: loss=0.5926 
[epoch 23] step 8/44: loss=0.5910 
[epoch 23] step 10/44: loss=0.5929 
[epoch 23] step 12/44: loss=0.5961 
[epoch 23] step 14/44: loss=0.5944 
[epoch 23] step 16/44: loss=0.5899 
[epoch 23] step 18/44: loss=0.5876 
[epoch 23] step 20/44: loss=0.5881 
[epoch 23] step 22/44: loss=0.5882 
[epoch 23] step 24/44: loss=0.5905 
[epoch 23] step 26/44: loss=0.5933 
[epoch 23] step 28/44: loss=0.5949 
[epoch 23] step 30/44: loss=0.5945 
[epoch 23] step 32/44: loss=0.5926 
[epoch 23] step 34/44: loss=0.5940 
[epoch 23] step 36/44: loss=0.5950 
[epoch 23] step 38/44: loss=0.5923 
[epoch 23] step 40/44: loss=0.5920 
[epoch 23] step 42/44: loss=0.5909 
[epoch 23] step 44/44: loss=0.5929 
[epoch 23] train_loss(avg per step)=1.1858 lambda[min,max]=[0.365750,1.000000]
[epoch 23] val_loss=1.2546 qwk=('0.4023', '0.3471', '0.3916') averageQWK=0.3803 macroEMD=0.3156 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    9    1    1
     0   16   53   13    0
     0    6  103   40    6
     0    0   17   47    9
     0    0    2    7    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0   10   47   19    0
     0    5   81   78    0
     0    0    9   71    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   11   72    9    0
     0   14  122   30    0
     0    1   24   47    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=0.5545 
[epoch 24] step 4/44: loss=0.5690 
[epoch 24] step 6/44: loss=0.5656 
[epoch 24] step 8/44: loss=0.5732 
[epoch 24] step 10/44: loss=0.5725 
[epoch 24] step 12/44: loss=0.5828 
[epoch 24] step 14/44: loss=0.5833 
[epoch 24] step 16/44: loss=0.5834 
[epoch 24] step 18/44: loss=0.5847 
[epoch 24] step 20/44: loss=0.5855 
[epoch 24] step 22/44: loss=0.5817 
[epoch 24] step 24/44: loss=0.5802 
[epoch 24] step 26/44: loss=0.5801 
[epoch 24] step 28/44: loss=0.5791 
[epoch 24] step 30/44: loss=0.5802 
[epoch 24] step 32/44: loss=0.5804 
[epoch 24] step 34/44: loss=0.5792 
[epoch 24] step 36/44: loss=0.5782 
[epoch 24] step 38/44: loss=0.5793 
[epoch 24] step 40/44: loss=0.5798 
[epoch 24] step 42/44: loss=0.5811 
[epoch 24] step 44/44: loss=0.5886 
[epoch 24] train_loss(avg per step)=1.1772 lambda[min,max]=[0.344036,1.000000]
[epoch 24] val_loss=1.2592 qwk=('0.4611', '0.3604', '0.3614') averageQWK=0.3943 macroEMD=0.3129 tailR0=('0.1000', '0.0000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    8    1    0
     0   21   45   16    0
     0    9   87   56    3
     0    0   13   55    5
     0    0    0    8    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0   12   46   18    0
     0    6   93   65    0
     0    1    7   72    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6   74   12    0
     0    6  129   31    0
     0    1   23   48    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=0.5788 
[epoch 25] step 4/44: loss=0.5663 
[epoch 25] step 6/44: loss=0.5622 
[epoch 25] step 8/44: loss=0.5472 
[epoch 25] step 10/44: loss=0.5449 
[epoch 25] step 12/44: loss=0.5453 
[epoch 25] step 14/44: loss=0.5512 
[epoch 25] step 16/44: loss=0.5526 
[epoch 25] step 18/44: loss=0.5550 
[epoch 25] step 20/44: loss=0.5551 
[epoch 25] step 22/44: loss=0.5563 
[epoch 25] step 24/44: loss=0.5582 
[epoch 25] step 26/44: loss=0.5587 
[epoch 25] step 28/44: loss=0.5616 
[epoch 25] step 30/44: loss=0.5612 
[epoch 25] step 32/44: loss=0.5592 
[epoch 25] step 34/44: loss=0.5579 
[epoch 25] step 36/44: loss=0.5581 
[epoch 25] step 38/44: loss=0.5590 
[epoch 25] step 40/44: loss=0.5586 
[epoch 25] step 42/44: loss=0.5589 
[epoch 25] step 44/44: loss=0.5511 
[epoch 25] train_loss(avg per step)=1.1022 lambda[min,max]=[0.364357,1.000000]
[epoch 25] val_loss=1.2361 qwk=('0.4236', '0.3328', '0.3700') averageQWK=0.3755 macroEMD=0.3155 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   16   54   12    0
     0    6  105   40    4
     0    0   20   44    9
     0    0    3    6    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    2    0
     0   10   46   20    0
     1   11   81   71    0
     0    1    8   71    0
     0    0    2    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   10   68   14    0
     0   12  118   36    0
     0    1   20   51    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=0.5465 
[epoch 26] step 4/44: loss=0.5568 
[epoch 26] step 6/44: loss=0.5455 
[epoch 26] step 8/44: loss=0.5629 
[epoch 26] step 10/44: loss=0.5669 
[epoch 26] step 12/44: loss=0.5674 
[epoch 26] step 14/44: loss=0.5695 
[epoch 26] step 16/44: loss=0.5709 
[epoch 26] step 18/44: loss=0.5680 
[epoch 26] step 20/44: loss=0.5678 
[epoch 26] step 22/44: loss=0.5646 
[epoch 26] step 24/44: loss=0.5641 
[epoch 26] step 26/44: loss=0.5638 
[epoch 26] step 28/44: loss=0.5642 
[epoch 26] step 30/44: loss=0.5638 
[epoch 26] step 32/44: loss=0.5635 
[epoch 26] step 34/44: loss=0.5627 
[epoch 26] step 36/44: loss=0.5614 
[epoch 26] step 38/44: loss=0.5632 
[epoch 26] step 40/44: loss=0.5637 
[epoch 26] step 42/44: loss=0.5643 
[epoch 26] step 44/44: loss=0.5691 
[epoch 26] train_loss(avg per step)=1.1382 lambda[min,max]=[0.360141,1.000000]
[epoch 26] val_loss=1.2463 qwk=('0.4356', '0.3117', '0.3620') averageQWK=0.3698 macroEMD=0.3084 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   18   50   14    0
     0    6   91   55    3
     0    0   14   53    6
     0    0    2    7    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    8   48   20    0
     0    7   72   85    0
     0    1    8   71    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   12   67   13    0
     0   17  118   31    0
     0    1   24   47    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=0.5379 
[epoch 27] step 4/44: loss=0.5559 
[epoch 27] step 6/44: loss=0.5528 
[epoch 27] step 8/44: loss=0.5509 
[epoch 27] step 10/44: loss=0.5600 
[epoch 27] step 12/44: loss=0.5657 
[epoch 27] step 14/44: loss=0.5649 
[epoch 27] step 16/44: loss=0.5651 
[epoch 27] step 18/44: loss=0.5694 
[epoch 27] step 20/44: loss=0.5715 
[epoch 27] step 22/44: loss=0.5677 
[epoch 27] step 24/44: loss=0.5674 
[epoch 27] step 26/44: loss=0.5670 
[epoch 27] step 28/44: loss=0.5674 
[epoch 27] step 30/44: loss=0.5675 
[epoch 27] step 32/44: loss=0.5676 
[epoch 27] step 34/44: loss=0.5672 
[epoch 27] step 36/44: loss=0.5679 
[epoch 27] step 38/44: loss=0.5677 
[epoch 27] step 40/44: loss=0.5674 
[epoch 27] step 42/44: loss=0.5638 
[epoch 27] step 44/44: loss=0.5593 
[epoch 27] train_loss(avg per step)=1.1186 lambda[min,max]=[0.385467,1.000000]
[epoch 27] val_loss=1.2435 qwk=('0.4008', '0.3160', '0.3614') averageQWK=0.3594 macroEMD=0.3118 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   13    1    0
     0   12   57   13    0
     0    5   90   57    3
     0    0   11   57    5
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    5   50   21    0
     0    5   71   88    0
     0    0    7   73    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   13   65   14    0
     0   18  117   31    0
     0    2   21   49    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=0.5511 
[epoch 28] step 4/44: loss=0.5578 
[epoch 28] step 6/44: loss=0.5603 
[epoch 28] step 8/44: loss=0.5594 
[epoch 28] step 10/44: loss=0.5655 
[epoch 28] step 12/44: loss=0.5692 
[epoch 28] step 14/44: loss=0.5703 
[epoch 28] step 16/44: loss=0.5674 
[epoch 28] step 18/44: loss=0.5664 
[epoch 28] step 20/44: loss=0.5614 
[epoch 28] step 22/44: loss=0.5608 
[epoch 28] step 24/44: loss=0.5597 
[epoch 28] step 26/44: loss=0.5601 
[epoch 28] step 28/44: loss=0.5585 
[epoch 28] step 30/44: loss=0.5592 
[epoch 28] step 32/44: loss=0.5586 
[epoch 28] step 34/44: loss=0.5590 
[epoch 28] step 36/44: loss=0.5596 
[epoch 28] step 38/44: loss=0.5586 
[epoch 28] step 40/44: loss=0.5584 
[epoch 28] step 42/44: loss=0.5561 
[epoch 28] step 44/44: loss=0.5587 
[epoch 28] train_loss(avg per step)=1.1173 lambda[min,max]=[0.363037,1.000000]
[epoch 28] val_loss=1.2475 qwk=('0.4186', '0.3206', '0.3740') averageQWK=0.3711 macroEMD=0.3074 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   15   51   16    0
     0    6   85   61    3
     0    0   12   55    6
     0    0    1    8    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    7   48   21    0
     0    4   61   99    0
     0    0    6   74    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7   72   13    0
     0    8  122   36    0
     0    1   19   52    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=0.5384 
[epoch 29] step 4/44: loss=0.5424 
[epoch 29] step 6/44: loss=0.5383 
[epoch 29] step 8/44: loss=0.5434 
[epoch 29] step 10/44: loss=0.5459 
[epoch 29] step 12/44: loss=0.5501 
[epoch 29] step 14/44: loss=0.5557 
[epoch 29] step 16/44: loss=0.5608 
[epoch 29] step 18/44: loss=0.5583 
[epoch 29] step 20/44: loss=0.5562 
[epoch 29] step 22/44: loss=0.5584 
[epoch 29] step 24/44: loss=0.5587 
[epoch 29] step 26/44: loss=0.5548 
[epoch 29] step 28/44: loss=0.5540 
[epoch 29] step 30/44: loss=0.5550 
[epoch 29] step 32/44: loss=0.5553 
[epoch 29] step 34/44: loss=0.5556 
[epoch 29] step 36/44: loss=0.5531 
[epoch 29] step 38/44: loss=0.5531 
[epoch 29] step 40/44: loss=0.5540 
[epoch 29] step 42/44: loss=0.5548 
[epoch 29] step 44/44: loss=0.5489 
[epoch 29] train_loss(avg per step)=1.0977 lambda[min,max]=[0.373418,1.000000]
[epoch 29] val_loss=1.2477 qwk=('0.4112', '0.3330', '0.3631') averageQWK=0.3691 macroEMD=0.3063 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   14   52   16    0
     0    6   88   60    1
     0    0   11   61    1
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0    6   49   21    0
     0    6   61   97    0
     0    0    4   76    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    9   70   13    0
     0   12  120   34    0
     0    1   22   49    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=0.5708 
[epoch 30] step 4/44: loss=0.5675 
[epoch 30] step 6/44: loss=0.5739 
[epoch 30] step 8/44: loss=0.5645 
[epoch 30] step 10/44: loss=0.5612 
[epoch 30] step 12/44: loss=0.5635 
[epoch 30] step 14/44: loss=0.5594 
[epoch 30] step 16/44: loss=0.5598 
[epoch 30] step 18/44: loss=0.5587 
[epoch 30] step 20/44: loss=0.5570 
[epoch 30] step 22/44: loss=0.5563 
[epoch 30] step 24/44: loss=0.5546 
[epoch 30] step 26/44: loss=0.5522 
[epoch 30] step 28/44: loss=0.5513 
[epoch 30] step 30/44: loss=0.5490 
[epoch 30] step 32/44: loss=0.5467 
[epoch 30] step 34/44: loss=0.5475 
[epoch 30] step 36/44: loss=0.5472 
[epoch 30] step 38/44: loss=0.5473 
[epoch 30] step 40/44: loss=0.5465 
[epoch 30] step 42/44: loss=0.5456 
[epoch 30] step 44/44: loss=0.5527 
[epoch 30] train_loss(avg per step)=1.1054 lambda[min,max]=[0.361228,1.000000]
[epoch 30] val_loss=1.2550 qwk=('0.4278', '0.3424', '0.3704') averageQWK=0.3802 macroEMD=0.3077 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   17   50   15    0
     0    6   90   57    2
     0    0   13   58    2
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    5   54   17    0
     0    5   86   73    0
     0    0    9   71    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7   75   10    0
     0   12  121   33    0
     0    1   23   48    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=0.5688 
[epoch 31] step 4/44: loss=0.5560 
[epoch 31] step 6/44: loss=0.5683 
[epoch 31] step 8/44: loss=0.5627 
[epoch 31] step 10/44: loss=0.5602 
[epoch 31] step 12/44: loss=0.5578 
[epoch 31] step 14/44: loss=0.5548 
[epoch 31] step 16/44: loss=0.5533 
[epoch 31] step 18/44: loss=0.5552 
[epoch 31] step 20/44: loss=0.5534 
[epoch 31] step 22/44: loss=0.5513 
[epoch 31] step 24/44: loss=0.5537 
[epoch 31] step 26/44: loss=0.5556 
[epoch 31] step 28/44: loss=0.5585 
[epoch 31] step 30/44: loss=0.5569 
[epoch 31] step 32/44: loss=0.5560 
[epoch 31] step 34/44: loss=0.5553 
[epoch 31] step 36/44: loss=0.5549 
[epoch 31] step 38/44: loss=0.5527 
[epoch 31] step 40/44: loss=0.5518 
[epoch 31] step 42/44: loss=0.5517 
[epoch 31] step 44/44: loss=0.5442 
[epoch 31] train_loss(avg per step)=1.0884 lambda[min,max]=[0.370488,1.000000]
[epoch 31] val_loss=1.2292 qwk=('0.4123', '0.3445', '0.3786') averageQWK=0.3785 macroEMD=0.3117 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    8    1    0
     0   17   50   15    0
     0    8   90   55    2
     0    0   17   54    2
     0    0    2    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0    9   50   17    0
     0    9   85   70    0
     0    0   10   70    0
     0    0    2    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    9   74    9    0
     0   10  128   28    0
     0    1   26   45    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=0.5583 
[epoch 32] step 4/44: loss=0.5462 
[epoch 32] step 6/44: loss=0.5486 
[epoch 32] step 8/44: loss=0.5364 
[epoch 32] step 10/44: loss=0.5367 
[epoch 32] step 12/44: loss=0.5411 
[epoch 32] step 14/44: loss=0.5408 
[epoch 32] step 16/44: loss=0.5391 
[epoch 32] step 18/44: loss=0.5386 
[epoch 32] step 20/44: loss=0.5413 
[epoch 32] step 22/44: loss=0.5420 
[epoch 32] step 24/44: loss=0.5414 
[epoch 32] step 26/44: loss=0.5431 
[epoch 32] step 28/44: loss=0.5447 
[epoch 32] step 30/44: loss=0.5478 
[epoch 32] step 32/44: loss=0.5483 
[epoch 32] step 34/44: loss=0.5479 
[epoch 32] step 36/44: loss=0.5486 
[epoch 32] step 38/44: loss=0.5462 
[epoch 32] step 40/44: loss=0.5475 
[epoch 32] step 42/44: loss=0.5478 
[epoch 32] step 44/44: loss=0.5432 
[epoch 32] train_loss(avg per step)=1.0864 lambda[min,max]=[0.373347,1.000000]
[epoch 32] val_loss=1.2388 qwk=('0.4056', '0.3398', '0.3783') averageQWK=0.3746 macroEMD=0.3101 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   14   51   17    0
     0    6   89   56    4
     0    0   13   55    5
     0    0    1    8    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0    7   51   18    0
     0    6   80   78    0
     0    0    9   71    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   11   72    9    0
     0   13  125   28    0
     0    1   27   44    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=0.5428 
[epoch 33] step 4/44: loss=0.5497 
[epoch 33] step 6/44: loss=0.5470 
[epoch 33] step 8/44: loss=0.5397 
[epoch 33] step 10/44: loss=0.5358 
[epoch 33] step 12/44: loss=0.5384 
[epoch 33] step 14/44: loss=0.5445 
[epoch 33] step 16/44: loss=0.5404 
[epoch 33] step 18/44: loss=0.5391 
[epoch 33] step 20/44: loss=0.5417 
[epoch 33] step 22/44: loss=0.5419 
[epoch 33] step 24/44: loss=0.5413 
[epoch 33] step 26/44: loss=0.5409 
[epoch 33] step 28/44: loss=0.5435 
[epoch 33] step 30/44: loss=0.5440 
[epoch 33] step 32/44: loss=0.5438 
[epoch 33] step 34/44: loss=0.5424 
[epoch 33] step 36/44: loss=0.5416 
[epoch 33] step 38/44: loss=0.5418 
[epoch 33] step 40/44: loss=0.5408 
[epoch 33] step 42/44: loss=0.5413 
[epoch 33] step 44/44: loss=0.5407 
[epoch 33] train_loss(avg per step)=1.0814 lambda[min,max]=[0.385809,1.000000]
[epoch 33] val_loss=1.2388 qwk=('0.4048', '0.3261', '0.3609') averageQWK=0.3639 macroEMD=0.3085 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   15   51   16    0
     0    6   88   59    2
     0    0   14   56    3
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    6   51   19    0
     0    5   75   84    0
     0    0    9   71    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7   73   12    0
     0    8  124   34    0
     0    1   23   48    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=0.5167 
[epoch 34] step 4/44: loss=0.5300 
[epoch 34] step 6/44: loss=0.5347 
[epoch 34] step 8/44: loss=0.5441 
[epoch 34] step 10/44: loss=0.5479 
[epoch 34] step 12/44: loss=0.5520 
[epoch 34] step 14/44: loss=0.5491 
[epoch 34] step 16/44: loss=0.5484 
[epoch 34] step 18/44: loss=0.5487 
[epoch 34] step 20/44: loss=0.5477 
[epoch 34] step 22/44: loss=0.5481 
[epoch 34] step 24/44: loss=0.5492 
[epoch 34] step 26/44: loss=0.5502 
[epoch 34] step 28/44: loss=0.5533 
[epoch 34] step 30/44: loss=0.5520 
[epoch 34] step 32/44: loss=0.5509 
[epoch 34] step 34/44: loss=0.5505 
[epoch 34] step 36/44: loss=0.5509 
[epoch 34] step 38/44: loss=0.5488 
[epoch 34] step 40/44: loss=0.5492 
[epoch 34] step 42/44: loss=0.5482 
[epoch 34] step 44/44: loss=0.5424 
[epoch 34] train_loss(avg per step)=1.0848 lambda[min,max]=[0.372896,1.000000]
[epoch 34] val_loss=1.2397 qwk=('0.4138', '0.3358', '0.3643') averageQWK=0.3713 macroEMD=0.3069 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   16   49   17    0
     0    7   84   61    3
     0    0   12   57    4
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0    7   50   19    0
     0    6   71   87    0
     0    0    9   71    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8   72   12    0
     0    9  123   34    0
     0    1   23   48    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=0.5651 
[epoch 35] step 4/44: loss=0.5519 
[epoch 35] step 6/44: loss=0.5437 
[epoch 35] step 8/44: loss=0.5433 
[epoch 35] step 10/44: loss=0.5457 
[epoch 35] step 12/44: loss=0.5405 
[epoch 35] step 14/44: loss=0.5424 
[epoch 35] step 16/44: loss=0.5424 
[epoch 35] step 18/44: loss=0.5393 
[epoch 35] step 20/44: loss=0.5390 
[epoch 35] step 22/44: loss=0.5432 
[epoch 35] step 24/44: loss=0.5438 
[epoch 35] step 26/44: loss=0.5449 
[epoch 35] step 28/44: loss=0.5453 
[epoch 35] step 30/44: loss=0.5469 
[epoch 35] step 32/44: loss=0.5456 
[epoch 35] step 34/44: loss=0.5448 
[epoch 35] step 36/44: loss=0.5451 
[epoch 35] step 38/44: loss=0.5438 
[epoch 35] step 40/44: loss=0.5425 
[epoch 35] step 42/44: loss=0.5424 
[epoch 35] step 44/44: loss=0.5408 
[epoch 35] train_loss(avg per step)=1.0816 lambda[min,max]=[0.380302,1.000000]
[epoch 35] val_loss=1.2412 qwk=('0.4276', '0.3389', '0.3616') averageQWK=0.3760 macroEMD=0.3076 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    8    1    0
     0   16   50   16    0
     0    7   87   58    3
     0    0   14   55    4
     0    0    1    8    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0    7   50   19    0
     0    7   75   82    0
     0    0    9   71    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    9   71   12    0
     0   11  122   33    0
     0    1   24   47    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-1/fold4/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-1/fold4/metrics.json
Done.
