[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.8811 
[epoch 1] step 4/44: loss=0.8861 
[epoch 1] step 6/44: loss=0.8811 
[epoch 1] step 8/44: loss=0.8751 
[epoch 1] step 10/44: loss=0.8815 
[epoch 1] step 12/44: loss=0.8824 
[epoch 1] step 14/44: loss=0.8807 
[epoch 1] step 16/44: loss=0.8814 
[epoch 1] step 18/44: loss=0.8839 
[epoch 1] step 20/44: loss=0.8860 
[epoch 1] step 22/44: loss=0.8856 
[epoch 1] step 24/44: loss=0.8858 
[epoch 1] step 26/44: loss=0.8857 
[epoch 1] step 28/44: loss=0.8843 
[epoch 1] step 30/44: loss=0.8826 
[epoch 1] step 32/44: loss=0.8818 
[epoch 1] step 34/44: loss=0.8805 
[epoch 1] step 36/44: loss=0.8800 
[epoch 1] step 38/44: loss=0.8782 
[epoch 1] step 40/44: loss=0.8764 
[epoch 1] step 42/44: loss=0.8737 
[epoch 1] step 44/44: loss=0.8691 
[epoch 1] train_loss(avg per step)=1.7382 lambda[min,max]=[0.886108,1.000000]
[epoch 1] val_loss=1.6394 qwk=('-0.1938', '-0.1051', '0.2133') averageQWK=-0.0285 macroEMD=0.3929 tailR0=('0.0000', '0.0000', '0.3333') tailR0avg=0.1111
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    7    0
     0   18    0   22    0
     0   61    5   62    0
     0   77    8   37    0
     0   15    7    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
    15    0   33    0    0
    55    0   56    2    0
    88    0   57    3    0
     6    0    4    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   10   58    1    2
     0   13  126    1   11
     0    2   83    2   12
     0    0    1    0    2
[epoch 2] step 2/44: loss=0.8207 
[epoch 2] step 4/44: loss=0.7941 
[epoch 2] step 6/44: loss=0.7824 
[epoch 2] step 8/44: loss=0.7698 
[epoch 2] step 10/44: loss=0.7632 
[epoch 2] step 12/44: loss=0.7561 
[epoch 2] step 14/44: loss=0.7446 
[epoch 2] step 16/44: loss=0.7349 
[epoch 2] step 18/44: loss=0.7248 
[epoch 2] step 20/44: loss=0.7158 
[epoch 2] step 22/44: loss=0.7098 
[epoch 2] step 24/44: loss=0.7037 
[epoch 2] step 26/44: loss=0.6970 
[epoch 2] step 28/44: loss=0.6904 
[epoch 2] step 30/44: loss=0.6863 
[epoch 2] step 32/44: loss=0.6842 
[epoch 2] step 34/44: loss=0.6810 
[epoch 2] step 36/44: loss=0.6763 
[epoch 2] step 38/44: loss=0.6747 
[epoch 2] step 40/44: loss=0.6706 
[epoch 2] step 42/44: loss=0.6687 
[epoch 2] step 44/44: loss=0.6648 
[epoch 2] train_loss(avg per step)=1.3296 lambda[min,max]=[0.830257,1.000000]
[epoch 2] val_loss=1.1621 qwk=('0.0340', '0.2672', '0.3900') averageQWK=0.2304 macroEMD=0.3203 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    0    0
     0    0   40    0    0
     0    0  127    1    0
     0    0  121    1    0
     0    0   24    3    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   47    1    0
     0    0  101   12    0
     0    0  101   47    0
     0    0    3    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    1   69    1    0
     0    0  135   16    0
     0    0   49   50    0
     0    0    1    2    0
[epoch 3] step 2/44: loss=0.5964 
[epoch 3] step 4/44: loss=0.6009 
[epoch 3] step 6/44: loss=0.5954 
[epoch 3] step 8/44: loss=0.5839 
[epoch 3] step 10/44: loss=0.5763 
[epoch 3] step 12/44: loss=0.5775 
[epoch 3] step 14/44: loss=0.5769 
[epoch 3] step 16/44: loss=0.5750 
[epoch 3] step 18/44: loss=0.5690 
[epoch 3] step 20/44: loss=0.5639 
[epoch 3] step 22/44: loss=0.5565 
[epoch 3] step 24/44: loss=0.5601 
[epoch 3] step 26/44: loss=0.5558 
[epoch 3] step 28/44: loss=0.5515 
[epoch 3] step 30/44: loss=0.5473 
[epoch 3] step 32/44: loss=0.5477 
[epoch 3] step 34/44: loss=0.5433 
[epoch 3] step 36/44: loss=0.5391 
[epoch 3] step 38/44: loss=0.5368 
[epoch 3] step 40/44: loss=0.5331 
[epoch 3] step 42/44: loss=0.5310 
[epoch 3] step 44/44: loss=0.5271 
[epoch 3] train_loss(avg per step)=1.0541 lambda[min,max]=[0.754527,1.000000]
[epoch 3] val_loss=0.9205 qwk=('0.5215', '0.4191', '0.4902') averageQWK=0.4769 macroEMD=0.2492 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    0    0
     0    6   28    6    0
     0    2   90   36    0
     0    0   34   88    0
     0    0    1   26    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   38   10    0
     0    2   62   49    0
     0    0   27  121    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   11   55    5    0
     0    1  116   34    0
     0    0   28   71    0
     0    0    1    2    0
[epoch 4] step 2/44: loss=0.4633 
[epoch 4] step 4/44: loss=0.4576 
[epoch 4] step 6/44: loss=0.4478 
[epoch 4] step 8/44: loss=0.4525 
[epoch 4] step 10/44: loss=0.4432 
[epoch 4] step 12/44: loss=0.4393 
[epoch 4] step 14/44: loss=0.4398 
[epoch 4] step 16/44: loss=0.4350 
[epoch 4] step 18/44: loss=0.4323 
[epoch 4] step 20/44: loss=0.4351 
[epoch 4] step 22/44: loss=0.4315 
[epoch 4] step 24/44: loss=0.4308 
[epoch 4] step 26/44: loss=0.4308 
[epoch 4] step 28/44: loss=0.4284 
[epoch 4] step 30/44: loss=0.4282 
[epoch 4] step 32/44: loss=0.4259 
[epoch 4] step 34/44: loss=0.4244 
[epoch 4] step 36/44: loss=0.4271 
[epoch 4] step 38/44: loss=0.4290 
[epoch 4] step 40/44: loss=0.4274 
[epoch 4] step 42/44: loss=0.4249 
[epoch 4] step 44/44: loss=0.4243 
[epoch 4] train_loss(avg per step)=0.8486 lambda[min,max]=[0.638960,1.000000]
[epoch 4] val_loss=0.9095 qwk=('0.4404', '0.4439', '0.5250') averageQWK=0.4698 macroEMD=0.2435 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    0    0
     0    0   39    1    0
     0    0  104   24    0
     0    0   46   76    0
     0    0    5   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2   42    4    0
     0    2   87   24    0
     0    0   68   80    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   57    0    0
     0    3  124   24    0
     0    0   40   59    0
     0    0    1    2    0
[epoch 5] step 2/44: loss=0.3768 
[epoch 5] step 4/44: loss=0.3764 
[epoch 5] step 6/44: loss=0.3758 
[epoch 5] step 8/44: loss=0.3744 
[epoch 5] step 10/44: loss=0.3776 
[epoch 5] step 12/44: loss=0.3761 
[epoch 5] step 14/44: loss=0.3760 
[epoch 5] step 16/44: loss=0.3712 
[epoch 5] step 18/44: loss=0.3718 
[epoch 5] step 20/44: loss=0.3701 
[epoch 5] step 22/44: loss=0.3711 
[epoch 5] step 24/44: loss=0.3779 
[epoch 5] step 26/44: loss=0.3746 
[epoch 5] step 28/44: loss=0.3741 
[epoch 5] step 30/44: loss=0.3727 
[epoch 5] step 32/44: loss=0.3738 
[epoch 5] step 34/44: loss=0.3748 
[epoch 5] step 36/44: loss=0.3740 
[epoch 5] step 38/44: loss=0.3735 
[epoch 5] step 40/44: loss=0.3721 
[epoch 5] step 42/44: loss=0.3709 
[epoch 5] step 44/44: loss=0.3701 
[epoch 5] train_loss(avg per step)=0.7402 lambda[min,max]=[0.580724,1.000000]
[epoch 5] val_loss=0.9361 qwk=('0.4182', '0.5538', '0.5983') averageQWK=0.5234 macroEMD=0.2278 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    6   34    0    0
     0    3  114   11    0
     0    1   74   47    0
     0    0   12   15    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   21   27    0    0
     0   17   81   15    0
     0    3   75   70    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   36   35    0    0
     0   17  122   12    0
     0    0   50   49    0
     0    0    1    2    0
[epoch 6] step 2/44: loss=0.3359 
[epoch 6] step 4/44: loss=0.3120 
[epoch 6] step 6/44: loss=0.3345 
[epoch 6] step 8/44: loss=0.3358 
[epoch 6] step 10/44: loss=0.3339 
[epoch 6] step 12/44: loss=0.3295 
[epoch 6] step 14/44: loss=0.3338 
[epoch 6] step 16/44: loss=0.3306 
[epoch 6] step 18/44: loss=0.3279 
[epoch 6] step 20/44: loss=0.3307 
[epoch 6] step 22/44: loss=0.3398 
[epoch 6] step 24/44: loss=0.3403 
[epoch 6] step 26/44: loss=0.3398 
[epoch 6] step 28/44: loss=0.3394 
[epoch 6] step 30/44: loss=0.3334 
[epoch 6] step 32/44: loss=0.3324 
[epoch 6] step 34/44: loss=0.3346 
[epoch 6] step 36/44: loss=0.3371 
[epoch 6] step 38/44: loss=0.3362 
[epoch 6] step 40/44: loss=0.3375 
[epoch 6] step 42/44: loss=0.3387 
[epoch 6] step 44/44: loss=0.3399 
[epoch 6] train_loss(avg per step)=0.6798 lambda[min,max]=[0.584554,1.000000]
[epoch 6] val_loss=0.9031 qwk=('0.5186', '0.4889', '0.5761') averageQWK=0.5279 macroEMD=0.2222 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   13   24    3    0
     0    9   90   29    0
     0    1   54   67    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    6   38    4    0
     0    2   91   20    0
     0    0   69   79    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   48   23    0    0
     0   44   93   14    0
     0    3   49   47    0
     0    0    1    2    0
[epoch 7] step 2/44: loss=0.3051 
[epoch 7] step 4/44: loss=0.3132 
[epoch 7] step 6/44: loss=0.3099 
[epoch 7] step 8/44: loss=0.3103 
[epoch 7] step 10/44: loss=0.3067 
[epoch 7] step 12/44: loss=0.2963 
[epoch 7] step 14/44: loss=0.2909 
[epoch 7] step 16/44: loss=0.2874 
[epoch 7] step 18/44: loss=0.2895 
[epoch 7] step 20/44: loss=0.2856 
[epoch 7] step 22/44: loss=0.2852 
[epoch 7] step 24/44: loss=0.2832 
[epoch 7] step 26/44: loss=0.2815 
[epoch 7] step 28/44: loss=0.2814 
[epoch 7] step 30/44: loss=0.2829 
[epoch 7] step 32/44: loss=0.2800 
[epoch 7] step 34/44: loss=0.2804 
[epoch 7] step 36/44: loss=0.2806 
[epoch 7] step 38/44: loss=0.2811 
[epoch 7] step 40/44: loss=0.2822 
[epoch 7] step 42/44: loss=0.2852 
[epoch 7] step 44/44: loss=0.2844 
[epoch 7] train_loss(avg per step)=0.5688 lambda[min,max]=[0.537981,1.000000]
[epoch 7] val_loss=0.8820 qwk=('0.5297', '0.5246', '0.5328') averageQWK=0.5290 macroEMD=0.2127 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   13   24    3    0
     0   11   87   30    0
     0    2   49   70    1
     0    0    3   24    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   13   29    6    0
     0    8   67   38    0
     0    1   48   99    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   38    2    0
     0   18  110   23    0
     0    2   44   53    0
     0    0    1    2    0
[epoch 8] step 2/44: loss=0.2699 
[epoch 8] step 4/44: loss=0.2418 
[epoch 8] step 6/44: loss=0.2335 
[epoch 8] step 8/44: loss=0.2398 
[epoch 8] step 10/44: loss=0.2387 
[epoch 8] step 12/44: loss=0.2362 
[epoch 8] step 14/44: loss=0.2425 
[epoch 8] step 16/44: loss=0.2463 
[epoch 8] step 18/44: loss=0.2475 
[epoch 8] step 20/44: loss=0.2453 
[epoch 8] step 22/44: loss=0.2451 
[epoch 8] step 24/44: loss=0.2443 
[epoch 8] step 26/44: loss=0.2463 
[epoch 8] step 28/44: loss=0.2449 
[epoch 8] step 30/44: loss=0.2443 
[epoch 8] step 32/44: loss=0.2442 
[epoch 8] step 34/44: loss=0.2434 
[epoch 8] step 36/44: loss=0.2420 
[epoch 8] step 38/44: loss=0.2411 
[epoch 8] step 40/44: loss=0.2393 
[epoch 8] step 42/44: loss=0.2398 
[epoch 8] step 44/44: loss=0.2397 
[epoch 8] train_loss(avg per step)=0.4794 lambda[min,max]=[0.528546,1.000000]
[epoch 8] val_loss=0.8561 qwk=('0.5500', '0.5347', '0.5189') averageQWK=0.5345 macroEMD=0.2037 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   15   21    4    0
     0   13   70   45    0
     0    1   36   85    0
     0    0    2   25    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   16   23    9    0
     0   12   60   41    0
     0    3   36  109    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   27   42    2    0
     0   14  115   22    0
     0    1   47   51    0
     0    0    1    2    0
[epoch 9] step 2/44: loss=0.2032 
[epoch 9] step 4/44: loss=0.2208 
[epoch 9] step 6/44: loss=0.2142 
[epoch 9] step 8/44: loss=0.2179 
[epoch 9] step 10/44: loss=0.2217 
[epoch 9] step 12/44: loss=0.2061 
[epoch 9] step 14/44: loss=0.2042 
[epoch 9] step 16/44: loss=0.2061 
[epoch 9] step 18/44: loss=0.2007 
[epoch 9] step 20/44: loss=0.2023 
[epoch 9] step 22/44: loss=0.2021 
[epoch 9] step 24/44: loss=0.2013 
[epoch 9] step 26/44: loss=0.2069 
[epoch 9] step 28/44: loss=0.2052 
[epoch 9] step 30/44: loss=0.2038 
[epoch 9] step 32/44: loss=0.2002 
[epoch 9] step 34/44: loss=0.1989 
[epoch 9] step 36/44: loss=0.1970 
[epoch 9] step 38/44: loss=0.1981 
[epoch 9] step 40/44: loss=0.1968 
[epoch 9] step 42/44: loss=0.1975 
[epoch 9] step 44/44: loss=0.1962 
[epoch 9] train_loss(avg per step)=0.3924 lambda[min,max]=[0.510298,1.000000]
[epoch 9] val_loss=0.8517 qwk=('0.5564', '0.5101', '0.5404') averageQWK=0.5356 macroEMD=0.2002 tailR0=('0.0741', '0.0000', '0.0000') tailR0avg=0.0247
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   14   21    5    0
     0   10   84   34    0
     0    2   43   77    0
     0    0    2   21    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   14   26    8    0
     0    7   66   40    0
     0    2   45  101    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   44    1    0
     0   11  120   20    0
     0    1   45   53    0
     0    0    1    2    0
[epoch 10] step 2/44: loss=0.1636 
[epoch 10] step 4/44: loss=0.2038 
[epoch 10] step 6/44: loss=0.2055 
[epoch 10] step 8/44: loss=0.1914 
[epoch 10] step 10/44: loss=0.1841 
[epoch 10] step 12/44: loss=0.1904 
[epoch 10] step 14/44: loss=0.1909 
[epoch 10] step 16/44: loss=0.1813 
[epoch 10] step 18/44: loss=0.1801 
[epoch 10] step 20/44: loss=0.1792 
[epoch 10] step 22/44: loss=0.1752 
[epoch 10] step 24/44: loss=0.1767 
[epoch 10] step 26/44: loss=0.1722 
[epoch 10] step 28/44: loss=0.1702 
[epoch 10] step 30/44: loss=0.1703 
[epoch 10] step 32/44: loss=0.1674 
[epoch 10] step 34/44: loss=0.1657 
[epoch 10] step 36/44: loss=0.1660 
[epoch 10] step 38/44: loss=0.1682 
[epoch 10] step 40/44: loss=0.1666 
[epoch 10] step 42/44: loss=0.1638 
[epoch 10] step 44/44: loss=0.1627 
[epoch 10] train_loss(avg per step)=0.3254 lambda[min,max]=[0.509443,1.000000]
[epoch 10] val_loss=0.8744 qwk=('0.5355', '0.5404', '0.5843') averageQWK=0.5534 macroEMD=0.1952 tailR0=('0.0185', '0.0000', '0.0000') tailR0avg=0.0062
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   15   22    3    0
     0   10   85   33    0
     0    2   47   73    0
     0    0    4   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   15   28    5    0
     0   11   68   34    0
     0    2   48   98    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   44   26    1    0
     0   30   96   25    0
     0    2   43   54    0
     0    0    1    2    0
[epoch 11] step 2/44: loss=0.1512 
[epoch 11] step 4/44: loss=0.1286 
[epoch 11] step 6/44: loss=0.1257 
[epoch 11] step 8/44: loss=0.1237 
[epoch 11] step 10/44: loss=0.1208 
[epoch 11] step 12/44: loss=0.1214 
[epoch 11] step 14/44: loss=0.1150 
[epoch 11] step 16/44: loss=0.1154 
[epoch 11] step 18/44: loss=0.1203 
[epoch 11] step 20/44: loss=0.1176 
[epoch 11] step 22/44: loss=0.1167 
[epoch 11] step 24/44: loss=0.1166 
[epoch 11] step 26/44: loss=0.1193 
[epoch 11] step 28/44: loss=0.1162 
[epoch 11] step 30/44: loss=0.1176 
[epoch 11] step 32/44: loss=0.1199 
[epoch 11] step 34/44: loss=0.1202 
[epoch 11] step 36/44: loss=0.1190 
[epoch 11] step 38/44: loss=0.1191 
[epoch 11] step 40/44: loss=0.1203 
[epoch 11] step 42/44: loss=0.1183 
[epoch 11] step 44/44: loss=0.1187 
[epoch 11] train_loss(avg per step)=0.2375 lambda[min,max]=[0.505823,1.000000]
[epoch 11] val_loss=0.8801 qwk=('0.5050', '0.5522', '0.5295') averageQWK=0.5289 macroEMD=0.1998 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    7   28    5    0
     0    3   92   33    0
     0    0   47   75    0
     0    0    3   24    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   12   31    5    0
     0    7   73   33    0
     0    0   50   98    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   29   41    1    0
     0   15  115   21    0
     0    1   49   49    0
     0    0    1    2    0
[epoch 12] step 2/44: loss=0.0326 
[epoch 12] step 4/44: loss=0.0531 
[epoch 12] step 6/44: loss=0.0632 
[epoch 12] step 8/44: loss=0.0795 
[epoch 12] step 10/44: loss=0.0861 
[epoch 12] step 12/44: loss=0.0952 
[epoch 12] step 14/44: loss=0.0884 
[epoch 12] step 16/44: loss=0.0856 
[epoch 12] step 18/44: loss=0.0832 
[epoch 12] step 20/44: loss=0.0839 
[epoch 12] step 22/44: loss=0.0855 
[epoch 12] step 24/44: loss=0.0870 
[epoch 12] step 26/44: loss=0.0905 
[epoch 12] step 28/44: loss=0.0911 
[epoch 12] step 30/44: loss=0.0936 
[epoch 12] step 32/44: loss=0.0929 
[epoch 12] step 34/44: loss=0.0912 
[epoch 12] step 36/44: loss=0.0903 
[epoch 12] step 38/44: loss=0.0881 
[epoch 12] step 40/44: loss=0.0892 
[epoch 12] step 42/44: loss=0.0888 
[epoch 12] step 44/44: loss=0.0874 
[epoch 12] train_loss(avg per step)=0.1748 lambda[min,max]=[0.503872,1.000000]
[epoch 12] val_loss=0.9023 qwk=('0.4938', '0.5101', '0.5118') averageQWK=0.5052 macroEMD=0.1974 tailR0=('0.0995', '0.0500', '0.0000') tailR0avg=0.0498
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    4   27    9    0
     0    4   69   55    0
     0    0   27   95    0
     0    0    1   24    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    9   27   12    0
     0    5   51   57    0
     0    0   26  121    1
     0    0    0    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   46    3    0
     0    8  113   30    0
     0    0   42   57    0
     0    0    1    2    0
[epoch 13] step 2/44: loss=0.0653 
[epoch 13] step 4/44: loss=0.0491 
[epoch 13] step 6/44: loss=0.0553 
[epoch 13] step 8/44: loss=0.0658 
[epoch 13] step 10/44: loss=0.0593 
[epoch 13] step 12/44: loss=0.0563 
[epoch 13] step 14/44: loss=0.0532 
[epoch 13] step 16/44: loss=0.0499 
[epoch 13] step 18/44: loss=0.0515 
[epoch 13] step 20/44: loss=0.0493 
[epoch 13] step 22/44: loss=0.0506 
[epoch 13] step 24/44: loss=0.0512 
[epoch 13] step 26/44: loss=0.0547 
[epoch 13] step 28/44: loss=0.0560 
[epoch 13] step 30/44: loss=0.0548 
[epoch 13] step 32/44: loss=0.0517 
[epoch 13] step 34/44: loss=0.0521 
[epoch 13] step 36/44: loss=0.0515 
[epoch 13] step 38/44: loss=0.0519 
[epoch 13] step 40/44: loss=0.0559 
[epoch 13] step 42/44: loss=0.0570 
[epoch 13] step 44/44: loss=0.0567 
[epoch 13] train_loss(avg per step)=0.1135 lambda[min,max]=[0.503966,1.000000]
[epoch 13] val_loss=0.9641 qwk=('0.5293', '0.5449', '0.5365') averageQWK=0.5369 macroEMD=0.1917 tailR0=('0.1991', '0.0833', '0.0000') tailR0avg=0.0941
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    0    0
     1   14   22    3    0
     0   10   97   21    0
     0    0   70   52    0
     0    0    6   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    0    0
     0   16   27    5    0
     0    9   81   23    0
     0    2   59   86    1
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   50   21    0    0
     0   53   89    9    0
     0    4   58   37    0
     0    0    1    2    0
[epoch 14] step 2/44: loss=0.0442 
[epoch 14] step 4/44: loss=0.0638 
[epoch 14] step 6/44: loss=0.0594 
[epoch 14] step 8/44: loss=0.0519 
[epoch 14] step 10/44: loss=0.0569 
[epoch 14] step 12/44: loss=0.0580 
[epoch 14] step 14/44: loss=0.0507 
[epoch 14] step 16/44: loss=0.0467 
[epoch 14] step 18/44: loss=0.0487 
[epoch 14] step 20/44: loss=0.0473 
[epoch 14] step 22/44: loss=0.0420 
[epoch 14] step 24/44: loss=0.0424 
[epoch 14] step 26/44: loss=0.0420 
[epoch 14] step 28/44: loss=0.0389 
[epoch 14] step 30/44: loss=0.0424 
[epoch 14] step 32/44: loss=0.0458 
[epoch 14] step 34/44: loss=0.0485 
[epoch 14] step 36/44: loss=0.0473 
[epoch 14] step 38/44: loss=0.0491 
[epoch 14] step 40/44: loss=0.0498 
[epoch 14] step 42/44: loss=0.0515 
[epoch 14] step 44/44: loss=0.0490 
[epoch 14] train_loss(avg per step)=0.0980 lambda[min,max]=[0.503893,1.000000]
[epoch 14] val_loss=0.9532 qwk=('0.5035', '0.5299', '0.5357') averageQWK=0.5231 macroEMD=0.1909 tailR0=('0.0995', '0.0833', '0.0000') tailR0avg=0.0610
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     0   16   20    4    0
     0   10   92   26    0
     0    2   65   55    0
     0    0    6   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    0    0
     0   17   25    6    0
     0   12   79   22    0
     0    3   60   84    1
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   41   30    0    0
     0   36  101   14    0
     0    3   54   42    0
     0    0    1    2    0
[epoch 15] step 2/44: loss=0.0459 
[epoch 15] step 4/44: loss=0.0598 
[epoch 15] step 6/44: loss=0.0519 
[epoch 15] step 8/44: loss=0.0418 
[epoch 15] step 10/44: loss=0.0387 
[epoch 15] step 12/44: loss=0.0365 
[epoch 15] step 14/44: loss=0.0304 
[epoch 15] step 16/44: loss=0.0233 
[epoch 15] step 18/44: loss=0.0230 
[epoch 15] step 20/44: loss=0.0202 
[epoch 15] step 22/44: loss=0.0191 
[epoch 15] step 24/44: loss=0.0210 
[epoch 15] step 26/44: loss=0.0205 
[epoch 15] step 28/44: loss=0.0178 
[epoch 15] step 30/44: loss=0.0171 
[epoch 15] step 32/44: loss=0.0202 
[epoch 15] step 34/44: loss=0.0189 
[epoch 15] step 36/44: loss=0.0175 
[epoch 15] step 38/44: loss=0.0187 
[epoch 15] step 40/44: loss=0.0175 
[epoch 15] step 42/44: loss=0.0163 
[epoch 15] step 44/44: loss=0.0137 
[epoch 15] train_loss(avg per step)=0.0274 lambda[min,max]=[0.503142,1.000000]
[epoch 15] val_loss=0.9353 qwk=('0.4905', '0.4931', '0.5128') averageQWK=0.4988 macroEMD=0.1993 tailR0=('0.1366', '0.1333', '0.0000') tailR0avg=0.0900
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    5   27    8    0
     0    2   78   47    1
     0    0   40   82    0
     0    0    1   22    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    4   33   11    0
     0    2   52   59    0
     0    0   24  123    1
     0    0    0    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   32   37    2    0
     0   22  105   24    0
     0    2   48   49    0
     0    0    1    2    0
[epoch 16] step 2/44: loss=-0.0045 
[epoch 16] step 4/44: loss=0.0008 
[epoch 16] step 6/44: loss=-0.0104 
[epoch 16] step 8/44: loss=-0.0104 
[epoch 16] step 10/44: loss=-0.0082 
[epoch 16] step 12/44: loss=-0.0098 
[epoch 16] step 14/44: loss=-0.0033 
[epoch 16] step 16/44: loss=-0.0063 
[epoch 16] step 18/44: loss=-0.0069 
[epoch 16] step 20/44: loss=-0.0046 
[epoch 16] step 22/44: loss=-0.0093 
[epoch 16] step 24/44: loss=-0.0106 
[epoch 16] step 26/44: loss=-0.0114 
[epoch 16] step 28/44: loss=-0.0107 
[epoch 16] step 30/44: loss=-0.0137 
[epoch 16] step 32/44: loss=-0.0133 
[epoch 16] step 34/44: loss=-0.0158 
[epoch 16] step 36/44: loss=-0.0143 
[epoch 16] step 38/44: loss=-0.0129 
[epoch 16] step 40/44: loss=-0.0145 
[epoch 16] step 42/44: loss=-0.0138 
[epoch 16] step 44/44: loss=-0.0143 
[epoch 16] train_loss(avg per step)=-0.0286 lambda[min,max]=[0.502577,1.000000]
[epoch 16] val_loss=0.9496 qwk=('0.5201', '0.5391', '0.5088') averageQWK=0.5227 macroEMD=0.1993 tailR0=('0.1181', '0.1500', '0.0000') tailR0avg=0.0894
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    5   28    7    0
     0    4   81   42    1
     0    0   35   86    1
     0    0    2   22    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   11   28    9    0
     0    4   53   56    0
     0    2   26  118    2
     0    0    0    7    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   45    2    0
     0   13  109   29    0
     0    1   43   55    0
     0    0    1    2    0
[epoch 17] step 2/44: loss=-0.0656 
[epoch 17] step 4/44: loss=-0.0491 
[epoch 17] step 6/44: loss=-0.0313 
[epoch 17] step 8/44: loss=-0.0309 
[epoch 17] step 10/44: loss=-0.0377 
[epoch 17] step 12/44: loss=-0.0360 
[epoch 17] step 14/44: loss=-0.0351 
[epoch 17] step 16/44: loss=-0.0389 
[epoch 17] step 18/44: loss=-0.0422 
[epoch 17] step 20/44: loss=-0.0412 
[epoch 17] step 22/44: loss=-0.0416 
[epoch 17] step 24/44: loss=-0.0432 
[epoch 17] step 26/44: loss=-0.0397 
[epoch 17] step 28/44: loss=-0.0422 
[epoch 17] step 30/44: loss=-0.0429 
[epoch 17] step 32/44: loss=-0.0420 
[epoch 17] step 34/44: loss=-0.0431 
[epoch 17] step 36/44: loss=-0.0429 
[epoch 17] step 38/44: loss=-0.0417 
[epoch 17] step 40/44: loss=-0.0431 
[epoch 17] step 42/44: loss=-0.0431 
[epoch 17] step 44/44: loss=-0.0432 
[epoch 17] train_loss(avg per step)=-0.0864 lambda[min,max]=[0.502050,1.000000]
[epoch 17] val_loss=0.9866 qwk=('0.5075', '0.4999', '0.4650') averageQWK=0.4908 macroEMD=0.1977 tailR0=('0.0995', '0.1000', '0.0000') tailR0avg=0.0665
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    6   28    6    0
     0    4   80   44    0
     0    0   39   83    0
     0    0    2   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    8   32    8    0
     0    4   72   37    0
     0    1   42  104    1
     0    0    2    6    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   48    3    0
     0   11  115   25    0
     0    1   48   50    0
     0    0    1    2    0
[epoch 18] step 2/44: loss=-0.0827 
[epoch 18] step 4/44: loss=-0.0529 
[epoch 18] step 6/44: loss=-0.0583 
[epoch 18] step 8/44: loss=-0.0577 
[epoch 18] step 10/44: loss=-0.0568 
[epoch 18] step 12/44: loss=-0.0642 
[epoch 18] step 14/44: loss=-0.0665 
[epoch 18] step 16/44: loss=-0.0689 
[epoch 18] step 18/44: loss=-0.0711 
[epoch 18] step 20/44: loss=-0.0699 
[epoch 18] step 22/44: loss=-0.0682 
[epoch 18] step 24/44: loss=-0.0658 
[epoch 18] step 26/44: loss=-0.0668 
[epoch 18] step 28/44: loss=-0.0670 
[epoch 18] step 30/44: loss=-0.0694 
[epoch 18] step 32/44: loss=-0.0704 
[epoch 18] step 34/44: loss=-0.0706 
[epoch 18] step 36/44: loss=-0.0711 
[epoch 18] step 38/44: loss=-0.0704 
[epoch 18] step 40/44: loss=-0.0709 
[epoch 18] step 42/44: loss=-0.0716 
[epoch 18] step 44/44: loss=-0.0719 
[epoch 18] train_loss(avg per step)=-0.1439 lambda[min,max]=[0.501648,1.000000]
[epoch 18] val_loss=1.0011 qwk=('0.5127', '0.5051', '0.5212') averageQWK=0.5130 macroEMD=0.1897 tailR0=('0.0995', '0.0833', '0.5000') tailR0avg=0.2276
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    7   26    7    0
     0    4   80   44    0
     0    0   37   85    0
     0    0    3   22    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0   10   29    9    0
     0    4   63   46    0
     0    0   39  108    1
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    0    0    0
     0   26   44    1    0
     0   20  104   27    0
     0    1   45   53    0
     0    0    1    2    0
[epoch 19] step 2/44: loss=-0.0781 
[epoch 19] step 4/44: loss=-0.0859 
[epoch 19] step 6/44: loss=-0.0877 
[epoch 19] step 8/44: loss=-0.0911 
[epoch 19] step 10/44: loss=-0.0832 
[epoch 19] step 12/44: loss=-0.0809 
[epoch 19] step 14/44: loss=-0.0810 
[epoch 19] step 16/44: loss=-0.0833 
[epoch 19] step 18/44: loss=-0.0863 
[epoch 19] step 20/44: loss=-0.0888 
[epoch 19] step 22/44: loss=-0.0868 
[epoch 19] step 24/44: loss=-0.0832 
[epoch 19] step 26/44: loss=-0.0824 
[epoch 19] step 28/44: loss=-0.0824 
[epoch 19] step 30/44: loss=-0.0809 
[epoch 19] step 32/44: loss=-0.0828 
[epoch 19] step 34/44: loss=-0.0841 
[epoch 19] step 36/44: loss=-0.0855 
[epoch 19] step 38/44: loss=-0.0851 
[epoch 19] step 40/44: loss=-0.0851 
[epoch 19] step 42/44: loss=-0.0858 
[epoch 19] step 44/44: loss=-0.0864 
[epoch 19] train_loss(avg per step)=-0.1727 lambda[min,max]=[0.501564,1.000000]
[epoch 19] val_loss=1.0530 qwk=('0.5256', '0.5202', '0.5357') averageQWK=0.5272 macroEMD=0.1944 tailR0=('0.0995', '0.0833', '0.0000') tailR0avg=0.0610
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0   12   24    4    0
     0    7   87   34    0
     0    1   50   71    0
     0    0    4   21    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    0    0
     0   14   27    7    0
     0   10   78   25    0
     0    2   57   89    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   37   33    1    0
     0   33  106   12    0
     0    1   55   43    0
     0    0    1    2    0
[epoch 20] step 2/44: loss=-0.0778 
[epoch 20] step 4/44: loss=-0.0874 
[epoch 20] step 6/44: loss=-0.0929 
[epoch 20] step 8/44: loss=-0.0967 
[epoch 20] step 10/44: loss=-0.1040 
[epoch 20] step 12/44: loss=-0.1051 
[epoch 20] step 14/44: loss=-0.1060 
[epoch 20] step 16/44: loss=-0.1077 
[epoch 20] step 18/44: loss=-0.1082 
[epoch 20] step 20/44: loss=-0.1105 
[epoch 20] step 22/44: loss=-0.1100 
[epoch 20] step 24/44: loss=-0.1105 
[epoch 20] step 26/44: loss=-0.1100 
[epoch 20] step 28/44: loss=-0.1104 
[epoch 20] step 30/44: loss=-0.1096 
[epoch 20] step 32/44: loss=-0.1093 
[epoch 20] step 34/44: loss=-0.1070 
[epoch 20] step 36/44: loss=-0.1073 
[epoch 20] step 38/44: loss=-0.1085 
[epoch 20] step 40/44: loss=-0.1087 
[epoch 20] step 42/44: loss=-0.1082 
[epoch 20] step 44/44: loss=-0.1081 
[epoch 20] train_loss(avg per step)=-0.2162 lambda[min,max]=[0.501431,1.000000]
[epoch 20] val_loss=1.0792 qwk=('0.4994', '0.4711', '0.4648') averageQWK=0.4785 macroEMD=0.2044 tailR0=('0.1181', '0.0000', '0.0000') tailR0avg=0.0394
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     0    3   30    7    0
     0    1   85   40    2
     0    0   34   88    0
     0    0    1   23    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    3   36    9    0
     0    4   63   46    0
     0    0   35  112    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   54    1    0
     0    9  119   23    0
     0    0   51   48    0
     0    0    1    2    0
[epoch 21] step 2/44: loss=-0.1143 
[epoch 21] step 4/44: loss=-0.1101 
[epoch 21] step 6/44: loss=-0.1054 
[epoch 21] step 8/44: loss=-0.1042 
[epoch 21] step 10/44: loss=-0.1075 
[epoch 21] step 12/44: loss=-0.1084 
[epoch 21] step 14/44: loss=-0.1106 
[epoch 21] step 16/44: loss=-0.1125 
[epoch 21] step 18/44: loss=-0.1127 
[epoch 21] step 20/44: loss=-0.1119 
[epoch 21] step 22/44: loss=-0.1133 
[epoch 21] step 24/44: loss=-0.1118 
[epoch 21] step 26/44: loss=-0.1123 
[epoch 21] step 28/44: loss=-0.1133 
[epoch 21] step 30/44: loss=-0.1138 
[epoch 21] step 32/44: loss=-0.1148 
[epoch 21] step 34/44: loss=-0.1148 
[epoch 21] step 36/44: loss=-0.1159 
[epoch 21] step 38/44: loss=-0.1167 
[epoch 21] step 40/44: loss=-0.1178 
[epoch 21] step 42/44: loss=-0.1186 
[epoch 21] step 44/44: loss=-0.1204 
[epoch 21] train_loss(avg per step)=-0.2407 lambda[min,max]=[0.501378,1.000000]
[epoch 21] val_loss=1.0637 qwk=('0.4943', '0.4615', '0.5070') averageQWK=0.4876 macroEMD=0.2041 tailR0=('0.0370', '0.0000', '0.0000') tailR0avg=0.0123
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    0    0
     0    3   31    6    0
     0    1   82   45    0
     0    0   32   90    0
     0    0    2   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5   35    8    0
     0    3   75   35    0
     0    1   46  101    0
     0    0    2    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   42    3    0
     0   12  115   24    0
     0    0   49   50    0
     0    0    1    2    0
[epoch 22] step 2/44: loss=-0.1453 
[epoch 22] step 4/44: loss=-0.1320 
[epoch 22] step 6/44: loss=-0.1335 
[epoch 22] step 8/44: loss=-0.1326 
[epoch 22] step 10/44: loss=-0.1319 
[epoch 22] step 12/44: loss=-0.1303 
[epoch 22] step 14/44: loss=-0.1288 
[epoch 22] step 16/44: loss=-0.1278 
[epoch 22] step 18/44: loss=-0.1279 
[epoch 22] step 20/44: loss=-0.1299 
[epoch 22] step 22/44: loss=-0.1302 
[epoch 22] step 24/44: loss=-0.1289 
[epoch 22] step 26/44: loss=-0.1305 
[epoch 22] step 28/44: loss=-0.1303 
[epoch 22] step 30/44: loss=-0.1315 
[epoch 22] step 32/44: loss=-0.1316 
[epoch 22] step 34/44: loss=-0.1303 
[epoch 22] step 36/44: loss=-0.1308 
[epoch 22] step 38/44: loss=-0.1309 
[epoch 22] step 40/44: loss=-0.1312 
[epoch 22] step 42/44: loss=-0.1317 
[epoch 22] step 44/44: loss=-0.1319 
[epoch 22] train_loss(avg per step)=-0.2638 lambda[min,max]=[0.501300,1.000000]
[epoch 22] val_loss=1.0547 qwk=('0.5047', '0.5047', '0.5293') averageQWK=0.5129 macroEMD=0.1989 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    6   28    6    0
     0    4   84   39    1
     0    0   43   78    1
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    8   30   10    0
     0    3   58   52    0
     0    1   30  117    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   38    2    0
     0   17  113   21    0
     0    2   46   51    0
     0    0    1    2    0
[epoch 23] step 2/44: loss=-0.1264 
[epoch 23] step 4/44: loss=-0.1376 
[epoch 23] step 6/44: loss=-0.1403 
[epoch 23] step 8/44: loss=-0.1417 
[epoch 23] step 10/44: loss=-0.1441 
[epoch 23] step 12/44: loss=-0.1432 
[epoch 23] step 14/44: loss=-0.1414 
[epoch 23] step 16/44: loss=-0.1424 
[epoch 23] step 18/44: loss=-0.1444 
[epoch 23] step 20/44: loss=-0.1447 
[epoch 23] step 22/44: loss=-0.1432 
[epoch 23] step 24/44: loss=-0.1431 
[epoch 23] step 26/44: loss=-0.1429 
[epoch 23] step 28/44: loss=-0.1424 
[epoch 23] step 30/44: loss=-0.1429 
[epoch 23] step 32/44: loss=-0.1435 
[epoch 23] step 34/44: loss=-0.1432 
[epoch 23] step 36/44: loss=-0.1433 
[epoch 23] step 38/44: loss=-0.1433 
[epoch 23] step 40/44: loss=-0.1430 
[epoch 23] step 42/44: loss=-0.1429 
[epoch 23] step 44/44: loss=-0.1438 
[epoch 23] train_loss(avg per step)=-0.2877 lambda[min,max]=[0.501009,1.000000]
[epoch 23] val_loss=1.0828 qwk=('0.5223', '0.4941', '0.4969') averageQWK=0.5044 macroEMD=0.1981 tailR0=('0.1181', '0.0000', '0.0000') tailR0avg=0.0394
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    6   27    7    0
     0    3   85   40    0
     0    0   40   82    0
     0    0    2   22    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    9   30    9    0
     0    4   76   33    0
     0    2   45  101    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   42    3    0
     0   12  110   29    0
     0    0   49   50    0
     0    0    1    2    0
[epoch 24] step 2/44: loss=-0.1537 
[epoch 24] step 4/44: loss=-0.1577 
[epoch 24] step 6/44: loss=-0.1583 
[epoch 24] step 8/44: loss=-0.1582 
[epoch 24] step 10/44: loss=-0.1559 
[epoch 24] step 12/44: loss=-0.1558 
[epoch 24] step 14/44: loss=-0.1556 
[epoch 24] step 16/44: loss=-0.1549 
[epoch 24] step 18/44: loss=-0.1535 
[epoch 24] step 20/44: loss=-0.1532 
[epoch 24] step 22/44: loss=-0.1531 
[epoch 24] step 24/44: loss=-0.1524 
[epoch 24] step 26/44: loss=-0.1516 
[epoch 24] step 28/44: loss=-0.1504 
[epoch 24] step 30/44: loss=-0.1511 
[epoch 24] step 32/44: loss=-0.1513 
[epoch 24] step 34/44: loss=-0.1498 
[epoch 24] step 36/44: loss=-0.1495 
[epoch 24] step 38/44: loss=-0.1489 
[epoch 24] step 40/44: loss=-0.1494 
[epoch 24] step 42/44: loss=-0.1482 
[epoch 24] step 44/44: loss=-0.1492 
[epoch 24] train_loss(avg per step)=-0.2984 lambda[min,max]=[0.501222,1.000000]
[epoch 24] val_loss=1.0875 qwk=('0.4976', '0.4632', '0.4976') averageQWK=0.4861 macroEMD=0.2001 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    4   30    6    0
     0    2   92   34    0
     0    0   45   77    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7   32    9    0
     0    4   64   45    0
     0    1   42  105    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   19   49    3    0
     0    8  114   29    0
     0    0   42   57    0
     0    0    1    2    0
[epoch 25] step 2/44: loss=-0.1594 
[epoch 25] step 4/44: loss=-0.1588 
[epoch 25] step 6/44: loss=-0.1586 
[epoch 25] step 8/44: loss=-0.1631 
[epoch 25] step 10/44: loss=-0.1602 
[epoch 25] step 12/44: loss=-0.1577 
[epoch 25] step 14/44: loss=-0.1598 
[epoch 25] step 16/44: loss=-0.1594 
[epoch 25] step 18/44: loss=-0.1604 
[epoch 25] step 20/44: loss=-0.1601 
[epoch 25] step 22/44: loss=-0.1613 
[epoch 25] step 24/44: loss=-0.1614 
[epoch 25] step 26/44: loss=-0.1610 
[epoch 25] step 28/44: loss=-0.1602 
[epoch 25] step 30/44: loss=-0.1596 
[epoch 25] step 32/44: loss=-0.1596 
[epoch 25] step 34/44: loss=-0.1589 
[epoch 25] step 36/44: loss=-0.1577 
[epoch 25] step 38/44: loss=-0.1573 
[epoch 25] step 40/44: loss=-0.1567 
[epoch 25] step 42/44: loss=-0.1563 
[epoch 25] step 44/44: loss=-0.1562 
[epoch 25] train_loss(avg per step)=-0.3125 lambda[min,max]=[0.501203,1.000000]
[epoch 25] val_loss=1.1091 qwk=('0.4737', '0.4649', '0.4920') averageQWK=0.4769 macroEMD=0.2032 tailR0=('0.0810', '0.1500', '0.0000') tailR0avg=0.0770
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    5    0    0
     0    4   29    7    0
     0    1   82   45    0
     0    0   35   87    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2   37    9    0
     0    3   68   42    0
     0    1   41  105    1
     0    0    0    7    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   21   47    3    0
     0   10  117   24    0
     0    0   47   52    0
     0    0    1    2    0
[epoch 26] step 2/44: loss=-0.1642 
[epoch 26] step 4/44: loss=-0.1694 
[epoch 26] step 6/44: loss=-0.1703 
[epoch 26] step 8/44: loss=-0.1697 
[epoch 26] step 10/44: loss=-0.1673 
[epoch 26] step 12/44: loss=-0.1662 
[epoch 26] step 14/44: loss=-0.1662 
[epoch 26] step 16/44: loss=-0.1654 
[epoch 26] step 18/44: loss=-0.1646 
[epoch 26] step 20/44: loss=-0.1631 
[epoch 26] step 22/44: loss=-0.1621 
[epoch 26] step 24/44: loss=-0.1621 
[epoch 26] step 26/44: loss=-0.1624 
[epoch 26] step 28/44: loss=-0.1611 
[epoch 26] step 30/44: loss=-0.1617 
[epoch 26] step 32/44: loss=-0.1623 
[epoch 26] step 34/44: loss=-0.1626 
[epoch 26] step 36/44: loss=-0.1628 
[epoch 26] step 38/44: loss=-0.1628 
[epoch 26] step 40/44: loss=-0.1623 
[epoch 26] step 42/44: loss=-0.1624 
[epoch 26] step 44/44: loss=-0.1625 
[epoch 26] train_loss(avg per step)=-0.3249 lambda[min,max]=[0.501056,1.000000]
[epoch 26] val_loss=1.1216 qwk=('0.5001', '0.4592', '0.5134') averageQWK=0.4909 macroEMD=0.1981 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    6   27    7    0
     0    4   82   42    0
     0    0   42   80    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    3   37    8    0
     0    3   78   32    0
     0    0   51   97    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   28   40    3    0
     0   12  114   25    0
     0    2   44   53    0
     0    0    1    2    0
[epoch 27] step 2/44: loss=-0.1708 
[epoch 27] step 4/44: loss=-0.1730 
[epoch 27] step 6/44: loss=-0.1732 
[epoch 27] step 8/44: loss=-0.1716 
[epoch 27] step 10/44: loss=-0.1723 
[epoch 27] step 12/44: loss=-0.1727 
[epoch 27] step 14/44: loss=-0.1737 
[epoch 27] step 16/44: loss=-0.1743 
[epoch 27] step 18/44: loss=-0.1721 
[epoch 27] step 20/44: loss=-0.1725 
[epoch 27] step 22/44: loss=-0.1714 
[epoch 27] step 24/44: loss=-0.1718 
[epoch 27] step 26/44: loss=-0.1721 
[epoch 27] step 28/44: loss=-0.1710 
[epoch 27] step 30/44: loss=-0.1691 
[epoch 27] step 32/44: loss=-0.1700 
[epoch 27] step 34/44: loss=-0.1694 
[epoch 27] step 36/44: loss=-0.1698 
[epoch 27] step 38/44: loss=-0.1703 
[epoch 27] step 40/44: loss=-0.1700 
[epoch 27] step 42/44: loss=-0.1686 
[epoch 27] step 44/44: loss=-0.1689 
[epoch 27] train_loss(avg per step)=-0.3378 lambda[min,max]=[0.501046,1.000000]
[epoch 27] val_loss=1.1369 qwk=('0.4963', '0.4741', '0.5229') averageQWK=0.4978 macroEMD=0.1966 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    6   27    7    0
     0    5   87   36    0
     0    0   45   77    0
     0    0    3   23    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    8   33    7    0
     0    3   90   20    0
     0    1   63   83    1
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   33   35    3    0
     0   19  110   22    0
     0    3   44   52    0
     0    0    1    2    0
[epoch 28] step 2/44: loss=-0.1810 
[epoch 28] step 4/44: loss=-0.1775 
[epoch 28] step 6/44: loss=-0.1760 
[epoch 28] step 8/44: loss=-0.1766 
[epoch 28] step 10/44: loss=-0.1737 
[epoch 28] step 12/44: loss=-0.1735 
[epoch 28] step 14/44: loss=-0.1728 
[epoch 28] step 16/44: loss=-0.1729 
[epoch 28] step 18/44: loss=-0.1726 
[epoch 28] step 20/44: loss=-0.1726 
[epoch 28] step 22/44: loss=-0.1717 
[epoch 28] step 24/44: loss=-0.1721 
[epoch 28] step 26/44: loss=-0.1723 
[epoch 28] step 28/44: loss=-0.1706 
[epoch 28] step 30/44: loss=-0.1702 
[epoch 28] step 32/44: loss=-0.1698 
[epoch 28] step 34/44: loss=-0.1700 
[epoch 28] step 36/44: loss=-0.1705 
[epoch 28] step 38/44: loss=-0.1709 
[epoch 28] step 40/44: loss=-0.1710 
[epoch 28] step 42/44: loss=-0.1714 
[epoch 28] step 44/44: loss=-0.1713 
[epoch 28] train_loss(avg per step)=-0.3426 lambda[min,max]=[0.501085,1.000000]
[epoch 28] val_loss=1.1409 qwk=('0.4987', '0.4652', '0.5063') averageQWK=0.4901 macroEMD=0.2003 tailR0=('0.0995', '0.0500', '0.0000') tailR0avg=0.0498
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     0    5   28    7    0
     0    2   79   47    0
     0    0   35   87    0
     0    0    1   24    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    4   35    9    0
     0    3   72   38    0
     0    1   47   99    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   25   42    4    0
     0   10  113   28    0
     0    0   45   54    0
     0    0    1    2    0
[epoch 29] step 2/44: loss=-0.1837 
[epoch 29] step 4/44: loss=-0.1771 
[epoch 29] step 6/44: loss=-0.1750 
[epoch 29] step 8/44: loss=-0.1753 
[epoch 29] step 10/44: loss=-0.1743 
[epoch 29] step 12/44: loss=-0.1739 
[epoch 29] step 14/44: loss=-0.1735 
[epoch 29] step 16/44: loss=-0.1741 
[epoch 29] step 18/44: loss=-0.1754 
[epoch 29] step 20/44: loss=-0.1751 
[epoch 29] step 22/44: loss=-0.1762 
[epoch 29] step 24/44: loss=-0.1769 
[epoch 29] step 26/44: loss=-0.1770 
[epoch 29] step 28/44: loss=-0.1767 
[epoch 29] step 30/44: loss=-0.1775 
[epoch 29] step 32/44: loss=-0.1770 
[epoch 29] step 34/44: loss=-0.1772 
[epoch 29] step 36/44: loss=-0.1772 
[epoch 29] step 38/44: loss=-0.1769 
[epoch 29] step 40/44: loss=-0.1765 
[epoch 29] step 42/44: loss=-0.1770 
[epoch 29] step 44/44: loss=-0.1773 
[epoch 29] train_loss(avg per step)=-0.3545 lambda[min,max]=[0.500986,1.000000]
[epoch 29] val_loss=1.1724 qwk=('0.4577', '0.4729', '0.5356') averageQWK=0.4887 macroEMD=0.2095 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    5    0    0
     0    1   32    7    0
     0    1   78   49    0
     0    0   32   90    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    3   36    9    0
     0    3   57   53    0
     0    1   30  117    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   27   44    0    0
     0   14  119   18    0
     0    1   49   49    0
     0    0    1    2    0
[epoch 30] step 2/44: loss=-0.1848 
[epoch 30] step 4/44: loss=-0.1821 
[epoch 30] step 6/44: loss=-0.1808 
[epoch 30] step 8/44: loss=-0.1788 
[epoch 30] step 10/44: loss=-0.1779 
[epoch 30] step 12/44: loss=-0.1791 
[epoch 30] step 14/44: loss=-0.1785 
[epoch 30] step 16/44: loss=-0.1792 
[epoch 30] step 18/44: loss=-0.1776 
[epoch 30] step 20/44: loss=-0.1778 
[epoch 30] step 22/44: loss=-0.1782 
[epoch 30] step 24/44: loss=-0.1789 
[epoch 30] step 26/44: loss=-0.1790 
[epoch 30] step 28/44: loss=-0.1794 
[epoch 30] step 30/44: loss=-0.1796 
[epoch 30] step 32/44: loss=-0.1793 
[epoch 30] step 34/44: loss=-0.1795 
[epoch 30] step 36/44: loss=-0.1790 
[epoch 30] step 38/44: loss=-0.1792 
[epoch 30] step 40/44: loss=-0.1791 
[epoch 30] step 42/44: loss=-0.1791 
[epoch 30] step 44/44: loss=-0.1793 
[epoch 30] train_loss(avg per step)=-0.3586 lambda[min,max]=[0.501002,1.000000]
[epoch 30] val_loss=1.1542 qwk=('0.5191', '0.4951', '0.5182') averageQWK=0.5108 macroEMD=0.1981 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    6   27    7    0
     0    4   85   39    0
     0    0   38   84    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   11   28    9    0
     0    5   77   31    0
     0    1   52   95    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   28   41    2    0
     0   15  118   18    0
     0    2   47   50    0
     0    0    1    2    0
[epoch 31] step 2/44: loss=-0.1780 
[epoch 31] step 4/44: loss=-0.1819 
[epoch 31] step 6/44: loss=-0.1832 
[epoch 31] step 8/44: loss=-0.1838 
[epoch 31] step 10/44: loss=-0.1852 
[epoch 31] step 12/44: loss=-0.1837 
[epoch 31] step 14/44: loss=-0.1834 
[epoch 31] step 16/44: loss=-0.1837 
[epoch 31] step 18/44: loss=-0.1836 
[epoch 31] step 20/44: loss=-0.1837 
[epoch 31] step 22/44: loss=-0.1841 
[epoch 31] step 24/44: loss=-0.1838 
[epoch 31] step 26/44: loss=-0.1836 
[epoch 31] step 28/44: loss=-0.1832 
[epoch 31] step 30/44: loss=-0.1832 
[epoch 31] step 32/44: loss=-0.1836 
[epoch 31] step 34/44: loss=-0.1838 
[epoch 31] step 36/44: loss=-0.1837 
[epoch 31] step 38/44: loss=-0.1835 
[epoch 31] step 40/44: loss=-0.1834 
[epoch 31] step 42/44: loss=-0.1836 
[epoch 31] step 44/44: loss=-0.1830 
[epoch 31] train_loss(avg per step)=-0.3659 lambda[min,max]=[0.500916,1.000000]
[epoch 31] val_loss=1.1573 qwk=('0.4720', '0.4840', '0.5023') averageQWK=0.4861 macroEMD=0.1980 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     0    3   30    7    0
     0    2   86   40    0
     0    0   41   81    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    8   31    9    0
     0    3   68   42    0
     0    1   43  104    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   47    2    0
     0   12  119   20    0
     0    0   49   50    0
     0    0    1    2    0
[epoch 32] step 2/44: loss=-0.1896 
[epoch 32] step 4/44: loss=-0.1882 
[epoch 32] step 6/44: loss=-0.1863 
[epoch 32] step 8/44: loss=-0.1868 
[epoch 32] step 10/44: loss=-0.1869 
[epoch 32] step 12/44: loss=-0.1861 
[epoch 32] step 14/44: loss=-0.1867 
[epoch 32] step 16/44: loss=-0.1854 
[epoch 32] step 18/44: loss=-0.1856 
[epoch 32] step 20/44: loss=-0.1849 
[epoch 32] step 22/44: loss=-0.1854 
[epoch 32] step 24/44: loss=-0.1850 
[epoch 32] step 26/44: loss=-0.1850 
[epoch 32] step 28/44: loss=-0.1849 
[epoch 32] step 30/44: loss=-0.1848 
[epoch 32] step 32/44: loss=-0.1845 
[epoch 32] step 34/44: loss=-0.1849 
[epoch 32] step 36/44: loss=-0.1846 
[epoch 32] step 38/44: loss=-0.1845 
[epoch 32] step 40/44: loss=-0.1848 
[epoch 32] step 42/44: loss=-0.1844 
[epoch 32] step 44/44: loss=-0.1846 
[epoch 32] train_loss(avg per step)=-0.3692 lambda[min,max]=[0.501004,1.000000]
[epoch 32] val_loss=1.1729 qwk=('0.4656', '0.4881', '0.5539') averageQWK=0.5025 macroEMD=0.2006 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    3   30    7    0
     0    2   89   37    0
     0    0   46   76    0
     0    0    3   23    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    7   32    9    0
     0    3   79   31    0
     0    1   48   99    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   30   41    0    0
     0   14  124   13    0
     0    2   48   49    0
     0    0    1    2    0
[epoch 33] step 2/44: loss=-0.1814 
[epoch 33] step 4/44: loss=-0.1817 
[epoch 33] step 6/44: loss=-0.1807 
[epoch 33] step 8/44: loss=-0.1824 
[epoch 33] step 10/44: loss=-0.1830 
[epoch 33] step 12/44: loss=-0.1834 
[epoch 33] step 14/44: loss=-0.1840 
[epoch 33] step 16/44: loss=-0.1848 
[epoch 33] step 18/44: loss=-0.1847 
[epoch 33] step 20/44: loss=-0.1846 
[epoch 33] step 22/44: loss=-0.1844 
[epoch 33] step 24/44: loss=-0.1843 
[epoch 33] step 26/44: loss=-0.1848 
[epoch 33] step 28/44: loss=-0.1850 
[epoch 33] step 30/44: loss=-0.1850 
[epoch 33] step 32/44: loss=-0.1846 
[epoch 33] step 34/44: loss=-0.1846 
[epoch 33] step 36/44: loss=-0.1848 
[epoch 33] step 38/44: loss=-0.1849 
[epoch 33] step 40/44: loss=-0.1850 
[epoch 33] step 42/44: loss=-0.1852 
[epoch 33] step 44/44: loss=-0.1856 
[epoch 33] train_loss(avg per step)=-0.3712 lambda[min,max]=[0.501003,1.000000]
[epoch 33] val_loss=1.1757 qwk=('0.4978', '0.4797', '0.5043') averageQWK=0.4939 macroEMD=0.2011 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    4   29    7    0
     0    2   87   39    0
     0    0   42   80    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    6   33    9    0
     0    3   75   35    0
     0    1   46  101    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   25   43    3    0
     0   12  118   21    0
     0    1   47   51    0
     0    0    1    2    0
[epoch 34] step 2/44: loss=-0.1911 
[epoch 34] step 4/44: loss=-0.1918 
[epoch 34] step 6/44: loss=-0.1876 
[epoch 34] step 8/44: loss=-0.1876 
[epoch 34] step 10/44: loss=-0.1863 
[epoch 34] step 12/44: loss=-0.1869 
[epoch 34] step 14/44: loss=-0.1874 
[epoch 34] step 16/44: loss=-0.1872 
[epoch 34] step 18/44: loss=-0.1877 
[epoch 34] step 20/44: loss=-0.1881 
[epoch 34] step 22/44: loss=-0.1878 
[epoch 34] step 24/44: loss=-0.1874 
[epoch 34] step 26/44: loss=-0.1869 
[epoch 34] step 28/44: loss=-0.1869 
[epoch 34] step 30/44: loss=-0.1868 
[epoch 34] step 32/44: loss=-0.1865 
[epoch 34] step 34/44: loss=-0.1866 
[epoch 34] step 36/44: loss=-0.1867 
[epoch 34] step 38/44: loss=-0.1870 
[epoch 34] step 40/44: loss=-0.1868 
[epoch 34] step 42/44: loss=-0.1867 
[epoch 34] step 44/44: loss=-0.1869 
[epoch 34] train_loss(avg per step)=-0.3737 lambda[min,max]=[0.500978,1.000000]
[epoch 34] val_loss=1.1697 qwk=('0.4852', '0.4669', '0.5363') averageQWK=0.4961 macroEMD=0.1992 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    4   29    7    0
     0    3   86   39    0
     0    0   46   76    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    5   34    9    0
     0    3   72   38    0
     0    1   46  101    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   28   42    1    0
     0   13  123   15    0
     0    2   47   50    0
     0    0    1    2    0
[epoch 35] step 2/44: loss=-0.1888 
[epoch 35] step 4/44: loss=-0.1900 
[epoch 35] step 6/44: loss=-0.1874 
[epoch 35] step 8/44: loss=-0.1891 
[epoch 35] step 10/44: loss=-0.1898 
[epoch 35] step 12/44: loss=-0.1898 
[epoch 35] step 14/44: loss=-0.1901 
[epoch 35] step 16/44: loss=-0.1898 
[epoch 35] step 18/44: loss=-0.1887 
[epoch 35] step 20/44: loss=-0.1880 
[epoch 35] step 22/44: loss=-0.1881 
[epoch 35] step 24/44: loss=-0.1878 
[epoch 35] step 26/44: loss=-0.1879 
[epoch 35] step 28/44: loss=-0.1881 
[epoch 35] step 30/44: loss=-0.1883 
[epoch 35] step 32/44: loss=-0.1878 
[epoch 35] step 34/44: loss=-0.1879 
[epoch 35] step 36/44: loss=-0.1881 
[epoch 35] step 38/44: loss=-0.1883 
[epoch 35] step 40/44: loss=-0.1884 
[epoch 35] step 42/44: loss=-0.1876 
[epoch 35] step 44/44: loss=-0.1878 
[epoch 35] train_loss(avg per step)=-0.3756 lambda[min,max]=[0.500986,1.000000]
[epoch 35] val_loss=1.1745 qwk=('0.4896', '0.4797', '0.5372') averageQWK=0.5021 macroEMD=0.1974 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    5   28    7    0
     0    3   87   38    0
     0    0   47   75    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    7   32    9    0
     0    3   77   33    0
     0    1   49   98    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   27   43    1    0
     0   13  122   16    0
     0    1   48   50    0
     0    0    1    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-0-conf_gating-0-reassignment-0/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-0-conf_gating-0-reassignment-0/fold3/metrics.json
Done.
