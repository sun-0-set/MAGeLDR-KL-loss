[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.9034 
[epoch 1] step 4/44: loss=0.8899 
[epoch 1] step 6/44: loss=0.8837 
[epoch 1] step 8/44: loss=0.8848 
[epoch 1] step 10/44: loss=0.8886 
[epoch 1] step 12/44: loss=0.8847 
[epoch 1] step 14/44: loss=0.8854 
[epoch 1] step 16/44: loss=0.8860 
[epoch 1] step 18/44: loss=0.8860 
[epoch 1] step 20/44: loss=0.8854 
[epoch 1] step 22/44: loss=0.8858 
[epoch 1] step 24/44: loss=0.8860 
[epoch 1] step 26/44: loss=0.8850 
[epoch 1] step 28/44: loss=0.8844 
[epoch 1] step 30/44: loss=0.8840 
[epoch 1] step 32/44: loss=0.8823 
[epoch 1] step 34/44: loss=0.8805 
[epoch 1] step 36/44: loss=0.8785 
[epoch 1] step 38/44: loss=0.8749 
[epoch 1] step 40/44: loss=0.8714 
[epoch 1] step 42/44: loss=0.8673 
[epoch 1] step 44/44: loss=0.8613 
[epoch 1] train_loss(avg per step)=1.7226 lambda[min,max]=[0.890848,1.000000]
[epoch 1] val_loss=1.3697 qwk=('0.0682', '0.1362', '0.1010') averageQWK=0.1018 macroEMD=0.3632 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    9    0
     0    3    0   38    0
     0    9    0  113    0
     0    4    0  137    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    0    0
     1    0   36    2    0
     2    0   95    7    0
     2    0  134   27    0
     0    0    9    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   19   33    0    0
     0   26  132    0    0
     0   22   88    0    0
     0    1    2    0    0
[epoch 2] step 2/44: loss=0.7413 
[epoch 2] step 4/44: loss=0.7202 
[epoch 2] step 6/44: loss=0.7138 
[epoch 2] step 8/44: loss=0.6969 
[epoch 2] step 10/44: loss=0.6859 
[epoch 2] step 12/44: loss=0.6809 
[epoch 2] step 14/44: loss=0.6773 
[epoch 2] step 16/44: loss=0.6704 
[epoch 2] step 18/44: loss=0.6662 
[epoch 2] step 20/44: loss=0.6612 
[epoch 2] step 22/44: loss=0.6595 
[epoch 2] step 24/44: loss=0.6574 
[epoch 2] step 26/44: loss=0.6550 
[epoch 2] step 28/44: loss=0.6528 
[epoch 2] step 30/44: loss=0.6525 
[epoch 2] step 32/44: loss=0.6498 
[epoch 2] step 34/44: loss=0.6465 
[epoch 2] step 36/44: loss=0.6437 
[epoch 2] step 38/44: loss=0.6417 
[epoch 2] step 40/44: loss=0.6381 
[epoch 2] step 42/44: loss=0.6345 
[epoch 2] step 44/44: loss=0.6288 
[epoch 2] train_loss(avg per step)=1.2576 lambda[min,max]=[0.837183,1.000000]
[epoch 2] val_loss=1.0992 qwk=('0.4498', '0.3755', '0.0068') averageQWK=0.2774 macroEMD=0.3113 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    1    0
     0    0   35    6    0
     0    0   67   55    0
     0    0   19  122    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    0    0
     0    0   38    1    0
     0    0   95    9    0
     0    0   82   81    0
     0    0    4   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    0   52    0    0
     0    0  157    1    0
     0    0  109    1    0
     0    0    3    0    0
[epoch 3] step 2/44: loss=0.5393 
[epoch 3] step 4/44: loss=0.5474 
[epoch 3] step 6/44: loss=0.5536 
[epoch 3] step 8/44: loss=0.5472 
[epoch 3] step 10/44: loss=0.5458 
[epoch 3] step 12/44: loss=0.5412 
[epoch 3] step 14/44: loss=0.5424 
[epoch 3] step 16/44: loss=0.5389 
[epoch 3] step 18/44: loss=0.5399 
[epoch 3] step 20/44: loss=0.5357 
[epoch 3] step 22/44: loss=0.5337 
[epoch 3] step 24/44: loss=0.5308 
[epoch 3] step 26/44: loss=0.5278 
[epoch 3] step 28/44: loss=0.5235 
[epoch 3] step 30/44: loss=0.5239 
[epoch 3] step 32/44: loss=0.5213 
[epoch 3] step 34/44: loss=0.5137 
[epoch 3] step 36/44: loss=0.5101 
[epoch 3] step 38/44: loss=0.5035 
[epoch 3] step 40/44: loss=0.5034 
[epoch 3] step 42/44: loss=0.5016 
[epoch 3] step 44/44: loss=0.4961 
[epoch 3] train_loss(avg per step)=0.9923 lambda[min,max]=[0.688475,1.000000]
[epoch 3] val_loss=0.9450 qwk=('0.3687', '0.3920', '0.3791') averageQWK=0.3799 macroEMD=0.2651 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    2    0
     0    0   30   11    0
     0    0   47   75    0
     0    0   11  130    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    2    0
     0    0   27   12    0
     0    0   44   60    0
     0    0   13  150    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    3   35   14    0
     0    4   69   85    0
     0    0   11   99    0
     0    0    0    3    0
[epoch 4] step 2/44: loss=0.4142 
[epoch 4] step 4/44: loss=0.4117 
[epoch 4] step 6/44: loss=0.4234 
[epoch 4] step 8/44: loss=0.4357 
[epoch 4] step 10/44: loss=0.4273 
[epoch 4] step 12/44: loss=0.4276 
[epoch 4] step 14/44: loss=0.4372 
[epoch 4] step 16/44: loss=0.4311 
[epoch 4] step 18/44: loss=0.4259 
[epoch 4] step 20/44: loss=0.4296 
[epoch 4] step 22/44: loss=0.4352 
[epoch 4] step 24/44: loss=0.4379 
[epoch 4] step 26/44: loss=0.4379 
[epoch 4] step 28/44: loss=0.4372 
[epoch 4] step 30/44: loss=0.4372 
[epoch 4] step 32/44: loss=0.4354 
[epoch 4] step 34/44: loss=0.4335 
[epoch 4] step 36/44: loss=0.4328 
[epoch 4] step 38/44: loss=0.4344 
[epoch 4] step 40/44: loss=0.4395 
[epoch 4] step 42/44: loss=0.4369 
[epoch 4] step 44/44: loss=0.4370 
[epoch 4] train_loss(avg per step)=0.8740 lambda[min,max]=[0.614542,1.000000]
[epoch 4] val_loss=0.9612 qwk=('0.4320', '0.5316', '0.3036') averageQWK=0.4224 macroEMD=0.2490 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    9   31    1    0
     0    3   96   23    0
     0    0   67   74    0
     0    0    6   15    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    1    0
     0    9   29    1    0
     0   18   62   24    0
     0    4   44  115    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   45    6    0
     0    2  122   34    0
     0    0   54   56    0
     0    0    1    2    0
[epoch 5] step 2/44: loss=0.3388 
[epoch 5] step 4/44: loss=0.3749 
[epoch 5] step 6/44: loss=0.3809 
[epoch 5] step 8/44: loss=0.4003 
[epoch 5] step 10/44: loss=0.3958 
[epoch 5] step 12/44: loss=0.3912 
[epoch 5] step 14/44: loss=0.3915 
[epoch 5] step 16/44: loss=0.3953 
[epoch 5] step 18/44: loss=0.3903 
[epoch 5] step 20/44: loss=0.3861 
[epoch 5] step 22/44: loss=0.3855 
[epoch 5] step 24/44: loss=0.3836 
[epoch 5] step 26/44: loss=0.3817 
[epoch 5] step 28/44: loss=0.3836 
[epoch 5] step 30/44: loss=0.3891 
[epoch 5] step 32/44: loss=0.3880 
[epoch 5] step 34/44: loss=0.3821 
[epoch 5] step 36/44: loss=0.3833 
[epoch 5] step 38/44: loss=0.3835 
[epoch 5] step 40/44: loss=0.3836 
[epoch 5] step 42/44: loss=0.3841 
[epoch 5] step 44/44: loss=0.3829 
[epoch 5] train_loss(avg per step)=0.7657 lambda[min,max]=[0.591817,1.000000]
[epoch 5] val_loss=0.9198 qwk=('0.4766', '0.3851', '0.4173') averageQWK=0.4263 macroEMD=0.2558 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    2    0
     0   13   18   10    0
     0    7   49   66    0
     0    0   20  121    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    1   26   12    0
     0    0   51   53    0
     0    0   26  137    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   45    6    0
     0    4   96   58    0
     0    0   23   87    0
     0    0    0    3    0
[epoch 6] step 2/44: loss=0.3558 
[epoch 6] step 4/44: loss=0.3476 
[epoch 6] step 6/44: loss=0.3589 
[epoch 6] step 8/44: loss=0.3534 
[epoch 6] step 10/44: loss=0.3581 
[epoch 6] step 12/44: loss=0.3665 
[epoch 6] step 14/44: loss=0.3678 
[epoch 6] step 16/44: loss=0.3592 
[epoch 6] step 18/44: loss=0.3534 
[epoch 6] step 20/44: loss=0.3536 
[epoch 6] step 22/44: loss=0.3569 
[epoch 6] step 24/44: loss=0.3509 
[epoch 6] step 26/44: loss=0.3466 
[epoch 6] step 28/44: loss=0.3465 
[epoch 6] step 30/44: loss=0.3420 
[epoch 6] step 32/44: loss=0.3424 
[epoch 6] step 34/44: loss=0.3427 
[epoch 6] step 36/44: loss=0.3441 
[epoch 6] step 38/44: loss=0.3447 
[epoch 6] step 40/44: loss=0.3452 
[epoch 6] step 42/44: loss=0.3450 
[epoch 6] step 44/44: loss=0.3413 
[epoch 6] train_loss(avg per step)=0.6826 lambda[min,max]=[0.560883,1.000000]
[epoch 6] val_loss=0.9791 qwk=('0.4778', '0.4153', '0.3854') averageQWK=0.4262 macroEMD=0.2485 tailR0=('0.0476', '0.0000', '0.0000') tailR0avg=0.0159
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    2    0
     0   11   20   10    0
     0    6   44   72    0
     0    0   15  126    0
     0    0    0   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    5   23   11    0
     0    9   32   63    0
     0    1   15  147    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    3   37   12    0
     0    8   59   91    0
     0    1   10   99    0
     0    0    0    3    0
[epoch 7] step 2/44: loss=0.3012 
[epoch 7] step 4/44: loss=0.3071 
[epoch 7] step 6/44: loss=0.2939 
[epoch 7] step 8/44: loss=0.2899 
[epoch 7] step 10/44: loss=0.2975 
[epoch 7] step 12/44: loss=0.2944 
[epoch 7] step 14/44: loss=0.2948 
[epoch 7] step 16/44: loss=0.2950 
[epoch 7] step 18/44: loss=0.2940 
[epoch 7] step 20/44: loss=0.3016 
[epoch 7] step 22/44: loss=0.2979 
[epoch 7] step 24/44: loss=0.3000 
[epoch 7] step 26/44: loss=0.3043 
[epoch 7] step 28/44: loss=0.3012 
[epoch 7] step 30/44: loss=0.3026 
[epoch 7] step 32/44: loss=0.3005 
[epoch 7] step 34/44: loss=0.3019 
[epoch 7] step 36/44: loss=0.3015 
[epoch 7] step 38/44: loss=0.3005 
[epoch 7] step 40/44: loss=0.3004 
[epoch 7] step 42/44: loss=0.2991 
[epoch 7] step 44/44: loss=0.3035 
[epoch 7] train_loss(avg per step)=0.6070 lambda[min,max]=[0.537774,1.000000]
[epoch 7] val_loss=0.9816 qwk=('0.4524', '0.4199', '0.4039') averageQWK=0.4254 macroEMD=0.2524 tailR0=('0.0476', '0.0000', '0.0000') tailR0avg=0.0159
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    2    0
     0    9   22   10    0
     0    3   49   70    0
     0    0   19  121    1
     0    0    0   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     0    6   19   14    0
     0   10   34   60    0
     0    1   17  145    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    1    0
     0   10   30   12    0
     0   15   60   83    0
     0    3   12   95    0
     0    0    0    3    0
[epoch 8] step 2/44: loss=0.2164 
[epoch 8] step 4/44: loss=0.2190 
[epoch 8] step 6/44: loss=0.2351 
[epoch 8] step 8/44: loss=0.2312 
[epoch 8] step 10/44: loss=0.2324 
[epoch 8] step 12/44: loss=0.2401 
[epoch 8] step 14/44: loss=0.2452 
[epoch 8] step 16/44: loss=0.2484 
[epoch 8] step 18/44: loss=0.2506 
[epoch 8] step 20/44: loss=0.2508 
[epoch 8] step 22/44: loss=0.2517 
[epoch 8] step 24/44: loss=0.2538 
[epoch 8] step 26/44: loss=0.2573 
[epoch 8] step 28/44: loss=0.2557 
[epoch 8] step 30/44: loss=0.2556 
[epoch 8] step 32/44: loss=0.2581 
[epoch 8] step 34/44: loss=0.2605 
[epoch 8] step 36/44: loss=0.2602 
[epoch 8] step 38/44: loss=0.2597 
[epoch 8] step 40/44: loss=0.2589 
[epoch 8] step 42/44: loss=0.2594 
[epoch 8] step 44/44: loss=0.2621 
[epoch 8] train_loss(avg per step)=0.5242 lambda[min,max]=[0.519013,1.000000]
[epoch 8] val_loss=0.9454 qwk=('0.4773', '0.4649', '0.5056') averageQWK=0.4826 macroEMD=0.2378 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    2    0
     0   10   22    9    0
     0   13   48   61    0
     0    1   17  123    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     0    7   23    9    0
     0   16   37   51    0
     0    1   22  140    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   14   32    6    0
     0   23   78   57    0
     0    3   16   91    0
     0    0    0    3    0
[epoch 9] step 2/44: loss=0.2498 
[epoch 9] step 4/44: loss=0.2117 
[epoch 9] step 6/44: loss=0.1926 
[epoch 9] step 8/44: loss=0.2126 
[epoch 9] step 10/44: loss=0.2127 
[epoch 9] step 12/44: loss=0.2062 
[epoch 9] step 14/44: loss=0.2117 
[epoch 9] step 16/44: loss=0.2152 
[epoch 9] step 18/44: loss=0.2173 
[epoch 9] step 20/44: loss=0.2139 
[epoch 9] step 22/44: loss=0.2113 
[epoch 9] step 24/44: loss=0.2112 
[epoch 9] step 26/44: loss=0.2099 
[epoch 9] step 28/44: loss=0.2123 
[epoch 9] step 30/44: loss=0.2109 
[epoch 9] step 32/44: loss=0.2115 
[epoch 9] step 34/44: loss=0.2076 
[epoch 9] step 36/44: loss=0.2072 
[epoch 9] step 38/44: loss=0.2082 
[epoch 9] step 40/44: loss=0.2096 
[epoch 9] step 42/44: loss=0.2120 
[epoch 9] step 44/44: loss=0.2112 
[epoch 9] train_loss(avg per step)=0.4223 lambda[min,max]=[0.512230,1.000000]
[epoch 9] val_loss=0.9640 qwk=('0.5166', '0.4364', '0.4779') averageQWK=0.4770 macroEMD=0.2385 tailR0=('0.1667', '0.0000', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0   11   24    6    0
     0   10   66   42    4
     0    1   29  103    8
     0    0    1   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    7   23    9    0
     0   13   40   51    0
     0    1   29  133    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   15   32    5    0
     0   21   85   52    0
     0    3   27   80    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=0.1783 
[epoch 10] step 4/44: loss=0.1895 
[epoch 10] step 6/44: loss=0.1842 
[epoch 10] step 8/44: loss=0.2023 
[epoch 10] step 10/44: loss=0.1989 
[epoch 10] step 12/44: loss=0.1916 
[epoch 10] step 14/44: loss=0.1918 
[epoch 10] step 16/44: loss=0.1966 
[epoch 10] step 18/44: loss=0.1996 
[epoch 10] step 20/44: loss=0.1960 
[epoch 10] step 22/44: loss=0.1902 
[epoch 10] step 24/44: loss=0.1851 
[epoch 10] step 26/44: loss=0.1825 
[epoch 10] step 28/44: loss=0.1806 
[epoch 10] step 30/44: loss=0.1782 
[epoch 10] step 32/44: loss=0.1776 
[epoch 10] step 34/44: loss=0.1756 
[epoch 10] step 36/44: loss=0.1760 
[epoch 10] step 38/44: loss=0.1751 
[epoch 10] step 40/44: loss=0.1725 
[epoch 10] step 42/44: loss=0.1715 
[epoch 10] step 44/44: loss=0.1690 
[epoch 10] train_loss(avg per step)=0.3381 lambda[min,max]=[0.509791,1.000000]
[epoch 10] val_loss=0.9405 qwk=('0.5107', '0.4680', '0.4773') averageQWK=0.4853 macroEMD=0.2304 tailR0=('0.0476', '0.0000', '0.0000') tailR0avg=0.0159
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     0   15   23    3    0
     0   23   52   47    0
     0    8   26  106    1
     0    0    1   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    2    0
     0   10   23    6    0
     0   19   36   49    0
     0    8   24  131    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   19   31    2    0
     0   28   99   31    0
     0    5   42   63    0
     0    0    0    3    0
[epoch 11] step 2/44: loss=0.2275 
[epoch 11] step 4/44: loss=0.1991 
[epoch 11] step 6/44: loss=0.1748 
[epoch 11] step 8/44: loss=0.1733 
[epoch 11] step 10/44: loss=0.1662 
[epoch 11] step 12/44: loss=0.1602 
[epoch 11] step 14/44: loss=0.1604 
[epoch 11] step 16/44: loss=0.1622 
[epoch 11] step 18/44: loss=0.1609 
[epoch 11] step 20/44: loss=0.1566 
[epoch 11] step 22/44: loss=0.1556 
[epoch 11] step 24/44: loss=0.1558 
[epoch 11] step 26/44: loss=0.1545 
[epoch 11] step 28/44: loss=0.1536 
[epoch 11] step 30/44: loss=0.1542 
[epoch 11] step 32/44: loss=0.1527 
[epoch 11] step 34/44: loss=0.1531 
[epoch 11] step 36/44: loss=0.1517 
[epoch 11] step 38/44: loss=0.1508 
[epoch 11] step 40/44: loss=0.1490 
[epoch 11] step 42/44: loss=0.1476 
[epoch 11] step 44/44: loss=0.1418 
[epoch 11] train_loss(avg per step)=0.2836 lambda[min,max]=[0.507473,1.000000]
[epoch 11] val_loss=0.9704 qwk=('0.4617', '0.4018', '0.3878') averageQWK=0.4171 macroEMD=0.2468 tailR0=('0.0714', '0.0625', '0.0000') tailR0avg=0.0446
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    9   23    9    0
     0    5   59   58    0
     0    0   26  112    3
     0    0    0   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    3   30    6    0
     0    5   62   37    0
     0    1   48  113    1
     0    0    2   12    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    0   50    2    0
     0    6  104   48    0
     0    0   39   71    0
     0    0    0    3    0
[epoch 12] step 2/44: loss=0.1072 
[epoch 12] step 4/44: loss=0.1423 
[epoch 12] step 6/44: loss=0.1369 
[epoch 12] step 8/44: loss=0.1409 
[epoch 12] step 10/44: loss=0.1356 
[epoch 12] step 12/44: loss=0.1238 
[epoch 12] step 14/44: loss=0.1208 
[epoch 12] step 16/44: loss=0.1183 
[epoch 12] step 18/44: loss=0.1192 
[epoch 12] step 20/44: loss=0.1179 
[epoch 12] step 22/44: loss=0.1182 
[epoch 12] step 24/44: loss=0.1143 
[epoch 12] step 26/44: loss=0.1138 
[epoch 12] step 28/44: loss=0.1174 
[epoch 12] step 30/44: loss=0.1173 
[epoch 12] step 32/44: loss=0.1154 
[epoch 12] step 34/44: loss=0.1163 
[epoch 12] step 36/44: loss=0.1136 
[epoch 12] step 38/44: loss=0.1146 
[epoch 12] step 40/44: loss=0.1138 
[epoch 12] step 42/44: loss=0.1137 
[epoch 12] step 44/44: loss=0.1085 
[epoch 12] train_loss(avg per step)=0.2170 lambda[min,max]=[0.503850,1.000000]
[epoch 12] val_loss=0.9872 qwk=('0.4516', '0.3970', '0.4563') averageQWK=0.4350 macroEMD=0.2421 tailR0=('0.0714', '0.0312', '0.0000') tailR0avg=0.0342
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    8   24    9    0
     0    2   59   61    0
     0    0   23  115    3
     0    0    1   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    3   27    9    0
     0    5   51   48    0
     0    0   34  129    0
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    8   42    2    0
     0   14  108   36    0
     0    1   41   68    0
     0    0    0    3    0
[epoch 13] step 2/44: loss=0.1192 
[epoch 13] step 4/44: loss=0.1021 
[epoch 13] step 6/44: loss=0.0970 
[epoch 13] step 8/44: loss=0.0993 
[epoch 13] step 10/44: loss=0.0948 
[epoch 13] step 12/44: loss=0.0857 
[epoch 13] step 14/44: loss=0.0848 
[epoch 13] step 16/44: loss=0.0918 
[epoch 13] step 18/44: loss=0.0857 
[epoch 13] step 20/44: loss=0.0848 
[epoch 13] step 22/44: loss=0.0846 
[epoch 13] step 24/44: loss=0.0847 
[epoch 13] step 26/44: loss=0.0880 
[epoch 13] step 28/44: loss=0.0865 
[epoch 13] step 30/44: loss=0.0845 
[epoch 13] step 32/44: loss=0.0844 
[epoch 13] step 34/44: loss=0.0838 
[epoch 13] step 36/44: loss=0.0836 
[epoch 13] step 38/44: loss=0.0822 
[epoch 13] step 40/44: loss=0.0814 
[epoch 13] step 42/44: loss=0.0818 
[epoch 13] step 44/44: loss=0.0789 
[epoch 13] train_loss(avg per step)=0.1579 lambda[min,max]=[0.503888,1.000000]
[epoch 13] val_loss=1.0087 qwk=('0.4565', '0.3883', '0.4286') averageQWK=0.4245 macroEMD=0.2418 tailR0=('0.1667', '0.0312', '0.0000') tailR0avg=0.0660
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    8   24    9    0
     0    5   47   68    2
     0    0   21  108   12
     0    0    1   13    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    4   22   13    0
     0    8   41   55    0
     0    1   23  139    0
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    7   41    4    0
     0   12  106   40    0
     0    2   39   69    0
     0    0    0    3    0
[epoch 14] step 2/44: loss=0.0476 
[epoch 14] step 4/44: loss=0.0598 
[epoch 14] step 6/44: loss=0.0517 
[epoch 14] step 8/44: loss=0.0535 
[epoch 14] step 10/44: loss=0.0510 
[epoch 14] step 12/44: loss=0.0554 
[epoch 14] step 14/44: loss=0.0549 
[epoch 14] step 16/44: loss=0.0545 
[epoch 14] step 18/44: loss=0.0533 
[epoch 14] step 20/44: loss=0.0497 
[epoch 14] step 22/44: loss=0.0473 
[epoch 14] step 24/44: loss=0.0470 
[epoch 14] step 26/44: loss=0.0479 
[epoch 14] step 28/44: loss=0.0493 
[epoch 14] step 30/44: loss=0.0494 
[epoch 14] step 32/44: loss=0.0517 
[epoch 14] step 34/44: loss=0.0516 
[epoch 14] step 36/44: loss=0.0510 
[epoch 14] step 38/44: loss=0.0495 
[epoch 14] step 40/44: loss=0.0486 
[epoch 14] step 42/44: loss=0.0484 
[epoch 14] step 44/44: loss=0.0479 
[epoch 14] train_loss(avg per step)=0.0959 lambda[min,max]=[0.502589,1.000000]
[epoch 14] val_loss=1.0099 qwk=('0.5033', '0.4213', '0.4858') averageQWK=0.4702 macroEMD=0.2341 tailR0=('0.0476', '0.0938', '0.0000') tailR0avg=0.0471
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    2    0
     0   12   21    8    0
     0   12   49   61    0
     0    0   21  118    2
     0    0    1   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    2    0
     0    5   24   10    0
     0    9   43   52    0
     0    2   29  131    1
     0    0    1   12    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   15   31    6    0
     0   21   86   51    0
     0    3   26   81    0
     0    0    0    3    0
[epoch 15] step 2/44: loss=0.0253 
[epoch 15] step 4/44: loss=0.0240 
[epoch 15] step 6/44: loss=0.0186 
[epoch 15] step 8/44: loss=0.0287 
[epoch 15] step 10/44: loss=0.0336 
[epoch 15] step 12/44: loss=0.0339 
[epoch 15] step 14/44: loss=0.0381 
[epoch 15] step 16/44: loss=0.0347 
[epoch 15] step 18/44: loss=0.0344 
[epoch 15] step 20/44: loss=0.0313 
[epoch 15] step 22/44: loss=0.0350 
[epoch 15] step 24/44: loss=0.0337 
[epoch 15] step 26/44: loss=0.0312 
[epoch 15] step 28/44: loss=0.0292 
[epoch 15] step 30/44: loss=0.0270 
[epoch 15] step 32/44: loss=0.0256 
[epoch 15] step 34/44: loss=0.0266 
[epoch 15] step 36/44: loss=0.0255 
[epoch 15] step 38/44: loss=0.0252 
[epoch 15] step 40/44: loss=0.0249 
[epoch 15] step 42/44: loss=0.0226 
[epoch 15] step 44/44: loss=0.0175 
[epoch 15] train_loss(avg per step)=0.0350 lambda[min,max]=[0.502715,1.000000]
[epoch 15] val_loss=0.9930 qwk=('0.4701', '0.4193', '0.4552') averageQWK=0.4482 macroEMD=0.2335 tailR0=('0.0714', '0.0312', '0.0000') tailR0avg=0.0342
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0   10   27    4    0
     0    5   83   34    0
     0    0   51   88    2
     0    0    3   15    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    6   22   11    0
     0   10   42   52    0
     0    1   31  131    0
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   17   33    2    0
     0   29  104   25    0
     0    6   45   59    0
     0    0    0    3    0
[epoch 16] step 2/44: loss=0.0251 
[epoch 16] step 4/44: loss=0.0263 
[epoch 16] step 6/44: loss=0.0236 
[epoch 16] step 8/44: loss=0.0150 
[epoch 16] step 10/44: loss=0.0072 
[epoch 16] step 12/44: loss=0.0117 
[epoch 16] step 14/44: loss=0.0140 
[epoch 16] step 16/44: loss=0.0164 
[epoch 16] step 18/44: loss=0.0120 
[epoch 16] step 20/44: loss=0.0119 
[epoch 16] step 22/44: loss=0.0156 
[epoch 16] step 24/44: loss=0.0095 
[epoch 16] step 26/44: loss=0.0076 
[epoch 16] step 28/44: loss=0.0035 
[epoch 16] step 30/44: loss=0.0039 
[epoch 16] step 32/44: loss=0.0029 
[epoch 16] step 34/44: loss=0.0028 
[epoch 16] step 36/44: loss=-0.0003 
[epoch 16] step 38/44: loss=-0.0017 
[epoch 16] step 40/44: loss=-0.0021 
[epoch 16] step 42/44: loss=-0.0017 
[epoch 16] step 44/44: loss=-0.0048 
[epoch 16] train_loss(avg per step)=-0.0097 lambda[min,max]=[0.502830,1.000000]
[epoch 16] val_loss=1.0159 qwk=('0.5164', '0.4231', '0.4744') averageQWK=0.4713 macroEMD=0.2323 tailR0=('0.1690', '0.0938', '0.0000') tailR0avg=0.0876
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    1    0
     0   10   25    6    0
     0    6   67   49    0
     0    0   31  106    4
     0    0    2   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    5   20   14    0
     0   11   38   55    0
     0    0   28  133    2
     0    0    0   13    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   13   35    4    0
     0   23   98   37    0
     0    3   36   71    0
     0    0    0    3    0
[epoch 17] step 2/44: loss=-0.0490 
[epoch 17] step 4/44: loss=-0.0393 
[epoch 17] step 6/44: loss=-0.0334 
[epoch 17] step 8/44: loss=-0.0265 
[epoch 17] step 10/44: loss=-0.0254 
[epoch 17] step 12/44: loss=-0.0184 
[epoch 17] step 14/44: loss=-0.0226 
[epoch 17] step 16/44: loss=-0.0220 
[epoch 17] step 18/44: loss=-0.0239 
[epoch 17] step 20/44: loss=-0.0262 
[epoch 17] step 22/44: loss=-0.0270 
[epoch 17] step 24/44: loss=-0.0288 
[epoch 17] step 26/44: loss=-0.0312 
[epoch 17] step 28/44: loss=-0.0334 
[epoch 17] step 30/44: loss=-0.0362 
[epoch 17] step 32/44: loss=-0.0350 
[epoch 17] step 34/44: loss=-0.0358 
[epoch 17] step 36/44: loss=-0.0364 
[epoch 17] step 38/44: loss=-0.0371 
[epoch 17] step 40/44: loss=-0.0383 
[epoch 17] step 42/44: loss=-0.0376 
[epoch 17] step 44/44: loss=-0.0374 
[epoch 17] train_loss(avg per step)=-0.0748 lambda[min,max]=[0.501993,1.000000]
[epoch 17] val_loss=1.0755 qwk=('0.5201', '0.4848', '0.4277') averageQWK=0.4775 macroEMD=0.2274 tailR0=('0.1190', '0.1562', '0.0000') tailR0avg=0.0918
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0   12   25    4    0
     0    7   72   43    0
     0    0   40   97    4
     0    0    2   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    2    0
     0    9   27    3    0
     0   14   58   32    0
     0    0   62   97    4
     0    0    4    7    5
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    3   47    2    0
     0    7  117   34    0
     0    0   44   66    0
     0    0    0    3    0
[epoch 18] step 2/44: loss=-0.0163 
[epoch 18] step 4/44: loss=-0.0249 
[epoch 18] step 6/44: loss=-0.0321 
[epoch 18] step 8/44: loss=-0.0381 
[epoch 18] step 10/44: loss=-0.0360 
[epoch 18] step 12/44: loss=-0.0354 
[epoch 18] step 14/44: loss=-0.0413 
[epoch 18] step 16/44: loss=-0.0418 
[epoch 18] step 18/44: loss=-0.0422 
[epoch 18] step 20/44: loss=-0.0447 
[epoch 18] step 22/44: loss=-0.0459 
[epoch 18] step 24/44: loss=-0.0459 
[epoch 18] step 26/44: loss=-0.0458 
[epoch 18] step 28/44: loss=-0.0485 
[epoch 18] step 30/44: loss=-0.0496 
[epoch 18] step 32/44: loss=-0.0517 
[epoch 18] step 34/44: loss=-0.0540 
[epoch 18] step 36/44: loss=-0.0540 
[epoch 18] step 38/44: loss=-0.0552 
[epoch 18] step 40/44: loss=-0.0547 
[epoch 18] step 42/44: loss=-0.0559 
[epoch 18] step 44/44: loss=-0.0560 
[epoch 18] train_loss(avg per step)=-0.1119 lambda[min,max]=[0.502010,1.000000]
[epoch 18] val_loss=1.1150 qwk=('0.4559', '0.4104', '0.4699') averageQWK=0.4454 macroEMD=0.2395 tailR0=('0.1429', '0.1875', '0.0000') tailR0avg=0.1101
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    7   25    9    0
     0    2   58   61    1
     0    0   24  111    6
     0    0    1   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    6   14   19    0
     0   10   32   62    0
     0    0   19  139    5
     0    0    0   10    6
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    9   40    3    0
     0   16  100   42    0
     0    1   34   75    0
     0    0    0    3    0
[epoch 19] step 2/44: loss=-0.0927 
[epoch 19] step 4/44: loss=-0.0921 
[epoch 19] step 6/44: loss=-0.0812 
[epoch 19] step 8/44: loss=-0.0750 
[epoch 19] step 10/44: loss=-0.0718 
[epoch 19] step 12/44: loss=-0.0707 
[epoch 19] step 14/44: loss=-0.0689 
[epoch 19] step 16/44: loss=-0.0736 
[epoch 19] step 18/44: loss=-0.0774 
[epoch 19] step 20/44: loss=-0.0762 
[epoch 19] step 22/44: loss=-0.0788 
[epoch 19] step 24/44: loss=-0.0783 
[epoch 19] step 26/44: loss=-0.0772 
[epoch 19] step 28/44: loss=-0.0776 
[epoch 19] step 30/44: loss=-0.0787 
[epoch 19] step 32/44: loss=-0.0804 
[epoch 19] step 34/44: loss=-0.0809 
[epoch 19] step 36/44: loss=-0.0809 
[epoch 19] step 38/44: loss=-0.0793 
[epoch 19] step 40/44: loss=-0.0782 
[epoch 19] step 42/44: loss=-0.0789 
[epoch 19] step 44/44: loss=-0.0798 
[epoch 19] train_loss(avg per step)=-0.1595 lambda[min,max]=[0.501746,1.000000]
[epoch 19] val_loss=1.1264 qwk=('0.4886', '0.4147', '0.4382') averageQWK=0.4472 macroEMD=0.2402 tailR0=('0.1429', '0.1562', '0.0000') tailR0avg=0.0997
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    9   27    5    0
     0    5   67   49    1
     0    0   36   98    7
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    6   21   12    0
     0   10   42   50    2
     0    0   35  123    5
     0    0    1   10    5
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    5   43    4    0
     0    9  104   45    0
     0    1   33   76    0
     0    0    0    3    0
[epoch 20] step 2/44: loss=-0.1104 
[epoch 20] step 4/44: loss=-0.1160 
[epoch 20] step 6/44: loss=-0.1106 
[epoch 20] step 8/44: loss=-0.1045 
[epoch 20] step 10/44: loss=-0.1061 
[epoch 20] step 12/44: loss=-0.1039 
[epoch 20] step 14/44: loss=-0.1024 
[epoch 20] step 16/44: loss=-0.1032 
[epoch 20] step 18/44: loss=-0.1051 
[epoch 20] step 20/44: loss=-0.1032 
[epoch 20] step 22/44: loss=-0.1021 
[epoch 20] step 24/44: loss=-0.0983 
[epoch 20] step 26/44: loss=-0.1004 
[epoch 20] step 28/44: loss=-0.1009 
[epoch 20] step 30/44: loss=-0.1006 
[epoch 20] step 32/44: loss=-0.1013 
[epoch 20] step 34/44: loss=-0.1001 
[epoch 20] step 36/44: loss=-0.1003 
[epoch 20] step 38/44: loss=-0.0991 
[epoch 20] step 40/44: loss=-0.0992 
[epoch 20] step 42/44: loss=-0.0988 
[epoch 20] step 44/44: loss=-0.1004 
[epoch 20] train_loss(avg per step)=-0.2008 lambda[min,max]=[0.501307,1.000000]
[epoch 20] val_loss=1.1696 qwk=('0.4346', '0.3925', '0.4316') averageQWK=0.4196 macroEMD=0.2413 tailR0=('0.1190', '0.0938', '0.0000') tailR0avg=0.0709
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    7   25    9    0
     0    4   59   59    0
     0    0   30  107    4
     0    0    2   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    4   22   13    0
     0   10   42   52    0
     0    0   35  126    2
     0    0    1   12    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0   10   38    4    0
     0   14  112   32    0
     0    3   42   65    0
     0    0    0    3    0
[epoch 21] step 2/44: loss=-0.1409 
[epoch 21] step 4/44: loss=-0.1379 
[epoch 21] step 6/44: loss=-0.1278 
[epoch 21] step 8/44: loss=-0.1210 
[epoch 21] step 10/44: loss=-0.1137 
[epoch 21] step 12/44: loss=-0.1115 
[epoch 21] step 14/44: loss=-0.1113 
[epoch 21] step 16/44: loss=-0.1121 
[epoch 21] step 18/44: loss=-0.1099 
[epoch 21] step 20/44: loss=-0.1101 
[epoch 21] step 22/44: loss=-0.1124 
[epoch 21] step 24/44: loss=-0.1134 
[epoch 21] step 26/44: loss=-0.1143 
[epoch 21] step 28/44: loss=-0.1157 
[epoch 21] step 30/44: loss=-0.1156 
[epoch 21] step 32/44: loss=-0.1150 
[epoch 21] step 34/44: loss=-0.1157 
[epoch 21] step 36/44: loss=-0.1143 
[epoch 21] step 38/44: loss=-0.1155 
[epoch 21] step 40/44: loss=-0.1160 
[epoch 21] step 42/44: loss=-0.1169 
[epoch 21] step 44/44: loss=-0.1186 
[epoch 21] train_loss(avg per step)=-0.2373 lambda[min,max]=[0.501287,1.000000]
[epoch 21] val_loss=1.1582 qwk=('0.4470', '0.4508', '0.4729') averageQWK=0.4569 macroEMD=0.2358 tailR0=('0.1190', '0.1875', '0.0000') tailR0avg=0.1022
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0   10   21   10    0
     0    5   59   58    0
     0    0   29  108    4
     0    0    2   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     0    7   23    9    0
     0   12   45   45    2
     0    0   37  123    3
     0    0    2    8    6
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    9   39    4    0
     0   12  104   42    0
     0    1   35   74    0
     0    0    0    3    0
[epoch 22] step 2/44: loss=-0.1484 
[epoch 22] step 4/44: loss=-0.1435 
[epoch 22] step 6/44: loss=-0.1334 
[epoch 22] step 8/44: loss=-0.1301 
[epoch 22] step 10/44: loss=-0.1328 
[epoch 22] step 12/44: loss=-0.1340 
[epoch 22] step 14/44: loss=-0.1344 
[epoch 22] step 16/44: loss=-0.1352 
[epoch 22] step 18/44: loss=-0.1365 
[epoch 22] step 20/44: loss=-0.1357 
[epoch 22] step 22/44: loss=-0.1314 
[epoch 22] step 24/44: loss=-0.1325 
[epoch 22] step 26/44: loss=-0.1322 
[epoch 22] step 28/44: loss=-0.1308 
[epoch 22] step 30/44: loss=-0.1322 
[epoch 22] step 32/44: loss=-0.1327 
[epoch 22] step 34/44: loss=-0.1317 
[epoch 22] step 36/44: loss=-0.1314 
[epoch 22] step 38/44: loss=-0.1304 
[epoch 22] step 40/44: loss=-0.1298 
[epoch 22] step 42/44: loss=-0.1293 
[epoch 22] step 44/44: loss=-0.1243 
[epoch 22] train_loss(avg per step)=-0.2485 lambda[min,max]=[0.501167,1.000000]
[epoch 22] val_loss=1.1835 qwk=('0.4770', '0.4432', '0.4549') averageQWK=0.4584 macroEMD=0.2326 tailR0=('0.1452', '0.1250', '0.0000') tailR0avg=0.0901
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     0    7   33    1    0
     0    3   92   27    0
     0    0   53   85    3
     0    0    6   11    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    3    0
     0   10   18   11    0
     0   17   37   49    1
     0    3   34  123    3
     0    0    2   10    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   11   38    3    0
     1   16  108   33    0
     0    4   40   66    0
     0    0    0    3    0
[epoch 23] step 2/44: loss=-0.1266 
[epoch 23] step 4/44: loss=-0.1189 
[epoch 23] step 6/44: loss=-0.1236 
[epoch 23] step 8/44: loss=-0.1268 
[epoch 23] step 10/44: loss=-0.1267 
[epoch 23] step 12/44: loss=-0.1290 
[epoch 23] step 14/44: loss=-0.1303 
[epoch 23] step 16/44: loss=-0.1313 
[epoch 23] step 18/44: loss=-0.1344 
[epoch 23] step 20/44: loss=-0.1350 
[epoch 23] step 22/44: loss=-0.1350 
[epoch 23] step 24/44: loss=-0.1345 
[epoch 23] step 26/44: loss=-0.1330 
[epoch 23] step 28/44: loss=-0.1334 
[epoch 23] step 30/44: loss=-0.1322 
[epoch 23] step 32/44: loss=-0.1338 
[epoch 23] step 34/44: loss=-0.1343 
[epoch 23] step 36/44: loss=-0.1349 
[epoch 23] step 38/44: loss=-0.1338 
[epoch 23] step 40/44: loss=-0.1346 
[epoch 23] step 42/44: loss=-0.1341 
[epoch 23] step 44/44: loss=-0.1357 
[epoch 23] train_loss(avg per step)=-0.2714 lambda[min,max]=[0.501146,1.000000]
[epoch 23] val_loss=1.1965 qwk=('0.4833', '0.4171', '0.4571') averageQWK=0.4525 macroEMD=0.2404 tailR0=('0.1190', '0.1875', '0.0000') tailR0avg=0.1022
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   28    6    0
     0    2   65   55    0
     0    0   28  108    5
     0    0    2   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    4    0
     0    7   14   18    0
     0   13   32   58    1
     0    0   24  136    3
     0    0    0   10    6
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    9   39    4    0
     0   14  100   44    0
     0    1   35   74    0
     0    0    0    3    0
[epoch 24] step 2/44: loss=-0.1514 
[epoch 24] step 4/44: loss=-0.1544 
[epoch 24] step 6/44: loss=-0.1523 
[epoch 24] step 8/44: loss=-0.1480 
[epoch 24] step 10/44: loss=-0.1465 
[epoch 24] step 12/44: loss=-0.1461 
[epoch 24] step 14/44: loss=-0.1464 
[epoch 24] step 16/44: loss=-0.1452 
[epoch 24] step 18/44: loss=-0.1445 
[epoch 24] step 20/44: loss=-0.1411 
[epoch 24] step 22/44: loss=-0.1413 
[epoch 24] step 24/44: loss=-0.1423 
[epoch 24] step 26/44: loss=-0.1423 
[epoch 24] step 28/44: loss=-0.1442 
[epoch 24] step 30/44: loss=-0.1448 
[epoch 24] step 32/44: loss=-0.1439 
[epoch 24] step 34/44: loss=-0.1450 
[epoch 24] step 36/44: loss=-0.1447 
[epoch 24] step 38/44: loss=-0.1454 
[epoch 24] step 40/44: loss=-0.1460 
[epoch 24] step 42/44: loss=-0.1460 
[epoch 24] step 44/44: loss=-0.1475 
[epoch 24] train_loss(avg per step)=-0.2950 lambda[min,max]=[0.501369,1.000000]
[epoch 24] val_loss=1.2180 qwk=('0.4796', '0.4895', '0.4471') averageQWK=0.4721 macroEMD=0.2308 tailR0=('0.1690', '0.1875', '0.0000') tailR0avg=0.1188
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     0   11   24    6    0
     0    9   63   50    0
     0    0   36  101    4
     0    0    4   12    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    2    0
     0    8   28    3    0
     0   16   55   31    2
     0    1   56  102    4
     0    0    3    7    6
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     1   10   37    4    0
     2   16  104   36    0
     0    3   41   66    0
     0    0    0    3    0
[epoch 25] step 2/44: loss=-0.1346 
[epoch 25] step 4/44: loss=-0.1475 
[epoch 25] step 6/44: loss=-0.1508 
[epoch 25] step 8/44: loss=-0.1520 
[epoch 25] step 10/44: loss=-0.1551 
[epoch 25] step 12/44: loss=-0.1516 
[epoch 25] step 14/44: loss=-0.1492 
[epoch 25] step 16/44: loss=-0.1513 
[epoch 25] step 18/44: loss=-0.1539 
[epoch 25] step 20/44: loss=-0.1549 
[epoch 25] step 22/44: loss=-0.1548 
[epoch 25] step 24/44: loss=-0.1548 
[epoch 25] step 26/44: loss=-0.1541 
[epoch 25] step 28/44: loss=-0.1546 
[epoch 25] step 30/44: loss=-0.1544 
[epoch 25] step 32/44: loss=-0.1547 
[epoch 25] step 34/44: loss=-0.1546 
[epoch 25] step 36/44: loss=-0.1545 
[epoch 25] step 38/44: loss=-0.1550 
[epoch 25] step 40/44: loss=-0.1553 
[epoch 25] step 42/44: loss=-0.1556 
[epoch 25] step 44/44: loss=-0.1567 
[epoch 25] train_loss(avg per step)=-0.3134 lambda[min,max]=[0.501211,1.000000]
[epoch 25] val_loss=1.2345 qwk=('0.4874', '0.4589', '0.4274') averageQWK=0.4579 macroEMD=0.2347 tailR0=('0.2167', '0.1875', '0.0000') tailR0avg=0.1347
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     0    7   28    6    0
     0    2   69   49    2
     0    0   33  101    7
     0    0    2   12    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    6   24    9    0
     0   13   50   39    2
     0    0   38  120    5
     0    0    2    8    6
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    6   41    5    0
     1   12   95   50    0
     0    0   34   76    0
     0    0    0    3    0
[epoch 26] step 2/44: loss=-0.1529 
[epoch 26] step 4/44: loss=-0.1635 
[epoch 26] step 6/44: loss=-0.1642 
[epoch 26] step 8/44: loss=-0.1660 
[epoch 26] step 10/44: loss=-0.1658 
[epoch 26] step 12/44: loss=-0.1638 
[epoch 26] step 14/44: loss=-0.1623 
[epoch 26] step 16/44: loss=-0.1629 
[epoch 26] step 18/44: loss=-0.1619 
[epoch 26] step 20/44: loss=-0.1597 
[epoch 26] step 22/44: loss=-0.1606 
[epoch 26] step 24/44: loss=-0.1612 
[epoch 26] step 26/44: loss=-0.1614 
[epoch 26] step 28/44: loss=-0.1607 
[epoch 26] step 30/44: loss=-0.1598 
[epoch 26] step 32/44: loss=-0.1581 
[epoch 26] step 34/44: loss=-0.1587 
[epoch 26] step 36/44: loss=-0.1596 
[epoch 26] step 38/44: loss=-0.1587 
[epoch 26] step 40/44: loss=-0.1598 
[epoch 26] step 42/44: loss=-0.1603 
[epoch 26] step 44/44: loss=-0.1609 
[epoch 26] train_loss(avg per step)=-0.3218 lambda[min,max]=[0.501166,1.000000]
[epoch 26] val_loss=1.2091 qwk=('0.4791', '0.4336', '0.4806') averageQWK=0.4644 macroEMD=0.2339 tailR0=('0.1690', '0.1875', '0.0000') tailR0avg=0.1188
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     0   10   25    6    0
     0    3   70   48    1
     0    0   35   97    9
     0    0    4   12    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0    6   19   14    0
     0   14   37   52    1
     0    0   32  129    2
     0    0    1    9    6
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   15   33    4    0
     1   20   94   43    0
     0    4   31   75    0
     0    0    0    3    0
[epoch 27] step 2/44: loss=-0.1731 
[epoch 27] step 4/44: loss=-0.1660 
[epoch 27] step 6/44: loss=-0.1675 
[epoch 27] step 8/44: loss=-0.1692 
[epoch 27] step 10/44: loss=-0.1704 
[epoch 27] step 12/44: loss=-0.1692 
[epoch 27] step 14/44: loss=-0.1697 
[epoch 27] step 16/44: loss=-0.1690 
[epoch 27] step 18/44: loss=-0.1698 
[epoch 27] step 20/44: loss=-0.1696 
[epoch 27] step 22/44: loss=-0.1694 
[epoch 27] step 24/44: loss=-0.1688 
[epoch 27] step 26/44: loss=-0.1689 
[epoch 27] step 28/44: loss=-0.1692 
[epoch 27] step 30/44: loss=-0.1696 
[epoch 27] step 32/44: loss=-0.1698 
[epoch 27] step 34/44: loss=-0.1688 
[epoch 27] step 36/44: loss=-0.1687 
[epoch 27] step 38/44: loss=-0.1684 
[epoch 27] step 40/44: loss=-0.1679 
[epoch 27] step 42/44: loss=-0.1684 
[epoch 27] step 44/44: loss=-0.1692 
[epoch 27] train_loss(avg per step)=-0.3384 lambda[min,max]=[0.501213,1.000000]
[epoch 27] val_loss=1.2325 qwk=('0.4707', '0.4244', '0.4150') averageQWK=0.4367 macroEMD=0.2372 tailR0=('0.1690', '0.1250', '0.0000') tailR0avg=0.0980
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     0    6   28    7    0
     0    1   66   55    0
     0    0   27  107    7
     0    0    2   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0    8   16   15    0
     0   14   36   54    0
     0    0   33  129    1
     0    0    1   11    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0   10   38    4    0
     1   14  110   33    0
     0    3   42   65    0
     0    0    0    3    0
[epoch 28] step 2/44: loss=-0.1732 
[epoch 28] step 4/44: loss=-0.1772 
[epoch 28] step 6/44: loss=-0.1767 
[epoch 28] step 8/44: loss=-0.1755 
[epoch 28] step 10/44: loss=-0.1750 
[epoch 28] step 12/44: loss=-0.1744 
[epoch 28] step 14/44: loss=-0.1744 
[epoch 28] step 16/44: loss=-0.1744 
[epoch 28] step 18/44: loss=-0.1750 
[epoch 28] step 20/44: loss=-0.1747 
[epoch 28] step 22/44: loss=-0.1730 
[epoch 28] step 24/44: loss=-0.1725 
[epoch 28] step 26/44: loss=-0.1731 
[epoch 28] step 28/44: loss=-0.1738 
[epoch 28] step 30/44: loss=-0.1732 
[epoch 28] step 32/44: loss=-0.1724 
[epoch 28] step 34/44: loss=-0.1721 
[epoch 28] step 36/44: loss=-0.1725 
[epoch 28] step 38/44: loss=-0.1719 
[epoch 28] step 40/44: loss=-0.1715 
[epoch 28] step 42/44: loss=-0.1717 
[epoch 28] step 44/44: loss=-0.1717 
[epoch 28] train_loss(avg per step)=-0.3433 lambda[min,max]=[0.501183,1.000000]
[epoch 28] val_loss=1.2667 qwk=('0.4882', '0.4768', '0.4236') averageQWK=0.4629 macroEMD=0.2376 tailR0=('0.1190', '0.1875', '0.0000') tailR0avg=0.1022
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0   10   22    9    0
     0    4   60   58    0
     0    0   24  112    5
     0    0    1   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     0    6   27    6    0
     0   10   54   38    2
     0    0   39  119    5
     0    0    2    8    6
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    5   41    6    0
     1   10   91   56    0
     0    0   30   80    0
     0    0    0    3    0
[epoch 29] step 2/44: loss=-0.1646 
[epoch 29] step 4/44: loss=-0.1723 
[epoch 29] step 6/44: loss=-0.1723 
[epoch 29] step 8/44: loss=-0.1719 
[epoch 29] step 10/44: loss=-0.1727 
[epoch 29] step 12/44: loss=-0.1729 
[epoch 29] step 14/44: loss=-0.1723 
[epoch 29] step 16/44: loss=-0.1717 
[epoch 29] step 18/44: loss=-0.1726 
[epoch 29] step 20/44: loss=-0.1724 
[epoch 29] step 22/44: loss=-0.1727 
[epoch 29] step 24/44: loss=-0.1736 
[epoch 29] step 26/44: loss=-0.1746 
[epoch 29] step 28/44: loss=-0.1749 
[epoch 29] step 30/44: loss=-0.1745 
[epoch 29] step 32/44: loss=-0.1742 
[epoch 29] step 34/44: loss=-0.1738 
[epoch 29] step 36/44: loss=-0.1742 
[epoch 29] step 38/44: loss=-0.1746 
[epoch 29] step 40/44: loss=-0.1747 
[epoch 29] step 42/44: loss=-0.1742 
[epoch 29] step 44/44: loss=-0.1743 
[epoch 29] train_loss(avg per step)=-0.3487 lambda[min,max]=[0.501071,1.000000]
[epoch 29] val_loss=1.2222 qwk=('0.5243', '0.4798', '0.4790') averageQWK=0.4943 macroEMD=0.2299 tailR0=('0.1929', '0.1322', '0.1667') tailR0avg=0.1639
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     0   11   26    4    0
     0    4   72   46    0
     0    0   36  100    5
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    5    3    0
     0    8   24    7    0
     0   13   39   52    0
     0    0   32  131    0
     0    0    2   11    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   13   35    4    0
     1   20   99   38    0
     0    3   36   70    1
     0    0    0    2    1
[epoch 30] step 2/44: loss=-0.1824 
[epoch 30] step 4/44: loss=-0.1812 
[epoch 30] step 6/44: loss=-0.1802 
[epoch 30] step 8/44: loss=-0.1813 
[epoch 30] step 10/44: loss=-0.1786 
[epoch 30] step 12/44: loss=-0.1794 
[epoch 30] step 14/44: loss=-0.1783 
[epoch 30] step 16/44: loss=-0.1776 
[epoch 30] step 18/44: loss=-0.1776 
[epoch 30] step 20/44: loss=-0.1779 
[epoch 30] step 22/44: loss=-0.1773 
[epoch 30] step 24/44: loss=-0.1769 
[epoch 30] step 26/44: loss=-0.1760 
[epoch 30] step 28/44: loss=-0.1763 
[epoch 30] step 30/44: loss=-0.1763 
[epoch 30] step 32/44: loss=-0.1766 
[epoch 30] step 34/44: loss=-0.1762 
[epoch 30] step 36/44: loss=-0.1764 
[epoch 30] step 38/44: loss=-0.1755 
[epoch 30] step 40/44: loss=-0.1761 
[epoch 30] step 42/44: loss=-0.1763 
[epoch 30] step 44/44: loss=-0.1770 
[epoch 30] train_loss(avg per step)=-0.3541 lambda[min,max]=[0.501189,1.000000]
[epoch 30] val_loss=1.2333 qwk=('0.4805', '0.5124', '0.4530') averageQWK=0.4820 macroEMD=0.2289 tailR0=('0.1452', '0.1562', '0.0000') tailR0avg=0.1005
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     0   11   26    4    0
     0    4   73   45    0
     0    0   43   94    4
     0    0    4   13    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    2    0
     0    9   26    4    0
     0   14   47   43    0
     0    0   42  119    2
     0    0    2    9    5
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   10   38    4    0
     1   12  111   34    0
     0    3   38   69    0
     0    0    0    3    0
[epoch 31] step 2/44: loss=-0.1756 
[epoch 31] step 4/44: loss=-0.1790 
[epoch 31] step 6/44: loss=-0.1810 
[epoch 31] step 8/44: loss=-0.1816 
[epoch 31] step 10/44: loss=-0.1799 
[epoch 31] step 12/44: loss=-0.1791 
[epoch 31] step 14/44: loss=-0.1802 
[epoch 31] step 16/44: loss=-0.1808 
[epoch 31] step 18/44: loss=-0.1811 
[epoch 31] step 20/44: loss=-0.1812 
[epoch 31] step 22/44: loss=-0.1818 
[epoch 31] step 24/44: loss=-0.1811 
[epoch 31] step 26/44: loss=-0.1814 
[epoch 31] step 28/44: loss=-0.1817 
[epoch 31] step 30/44: loss=-0.1821 
[epoch 31] step 32/44: loss=-0.1820 
[epoch 31] step 34/44: loss=-0.1812 
[epoch 31] step 36/44: loss=-0.1812 
[epoch 31] step 38/44: loss=-0.1816 
[epoch 31] step 40/44: loss=-0.1818 
[epoch 31] step 42/44: loss=-0.1817 
[epoch 31] step 44/44: loss=-0.1820 
[epoch 31] train_loss(avg per step)=-0.3641 lambda[min,max]=[0.501075,1.000000]
[epoch 31] val_loss=1.2758 qwk=('0.4880', '0.4291', '0.4289') averageQWK=0.4487 macroEMD=0.2359 tailR0=('0.1929', '0.1875', '0.0000') tailR0avg=0.1268
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     0    9   24    8    0
     0    3   63   56    0
     0    0   31  105    5
     0    0    1   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     0    7   19   13    0
     0   12   40   52    0
     0    0   34  127    2
     0    0    2    8    6
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    7   41    4    0
     0   11   97   50    0
     0    3   30   77    0
     0    0    0    3    0
[epoch 32] step 2/44: loss=-0.1830 
[epoch 32] step 4/44: loss=-0.1835 
[epoch 32] step 6/44: loss=-0.1831 
[epoch 32] step 8/44: loss=-0.1853 
[epoch 32] step 10/44: loss=-0.1849 
[epoch 32] step 12/44: loss=-0.1856 
[epoch 32] step 14/44: loss=-0.1852 
[epoch 32] step 16/44: loss=-0.1848 
[epoch 32] step 18/44: loss=-0.1845 
[epoch 32] step 20/44: loss=-0.1844 
[epoch 32] step 22/44: loss=-0.1843 
[epoch 32] step 24/44: loss=-0.1836 
[epoch 32] step 26/44: loss=-0.1841 
[epoch 32] step 28/44: loss=-0.1844 
[epoch 32] step 30/44: loss=-0.1848 
[epoch 32] step 32/44: loss=-0.1851 
[epoch 32] step 34/44: loss=-0.1847 
[epoch 32] step 36/44: loss=-0.1847 
[epoch 32] step 38/44: loss=-0.1844 
[epoch 32] step 40/44: loss=-0.1843 
[epoch 32] step 42/44: loss=-0.1840 
[epoch 32] step 44/44: loss=-0.1839 
[epoch 32] train_loss(avg per step)=-0.3678 lambda[min,max]=[0.501055,1.000000]
[epoch 32] val_loss=1.2566 qwk=('0.4860', '0.4825', '0.4506') averageQWK=0.4730 macroEMD=0.2307 tailR0=('0.1452', '0.1875', '0.0000') tailR0avg=0.1109
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     0    9   28    4    0
     0    4   72   46    0
     0    0   37  100    4
     0    0    4   13    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0    8   26    5    0
     0   14   49   39    2
     0    0   45  115    3
     0    0    2    8    6
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   11   37    4    0
     1   16  100   41    0
     0    3   36   71    0
     0    0    0    3    0
[epoch 33] step 2/44: loss=-0.1781 
[epoch 33] step 4/44: loss=-0.1801 
[epoch 33] step 6/44: loss=-0.1818 
[epoch 33] step 8/44: loss=-0.1823 
[epoch 33] step 10/44: loss=-0.1832 
[epoch 33] step 12/44: loss=-0.1817 
[epoch 33] step 14/44: loss=-0.1812 
[epoch 33] step 16/44: loss=-0.1817 
[epoch 33] step 18/44: loss=-0.1825 
[epoch 33] step 20/44: loss=-0.1827 
[epoch 33] step 22/44: loss=-0.1824 
[epoch 33] step 24/44: loss=-0.1831 
[epoch 33] step 26/44: loss=-0.1837 
[epoch 33] step 28/44: loss=-0.1842 
[epoch 33] step 30/44: loss=-0.1843 
[epoch 33] step 32/44: loss=-0.1842 
[epoch 33] step 34/44: loss=-0.1843 
[epoch 33] step 36/44: loss=-0.1842 
[epoch 33] step 38/44: loss=-0.1845 
[epoch 33] step 40/44: loss=-0.1844 
[epoch 33] step 42/44: loss=-0.1846 
[epoch 33] step 44/44: loss=-0.1851 
[epoch 33] train_loss(avg per step)=-0.3702 lambda[min,max]=[0.501002,1.000000]
[epoch 33] val_loss=1.2689 qwk=('0.4664', '0.4443', '0.4353') averageQWK=0.4487 macroEMD=0.2342 tailR0=('0.1190', '0.1875', '0.0000') tailR0avg=0.1022
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    9   24    8    0
     0    4   62   56    0
     0    0   31  107    3
     0    0    2   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0    8   18   13    0
     0   13   39   51    1
     0    0   32  129    2
     0    0    2    8    6
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    8   40    4    0
     0   11  103   44    0
     0    3   32   75    0
     0    0    0    3    0
[epoch 34] step 2/44: loss=-0.1883 
[epoch 34] step 4/44: loss=-0.1887 
[epoch 34] step 6/44: loss=-0.1837 
[epoch 34] step 8/44: loss=-0.1843 
[epoch 34] step 10/44: loss=-0.1851 
[epoch 34] step 12/44: loss=-0.1855 
[epoch 34] step 14/44: loss=-0.1840 
[epoch 34] step 16/44: loss=-0.1849 
[epoch 34] step 18/44: loss=-0.1855 
[epoch 34] step 20/44: loss=-0.1858 
[epoch 34] step 22/44: loss=-0.1860 
[epoch 34] step 24/44: loss=-0.1864 
[epoch 34] step 26/44: loss=-0.1863 
[epoch 34] step 28/44: loss=-0.1865 
[epoch 34] step 30/44: loss=-0.1868 
[epoch 34] step 32/44: loss=-0.1866 
[epoch 34] step 34/44: loss=-0.1868 
[epoch 34] step 36/44: loss=-0.1864 
[epoch 34] step 38/44: loss=-0.1858 
[epoch 34] step 40/44: loss=-0.1859 
[epoch 34] step 42/44: loss=-0.1861 
[epoch 34] step 44/44: loss=-0.1863 
[epoch 34] train_loss(avg per step)=-0.3726 lambda[min,max]=[0.501065,1.000000]
[epoch 34] val_loss=1.2629 qwk=('0.5021', '0.4339', '0.4500') averageQWK=0.4620 macroEMD=0.2323 tailR0=('0.1690', '0.1875', '0.0000') tailR0avg=0.1188
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     0    9   28    4    0
     0    3   67   51    1
     0    0   33  101    7
     0    0    2   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0    8   18   13    0
     0   14   40   48    2
     0    0   36  125    2
     0    0    2    8    6
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    8   40    4    0
     1   14  101   42    0
     0    3   33   73    1
     0    0    0    3    0
[epoch 35] step 2/44: loss=-0.1894 
[epoch 35] step 4/44: loss=-0.1837 
[epoch 35] step 6/44: loss=-0.1846 
[epoch 35] step 8/44: loss=-0.1844 
[epoch 35] step 10/44: loss=-0.1845 
[epoch 35] step 12/44: loss=-0.1833 
[epoch 35] step 14/44: loss=-0.1845 
[epoch 35] step 16/44: loss=-0.1851 
[epoch 35] step 18/44: loss=-0.1853 
[epoch 35] step 20/44: loss=-0.1859 
[epoch 35] step 22/44: loss=-0.1864 
[epoch 35] step 24/44: loss=-0.1868 
[epoch 35] step 26/44: loss=-0.1870 
[epoch 35] step 28/44: loss=-0.1871 
[epoch 35] step 30/44: loss=-0.1873 
[epoch 35] step 32/44: loss=-0.1876 
[epoch 35] step 34/44: loss=-0.1879 
[epoch 35] step 36/44: loss=-0.1877 
[epoch 35] step 38/44: loss=-0.1878 
[epoch 35] step 40/44: loss=-0.1876 
[epoch 35] step 42/44: loss=-0.1870 
[epoch 35] step 44/44: loss=-0.1870 
[epoch 35] train_loss(avg per step)=-0.3740 lambda[min,max]=[0.500928,1.000000]
[epoch 35] val_loss=1.2625 qwk=('0.4916', '0.4781', '0.4336') averageQWK=0.4678 macroEMD=0.2319 tailR0=('0.1690', '0.1562', '0.0000') tailR0avg=0.1084
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     0    9   28    4    0
     0    3   68   51    0
     0    0   36  101    4
     0    0    3   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0    8   24    7    0
     0   14   43   47    0
     0    0   38  123    2
     0    0    2    9    5
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    8   40    4    0
     0   12  104   42    0
     0    3   33   74    0
     0    0    0    3    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-0-conf_gating-0-reassignment-0/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-0-conf_gating-0-reassignment-0/fold1/metrics.json
Done.
