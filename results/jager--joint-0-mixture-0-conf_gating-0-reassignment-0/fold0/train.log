[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.8690 
[epoch 1] step 4/44: loss=0.8746 
[epoch 1] step 6/44: loss=0.8737 
[epoch 1] step 8/44: loss=0.8779 
[epoch 1] step 10/44: loss=0.8812 
[epoch 1] step 12/44: loss=0.8800 
[epoch 1] step 14/44: loss=0.8792 
[epoch 1] step 16/44: loss=0.8790 
[epoch 1] step 18/44: loss=0.8796 
[epoch 1] step 20/44: loss=0.8767 
[epoch 1] step 22/44: loss=0.8762 
[epoch 1] step 24/44: loss=0.8750 
[epoch 1] step 26/44: loss=0.8755 
[epoch 1] step 28/44: loss=0.8733 
[epoch 1] step 30/44: loss=0.8725 
[epoch 1] step 32/44: loss=0.8700 
[epoch 1] step 34/44: loss=0.8673 
[epoch 1] step 36/44: loss=0.8642 
[epoch 1] step 38/44: loss=0.8599 
[epoch 1] step 40/44: loss=0.8557 
[epoch 1] step 42/44: loss=0.8495 
[epoch 1] step 44/44: loss=0.8441 
[epoch 1] train_loss(avg per step)=1.6882 lambda[min,max]=[0.882924,1.000000]
[epoch 1] val_loss=1.3856 qwk=('-0.0060', '-0.0003', '-0.0699') averageQWK=-0.0254 macroEMD=0.3612 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    4    0
     0    0    0   15    0
     0    2    0   76    0
     0   12    0  150    0
     0    0    0   64    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   16    0    0
     2    0   61    3    0
     6    0  190    9    0
     0    0   30    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    5   24    0    0
     0   23   88    0    0
     0   60  121    0    0
     0    0    1    0    0
[epoch 2] step 2/44: loss=0.7204 
[epoch 2] step 4/44: loss=0.6989 
[epoch 2] step 6/44: loss=0.6999 
[epoch 2] step 8/44: loss=0.6818 
[epoch 2] step 10/44: loss=0.6687 
[epoch 2] step 12/44: loss=0.6689 
[epoch 2] step 14/44: loss=0.6666 
[epoch 2] step 16/44: loss=0.6634 
[epoch 2] step 18/44: loss=0.6575 
[epoch 2] step 20/44: loss=0.6524 
[epoch 2] step 22/44: loss=0.6490 
[epoch 2] step 24/44: loss=0.6461 
[epoch 2] step 26/44: loss=0.6427 
[epoch 2] step 28/44: loss=0.6429 
[epoch 2] step 30/44: loss=0.6371 
[epoch 2] step 32/44: loss=0.6322 
[epoch 2] step 34/44: loss=0.6303 
[epoch 2] step 36/44: loss=0.6259 
[epoch 2] step 38/44: loss=0.6240 
[epoch 2] step 40/44: loss=0.6205 
[epoch 2] step 42/44: loss=0.6153 
[epoch 2] step 44/44: loss=0.6120 
[epoch 2] train_loss(avg per step)=1.2240 lambda[min,max]=[0.816998,1.000000]
[epoch 2] val_loss=1.3166 qwk=('0.0335', '0.0453', '0.0283') averageQWK=0.0357 macroEMD=0.3139 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    1    0
     0    1   12    2    0
     0    0   55   23    0
     0    0   97   65    0
     0    1   53   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   14    2    0
     0    0   54   12    0
     0    0  159   46    0
     0    0   24    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    0   29    0    0
     0    1  110    0    0
     0    0  176    5    0
     0    0    1    0    0
[epoch 3] step 2/44: loss=0.5624 
[epoch 3] step 4/44: loss=0.5209 
[epoch 3] step 6/44: loss=0.5295 
[epoch 3] step 8/44: loss=0.5295 
[epoch 3] step 10/44: loss=0.5279 
[epoch 3] step 12/44: loss=0.5224 
[epoch 3] step 14/44: loss=0.5270 
[epoch 3] step 16/44: loss=0.5200 
[epoch 3] step 18/44: loss=0.5143 
[epoch 3] step 20/44: loss=0.5144 
[epoch 3] step 22/44: loss=0.5092 
[epoch 3] step 24/44: loss=0.5075 
[epoch 3] step 26/44: loss=0.5065 
[epoch 3] step 28/44: loss=0.5036 
[epoch 3] step 30/44: loss=0.5025 
[epoch 3] step 32/44: loss=0.4989 
[epoch 3] step 34/44: loss=0.4963 
[epoch 3] step 36/44: loss=0.4963 
[epoch 3] step 38/44: loss=0.4953 
[epoch 3] step 40/44: loss=0.4955 
[epoch 3] step 42/44: loss=0.4927 
[epoch 3] step 44/44: loss=0.4885 
[epoch 3] train_loss(avg per step)=0.9771 lambda[min,max]=[0.685627,1.000000]
[epoch 3] val_loss=1.2167 qwk=('0.1185', '0.1325', '0.1207') averageQWK=0.1239 macroEMD=0.2795 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    0   13    2    0
     0    0   61   17    0
     0    0   96   66    0
     0    0   44   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   13    3    0
     0    0   48   18    0
     0    0  125   80    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   27    0    0
     0    1  108    2    0
     0    0  160   21    0
     0    0    1    0    0
[epoch 4] step 2/44: loss=0.4574 
[epoch 4] step 4/44: loss=0.4426 
[epoch 4] step 6/44: loss=0.4397 
[epoch 4] step 8/44: loss=0.4411 
[epoch 4] step 10/44: loss=0.4348 
[epoch 4] step 12/44: loss=0.4262 
[epoch 4] step 14/44: loss=0.4354 
[epoch 4] step 16/44: loss=0.4354 
[epoch 4] step 18/44: loss=0.4368 
[epoch 4] step 20/44: loss=0.4328 
[epoch 4] step 22/44: loss=0.4368 
[epoch 4] step 24/44: loss=0.4490 
[epoch 4] step 26/44: loss=0.4582 
[epoch 4] step 28/44: loss=0.4624 
[epoch 4] step 30/44: loss=0.4568 
[epoch 4] step 32/44: loss=0.4585 
[epoch 4] step 34/44: loss=0.4604 
[epoch 4] step 36/44: loss=0.4643 
[epoch 4] step 38/44: loss=0.4620 
[epoch 4] step 40/44: loss=0.4607 
[epoch 4] step 42/44: loss=0.4609 
[epoch 4] step 44/44: loss=0.4605 
[epoch 4] train_loss(avg per step)=0.9210 lambda[min,max]=[0.614697,1.000000]
[epoch 4] val_loss=1.5137 qwk=('0.1035', '0.1741', '0.1339') averageQWK=0.1372 macroEMD=0.2849 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   12    3    0    0
     0   43   32    3    0
     0   50   82   30    0
     0   27   29    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    7    9    0    0
     0    6   57    3    0
     0   10  171   24    0
     0    1   26    3    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26    3    0    0
     0   56   55    0    0
     0   64  116    1    0
     0    0    1    0    0
[epoch 5] step 2/44: loss=0.4602 
[epoch 5] step 4/44: loss=0.4628 
[epoch 5] step 6/44: loss=0.4753 
[epoch 5] step 8/44: loss=0.4633 
[epoch 5] step 10/44: loss=0.4599 
[epoch 5] step 12/44: loss=0.4548 
[epoch 5] step 14/44: loss=0.4459 
[epoch 5] step 16/44: loss=0.4392 
[epoch 5] step 18/44: loss=0.4304 
[epoch 5] step 20/44: loss=0.4291 
[epoch 5] step 22/44: loss=0.4288 
[epoch 5] step 24/44: loss=0.4232 
[epoch 5] step 26/44: loss=0.4223 
[epoch 5] step 28/44: loss=0.4167 
[epoch 5] step 30/44: loss=0.4161 
[epoch 5] step 32/44: loss=0.4133 
[epoch 5] step 34/44: loss=0.4129 
[epoch 5] step 36/44: loss=0.4122 
[epoch 5] step 38/44: loss=0.4083 
[epoch 5] step 40/44: loss=0.4078 
[epoch 5] step 42/44: loss=0.4094 
[epoch 5] step 44/44: loss=0.4071 
[epoch 5] train_loss(avg per step)=0.8141 lambda[min,max]=[0.588911,1.000000]
[epoch 5] val_loss=1.2906 qwk=('0.1482', '0.1220', '0.2774') averageQWK=0.1825 macroEMD=0.2597 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   12    0    0
     0    2   68    8    0
     0    1  121   40    0
     0    1   48   15    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   16    0    0
     0    0   58    8    0
     0    0  163   42    0
     0    0   20   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20    9    0    0
     0   19   87    5    0
     0   15  141   25    0
     0    0    0    1    0
[epoch 6] step 2/44: loss=0.3910 
[epoch 6] step 4/44: loss=0.3962 
[epoch 6] step 6/44: loss=0.3916 
[epoch 6] step 8/44: loss=0.3889 
[epoch 6] step 10/44: loss=0.3872 
[epoch 6] step 12/44: loss=0.3894 
[epoch 6] step 14/44: loss=0.3800 
[epoch 6] step 16/44: loss=0.3754 
[epoch 6] step 18/44: loss=0.3751 
[epoch 6] step 20/44: loss=0.3759 
[epoch 6] step 22/44: loss=0.3817 
[epoch 6] step 24/44: loss=0.3858 
[epoch 6] step 26/44: loss=0.3833 
[epoch 6] step 28/44: loss=0.3834 
[epoch 6] step 30/44: loss=0.3812 
[epoch 6] step 32/44: loss=0.3869 
[epoch 6] step 34/44: loss=0.3810 
[epoch 6] step 36/44: loss=0.3800 
[epoch 6] step 38/44: loss=0.3776 
[epoch 6] step 40/44: loss=0.3776 
[epoch 6] step 42/44: loss=0.3759 
[epoch 6] step 44/44: loss=0.3720 
[epoch 6] train_loss(avg per step)=0.7440 lambda[min,max]=[0.558177,1.000000]
[epoch 6] val_loss=1.0874 qwk=('0.2281', '0.2982', '0.3719') averageQWK=0.2994 macroEMD=0.2451 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    7    2    0
     0   13   36   29    0
     0    6   67   89    0
     0    5   26   33    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    2   11    3    0
     0    4   32   30    0
     0    0   78  127    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   13    1    0
     0   14   69   28    0
     0    7   97   77    0
     0    0    0    1    0
[epoch 7] step 2/44: loss=0.3620 
[epoch 7] step 4/44: loss=0.3643 
[epoch 7] step 6/44: loss=0.3530 
[epoch 7] step 8/44: loss=0.3402 
[epoch 7] step 10/44: loss=0.3306 
[epoch 7] step 12/44: loss=0.3317 
[epoch 7] step 14/44: loss=0.3255 
[epoch 7] step 16/44: loss=0.3284 
[epoch 7] step 18/44: loss=0.3318 
[epoch 7] step 20/44: loss=0.3344 
[epoch 7] step 22/44: loss=0.3321 
[epoch 7] step 24/44: loss=0.3324 
[epoch 7] step 26/44: loss=0.3302 
[epoch 7] step 28/44: loss=0.3278 
[epoch 7] step 30/44: loss=0.3259 
[epoch 7] step 32/44: loss=0.3233 
[epoch 7] step 34/44: loss=0.3253 
[epoch 7] step 36/44: loss=0.3235 
[epoch 7] step 38/44: loss=0.3228 
[epoch 7] step 40/44: loss=0.3231 
[epoch 7] step 42/44: loss=0.3202 
[epoch 7] step 44/44: loss=0.3169 
[epoch 7] train_loss(avg per step)=0.6338 lambda[min,max]=[0.543448,1.000000]
[epoch 7] val_loss=1.0697 qwk=('0.2467', '0.2290', '0.1938') averageQWK=0.2232 macroEMD=0.2471 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    0   13    2    0
     0    0   52   26    0
     0    0   66   96    0
     0    0   27   37    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    0   13    3    0
     0    0   38   28    0
     0    0  101  104    0
     0    0    9   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    3   26    0    0
     0    1  104    6    0
     0    0  146   35    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=0.2779 
[epoch 8] step 4/44: loss=0.2691 
[epoch 8] step 6/44: loss=0.2871 
[epoch 8] step 8/44: loss=0.2908 
[epoch 8] step 10/44: loss=0.2771 
[epoch 8] step 12/44: loss=0.2801 
[epoch 8] step 14/44: loss=0.2763 
[epoch 8] step 16/44: loss=0.2747 
[epoch 8] step 18/44: loss=0.2770 
[epoch 8] step 20/44: loss=0.2786 
[epoch 8] step 22/44: loss=0.2736 
[epoch 8] step 24/44: loss=0.2751 
[epoch 8] step 26/44: loss=0.2735 
[epoch 8] step 28/44: loss=0.2744 
[epoch 8] step 30/44: loss=0.2751 
[epoch 8] step 32/44: loss=0.2765 
[epoch 8] step 34/44: loss=0.2739 
[epoch 8] step 36/44: loss=0.2732 
[epoch 8] step 38/44: loss=0.2743 
[epoch 8] step 40/44: loss=0.2751 
[epoch 8] step 42/44: loss=0.2750 
[epoch 8] step 44/44: loss=0.2734 
[epoch 8] train_loss(avg per step)=0.5468 lambda[min,max]=[0.530110,1.000000]
[epoch 8] val_loss=1.1235 qwk=('0.2138', '0.2089', '0.2594') averageQWK=0.2274 macroEMD=0.2490 tailR0=('0.0469', '0.0000', '0.0000') tailR0avg=0.0156
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    1   55   20    2
     0    0   92   59   11
     0    0   37   21    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    1   12    3    0
     0    3   35   28    0
     0    0  115   90    0
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   22    0    0
     0    3  100    8    0
     0    0  140   41    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=0.2901 
[epoch 9] step 4/44: loss=0.2847 
[epoch 9] step 6/44: loss=0.2605 
[epoch 9] step 8/44: loss=0.2527 
[epoch 9] step 10/44: loss=0.2485 
[epoch 9] step 12/44: loss=0.2454 
[epoch 9] step 14/44: loss=0.2469 
[epoch 9] step 16/44: loss=0.2449 
[epoch 9] step 18/44: loss=0.2447 
[epoch 9] step 20/44: loss=0.2444 
[epoch 9] step 22/44: loss=0.2391 
[epoch 9] step 24/44: loss=0.2368 
[epoch 9] step 26/44: loss=0.2407 
[epoch 9] step 28/44: loss=0.2398 
[epoch 9] step 30/44: loss=0.2375 
[epoch 9] step 32/44: loss=0.2387 
[epoch 9] step 34/44: loss=0.2409 
[epoch 9] step 36/44: loss=0.2394 
[epoch 9] step 38/44: loss=0.2380 
[epoch 9] step 40/44: loss=0.2354 
[epoch 9] step 42/44: loss=0.2363 
[epoch 9] step 44/44: loss=0.2338 
[epoch 9] train_loss(avg per step)=0.4676 lambda[min,max]=[0.524481,1.000000]
[epoch 9] val_loss=1.2465 qwk=('0.2321', '0.2538', '0.2269') averageQWK=0.2376 macroEMD=0.2401 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    7   53   16    2
     0    1   89   68    4
     0    2   34   27    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    5   10    1    0
     0    8   42   16    0
     0    2  137   66    0
     0    1   14   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   11   18    0    0
     0    7  103    1    0
     0    1  160   20    0
     0    0    1    0    0
[epoch 10] step 2/44: loss=0.2219 
[epoch 10] step 4/44: loss=0.2510 
[epoch 10] step 6/44: loss=0.2251 
[epoch 10] step 8/44: loss=0.2194 
[epoch 10] step 10/44: loss=0.2115 
[epoch 10] step 12/44: loss=0.2137 
[epoch 10] step 14/44: loss=0.2108 
[epoch 10] step 16/44: loss=0.2072 
[epoch 10] step 18/44: loss=0.2046 
[epoch 10] step 20/44: loss=0.2054 
[epoch 10] step 22/44: loss=0.2022 
[epoch 10] step 24/44: loss=0.2024 
[epoch 10] step 26/44: loss=0.2038 
[epoch 10] step 28/44: loss=0.2003 
[epoch 10] step 30/44: loss=0.1990 
[epoch 10] step 32/44: loss=0.1983 
[epoch 10] step 34/44: loss=0.1977 
[epoch 10] step 36/44: loss=0.1957 
[epoch 10] step 38/44: loss=0.1932 
[epoch 10] step 40/44: loss=0.1941 
[epoch 10] step 42/44: loss=0.1914 
[epoch 10] step 44/44: loss=0.1889 
[epoch 10] train_loss(avg per step)=0.3778 lambda[min,max]=[0.520681,1.000000]
[epoch 10] val_loss=1.1914 qwk=('0.3070', '0.2855', '0.3482') averageQWK=0.3136 macroEMD=0.2307 tailR0=('0.0469', '0.0000', '0.0000') tailR0avg=0.0156
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    8    1    0
     0    9   40   26    3
     0    1   70   79   12
     0    1   26   31    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    5    9    2    0
     0    6   36   24    0
     0    1  115   89    0
     0    1   10   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   22   79   10    0
     0    6  128   47    0
     0    0    0    1    0
[epoch 11] step 2/44: loss=0.1165 
[epoch 11] step 4/44: loss=0.1348 
[epoch 11] step 6/44: loss=0.1492 
[epoch 11] step 8/44: loss=0.1519 
[epoch 11] step 10/44: loss=0.1472 
[epoch 11] step 12/44: loss=0.1534 
[epoch 11] step 14/44: loss=0.1518 
[epoch 11] step 16/44: loss=0.1501 
[epoch 11] step 18/44: loss=0.1474 
[epoch 11] step 20/44: loss=0.1452 
[epoch 11] step 22/44: loss=0.1496 
[epoch 11] step 24/44: loss=0.1436 
[epoch 11] step 26/44: loss=0.1457 
[epoch 11] step 28/44: loss=0.1468 
[epoch 11] step 30/44: loss=0.1460 
[epoch 11] step 32/44: loss=0.1449 
[epoch 11] step 34/44: loss=0.1442 
[epoch 11] step 36/44: loss=0.1448 
[epoch 11] step 38/44: loss=0.1442 
[epoch 11] step 40/44: loss=0.1426 
[epoch 11] step 42/44: loss=0.1426 
[epoch 11] step 44/44: loss=0.1434 
[epoch 11] train_loss(avg per step)=0.2868 lambda[min,max]=[0.508958,1.000000]
[epoch 11] val_loss=1.2452 qwk=('0.2485', '0.2646', '0.3969') averageQWK=0.3033 macroEMD=0.2259 tailR0=('0.0391', '0.0000', '0.0000') tailR0avg=0.0130
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0   10   51   15    2
     0    2   88   66    6
     0    1   38   20    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    3   12    1    0
     0    9   39   18    0
     0    2  128   73    2
     0    1   12   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   11    0    0
     0   24   75   12    0
     0    9  110   62    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=0.1217 
[epoch 12] step 4/44: loss=0.1312 
[epoch 12] step 6/44: loss=0.1295 
[epoch 12] step 8/44: loss=0.1303 
[epoch 12] step 10/44: loss=0.1173 
[epoch 12] step 12/44: loss=0.1197 
[epoch 12] step 14/44: loss=0.1195 
[epoch 12] step 16/44: loss=0.1167 
[epoch 12] step 18/44: loss=0.1187 
[epoch 12] step 20/44: loss=0.1229 
[epoch 12] step 22/44: loss=0.1226 
[epoch 12] step 24/44: loss=0.1183 
[epoch 12] step 26/44: loss=0.1212 
[epoch 12] step 28/44: loss=0.1169 
[epoch 12] step 30/44: loss=0.1154 
[epoch 12] step 32/44: loss=0.1130 
[epoch 12] step 34/44: loss=0.1125 
[epoch 12] step 36/44: loss=0.1092 
[epoch 12] step 38/44: loss=0.1085 
[epoch 12] step 40/44: loss=0.1099 
[epoch 12] step 42/44: loss=0.1103 
[epoch 12] step 44/44: loss=0.1113 
[epoch 12] train_loss(avg per step)=0.2227 lambda[min,max]=[0.507038,1.000000]
[epoch 12] val_loss=1.4219 qwk=('0.2078', '0.2451', '0.2865') averageQWK=0.2465 macroEMD=0.2351 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    9    0    0
     0    9   61    7    1
     0    1  114   41    6
     0    1   46   16    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    6    9    1    0
     0    8   44   14    0
     0    3  136   64    2
     0    1   17   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0   20   87    4    0
     0    9  141   31    0
     0    0    0    1    0
[epoch 13] step 2/44: loss=0.0708 
[epoch 13] step 4/44: loss=0.0688 
[epoch 13] step 6/44: loss=0.0647 
[epoch 13] step 8/44: loss=0.0732 
[epoch 13] step 10/44: loss=0.0761 
[epoch 13] step 12/44: loss=0.0763 
[epoch 13] step 14/44: loss=0.0816 
[epoch 13] step 16/44: loss=0.0805 
[epoch 13] step 18/44: loss=0.0833 
[epoch 13] step 20/44: loss=0.0857 
[epoch 13] step 22/44: loss=0.0871 
[epoch 13] step 24/44: loss=0.0862 
[epoch 13] step 26/44: loss=0.0893 
[epoch 13] step 28/44: loss=0.0888 
[epoch 13] step 30/44: loss=0.0890 
[epoch 13] step 32/44: loss=0.0853 
[epoch 13] step 34/44: loss=0.0867 
[epoch 13] step 36/44: loss=0.0881 
[epoch 13] step 38/44: loss=0.0892 
[epoch 13] step 40/44: loss=0.0882 
[epoch 13] step 42/44: loss=0.0893 
[epoch 13] step 44/44: loss=0.0920 
[epoch 13] train_loss(avg per step)=0.1839 lambda[min,max]=[0.504634,1.000000]
[epoch 13] val_loss=1.2637 qwk=('0.2626', '0.2535', '0.3576') averageQWK=0.2912 macroEMD=0.2233 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0   11   46   19    2
     0    2   79   75    6
     0    1   33   28    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    4    9    3    0
     0   10   33   22    1
     0    4  111   87    3
     0    1   12   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   12    0    0
     0   30   76    5    0
     0    9  128   44    0
     0    0    0    1    0
[epoch 14] step 2/44: loss=0.0554 
[epoch 14] step 4/44: loss=0.0476 
[epoch 14] step 6/44: loss=0.0459 
[epoch 14] step 8/44: loss=0.0528 
[epoch 14] step 10/44: loss=0.0459 
[epoch 14] step 12/44: loss=0.0466 
[epoch 14] step 14/44: loss=0.0530 
[epoch 14] step 16/44: loss=0.0563 
[epoch 14] step 18/44: loss=0.0582 
[epoch 14] step 20/44: loss=0.0629 
[epoch 14] step 22/44: loss=0.0643 
[epoch 14] step 24/44: loss=0.0664 
[epoch 14] step 26/44: loss=0.0691 
[epoch 14] step 28/44: loss=0.0651 
[epoch 14] step 30/44: loss=0.0630 
[epoch 14] step 32/44: loss=0.0608 
[epoch 14] step 34/44: loss=0.0610 
[epoch 14] step 36/44: loss=0.0582 
[epoch 14] step 38/44: loss=0.0580 
[epoch 14] step 40/44: loss=0.0569 
[epoch 14] step 42/44: loss=0.0566 
[epoch 14] step 44/44: loss=0.0562 
[epoch 14] train_loss(avg per step)=0.1124 lambda[min,max]=[0.504934,1.000000]
[epoch 14] val_loss=1.3196 qwk=('0.2739', '0.2101', '0.3809') averageQWK=0.2883 macroEMD=0.2251 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    8   53   15    2
     0    4   78   72    8
     0    1   32   28    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    4   12    0    0
     0    7   46   13    0
     0    5  140   58    2
     0    1   19   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   17    0    0
     0    9   97    5    0
     0    2  125   54    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=0.0628 
[epoch 15] step 4/44: loss=0.0373 
[epoch 15] step 6/44: loss=0.0298 
[epoch 15] step 8/44: loss=0.0196 
[epoch 15] step 10/44: loss=0.0241 
[epoch 15] step 12/44: loss=0.0236 
[epoch 15] step 14/44: loss=0.0270 
[epoch 15] step 16/44: loss=0.0247 
[epoch 15] step 18/44: loss=0.0202 
[epoch 15] step 20/44: loss=0.0204 
[epoch 15] step 22/44: loss=0.0204 
[epoch 15] step 24/44: loss=0.0221 
[epoch 15] step 26/44: loss=0.0226 
[epoch 15] step 28/44: loss=0.0245 
[epoch 15] step 30/44: loss=0.0244 
[epoch 15] step 32/44: loss=0.0222 
[epoch 15] step 34/44: loss=0.0244 
[epoch 15] step 36/44: loss=0.0256 
[epoch 15] step 38/44: loss=0.0272 
[epoch 15] step 40/44: loss=0.0282 
[epoch 15] step 42/44: loss=0.0273 
[epoch 15] step 44/44: loss=0.0262 
[epoch 15] train_loss(avg per step)=0.0524 lambda[min,max]=[0.502690,1.000000]
[epoch 15] val_loss=1.2723 qwk=('0.2418', '0.2566', '0.3790') averageQWK=0.2924 macroEMD=0.2269 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   11    1    0
     0    4   52   20    2
     0    0   83   69   10
     0    1   32   28    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2   11    3    0
     0    5   35   25    1
     0    1  100  103    1
     0    1   11   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   13    0    0
     0   22   83    6    0
     0    7  122   52    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=0.0084 
[epoch 16] step 4/44: loss=0.0154 
[epoch 16] step 6/44: loss=0.0137 
[epoch 16] step 8/44: loss=0.0120 
[epoch 16] step 10/44: loss=0.0134 
[epoch 16] step 12/44: loss=0.0074 
[epoch 16] step 14/44: loss=0.0105 
[epoch 16] step 16/44: loss=0.0050 
[epoch 16] step 18/44: loss=0.0010 
[epoch 16] step 20/44: loss=-0.0038 
[epoch 16] step 22/44: loss=-0.0041 
[epoch 16] step 24/44: loss=-0.0038 
[epoch 16] step 26/44: loss=-0.0021 
[epoch 16] step 28/44: loss=-0.0036 
[epoch 16] step 30/44: loss=-0.0036 
[epoch 16] step 32/44: loss=-0.0014 
[epoch 16] step 34/44: loss=-0.0014 
[epoch 16] step 36/44: loss=-0.0023 
[epoch 16] step 38/44: loss=-0.0030 
[epoch 16] step 40/44: loss=-0.0019 
[epoch 16] step 42/44: loss=-0.0016 
[epoch 16] step 44/44: loss=-0.0007 
[epoch 16] train_loss(avg per step)=-0.0014 lambda[min,max]=[0.502548,1.000000]
[epoch 16] val_loss=1.2627 qwk=('0.2629', '0.1899', '0.4134') averageQWK=0.2887 macroEMD=0.2278 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   11    1    0
     0    4   51   21    2
     0    0   78   75    9
     0    1   29   31    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2   11    3    0
     0    5   35   24    2
     0    2  110   89    4
     0    1   16   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   11    0    0
     0   26   75   10    0
     0    9  107   65    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=-0.0320 
[epoch 17] step 4/44: loss=-0.0254 
[epoch 17] step 6/44: loss=-0.0173 
[epoch 17] step 8/44: loss=-0.0222 
[epoch 17] step 10/44: loss=-0.0222 
[epoch 17] step 12/44: loss=-0.0245 
[epoch 17] step 14/44: loss=-0.0269 
[epoch 17] step 16/44: loss=-0.0280 
[epoch 17] step 18/44: loss=-0.0291 
[epoch 17] step 20/44: loss=-0.0293 
[epoch 17] step 22/44: loss=-0.0279 
[epoch 17] step 24/44: loss=-0.0274 
[epoch 17] step 26/44: loss=-0.0283 
[epoch 17] step 28/44: loss=-0.0276 
[epoch 17] step 30/44: loss=-0.0300 
[epoch 17] step 32/44: loss=-0.0297 
[epoch 17] step 34/44: loss=-0.0300 
[epoch 17] step 36/44: loss=-0.0296 
[epoch 17] step 38/44: loss=-0.0296 
[epoch 17] step 40/44: loss=-0.0289 
[epoch 17] step 42/44: loss=-0.0292 
[epoch 17] step 44/44: loss=-0.0293 
[epoch 17] train_loss(avg per step)=-0.0586 lambda[min,max]=[0.502166,1.000000]
[epoch 17] val_loss=1.3656 qwk=('0.2275', '0.2297', '0.4145') averageQWK=0.2906 macroEMD=0.2225 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    8   54   14    2
     0    1   91   65    5
     0    1   37   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    4   11    1    0
     0    8   38   20    0
     0    5  122   76    2
     0    1   16   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   16    0    0
     0   15   87    9    0
     0    5  107   69    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=-0.0699 
[epoch 18] step 4/44: loss=-0.0698 
[epoch 18] step 6/44: loss=-0.0696 
[epoch 18] step 8/44: loss=-0.0642 
[epoch 18] step 10/44: loss=-0.0594 
[epoch 18] step 12/44: loss=-0.0576 
[epoch 18] step 14/44: loss=-0.0549 
[epoch 18] step 16/44: loss=-0.0548 
[epoch 18] step 18/44: loss=-0.0578 
[epoch 18] step 20/44: loss=-0.0579 
[epoch 18] step 22/44: loss=-0.0573 
[epoch 18] step 24/44: loss=-0.0587 
[epoch 18] step 26/44: loss=-0.0593 
[epoch 18] step 28/44: loss=-0.0603 
[epoch 18] step 30/44: loss=-0.0600 
[epoch 18] step 32/44: loss=-0.0613 
[epoch 18] step 34/44: loss=-0.0603 
[epoch 18] step 36/44: loss=-0.0605 
[epoch 18] step 38/44: loss=-0.0587 
[epoch 18] step 40/44: loss=-0.0600 
[epoch 18] step 42/44: loss=-0.0593 
[epoch 18] step 44/44: loss=-0.0565 
[epoch 18] train_loss(avg per step)=-0.1130 lambda[min,max]=[0.501817,1.000000]
[epoch 18] val_loss=1.5136 qwk=('0.2195', '0.2302', '0.3701') averageQWK=0.2733 macroEMD=0.2238 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    8    1    0
     0   12   53   12    1
     0    4   92   65    1
     0    3   38   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5   11    0    0
     0    8   51    6    1
     0    5  143   56    1
     0    1   21    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0   14   92    5    0
     0    5  125   51    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=-0.0785 
[epoch 19] step 4/44: loss=-0.0865 
[epoch 19] step 6/44: loss=-0.0792 
[epoch 19] step 8/44: loss=-0.0783 
[epoch 19] step 10/44: loss=-0.0784 
[epoch 19] step 12/44: loss=-0.0811 
[epoch 19] step 14/44: loss=-0.0769 
[epoch 19] step 16/44: loss=-0.0776 
[epoch 19] step 18/44: loss=-0.0760 
[epoch 19] step 20/44: loss=-0.0778 
[epoch 19] step 22/44: loss=-0.0774 
[epoch 19] step 24/44: loss=-0.0775 
[epoch 19] step 26/44: loss=-0.0780 
[epoch 19] step 28/44: loss=-0.0791 
[epoch 19] step 30/44: loss=-0.0791 
[epoch 19] step 32/44: loss=-0.0790 
[epoch 19] step 34/44: loss=-0.0791 
[epoch 19] step 36/44: loss=-0.0781 
[epoch 19] step 38/44: loss=-0.0790 
[epoch 19] step 40/44: loss=-0.0795 
[epoch 19] step 42/44: loss=-0.0802 
[epoch 19] step 44/44: loss=-0.0823 
[epoch 19] train_loss(avg per step)=-0.1646 lambda[min,max]=[0.501519,1.000000]
[epoch 19] val_loss=1.5014 qwk=('0.2963', '0.2064', '0.3556') averageQWK=0.2861 macroEMD=0.2238 tailR0=('0.0000', '0.0833', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    7   46   23    2
     0    1   63   93    5
     0    1   25   38    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    1   15    0    0
     0    5   53    6    2
     0    1  144   58    2
     0    1   20    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   17    0    0
     0   15   90    6    0
     0    5  124   52    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=-0.0942 
[epoch 20] step 4/44: loss=-0.0943 
[epoch 20] step 6/44: loss=-0.0921 
[epoch 20] step 8/44: loss=-0.0982 
[epoch 20] step 10/44: loss=-0.0946 
[epoch 20] step 12/44: loss=-0.0949 
[epoch 20] step 14/44: loss=-0.0969 
[epoch 20] step 16/44: loss=-0.1005 
[epoch 20] step 18/44: loss=-0.0991 
[epoch 20] step 20/44: loss=-0.0994 
[epoch 20] step 22/44: loss=-0.1015 
[epoch 20] step 24/44: loss=-0.1033 
[epoch 20] step 26/44: loss=-0.1032 
[epoch 20] step 28/44: loss=-0.1017 
[epoch 20] step 30/44: loss=-0.1002 
[epoch 20] step 32/44: loss=-0.0996 
[epoch 20] step 34/44: loss=-0.0996 
[epoch 20] step 36/44: loss=-0.0993 
[epoch 20] step 38/44: loss=-0.0997 
[epoch 20] step 40/44: loss=-0.1003 
[epoch 20] step 42/44: loss=-0.0997 
[epoch 20] step 44/44: loss=-0.1011 
[epoch 20] train_loss(avg per step)=-0.2023 lambda[min,max]=[0.501312,1.000000]
[epoch 20] val_loss=1.5125 qwk=('0.1814', '0.2548', '0.3462') averageQWK=0.2608 macroEMD=0.2267 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4   10    1    0
     0    7   55   15    1
     0    1   93   67    1
     0    0   44   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   10    2    0
     0    5   43   18    0
     0    2  119   84    0
     0    0   18   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20    9    0    0
     0   33   73    5    0
     0   18  115   48    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=-0.1135 
[epoch 21] step 4/44: loss=-0.1018 
[epoch 21] step 6/44: loss=-0.1038 
[epoch 21] step 8/44: loss=-0.1072 
[epoch 21] step 10/44: loss=-0.1104 
[epoch 21] step 12/44: loss=-0.1063 
[epoch 21] step 14/44: loss=-0.1067 
[epoch 21] step 16/44: loss=-0.1050 
[epoch 21] step 18/44: loss=-0.1061 
[epoch 21] step 20/44: loss=-0.1093 
[epoch 21] step 22/44: loss=-0.1117 
[epoch 21] step 24/44: loss=-0.1112 
[epoch 21] step 26/44: loss=-0.1109 
[epoch 21] step 28/44: loss=-0.1104 
[epoch 21] step 30/44: loss=-0.1116 
[epoch 21] step 32/44: loss=-0.1112 
[epoch 21] step 34/44: loss=-0.1119 
[epoch 21] step 36/44: loss=-0.1130 
[epoch 21] step 38/44: loss=-0.1131 
[epoch 21] step 40/44: loss=-0.1144 
[epoch 21] step 42/44: loss=-0.1147 
[epoch 21] step 44/44: loss=-0.1159 
[epoch 21] train_loss(avg per step)=-0.2318 lambda[min,max]=[0.501245,1.000000]
[epoch 21] val_loss=1.5567 qwk=('0.2096', '0.2524', '0.3961') averageQWK=0.2860 macroEMD=0.2222 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    8    1    0
     0   11   51   14    2
     0    5   84   70    3
     0    2   40   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   11    1    0
     0    7   46   13    0
     0    4  128   73    0
     0    1   17   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   18   85    8    0
     0    6  115   60    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=-0.1391 
[epoch 22] step 4/44: loss=-0.1323 
[epoch 22] step 6/44: loss=-0.1280 
[epoch 22] step 8/44: loss=-0.1315 
[epoch 22] step 10/44: loss=-0.1352 
[epoch 22] step 12/44: loss=-0.1344 
[epoch 22] step 14/44: loss=-0.1356 
[epoch 22] step 16/44: loss=-0.1352 
[epoch 22] step 18/44: loss=-0.1354 
[epoch 22] step 20/44: loss=-0.1335 
[epoch 22] step 22/44: loss=-0.1327 
[epoch 22] step 24/44: loss=-0.1310 
[epoch 22] step 26/44: loss=-0.1300 
[epoch 22] step 28/44: loss=-0.1308 
[epoch 22] step 30/44: loss=-0.1309 
[epoch 22] step 32/44: loss=-0.1304 
[epoch 22] step 34/44: loss=-0.1300 
[epoch 22] step 36/44: loss=-0.1292 
[epoch 22] step 38/44: loss=-0.1293 
[epoch 22] step 40/44: loss=-0.1288 
[epoch 22] step 42/44: loss=-0.1294 
[epoch 22] step 44/44: loss=-0.1302 
[epoch 22] train_loss(avg per step)=-0.2603 lambda[min,max]=[0.501117,1.000000]
[epoch 22] val_loss=1.5814 qwk=('0.2199', '0.2392', '0.4198') averageQWK=0.2930 macroEMD=0.2220 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    8    1    0
     0    8   57   11    2
     0    1   99   58    4
     0    1   41   21    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   11    1    0
     0    5   47   12    2
     0    3  124   77    1
     0    1   18   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   13    0    0
     0   13   90    8    0
     0    3  118   60    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=-0.1438 
[epoch 23] step 4/44: loss=-0.1499 
[epoch 23] step 6/44: loss=-0.1468 
[epoch 23] step 8/44: loss=-0.1439 
[epoch 23] step 10/44: loss=-0.1428 
[epoch 23] step 12/44: loss=-0.1433 
[epoch 23] step 14/44: loss=-0.1406 
[epoch 23] step 16/44: loss=-0.1411 
[epoch 23] step 18/44: loss=-0.1391 
[epoch 23] step 20/44: loss=-0.1378 
[epoch 23] step 22/44: loss=-0.1373 
[epoch 23] step 24/44: loss=-0.1362 
[epoch 23] step 26/44: loss=-0.1367 
[epoch 23] step 28/44: loss=-0.1358 
[epoch 23] step 30/44: loss=-0.1357 
[epoch 23] step 32/44: loss=-0.1361 
[epoch 23] step 34/44: loss=-0.1360 
[epoch 23] step 36/44: loss=-0.1353 
[epoch 23] step 38/44: loss=-0.1344 
[epoch 23] step 40/44: loss=-0.1344 
[epoch 23] step 42/44: loss=-0.1345 
[epoch 23] step 44/44: loss=-0.1351 
[epoch 23] train_loss(avg per step)=-0.2701 lambda[min,max]=[0.501227,1.000000]
[epoch 23] val_loss=1.6021 qwk=('0.2558', '0.2369', '0.3188') averageQWK=0.2705 macroEMD=0.2239 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    7   52   17    2
     0    1   82   76    3
     0    1   33   29    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5   10    1    0
     0    5   47   14    0
     0    2  130   72    1
     0    1   20    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   10   19    0    0
     0    7   98    6    0
     0    2  135   44    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=-0.1369 
[epoch 24] step 4/44: loss=-0.1273 
[epoch 24] step 6/44: loss=-0.1350 
[epoch 24] step 8/44: loss=-0.1372 
[epoch 24] step 10/44: loss=-0.1388 
[epoch 24] step 12/44: loss=-0.1382 
[epoch 24] step 14/44: loss=-0.1398 
[epoch 24] step 16/44: loss=-0.1386 
[epoch 24] step 18/44: loss=-0.1405 
[epoch 24] step 20/44: loss=-0.1400 
[epoch 24] step 22/44: loss=-0.1384 
[epoch 24] step 24/44: loss=-0.1371 
[epoch 24] step 26/44: loss=-0.1390 
[epoch 24] step 28/44: loss=-0.1392 
[epoch 24] step 30/44: loss=-0.1386 
[epoch 24] step 32/44: loss=-0.1381 
[epoch 24] step 34/44: loss=-0.1391 
[epoch 24] step 36/44: loss=-0.1394 
[epoch 24] step 38/44: loss=-0.1406 
[epoch 24] step 40/44: loss=-0.1417 
[epoch 24] step 42/44: loss=-0.1423 
[epoch 24] step 44/44: loss=-0.1416 
[epoch 24] train_loss(avg per step)=-0.2831 lambda[min,max]=[0.501044,1.000000]
[epoch 24] val_loss=1.5724 qwk=('0.3088', '0.2092', '0.4184') averageQWK=0.3122 macroEMD=0.2185 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    8   49   19    2
     0    2   67   88    5
     0    1   26   36    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    3   12    1    0
     0    6   48   11    1
     0    2  136   66    1
     0    1   19   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   11    0    0
     0   21   83    7    0
     0    6  116   59    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=-0.1446 
[epoch 25] step 4/44: loss=-0.1431 
[epoch 25] step 6/44: loss=-0.1425 
[epoch 25] step 8/44: loss=-0.1428 
[epoch 25] step 10/44: loss=-0.1488 
[epoch 25] step 12/44: loss=-0.1504 
[epoch 25] step 14/44: loss=-0.1469 
[epoch 25] step 16/44: loss=-0.1491 
[epoch 25] step 18/44: loss=-0.1499 
[epoch 25] step 20/44: loss=-0.1493 
[epoch 25] step 22/44: loss=-0.1494 
[epoch 25] step 24/44: loss=-0.1502 
[epoch 25] step 26/44: loss=-0.1503 
[epoch 25] step 28/44: loss=-0.1489 
[epoch 25] step 30/44: loss=-0.1482 
[epoch 25] step 32/44: loss=-0.1474 
[epoch 25] step 34/44: loss=-0.1482 
[epoch 25] step 36/44: loss=-0.1488 
[epoch 25] step 38/44: loss=-0.1485 
[epoch 25] step 40/44: loss=-0.1484 
[epoch 25] step 42/44: loss=-0.1489 
[epoch 25] step 44/44: loss=-0.1489 
[epoch 25] train_loss(avg per step)=-0.2979 lambda[min,max]=[0.501118,1.000000]
[epoch 25] val_loss=1.6744 qwk=('0.2064', '0.2538', '0.3145') averageQWK=0.2582 macroEMD=0.2237 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    7   59   11    1
     0    1  100   60    1
     0    1   42   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    5   10    1    0
     0    6   45   15    0
     0    4  122   79    0
     0    2   14   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    7   22    0    0
     0    4  101    6    0
     0    1  131   49    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=-0.1741 
[epoch 26] step 4/44: loss=-0.1585 
[epoch 26] step 6/44: loss=-0.1560 
[epoch 26] step 8/44: loss=-0.1583 
[epoch 26] step 10/44: loss=-0.1603 
[epoch 26] step 12/44: loss=-0.1597 
[epoch 26] step 14/44: loss=-0.1581 
[epoch 26] step 16/44: loss=-0.1590 
[epoch 26] step 18/44: loss=-0.1572 
[epoch 26] step 20/44: loss=-0.1569 
[epoch 26] step 22/44: loss=-0.1583 
[epoch 26] step 24/44: loss=-0.1581 
[epoch 26] step 26/44: loss=-0.1577 
[epoch 26] step 28/44: loss=-0.1576 
[epoch 26] step 30/44: loss=-0.1578 
[epoch 26] step 32/44: loss=-0.1585 
[epoch 26] step 34/44: loss=-0.1590 
[epoch 26] step 36/44: loss=-0.1590 
[epoch 26] step 38/44: loss=-0.1595 
[epoch 26] step 40/44: loss=-0.1594 
[epoch 26] step 42/44: loss=-0.1582 
[epoch 26] step 44/44: loss=-0.1587 
[epoch 26] train_loss(avg per step)=-0.3174 lambda[min,max]=[0.501178,1.000000]
[epoch 26] val_loss=1.5527 qwk=('0.2606', '0.1713', '0.4116') averageQWK=0.2812 macroEMD=0.2246 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    7   52   17    2
     0    1   83   74    4
     0    1   32   30    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    2   12    2    0
     0    5   43   18    0
     0    2  123   80    0
     0    1   18   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   13    0    0
     0   19   86    6    0
     0    8  109   64    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=-0.1649 
[epoch 27] step 4/44: loss=-0.1728 
[epoch 27] step 6/44: loss=-0.1729 
[epoch 27] step 8/44: loss=-0.1691 
[epoch 27] step 10/44: loss=-0.1642 
[epoch 27] step 12/44: loss=-0.1661 
[epoch 27] step 14/44: loss=-0.1666 
[epoch 27] step 16/44: loss=-0.1657 
[epoch 27] step 18/44: loss=-0.1640 
[epoch 27] step 20/44: loss=-0.1634 
[epoch 27] step 22/44: loss=-0.1632 
[epoch 27] step 24/44: loss=-0.1629 
[epoch 27] step 26/44: loss=-0.1635 
[epoch 27] step 28/44: loss=-0.1645 
[epoch 27] step 30/44: loss=-0.1650 
[epoch 27] step 32/44: loss=-0.1644 
[epoch 27] step 34/44: loss=-0.1648 
[epoch 27] step 36/44: loss=-0.1642 
[epoch 27] step 38/44: loss=-0.1638 
[epoch 27] step 40/44: loss=-0.1644 
[epoch 27] step 42/44: loss=-0.1645 
[epoch 27] step 44/44: loss=-0.1644 
[epoch 27] train_loss(avg per step)=-0.3289 lambda[min,max]=[0.501109,1.000000]
[epoch 27] val_loss=1.5182 qwk=('0.3264', '0.2662', '0.4041') averageQWK=0.3323 macroEMD=0.2164 tailR0=('0.0078', '0.1667', '0.0000') tailR0avg=0.0582
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    8   46   22    2
     0    1   59   99    3
     0    1   24   38    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    2    0    0
     0    4   10    2    0
     0    5   43   18    0
     0    2  118   84    1
     0    1   16   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   11   18    0    0
     0   13   92    6    0
     0    4  111   66    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=-0.1704 
[epoch 28] step 4/44: loss=-0.1671 
[epoch 28] step 6/44: loss=-0.1635 
[epoch 28] step 8/44: loss=-0.1626 
[epoch 28] step 10/44: loss=-0.1603 
[epoch 28] step 12/44: loss=-0.1632 
[epoch 28] step 14/44: loss=-0.1646 
[epoch 28] step 16/44: loss=-0.1651 
[epoch 28] step 18/44: loss=-0.1664 
[epoch 28] step 20/44: loss=-0.1667 
[epoch 28] step 22/44: loss=-0.1663 
[epoch 28] step 24/44: loss=-0.1671 
[epoch 28] step 26/44: loss=-0.1676 
[epoch 28] step 28/44: loss=-0.1672 
[epoch 28] step 30/44: loss=-0.1679 
[epoch 28] step 32/44: loss=-0.1679 
[epoch 28] step 34/44: loss=-0.1680 
[epoch 28] step 36/44: loss=-0.1685 
[epoch 28] step 38/44: loss=-0.1686 
[epoch 28] step 40/44: loss=-0.1684 
[epoch 28] step 42/44: loss=-0.1690 
[epoch 28] step 44/44: loss=-0.1685 
[epoch 28] train_loss(avg per step)=-0.3370 lambda[min,max]=[0.501081,1.000000]
[epoch 28] val_loss=1.5785 qwk=('0.2884', '0.2106', '0.4305') averageQWK=0.3098 macroEMD=0.2241 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    7   51   18    2
     0    1   82   73    6
     0    1   27   35    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2   12    2    0
     0    5   43   18    0
     0    2  126   76    1
     0    1   16   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   13    0    0
     0   17   88    6    0
     0    7  106   68    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=-0.1742 
[epoch 29] step 4/44: loss=-0.1725 
[epoch 29] step 6/44: loss=-0.1707 
[epoch 29] step 8/44: loss=-0.1718 
[epoch 29] step 10/44: loss=-0.1723 
[epoch 29] step 12/44: loss=-0.1712 
[epoch 29] step 14/44: loss=-0.1729 
[epoch 29] step 16/44: loss=-0.1745 
[epoch 29] step 18/44: loss=-0.1746 
[epoch 29] step 20/44: loss=-0.1747 
[epoch 29] step 22/44: loss=-0.1741 
[epoch 29] step 24/44: loss=-0.1740 
[epoch 29] step 26/44: loss=-0.1741 
[epoch 29] step 28/44: loss=-0.1740 
[epoch 29] step 30/44: loss=-0.1745 
[epoch 29] step 32/44: loss=-0.1747 
[epoch 29] step 34/44: loss=-0.1750 
[epoch 29] step 36/44: loss=-0.1745 
[epoch 29] step 38/44: loss=-0.1744 
[epoch 29] step 40/44: loss=-0.1739 
[epoch 29] step 42/44: loss=-0.1738 
[epoch 29] step 44/44: loss=-0.1735 
[epoch 29] train_loss(avg per step)=-0.3471 lambda[min,max]=[0.500989,1.000000]
[epoch 29] val_loss=1.6487 qwk=('0.2437', '0.2360', '0.4027') averageQWK=0.2941 macroEMD=0.2207 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    7   54   15    2
     0    1   88   71    2
     0    1   35   27    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   11    1    0
     0    6   46   14    0
     0    4  126   74    1
     0    1   19   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   16    0    0
     0   13   92    6    0
     0    6  110   65    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=-0.1862 
[epoch 30] step 4/44: loss=-0.1852 
[epoch 30] step 6/44: loss=-0.1771 
[epoch 30] step 8/44: loss=-0.1778 
[epoch 30] step 10/44: loss=-0.1775 
[epoch 30] step 12/44: loss=-0.1777 
[epoch 30] step 14/44: loss=-0.1785 
[epoch 30] step 16/44: loss=-0.1787 
[epoch 30] step 18/44: loss=-0.1776 
[epoch 30] step 20/44: loss=-0.1777 
[epoch 30] step 22/44: loss=-0.1768 
[epoch 30] step 24/44: loss=-0.1765 
[epoch 30] step 26/44: loss=-0.1770 
[epoch 30] step 28/44: loss=-0.1768 
[epoch 30] step 30/44: loss=-0.1764 
[epoch 30] step 32/44: loss=-0.1766 
[epoch 30] step 34/44: loss=-0.1771 
[epoch 30] step 36/44: loss=-0.1770 
[epoch 30] step 38/44: loss=-0.1767 
[epoch 30] step 40/44: loss=-0.1767 
[epoch 30] step 42/44: loss=-0.1771 
[epoch 30] step 44/44: loss=-0.1775 
[epoch 30] train_loss(avg per step)=-0.3550 lambda[min,max]=[0.500956,1.000000]
[epoch 30] val_loss=1.6320 qwk=('0.2722', '0.2153', '0.3988') averageQWK=0.2955 macroEMD=0.2255 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    6   52   18    2
     0    1   78   80    3
     0    1   29   33    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    4   10    2    0
     0    5   47   14    0
     0    2  133   69    1
     0    1   18   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   10   19    0    0
     0    9   96    6    0
     0    1  118   62    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=-0.1796 
[epoch 31] step 4/44: loss=-0.1788 
[epoch 31] step 6/44: loss=-0.1792 
[epoch 31] step 8/44: loss=-0.1800 
[epoch 31] step 10/44: loss=-0.1809 
[epoch 31] step 12/44: loss=-0.1797 
[epoch 31] step 14/44: loss=-0.1797 
[epoch 31] step 16/44: loss=-0.1795 
[epoch 31] step 18/44: loss=-0.1797 
[epoch 31] step 20/44: loss=-0.1800 
[epoch 31] step 22/44: loss=-0.1804 
[epoch 31] step 24/44: loss=-0.1800 
[epoch 31] step 26/44: loss=-0.1799 
[epoch 31] step 28/44: loss=-0.1797 
[epoch 31] step 30/44: loss=-0.1793 
[epoch 31] step 32/44: loss=-0.1794 
[epoch 31] step 34/44: loss=-0.1789 
[epoch 31] step 36/44: loss=-0.1791 
[epoch 31] step 38/44: loss=-0.1793 
[epoch 31] step 40/44: loss=-0.1794 
[epoch 31] step 42/44: loss=-0.1793 
[epoch 31] step 44/44: loss=-0.1798 
[epoch 31] train_loss(avg per step)=-0.3596 lambda[min,max]=[0.501026,1.000000]
[epoch 31] val_loss=1.6207 qwk=('0.2545', '0.2598', '0.3882') averageQWK=0.3008 macroEMD=0.2215 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    7   53   17    1
     0    1   85   74    2
     0    1   34   28    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    4   11    1    0
     0    5   42   19    0
     0    4  118   82    1
     0    1   13   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   17    0    0
     0   15   90    6    0
     0    5  115   61    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=-0.1861 
[epoch 32] step 4/44: loss=-0.1812 
[epoch 32] step 6/44: loss=-0.1817 
[epoch 32] step 8/44: loss=-0.1828 
[epoch 32] step 10/44: loss=-0.1844 
[epoch 32] step 12/44: loss=-0.1842 
[epoch 32] step 14/44: loss=-0.1828 
[epoch 32] step 16/44: loss=-0.1835 
[epoch 32] step 18/44: loss=-0.1826 
[epoch 32] step 20/44: loss=-0.1818 
[epoch 32] step 22/44: loss=-0.1819 
[epoch 32] step 24/44: loss=-0.1817 
[epoch 32] step 26/44: loss=-0.1819 
[epoch 32] step 28/44: loss=-0.1819 
[epoch 32] step 30/44: loss=-0.1823 
[epoch 32] step 32/44: loss=-0.1826 
[epoch 32] step 34/44: loss=-0.1829 
[epoch 32] step 36/44: loss=-0.1831 
[epoch 32] step 38/44: loss=-0.1830 
[epoch 32] step 40/44: loss=-0.1830 
[epoch 32] step 42/44: loss=-0.1829 
[epoch 32] step 44/44: loss=-0.1829 
[epoch 32] train_loss(avg per step)=-0.3658 lambda[min,max]=[0.501008,1.000000]
[epoch 32] val_loss=1.6472 qwk=('0.2368', '0.2570', '0.4296') averageQWK=0.3078 macroEMD=0.2197 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    9   49   18    2
     0    2   86   71    3
     0    1   35   27    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    4   11    1    0
     0    6   44   16    0
     0    4  127   73    1
     0    1   13   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   15   90    6    0
     0    7  104   70    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=-0.1792 
[epoch 33] step 4/44: loss=-0.1805 
[epoch 33] step 6/44: loss=-0.1806 
[epoch 33] step 8/44: loss=-0.1823 
[epoch 33] step 10/44: loss=-0.1820 
[epoch 33] step 12/44: loss=-0.1799 
[epoch 33] step 14/44: loss=-0.1806 
[epoch 33] step 16/44: loss=-0.1815 
[epoch 33] step 18/44: loss=-0.1818 
[epoch 33] step 20/44: loss=-0.1824 
[epoch 33] step 22/44: loss=-0.1817 
[epoch 33] step 24/44: loss=-0.1820 
[epoch 33] step 26/44: loss=-0.1825 
[epoch 33] step 28/44: loss=-0.1826 
[epoch 33] step 30/44: loss=-0.1830 
[epoch 33] step 32/44: loss=-0.1836 
[epoch 33] step 34/44: loss=-0.1838 
[epoch 33] step 36/44: loss=-0.1838 
[epoch 33] step 38/44: loss=-0.1839 
[epoch 33] step 40/44: loss=-0.1841 
[epoch 33] step 42/44: loss=-0.1844 
[epoch 33] step 44/44: loss=-0.1845 
[epoch 33] train_loss(avg per step)=-0.3690 lambda[min,max]=[0.501015,1.000000]
[epoch 33] val_loss=1.6903 qwk=('0.2366', '0.2853', '0.3430') averageQWK=0.2883 macroEMD=0.2205 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    9   51   17    1
     0    1   89   70    2
     0    1   37   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    7    7    2    0
     0    7   40   19    0
     0    4  118   83    0
     0    1   12   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   16    0    0
     0   15   90    6    0
     0    6  127   48    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=-0.1847 
[epoch 34] step 4/44: loss=-0.1869 
[epoch 34] step 6/44: loss=-0.1867 
[epoch 34] step 8/44: loss=-0.1873 
[epoch 34] step 10/44: loss=-0.1867 
[epoch 34] step 12/44: loss=-0.1860 
[epoch 34] step 14/44: loss=-0.1862 
[epoch 34] step 16/44: loss=-0.1861 
[epoch 34] step 18/44: loss=-0.1861 
[epoch 34] step 20/44: loss=-0.1858 
[epoch 34] step 22/44: loss=-0.1854 
[epoch 34] step 24/44: loss=-0.1857 
[epoch 34] step 26/44: loss=-0.1860 
[epoch 34] step 28/44: loss=-0.1858 
[epoch 34] step 30/44: loss=-0.1852 
[epoch 34] step 32/44: loss=-0.1856 
[epoch 34] step 34/44: loss=-0.1858 
[epoch 34] step 36/44: loss=-0.1858 
[epoch 34] step 38/44: loss=-0.1860 
[epoch 34] step 40/44: loss=-0.1859 
[epoch 34] step 42/44: loss=-0.1858 
[epoch 34] step 44/44: loss=-0.1859 
[epoch 34] train_loss(avg per step)=-0.3718 lambda[min,max]=[0.501001,1.000000]
[epoch 34] val_loss=1.6405 qwk=('0.2497', '0.2413', '0.3898') averageQWK=0.2936 macroEMD=0.2209 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    8   50   19    1
     0    1   85   74    2
     0    1   34   28    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    4   10    2    0
     0    6   41   19    0
     0    4  120   81    0
     0    1   14   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   16    0    0
     0   14   91    6    0
     0    7  111   63    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=-0.1909 
[epoch 35] step 4/44: loss=-0.1899 
[epoch 35] step 6/44: loss=-0.1895 
[epoch 35] step 8/44: loss=-0.1875 
[epoch 35] step 10/44: loss=-0.1870 
[epoch 35] step 12/44: loss=-0.1872 
[epoch 35] step 14/44: loss=-0.1861 
[epoch 35] step 16/44: loss=-0.1865 
[epoch 35] step 18/44: loss=-0.1865 
[epoch 35] step 20/44: loss=-0.1861 
[epoch 35] step 22/44: loss=-0.1859 
[epoch 35] step 24/44: loss=-0.1863 
[epoch 35] step 26/44: loss=-0.1859 
[epoch 35] step 28/44: loss=-0.1860 
[epoch 35] step 30/44: loss=-0.1858 
[epoch 35] step 32/44: loss=-0.1858 
[epoch 35] step 34/44: loss=-0.1861 
[epoch 35] step 36/44: loss=-0.1864 
[epoch 35] step 38/44: loss=-0.1864 
[epoch 35] step 40/44: loss=-0.1864 
[epoch 35] step 42/44: loss=-0.1866 
[epoch 35] step 44/44: loss=-0.1868 
[epoch 35] train_loss(avg per step)=-0.3737 lambda[min,max]=[0.500950,1.000000]
[epoch 35] val_loss=1.6829 qwk=('0.2449', '0.2257', '0.3795') averageQWK=0.2834 macroEMD=0.2204 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    9   49   19    1
     0    1   86   74    1
     0    1   35   27    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    4   11    1    0
     0    6   44   16    0
     0    4  128   73    0
     0    1   17   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0   14   91    6    0
     0    7  116   58    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-0-conf_gating-0-reassignment-0/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-0-conf_gating-0-reassignment-0/fold0/metrics.json
Done.
