[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.5056 
[epoch 1] step 4/44: loss=0.5119 
[epoch 1] step 6/44: loss=0.5075 
[epoch 1] step 8/44: loss=0.5036 
[epoch 1] step 10/44: loss=0.5127 
[epoch 1] step 12/44: loss=0.5162 
[epoch 1] step 14/44: loss=0.5179 
[epoch 1] step 16/44: loss=0.5225 
[epoch 1] step 18/44: loss=0.5288 
[epoch 1] step 20/44: loss=0.5351 
[epoch 1] step 22/44: loss=0.5394 
[epoch 1] step 24/44: loss=0.5437 
[epoch 1] step 26/44: loss=0.5483 
[epoch 1] step 28/44: loss=0.5513 
[epoch 1] step 30/44: loss=0.5545 
[epoch 1] step 32/44: loss=0.5574 
[epoch 1] step 34/44: loss=0.5601 
[epoch 1] step 36/44: loss=0.5636 
[epoch 1] step 38/44: loss=0.5649 
[epoch 1] step 40/44: loss=0.5663 
[epoch 1] step 42/44: loss=0.5683 
[epoch 1] step 44/44: loss=0.5704 
[epoch 1] train_loss(avg per step)=1.1408 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=0.7886 qwk=('0.0079', '0.1981', '0.0977') averageQWK=0.1012 macroEMD=0.3609 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    8    0
     0    1    0   39    0
     0    7    0  121    0
     0    5    0  117    0
     0    0    0   27    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   34   14    0
     2    0   61   50    0
     1    0   63   84    0
     0    0    3    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   64    0    0
     0    2  149    0    0
     0    0   97    2    0
     0    0    3    0    0
[epoch 2] step 2/44: loss=0.6618 
[epoch 2] step 4/44: loss=0.6935 
[epoch 2] step 6/44: loss=0.7125 
[epoch 2] step 8/44: loss=0.7253 
[epoch 2] step 10/44: loss=0.7482 
[epoch 2] step 12/44: loss=0.7656 
[epoch 2] step 14/44: loss=0.7797 
[epoch 2] step 16/44: loss=0.7930 
[epoch 2] step 18/44: loss=0.7981 
[epoch 2] step 20/44: loss=0.8029 
[epoch 2] step 22/44: loss=0.8052 
[epoch 2] step 24/44: loss=0.8093 
[epoch 2] step 26/44: loss=0.8118 
[epoch 2] step 28/44: loss=0.8132 
[epoch 2] step 30/44: loss=0.8141 
[epoch 2] step 32/44: loss=0.8152 
[epoch 2] step 34/44: loss=0.8155 
[epoch 2] step 36/44: loss=0.8182 
[epoch 2] step 38/44: loss=0.8196 
[epoch 2] step 40/44: loss=0.8223 
[epoch 2] step 42/44: loss=0.8235 
[epoch 2] step 44/44: loss=0.8237 
[epoch 2] train_loss(avg per step)=1.6474 lambda[min,max]=[0.507519,1.000000]
[epoch 2] val_loss=1.4773 qwk=('0.1879', '0.3030', '0.4912') averageQWK=0.3274 macroEMD=0.3486 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    2    0
     0    3    3   34    0
     0    2    0  126    0
     0    0    0  122    0
     0    0    0   27    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   25   23    0
     0    0   28   85    0
     0    0    6  142    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   56    3   12    0
     0   73    6   72    0
     0   12    3   84    0
     0    0    0    3    0
[epoch 3] step 2/44: loss=0.7027 
[epoch 3] step 4/44: loss=0.7087 
[epoch 3] step 6/44: loss=0.7150 
[epoch 3] step 8/44: loss=0.7207 
[epoch 3] step 10/44: loss=0.7363 
[epoch 3] step 12/44: loss=0.7476 
[epoch 3] step 14/44: loss=0.7615 
[epoch 3] step 16/44: loss=0.7699 
[epoch 3] step 18/44: loss=0.7754 
[epoch 3] step 20/44: loss=0.7843 
[epoch 3] step 22/44: loss=0.7857 
[epoch 3] step 24/44: loss=0.7942 
[epoch 3] step 26/44: loss=0.7937 
[epoch 3] step 28/44: loss=0.7950 
[epoch 3] step 30/44: loss=0.7957 
[epoch 3] step 32/44: loss=0.7953 
[epoch 3] step 34/44: loss=0.7953 
[epoch 3] step 36/44: loss=0.7970 
[epoch 3] step 38/44: loss=0.7987 
[epoch 3] step 40/44: loss=0.8008 
[epoch 3] step 42/44: loss=0.8000 
[epoch 3] step 44/44: loss=0.8004 
[epoch 3] train_loss(avg per step)=1.6008 lambda[min,max]=[0.505427,1.000000]
[epoch 3] val_loss=1.4300 qwk=('0.5076', '0.4389', '0.4978') averageQWK=0.4814 macroEMD=0.3245 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   11   28    1    0
     0   12   98   18    0
     0    2   62   58    0
     0    0    5   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0   14   29    5    0
     0   17   71   25    0
     0    9   51   88    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   33   38    0    0
     0   24  121    6    0
     0    1   66   32    0
     0    0    1    2    0
[epoch 4] step 2/44: loss=0.8557 
[epoch 4] step 4/44: loss=0.8463 
[epoch 4] step 6/44: loss=0.8424 
[epoch 4] step 8/44: loss=0.8434 
[epoch 4] step 10/44: loss=0.8421 
[epoch 4] step 12/44: loss=0.8498 
[epoch 4] step 14/44: loss=0.8405 
[epoch 4] step 16/44: loss=0.8327 
[epoch 4] step 18/44: loss=0.8290 
[epoch 4] step 20/44: loss=0.8291 
[epoch 4] step 22/44: loss=0.8263 
[epoch 4] step 24/44: loss=0.8221 
[epoch 4] step 26/44: loss=0.8211 
[epoch 4] step 28/44: loss=0.8192 
[epoch 4] step 30/44: loss=0.8218 
[epoch 4] step 32/44: loss=0.8224 
[epoch 4] step 34/44: loss=0.8215 
[epoch 4] step 36/44: loss=0.8224 
[epoch 4] step 38/44: loss=0.8218 
[epoch 4] step 40/44: loss=0.8196 
[epoch 4] step 42/44: loss=0.8177 
[epoch 4] step 44/44: loss=0.8172 
[epoch 4] train_loss(avg per step)=1.6344 lambda[min,max]=[0.500488,1.000000]
[epoch 4] val_loss=1.4610 qwk=('0.5407', '0.4480', '0.5427') averageQWK=0.5104 macroEMD=0.3178 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   15   25    0    0
     0    9  103   16    0
     0    1   62   59    0
     0    0    6   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2   41    5    0
     0    0   89   24    0
     0    0   62   86    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   29   42    0    0
     0   15  124   12    0
     0    0   55   44    0
     0    0    1    2    0
[epoch 5] step 2/44: loss=0.8430 
[epoch 5] step 4/44: loss=0.8236 
[epoch 5] step 6/44: loss=0.8226 
[epoch 5] step 8/44: loss=0.8107 
[epoch 5] step 10/44: loss=0.8056 
[epoch 5] step 12/44: loss=0.8037 
[epoch 5] step 14/44: loss=0.8000 
[epoch 5] step 16/44: loss=0.8004 
[epoch 5] step 18/44: loss=0.8017 
[epoch 5] step 20/44: loss=0.8041 
[epoch 5] step 22/44: loss=0.8019 
[epoch 5] step 24/44: loss=0.8053 
[epoch 5] step 26/44: loss=0.8037 
[epoch 5] step 28/44: loss=0.8041 
[epoch 5] step 30/44: loss=0.8046 
[epoch 5] step 32/44: loss=0.8028 
[epoch 5] step 34/44: loss=0.8025 
[epoch 5] step 36/44: loss=0.8016 
[epoch 5] step 38/44: loss=0.8001 
[epoch 5] step 40/44: loss=0.8013 
[epoch 5] step 42/44: loss=0.8030 
[epoch 5] step 44/44: loss=0.8033 
[epoch 5] train_loss(avg per step)=1.6066 lambda[min,max]=[0.500057,1.000000]
[epoch 5] val_loss=1.4424 qwk=('0.5277', '0.4979', '0.6061') averageQWK=0.5439 macroEMD=0.3097 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   10   28    2    0
     0    4  102   22    0
     0    0   55   67    0
     0    0    5   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    9   33    6    0
     0    2   81   30    0
     0    0   56   92    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   39   32    0    0
     0   29   93   29    0
     0    1   35   63    0
     0    0    1    2    0
[epoch 6] step 2/44: loss=0.8068 
[epoch 6] step 4/44: loss=0.8061 
[epoch 6] step 6/44: loss=0.8107 
[epoch 6] step 8/44: loss=0.8107 
[epoch 6] step 10/44: loss=0.8166 
[epoch 6] step 12/44: loss=0.8137 
[epoch 6] step 14/44: loss=0.8214 
[epoch 6] step 16/44: loss=0.8237 
[epoch 6] step 18/44: loss=0.8239 
[epoch 6] step 20/44: loss=0.8245 
[epoch 6] step 22/44: loss=0.8282 
[epoch 6] step 24/44: loss=0.8284 
[epoch 6] step 26/44: loss=0.8247 
[epoch 6] step 28/44: loss=0.8199 
[epoch 6] step 30/44: loss=0.8157 
[epoch 6] step 32/44: loss=0.8112 
[epoch 6] step 34/44: loss=0.8096 
[epoch 6] step 36/44: loss=0.8086 
[epoch 6] step 38/44: loss=0.8061 
[epoch 6] step 40/44: loss=0.8046 
[epoch 6] step 42/44: loss=0.8059 
[epoch 6] step 44/44: loss=0.8052 
[epoch 6] train_loss(avg per step)=1.6103 lambda[min,max]=[0.500003,1.000000]
[epoch 6] val_loss=1.4377 qwk=('0.5106', '0.4240', '0.5749') averageQWK=0.5032 macroEMD=0.3019 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    3   30    7    0
     0    0   82   46    0
     0    0   26   96    0
     0    0    1   26    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    1   36   11    0
     0    0   65   48    0
     0    0   29  119    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   49    2    0
     0    2  113   36    0
     0    0   27   72    0
     0    0    1    2    0
[epoch 7] step 2/44: loss=0.8298 
[epoch 7] step 4/44: loss=0.7978 
[epoch 7] step 6/44: loss=0.8026 
[epoch 7] step 8/44: loss=0.7997 
[epoch 7] step 10/44: loss=0.7908 
[epoch 7] step 12/44: loss=0.7836 
[epoch 7] step 14/44: loss=0.7848 
[epoch 7] step 16/44: loss=0.7890 
[epoch 7] step 18/44: loss=0.7916 
[epoch 7] step 20/44: loss=0.7935 
[epoch 7] step 22/44: loss=0.7948 
[epoch 7] step 24/44: loss=0.7938 
[epoch 7] step 26/44: loss=0.7964 
[epoch 7] step 28/44: loss=0.7952 
[epoch 7] step 30/44: loss=0.7951 
[epoch 7] step 32/44: loss=0.7926 
[epoch 7] step 34/44: loss=0.7901 
[epoch 7] step 36/44: loss=0.7903 
[epoch 7] step 38/44: loss=0.7907 
[epoch 7] step 40/44: loss=0.7905 
[epoch 7] step 42/44: loss=0.7913 
[epoch 7] step 44/44: loss=0.7914 
[epoch 7] train_loss(avg per step)=1.5828 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.4526 qwk=('0.5527', '0.5240', '0.5347') averageQWK=0.5371 macroEMD=0.2992 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    9   28    3    0
     0    4   83   41    0
     0    0   36   86    0
     0    0    2   25    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    9   31    8    0
     0    2   66   45    0
     0    0   36  112    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   19   52    0    0
     0    3  129   19    0
     0    0   46   53    0
     0    0    1    2    0
[epoch 8] step 2/44: loss=0.8256 
[epoch 8] step 4/44: loss=0.8001 
[epoch 8] step 6/44: loss=0.7877 
[epoch 8] step 8/44: loss=0.7791 
[epoch 8] step 10/44: loss=0.7669 
[epoch 8] step 12/44: loss=0.7629 
[epoch 8] step 14/44: loss=0.7672 
[epoch 8] step 16/44: loss=0.7711 
[epoch 8] step 18/44: loss=0.7754 
[epoch 8] step 20/44: loss=0.7787 
[epoch 8] step 22/44: loss=0.7791 
[epoch 8] step 24/44: loss=0.7820 
[epoch 8] step 26/44: loss=0.7851 
[epoch 8] step 28/44: loss=0.7870 
[epoch 8] step 30/44: loss=0.7872 
[epoch 8] step 32/44: loss=0.7879 
[epoch 8] step 34/44: loss=0.7884 
[epoch 8] step 36/44: loss=0.7877 
[epoch 8] step 38/44: loss=0.7881 
[epoch 8] step 40/44: loss=0.7880 
[epoch 8] step 42/44: loss=0.7891 
[epoch 8] step 44/44: loss=0.7902 
[epoch 8] train_loss(avg per step)=1.5804 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.4760 qwk=('0.5428', '0.5273', '0.5572') averageQWK=0.5424 macroEMD=0.3001 tailR0=('0.0185', '0.0000', '0.0000') tailR0avg=0.0062
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   16   22    2    0
     0   11   93   24    0
     0    3   47   70    2
     0    0    6   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   10   33    5    0
     0    4   77   32    0
     0    0   53   95    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   30   41    0    0
     0   19  114   18    0
     0    1   46   52    0
     0    0    1    2    0
[epoch 9] step 2/44: loss=0.7538 
[epoch 9] step 4/44: loss=0.7394 
[epoch 9] step 6/44: loss=0.7448 
[epoch 9] step 8/44: loss=0.7535 
[epoch 9] step 10/44: loss=0.7628 
[epoch 9] step 12/44: loss=0.7648 
[epoch 9] step 14/44: loss=0.7619 
[epoch 9] step 16/44: loss=0.7638 
[epoch 9] step 18/44: loss=0.7625 
[epoch 9] step 20/44: loss=0.7659 
[epoch 9] step 22/44: loss=0.7647 
[epoch 9] step 24/44: loss=0.7639 
[epoch 9] step 26/44: loss=0.7638 
[epoch 9] step 28/44: loss=0.7633 
[epoch 9] step 30/44: loss=0.7640 
[epoch 9] step 32/44: loss=0.7629 
[epoch 9] step 34/44: loss=0.7623 
[epoch 9] step 36/44: loss=0.7614 
[epoch 9] step 38/44: loss=0.7608 
[epoch 9] step 40/44: loss=0.7615 
[epoch 9] step 42/44: loss=0.7611 
[epoch 9] step 44/44: loss=0.7604 
[epoch 9] train_loss(avg per step)=1.5207 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.4394 qwk=('0.5754', '0.5137', '0.5805') averageQWK=0.5566 macroEMD=0.2919 tailR0=('0.0556', '0.0000', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    9   26    5    0
     0    7   76   45    0
     0    2   24   95    1
     0    0    0   24    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   13   24   11    0
     0    6   55   52    0
     0    0   29  119    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   38    2    0
     0   16  101   34    0
     0    1   31   67    0
     0    0    1    2    0
[epoch 10] step 2/44: loss=0.7808 
[epoch 10] step 4/44: loss=0.7683 
[epoch 10] step 6/44: loss=0.7646 
[epoch 10] step 8/44: loss=0.7615 
[epoch 10] step 10/44: loss=0.7642 
[epoch 10] step 12/44: loss=0.7660 
[epoch 10] step 14/44: loss=0.7658 
[epoch 10] step 16/44: loss=0.7625 
[epoch 10] step 18/44: loss=0.7600 
[epoch 10] step 20/44: loss=0.7584 
[epoch 10] step 22/44: loss=0.7543 
[epoch 10] step 24/44: loss=0.7519 
[epoch 10] step 26/44: loss=0.7495 
[epoch 10] step 28/44: loss=0.7516 
[epoch 10] step 30/44: loss=0.7537 
[epoch 10] step 32/44: loss=0.7550 
[epoch 10] step 34/44: loss=0.7539 
[epoch 10] step 36/44: loss=0.7542 
[epoch 10] step 38/44: loss=0.7530 
[epoch 10] step 40/44: loss=0.7517 
[epoch 10] step 42/44: loss=0.7511 
[epoch 10] step 44/44: loss=0.7512 
[epoch 10] train_loss(avg per step)=1.5024 lambda[min,max]=[0.480993,1.000000]
[epoch 10] val_loss=1.4410 qwk=('0.5289', '0.5024', '0.5657') averageQWK=0.5323 macroEMD=0.2922 tailR0=('0.0185', '0.0000', '0.0000') tailR0avg=0.0062
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    6   29    5    0
     0    3   81   44    0
     0    0   33   89    0
     0    0    1   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    9   31    8    0
     0    5   69   39    0
     0    0   43  105    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   30   39    2    0
     0   18  106   27    0
     0    0   39   60    0
     0    0    1    2    0
[epoch 11] step 2/44: loss=0.7185 
[epoch 11] step 4/44: loss=0.7112 
[epoch 11] step 6/44: loss=0.7040 
[epoch 11] step 8/44: loss=0.6980 
[epoch 11] step 10/44: loss=0.7103 
[epoch 11] step 12/44: loss=0.7109 
[epoch 11] step 14/44: loss=0.7116 
[epoch 11] step 16/44: loss=0.7119 
[epoch 11] step 18/44: loss=0.7200 
[epoch 11] step 20/44: loss=0.7255 
[epoch 11] step 22/44: loss=0.7288 
[epoch 11] step 24/44: loss=0.7311 
[epoch 11] step 26/44: loss=0.7335 
[epoch 11] step 28/44: loss=0.7344 
[epoch 11] step 30/44: loss=0.7362 
[epoch 11] step 32/44: loss=0.7353 
[epoch 11] step 34/44: loss=0.7338 
[epoch 11] step 36/44: loss=0.7345 
[epoch 11] step 38/44: loss=0.7339 
[epoch 11] step 40/44: loss=0.7348 
[epoch 11] step 42/44: loss=0.7370 
[epoch 11] step 44/44: loss=0.7390 
[epoch 11] train_loss(avg per step)=1.4779 lambda[min,max]=[0.432107,1.000000]
[epoch 11] val_loss=1.4456 qwk=('0.5013', '0.4753', '0.5332') averageQWK=0.5033 macroEMD=0.2978 tailR0=('0.0556', '0.0000', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    0    0
     0    4   32    4    0
     0    2   97   29    0
     0    0   45   77    0
     0    0    4   20    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    6   34    8    0
     0    2   76   35    0
     0    0   46  102    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   47    0    0
     0    8  121   22    0
     0    0   49   50    0
     0    0    1    2    0
[epoch 12] step 2/44: loss=0.7228 
[epoch 12] step 4/44: loss=0.7110 
[epoch 12] step 6/44: loss=0.7194 
[epoch 12] step 8/44: loss=0.7304 
[epoch 12] step 10/44: loss=0.7327 
[epoch 12] step 12/44: loss=0.7407 
[epoch 12] step 14/44: loss=0.7387 
[epoch 12] step 16/44: loss=0.7375 
[epoch 12] step 18/44: loss=0.7401 
[epoch 12] step 20/44: loss=0.7369 
[epoch 12] step 22/44: loss=0.7402 
[epoch 12] step 24/44: loss=0.7367 
[epoch 12] step 26/44: loss=0.7333 
[epoch 12] step 28/44: loss=0.7290 
[epoch 12] step 30/44: loss=0.7265 
[epoch 12] step 32/44: loss=0.7233 
[epoch 12] step 34/44: loss=0.7205 
[epoch 12] step 36/44: loss=0.7186 
[epoch 12] step 38/44: loss=0.7213 
[epoch 12] step 40/44: loss=0.7212 
[epoch 12] step 42/44: loss=0.7245 
[epoch 12] step 44/44: loss=0.7243 
[epoch 12] train_loss(avg per step)=1.4486 lambda[min,max]=[0.441751,1.000000]
[epoch 12] val_loss=1.4618 qwk=('0.5519', '0.4821', '0.5348') averageQWK=0.5229 macroEMD=0.2912 tailR0=('0.0556', '0.0000', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    9   25    6    0
     0    5   80   43    0
     0    3   26   92    1
     0    0    1   23    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   14   22   12    0
     0    7   52   54    0
     0    3   28  117    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   44    3    0
     0    9  116   26    0
     0    1   38   60    0
     0    0    1    2    0
[epoch 13] step 2/44: loss=0.7264 
[epoch 13] step 4/44: loss=0.7303 
[epoch 13] step 6/44: loss=0.7265 
[epoch 13] step 8/44: loss=0.7196 
[epoch 13] step 10/44: loss=0.7095 
[epoch 13] step 12/44: loss=0.7086 
[epoch 13] step 14/44: loss=0.7096 
[epoch 13] step 16/44: loss=0.7063 
[epoch 13] step 18/44: loss=0.7097 
[epoch 13] step 20/44: loss=0.7096 
[epoch 13] step 22/44: loss=0.7107 
[epoch 13] step 24/44: loss=0.7104 
[epoch 13] step 26/44: loss=0.7101 
[epoch 13] step 28/44: loss=0.7094 
[epoch 13] step 30/44: loss=0.7066 
[epoch 13] step 32/44: loss=0.7066 
[epoch 13] step 34/44: loss=0.7077 
[epoch 13] step 36/44: loss=0.7083 
[epoch 13] step 38/44: loss=0.7093 
[epoch 13] step 40/44: loss=0.7102 
[epoch 13] step 42/44: loss=0.7077 
[epoch 13] step 44/44: loss=0.7078 
[epoch 13] train_loss(avg per step)=1.4155 lambda[min,max]=[0.396111,1.000000]
[epoch 13] val_loss=1.4405 qwk=('0.5052', '0.5030', '0.5322') averageQWK=0.5135 macroEMD=0.3004 tailR0=('0.0556', '0.0000', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    0    0
     0    4   32    4    0
     0    1   93   33    1
     0    0   44   77    1
     0    0    2   22    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1    4   37    6    0
     0    1   85   27    0
     0    0   48  100    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   29   42    0    0
     0   14  120   17    0
     0    1   50   48    0
     0    0    2    1    0
[epoch 14] step 2/44: loss=0.6964 
[epoch 14] step 4/44: loss=0.7090 
[epoch 14] step 6/44: loss=0.7121 
[epoch 14] step 8/44: loss=0.7100 
[epoch 14] step 10/44: loss=0.7141 
[epoch 14] step 12/44: loss=0.7145 
[epoch 14] step 14/44: loss=0.7175 
[epoch 14] step 16/44: loss=0.7105 
[epoch 14] step 18/44: loss=0.7067 
[epoch 14] step 20/44: loss=0.7031 
[epoch 14] step 22/44: loss=0.7008 
[epoch 14] step 24/44: loss=0.6984 
[epoch 14] step 26/44: loss=0.6980 
[epoch 14] step 28/44: loss=0.6983 
[epoch 14] step 30/44: loss=0.7000 
[epoch 14] step 32/44: loss=0.7009 
[epoch 14] step 34/44: loss=0.6977 
[epoch 14] step 36/44: loss=0.6952 
[epoch 14] step 38/44: loss=0.6961 
[epoch 14] step 40/44: loss=0.6956 
[epoch 14] step 42/44: loss=0.6960 
[epoch 14] step 44/44: loss=0.6947 
[epoch 14] train_loss(avg per step)=1.3894 lambda[min,max]=[0.418986,1.000000]
[epoch 14] val_loss=1.4659 qwk=('0.4772', '0.4667', '0.5236') averageQWK=0.4892 macroEMD=0.2920 tailR0=('0.0741', '0.0000', '0.0000') tailR0avg=0.0247
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    1    0
     0    7   25    8    0
     0    3   69   55    1
     0    2   26   92    2
     0    0    1   22    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    8   29   11    0
     0    3   63   47    0
     0    0   36  112    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   47    0    0
     0    8  125   18    0
     0    1   50   48    0
     0    0    1    2    0
[epoch 15] step 2/44: loss=0.7046 
[epoch 15] step 4/44: loss=0.7138 
[epoch 15] step 6/44: loss=0.7208 
[epoch 15] step 8/44: loss=0.7171 
[epoch 15] step 10/44: loss=0.7156 
[epoch 15] step 12/44: loss=0.7184 
[epoch 15] step 14/44: loss=0.7114 
[epoch 15] step 16/44: loss=0.7032 
[epoch 15] step 18/44: loss=0.6969 
[epoch 15] step 20/44: loss=0.6910 
[epoch 15] step 22/44: loss=0.6890 
[epoch 15] step 24/44: loss=0.6880 
[epoch 15] step 26/44: loss=0.6852 
[epoch 15] step 28/44: loss=0.6854 
[epoch 15] step 30/44: loss=0.6874 
[epoch 15] step 32/44: loss=0.6918 
[epoch 15] step 34/44: loss=0.6948 
[epoch 15] step 36/44: loss=0.6922 
[epoch 15] step 38/44: loss=0.6917 
[epoch 15] step 40/44: loss=0.6921 
[epoch 15] step 42/44: loss=0.6907 
[epoch 15] step 44/44: loss=0.6892 
[epoch 15] train_loss(avg per step)=1.3784 lambda[min,max]=[0.412143,1.000000]
[epoch 15] val_loss=1.4598 qwk=('0.5476', '0.5027', '0.5441') averageQWK=0.5315 macroEMD=0.2959 tailR0=('0.1296', '0.1000', '0.0000') tailR0avg=0.0765
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    9   25    6    0
     0    4   81   41    2
     0    1   34   84    3
     0    0    1   19    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0   10   30    8    0
     1    4   77   31    0
     0    1   47   98    2
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   38    2    0
     0   13  117   21    0
     0    2   44   53    0
     0    0    1    2    0
[epoch 16] step 2/44: loss=0.6728 
[epoch 16] step 4/44: loss=0.6870 
[epoch 16] step 6/44: loss=0.6953 
[epoch 16] step 8/44: loss=0.6944 
[epoch 16] step 10/44: loss=0.6916 
[epoch 16] step 12/44: loss=0.6832 
[epoch 16] step 14/44: loss=0.6837 
[epoch 16] step 16/44: loss=0.6808 
[epoch 16] step 18/44: loss=0.6789 
[epoch 16] step 20/44: loss=0.6777 
[epoch 16] step 22/44: loss=0.6763 
[epoch 16] step 24/44: loss=0.6773 
[epoch 16] step 26/44: loss=0.6750 
[epoch 16] step 28/44: loss=0.6740 
[epoch 16] step 30/44: loss=0.6743 
[epoch 16] step 32/44: loss=0.6737 
[epoch 16] step 34/44: loss=0.6716 
[epoch 16] step 36/44: loss=0.6725 
[epoch 16] step 38/44: loss=0.6721 
[epoch 16] step 40/44: loss=0.6740 
[epoch 16] step 42/44: loss=0.6742 
[epoch 16] step 44/44: loss=0.6740 
[epoch 16] train_loss(avg per step)=1.3481 lambda[min,max]=[0.374860,1.000000]
[epoch 16] val_loss=1.4648 qwk=('0.5189', '0.4800', '0.4853') averageQWK=0.4947 macroEMD=0.2929 tailR0=('0.1481', '0.0500', '0.0000') tailR0avg=0.0660
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    1    0
     0   10   22    8    0
     0    7   63   54    4
     0    2   23   91    6
     0    0    0   19    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    9   28   11    0
     1    5   61   46    0
     0    0   35  113    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   46    7    0
     0    8  101   42    0
     0    1   28   70    0
     0    0    1    2    0
[epoch 17] step 2/44: loss=0.6584 
[epoch 17] step 4/44: loss=0.6502 
[epoch 17] step 6/44: loss=0.6452 
[epoch 17] step 8/44: loss=0.6537 
[epoch 17] step 10/44: loss=0.6563 
[epoch 17] step 12/44: loss=0.6657 
[epoch 17] step 14/44: loss=0.6720 
[epoch 17] step 16/44: loss=0.6726 
[epoch 17] step 18/44: loss=0.6673 
[epoch 17] step 20/44: loss=0.6643 
[epoch 17] step 22/44: loss=0.6603 
[epoch 17] step 24/44: loss=0.6584 
[epoch 17] step 26/44: loss=0.6559 
[epoch 17] step 28/44: loss=0.6530 
[epoch 17] step 30/44: loss=0.6515 
[epoch 17] step 32/44: loss=0.6508 
[epoch 17] step 34/44: loss=0.6514 
[epoch 17] step 36/44: loss=0.6506 
[epoch 17] step 38/44: loss=0.6521 
[epoch 17] step 40/44: loss=0.6528 
[epoch 17] step 42/44: loss=0.6536 
[epoch 17] step 44/44: loss=0.6558 
[epoch 17] train_loss(avg per step)=1.3116 lambda[min,max]=[0.406724,1.000000]
[epoch 17] val_loss=1.4607 qwk=('0.4730', '0.4759', '0.5043') averageQWK=0.4844 macroEMD=0.2923 tailR0=('0.1111', '0.1000', '0.0000') tailR0avg=0.0704
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    1    0
     0    9   24    7    0
     0    6   63   48   11
     0    3   23   89    7
     0    0    0   21    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1    7   27   12    1
     1    4   57   51    0
     0    1   26  120    1
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   46    3    0
     0   10  119   22    0
     0    2   41   56    0
     0    0    1    2    0
[epoch 18] step 2/44: loss=0.6560 
[epoch 18] step 4/44: loss=0.6508 
[epoch 18] step 6/44: loss=0.6518 
[epoch 18] step 8/44: loss=0.6409 
[epoch 18] step 10/44: loss=0.6305 
[epoch 18] step 12/44: loss=0.6320 
[epoch 18] step 14/44: loss=0.6267 
[epoch 18] step 16/44: loss=0.6241 
[epoch 18] step 18/44: loss=0.6230 
[epoch 18] step 20/44: loss=0.6230 
[epoch 18] step 22/44: loss=0.6219 
[epoch 18] step 24/44: loss=0.6272 
[epoch 18] step 26/44: loss=0.6320 
[epoch 18] step 28/44: loss=0.6349 
[epoch 18] step 30/44: loss=0.6375 
[epoch 18] step 32/44: loss=0.6369 
[epoch 18] step 34/44: loss=0.6362 
[epoch 18] step 36/44: loss=0.6348 
[epoch 18] step 38/44: loss=0.6323 
[epoch 18] step 40/44: loss=0.6312 
[epoch 18] step 42/44: loss=0.6305 
[epoch 18] step 44/44: loss=0.6312 
[epoch 18] train_loss(avg per step)=1.2624 lambda[min,max]=[0.404760,1.000000]
[epoch 18] val_loss=1.4142 qwk=('0.5594', '0.5244', '0.5327') averageQWK=0.5388 macroEMD=0.2896 tailR0=('0.0926', '0.1000', '0.0000') tailR0avg=0.0642
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0   10   27    3    0
     0    6   90   30    2
     0    1   41   78    2
     0    0    2   20    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0   11   29    8    0
     1   10   65   37    0
     0    1   39  108    0
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   32   38    1    0
     0   27  105   19    0
     0    2   46   51    0
     0    0    1    2    0
[epoch 19] step 2/44: loss=0.6512 
[epoch 19] step 4/44: loss=0.6419 
[epoch 19] step 6/44: loss=0.6425 
[epoch 19] step 8/44: loss=0.6437 
[epoch 19] step 10/44: loss=0.6457 
[epoch 19] step 12/44: loss=0.6432 
[epoch 19] step 14/44: loss=0.6385 
[epoch 19] step 16/44: loss=0.6366 
[epoch 19] step 18/44: loss=0.6354 
[epoch 19] step 20/44: loss=0.6338 
[epoch 19] step 22/44: loss=0.6327 
[epoch 19] step 24/44: loss=0.6341 
[epoch 19] step 26/44: loss=0.6348 
[epoch 19] step 28/44: loss=0.6335 
[epoch 19] step 30/44: loss=0.6341 
[epoch 19] step 32/44: loss=0.6325 
[epoch 19] step 34/44: loss=0.6309 
[epoch 19] step 36/44: loss=0.6315 
[epoch 19] step 38/44: loss=0.6318 
[epoch 19] step 40/44: loss=0.6324 
[epoch 19] step 42/44: loss=0.6313 
[epoch 19] step 44/44: loss=0.6311 
[epoch 19] train_loss(avg per step)=1.2621 lambda[min,max]=[0.401895,1.000000]
[epoch 19] val_loss=1.4384 qwk=('0.5238', '0.4564', '0.4969') averageQWK=0.4924 macroEMD=0.2937 tailR0=('0.1667', '0.0500', '0.0000') tailR0avg=0.0722
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    8   27    5    0
     0    3   82   36    7
     0    1   39   76    6
     0    0    1   17    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1    4   28   15    0
     1    3   56   53    0
     0    0   25  123    0
     0    0    0    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   51    2    0
     0    7  114   30    0
     0    1   40   58    0
     0    0    1    2    0
[epoch 20] step 2/44: loss=0.5981 
[epoch 20] step 4/44: loss=0.6263 
[epoch 20] step 6/44: loss=0.6176 
[epoch 20] step 8/44: loss=0.6161 
[epoch 20] step 10/44: loss=0.6103 
[epoch 20] step 12/44: loss=0.6124 
[epoch 20] step 14/44: loss=0.6010 
[epoch 20] step 16/44: loss=0.6042 
[epoch 20] step 18/44: loss=0.6132 
[epoch 20] step 20/44: loss=0.6128 
[epoch 20] step 22/44: loss=0.6106 
[epoch 20] step 24/44: loss=0.6127 
[epoch 20] step 26/44: loss=0.6124 
[epoch 20] step 28/44: loss=0.6148 
[epoch 20] step 30/44: loss=0.6153 
[epoch 20] step 32/44: loss=0.6164 
[epoch 20] step 34/44: loss=0.6138 
[epoch 20] step 36/44: loss=0.6166 
[epoch 20] step 38/44: loss=0.6186 
[epoch 20] step 40/44: loss=0.6177 
[epoch 20] step 42/44: loss=0.6193 
[epoch 20] step 44/44: loss=0.6192 
[epoch 20] train_loss(avg per step)=1.2385 lambda[min,max]=[0.392060,1.000000]
[epoch 20] val_loss=1.4482 qwk=('0.5003', '0.4817', '0.4599') averageQWK=0.4806 macroEMD=0.2916 tailR0=('0.0556', '0.1000', '0.0000') tailR0avg=0.0519
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    1    0
     0    7   26    7    0
     0    2   80   43    3
     0    1   26   93    2
     0    0    1   23    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1    6   29   12    0
     1    3   67   42    0
     0    2   32  112    2
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    7   60    4    0
     0    2  121   28    0
     0    0   36   63    0
     0    0    1    2    0
[epoch 21] step 2/44: loss=0.6355 
[epoch 21] step 4/44: loss=0.5942 
[epoch 21] step 6/44: loss=0.5805 
[epoch 21] step 8/44: loss=0.5752 
[epoch 21] step 10/44: loss=0.5764 
[epoch 21] step 12/44: loss=0.5715 
[epoch 21] step 14/44: loss=0.5765 
[epoch 21] step 16/44: loss=0.5824 
[epoch 21] step 18/44: loss=0.5937 
[epoch 21] step 20/44: loss=0.6025 
[epoch 21] step 22/44: loss=0.6021 
[epoch 21] step 24/44: loss=0.6055 
[epoch 21] step 26/44: loss=0.6083 
[epoch 21] step 28/44: loss=0.6121 
[epoch 21] step 30/44: loss=0.6125 
[epoch 21] step 32/44: loss=0.6134 
[epoch 21] step 34/44: loss=0.6123 
[epoch 21] step 36/44: loss=0.6102 
[epoch 21] step 38/44: loss=0.6084 
[epoch 21] step 40/44: loss=0.6087 
[epoch 21] step 42/44: loss=0.6052 
[epoch 21] step 44/44: loss=0.6038 
[epoch 21] train_loss(avg per step)=1.2076 lambda[min,max]=[0.360668,1.000000]
[epoch 21] val_loss=1.4349 qwk=('0.4984', '0.4770', '0.4473') averageQWK=0.4742 macroEMD=0.2911 tailR0=('0.1181', '0.1000', '0.0000') tailR0avg=0.0727
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    1    0
     0    8   24    8    0
     0    3   72   51    2
     0    2   25   93    2
     0    0    1   23    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1    9   23   15    0
     1    8   55   49    0
     0    1   28  119    0
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   58    1    0
     0    2  124   25    0
     0    1   48   50    0
     0    0    1    2    0
[epoch 22] step 2/44: loss=0.6437 
[epoch 22] step 4/44: loss=0.6350 
[epoch 22] step 6/44: loss=0.6159 
[epoch 22] step 8/44: loss=0.5970 
[epoch 22] step 10/44: loss=0.5931 
[epoch 22] step 12/44: loss=0.5949 
[epoch 22] step 14/44: loss=0.5936 
[epoch 22] step 16/44: loss=0.5981 
[epoch 22] step 18/44: loss=0.5967 
[epoch 22] step 20/44: loss=0.6006 
[epoch 22] step 22/44: loss=0.6014 
[epoch 22] step 24/44: loss=0.5975 
[epoch 22] step 26/44: loss=0.5939 
[epoch 22] step 28/44: loss=0.5928 
[epoch 22] step 30/44: loss=0.5914 
[epoch 22] step 32/44: loss=0.5932 
[epoch 22] step 34/44: loss=0.5973 
[epoch 22] step 36/44: loss=0.5980 
[epoch 22] step 38/44: loss=0.5974 
[epoch 22] step 40/44: loss=0.5980 
[epoch 22] step 42/44: loss=0.5966 
[epoch 22] step 44/44: loss=0.5953 
[epoch 22] train_loss(avg per step)=1.1906 lambda[min,max]=[0.358367,1.000000]
[epoch 22] val_loss=1.4336 qwk=('0.4742', '0.4487', '0.5106') averageQWK=0.4778 macroEMD=0.2921 tailR0=('0.2847', '0.1000', '0.0000') tailR0avg=0.1282
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     2    5   28    3    2
     0    2   90   25   11
     0    0   53   61    8
     0    0    4   11   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1    6   29   11    1
     1    7   64   41    0
     0    2   37  106    3
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   47    2    0
     0    7  117   27    0
     0    1   43   55    0
     0    0    1    2    0
[epoch 23] step 2/44: loss=0.6102 
[epoch 23] step 4/44: loss=0.5938 
[epoch 23] step 6/44: loss=0.5931 
[epoch 23] step 8/44: loss=0.5911 
[epoch 23] step 10/44: loss=0.5957 
[epoch 23] step 12/44: loss=0.6040 
[epoch 23] step 14/44: loss=0.6042 
[epoch 23] step 16/44: loss=0.6029 
[epoch 23] step 18/44: loss=0.5987 
[epoch 23] step 20/44: loss=0.5964 
[epoch 23] step 22/44: loss=0.5938 
[epoch 23] step 24/44: loss=0.5904 
[epoch 23] step 26/44: loss=0.5891 
[epoch 23] step 28/44: loss=0.5909 
[epoch 23] step 30/44: loss=0.5954 
[epoch 23] step 32/44: loss=0.5955 
[epoch 23] step 34/44: loss=0.5947 
[epoch 23] step 36/44: loss=0.5956 
[epoch 23] step 38/44: loss=0.5962 
[epoch 23] step 40/44: loss=0.5944 
[epoch 23] step 42/44: loss=0.5918 
[epoch 23] step 44/44: loss=0.5903 
[epoch 23] train_loss(avg per step)=1.1806 lambda[min,max]=[0.365581,1.000000]
[epoch 23] val_loss=1.4203 qwk=('0.5086', '0.4547', '0.4877') averageQWK=0.4837 macroEMD=0.2969 tailR0=('0.2292', '0.1833', '0.0000') tailR0avg=0.1375
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     1    3   30    6    0
     0    1   89   33    5
     0    0   43   73    6
     0    0    2   16    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1    3   35    8    1
     1    2   79   31    0
     1    0   47   99    1
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   49    2    0
     0    8  118   25    0
     0    1   46   52    0
     0    0    1    2    0
[epoch 24] step 2/44: loss=0.5543 
[epoch 24] step 4/44: loss=0.5513 
[epoch 24] step 6/44: loss=0.5640 
[epoch 24] step 8/44: loss=0.5731 
[epoch 24] step 10/44: loss=0.5901 
[epoch 24] step 12/44: loss=0.5926 
[epoch 24] step 14/44: loss=0.5953 
[epoch 24] step 16/44: loss=0.5982 
[epoch 24] step 18/44: loss=0.5975 
[epoch 24] step 20/44: loss=0.5917 
[epoch 24] step 22/44: loss=0.5904 
[epoch 24] step 24/44: loss=0.5851 
[epoch 24] step 26/44: loss=0.5861 
[epoch 24] step 28/44: loss=0.5852 
[epoch 24] step 30/44: loss=0.5844 
[epoch 24] step 32/44: loss=0.5828 
[epoch 24] step 34/44: loss=0.5817 
[epoch 24] step 36/44: loss=0.5816 
[epoch 24] step 38/44: loss=0.5821 
[epoch 24] step 40/44: loss=0.5817 
[epoch 24] step 42/44: loss=0.5811 
[epoch 24] step 44/44: loss=0.5839 
[epoch 24] train_loss(avg per step)=1.1678 lambda[min,max]=[0.364404,1.000000]
[epoch 24] val_loss=1.4285 qwk=('0.5188', '0.5031', '0.5080') averageQWK=0.5099 macroEMD=0.2937 tailR0=('0.2292', '0.1000', '0.0000') tailR0avg=0.1097
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    8   28    4    0
     0    5   89   28    6
     0    1   46   69    6
     0    0    4   14    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1    6   36    5    0
     1    7   78   27    0
     1    1   47   97    2
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   50    1    0
     0    7  119   25    0
     0    1   44   54    0
     0    0    1    2    0
[epoch 25] step 2/44: loss=0.5973 
[epoch 25] step 4/44: loss=0.5908 
[epoch 25] step 6/44: loss=0.5802 
[epoch 25] step 8/44: loss=0.5750 
[epoch 25] step 10/44: loss=0.5762 
[epoch 25] step 12/44: loss=0.5712 
[epoch 25] step 14/44: loss=0.5695 
[epoch 25] step 16/44: loss=0.5763 
[epoch 25] step 18/44: loss=0.5794 
[epoch 25] step 20/44: loss=0.5807 
[epoch 25] step 22/44: loss=0.5802 
[epoch 25] step 24/44: loss=0.5763 
[epoch 25] step 26/44: loss=0.5758 
[epoch 25] step 28/44: loss=0.5768 
[epoch 25] step 30/44: loss=0.5749 
[epoch 25] step 32/44: loss=0.5754 
[epoch 25] step 34/44: loss=0.5750 
[epoch 25] step 36/44: loss=0.5726 
[epoch 25] step 38/44: loss=0.5708 
[epoch 25] step 40/44: loss=0.5684 
[epoch 25] step 42/44: loss=0.5693 
[epoch 25] step 44/44: loss=0.5709 
[epoch 25] train_loss(avg per step)=1.1417 lambda[min,max]=[0.376409,1.000000]
[epoch 25] val_loss=1.4245 qwk=('0.4874', '0.4673', '0.5188') averageQWK=0.4912 macroEMD=0.2905 tailR0=('0.2662', '0.1000', '0.0000') tailR0avg=0.1221
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     1    4   30    4    1
     0    3   86   27   12
     0    0   46   68    8
     0    0    1   15   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1    7   27   13    0
     1    7   58   47    0
     1    1   29  116    1
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   48    3    0
     0    7  110   34    0
     0    1   34   64    0
     0    0    1    2    0
[epoch 26] step 2/44: loss=0.6158 
[epoch 26] step 4/44: loss=0.6046 
[epoch 26] step 6/44: loss=0.6036 
[epoch 26] step 8/44: loss=0.6075 
[epoch 26] step 10/44: loss=0.6050 
[epoch 26] step 12/44: loss=0.6072 
[epoch 26] step 14/44: loss=0.6008 
[epoch 26] step 16/44: loss=0.5907 
[epoch 26] step 18/44: loss=0.5828 
[epoch 26] step 20/44: loss=0.5780 
[epoch 26] step 22/44: loss=0.5730 
[epoch 26] step 24/44: loss=0.5686 
[epoch 26] step 26/44: loss=0.5660 
[epoch 26] step 28/44: loss=0.5642 
[epoch 26] step 30/44: loss=0.5655 
[epoch 26] step 32/44: loss=0.5662 
[epoch 26] step 34/44: loss=0.5692 
[epoch 26] step 36/44: loss=0.5743 
[epoch 26] step 38/44: loss=0.5776 
[epoch 26] step 40/44: loss=0.5775 
[epoch 26] step 42/44: loss=0.5759 
[epoch 26] step 44/44: loss=0.5753 
[epoch 26] train_loss(avg per step)=1.1505 lambda[min,max]=[0.357499,1.000000]
[epoch 26] val_loss=1.4419 qwk=('0.5342', '0.4544', '0.5458') averageQWK=0.5115 macroEMD=0.2945 tailR0=('0.1921', '0.0000', '0.0000') tailR0avg=0.0640
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     1    4   30    5    0
     0    3   88   33    4
     0    0   39   80    3
     0    0    1   19    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1    7   25   15    0
     1    7   51   54    0
     0    2   22  124    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   40    0    0
     0   18  115   18    0
     0    1   50   48    0
     0    0    1    2    0
[epoch 27] step 2/44: loss=0.5410 
[epoch 27] step 4/44: loss=0.5335 
[epoch 27] step 6/44: loss=0.5443 
[epoch 27] step 8/44: loss=0.5557 
[epoch 27] step 10/44: loss=0.5680 
[epoch 27] step 12/44: loss=0.5659 
[epoch 27] step 14/44: loss=0.5647 
[epoch 27] step 16/44: loss=0.5605 
[epoch 27] step 18/44: loss=0.5626 
[epoch 27] step 20/44: loss=0.5641 
[epoch 27] step 22/44: loss=0.5658 
[epoch 27] step 24/44: loss=0.5655 
[epoch 27] step 26/44: loss=0.5663 
[epoch 27] step 28/44: loss=0.5660 
[epoch 27] step 30/44: loss=0.5688 
[epoch 27] step 32/44: loss=0.5696 
[epoch 27] step 34/44: loss=0.5687 
[epoch 27] step 36/44: loss=0.5700 
[epoch 27] step 38/44: loss=0.5705 
[epoch 27] step 40/44: loss=0.5724 
[epoch 27] step 42/44: loss=0.5712 
[epoch 27] step 44/44: loss=0.5710 
[epoch 27] train_loss(avg per step)=1.1420 lambda[min,max]=[0.359778,1.000000]
[epoch 27] val_loss=1.4392 qwk=('0.5228', '0.4890', '0.5043') averageQWK=0.5054 macroEMD=0.2944 tailR0=('0.2106', '0.1000', '0.0000') tailR0avg=0.1035
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     0    6   28    6    0
     0    3   84   35    6
     0    1   34   82    5
     0    0    1   18    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1    7   29   11    0
     1    6   64   42    0
     0    1   36  110    1
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   21   48    2    0
     0   10  111   30    0
     0    1   41   57    0
     0    0    1    2    0
[epoch 28] step 2/44: loss=0.5772 
[epoch 28] step 4/44: loss=0.5526 
[epoch 28] step 6/44: loss=0.5585 
[epoch 28] step 8/44: loss=0.5477 
[epoch 28] step 10/44: loss=0.5527 
[epoch 28] step 12/44: loss=0.5493 
[epoch 28] step 14/44: loss=0.5469 
[epoch 28] step 16/44: loss=0.5493 
[epoch 28] step 18/44: loss=0.5533 
[epoch 28] step 20/44: loss=0.5501 
[epoch 28] step 22/44: loss=0.5531 
[epoch 28] step 24/44: loss=0.5540 
[epoch 28] step 26/44: loss=0.5533 
[epoch 28] step 28/44: loss=0.5535 
[epoch 28] step 30/44: loss=0.5555 
[epoch 28] step 32/44: loss=0.5546 
[epoch 28] step 34/44: loss=0.5545 
[epoch 28] step 36/44: loss=0.5584 
[epoch 28] step 38/44: loss=0.5605 
[epoch 28] step 40/44: loss=0.5613 
[epoch 28] step 42/44: loss=0.5618 
[epoch 28] step 44/44: loss=0.5643 
[epoch 28] train_loss(avg per step)=1.1286 lambda[min,max]=[0.367300,1.000000]
[epoch 28] val_loss=1.4420 qwk=('0.5205', '0.4788', '0.4821') averageQWK=0.4938 macroEMD=0.2931 tailR0=('0.2106', '0.1000', '0.0000') tailR0avg=0.1035
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     1    5   28    6    0
     0    3   84   37    4
     0    1   36   82    3
     0    0    2   17    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    7   31   10    0
     1    7   64   41    0
     0    2   37  108    1
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   52    1    0
     0    7  124   20    0
     0    1   49   49    0
     0    0    1    2    0
[epoch 29] step 2/44: loss=0.5780 
[epoch 29] step 4/44: loss=0.5717 
[epoch 29] step 6/44: loss=0.5725 
[epoch 29] step 8/44: loss=0.5664 
[epoch 29] step 10/44: loss=0.5596 
[epoch 29] step 12/44: loss=0.5563 
[epoch 29] step 14/44: loss=0.5565 
[epoch 29] step 16/44: loss=0.5509 
[epoch 29] step 18/44: loss=0.5490 
[epoch 29] step 20/44: loss=0.5440 
[epoch 29] step 22/44: loss=0.5419 
[epoch 29] step 24/44: loss=0.5443 
[epoch 29] step 26/44: loss=0.5496 
[epoch 29] step 28/44: loss=0.5512 
[epoch 29] step 30/44: loss=0.5514 
[epoch 29] step 32/44: loss=0.5536 
[epoch 29] step 34/44: loss=0.5549 
[epoch 29] step 36/44: loss=0.5545 
[epoch 29] step 38/44: loss=0.5543 
[epoch 29] step 40/44: loss=0.5563 
[epoch 29] step 42/44: loss=0.5575 
[epoch 29] step 44/44: loss=0.5574 
[epoch 29] train_loss(avg per step)=1.1149 lambda[min,max]=[0.379447,1.000000]
[epoch 29] val_loss=1.4359 qwk=('0.5413', '0.5022', '0.4853') averageQWK=0.5096 macroEMD=0.2944 tailR0=('0.1551', '0.1000', '0.0000') tailR0avg=0.0850
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     1    5   28    6    0
     0    3   85   38    2
     0    1   30   89    2
     0    0    1   21    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    7   33    8    0
     1    7   70   35    0
     0    1   42  102    3
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   49    2    0
     0    7  122   22    0
     0    1   48   50    0
     0    0    1    2    0
[epoch 30] step 2/44: loss=0.5708 
[epoch 30] step 4/44: loss=0.5662 
[epoch 30] step 6/44: loss=0.5632 
[epoch 30] step 8/44: loss=0.5554 
[epoch 30] step 10/44: loss=0.5547 
[epoch 30] step 12/44: loss=0.5618 
[epoch 30] step 14/44: loss=0.5566 
[epoch 30] step 16/44: loss=0.5545 
[epoch 30] step 18/44: loss=0.5576 
[epoch 30] step 20/44: loss=0.5563 
[epoch 30] step 22/44: loss=0.5534 
[epoch 30] step 24/44: loss=0.5518 
[epoch 30] step 26/44: loss=0.5530 
[epoch 30] step 28/44: loss=0.5542 
[epoch 30] step 30/44: loss=0.5566 
[epoch 30] step 32/44: loss=0.5578 
[epoch 30] step 34/44: loss=0.5573 
[epoch 30] step 36/44: loss=0.5577 
[epoch 30] step 38/44: loss=0.5592 
[epoch 30] step 40/44: loss=0.5582 
[epoch 30] step 42/44: loss=0.5608 
[epoch 30] step 44/44: loss=0.5597 
[epoch 30] train_loss(avg per step)=1.1195 lambda[min,max]=[0.374454,1.000000]
[epoch 30] val_loss=1.4358 qwk=('0.5616', '0.4876', '0.5100') averageQWK=0.5197 macroEMD=0.2962 tailR0=('0.2292', '0.1000', '0.0000') tailR0avg=0.1097
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     2    5   29    4    0
     0    4   90   31    3
     0    0   43   73    6
     0    0    1   17    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    8   31    9    0
     1    7   65   40    0
     0    2   39  106    1
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   29   42    0    0
     0   16  116   19    0
     0    3   47   49    0
     0    1    0    2    0
[epoch 31] step 2/44: loss=0.5209 
[epoch 31] step 4/44: loss=0.5343 
[epoch 31] step 6/44: loss=0.5294 
[epoch 31] step 8/44: loss=0.5235 
[epoch 31] step 10/44: loss=0.5244 
[epoch 31] step 12/44: loss=0.5299 
[epoch 31] step 14/44: loss=0.5312 
[epoch 31] step 16/44: loss=0.5342 
[epoch 31] step 18/44: loss=0.5372 
[epoch 31] step 20/44: loss=0.5375 
[epoch 31] step 22/44: loss=0.5410 
[epoch 31] step 24/44: loss=0.5408 
[epoch 31] step 26/44: loss=0.5431 
[epoch 31] step 28/44: loss=0.5453 
[epoch 31] step 30/44: loss=0.5470 
[epoch 31] step 32/44: loss=0.5472 
[epoch 31] step 34/44: loss=0.5491 
[epoch 31] step 36/44: loss=0.5501 
[epoch 31] step 38/44: loss=0.5488 
[epoch 31] step 40/44: loss=0.5499 
[epoch 31] step 42/44: loss=0.5501 
[epoch 31] step 44/44: loss=0.5493 
[epoch 31] train_loss(avg per step)=1.0987 lambda[min,max]=[0.376784,1.000000]
[epoch 31] val_loss=1.4277 qwk=('0.5404', '0.4849', '0.4975') averageQWK=0.5076 macroEMD=0.2918 tailR0=('0.1921', '0.1000', '0.0000') tailR0avg=0.0974
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     1    5   28    6    0
     0    4   83   39    2
     0    1   33   86    2
     0    0    1   19    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    9   30    9    0
     1    7   63   42    0
     0    2   40  105    1
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   46    3    0
     0    8  117   26    0
     0    1   44   54    0
     0    0    1    2    0
[epoch 32] step 2/44: loss=0.5752 
[epoch 32] step 4/44: loss=0.5884 
[epoch 32] step 6/44: loss=0.5883 
[epoch 32] step 8/44: loss=0.5767 
[epoch 32] step 10/44: loss=0.5709 
[epoch 32] step 12/44: loss=0.5643 
[epoch 32] step 14/44: loss=0.5607 
[epoch 32] step 16/44: loss=0.5631 
[epoch 32] step 18/44: loss=0.5618 
[epoch 32] step 20/44: loss=0.5607 
[epoch 32] step 22/44: loss=0.5572 
[epoch 32] step 24/44: loss=0.5547 
[epoch 32] step 26/44: loss=0.5530 
[epoch 32] step 28/44: loss=0.5514 
[epoch 32] step 30/44: loss=0.5499 
[epoch 32] step 32/44: loss=0.5482 
[epoch 32] step 34/44: loss=0.5482 
[epoch 32] step 36/44: loss=0.5482 
[epoch 32] step 38/44: loss=0.5484 
[epoch 32] step 40/44: loss=0.5504 
[epoch 32] step 42/44: loss=0.5515 
[epoch 32] step 44/44: loss=0.5497 
[epoch 32] train_loss(avg per step)=1.0993 lambda[min,max]=[0.367191,1.000000]
[epoch 32] val_loss=1.4355 qwk=('0.5516', '0.4845', '0.5112') averageQWK=0.5158 macroEMD=0.2921 tailR0=('0.2106', '0.1000', '0.0000') tailR0avg=0.1035
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     1    5   29    5    0
     0    4   84   37    3
     0    0   36   81    5
     0    0    2   17    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    8   30   10    0
     1    7   60   45    0
     0    2   34  111    1
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   21   48    2    0
     0    8  115   28    0
     0    1   41   57    0
     0    0    1    2    0
[epoch 33] step 2/44: loss=0.5530 
[epoch 33] step 4/44: loss=0.5733 
[epoch 33] step 6/44: loss=0.5556 
[epoch 33] step 8/44: loss=0.5557 
[epoch 33] step 10/44: loss=0.5475 
[epoch 33] step 12/44: loss=0.5492 
[epoch 33] step 14/44: loss=0.5500 
[epoch 33] step 16/44: loss=0.5534 
[epoch 33] step 18/44: loss=0.5529 
[epoch 33] step 20/44: loss=0.5517 
[epoch 33] step 22/44: loss=0.5522 
[epoch 33] step 24/44: loss=0.5524 
[epoch 33] step 26/44: loss=0.5502 
[epoch 33] step 28/44: loss=0.5495 
[epoch 33] step 30/44: loss=0.5482 
[epoch 33] step 32/44: loss=0.5484 
[epoch 33] step 34/44: loss=0.5482 
[epoch 33] step 36/44: loss=0.5494 
[epoch 33] step 38/44: loss=0.5508 
[epoch 33] step 40/44: loss=0.5515 
[epoch 33] step 42/44: loss=0.5505 
[epoch 33] step 44/44: loss=0.5491 
[epoch 33] train_loss(avg per step)=1.0982 lambda[min,max]=[0.359332,1.000000]
[epoch 33] val_loss=1.4344 qwk=('0.5308', '0.4777', '0.5030') averageQWK=0.5039 macroEMD=0.2924 tailR0=('0.1921', '0.1000', '0.0000') tailR0avg=0.0974
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     1    5   28    6    0
     0    4   86   36    2
     0    0   39   80    3
     0    0    2   18    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1    7   30   10    0
     1    7   63   42    0
     0    2   39  106    1
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   21   48    2    0
     0    8  118   25    0
     0    1   44   54    0
     0    0    1    2    0
[epoch 34] step 2/44: loss=0.5700 
[epoch 34] step 4/44: loss=0.5514 
[epoch 34] step 6/44: loss=0.5489 
[epoch 34] step 8/44: loss=0.5461 
[epoch 34] step 10/44: loss=0.5405 
[epoch 34] step 12/44: loss=0.5410 
[epoch 34] step 14/44: loss=0.5444 
[epoch 34] step 16/44: loss=0.5426 
[epoch 34] step 18/44: loss=0.5491 
[epoch 34] step 20/44: loss=0.5497 
[epoch 34] step 22/44: loss=0.5513 
[epoch 34] step 24/44: loss=0.5501 
[epoch 34] step 26/44: loss=0.5508 
[epoch 34] step 28/44: loss=0.5518 
[epoch 34] step 30/44: loss=0.5534 
[epoch 34] step 32/44: loss=0.5522 
[epoch 34] step 34/44: loss=0.5507 
[epoch 34] step 36/44: loss=0.5508 
[epoch 34] step 38/44: loss=0.5522 
[epoch 34] step 40/44: loss=0.5520 
[epoch 34] step 42/44: loss=0.5498 
[epoch 34] step 44/44: loss=0.5516 
[epoch 34] train_loss(avg per step)=1.1033 lambda[min,max]=[0.372342,1.000000]
[epoch 34] val_loss=1.4371 qwk=('0.5304', '0.4890', '0.5056') averageQWK=0.5083 macroEMD=0.2929 tailR0=('0.1921', '0.1000', '0.0000') tailR0avg=0.0974
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     1    5   28    6    0
     0    4   87   35    2
     0    1   37   81    3
     0    0    2   18    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1    7   31    9    0
     1    7   66   39    0
     0    2   40  105    1
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   23   46    2    0
     0   12  115   24    0
     0    1   45   53    0
     0    0    1    2    0
[epoch 35] step 2/44: loss=0.5656 
[epoch 35] step 4/44: loss=0.5509 
[epoch 35] step 6/44: loss=0.5454 
[epoch 35] step 8/44: loss=0.5486 
[epoch 35] step 10/44: loss=0.5518 
[epoch 35] step 12/44: loss=0.5479 
[epoch 35] step 14/44: loss=0.5420 
[epoch 35] step 16/44: loss=0.5462 
[epoch 35] step 18/44: loss=0.5503 
[epoch 35] step 20/44: loss=0.5537 
[epoch 35] step 22/44: loss=0.5515 
[epoch 35] step 24/44: loss=0.5499 
[epoch 35] step 26/44: loss=0.5487 
[epoch 35] step 28/44: loss=0.5472 
[epoch 35] step 30/44: loss=0.5474 
[epoch 35] step 32/44: loss=0.5485 
[epoch 35] step 34/44: loss=0.5500 
[epoch 35] step 36/44: loss=0.5510 
[epoch 35] step 38/44: loss=0.5479 
[epoch 35] step 40/44: loss=0.5494 
[epoch 35] step 42/44: loss=0.5507 
[epoch 35] step 44/44: loss=0.5525 
[epoch 35] train_loss(avg per step)=1.1051 lambda[min,max]=[0.353176,1.000000]
[epoch 35] val_loss=1.4403 qwk=('0.5318', '0.4800', '0.5165') averageQWK=0.5094 macroEMD=0.2932 tailR0=('0.1921', '0.1000', '0.0000') tailR0avg=0.0974
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     1    5   29    5    0
     0    4   87   35    2
     0    0   42   77    3
     0    0    2   18    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1    7   30   10    0
     1    7   64   41    0
     0    2   39  106    1
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   23   46    2    0
     0   11  116   24    0
     0    1   43   55    0
     0    0    1    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold3/metrics.json
Done.
