[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.5294 
[epoch 1] step 4/44: loss=0.5153 
[epoch 1] step 6/44: loss=0.5094 
[epoch 1] step 8/44: loss=0.5118 
[epoch 1] step 10/44: loss=0.5182 
[epoch 1] step 12/44: loss=0.5168 
[epoch 1] step 14/44: loss=0.5206 
[epoch 1] step 16/44: loss=0.5251 
[epoch 1] step 18/44: loss=0.5284 
[epoch 1] step 20/44: loss=0.5312 
[epoch 1] step 22/44: loss=0.5365 
[epoch 1] step 24/44: loss=0.5402 
[epoch 1] step 26/44: loss=0.5432 
[epoch 1] step 28/44: loss=0.5473 
[epoch 1] step 30/44: loss=0.5511 
[epoch 1] step 32/44: loss=0.5545 
[epoch 1] step 34/44: loss=0.5578 
[epoch 1] step 36/44: loss=0.5612 
[epoch 1] step 38/44: loss=0.5630 
[epoch 1] step 40/44: loss=0.5665 
[epoch 1] step 42/44: loss=0.5695 
[epoch 1] step 44/44: loss=0.5737 
[epoch 1] train_loss(avg per step)=1.1474 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=0.8200 qwk=('0.0633', '0.1284', '0.0841') averageQWK=0.0919 macroEMD=0.3665 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    9    0
     0    4    0   37    0
     0   19    0  103    0
     0   12    0  129    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    0    0
     6    0   32    1    0
     9    0   89    6    0
    10    0  130   23    0
     0    0   11    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   21   31    0    0
     0   38  120    0    0
     0   28   82    0    0
     0    1    2    0    0
[epoch 2] step 2/44: loss=0.6885 
[epoch 2] step 4/44: loss=0.6901 
[epoch 2] step 6/44: loss=0.7123 
[epoch 2] step 8/44: loss=0.7252 
[epoch 2] step 10/44: loss=0.7375 
[epoch 2] step 12/44: loss=0.7551 
[epoch 2] step 14/44: loss=0.7740 
[epoch 2] step 16/44: loss=0.7876 
[epoch 2] step 18/44: loss=0.7981 
[epoch 2] step 20/44: loss=0.8036 
[epoch 2] step 22/44: loss=0.8108 
[epoch 2] step 24/44: loss=0.8150 
[epoch 2] step 26/44: loss=0.8143 
[epoch 2] step 28/44: loss=0.8136 
[epoch 2] step 30/44: loss=0.8118 
[epoch 2] step 32/44: loss=0.8102 
[epoch 2] step 34/44: loss=0.8094 
[epoch 2] step 36/44: loss=0.8091 
[epoch 2] step 38/44: loss=0.8115 
[epoch 2] step 40/44: loss=0.8141 
[epoch 2] step 42/44: loss=0.8169 
[epoch 2] step 44/44: loss=0.8180 
[epoch 2] train_loss(avg per step)=1.6360 lambda[min,max]=[0.505695,1.000000]
[epoch 2] val_loss=1.4907 qwk=('0.4734', '0.4626', '0.4709') averageQWK=0.4690 macroEMD=0.3523 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    8   27    6    0
     0    1   51   70    0
     0    0   17  124    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    1    0
     0    0   31    8    0
     0    0   59   45    0
     0    0   16  147    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   11    1    0    0
     0   30   22    0    0
     0   38  116    4    0
     0    5   80   25    0
     0    0    1    2    0
[epoch 3] step 2/44: loss=0.7629 
[epoch 3] step 4/44: loss=0.7655 
[epoch 3] step 6/44: loss=0.7654 
[epoch 3] step 8/44: loss=0.7619 
[epoch 3] step 10/44: loss=0.7620 
[epoch 3] step 12/44: loss=0.7673 
[epoch 3] step 14/44: loss=0.7729 
[epoch 3] step 16/44: loss=0.7837 
[epoch 3] step 18/44: loss=0.7919 
[epoch 3] step 20/44: loss=0.7981 
[epoch 3] step 22/44: loss=0.8042 
[epoch 3] step 24/44: loss=0.8099 
[epoch 3] step 26/44: loss=0.8121 
[epoch 3] step 28/44: loss=0.8130 
[epoch 3] step 30/44: loss=0.8138 
[epoch 3] step 32/44: loss=0.8143 
[epoch 3] step 34/44: loss=0.8157 
[epoch 3] step 36/44: loss=0.8149 
[epoch 3] step 38/44: loss=0.8142 
[epoch 3] step 40/44: loss=0.8180 
[epoch 3] step 42/44: loss=0.8189 
[epoch 3] step 44/44: loss=0.8152 
[epoch 3] train_loss(avg per step)=1.6303 lambda[min,max]=[0.506381,1.000000]
[epoch 3] val_loss=1.4088 qwk=('0.3361', '0.3232', '0.3425') averageQWK=0.3340 macroEMD=0.3261 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    4    0
     0    4   23   14    0
     0    0   41   81    0
     0    0    9  132    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    4    0
     0    0   21   18    0
     0    0   40   64    0
     0    0    9  154    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    0   48    4    0
     0    0  132   26    0
     0    0   51   59    0
     0    0    0    3    0
[epoch 4] step 2/44: loss=0.8629 
[epoch 4] step 4/44: loss=0.8591 
[epoch 4] step 6/44: loss=0.8583 
[epoch 4] step 8/44: loss=0.8563 
[epoch 4] step 10/44: loss=0.8508 
[epoch 4] step 12/44: loss=0.8475 
[epoch 4] step 14/44: loss=0.8429 
[epoch 4] step 16/44: loss=0.8308 
[epoch 4] step 18/44: loss=0.8240 
[epoch 4] step 20/44: loss=0.8241 
[epoch 4] step 22/44: loss=0.8212 
[epoch 4] step 24/44: loss=0.8236 
[epoch 4] step 26/44: loss=0.8258 
[epoch 4] step 28/44: loss=0.8256 
[epoch 4] step 30/44: loss=0.8281 
[epoch 4] step 32/44: loss=0.8275 
[epoch 4] step 34/44: loss=0.8274 
[epoch 4] step 36/44: loss=0.8296 
[epoch 4] step 38/44: loss=0.8290 
[epoch 4] step 40/44: loss=0.8315 
[epoch 4] step 42/44: loss=0.8319 
[epoch 4] step 44/44: loss=0.8303 
[epoch 4] train_loss(avg per step)=1.6605 lambda[min,max]=[0.500455,1.000000]
[epoch 4] val_loss=1.4757 qwk=('0.4446', '0.4084', '0.3835') averageQWK=0.4122 macroEMD=0.3217 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    2   34    5    0
     0    0   64   58    0
     0    0   25  116    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    3    0
     0    1   30    8    0
     0    0   58   46    0
     0    0   26  137    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    0   47    5    0
     0    0  119   39    0
     0    0   39   71    0
     0    0    0    3    0
[epoch 5] step 2/44: loss=0.8207 
[epoch 5] step 4/44: loss=0.8165 
[epoch 5] step 6/44: loss=0.8150 
[epoch 5] step 8/44: loss=0.8177 
[epoch 5] step 10/44: loss=0.8136 
[epoch 5] step 12/44: loss=0.8119 
[epoch 5] step 14/44: loss=0.8095 
[epoch 5] step 16/44: loss=0.8091 
[epoch 5] step 18/44: loss=0.8041 
[epoch 5] step 20/44: loss=0.8013 
[epoch 5] step 22/44: loss=0.8019 
[epoch 5] step 24/44: loss=0.8030 
[epoch 5] step 26/44: loss=0.8033 
[epoch 5] step 28/44: loss=0.8043 
[epoch 5] step 30/44: loss=0.8046 
[epoch 5] step 32/44: loss=0.8034 
[epoch 5] step 34/44: loss=0.8023 
[epoch 5] step 36/44: loss=0.8029 
[epoch 5] step 38/44: loss=0.8061 
[epoch 5] step 40/44: loss=0.8070 
[epoch 5] step 42/44: loss=0.8089 
[epoch 5] step 44/44: loss=0.8063 
[epoch 5] train_loss(avg per step)=1.6127 lambda[min,max]=[0.500031,1.000000]
[epoch 5] val_loss=1.4684 qwk=('0.2890', '0.2936', '0.2967') averageQWK=0.2931 macroEMD=0.3179 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    4    0
     0    3   17   21    0
     0    1   28   93    0
     0    0    4  137    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    6    0
     0    1   20   18    0
     0    0   37   67    0
     0    0   10  153    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    1    0
     0    1   30   21    0
     0    4   39  115    0
     0    0    6  104    0
     0    0    0    3    0
[epoch 6] step 2/44: loss=0.8672 
[epoch 6] step 4/44: loss=0.8538 
[epoch 6] step 6/44: loss=0.8544 
[epoch 6] step 8/44: loss=0.8477 
[epoch 6] step 10/44: loss=0.8422 
[epoch 6] step 12/44: loss=0.8330 
[epoch 6] step 14/44: loss=0.8283 
[epoch 6] step 16/44: loss=0.8218 
[epoch 6] step 18/44: loss=0.8145 
[epoch 6] step 20/44: loss=0.8080 
[epoch 6] step 22/44: loss=0.8090 
[epoch 6] step 24/44: loss=0.8068 
[epoch 6] step 26/44: loss=0.8039 
[epoch 6] step 28/44: loss=0.8033 
[epoch 6] step 30/44: loss=0.8069 
[epoch 6] step 32/44: loss=0.8130 
[epoch 6] step 34/44: loss=0.8214 
[epoch 6] step 36/44: loss=0.8251 
[epoch 6] step 38/44: loss=0.8274 
[epoch 6] step 40/44: loss=0.8281 
[epoch 6] step 42/44: loss=0.8271 
[epoch 6] step 44/44: loss=0.8252 
[epoch 6] train_loss(avg per step)=1.6503 lambda[min,max]=[0.500002,1.000000]
[epoch 6] val_loss=1.4905 qwk=('0.5616', '0.4803', '0.5081') averageQWK=0.5167 macroEMD=0.3115 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    2    0
     0   23   12    6    0
     0   47   19   56    0
     0    2   15  124    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0    7   23    9    0
     0   16   36   52    0
     0    1   19  143    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    5    0    0
     0   17   32    3    0
     0   20  109   29    0
     0    4   38   68    0
     0    0    0    3    0
[epoch 7] step 2/44: loss=0.7755 
[epoch 7] step 4/44: loss=0.7774 
[epoch 7] step 6/44: loss=0.7682 
[epoch 7] step 8/44: loss=0.7758 
[epoch 7] step 10/44: loss=0.7763 
[epoch 7] step 12/44: loss=0.7856 
[epoch 7] step 14/44: loss=0.7926 
[epoch 7] step 16/44: loss=0.7971 
[epoch 7] step 18/44: loss=0.8057 
[epoch 7] step 20/44: loss=0.8153 
[epoch 7] step 22/44: loss=0.8192 
[epoch 7] step 24/44: loss=0.8233 
[epoch 7] step 26/44: loss=0.8235 
[epoch 7] step 28/44: loss=0.8218 
[epoch 7] step 30/44: loss=0.8219 
[epoch 7] step 32/44: loss=0.8207 
[epoch 7] step 34/44: loss=0.8209 
[epoch 7] step 36/44: loss=0.8190 
[epoch 7] step 38/44: loss=0.8160 
[epoch 7] step 40/44: loss=0.8152 
[epoch 7] step 42/44: loss=0.8146 
[epoch 7] step 44/44: loss=0.8134 
[epoch 7] train_loss(avg per step)=1.6267 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.4605 qwk=('0.4623', '0.3488', '0.4768') averageQWK=0.4293 macroEMD=0.3090 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    1    0
     0    3   33    5    0
     0    1   67   54    0
     0    0   24  115    2
     0    0    2   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    5    0
     0    5   18   16    0
     0    8   34   62    0
     0    0   17  146    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    8   38    6    0
     0   12   79   67    0
     0    3   13   94    0
     0    0    0    3    0
[epoch 8] step 2/44: loss=0.7715 
[epoch 8] step 4/44: loss=0.7940 
[epoch 8] step 6/44: loss=0.8064 
[epoch 8] step 8/44: loss=0.8059 
[epoch 8] step 10/44: loss=0.8034 
[epoch 8] step 12/44: loss=0.8028 
[epoch 8] step 14/44: loss=0.8042 
[epoch 8] step 16/44: loss=0.8055 
[epoch 8] step 18/44: loss=0.8002 
[epoch 8] step 20/44: loss=0.7984 
[epoch 8] step 22/44: loss=0.7997 
[epoch 8] step 24/44: loss=0.7995 
[epoch 8] step 26/44: loss=0.8007 
[epoch 8] step 28/44: loss=0.8001 
[epoch 8] step 30/44: loss=0.7984 
[epoch 8] step 32/44: loss=0.7942 
[epoch 8] step 34/44: loss=0.7953 
[epoch 8] step 36/44: loss=0.7937 
[epoch 8] step 38/44: loss=0.7928 
[epoch 8] step 40/44: loss=0.7917 
[epoch 8] step 42/44: loss=0.7928 
[epoch 8] step 44/44: loss=0.7975 
[epoch 8] train_loss(avg per step)=1.5949 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.4520 qwk=('0.5042', '0.5020', '0.5301') averageQWK=0.5121 macroEMD=0.2931 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0    9   30    2    0
     0    8   80   34    0
     0    0   40  101    0
     0    0    3   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    1    0
     0    6   30    3    0
     0   12   64   28    0
     0    3   41  119    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    5    0    0
     0   20   29    3    0
     0   28  101   29    0
     0    3   36   71    0
     0    0    0    3    0
[epoch 9] step 2/44: loss=0.8049 
[epoch 9] step 4/44: loss=0.8161 
[epoch 9] step 6/44: loss=0.8194 
[epoch 9] step 8/44: loss=0.8315 
[epoch 9] step 10/44: loss=0.8231 
[epoch 9] step 12/44: loss=0.8123 
[epoch 9] step 14/44: loss=0.8013 
[epoch 9] step 16/44: loss=0.7981 
[epoch 9] step 18/44: loss=0.7925 
[epoch 9] step 20/44: loss=0.7898 
[epoch 9] step 22/44: loss=0.7866 
[epoch 9] step 24/44: loss=0.7850 
[epoch 9] step 26/44: loss=0.7807 
[epoch 9] step 28/44: loss=0.7806 
[epoch 9] step 30/44: loss=0.7807 
[epoch 9] step 32/44: loss=0.7810 
[epoch 9] step 34/44: loss=0.7794 
[epoch 9] step 36/44: loss=0.7781 
[epoch 9] step 38/44: loss=0.7753 
[epoch 9] step 40/44: loss=0.7762 
[epoch 9] step 42/44: loss=0.7764 
[epoch 9] step 44/44: loss=0.7775 
[epoch 9] train_loss(avg per step)=1.5550 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.4939 qwk=('0.4248', '0.3331', '0.3506') averageQWK=0.3695 macroEMD=0.3062 tailR0=('0.0952', '0.0000', '0.0000') tailR0avg=0.0317
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    4    0
     0   10   19   11    1
     0   11   33   76    2
     0    0   10  126    5
     0    0    0   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    6    0
     0    3   21   15    0
     0   10   29   65    0
     0    0   15  148    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    2    0
     0    6   33   13    0
     0   12   56   90    0
     0    3   10   97    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=0.8355 
[epoch 10] step 4/44: loss=0.8128 
[epoch 10] step 6/44: loss=0.8030 
[epoch 10] step 8/44: loss=0.7898 
[epoch 10] step 10/44: loss=0.7846 
[epoch 10] step 12/44: loss=0.7811 
[epoch 10] step 14/44: loss=0.7771 
[epoch 10] step 16/44: loss=0.7755 
[epoch 10] step 18/44: loss=0.7682 
[epoch 10] step 20/44: loss=0.7625 
[epoch 10] step 22/44: loss=0.7576 
[epoch 10] step 24/44: loss=0.7574 
[epoch 10] step 26/44: loss=0.7553 
[epoch 10] step 28/44: loss=0.7571 
[epoch 10] step 30/44: loss=0.7562 
[epoch 10] step 32/44: loss=0.7583 
[epoch 10] step 34/44: loss=0.7611 
[epoch 10] step 36/44: loss=0.7661 
[epoch 10] step 38/44: loss=0.7680 
[epoch 10] step 40/44: loss=0.7683 
[epoch 10] step 42/44: loss=0.7674 
[epoch 10] step 44/44: loss=0.7685 
[epoch 10] train_loss(avg per step)=1.5370 lambda[min,max]=[0.458762,1.000000]
[epoch 10] val_loss=1.4887 qwk=('0.5516', '0.5267', '0.5185') averageQWK=0.5323 macroEMD=0.2901 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    2    0
     0   25   11    5    0
     0   39   30   53    0
     0    7   17  117    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    1    0
     0    8   25    6    0
     0   17   60   27    0
     0    5   28  130    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   26   19    7    0
     0   37   62   59    0
     0    6   11   93    0
     0    0    0    3    0
[epoch 11] step 2/44: loss=0.8094 
[epoch 11] step 4/44: loss=0.8055 
[epoch 11] step 6/44: loss=0.7946 
[epoch 11] step 8/44: loss=0.7789 
[epoch 11] step 10/44: loss=0.7688 
[epoch 11] step 12/44: loss=0.7614 
[epoch 11] step 14/44: loss=0.7550 
[epoch 11] step 16/44: loss=0.7502 
[epoch 11] step 18/44: loss=0.7499 
[epoch 11] step 20/44: loss=0.7486 
[epoch 11] step 22/44: loss=0.7546 
[epoch 11] step 24/44: loss=0.7552 
[epoch 11] step 26/44: loss=0.7570 
[epoch 11] step 28/44: loss=0.7575 
[epoch 11] step 30/44: loss=0.7587 
[epoch 11] step 32/44: loss=0.7562 
[epoch 11] step 34/44: loss=0.7593 
[epoch 11] step 36/44: loss=0.7564 
[epoch 11] step 38/44: loss=0.7549 
[epoch 11] step 40/44: loss=0.7539 
[epoch 11] step 42/44: loss=0.7530 
[epoch 11] step 44/44: loss=0.7449 
[epoch 11] train_loss(avg per step)=1.4898 lambda[min,max]=[0.486085,1.000000]
[epoch 11] val_loss=1.4520 qwk=('0.4150', '0.3794', '0.4532') averageQWK=0.4159 macroEMD=0.3030 tailR0=('0.1190', '0.0000', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    4    0
     0    4   28    9    0
     0    4   52   64    2
     0    0   18  119    4
     0    0    1   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    2   26   11    0
     0    3   54   47    0
     0    0   30  133    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    5   41    6    0
     0   13   91   54    0
     0    3   21   86    0
     0    0    0    3    0
[epoch 12] step 2/44: loss=0.7643 
[epoch 12] step 4/44: loss=0.7780 
[epoch 12] step 6/44: loss=0.7670 
[epoch 12] step 8/44: loss=0.7674 
[epoch 12] step 10/44: loss=0.7659 
[epoch 12] step 12/44: loss=0.7584 
[epoch 12] step 14/44: loss=0.7548 
[epoch 12] step 16/44: loss=0.7569 
[epoch 12] step 18/44: loss=0.7558 
[epoch 12] step 20/44: loss=0.7545 
[epoch 12] step 22/44: loss=0.7514 
[epoch 12] step 24/44: loss=0.7491 
[epoch 12] step 26/44: loss=0.7489 
[epoch 12] step 28/44: loss=0.7494 
[epoch 12] step 30/44: loss=0.7485 
[epoch 12] step 32/44: loss=0.7494 
[epoch 12] step 34/44: loss=0.7497 
[epoch 12] step 36/44: loss=0.7486 
[epoch 12] step 38/44: loss=0.7494 
[epoch 12] step 40/44: loss=0.7504 
[epoch 12] step 42/44: loss=0.7514 
[epoch 12] step 44/44: loss=0.7484 
[epoch 12] train_loss(avg per step)=1.4968 lambda[min,max]=[0.484730,1.000000]
[epoch 12] val_loss=1.4989 qwk=('0.5431', '0.4400', '0.5031') averageQWK=0.4954 macroEMD=0.2980 tailR0=('0.2143', '0.0000', '0.0000') tailR0avg=0.0714
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0   10   28    3    0
     0   12   76   33    1
     0    0   40   91   10
     0    0    3    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    1    0
     0    6   30    3    0
     0   13   61   29    1
     0    1   55  106    1
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   20   30    2    0
     0   23  106   29    0
     0    3   44   63    0
     0    0    0    3    0
[epoch 13] step 2/44: loss=0.6848 
[epoch 13] step 4/44: loss=0.6908 
[epoch 13] step 6/44: loss=0.6921 
[epoch 13] step 8/44: loss=0.7041 
[epoch 13] step 10/44: loss=0.7086 
[epoch 13] step 12/44: loss=0.7092 
[epoch 13] step 14/44: loss=0.7170 
[epoch 13] step 16/44: loss=0.7172 
[epoch 13] step 18/44: loss=0.7169 
[epoch 13] step 20/44: loss=0.7165 
[epoch 13] step 22/44: loss=0.7127 
[epoch 13] step 24/44: loss=0.7087 
[epoch 13] step 26/44: loss=0.7093 
[epoch 13] step 28/44: loss=0.7112 
[epoch 13] step 30/44: loss=0.7090 
[epoch 13] step 32/44: loss=0.7110 
[epoch 13] step 34/44: loss=0.7084 
[epoch 13] step 36/44: loss=0.7084 
[epoch 13] step 38/44: loss=0.7077 
[epoch 13] step 40/44: loss=0.7112 
[epoch 13] step 42/44: loss=0.7136 
[epoch 13] step 44/44: loss=0.7108 
[epoch 13] train_loss(avg per step)=1.4216 lambda[min,max]=[0.453070,1.000000]
[epoch 13] val_loss=1.4298 qwk=('0.5086', '0.4812', '0.4163') averageQWK=0.4687 macroEMD=0.2940 tailR0=('0.1190', '0.0000', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    2    0
     0   10   27    4    0
     0    9   75   37    1
     0    0   39   99    3
     0    0    3   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    2    0
     0    5   29    5    0
     0    9   61   34    0
     0    2   39  122    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    9   42    1    0
     0   17  119   22    0
     0    3   53   54    0
     0    0    0    3    0
[epoch 14] step 2/44: loss=0.7801 
[epoch 14] step 4/44: loss=0.7811 
[epoch 14] step 6/44: loss=0.7653 
[epoch 14] step 8/44: loss=0.7626 
[epoch 14] step 10/44: loss=0.7499 
[epoch 14] step 12/44: loss=0.7456 
[epoch 14] step 14/44: loss=0.7402 
[epoch 14] step 16/44: loss=0.7333 
[epoch 14] step 18/44: loss=0.7216 
[epoch 14] step 20/44: loss=0.7188 
[epoch 14] step 22/44: loss=0.7157 
[epoch 14] step 24/44: loss=0.7110 
[epoch 14] step 26/44: loss=0.7087 
[epoch 14] step 28/44: loss=0.7071 
[epoch 14] step 30/44: loss=0.7041 
[epoch 14] step 32/44: loss=0.7039 
[epoch 14] step 34/44: loss=0.7056 
[epoch 14] step 36/44: loss=0.7052 
[epoch 14] step 38/44: loss=0.7048 
[epoch 14] step 40/44: loss=0.7057 
[epoch 14] step 42/44: loss=0.7069 
[epoch 14] step 44/44: loss=0.7014 
[epoch 14] train_loss(avg per step)=1.4028 lambda[min,max]=[0.412311,1.000000]
[epoch 14] val_loss=1.4674 qwk=('0.4709', '0.4232', '0.4515') averageQWK=0.4485 macroEMD=0.3000 tailR0=('0.2381', '0.0000', '0.0000') tailR0avg=0.0794
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    3    0
     0    8   26    6    1
     0    6   66   47    3
     0    0   26  106    9
     0    0    3    8   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    4   24   11    0
     0    7   51   46    0
     0    0   27  136    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    2    0
     0    8   38    6    0
     0   11   89   58    0
     0    2   20   88    0
     0    0    0    3    0
[epoch 15] step 2/44: loss=0.7509 
[epoch 15] step 4/44: loss=0.7462 
[epoch 15] step 6/44: loss=0.7333 
[epoch 15] step 8/44: loss=0.7210 
[epoch 15] step 10/44: loss=0.7123 
[epoch 15] step 12/44: loss=0.7009 
[epoch 15] step 14/44: loss=0.6976 
[epoch 15] step 16/44: loss=0.6927 
[epoch 15] step 18/44: loss=0.6907 
[epoch 15] step 20/44: loss=0.6906 
[epoch 15] step 22/44: loss=0.6916 
[epoch 15] step 24/44: loss=0.6903 
[epoch 15] step 26/44: loss=0.6893 
[epoch 15] step 28/44: loss=0.6886 
[epoch 15] step 30/44: loss=0.6878 
[epoch 15] step 32/44: loss=0.6875 
[epoch 15] step 34/44: loss=0.6902 
[epoch 15] step 36/44: loss=0.6922 
[epoch 15] step 38/44: loss=0.6923 
[epoch 15] step 40/44: loss=0.6935 
[epoch 15] step 42/44: loss=0.6921 
[epoch 15] step 44/44: loss=0.6872 
[epoch 15] train_loss(avg per step)=1.3744 lambda[min,max]=[0.417376,1.000000]
[epoch 15] val_loss=1.4493 qwk=('0.4897', '0.4239', '0.4753') averageQWK=0.4630 macroEMD=0.3005 tailR0=('0.1905', '0.0312', '0.0000') tailR0avg=0.0739
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    6   33    2    0
     0    3   95   21    3
     0    0   49   84    8
     0    0    4    9    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    4   26    9    0
     0    7   61   35    1
     0    0   37  124    2
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   12   36    4    0
     0   20   97   41    0
     0    3   31   76    0
     0    0    0    3    0
[epoch 16] step 2/44: loss=0.6747 
[epoch 16] step 4/44: loss=0.6703 
[epoch 16] step 6/44: loss=0.6771 
[epoch 16] step 8/44: loss=0.6870 
[epoch 16] step 10/44: loss=0.6862 
[epoch 16] step 12/44: loss=0.6841 
[epoch 16] step 14/44: loss=0.6862 
[epoch 16] step 16/44: loss=0.6875 
[epoch 16] step 18/44: loss=0.6843 
[epoch 16] step 20/44: loss=0.6802 
[epoch 16] step 22/44: loss=0.6778 
[epoch 16] step 24/44: loss=0.6754 
[epoch 16] step 26/44: loss=0.6768 
[epoch 16] step 28/44: loss=0.6796 
[epoch 16] step 30/44: loss=0.6801 
[epoch 16] step 32/44: loss=0.6798 
[epoch 16] step 34/44: loss=0.6775 
[epoch 16] step 36/44: loss=0.6745 
[epoch 16] step 38/44: loss=0.6740 
[epoch 16] step 40/44: loss=0.6742 
[epoch 16] step 42/44: loss=0.6761 
[epoch 16] step 44/44: loss=0.6762 
[epoch 16] train_loss(avg per step)=1.3525 lambda[min,max]=[0.432582,1.000000]
[epoch 16] val_loss=1.4503 qwk=('0.4987', '0.4561', '0.4673') averageQWK=0.4740 macroEMD=0.2992 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    2    0
     0   11   25    5    0
     0   10   72   39    1
     0    0   36  100    5
     0    0    4   11    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0    5   26    8    0
     0   12   55   37    0
     0    0   39  124    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   17   30    5    0
     0   34   93   31    0
     0    3   38   69    0
     0    0    0    3    0
[epoch 17] step 2/44: loss=0.7079 
[epoch 17] step 4/44: loss=0.7069 
[epoch 17] step 6/44: loss=0.7069 
[epoch 17] step 8/44: loss=0.6975 
[epoch 17] step 10/44: loss=0.6878 
[epoch 17] step 12/44: loss=0.6770 
[epoch 17] step 14/44: loss=0.6623 
[epoch 17] step 16/44: loss=0.6581 
[epoch 17] step 18/44: loss=0.6532 
[epoch 17] step 20/44: loss=0.6476 
[epoch 17] step 22/44: loss=0.6491 
[epoch 17] step 24/44: loss=0.6508 
[epoch 17] step 26/44: loss=0.6545 
[epoch 17] step 28/44: loss=0.6598 
[epoch 17] step 30/44: loss=0.6633 
[epoch 17] step 32/44: loss=0.6633 
[epoch 17] step 34/44: loss=0.6655 
[epoch 17] step 36/44: loss=0.6676 
[epoch 17] step 38/44: loss=0.6671 
[epoch 17] step 40/44: loss=0.6661 
[epoch 17] step 42/44: loss=0.6655 
[epoch 17] step 44/44: loss=0.6621 
[epoch 17] train_loss(avg per step)=1.3243 lambda[min,max]=[0.417006,1.000000]
[epoch 17] val_loss=1.4271 qwk=('0.4474', '0.4102', '0.3628') averageQWK=0.4068 macroEMD=0.3047 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    3    0
     0    6   31    4    0
     0    4   84   34    0
     0    0   44   94    3
     0    0    5   10    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    4   30    5    0
     0    7   67   30    0
     0    1   55  107    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    5   45    2    0
     0   11  121   26    0
     0    2   55   53    0
     0    0    0    3    0
[epoch 18] step 2/44: loss=0.7051 
[epoch 18] step 4/44: loss=0.6876 
[epoch 18] step 6/44: loss=0.6804 
[epoch 18] step 8/44: loss=0.6747 
[epoch 18] step 10/44: loss=0.6688 
[epoch 18] step 12/44: loss=0.6680 
[epoch 18] step 14/44: loss=0.6618 
[epoch 18] step 16/44: loss=0.6553 
[epoch 18] step 18/44: loss=0.6498 
[epoch 18] step 20/44: loss=0.6469 
[epoch 18] step 22/44: loss=0.6469 
[epoch 18] step 24/44: loss=0.6474 
[epoch 18] step 26/44: loss=0.6458 
[epoch 18] step 28/44: loss=0.6468 
[epoch 18] step 30/44: loss=0.6472 
[epoch 18] step 32/44: loss=0.6483 
[epoch 18] step 34/44: loss=0.6490 
[epoch 18] step 36/44: loss=0.6468 
[epoch 18] step 38/44: loss=0.6465 
[epoch 18] step 40/44: loss=0.6471 
[epoch 18] step 42/44: loss=0.6465 
[epoch 18] step 44/44: loss=0.6449 
[epoch 18] train_loss(avg per step)=1.2898 lambda[min,max]=[0.401600,1.000000]
[epoch 18] val_loss=1.4456 qwk=('0.4673', '0.4103', '0.4166') averageQWK=0.4314 macroEMD=0.3028 tailR0=('0.2143', '0.0000', '0.0000') tailR0avg=0.0714
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    8   25    7    1
     0    6   72   42    2
     0    0   36   96    9
     0    0    2   10    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    4   25   10    0
     0    8   52   44    0
     0    0   32  131    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    2    0
     0   11   35    6    0
     0   22   89   47    0
     0    4   27   79    0
     0    0    0    3    0
[epoch 19] step 2/44: loss=0.6354 
[epoch 19] step 4/44: loss=0.6477 
[epoch 19] step 6/44: loss=0.6640 
[epoch 19] step 8/44: loss=0.6496 
[epoch 19] step 10/44: loss=0.6445 
[epoch 19] step 12/44: loss=0.6356 
[epoch 19] step 14/44: loss=0.6353 
[epoch 19] step 16/44: loss=0.6292 
[epoch 19] step 18/44: loss=0.6259 
[epoch 19] step 20/44: loss=0.6251 
[epoch 19] step 22/44: loss=0.6256 
[epoch 19] step 24/44: loss=0.6266 
[epoch 19] step 26/44: loss=0.6287 
[epoch 19] step 28/44: loss=0.6267 
[epoch 19] step 30/44: loss=0.6275 
[epoch 19] step 32/44: loss=0.6290 
[epoch 19] step 34/44: loss=0.6303 
[epoch 19] step 36/44: loss=0.6304 
[epoch 19] step 38/44: loss=0.6318 
[epoch 19] step 40/44: loss=0.6311 
[epoch 19] step 42/44: loss=0.6312 
[epoch 19] step 44/44: loss=0.6268 
[epoch 19] train_loss(avg per step)=1.2536 lambda[min,max]=[0.402337,1.000000]
[epoch 19] val_loss=1.4318 qwk=('0.5076', '0.4044', '0.4045') averageQWK=0.4389 macroEMD=0.3039 tailR0=('0.2857', '0.0625', '0.0000') tailR0avg=0.1161
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    6   32    2    1
     0    4  100   15    3
     0    0   58   67   16
     0    0    4    5   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    2    0
     0    4   29    5    1
     0    4   66   33    1
     0    0   50  112    1
     0    0    3   11    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    5   41    6    0
     0   13  100   45    0
     0    3   29   78    0
     0    0    0    3    0
[epoch 20] step 2/44: loss=0.6429 
[epoch 20] step 4/44: loss=0.6519 
[epoch 20] step 6/44: loss=0.6431 
[epoch 20] step 8/44: loss=0.6506 
[epoch 20] step 10/44: loss=0.6424 
[epoch 20] step 12/44: loss=0.6458 
[epoch 20] step 14/44: loss=0.6447 
[epoch 20] step 16/44: loss=0.6384 
[epoch 20] step 18/44: loss=0.6345 
[epoch 20] step 20/44: loss=0.6291 
[epoch 20] step 22/44: loss=0.6256 
[epoch 20] step 24/44: loss=0.6262 
[epoch 20] step 26/44: loss=0.6217 
[epoch 20] step 28/44: loss=0.6192 
[epoch 20] step 30/44: loss=0.6211 
[epoch 20] step 32/44: loss=0.6206 
[epoch 20] step 34/44: loss=0.6221 
[epoch 20] step 36/44: loss=0.6246 
[epoch 20] step 38/44: loss=0.6259 
[epoch 20] step 40/44: loss=0.6259 
[epoch 20] step 42/44: loss=0.6267 
[epoch 20] step 44/44: loss=0.6273 
[epoch 20] train_loss(avg per step)=1.2546 lambda[min,max]=[0.370404,1.000000]
[epoch 20] val_loss=1.4368 qwk=('0.4643', '0.4064', '0.4718') averageQWK=0.4475 macroEMD=0.3042 tailR0=('0.1905', '0.0000', '0.0000') tailR0avg=0.0635
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    5   32    4    0
     0    3   94   24    1
     0    0   52   83    6
     0    0    6    7    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0    4   24   10    1
     0    5   55   44    0
     1    0   33  129    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   17   32    3    0
     0   34   92   32    0
     0    4   40   66    0
     0    0    0    3    0
[epoch 21] step 2/44: loss=0.5968 
[epoch 21] step 4/44: loss=0.5947 
[epoch 21] step 6/44: loss=0.5939 
[epoch 21] step 8/44: loss=0.5971 
[epoch 21] step 10/44: loss=0.6040 
[epoch 21] step 12/44: loss=0.6080 
[epoch 21] step 14/44: loss=0.6108 
[epoch 21] step 16/44: loss=0.6121 
[epoch 21] step 18/44: loss=0.6072 
[epoch 21] step 20/44: loss=0.6050 
[epoch 21] step 22/44: loss=0.6020 
[epoch 21] step 24/44: loss=0.5969 
[epoch 21] step 26/44: loss=0.5960 
[epoch 21] step 28/44: loss=0.5966 
[epoch 21] step 30/44: loss=0.6005 
[epoch 21] step 32/44: loss=0.6036 
[epoch 21] step 34/44: loss=0.6069 
[epoch 21] step 36/44: loss=0.6093 
[epoch 21] step 38/44: loss=0.6123 
[epoch 21] step 40/44: loss=0.6126 
[epoch 21] step 42/44: loss=0.6124 
[epoch 21] step 44/44: loss=0.6009 
[epoch 21] train_loss(avg per step)=1.2017 lambda[min,max]=[0.373903,1.000000]
[epoch 21] val_loss=1.4422 qwk=('0.4999', '0.3985', '0.4543') averageQWK=0.4509 macroEMD=0.3054 tailR0=('0.3095', '0.0000', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    6   31    3    1
     0    3   79   33    7
     0    0   41   85   15
     0    0    1    7   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     0    4   24   10    1
     0    5   50   49    0
     0    0   31  131    1
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    2    0
     0   11   35    6    0
     0   20   84   54    0
     0    2   25   83    0
     0    0    0    3    0
[epoch 22] step 2/44: loss=0.6553 
[epoch 22] step 4/44: loss=0.6187 
[epoch 22] step 6/44: loss=0.6153 
[epoch 22] step 8/44: loss=0.6214 
[epoch 22] step 10/44: loss=0.6144 
[epoch 22] step 12/44: loss=0.6078 
[epoch 22] step 14/44: loss=0.6018 
[epoch 22] step 16/44: loss=0.5978 
[epoch 22] step 18/44: loss=0.6014 
[epoch 22] step 20/44: loss=0.6047 
[epoch 22] step 22/44: loss=0.6049 
[epoch 22] step 24/44: loss=0.6052 
[epoch 22] step 26/44: loss=0.6034 
[epoch 22] step 28/44: loss=0.6012 
[epoch 22] step 30/44: loss=0.6031 
[epoch 22] step 32/44: loss=0.6006 
[epoch 22] step 34/44: loss=0.6011 
[epoch 22] step 36/44: loss=0.5999 
[epoch 22] step 38/44: loss=0.6002 
[epoch 22] step 40/44: loss=0.5992 
[epoch 22] step 42/44: loss=0.5991 
[epoch 22] step 44/44: loss=0.6030 
[epoch 22] train_loss(avg per step)=1.2059 lambda[min,max]=[0.380779,1.000000]
[epoch 22] val_loss=1.4415 qwk=('0.5027', '0.4317', '0.4083') averageQWK=0.4475 macroEMD=0.3059 tailR0=('0.2619', '0.0312', '0.0000') tailR0avg=0.0977
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   30    2    2
     0    3   86   30    3
     0    0   41   83   17
     0    0    3    7   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     0    4   26    8    1
     0    3   54   46    1
     0    0   30  129    4
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    2    0
     0    8   37    7    0
     0   19   88   51    0
     0    4   28   78    0
     0    0    0    3    0
[epoch 23] step 2/44: loss=0.5840 
[epoch 23] step 4/44: loss=0.5760 
[epoch 23] step 6/44: loss=0.5819 
[epoch 23] step 8/44: loss=0.5878 
[epoch 23] step 10/44: loss=0.5924 
[epoch 23] step 12/44: loss=0.5986 
[epoch 23] step 14/44: loss=0.6006 
[epoch 23] step 16/44: loss=0.6017 
[epoch 23] step 18/44: loss=0.6030 
[epoch 23] step 20/44: loss=0.6075 
[epoch 23] step 22/44: loss=0.6080 
[epoch 23] step 24/44: loss=0.6043 
[epoch 23] step 26/44: loss=0.6036 
[epoch 23] step 28/44: loss=0.6004 
[epoch 23] step 30/44: loss=0.5994 
[epoch 23] step 32/44: loss=0.5979 
[epoch 23] step 34/44: loss=0.5970 
[epoch 23] step 36/44: loss=0.5943 
[epoch 23] step 38/44: loss=0.5961 
[epoch 23] step 40/44: loss=0.5946 
[epoch 23] step 42/44: loss=0.5948 
[epoch 23] step 44/44: loss=0.5992 
[epoch 23] train_loss(avg per step)=1.1985 lambda[min,max]=[0.373569,1.000000]
[epoch 23] val_loss=1.4256 qwk=('0.5078', '0.4022', '0.4430') averageQWK=0.4510 macroEMD=0.3074 tailR0=('0.2857', '0.0000', '0.0000') tailR0avg=0.0952
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     1    4   32    2    2
     0    2   86   30    4
     0    0   39   83   19
     0    0    2    7   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     1    3   26    8    1
     0    3   51   50    0
     0    0   35  127    1
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    9   38    5    0
     0   17  101   40    0
     0    3   35   72    0
     0    0    0    3    0
[epoch 24] step 2/44: loss=0.5525 
[epoch 24] step 4/44: loss=0.5564 
[epoch 24] step 6/44: loss=0.5717 
[epoch 24] step 8/44: loss=0.5703 
[epoch 24] step 10/44: loss=0.5719 
[epoch 24] step 12/44: loss=0.5804 
[epoch 24] step 14/44: loss=0.5854 
[epoch 24] step 16/44: loss=0.5872 
[epoch 24] step 18/44: loss=0.5889 
[epoch 24] step 20/44: loss=0.5900 
[epoch 24] step 22/44: loss=0.5915 
[epoch 24] step 24/44: loss=0.5900 
[epoch 24] step 26/44: loss=0.5909 
[epoch 24] step 28/44: loss=0.5904 
[epoch 24] step 30/44: loss=0.5893 
[epoch 24] step 32/44: loss=0.5851 
[epoch 24] step 34/44: loss=0.5837 
[epoch 24] step 36/44: loss=0.5823 
[epoch 24] step 38/44: loss=0.5804 
[epoch 24] step 40/44: loss=0.5813 
[epoch 24] step 42/44: loss=0.5822 
[epoch 24] step 44/44: loss=0.5825 
[epoch 24] train_loss(avg per step)=1.1650 lambda[min,max]=[0.379383,1.000000]
[epoch 24] val_loss=1.4131 qwk=('0.4314', '0.3764', '0.4244') averageQWK=0.4107 macroEMD=0.3086 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    6   28    7    0
     0    3   70   47    2
     0    0   35  103    3
     0    0    4   11    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     1    3   27    8    0
     0    3   53   48    0
     0    0   38  125    0
     0    0    4   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    9   40    3    0
     0   16  103   39    0
     0    4   36   70    0
     0    0    0    3    0
[epoch 25] step 2/44: loss=0.5758 
[epoch 25] step 4/44: loss=0.5831 
[epoch 25] step 6/44: loss=0.5836 
[epoch 25] step 8/44: loss=0.5946 
[epoch 25] step 10/44: loss=0.5957 
[epoch 25] step 12/44: loss=0.5960 
[epoch 25] step 14/44: loss=0.5926 
[epoch 25] step 16/44: loss=0.5878 
[epoch 25] step 18/44: loss=0.5857 
[epoch 25] step 20/44: loss=0.5811 
[epoch 25] step 22/44: loss=0.5817 
[epoch 25] step 24/44: loss=0.5826 
[epoch 25] step 26/44: loss=0.5812 
[epoch 25] step 28/44: loss=0.5785 
[epoch 25] step 30/44: loss=0.5765 
[epoch 25] step 32/44: loss=0.5728 
[epoch 25] step 34/44: loss=0.5726 
[epoch 25] step 36/44: loss=0.5705 
[epoch 25] step 38/44: loss=0.5703 
[epoch 25] step 40/44: loss=0.5733 
[epoch 25] step 42/44: loss=0.5752 
[epoch 25] step 44/44: loss=0.5734 
[epoch 25] train_loss(avg per step)=1.1467 lambda[min,max]=[0.357210,1.000000]
[epoch 25] val_loss=1.4171 qwk=('0.4483', '0.4100', '0.4673') averageQWK=0.4419 macroEMD=0.2994 tailR0=('0.1667', '0.0000', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     1    8   25    6    1
     0    4   76   40    2
     0    0   39   99    3
     0    0    4   10    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     0    4   30    5    0
     0    5   57   42    0
     0    0   45  118    0
     0    0    4   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   11   38    3    0
     0   17   99   42    0
     0    4   34   72    0
     0    0    0    3    0
[epoch 26] step 2/44: loss=0.6199 
[epoch 26] step 4/44: loss=0.6197 
[epoch 26] step 6/44: loss=0.6178 
[epoch 26] step 8/44: loss=0.6117 
[epoch 26] step 10/44: loss=0.6030 
[epoch 26] step 12/44: loss=0.5951 
[epoch 26] step 14/44: loss=0.5948 
[epoch 26] step 16/44: loss=0.5909 
[epoch 26] step 18/44: loss=0.5876 
[epoch 26] step 20/44: loss=0.5833 
[epoch 26] step 22/44: loss=0.5805 
[epoch 26] step 24/44: loss=0.5742 
[epoch 26] step 26/44: loss=0.5738 
[epoch 26] step 28/44: loss=0.5732 
[epoch 26] step 30/44: loss=0.5747 
[epoch 26] step 32/44: loss=0.5736 
[epoch 26] step 34/44: loss=0.5751 
[epoch 26] step 36/44: loss=0.5777 
[epoch 26] step 38/44: loss=0.5794 
[epoch 26] step 40/44: loss=0.5822 
[epoch 26] step 42/44: loss=0.5834 
[epoch 26] step 44/44: loss=0.5874 
[epoch 26] train_loss(avg per step)=1.1749 lambda[min,max]=[0.375845,1.000000]
[epoch 26] val_loss=1.4427 qwk=('0.5037', '0.3772', '0.4493') averageQWK=0.4434 macroEMD=0.3029 tailR0=('0.2881', '0.0000', '0.0000') tailR0avg=0.0960
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    5   30    3    1
     0    3   87   29    3
     0    0   46   86    9
     0    0    3    8   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     1    3   27    7    1
     0    3   55   46    0
     0    0   40  122    1
     0    0    4   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0    8   40    4    0
     0   17  101   40    0
     0    4   34   72    0
     0    0    0    3    0
[epoch 27] step 2/44: loss=0.5309 
[epoch 27] step 4/44: loss=0.5470 
[epoch 27] step 6/44: loss=0.5581 
[epoch 27] step 8/44: loss=0.5598 
[epoch 27] step 10/44: loss=0.5534 
[epoch 27] step 12/44: loss=0.5572 
[epoch 27] step 14/44: loss=0.5560 
[epoch 27] step 16/44: loss=0.5596 
[epoch 27] step 18/44: loss=0.5585 
[epoch 27] step 20/44: loss=0.5622 
[epoch 27] step 22/44: loss=0.5629 
[epoch 27] step 24/44: loss=0.5624 
[epoch 27] step 26/44: loss=0.5644 
[epoch 27] step 28/44: loss=0.5640 
[epoch 27] step 30/44: loss=0.5636 
[epoch 27] step 32/44: loss=0.5627 
[epoch 27] step 34/44: loss=0.5607 
[epoch 27] step 36/44: loss=0.5610 
[epoch 27] step 38/44: loss=0.5616 
[epoch 27] step 40/44: loss=0.5625 
[epoch 27] step 42/44: loss=0.5640 
[epoch 27] step 44/44: loss=0.5615 
[epoch 27] train_loss(avg per step)=1.1230 lambda[min,max]=[0.373181,1.000000]
[epoch 27] val_loss=1.4151 qwk=('0.4499', '0.3733', '0.4059') averageQWK=0.4097 macroEMD=0.3068 tailR0=('0.1190', '0.0000', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     1    6   28    5    1
     0    3   72   46    1
     0    0   34  105    2
     0    0    3   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    4   23   12    0
     0    4   48   52    0
     0    0   34  129    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    4   44    4    0
     0   13  105   40    0
     0    2   38   70    0
     0    0    0    3    0
[epoch 28] step 2/44: loss=0.6338 
[epoch 28] step 4/44: loss=0.6096 
[epoch 28] step 6/44: loss=0.5987 
[epoch 28] step 8/44: loss=0.5953 
[epoch 28] step 10/44: loss=0.5888 
[epoch 28] step 12/44: loss=0.5833 
[epoch 28] step 14/44: loss=0.5787 
[epoch 28] step 16/44: loss=0.5744 
[epoch 28] step 18/44: loss=0.5742 
[epoch 28] step 20/44: loss=0.5724 
[epoch 28] step 22/44: loss=0.5712 
[epoch 28] step 24/44: loss=0.5686 
[epoch 28] step 26/44: loss=0.5677 
[epoch 28] step 28/44: loss=0.5657 
[epoch 28] step 30/44: loss=0.5643 
[epoch 28] step 32/44: loss=0.5643 
[epoch 28] step 34/44: loss=0.5638 
[epoch 28] step 36/44: loss=0.5657 
[epoch 28] step 38/44: loss=0.5654 
[epoch 28] step 40/44: loss=0.5648 
[epoch 28] step 42/44: loss=0.5649 
[epoch 28] step 44/44: loss=0.5657 
[epoch 28] train_loss(avg per step)=1.1314 lambda[min,max]=[0.381179,1.000000]
[epoch 28] val_loss=1.4320 qwk=('0.4395', '0.3804', '0.4497') averageQWK=0.4232 macroEMD=0.3053 tailR0=('0.2167', '0.0000', '0.0000') tailR0avg=0.0722
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     1    4   30    5    1
     0    2   77   41    2
     0    0   40   97    4
     0    0    4   10    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0    4   24   10    1
     0    5   53   46    0
     0    0   40  123    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    1    0
     0    8   39    5    0
     0   18   91   49    0
     0    3   25   82    0
     0    0    0    3    0
[epoch 29] step 2/44: loss=0.5852 
[epoch 29] step 4/44: loss=0.5824 
[epoch 29] step 6/44: loss=0.5754 
[epoch 29] step 8/44: loss=0.5685 
[epoch 29] step 10/44: loss=0.5658 
[epoch 29] step 12/44: loss=0.5673 
[epoch 29] step 14/44: loss=0.5615 
[epoch 29] step 16/44: loss=0.5536 
[epoch 29] step 18/44: loss=0.5507 
[epoch 29] step 20/44: loss=0.5489 
[epoch 29] step 22/44: loss=0.5470 
[epoch 29] step 24/44: loss=0.5437 
[epoch 29] step 26/44: loss=0.5444 
[epoch 29] step 28/44: loss=0.5440 
[epoch 29] step 30/44: loss=0.5474 
[epoch 29] step 32/44: loss=0.5512 
[epoch 29] step 34/44: loss=0.5555 
[epoch 29] step 36/44: loss=0.5568 
[epoch 29] step 38/44: loss=0.5565 
[epoch 29] step 40/44: loss=0.5574 
[epoch 29] step 42/44: loss=0.5587 
[epoch 29] step 44/44: loss=0.5498 
[epoch 29] train_loss(avg per step)=1.0996 lambda[min,max]=[0.361061,1.000000]
[epoch 29] val_loss=1.4351 qwk=('0.4592', '0.4278', '0.4467') averageQWK=0.4446 macroEMD=0.3009 tailR0=('0.2167', '0.0312', '0.0000') tailR0avg=0.0826
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     1    6   30    3    1
     0    3   94   24    1
     0    0   55   82    4
     0    0    6    8    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0   11   22    5    1
     0   10   62   32    0
     0    4   48  111    0
     0    0    4   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    9   39    4    0
     0   15  112   31    0
     0    3   40   67    0
     0    0    0    3    0
[epoch 30] step 2/44: loss=0.5845 
[epoch 30] step 4/44: loss=0.5826 
[epoch 30] step 6/44: loss=0.5929 
[epoch 30] step 8/44: loss=0.5941 
[epoch 30] step 10/44: loss=0.5923 
[epoch 30] step 12/44: loss=0.5924 
[epoch 30] step 14/44: loss=0.5879 
[epoch 30] step 16/44: loss=0.5875 
[epoch 30] step 18/44: loss=0.5833 
[epoch 30] step 20/44: loss=0.5792 
[epoch 30] step 22/44: loss=0.5771 
[epoch 30] step 24/44: loss=0.5714 
[epoch 30] step 26/44: loss=0.5695 
[epoch 30] step 28/44: loss=0.5676 
[epoch 30] step 30/44: loss=0.5645 
[epoch 30] step 32/44: loss=0.5616 
[epoch 30] step 34/44: loss=0.5602 
[epoch 30] step 36/44: loss=0.5576 
[epoch 30] step 38/44: loss=0.5566 
[epoch 30] step 40/44: loss=0.5571 
[epoch 30] step 42/44: loss=0.5575 
[epoch 30] step 44/44: loss=0.5546 
[epoch 30] train_loss(avg per step)=1.1092 lambda[min,max]=[0.355144,1.000000]
[epoch 30] val_loss=1.4214 qwk=('0.4692', '0.4317', '0.4329') averageQWK=0.4446 macroEMD=0.3046 tailR0=('0.0952', '0.0000', '0.0000') tailR0avg=0.0317
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     2    5   30    4    0
     0    2   85   34    1
     0    0   41   97    3
     0    0    4   13    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     1    3   30    5    0
     0    4   58   42    0
     0    0   45  118    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   11   39    2    0
     0   19  111   28    0
     0    4   47   59    0
     0    0    0    3    0
[epoch 31] step 2/44: loss=0.5898 
[epoch 31] step 4/44: loss=0.5859 
[epoch 31] step 6/44: loss=0.5816 
[epoch 31] step 8/44: loss=0.5619 
[epoch 31] step 10/44: loss=0.5613 
[epoch 31] step 12/44: loss=0.5698 
[epoch 31] step 14/44: loss=0.5634 
[epoch 31] step 16/44: loss=0.5605 
[epoch 31] step 18/44: loss=0.5639 
[epoch 31] step 20/44: loss=0.5646 
[epoch 31] step 22/44: loss=0.5658 
[epoch 31] step 24/44: loss=0.5668 
[epoch 31] step 26/44: loss=0.5636 
[epoch 31] step 28/44: loss=0.5642 
[epoch 31] step 30/44: loss=0.5642 
[epoch 31] step 32/44: loss=0.5623 
[epoch 31] step 34/44: loss=0.5604 
[epoch 31] step 36/44: loss=0.5595 
[epoch 31] step 38/44: loss=0.5599 
[epoch 31] step 40/44: loss=0.5586 
[epoch 31] step 42/44: loss=0.5593 
[epoch 31] step 44/44: loss=0.5541 
[epoch 31] train_loss(avg per step)=1.1082 lambda[min,max]=[0.354811,1.000000]
[epoch 31] val_loss=1.4298 qwk=('0.4557', '0.3993', '0.4482') averageQWK=0.4344 macroEMD=0.3048 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     1    6   28    5    1
     0    3   79   38    2
     0    0   38   99    4
     0    0    3   12    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     1    2   27    9    0
     0    5   51   48    0
     0    0   36  127    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   12   36    4    0
     0   22  105   31    0
     0    4   39   67    0
     0    0    0    3    0
[epoch 32] step 2/44: loss=0.5279 
[epoch 32] step 4/44: loss=0.5691 
[epoch 32] step 6/44: loss=0.5639 
[epoch 32] step 8/44: loss=0.5644 
[epoch 32] step 10/44: loss=0.5646 
[epoch 32] step 12/44: loss=0.5570 
[epoch 32] step 14/44: loss=0.5520 
[epoch 32] step 16/44: loss=0.5546 
[epoch 32] step 18/44: loss=0.5580 
[epoch 32] step 20/44: loss=0.5587 
[epoch 32] step 22/44: loss=0.5610 
[epoch 32] step 24/44: loss=0.5630 
[epoch 32] step 26/44: loss=0.5650 
[epoch 32] step 28/44: loss=0.5656 
[epoch 32] step 30/44: loss=0.5654 
[epoch 32] step 32/44: loss=0.5648 
[epoch 32] step 34/44: loss=0.5634 
[epoch 32] step 36/44: loss=0.5618 
[epoch 32] step 38/44: loss=0.5598 
[epoch 32] step 40/44: loss=0.5581 
[epoch 32] step 42/44: loss=0.5578 
[epoch 32] step 44/44: loss=0.5583 
[epoch 32] train_loss(avg per step)=1.1166 lambda[min,max]=[0.358085,1.000000]
[epoch 32] val_loss=1.4356 qwk=('0.4580', '0.3927', '0.4352') averageQWK=0.4287 macroEMD=0.3048 tailR0=('0.1929', '0.0000', '0.0000') tailR0avg=0.0643
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     1    6   30    3    1
     0    3   88   29    2
     0    0   46   91    4
     0    0    5   10    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     1    3   27    7    1
     0    6   56   42    0
     0    0   44  119    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   11   38    3    0
     0   23  106   29    0
     0    4   46   60    0
     0    0    0    3    0
[epoch 33] step 2/44: loss=0.5384 
[epoch 33] step 4/44: loss=0.5472 
[epoch 33] step 6/44: loss=0.5341 
[epoch 33] step 8/44: loss=0.5330 
[epoch 33] step 10/44: loss=0.5347 
[epoch 33] step 12/44: loss=0.5462 
[epoch 33] step 14/44: loss=0.5494 
[epoch 33] step 16/44: loss=0.5530 
[epoch 33] step 18/44: loss=0.5572 
[epoch 33] step 20/44: loss=0.5560 
[epoch 33] step 22/44: loss=0.5566 
[epoch 33] step 24/44: loss=0.5572 
[epoch 33] step 26/44: loss=0.5567 
[epoch 33] step 28/44: loss=0.5568 
[epoch 33] step 30/44: loss=0.5549 
[epoch 33] step 32/44: loss=0.5547 
[epoch 33] step 34/44: loss=0.5551 
[epoch 33] step 36/44: loss=0.5555 
[epoch 33] step 38/44: loss=0.5539 
[epoch 33] step 40/44: loss=0.5532 
[epoch 33] step 42/44: loss=0.5531 
[epoch 33] step 44/44: loss=0.5545 
[epoch 33] train_loss(avg per step)=1.1090 lambda[min,max]=[0.370656,1.000000]
[epoch 33] val_loss=1.4245 qwk=('0.4866', '0.3900', '0.4390') averageQWK=0.4385 macroEMD=0.3053 tailR0=('0.2405', '0.0000', '0.0000') tailR0avg=0.0802
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     2    5   30    3    1
     0    2   87   31    2
     0    0   42   94    5
     0    0    4    9    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     1    3   23   11    1
     0    5   51   48    0
     0    0   33  130    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   10   38    4    0
     0   16  109   33    0
     0    3   42   65    0
     0    0    0    3    0
[epoch 34] step 2/44: loss=0.5199 
[epoch 34] step 4/44: loss=0.5130 
[epoch 34] step 6/44: loss=0.5269 
[epoch 34] step 8/44: loss=0.5291 
[epoch 34] step 10/44: loss=0.5302 
[epoch 34] step 12/44: loss=0.5393 
[epoch 34] step 14/44: loss=0.5418 
[epoch 34] step 16/44: loss=0.5430 
[epoch 34] step 18/44: loss=0.5438 
[epoch 34] step 20/44: loss=0.5461 
[epoch 34] step 22/44: loss=0.5447 
[epoch 34] step 24/44: loss=0.5462 
[epoch 34] step 26/44: loss=0.5457 
[epoch 34] step 28/44: loss=0.5468 
[epoch 34] step 30/44: loss=0.5471 
[epoch 34] step 32/44: loss=0.5460 
[epoch 34] step 34/44: loss=0.5496 
[epoch 34] step 36/44: loss=0.5510 
[epoch 34] step 38/44: loss=0.5500 
[epoch 34] step 40/44: loss=0.5498 
[epoch 34] step 42/44: loss=0.5493 
[epoch 34] step 44/44: loss=0.5531 
[epoch 34] train_loss(avg per step)=1.1061 lambda[min,max]=[0.357484,1.000000]
[epoch 34] val_loss=1.4292 qwk=('0.4526', '0.3960', '0.4356') averageQWK=0.4281 macroEMD=0.3041 tailR0=('0.1929', '0.0000', '0.0000') tailR0avg=0.0643
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     1    6   28    5    1
     0    3   79   38    2
     0    0   39   98    4
     0    0    4   11    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     0    4   24   11    0
     0    5   50   49    0
     0    0   32  131    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   10   38    4    0
     0   17  108   33    0
     0    4   40   66    0
     0    0    0    3    0
[epoch 35] step 2/44: loss=0.5619 
[epoch 35] step 4/44: loss=0.5647 
[epoch 35] step 6/44: loss=0.5586 
[epoch 35] step 8/44: loss=0.5592 
[epoch 35] step 10/44: loss=0.5604 
[epoch 35] step 12/44: loss=0.5611 
[epoch 35] step 14/44: loss=0.5612 
[epoch 35] step 16/44: loss=0.5610 
[epoch 35] step 18/44: loss=0.5616 
[epoch 35] step 20/44: loss=0.5574 
[epoch 35] step 22/44: loss=0.5575 
[epoch 35] step 24/44: loss=0.5587 
[epoch 35] step 26/44: loss=0.5570 
[epoch 35] step 28/44: loss=0.5554 
[epoch 35] step 30/44: loss=0.5540 
[epoch 35] step 32/44: loss=0.5553 
[epoch 35] step 34/44: loss=0.5549 
[epoch 35] step 36/44: loss=0.5532 
[epoch 35] step 38/44: loss=0.5520 
[epoch 35] step 40/44: loss=0.5532 
[epoch 35] step 42/44: loss=0.5528 
[epoch 35] step 44/44: loss=0.5580 
[epoch 35] train_loss(avg per step)=1.1161 lambda[min,max]=[0.339672,1.000000]
[epoch 35] val_loss=1.4341 qwk=('0.4544', '0.3759', '0.4480') averageQWK=0.4261 macroEMD=0.3045 tailR0=('0.2167', '0.0000', '0.0000') tailR0avg=0.0722
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     1    6   28    5    1
     0    3   81   36    2
     0    0   42   94    5
     0    0    4   10    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     0    5   22   11    1
     0    5   50   49    0
     0    0   35  128    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   10   38    4    0
     0   16  107   35    0
     0    3   39   68    0
     0    0    0    3    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold1/metrics.json
Done.
