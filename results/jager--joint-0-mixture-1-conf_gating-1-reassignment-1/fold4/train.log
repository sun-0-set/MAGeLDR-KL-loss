[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.5433 
[epoch 1] step 4/44: loss=0.5298 
[epoch 1] step 6/44: loss=0.5292 
[epoch 1] step 8/44: loss=0.5248 
[epoch 1] step 10/44: loss=0.5295 
[epoch 1] step 12/44: loss=0.5335 
[epoch 1] step 14/44: loss=0.5371 
[epoch 1] step 16/44: loss=0.5400 
[epoch 1] step 18/44: loss=0.5410 
[epoch 1] step 20/44: loss=0.5432 
[epoch 1] step 22/44: loss=0.5466 
[epoch 1] step 24/44: loss=0.5495 
[epoch 1] step 26/44: loss=0.5531 
[epoch 1] step 28/44: loss=0.5554 
[epoch 1] step 30/44: loss=0.5593 
[epoch 1] step 32/44: loss=0.5621 
[epoch 1] step 34/44: loss=0.5655 
[epoch 1] step 36/44: loss=0.5671 
[epoch 1] step 38/44: loss=0.5696 
[epoch 1] step 40/44: loss=0.5717 
[epoch 1] step 42/44: loss=0.5741 
[epoch 1] step 44/44: loss=0.5748 
[epoch 1] train_loss(avg per step)=1.1496 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.0804 qwk=('0.0392', '0.0617', '0.1391') averageQWK=0.0800 macroEMD=0.3821 tailR0=('0.0000', '0.2778', '0.5000') tailR0avg=0.2593
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    0    5    0
     0   63    0   19    0
     0  134    0   21    0
     0   50    1   22    0
     0    6    0    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     5    0    3    1    0
    57    0   17    2    0
   140    0   17    7    0
    54    0   12   14    0
     1    0    0    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    9   83    0    0
     0    5  160    1    0
     0    0   71    0    1
     0    0    0    0    1
[epoch 2] step 2/44: loss=0.6623 
[epoch 2] step 4/44: loss=0.6751 
[epoch 2] step 6/44: loss=0.6881 
[epoch 2] step 8/44: loss=0.7027 
[epoch 2] step 10/44: loss=0.7171 
[epoch 2] step 12/44: loss=0.7329 
[epoch 2] step 14/44: loss=0.7517 
[epoch 2] step 16/44: loss=0.7633 
[epoch 2] step 18/44: loss=0.7740 
[epoch 2] step 20/44: loss=0.7789 
[epoch 2] step 22/44: loss=0.7833 
[epoch 2] step 24/44: loss=0.7846 
[epoch 2] step 26/44: loss=0.7893 
[epoch 2] step 28/44: loss=0.7916 
[epoch 2] step 30/44: loss=0.7955 
[epoch 2] step 32/44: loss=0.7984 
[epoch 2] step 34/44: loss=0.8016 
[epoch 2] step 36/44: loss=0.8039 
[epoch 2] step 38/44: loss=0.8053 
[epoch 2] step 40/44: loss=0.8043 
[epoch 2] step 42/44: loss=0.8055 
[epoch 2] step 44/44: loss=0.8032 
[epoch 2] train_loss(avg per step)=1.6065 lambda[min,max]=[0.504713,1.000000]
[epoch 2] val_loss=1.5179 qwk=('0.0060', '0.0072', '0.0962') averageQWK=0.0365 macroEMD=0.3587 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0   15    0
     0    1    0   81    0
     0    0    0  155    0
     0    0    0   73    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    9    0
     0    0    2   74    0
     0    0    0  164    0
     0    0    0   80    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    4   17   71    0
     0    0   19  147    0
     0    0    4   68    0
     0    0    0    1    0
[epoch 3] step 2/44: loss=0.6900 
[epoch 3] step 4/44: loss=0.6853 
[epoch 3] step 6/44: loss=0.7062 
[epoch 3] step 8/44: loss=0.7181 
[epoch 3] step 10/44: loss=0.7313 
[epoch 3] step 12/44: loss=0.7449 
[epoch 3] step 14/44: loss=0.7569 
[epoch 3] step 16/44: loss=0.7636 
[epoch 3] step 18/44: loss=0.7719 
[epoch 3] step 20/44: loss=0.7796 
[epoch 3] step 22/44: loss=0.7802 
[epoch 3] step 24/44: loss=0.7767 
[epoch 3] step 26/44: loss=0.7738 
[epoch 3] step 28/44: loss=0.7753 
[epoch 3] step 30/44: loss=0.7735 
[epoch 3] step 32/44: loss=0.7732 
[epoch 3] step 34/44: loss=0.7742 
[epoch 3] step 36/44: loss=0.7773 
[epoch 3] step 38/44: loss=0.7830 
[epoch 3] step 40/44: loss=0.7879 
[epoch 3] step 42/44: loss=0.7894 
[epoch 3] step 44/44: loss=0.7879 
[epoch 3] train_loss(avg per step)=1.5758 lambda[min,max]=[0.504774,1.000000]
[epoch 3] val_loss=1.4206 qwk=('0.4849', '0.3702', '0.4956') averageQWK=0.4502 macroEMD=0.3243 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    4    2    0
     0   34   36   12    0
     0   29   57   69    0
     0    0   11   62    0
     0    0    2    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   63   13    0
     0    0   96   68    0
     0    0    8   72    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   42   39   11    0
     0   42   88   36    0
     0    1   19   52    0
     0    0    0    1    0
[epoch 4] step 2/44: loss=0.8283 
[epoch 4] step 4/44: loss=0.8287 
[epoch 4] step 6/44: loss=0.8166 
[epoch 4] step 8/44: loss=0.8205 
[epoch 4] step 10/44: loss=0.8213 
[epoch 4] step 12/44: loss=0.8199 
[epoch 4] step 14/44: loss=0.8186 
[epoch 4] step 16/44: loss=0.8192 
[epoch 4] step 18/44: loss=0.8161 
[epoch 4] step 20/44: loss=0.8154 
[epoch 4] step 22/44: loss=0.8130 
[epoch 4] step 24/44: loss=0.8117 
[epoch 4] step 26/44: loss=0.8138 
[epoch 4] step 28/44: loss=0.8105 
[epoch 4] step 30/44: loss=0.8098 
[epoch 4] step 32/44: loss=0.8079 
[epoch 4] step 34/44: loss=0.8072 
[epoch 4] step 36/44: loss=0.8072 
[epoch 4] step 38/44: loss=0.8075 
[epoch 4] step 40/44: loss=0.8095 
[epoch 4] step 42/44: loss=0.8131 
[epoch 4] step 44/44: loss=0.8112 
[epoch 4] train_loss(avg per step)=1.6224 lambda[min,max]=[0.500320,1.000000]
[epoch 4] val_loss=1.4933 qwk=('0.4037', '0.2496', '0.3590') averageQWK=0.3375 macroEMD=0.3186 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    2    0
     0   15   47   20    0
     0    1   75   79    0
     0    0    8   65    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    0   45   31    0
     0    0   48  116    0
     0    0    2   78    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    2   83    7    0
     0    0  140   26    0
     0    0   25   47    0
     0    0    0    1    0
[epoch 5] step 2/44: loss=0.8127 
[epoch 5] step 4/44: loss=0.8214 
[epoch 5] step 6/44: loss=0.8288 
[epoch 5] step 8/44: loss=0.8320 
[epoch 5] step 10/44: loss=0.8231 
[epoch 5] step 12/44: loss=0.8145 
[epoch 5] step 14/44: loss=0.8105 
[epoch 5] step 16/44: loss=0.8098 
[epoch 5] step 18/44: loss=0.8060 
[epoch 5] step 20/44: loss=0.8021 
[epoch 5] step 22/44: loss=0.8058 
[epoch 5] step 24/44: loss=0.8090 
[epoch 5] step 26/44: loss=0.8102 
[epoch 5] step 28/44: loss=0.8111 
[epoch 5] step 30/44: loss=0.8097 
[epoch 5] step 32/44: loss=0.8096 
[epoch 5] step 34/44: loss=0.8113 
[epoch 5] step 36/44: loss=0.8127 
[epoch 5] step 38/44: loss=0.8171 
[epoch 5] step 40/44: loss=0.8186 
[epoch 5] step 42/44: loss=0.8193 
[epoch 5] step 44/44: loss=0.8179 
[epoch 5] train_loss(avg per step)=1.6358 lambda[min,max]=[0.500038,1.000000]
[epoch 5] val_loss=1.5733 qwk=('0.2449', '0.2894', '0.2318') averageQWK=0.2554 macroEMD=0.3134 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    4    0
     0    2   42   38    0
     0    0   38  117    0
     0    0    0   73    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   50   26    0
     0    0   50  114    0
     0    0    1   79    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    2   48   42    0
     0    0   63  103    0
     0    0    2   70    0
     0    0    0    1    0
[epoch 6] step 2/44: loss=0.8382 
[epoch 6] step 4/44: loss=0.8358 
[epoch 6] step 6/44: loss=0.8273 
[epoch 6] step 8/44: loss=0.8150 
[epoch 6] step 10/44: loss=0.8125 
[epoch 6] step 12/44: loss=0.8117 
[epoch 6] step 14/44: loss=0.7989 
[epoch 6] step 16/44: loss=0.7889 
[epoch 6] step 18/44: loss=0.7870 
[epoch 6] step 20/44: loss=0.7864 
[epoch 6] step 22/44: loss=0.7893 
[epoch 6] step 24/44: loss=0.7880 
[epoch 6] step 26/44: loss=0.7899 
[epoch 6] step 28/44: loss=0.7902 
[epoch 6] step 30/44: loss=0.7904 
[epoch 6] step 32/44: loss=0.7924 
[epoch 6] step 34/44: loss=0.7941 
[epoch 6] step 36/44: loss=0.7927 
[epoch 6] step 38/44: loss=0.7905 
[epoch 6] step 40/44: loss=0.7874 
[epoch 6] step 42/44: loss=0.7869 
[epoch 6] step 44/44: loss=0.7816 
[epoch 6] train_loss(avg per step)=1.5631 lambda[min,max]=[0.500002,1.000000]
[epoch 6] val_loss=1.5102 qwk=('0.3893', '0.3264', '0.3408') averageQWK=0.3522 macroEMD=0.3041 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    2    0
     0   19   39   24    0
     0    3   54   98    0
     0    0    6   67    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    5   48   23    0
     0    0   58  106    0
     0    0    4   76    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    9   55   28    0
     0    0   85   81    0
     0    0    6   66    0
     0    0    0    1    0
[epoch 7] step 2/44: loss=0.7842 
[epoch 7] step 4/44: loss=0.7789 
[epoch 7] step 6/44: loss=0.8021 
[epoch 7] step 8/44: loss=0.8096 
[epoch 7] step 10/44: loss=0.8162 
[epoch 7] step 12/44: loss=0.8253 
[epoch 7] step 14/44: loss=0.8309 
[epoch 7] step 16/44: loss=0.8273 
[epoch 7] step 18/44: loss=0.8213 
[epoch 7] step 20/44: loss=0.8194 
[epoch 7] step 22/44: loss=0.8173 
[epoch 7] step 24/44: loss=0.8157 
[epoch 7] step 26/44: loss=0.8124 
[epoch 7] step 28/44: loss=0.8098 
[epoch 7] step 30/44: loss=0.8079 
[epoch 7] step 32/44: loss=0.8087 
[epoch 7] step 34/44: loss=0.8101 
[epoch 7] step 36/44: loss=0.8079 
[epoch 7] step 38/44: loss=0.8078 
[epoch 7] step 40/44: loss=0.8070 
[epoch 7] step 42/44: loss=0.8054 
[epoch 7] step 44/44: loss=0.8048 
[epoch 7] train_loss(avg per step)=1.6096 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.5281 qwk=('0.3797', '0.3505', '0.3515') averageQWK=0.3606 macroEMD=0.2976 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   11    2    0
     0    9   56   17    0
     0    0   79   75    1
     0    0   10   61    2
     0    0    0    9    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    4   52   20    0
     0    0   73   91    0
     0    0    4   76    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4   70   18    0
     0    0  113   53    0
     0    0   14   58    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=0.7499 
[epoch 8] step 4/44: loss=0.7377 
[epoch 8] step 6/44: loss=0.7447 
[epoch 8] step 8/44: loss=0.7482 
[epoch 8] step 10/44: loss=0.7556 
[epoch 8] step 12/44: loss=0.7583 
[epoch 8] step 14/44: loss=0.7583 
[epoch 8] step 16/44: loss=0.7564 
[epoch 8] step 18/44: loss=0.7553 
[epoch 8] step 20/44: loss=0.7595 
[epoch 8] step 22/44: loss=0.7625 
[epoch 8] step 24/44: loss=0.7658 
[epoch 8] step 26/44: loss=0.7700 
[epoch 8] step 28/44: loss=0.7726 
[epoch 8] step 30/44: loss=0.7759 
[epoch 8] step 32/44: loss=0.7774 
[epoch 8] step 34/44: loss=0.7795 
[epoch 8] step 36/44: loss=0.7794 
[epoch 8] step 38/44: loss=0.7791 
[epoch 8] step 40/44: loss=0.7791 
[epoch 8] step 42/44: loss=0.7763 
[epoch 8] step 44/44: loss=0.7705 
[epoch 8] train_loss(avg per step)=1.5411 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.4862 qwk=('0.4789', '0.4702', '0.4015') averageQWK=0.4502 macroEMD=0.2918 tailR0=('0.1000', '0.0000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    6    1    0
     0   19   48   14    1
     0    5   88   58    4
     0    0   10   56    7
     0    0    0    8    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   18   45   13    0
     0   12   85   67    0
     0    0    7   73    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   23   52   17    0
     0   20  104   42    0
     0    1   18   53    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=0.7266 
[epoch 9] step 4/44: loss=0.7219 
[epoch 9] step 6/44: loss=0.7347 
[epoch 9] step 8/44: loss=0.7392 
[epoch 9] step 10/44: loss=0.7414 
[epoch 9] step 12/44: loss=0.7541 
[epoch 9] step 14/44: loss=0.7630 
[epoch 9] step 16/44: loss=0.7638 
[epoch 9] step 18/44: loss=0.7689 
[epoch 9] step 20/44: loss=0.7745 
[epoch 9] step 22/44: loss=0.7738 
[epoch 9] step 24/44: loss=0.7764 
[epoch 9] step 26/44: loss=0.7784 
[epoch 9] step 28/44: loss=0.7783 
[epoch 9] step 30/44: loss=0.7763 
[epoch 9] step 32/44: loss=0.7743 
[epoch 9] step 34/44: loss=0.7732 
[epoch 9] step 36/44: loss=0.7714 
[epoch 9] step 38/44: loss=0.7702 
[epoch 9] step 40/44: loss=0.7669 
[epoch 9] step 42/44: loss=0.7654 
[epoch 9] step 44/44: loss=0.7612 
[epoch 9] train_loss(avg per step)=1.5224 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.4822 qwk=('0.3655', '0.4028', '0.3738') averageQWK=0.3807 macroEMD=0.2971 tailR0=('0.1000', '0.0000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   13    1    0
     0    3   70    9    0
     0    0  102   48    5
     0    0   17   49    7
     0    0    4    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0   10   52   14    0
     0    1   91   72    0
     0    0    7   73    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   80    9    0
     0    0  140   26    0
     0    0   27   45    0
     0    0    0    1    0
[epoch 10] step 2/44: loss=0.7584 
[epoch 10] step 4/44: loss=0.7776 
[epoch 10] step 6/44: loss=0.7728 
[epoch 10] step 8/44: loss=0.7708 
[epoch 10] step 10/44: loss=0.7701 
[epoch 10] step 12/44: loss=0.7628 
[epoch 10] step 14/44: loss=0.7610 
[epoch 10] step 16/44: loss=0.7610 
[epoch 10] step 18/44: loss=0.7601 
[epoch 10] step 20/44: loss=0.7569 
[epoch 10] step 22/44: loss=0.7568 
[epoch 10] step 24/44: loss=0.7572 
[epoch 10] step 26/44: loss=0.7576 
[epoch 10] step 28/44: loss=0.7581 
[epoch 10] step 30/44: loss=0.7594 
[epoch 10] step 32/44: loss=0.7584 
[epoch 10] step 34/44: loss=0.7561 
[epoch 10] step 36/44: loss=0.7562 
[epoch 10] step 38/44: loss=0.7556 
[epoch 10] step 40/44: loss=0.7539 
[epoch 10] step 42/44: loss=0.7529 
[epoch 10] step 44/44: loss=0.7522 
[epoch 10] train_loss(avg per step)=1.5045 lambda[min,max]=[0.493470,1.000000]
[epoch 10] val_loss=1.4328 qwk=('0.4276', '0.4384', '0.4202') averageQWK=0.4287 macroEMD=0.2933 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   13   63    6    0
     0    2  118   35    0
     0    0   21   51    1
     0    0    5    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   10   57    9    0
     0    2  119   43    0
     0    0   14   66    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   17   68    7    0
     0   16  134   16    0
     0    1   29   42    0
     0    0    0    1    0
[epoch 11] step 2/44: loss=0.7199 
[epoch 11] step 4/44: loss=0.7104 
[epoch 11] step 6/44: loss=0.7085 
[epoch 11] step 8/44: loss=0.7150 
[epoch 11] step 10/44: loss=0.7175 
[epoch 11] step 12/44: loss=0.7236 
[epoch 11] step 14/44: loss=0.7241 
[epoch 11] step 16/44: loss=0.7356 
[epoch 11] step 18/44: loss=0.7362 
[epoch 11] step 20/44: loss=0.7367 
[epoch 11] step 22/44: loss=0.7381 
[epoch 11] step 24/44: loss=0.7392 
[epoch 11] step 26/44: loss=0.7428 
[epoch 11] step 28/44: loss=0.7453 
[epoch 11] step 30/44: loss=0.7453 
[epoch 11] step 32/44: loss=0.7461 
[epoch 11] step 34/44: loss=0.7451 
[epoch 11] step 36/44: loss=0.7418 
[epoch 11] step 38/44: loss=0.7416 
[epoch 11] step 40/44: loss=0.7417 
[epoch 11] step 42/44: loss=0.7414 
[epoch 11] step 44/44: loss=0.7471 
[epoch 11] train_loss(avg per step)=1.4943 lambda[min,max]=[0.471728,1.000000]
[epoch 11] val_loss=1.4945 qwk=('0.4603', '0.4026', '0.3908') averageQWK=0.4179 macroEMD=0.2956 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    2    0
     0   20   48   14    0
     0    5   95   54    1
     0    0   10   59    4
     0    0    1    8    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   15   42   19    0
     0    4   90   70    0
     0    0    7   73    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   10   74    8    0
     0   11  137   18    0
     0    0   30   42    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=0.6750 
[epoch 12] step 4/44: loss=0.6871 
[epoch 12] step 6/44: loss=0.7045 
[epoch 12] step 8/44: loss=0.7086 
[epoch 12] step 10/44: loss=0.7088 
[epoch 12] step 12/44: loss=0.7081 
[epoch 12] step 14/44: loss=0.7118 
[epoch 12] step 16/44: loss=0.7116 
[epoch 12] step 18/44: loss=0.7137 
[epoch 12] step 20/44: loss=0.7180 
[epoch 12] step 22/44: loss=0.7167 
[epoch 12] step 24/44: loss=0.7191 
[epoch 12] step 26/44: loss=0.7258 
[epoch 12] step 28/44: loss=0.7260 
[epoch 12] step 30/44: loss=0.7263 
[epoch 12] step 32/44: loss=0.7265 
[epoch 12] step 34/44: loss=0.7263 
[epoch 12] step 36/44: loss=0.7257 
[epoch 12] step 38/44: loss=0.7261 
[epoch 12] step 40/44: loss=0.7256 
[epoch 12] step 42/44: loss=0.7246 
[epoch 12] step 44/44: loss=0.7210 
[epoch 12] train_loss(avg per step)=1.4421 lambda[min,max]=[0.442083,1.000000]
[epoch 12] val_loss=1.5545 qwk=('0.3416', '0.3304', '0.3310') averageQWK=0.3344 macroEMD=0.3049 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   11    2    0
     0    4   60   18    0
     0    1   77   76    1
     0    0   10   61    2
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0    6   48   22    0
     0    2   77   85    0
     0    0    7   72    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4   73   15    0
     0    3  126   37    0
     0    0   23   49    0
     0    0    0    1    0
[epoch 13] step 2/44: loss=0.7331 
[epoch 13] step 4/44: loss=0.7399 
[epoch 13] step 6/44: loss=0.7413 
[epoch 13] step 8/44: loss=0.7301 
[epoch 13] step 10/44: loss=0.7213 
[epoch 13] step 12/44: loss=0.7149 
[epoch 13] step 14/44: loss=0.7069 
[epoch 13] step 16/44: loss=0.7044 
[epoch 13] step 18/44: loss=0.7047 
[epoch 13] step 20/44: loss=0.7066 
[epoch 13] step 22/44: loss=0.7071 
[epoch 13] step 24/44: loss=0.7036 
[epoch 13] step 26/44: loss=0.7051 
[epoch 13] step 28/44: loss=0.7050 
[epoch 13] step 30/44: loss=0.7059 
[epoch 13] step 32/44: loss=0.7051 
[epoch 13] step 34/44: loss=0.7049 
[epoch 13] step 36/44: loss=0.7045 
[epoch 13] step 38/44: loss=0.7040 
[epoch 13] step 40/44: loss=0.7051 
[epoch 13] step 42/44: loss=0.7059 
[epoch 13] step 44/44: loss=0.7180 
[epoch 13] train_loss(avg per step)=1.4360 lambda[min,max]=[0.428632,1.000000]
[epoch 13] val_loss=1.4658 qwk=('0.4615', '0.4328', '0.3309') averageQWK=0.4084 macroEMD=0.3031 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   16   62    4    0
     0    2  109   44    0
     0    0   18   54    1
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   11   54   11    0
     0    4  100   60    0
     0    0    8   72    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    5   78    9    0
     0    7  134   25    0
     0    0   32   40    0
     0    0    0    1    0
[epoch 14] step 2/44: loss=0.7116 
[epoch 14] step 4/44: loss=0.7066 
[epoch 14] step 6/44: loss=0.6943 
[epoch 14] step 8/44: loss=0.6848 
[epoch 14] step 10/44: loss=0.6828 
[epoch 14] step 12/44: loss=0.6829 
[epoch 14] step 14/44: loss=0.6814 
[epoch 14] step 16/44: loss=0.6895 
[epoch 14] step 18/44: loss=0.6879 
[epoch 14] step 20/44: loss=0.6870 
[epoch 14] step 22/44: loss=0.6862 
[epoch 14] step 24/44: loss=0.6869 
[epoch 14] step 26/44: loss=0.6889 
[epoch 14] step 28/44: loss=0.6872 
[epoch 14] step 30/44: loss=0.6875 
[epoch 14] step 32/44: loss=0.6918 
[epoch 14] step 34/44: loss=0.6925 
[epoch 14] step 36/44: loss=0.6956 
[epoch 14] step 38/44: loss=0.6961 
[epoch 14] step 40/44: loss=0.6974 
[epoch 14] step 42/44: loss=0.6959 
[epoch 14] step 44/44: loss=0.6958 
[epoch 14] train_loss(avg per step)=1.3917 lambda[min,max]=[0.443629,1.000000]
[epoch 14] val_loss=1.4650 qwk=('0.4561', '0.4868', '0.3856') averageQWK=0.4428 macroEMD=0.3042 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    6    1    0
     0   25   52    5    0
     0   12  114   25    4
     0    0   28   38    7
     0    0    7    2    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   25   41   10    0
     0   18  115   29    2
     0    0   21   55    4
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   11   75    6    0
     0   12  141   13    0
     0    0   35   37    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=0.7087 
[epoch 15] step 4/44: loss=0.7201 
[epoch 15] step 6/44: loss=0.7172 
[epoch 15] step 8/44: loss=0.7103 
[epoch 15] step 10/44: loss=0.7117 
[epoch 15] step 12/44: loss=0.7032 
[epoch 15] step 14/44: loss=0.6954 
[epoch 15] step 16/44: loss=0.6911 
[epoch 15] step 18/44: loss=0.6883 
[epoch 15] step 20/44: loss=0.6846 
[epoch 15] step 22/44: loss=0.6801 
[epoch 15] step 24/44: loss=0.6815 
[epoch 15] step 26/44: loss=0.6809 
[epoch 15] step 28/44: loss=0.6799 
[epoch 15] step 30/44: loss=0.6782 
[epoch 15] step 32/44: loss=0.6796 
[epoch 15] step 34/44: loss=0.6804 
[epoch 15] step 36/44: loss=0.6830 
[epoch 15] step 38/44: loss=0.6830 
[epoch 15] step 40/44: loss=0.6822 
[epoch 15] step 42/44: loss=0.6852 
[epoch 15] step 44/44: loss=0.6877 
[epoch 15] train_loss(avg per step)=1.3754 lambda[min,max]=[0.423801,1.000000]
[epoch 15] val_loss=1.4908 qwk=('0.3868', '0.3786', '0.3405') averageQWK=0.3686 macroEMD=0.3098 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   10   67    5    0
     0    5  117   29    4
     0    0   25   44    4
     0    0    6    3    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    5   55   16    0
     0    1  102   61    0
     0    0    8   72    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5   76   11    0
     0    7  127   32    0
     0    0   29   43    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=0.6757 
[epoch 16] step 4/44: loss=0.6569 
[epoch 16] step 6/44: loss=0.6613 
[epoch 16] step 8/44: loss=0.6541 
[epoch 16] step 10/44: loss=0.6498 
[epoch 16] step 12/44: loss=0.6511 
[epoch 16] step 14/44: loss=0.6498 
[epoch 16] step 16/44: loss=0.6519 
[epoch 16] step 18/44: loss=0.6533 
[epoch 16] step 20/44: loss=0.6543 
[epoch 16] step 22/44: loss=0.6547 
[epoch 16] step 24/44: loss=0.6526 
[epoch 16] step 26/44: loss=0.6543 
[epoch 16] step 28/44: loss=0.6543 
[epoch 16] step 30/44: loss=0.6545 
[epoch 16] step 32/44: loss=0.6577 
[epoch 16] step 34/44: loss=0.6607 
[epoch 16] step 36/44: loss=0.6615 
[epoch 16] step 38/44: loss=0.6626 
[epoch 16] step 40/44: loss=0.6635 
[epoch 16] step 42/44: loss=0.6645 
[epoch 16] step 44/44: loss=0.6570 
[epoch 16] train_loss(avg per step)=1.3140 lambda[min,max]=[0.376936,1.000000]
[epoch 16] val_loss=1.5195 qwk=('0.4214', '0.4016', '0.3217') averageQWK=0.3816 macroEMD=0.3064 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    2    0
     0   19   51   12    0
     0    5   86   59    5
     0    0   14   54    5
     0    0    3    6    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   13   43   20    0
     0    7   90   67    0
     0    0    7   71    2
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    2   76   14    0
     0    1  115   50    0
     0    0   23   49    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=0.6547 
[epoch 17] step 4/44: loss=0.6645 
[epoch 17] step 6/44: loss=0.6634 
[epoch 17] step 8/44: loss=0.6633 
[epoch 17] step 10/44: loss=0.6659 
[epoch 17] step 12/44: loss=0.6682 
[epoch 17] step 14/44: loss=0.6671 
[epoch 17] step 16/44: loss=0.6685 
[epoch 17] step 18/44: loss=0.6632 
[epoch 17] step 20/44: loss=0.6658 
[epoch 17] step 22/44: loss=0.6659 
[epoch 17] step 24/44: loss=0.6662 
[epoch 17] step 26/44: loss=0.6641 
[epoch 17] step 28/44: loss=0.6654 
[epoch 17] step 30/44: loss=0.6645 
[epoch 17] step 32/44: loss=0.6598 
[epoch 17] step 34/44: loss=0.6574 
[epoch 17] step 36/44: loss=0.6560 
[epoch 17] step 38/44: loss=0.6552 
[epoch 17] step 40/44: loss=0.6544 
[epoch 17] step 42/44: loss=0.6540 
[epoch 17] step 44/44: loss=0.6607 
[epoch 17] train_loss(avg per step)=1.3215 lambda[min,max]=[0.390773,1.000000]
[epoch 17] val_loss=1.5122 qwk=('0.4593', '0.4162', '0.3630') averageQWK=0.4129 macroEMD=0.3004 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   18   58    6    0
     0    6  105   42    2
     0    0   18   51    4
     0    0    4    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   15   44   17    0
     0    6   90   68    0
     0    0    7   72    1
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8   69   15    0
     0   13  108   45    0
     0    0   19   53    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=0.6605 
[epoch 18] step 4/44: loss=0.6624 
[epoch 18] step 6/44: loss=0.6521 
[epoch 18] step 8/44: loss=0.6529 
[epoch 18] step 10/44: loss=0.6568 
[epoch 18] step 12/44: loss=0.6550 
[epoch 18] step 14/44: loss=0.6504 
[epoch 18] step 16/44: loss=0.6425 
[epoch 18] step 18/44: loss=0.6363 
[epoch 18] step 20/44: loss=0.6358 
[epoch 18] step 22/44: loss=0.6305 
[epoch 18] step 24/44: loss=0.6310 
[epoch 18] step 26/44: loss=0.6313 
[epoch 18] step 28/44: loss=0.6303 
[epoch 18] step 30/44: loss=0.6325 
[epoch 18] step 32/44: loss=0.6348 
[epoch 18] step 34/44: loss=0.6377 
[epoch 18] step 36/44: loss=0.6388 
[epoch 18] step 38/44: loss=0.6420 
[epoch 18] step 40/44: loss=0.6450 
[epoch 18] step 42/44: loss=0.6434 
[epoch 18] step 44/44: loss=0.6470 
[epoch 18] train_loss(avg per step)=1.2939 lambda[min,max]=[0.370955,1.000000]
[epoch 18] val_loss=1.5137 qwk=('0.4659', '0.4431', '0.4034') averageQWK=0.4375 macroEMD=0.2995 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    7    1    0
     0   25   46   11    0
     0   12   90   51    2
     0    0   14   58    1
     0    0    4    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   26   30   20    0
     0   19   82   63    0
     0    0    8   72    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   14   68   10    0
     0   17  115   34    0
     0    0   24   48    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=0.6100 
[epoch 19] step 4/44: loss=0.6121 
[epoch 19] step 6/44: loss=0.6177 
[epoch 19] step 8/44: loss=0.6095 
[epoch 19] step 10/44: loss=0.6073 
[epoch 19] step 12/44: loss=0.6085 
[epoch 19] step 14/44: loss=0.6127 
[epoch 19] step 16/44: loss=0.6124 
[epoch 19] step 18/44: loss=0.6176 
[epoch 19] step 20/44: loss=0.6224 
[epoch 19] step 22/44: loss=0.6279 
[epoch 19] step 24/44: loss=0.6294 
[epoch 19] step 26/44: loss=0.6250 
[epoch 19] step 28/44: loss=0.6254 
[epoch 19] step 30/44: loss=0.6247 
[epoch 19] step 32/44: loss=0.6245 
[epoch 19] step 34/44: loss=0.6232 
[epoch 19] step 36/44: loss=0.6216 
[epoch 19] step 38/44: loss=0.6183 
[epoch 19] step 40/44: loss=0.6163 
[epoch 19] step 42/44: loss=0.6152 
[epoch 19] step 44/44: loss=0.6133 
[epoch 19] train_loss(avg per step)=1.2266 lambda[min,max]=[0.373142,1.000000]
[epoch 19] val_loss=1.5150 qwk=('0.4395', '0.3845', '0.3307') averageQWK=0.3849 macroEMD=0.3031 tailR0=('0.1000', '0.0000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   17   54   10    1
     0    6   88   56    5
     0    0   12   54    7
     0    0    3    5    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   13   43   20    0
     0    7   84   72    1
     0    0    7   71    2
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    3   74   15    0
     0    1  115   50    0
     0    0   19   53    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=0.6863 
[epoch 20] step 4/44: loss=0.7022 
[epoch 20] step 6/44: loss=0.6969 
[epoch 20] step 8/44: loss=0.6944 
[epoch 20] step 10/44: loss=0.6830 
[epoch 20] step 12/44: loss=0.6695 
[epoch 20] step 14/44: loss=0.6651 
[epoch 20] step 16/44: loss=0.6571 
[epoch 20] step 18/44: loss=0.6544 
[epoch 20] step 20/44: loss=0.6499 
[epoch 20] step 22/44: loss=0.6417 
[epoch 20] step 24/44: loss=0.6353 
[epoch 20] step 26/44: loss=0.6307 
[epoch 20] step 28/44: loss=0.6313 
[epoch 20] step 30/44: loss=0.6311 
[epoch 20] step 32/44: loss=0.6308 
[epoch 20] step 34/44: loss=0.6315 
[epoch 20] step 36/44: loss=0.6323 
[epoch 20] step 38/44: loss=0.6327 
[epoch 20] step 40/44: loss=0.6325 
[epoch 20] step 42/44: loss=0.6313 
[epoch 20] step 44/44: loss=0.6302 
[epoch 20] train_loss(avg per step)=1.2605 lambda[min,max]=[0.373963,1.000000]
[epoch 20] val_loss=1.5021 qwk=('0.4184', '0.4072', '0.3732') averageQWK=0.3996 macroEMD=0.3060 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   16   56   10    0
     0    6   94   53    2
     0    0   15   57    1
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   15   43   18    0
     0   12   80   72    0
     0    0    7   73    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   10   73    9    0
     0   14  123   29    0
     0    0   29   43    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=0.6212 
[epoch 21] step 4/44: loss=0.5824 
[epoch 21] step 6/44: loss=0.5892 
[epoch 21] step 8/44: loss=0.5911 
[epoch 21] step 10/44: loss=0.5949 
[epoch 21] step 12/44: loss=0.5857 
[epoch 21] step 14/44: loss=0.5872 
[epoch 21] step 16/44: loss=0.5822 
[epoch 21] step 18/44: loss=0.5871 
[epoch 21] step 20/44: loss=0.5905 
[epoch 21] step 22/44: loss=0.5973 
[epoch 21] step 24/44: loss=0.6066 
[epoch 21] step 26/44: loss=0.6086 
[epoch 21] step 28/44: loss=0.6108 
[epoch 21] step 30/44: loss=0.6109 
[epoch 21] step 32/44: loss=0.6108 
[epoch 21] step 34/44: loss=0.6096 
[epoch 21] step 36/44: loss=0.6094 
[epoch 21] step 38/44: loss=0.6077 
[epoch 21] step 40/44: loss=0.6071 
[epoch 21] step 42/44: loss=0.6064 
[epoch 21] step 44/44: loss=0.6022 
[epoch 21] train_loss(avg per step)=1.2045 lambda[min,max]=[0.376384,1.000000]
[epoch 21] val_loss=1.4739 qwk=('0.4243', '0.4125', '0.3599') averageQWK=0.3989 macroEMD=0.3122 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   18   58    6    0
     0    5  112   32    6
     0    0   25   41    7
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   13   49   14    0
     0    7   95   62    0
     0    0   10   68    2
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   10   69   13    0
     0   18  112   36    0
     0    0   24   48    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=0.5857 
[epoch 22] step 4/44: loss=0.5771 
[epoch 22] step 6/44: loss=0.5881 
[epoch 22] step 8/44: loss=0.6017 
[epoch 22] step 10/44: loss=0.6013 
[epoch 22] step 12/44: loss=0.5979 
[epoch 22] step 14/44: loss=0.5962 
[epoch 22] step 16/44: loss=0.5965 
[epoch 22] step 18/44: loss=0.5933 
[epoch 22] step 20/44: loss=0.5952 
[epoch 22] step 22/44: loss=0.5995 
[epoch 22] step 24/44: loss=0.6031 
[epoch 22] step 26/44: loss=0.6016 
[epoch 22] step 28/44: loss=0.6041 
[epoch 22] step 30/44: loss=0.5999 
[epoch 22] step 32/44: loss=0.5984 
[epoch 22] step 34/44: loss=0.5968 
[epoch 22] step 36/44: loss=0.5954 
[epoch 22] step 38/44: loss=0.5947 
[epoch 22] step 40/44: loss=0.5931 
[epoch 22] step 42/44: loss=0.5935 
[epoch 22] step 44/44: loss=0.5916 
[epoch 22] train_loss(avg per step)=1.1832 lambda[min,max]=[0.379765,1.000000]
[epoch 22] val_loss=1.4656 qwk=('0.4260', '0.4161', '0.3679') averageQWK=0.4033 macroEMD=0.3092 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   13   65    4    0
     0    4  114   34    3
     0    0   22   47    4
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   15   46   15    0
     0    9   92   62    1
     0    0    8   70    2
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   18   64   10    0
     0   24  112   30    0
     0    2   28   42    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=0.5887 
[epoch 23] step 4/44: loss=0.5888 
[epoch 23] step 6/44: loss=0.6039 
[epoch 23] step 8/44: loss=0.6109 
[epoch 23] step 10/44: loss=0.6208 
[epoch 23] step 12/44: loss=0.6261 
[epoch 23] step 14/44: loss=0.6246 
[epoch 23] step 16/44: loss=0.6224 
[epoch 23] step 18/44: loss=0.6179 
[epoch 23] step 20/44: loss=0.6135 
[epoch 23] step 22/44: loss=0.6109 
[epoch 23] step 24/44: loss=0.6082 
[epoch 23] step 26/44: loss=0.6062 
[epoch 23] step 28/44: loss=0.6033 
[epoch 23] step 30/44: loss=0.6008 
[epoch 23] step 32/44: loss=0.5984 
[epoch 23] step 34/44: loss=0.5975 
[epoch 23] step 36/44: loss=0.5973 
[epoch 23] step 38/44: loss=0.5971 
[epoch 23] step 40/44: loss=0.5964 
[epoch 23] step 42/44: loss=0.5973 
[epoch 23] step 44/44: loss=0.5956 
[epoch 23] train_loss(avg per step)=1.1913 lambda[min,max]=[0.363219,1.000000]
[epoch 23] val_loss=1.5357 qwk=('0.4210', '0.3723', '0.3567') averageQWK=0.3833 macroEMD=0.3085 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   16   52   14    0
     0    6   82   65    2
     0    0   11   60    2
     0    0    2    7    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    7   54   15    0
     0    1   99   64    0
     0    0   10   70    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    9   70   13    0
     0   15   98   53    0
     0    0   22   50    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=0.6274 
[epoch 24] step 4/44: loss=0.6249 
[epoch 24] step 6/44: loss=0.6197 
[epoch 24] step 8/44: loss=0.6192 
[epoch 24] step 10/44: loss=0.6117 
[epoch 24] step 12/44: loss=0.6127 
[epoch 24] step 14/44: loss=0.6006 
[epoch 24] step 16/44: loss=0.5953 
[epoch 24] step 18/44: loss=0.5944 
[epoch 24] step 20/44: loss=0.5932 
[epoch 24] step 22/44: loss=0.5916 
[epoch 24] step 24/44: loss=0.5919 
[epoch 24] step 26/44: loss=0.5908 
[epoch 24] step 28/44: loss=0.5893 
[epoch 24] step 30/44: loss=0.5890 
[epoch 24] step 32/44: loss=0.5897 
[epoch 24] step 34/44: loss=0.5902 
[epoch 24] step 36/44: loss=0.5900 
[epoch 24] step 38/44: loss=0.5896 
[epoch 24] step 40/44: loss=0.5913 
[epoch 24] step 42/44: loss=0.5918 
[epoch 24] step 44/44: loss=0.5894 
[epoch 24] train_loss(avg per step)=1.1788 lambda[min,max]=[0.369645,1.000000]
[epoch 24] val_loss=1.5047 qwk=('0.3970', '0.3779', '0.3316') averageQWK=0.3688 macroEMD=0.3138 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   11   62    9    0
     0    4   95   53    3
     0    0   16   54    3
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    9   49   18    0
     0    4   90   70    0
     0    0    7   72    1
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    9   70   13    0
     0   16  108   42    0
     0    0   28   44    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=0.5644 
[epoch 25] step 4/44: loss=0.5599 
[epoch 25] step 6/44: loss=0.5566 
[epoch 25] step 8/44: loss=0.5463 
[epoch 25] step 10/44: loss=0.5426 
[epoch 25] step 12/44: loss=0.5467 
[epoch 25] step 14/44: loss=0.5559 
[epoch 25] step 16/44: loss=0.5574 
[epoch 25] step 18/44: loss=0.5627 
[epoch 25] step 20/44: loss=0.5646 
[epoch 25] step 22/44: loss=0.5672 
[epoch 25] step 24/44: loss=0.5716 
[epoch 25] step 26/44: loss=0.5730 
[epoch 25] step 28/44: loss=0.5756 
[epoch 25] step 30/44: loss=0.5753 
[epoch 25] step 32/44: loss=0.5750 
[epoch 25] step 34/44: loss=0.5722 
[epoch 25] step 36/44: loss=0.5683 
[epoch 25] step 38/44: loss=0.5647 
[epoch 25] step 40/44: loss=0.5635 
[epoch 25] step 42/44: loss=0.5627 
[epoch 25] step 44/44: loss=0.5630 
[epoch 25] train_loss(avg per step)=1.1260 lambda[min,max]=[0.372800,1.000000]
[epoch 25] val_loss=1.4611 qwk=('0.4018', '0.4072', '0.3386') averageQWK=0.3825 macroEMD=0.3109 tailR0=('0.1000', '0.0000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   13   55   14    0
     0    7   89   57    2
     0    0   17   49    7
     0    0    3    5    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   15   47   14    0
     0   12   89   62    1
     0    0   11   67    2
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    9   74    9    0
     0   12  136   18    0
     0    0   36   36    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=0.5637 
[epoch 26] step 4/44: loss=0.5659 
[epoch 26] step 6/44: loss=0.5690 
[epoch 26] step 8/44: loss=0.5929 
[epoch 26] step 10/44: loss=0.5978 
[epoch 26] step 12/44: loss=0.5986 
[epoch 26] step 14/44: loss=0.6046 
[epoch 26] step 16/44: loss=0.6071 
[epoch 26] step 18/44: loss=0.6001 
[epoch 26] step 20/44: loss=0.5953 
[epoch 26] step 22/44: loss=0.5899 
[epoch 26] step 24/44: loss=0.5881 
[epoch 26] step 26/44: loss=0.5847 
[epoch 26] step 28/44: loss=0.5825 
[epoch 26] step 30/44: loss=0.5832 
[epoch 26] step 32/44: loss=0.5820 
[epoch 26] step 34/44: loss=0.5815 
[epoch 26] step 36/44: loss=0.5822 
[epoch 26] step 38/44: loss=0.5804 
[epoch 26] step 40/44: loss=0.5790 
[epoch 26] step 42/44: loss=0.5778 
[epoch 26] step 44/44: loss=0.5792 
[epoch 26] train_loss(avg per step)=1.1583 lambda[min,max]=[0.377999,1.000000]
[epoch 26] val_loss=1.5145 qwk=('0.3934', '0.3815', '0.3464') averageQWK=0.3738 macroEMD=0.3057 tailR0=('0.1000', '0.0000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    9    2    0
     0   13   53   16    0
     0    6   78   69    2
     0    0   12   58    3
     0    0    2    6    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   10   52   14    0
     0    5   87   71    1
     0    0   11   69    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   10   69   13    0
     0   20  103   43    0
     0    0   25   47    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=0.5413 
[epoch 27] step 4/44: loss=0.5507 
[epoch 27] step 6/44: loss=0.5464 
[epoch 27] step 8/44: loss=0.5431 
[epoch 27] step 10/44: loss=0.5466 
[epoch 27] step 12/44: loss=0.5505 
[epoch 27] step 14/44: loss=0.5529 
[epoch 27] step 16/44: loss=0.5540 
[epoch 27] step 18/44: loss=0.5605 
[epoch 27] step 20/44: loss=0.5699 
[epoch 27] step 22/44: loss=0.5750 
[epoch 27] step 24/44: loss=0.5790 
[epoch 27] step 26/44: loss=0.5799 
[epoch 27] step 28/44: loss=0.5787 
[epoch 27] step 30/44: loss=0.5783 
[epoch 27] step 32/44: loss=0.5766 
[epoch 27] step 34/44: loss=0.5737 
[epoch 27] step 36/44: loss=0.5707 
[epoch 27] step 38/44: loss=0.5696 
[epoch 27] step 40/44: loss=0.5676 
[epoch 27] step 42/44: loss=0.5632 
[epoch 27] step 44/44: loss=0.5544 
[epoch 27] train_loss(avg per step)=1.1088 lambda[min,max]=[0.372371,1.000000]
[epoch 27] val_loss=1.5322 qwk=('0.3896', '0.3689', '0.3123') averageQWK=0.3569 macroEMD=0.3135 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   10   59   13    0
     0    4   84   63    4
     0    0   12   56    5
     0    0    4    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    8   50   18    0
     0    4   81   79    0
     0    0    9   69    2
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    6   70   16    0
     0    7  106   53    0
     0    0   22   50    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=0.5670 
[epoch 28] step 4/44: loss=0.5869 
[epoch 28] step 6/44: loss=0.5845 
[epoch 28] step 8/44: loss=0.5875 
[epoch 28] step 10/44: loss=0.5905 
[epoch 28] step 12/44: loss=0.5931 
[epoch 28] step 14/44: loss=0.5923 
[epoch 28] step 16/44: loss=0.5916 
[epoch 28] step 18/44: loss=0.5890 
[epoch 28] step 20/44: loss=0.5865 
[epoch 28] step 22/44: loss=0.5863 
[epoch 28] step 24/44: loss=0.5822 
[epoch 28] step 26/44: loss=0.5802 
[epoch 28] step 28/44: loss=0.5788 
[epoch 28] step 30/44: loss=0.5775 
[epoch 28] step 32/44: loss=0.5752 
[epoch 28] step 34/44: loss=0.5740 
[epoch 28] step 36/44: loss=0.5741 
[epoch 28] step 38/44: loss=0.5734 
[epoch 28] step 40/44: loss=0.5735 
[epoch 28] step 42/44: loss=0.5721 
[epoch 28] step 44/44: loss=0.5739 
[epoch 28] train_loss(avg per step)=1.1477 lambda[min,max]=[0.367488,1.000000]
[epoch 28] val_loss=1.5444 qwk=('0.3774', '0.3780', '0.3383') averageQWK=0.3646 macroEMD=0.3102 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   12   55   15    0
     0    5   86   61    3
     0    0   17   52    4
     0    0    3    6    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   13   44   19    0
     0    8   79   76    1
     0    0    9   69    2
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8   71   13    0
     1   15  106   44    0
     0    0   25   47    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=0.5659 
[epoch 29] step 4/44: loss=0.5729 
[epoch 29] step 6/44: loss=0.5601 
[epoch 29] step 8/44: loss=0.5582 
[epoch 29] step 10/44: loss=0.5583 
[epoch 29] step 12/44: loss=0.5606 
[epoch 29] step 14/44: loss=0.5581 
[epoch 29] step 16/44: loss=0.5577 
[epoch 29] step 18/44: loss=0.5540 
[epoch 29] step 20/44: loss=0.5533 
[epoch 29] step 22/44: loss=0.5541 
[epoch 29] step 24/44: loss=0.5564 
[epoch 29] step 26/44: loss=0.5555 
[epoch 29] step 28/44: loss=0.5571 
[epoch 29] step 30/44: loss=0.5565 
[epoch 29] step 32/44: loss=0.5566 
[epoch 29] step 34/44: loss=0.5571 
[epoch 29] step 36/44: loss=0.5588 
[epoch 29] step 38/44: loss=0.5598 
[epoch 29] step 40/44: loss=0.5612 
[epoch 29] step 42/44: loss=0.5611 
[epoch 29] step 44/44: loss=0.5558 
[epoch 29] train_loss(avg per step)=1.1115 lambda[min,max]=[0.361818,1.000000]
[epoch 29] val_loss=1.5386 qwk=('0.3793', '0.3628', '0.3437') averageQWK=0.3619 macroEMD=0.3080 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   10   60   12    0
     0    4   89   59    3
     0    0   15   54    4
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   10   45   21    0
     0    5   76   83    0
     0    0    6   74    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   10   68   14    0
     0   20   94   52    0
     0    0   23   49    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=0.5718 
[epoch 30] step 4/44: loss=0.5642 
[epoch 30] step 6/44: loss=0.5684 
[epoch 30] step 8/44: loss=0.5628 
[epoch 30] step 10/44: loss=0.5637 
[epoch 30] step 12/44: loss=0.5613 
[epoch 30] step 14/44: loss=0.5577 
[epoch 30] step 16/44: loss=0.5539 
[epoch 30] step 18/44: loss=0.5535 
[epoch 30] step 20/44: loss=0.5507 
[epoch 30] step 22/44: loss=0.5498 
[epoch 30] step 24/44: loss=0.5490 
[epoch 30] step 26/44: loss=0.5493 
[epoch 30] step 28/44: loss=0.5492 
[epoch 30] step 30/44: loss=0.5480 
[epoch 30] step 32/44: loss=0.5484 
[epoch 30] step 34/44: loss=0.5497 
[epoch 30] step 36/44: loss=0.5490 
[epoch 30] step 38/44: loss=0.5500 
[epoch 30] step 40/44: loss=0.5489 
[epoch 30] step 42/44: loss=0.5489 
[epoch 30] step 44/44: loss=0.5495 
[epoch 30] train_loss(avg per step)=1.0990 lambda[min,max]=[0.358591,1.000000]
[epoch 30] val_loss=1.4935 qwk=('0.3893', '0.3885', '0.3594') averageQWK=0.3791 macroEMD=0.3054 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   12   60   10    0
     0    6   93   53    3
     0    0   17   53    3
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   12   48   16    0
     0    9   87   68    0
     0    0    9   71    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   11   68   13    0
     0   21  101   44    0
     0    0   23   49    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=0.5588 
[epoch 31] step 4/44: loss=0.5702 
[epoch 31] step 6/44: loss=0.5746 
[epoch 31] step 8/44: loss=0.5704 
[epoch 31] step 10/44: loss=0.5728 
[epoch 31] step 12/44: loss=0.5751 
[epoch 31] step 14/44: loss=0.5717 
[epoch 31] step 16/44: loss=0.5692 
[epoch 31] step 18/44: loss=0.5707 
[epoch 31] step 20/44: loss=0.5698 
[epoch 31] step 22/44: loss=0.5650 
[epoch 31] step 24/44: loss=0.5644 
[epoch 31] step 26/44: loss=0.5645 
[epoch 31] step 28/44: loss=0.5639 
[epoch 31] step 30/44: loss=0.5608 
[epoch 31] step 32/44: loss=0.5602 
[epoch 31] step 34/44: loss=0.5582 
[epoch 31] step 36/44: loss=0.5574 
[epoch 31] step 38/44: loss=0.5551 
[epoch 31] step 40/44: loss=0.5533 
[epoch 31] step 42/44: loss=0.5543 
[epoch 31] step 44/44: loss=0.5515 
[epoch 31] train_loss(avg per step)=1.1030 lambda[min,max]=[0.357514,1.000000]
[epoch 31] val_loss=1.4938 qwk=('0.3913', '0.3935', '0.3599') averageQWK=0.3816 macroEMD=0.3080 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   12   62    8    0
     0    5   99   48    3
     0    0   21   48    4
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   13   47   16    0
     0    6   90   68    0
     0    0   10   69    1
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   10   69   13    0
     0   19  106   41    0
     0    0   23   49    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=0.5942 
[epoch 32] step 4/44: loss=0.5932 
[epoch 32] step 6/44: loss=0.5859 
[epoch 32] step 8/44: loss=0.5756 
[epoch 32] step 10/44: loss=0.5734 
[epoch 32] step 12/44: loss=0.5728 
[epoch 32] step 14/44: loss=0.5761 
[epoch 32] step 16/44: loss=0.5725 
[epoch 32] step 18/44: loss=0.5700 
[epoch 32] step 20/44: loss=0.5740 
[epoch 32] step 22/44: loss=0.5706 
[epoch 32] step 24/44: loss=0.5687 
[epoch 32] step 26/44: loss=0.5675 
[epoch 32] step 28/44: loss=0.5649 
[epoch 32] step 30/44: loss=0.5664 
[epoch 32] step 32/44: loss=0.5658 
[epoch 32] step 34/44: loss=0.5633 
[epoch 32] step 36/44: loss=0.5619 
[epoch 32] step 38/44: loss=0.5608 
[epoch 32] step 40/44: loss=0.5617 
[epoch 32] step 42/44: loss=0.5603 
[epoch 32] step 44/44: loss=0.5560 
[epoch 32] train_loss(avg per step)=1.1120 lambda[min,max]=[0.368359,1.000000]
[epoch 32] val_loss=1.5368 qwk=('0.3884', '0.3725', '0.3492') averageQWK=0.3700 macroEMD=0.3083 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   10   63    9    0
     0    5   94   52    4
     0    0   18   49    6
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   14   41   21    0
     0    8   74   82    0
     0    0    7   73    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    9   70   13    0
     0   15  102   49    0
     0    0   22   50    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=0.5782 
[epoch 33] step 4/44: loss=0.5749 
[epoch 33] step 6/44: loss=0.5663 
[epoch 33] step 8/44: loss=0.5554 
[epoch 33] step 10/44: loss=0.5475 
[epoch 33] step 12/44: loss=0.5448 
[epoch 33] step 14/44: loss=0.5484 
[epoch 33] step 16/44: loss=0.5474 
[epoch 33] step 18/44: loss=0.5482 
[epoch 33] step 20/44: loss=0.5512 
[epoch 33] step 22/44: loss=0.5536 
[epoch 33] step 24/44: loss=0.5531 
[epoch 33] step 26/44: loss=0.5507 
[epoch 33] step 28/44: loss=0.5505 
[epoch 33] step 30/44: loss=0.5547 
[epoch 33] step 32/44: loss=0.5553 
[epoch 33] step 34/44: loss=0.5535 
[epoch 33] step 36/44: loss=0.5528 
[epoch 33] step 38/44: loss=0.5519 
[epoch 33] step 40/44: loss=0.5525 
[epoch 33] step 42/44: loss=0.5519 
[epoch 33] step 44/44: loss=0.5489 
[epoch 33] train_loss(avg per step)=1.0978 lambda[min,max]=[0.356369,1.000000]
[epoch 33] val_loss=1.5280 qwk=('0.3787', '0.3658', '0.3647') averageQWK=0.3697 macroEMD=0.3047 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0    9   61   12    0
     0    4   90   58    3
     0    0   15   53    5
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   12   43   21    0
     0    5   75   84    0
     0    0    7   73    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   10   69   13    0
     0   17  104   45    0
     0    0   22   50    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=0.5320 
[epoch 34] step 4/44: loss=0.5367 
[epoch 34] step 6/44: loss=0.5431 
[epoch 34] step 8/44: loss=0.5458 
[epoch 34] step 10/44: loss=0.5450 
[epoch 34] step 12/44: loss=0.5455 
[epoch 34] step 14/44: loss=0.5461 
[epoch 34] step 16/44: loss=0.5474 
[epoch 34] step 18/44: loss=0.5449 
[epoch 34] step 20/44: loss=0.5460 
[epoch 34] step 22/44: loss=0.5465 
[epoch 34] step 24/44: loss=0.5477 
[epoch 34] step 26/44: loss=0.5495 
[epoch 34] step 28/44: loss=0.5512 
[epoch 34] step 30/44: loss=0.5500 
[epoch 34] step 32/44: loss=0.5501 
[epoch 34] step 34/44: loss=0.5489 
[epoch 34] step 36/44: loss=0.5493 
[epoch 34] step 38/44: loss=0.5494 
[epoch 34] step 40/44: loss=0.5494 
[epoch 34] step 42/44: loss=0.5486 
[epoch 34] step 44/44: loss=0.5468 
[epoch 34] train_loss(avg per step)=1.0936 lambda[min,max]=[0.358804,1.000000]
[epoch 34] val_loss=1.5325 qwk=('0.4000', '0.3675', '0.3601') averageQWK=0.3758 macroEMD=0.3047 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   10   59   13    0
     0    4   86   63    2
     0    0   12   58    3
     0    0    3    6    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   12   43   21    0
     0    6   77   81    0
     0    0    7   73    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   10   69   13    0
     0   16  104   46    0
     0    0   23   49    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=0.5643 
[epoch 35] step 4/44: loss=0.5490 
[epoch 35] step 6/44: loss=0.5525 
[epoch 35] step 8/44: loss=0.5519 
[epoch 35] step 10/44: loss=0.5546 
[epoch 35] step 12/44: loss=0.5509 
[epoch 35] step 14/44: loss=0.5509 
[epoch 35] step 16/44: loss=0.5467 
[epoch 35] step 18/44: loss=0.5449 
[epoch 35] step 20/44: loss=0.5463 
[epoch 35] step 22/44: loss=0.5498 
[epoch 35] step 24/44: loss=0.5503 
[epoch 35] step 26/44: loss=0.5523 
[epoch 35] step 28/44: loss=0.5550 
[epoch 35] step 30/44: loss=0.5555 
[epoch 35] step 32/44: loss=0.5556 
[epoch 35] step 34/44: loss=0.5546 
[epoch 35] step 36/44: loss=0.5544 
[epoch 35] step 38/44: loss=0.5563 
[epoch 35] step 40/44: loss=0.5558 
[epoch 35] step 42/44: loss=0.5538 
[epoch 35] step 44/44: loss=0.5501 
[epoch 35] train_loss(avg per step)=1.1002 lambda[min,max]=[0.378296,1.000000]
[epoch 35] val_loss=1.5316 qwk=('0.3732', '0.3739', '0.3633') averageQWK=0.3701 macroEMD=0.3052 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   11   58   13    0
     0    5   86   61    3
     0    0   15   55    3
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   13   43   20    0
     0    8   78   78    0
     0    0    8   72    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   11   68   13    0
     0   17  103   46    0
     0    0   23   49    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold4/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold4/metrics.json
Done.
