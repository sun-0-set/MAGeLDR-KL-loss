[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.5080 
[epoch 1] step 4/44: loss=0.5096 
[epoch 1] step 6/44: loss=0.5136 
[epoch 1] step 8/44: loss=0.5198 
[epoch 1] step 10/44: loss=0.5237 
[epoch 1] step 12/44: loss=0.5258 
[epoch 1] step 14/44: loss=0.5304 
[epoch 1] step 16/44: loss=0.5334 
[epoch 1] step 18/44: loss=0.5367 
[epoch 1] step 20/44: loss=0.5415 
[epoch 1] step 22/44: loss=0.5456 
[epoch 1] step 24/44: loss=0.5513 
[epoch 1] step 26/44: loss=0.5544 
[epoch 1] step 28/44: loss=0.5571 
[epoch 1] step 30/44: loss=0.5613 
[epoch 1] step 32/44: loss=0.5640 
[epoch 1] step 34/44: loss=0.5667 
[epoch 1] step 36/44: loss=0.5704 
[epoch 1] step 38/44: loss=0.5732 
[epoch 1] step 40/44: loss=0.5753 
[epoch 1] step 42/44: loss=0.5788 
[epoch 1] step 44/44: loss=0.5814 
[epoch 1] train_loss(avg per step)=1.1627 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=0.9256 qwk=('-0.1025', '-0.0594', '0.1202') averageQWK=-0.0139 macroEMD=0.3643 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    6    0
     0    2    4   92    0
     0    3    9  143    0
     0    8    7   44    0
     0    0    5    1    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   14    0    0
     2    0   73    7    0
     3    0  151   12    0
     8    0   43   10    0
     0    0    2    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    1
     0   54   43    0    7
     0   73   89    1   17
     0   15   12    4    5
     0    0    0    0    0
[epoch 2] step 2/44: loss=0.6702 
[epoch 2] step 4/44: loss=0.6743 
[epoch 2] step 6/44: loss=0.6914 
[epoch 2] step 8/44: loss=0.6998 
[epoch 2] step 10/44: loss=0.7120 
[epoch 2] step 12/44: loss=0.7235 
[epoch 2] step 14/44: loss=0.7306 
[epoch 2] step 16/44: loss=0.7431 
[epoch 2] step 18/44: loss=0.7543 
[epoch 2] step 20/44: loss=0.7691 
[epoch 2] step 22/44: loss=0.7806 
[epoch 2] step 24/44: loss=0.7886 
[epoch 2] step 26/44: loss=0.7962 
[epoch 2] step 28/44: loss=0.8006 
[epoch 2] step 30/44: loss=0.8035 
[epoch 2] step 32/44: loss=0.8062 
[epoch 2] step 34/44: loss=0.8061 
[epoch 2] step 36/44: loss=0.8074 
[epoch 2] step 38/44: loss=0.8076 
[epoch 2] step 40/44: loss=0.8064 
[epoch 2] step 42/44: loss=0.8074 
[epoch 2] step 44/44: loss=0.8087 
[epoch 2] train_loss(avg per step)=1.6174 lambda[min,max]=[0.502694,1.000000]
[epoch 2] val_loss=1.5025 qwk=('0.0405', '0.0780', '0.2189') averageQWK=0.1125 macroEMD=0.3537 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    7    0
     0    3   10   85    0
     0    2    2  151    0
     0    0    1   58    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    9    0
     0    0   17   65    0
     0    0    9  157    0
     0    0    0   61    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0    0  101    3    0
     0    0  158   22    0
     0    0   17   19    0
     0    0    0    0    0
[epoch 3] step 2/44: loss=0.7583 
[epoch 3] step 4/44: loss=0.7677 
[epoch 3] step 6/44: loss=0.7603 
[epoch 3] step 8/44: loss=0.7623 
[epoch 3] step 10/44: loss=0.7584 
[epoch 3] step 12/44: loss=0.7505 
[epoch 3] step 14/44: loss=0.7485 
[epoch 3] step 16/44: loss=0.7427 
[epoch 3] step 18/44: loss=0.7476 
[epoch 3] step 20/44: loss=0.7572 
[epoch 3] step 22/44: loss=0.7633 
[epoch 3] step 24/44: loss=0.7688 
[epoch 3] step 26/44: loss=0.7772 
[epoch 3] step 28/44: loss=0.7840 
[epoch 3] step 30/44: loss=0.7917 
[epoch 3] step 32/44: loss=0.7989 
[epoch 3] step 34/44: loss=0.8016 
[epoch 3] step 36/44: loss=0.8060 
[epoch 3] step 38/44: loss=0.8102 
[epoch 3] step 40/44: loss=0.8099 
[epoch 3] step 42/44: loss=0.8095 
[epoch 3] step 44/44: loss=0.8101 
[epoch 3] train_loss(avg per step)=1.6202 lambda[min,max]=[0.508705,1.000000]
[epoch 3] val_loss=1.4906 qwk=('0.3237', '0.1580', '0.3752') averageQWK=0.2856 macroEMD=0.3376 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    3    0
     0   10   81    7    0
     0    6  120   29    0
     0    0   26   33    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    3    0
     0    0   82    0    0
     0    0  153   13    0
     0    0   42   19    0
     0    0    1    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    1    0
     0   65   29   10    0
     0   73   77   30    0
     0    2   12   22    0
     0    0    0    0    0
[epoch 4] step 2/44: loss=0.7783 
[epoch 4] step 4/44: loss=0.7646 
[epoch 4] step 6/44: loss=0.7754 
[epoch 4] step 8/44: loss=0.7797 
[epoch 4] step 10/44: loss=0.7864 
[epoch 4] step 12/44: loss=0.7958 
[epoch 4] step 14/44: loss=0.7972 
[epoch 4] step 16/44: loss=0.8016 
[epoch 4] step 18/44: loss=0.8041 
[epoch 4] step 20/44: loss=0.8086 
[epoch 4] step 22/44: loss=0.8062 
[epoch 4] step 24/44: loss=0.8006 
[epoch 4] step 26/44: loss=0.8007 
[epoch 4] step 28/44: loss=0.8011 
[epoch 4] step 30/44: loss=0.8001 
[epoch 4] step 32/44: loss=0.8032 
[epoch 4] step 34/44: loss=0.8044 
[epoch 4] step 36/44: loss=0.8073 
[epoch 4] step 38/44: loss=0.8087 
[epoch 4] step 40/44: loss=0.8097 
[epoch 4] step 42/44: loss=0.8096 
[epoch 4] step 44/44: loss=0.8106 
[epoch 4] train_loss(avg per step)=1.6213 lambda[min,max]=[0.500493,1.000000]
[epoch 4] val_loss=1.5631 qwk=('0.2757', '0.2122', '0.1814') averageQWK=0.2231 macroEMD=0.3275 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    5    0
     0   36   21   41    0
     0   25   30  100    0
     0    1    5   53    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    7    0
     0   20   25   37    0
     0   25   28  113    0
     0    0    3   58    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   23   37   44    0
     0   16   50  114    0
     0    0    7   29    0
     0    0    0    0    0
[epoch 5] step 2/44: loss=0.8310 
[epoch 5] step 4/44: loss=0.8030 
[epoch 5] step 6/44: loss=0.7848 
[epoch 5] step 8/44: loss=0.7791 
[epoch 5] step 10/44: loss=0.7885 
[epoch 5] step 12/44: loss=0.7884 
[epoch 5] step 14/44: loss=0.7980 
[epoch 5] step 16/44: loss=0.8031 
[epoch 5] step 18/44: loss=0.8069 
[epoch 5] step 20/44: loss=0.8069 
[epoch 5] step 22/44: loss=0.8068 
[epoch 5] step 24/44: loss=0.8087 
[epoch 5] step 26/44: loss=0.8083 
[epoch 5] step 28/44: loss=0.8081 
[epoch 5] step 30/44: loss=0.8051 
[epoch 5] step 32/44: loss=0.8038 
[epoch 5] step 34/44: loss=0.8026 
[epoch 5] step 36/44: loss=0.8006 
[epoch 5] step 38/44: loss=0.8019 
[epoch 5] step 40/44: loss=0.8020 
[epoch 5] step 42/44: loss=0.8036 
[epoch 5] step 44/44: loss=0.8057 
[epoch 5] train_loss(avg per step)=1.6113 lambda[min,max]=[0.500025,1.000000]
[epoch 5] val_loss=1.5135 qwk=('0.2266', '0.1961', '0.2908') averageQWK=0.2378 macroEMD=0.3174 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     0    3   66   29    0
     0    0   84   71    0
     0    0   12   47    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    7    0
     0    1   53   28    0
     0    0   69   97    0
     0    0    6   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   35   48   21    0
     0   25   90   65    0
     0    0   10   26    0
     0    0    0    0    0
[epoch 6] step 2/44: loss=0.7988 
[epoch 6] step 4/44: loss=0.8072 
[epoch 6] step 6/44: loss=0.7844 
[epoch 6] step 8/44: loss=0.7854 
[epoch 6] step 10/44: loss=0.7839 
[epoch 6] step 12/44: loss=0.7850 
[epoch 6] step 14/44: loss=0.7848 
[epoch 6] step 16/44: loss=0.7844 
[epoch 6] step 18/44: loss=0.7823 
[epoch 6] step 20/44: loss=0.7868 
[epoch 6] step 22/44: loss=0.7897 
[epoch 6] step 24/44: loss=0.7940 
[epoch 6] step 26/44: loss=0.7946 
[epoch 6] step 28/44: loss=0.7911 
[epoch 6] step 30/44: loss=0.7891 
[epoch 6] step 32/44: loss=0.7886 
[epoch 6] step 34/44: loss=0.7877 
[epoch 6] step 36/44: loss=0.7881 
[epoch 6] step 38/44: loss=0.7863 
[epoch 6] step 40/44: loss=0.7856 
[epoch 6] step 42/44: loss=0.7891 
[epoch 6] step 44/44: loss=0.7911 
[epoch 6] train_loss(avg per step)=1.5823 lambda[min,max]=[0.500002,1.000000]
[epoch 6] val_loss=1.5826 qwk=('0.1893', '0.1724', '0.1687') averageQWK=0.1768 macroEMD=0.3160 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0   15   33   50    0
     0    8   38  109    0
     0    1    3   55    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    8    0
     0    5   36   41    0
     0    3   48  115    0
     0    0    0   61    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    3    2    0
     0    0   74   30    0
     0    0   90   90    0
     0    0    6   30    0
     0    0    0    0    0
[epoch 7] step 2/44: loss=0.8835 
[epoch 7] step 4/44: loss=0.8652 
[epoch 7] step 6/44: loss=0.8540 
[epoch 7] step 8/44: loss=0.8475 
[epoch 7] step 10/44: loss=0.8398 
[epoch 7] step 12/44: loss=0.8321 
[epoch 7] step 14/44: loss=0.8270 
[epoch 7] step 16/44: loss=0.8240 
[epoch 7] step 18/44: loss=0.8197 
[epoch 7] step 20/44: loss=0.8144 
[epoch 7] step 22/44: loss=0.8081 
[epoch 7] step 24/44: loss=0.8090 
[epoch 7] step 26/44: loss=0.8078 
[epoch 7] step 28/44: loss=0.8062 
[epoch 7] step 30/44: loss=0.8060 
[epoch 7] step 32/44: loss=0.8056 
[epoch 7] step 34/44: loss=0.8055 
[epoch 7] step 36/44: loss=0.8016 
[epoch 7] step 38/44: loss=0.8017 
[epoch 7] step 40/44: loss=0.8037 
[epoch 7] step 42/44: loss=0.8014 
[epoch 7] step 44/44: loss=0.7996 
[epoch 7] train_loss(avg per step)=1.5993 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.6156 qwk=('0.1971', '0.2445', '0.1808') averageQWK=0.2075 macroEMD=0.3153 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0    4   54   39    1
     0    1   52  100    2
     0    0    6   53    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    7    0
     0   10   42   30    0
     0    6   53  107    0
     0    0    2   59    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    3    0
     0   23   34   47    0
     0   17   46  117    0
     0    0    3   33    0
     0    0    0    0    0
[epoch 8] step 2/44: loss=0.8628 
[epoch 8] step 4/44: loss=0.8569 
[epoch 8] step 6/44: loss=0.8562 
[epoch 8] step 8/44: loss=0.8525 
[epoch 8] step 10/44: loss=0.8309 
[epoch 8] step 12/44: loss=0.8243 
[epoch 8] step 14/44: loss=0.8124 
[epoch 8] step 16/44: loss=0.8036 
[epoch 8] step 18/44: loss=0.7970 
[epoch 8] step 20/44: loss=0.7934 
[epoch 8] step 22/44: loss=0.7908 
[epoch 8] step 24/44: loss=0.7880 
[epoch 8] step 26/44: loss=0.7880 
[epoch 8] step 28/44: loss=0.7867 
[epoch 8] step 30/44: loss=0.7837 
[epoch 8] step 32/44: loss=0.7833 
[epoch 8] step 34/44: loss=0.7837 
[epoch 8] step 36/44: loss=0.7829 
[epoch 8] step 38/44: loss=0.7815 
[epoch 8] step 40/44: loss=0.7814 
[epoch 8] step 42/44: loss=0.7822 
[epoch 8] step 44/44: loss=0.7822 
[epoch 8] train_loss(avg per step)=1.5643 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.5531 qwk=('0.2721', '0.2820', '0.2472') averageQWK=0.2671 macroEMD=0.3043 tailR0=('0.1667', '0.0000', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    3    1
     0   21   51   22    4
     0   10   80   52   13
     0    1   11   44    3
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    7    0
     0   21   32   29    0
     0   19   49   98    0
     0    0    5   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    3    0
     0   22   61   21    0
     0   13  100   67    0
     0    0    9   27    0
     0    0    0    0    0
[epoch 9] step 2/44: loss=0.8208 
[epoch 9] step 4/44: loss=0.8163 
[epoch 9] step 6/44: loss=0.8059 
[epoch 9] step 8/44: loss=0.8052 
[epoch 9] step 10/44: loss=0.7969 
[epoch 9] step 12/44: loss=0.7932 
[epoch 9] step 14/44: loss=0.7941 
[epoch 9] step 16/44: loss=0.7885 
[epoch 9] step 18/44: loss=0.7813 
[epoch 9] step 20/44: loss=0.7743 
[epoch 9] step 22/44: loss=0.7653 
[epoch 9] step 24/44: loss=0.7621 
[epoch 9] step 26/44: loss=0.7593 
[epoch 9] step 28/44: loss=0.7596 
[epoch 9] step 30/44: loss=0.7615 
[epoch 9] step 32/44: loss=0.7637 
[epoch 9] step 34/44: loss=0.7659 
[epoch 9] step 36/44: loss=0.7675 
[epoch 9] step 38/44: loss=0.7689 
[epoch 9] step 40/44: loss=0.7683 
[epoch 9] step 42/44: loss=0.7676 
[epoch 9] step 44/44: loss=0.7686 
[epoch 9] train_loss(avg per step)=1.5372 lambda[min,max]=[0.490565,1.000000]
[epoch 9] val_loss=1.5971 qwk=('0.2659', '0.3055', '0.2450') averageQWK=0.2721 macroEMD=0.3054 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    5    0
     0   27   37   30    4
     0   12   53   84    6
     0    1    8   47    3
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    7    0
     0   25   33   24    0
     0   22   44  100    0
     0    0    5   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   31   49   24    0
     0   26   82   72    0
     0    0   11   25    0
     0    0    0    0    0
[epoch 10] step 2/44: loss=0.7657 
[epoch 10] step 4/44: loss=0.7759 
[epoch 10] step 6/44: loss=0.7650 
[epoch 10] step 8/44: loss=0.7520 
[epoch 10] step 10/44: loss=0.7489 
[epoch 10] step 12/44: loss=0.7449 
[epoch 10] step 14/44: loss=0.7467 
[epoch 10] step 16/44: loss=0.7472 
[epoch 10] step 18/44: loss=0.7489 
[epoch 10] step 20/44: loss=0.7519 
[epoch 10] step 22/44: loss=0.7505 
[epoch 10] step 24/44: loss=0.7545 
[epoch 10] step 26/44: loss=0.7565 
[epoch 10] step 28/44: loss=0.7562 
[epoch 10] step 30/44: loss=0.7578 
[epoch 10] step 32/44: loss=0.7579 
[epoch 10] step 34/44: loss=0.7584 
[epoch 10] step 36/44: loss=0.7588 
[epoch 10] step 38/44: loss=0.7591 
[epoch 10] step 40/44: loss=0.7577 
[epoch 10] step 42/44: loss=0.7563 
[epoch 10] step 44/44: loss=0.7576 
[epoch 10] train_loss(avg per step)=1.5152 lambda[min,max]=[0.464141,1.000000]
[epoch 10] val_loss=1.6361 qwk=('0.2217', '0.2363', '0.2356') averageQWK=0.2312 macroEMD=0.3086 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0   14   51   31    2
     1    7   59   84    4
     0    1   10   45    3
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    7    0
     0   16   33   32    1
     0   11   46  109    0
     0    0    5   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   25   54   25    0
     0   19   86   75    0
     0    0   10   26    0
     0    0    0    0    0
[epoch 11] step 2/44: loss=0.7215 
[epoch 11] step 4/44: loss=0.7371 
[epoch 11] step 6/44: loss=0.7394 
[epoch 11] step 8/44: loss=0.7380 
[epoch 11] step 10/44: loss=0.7304 
[epoch 11] step 12/44: loss=0.7225 
[epoch 11] step 14/44: loss=0.7142 
[epoch 11] step 16/44: loss=0.7161 
[epoch 11] step 18/44: loss=0.7218 
[epoch 11] step 20/44: loss=0.7248 
[epoch 11] step 22/44: loss=0.7253 
[epoch 11] step 24/44: loss=0.7263 
[epoch 11] step 26/44: loss=0.7253 
[epoch 11] step 28/44: loss=0.7251 
[epoch 11] step 30/44: loss=0.7262 
[epoch 11] step 32/44: loss=0.7258 
[epoch 11] step 34/44: loss=0.7272 
[epoch 11] step 36/44: loss=0.7281 
[epoch 11] step 38/44: loss=0.7298 
[epoch 11] step 40/44: loss=0.7297 
[epoch 11] step 42/44: loss=0.7279 
[epoch 11] step 44/44: loss=0.7283 
[epoch 11] train_loss(avg per step)=1.4566 lambda[min,max]=[0.479880,1.000000]
[epoch 11] val_loss=1.5988 qwk=('0.3213', '0.3138', '0.2423') averageQWK=0.2924 macroEMD=0.2990 tailR0=('0.1667', '0.0000', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    5    0
     0   43   26   25    4
     0   26   47   76    6
     0    1   10   45    3
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    7    0
     0   33   26   23    0
     0   35   41   89    1
     0    0    9   52    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   34   48   22    0
     0   33   79   68    0
     0    0   13   23    0
     0    0    0    0    0
[epoch 12] step 2/44: loss=0.7244 
[epoch 12] step 4/44: loss=0.7276 
[epoch 12] step 6/44: loss=0.7444 
[epoch 12] step 8/44: loss=0.7504 
[epoch 12] step 10/44: loss=0.7542 
[epoch 12] step 12/44: loss=0.7447 
[epoch 12] step 14/44: loss=0.7422 
[epoch 12] step 16/44: loss=0.7374 
[epoch 12] step 18/44: loss=0.7380 
[epoch 12] step 20/44: loss=0.7376 
[epoch 12] step 22/44: loss=0.7368 
[epoch 12] step 24/44: loss=0.7308 
[epoch 12] step 26/44: loss=0.7276 
[epoch 12] step 28/44: loss=0.7266 
[epoch 12] step 30/44: loss=0.7233 
[epoch 12] step 32/44: loss=0.7230 
[epoch 12] step 34/44: loss=0.7230 
[epoch 12] step 36/44: loss=0.7208 
[epoch 12] step 38/44: loss=0.7220 
[epoch 12] step 40/44: loss=0.7229 
[epoch 12] step 42/44: loss=0.7227 
[epoch 12] step 44/44: loss=0.7239 
[epoch 12] train_loss(avg per step)=1.4479 lambda[min,max]=[0.431276,1.000000]
[epoch 12] val_loss=1.6155 qwk=('0.3205', '0.2963', '0.2617') averageQWK=0.2928 macroEMD=0.3007 tailR0=('0.1548', '0.0000', '0.0000') tailR0avg=0.0516
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    0    5    0
     5   28   39   24    2
     2   18   59   71    5
     0    1   12   43    3
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    8    0
     0   33   25   24    0
     0   35   44   85    2
     0    0   10   51    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   32   53   19    0
     0   27   94   59    0
     0    0   14   22    0
     0    0    0    0    0
[epoch 13] step 2/44: loss=0.7491 
[epoch 13] step 4/44: loss=0.7471 
[epoch 13] step 6/44: loss=0.7298 
[epoch 13] step 8/44: loss=0.7343 
[epoch 13] step 10/44: loss=0.7305 
[epoch 13] step 12/44: loss=0.7326 
[epoch 13] step 14/44: loss=0.7281 
[epoch 13] step 16/44: loss=0.7206 
[epoch 13] step 18/44: loss=0.7210 
[epoch 13] step 20/44: loss=0.7167 
[epoch 13] step 22/44: loss=0.7151 
[epoch 13] step 24/44: loss=0.7132 
[epoch 13] step 26/44: loss=0.7136 
[epoch 13] step 28/44: loss=0.7179 
[epoch 13] step 30/44: loss=0.7167 
[epoch 13] step 32/44: loss=0.7165 
[epoch 13] step 34/44: loss=0.7181 
[epoch 13] step 36/44: loss=0.7174 
[epoch 13] step 38/44: loss=0.7189 
[epoch 13] step 40/44: loss=0.7172 
[epoch 13] step 42/44: loss=0.7160 
[epoch 13] step 44/44: loss=0.7139 
[epoch 13] train_loss(avg per step)=1.4278 lambda[min,max]=[0.412181,1.000000]
[epoch 13] val_loss=1.6500 qwk=('0.2675', '0.2782', '0.2808') averageQWK=0.2755 macroEMD=0.3078 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
     6   19   33   40    0
     2   11   45   95    2
     0    1    7   51    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    9    0
     0   28   22   32    0
     0   23   40  103    0
     0    0    1   60    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   23   60   21    0
     0   18  102   60    0
     0    0    6   30    0
     0    0    0    0    0
[epoch 14] step 2/44: loss=0.7000 
[epoch 14] step 4/44: loss=0.6742 
[epoch 14] step 6/44: loss=0.6660 
[epoch 14] step 8/44: loss=0.6632 
[epoch 14] step 10/44: loss=0.6638 
[epoch 14] step 12/44: loss=0.6694 
[epoch 14] step 14/44: loss=0.6790 
[epoch 14] step 16/44: loss=0.6873 
[epoch 14] step 18/44: loss=0.6929 
[epoch 14] step 20/44: loss=0.6961 
[epoch 14] step 22/44: loss=0.6948 
[epoch 14] step 24/44: loss=0.6980 
[epoch 14] step 26/44: loss=0.6975 
[epoch 14] step 28/44: loss=0.6956 
[epoch 14] step 30/44: loss=0.6960 
[epoch 14] step 32/44: loss=0.6952 
[epoch 14] step 34/44: loss=0.6980 
[epoch 14] step 36/44: loss=0.6985 
[epoch 14] step 38/44: loss=0.6971 
[epoch 14] step 40/44: loss=0.6969 
[epoch 14] step 42/44: loss=0.6956 
[epoch 14] step 44/44: loss=0.6954 
[epoch 14] train_loss(avg per step)=1.3909 lambda[min,max]=[0.446202,1.000000]
[epoch 14] val_loss=1.6471 qwk=('0.3365', '0.2984', '0.2880') averageQWK=0.3076 macroEMD=0.3016 tailR0=('0.3095', '0.0000', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    25   16   27   26    4
     9   17   49   72    8
     0    1   10   46    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    8    0
     0   35   20   27    0
     0   32   38   94    2
     0    0    8   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   34   51   19    0
     0   33   86   61    0
     0    0   13   23    0
     0    0    0    0    0
[epoch 15] step 2/44: loss=0.6429 
[epoch 15] step 4/44: loss=0.6467 
[epoch 15] step 6/44: loss=0.6384 
[epoch 15] step 8/44: loss=0.6440 
[epoch 15] step 10/44: loss=0.6511 
[epoch 15] step 12/44: loss=0.6628 
[epoch 15] step 14/44: loss=0.6744 
[epoch 15] step 16/44: loss=0.6834 
[epoch 15] step 18/44: loss=0.6905 
[epoch 15] step 20/44: loss=0.6975 
[epoch 15] step 22/44: loss=0.6995 
[epoch 15] step 24/44: loss=0.6999 
[epoch 15] step 26/44: loss=0.6972 
[epoch 15] step 28/44: loss=0.6933 
[epoch 15] step 30/44: loss=0.6908 
[epoch 15] step 32/44: loss=0.6909 
[epoch 15] step 34/44: loss=0.6895 
[epoch 15] step 36/44: loss=0.6872 
[epoch 15] step 38/44: loss=0.6896 
[epoch 15] step 40/44: loss=0.6874 
[epoch 15] step 42/44: loss=0.6872 
[epoch 15] step 44/44: loss=0.6832 
[epoch 15] train_loss(avg per step)=1.3663 lambda[min,max]=[0.432285,1.000000]
[epoch 15] val_loss=1.6952 qwk=('0.2759', '0.2918', '0.1852') averageQWK=0.2509 macroEMD=0.2986 tailR0=('0.4762', '0.2500', '0.0000') tailR0avg=0.2421
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    19   10   32   29    8
     8   10   54   69   14
     0    1    9   45    4
     0    0    0    2    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    8    0
     4   28   17   33    0
     1   29   32  102    2
     0    0    4   57    0
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   29   36   39    0
     0   27   74   79    0
     0    0    8   28    0
     0    0    0    0    0
[epoch 16] step 2/44: loss=0.6535 
[epoch 16] step 4/44: loss=0.6622 
[epoch 16] step 6/44: loss=0.6671 
[epoch 16] step 8/44: loss=0.6737 
[epoch 16] step 10/44: loss=0.6834 
[epoch 16] step 12/44: loss=0.6848 
[epoch 16] step 14/44: loss=0.6792 
[epoch 16] step 16/44: loss=0.6753 
[epoch 16] step 18/44: loss=0.6757 
[epoch 16] step 20/44: loss=0.6716 
[epoch 16] step 22/44: loss=0.6696 
[epoch 16] step 24/44: loss=0.6705 
[epoch 16] step 26/44: loss=0.6685 
[epoch 16] step 28/44: loss=0.6681 
[epoch 16] step 30/44: loss=0.6710 
[epoch 16] step 32/44: loss=0.6717 
[epoch 16] step 34/44: loss=0.6691 
[epoch 16] step 36/44: loss=0.6694 
[epoch 16] step 38/44: loss=0.6714 
[epoch 16] step 40/44: loss=0.6711 
[epoch 16] step 42/44: loss=0.6709 
[epoch 16] step 44/44: loss=0.6735 
[epoch 16] train_loss(avg per step)=1.3470 lambda[min,max]=[0.425862,1.000000]
[epoch 16] val_loss=1.6451 qwk=('0.3145', '0.2855', '0.2660') averageQWK=0.2887 macroEMD=0.3052 tailR0=('0.1429', '0.0714', '0.0000') tailR0avg=0.0714
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    18   11   37   32    0
     7   12   55   80    1
     0    1    9   49    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    0    9    0
     5   25   20   32    0
     5   23   35  103    0
     0    0    4   57    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   29   57   18    0
     0   23  114   43    0
     0    0   13   23    0
     0    0    0    0    0
[epoch 17] step 2/44: loss=0.6527 
[epoch 17] step 4/44: loss=0.6549 
[epoch 17] step 6/44: loss=0.6583 
[epoch 17] step 8/44: loss=0.6532 
[epoch 17] step 10/44: loss=0.6418 
[epoch 17] step 12/44: loss=0.6384 
[epoch 17] step 14/44: loss=0.6402 
[epoch 17] step 16/44: loss=0.6435 
[epoch 17] step 18/44: loss=0.6499 
[epoch 17] step 20/44: loss=0.6539 
[epoch 17] step 22/44: loss=0.6516 
[epoch 17] step 24/44: loss=0.6528 
[epoch 17] step 26/44: loss=0.6488 
[epoch 17] step 28/44: loss=0.6495 
[epoch 17] step 30/44: loss=0.6484 
[epoch 17] step 32/44: loss=0.6487 
[epoch 17] step 34/44: loss=0.6508 
[epoch 17] step 36/44: loss=0.6512 
[epoch 17] step 38/44: loss=0.6526 
[epoch 17] step 40/44: loss=0.6509 
[epoch 17] step 42/44: loss=0.6497 
[epoch 17] step 44/44: loss=0.6497 
[epoch 17] train_loss(avg per step)=1.2993 lambda[min,max]=[0.406493,1.000000]
[epoch 17] val_loss=1.6160 qwk=('0.3101', '0.2893', '0.2298') averageQWK=0.2764 macroEMD=0.3041 tailR0=('0.3929', '0.0000', '0.0000') tailR0avg=0.1310
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    12   14   42   26    4
     6   11   59   76    3
     0    1    9   46    3
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    8    0
     3   25   30   24    0
     1   26   50   88    1
     0    0   11   50    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   25   60   19    0
     0   19  117   44    0
     0    0   16   20    0
     0    0    0    0    0
[epoch 18] step 2/44: loss=0.6228 
[epoch 18] step 4/44: loss=0.6258 
[epoch 18] step 6/44: loss=0.6192 
[epoch 18] step 8/44: loss=0.6267 
[epoch 18] step 10/44: loss=0.6289 
[epoch 18] step 12/44: loss=0.6268 
[epoch 18] step 14/44: loss=0.6230 
[epoch 18] step 16/44: loss=0.6230 
[epoch 18] step 18/44: loss=0.6319 
[epoch 18] step 20/44: loss=0.6350 
[epoch 18] step 22/44: loss=0.6427 
[epoch 18] step 24/44: loss=0.6423 
[epoch 18] step 26/44: loss=0.6400 
[epoch 18] step 28/44: loss=0.6390 
[epoch 18] step 30/44: loss=0.6386 
[epoch 18] step 32/44: loss=0.6400 
[epoch 18] step 34/44: loss=0.6432 
[epoch 18] step 36/44: loss=0.6423 
[epoch 18] step 38/44: loss=0.6416 
[epoch 18] step 40/44: loss=0.6402 
[epoch 18] step 42/44: loss=0.6394 
[epoch 18] step 44/44: loss=0.6382 
[epoch 18] train_loss(avg per step)=1.2764 lambda[min,max]=[0.413090,1.000000]
[epoch 18] val_loss=1.6827 qwk=('0.2629', '0.2782', '0.1836') averageQWK=0.2416 macroEMD=0.3041 tailR0=('0.3929', '0.2500', '0.0000') tailR0avg=0.2143
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
     6   21   34   31    6
     5   12   53   76    9
     0    1    9   45    4
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    9    0
     2   26   24   30    0
     0   25   40  100    1
     0    0    7   54    0
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    3    0
     0   26   46   32    0
     0   24   87   69    0
     0    1    8   27    0
     0    0    0    0    0
[epoch 19] step 2/44: loss=0.6514 
[epoch 19] step 4/44: loss=0.6300 
[epoch 19] step 6/44: loss=0.6390 
[epoch 19] step 8/44: loss=0.6392 
[epoch 19] step 10/44: loss=0.6431 
[epoch 19] step 12/44: loss=0.6360 
[epoch 19] step 14/44: loss=0.6367 
[epoch 19] step 16/44: loss=0.6317 
[epoch 19] step 18/44: loss=0.6312 
[epoch 19] step 20/44: loss=0.6284 
[epoch 19] step 22/44: loss=0.6279 
[epoch 19] step 24/44: loss=0.6274 
[epoch 19] step 26/44: loss=0.6270 
[epoch 19] step 28/44: loss=0.6273 
[epoch 19] step 30/44: loss=0.6253 
[epoch 19] step 32/44: loss=0.6271 
[epoch 19] step 34/44: loss=0.6245 
[epoch 19] step 36/44: loss=0.6245 
[epoch 19] step 38/44: loss=0.6232 
[epoch 19] step 40/44: loss=0.6220 
[epoch 19] step 42/44: loss=0.6217 
[epoch 19] step 44/44: loss=0.6180 
[epoch 19] train_loss(avg per step)=1.2361 lambda[min,max]=[0.363182,1.000000]
[epoch 19] val_loss=1.6263 qwk=('0.3560', '0.3340', '0.2285') averageQWK=0.3062 macroEMD=0.2989 tailR0=('0.3095', '0.3214', '0.0000') tailR0avg=0.2103
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    23   14   34   24    3
     8   15   63   66    3
     0    1    9   48    1
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    4    5    0
     7   28   32   15    0
     5   33   61   66    1
     0    2   20   39    0
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   32   48   24    0
     0   24  103   53    0
     0    1   15   20    0
     0    0    0    0    0
[epoch 20] step 2/44: loss=0.6414 
[epoch 20] step 4/44: loss=0.6263 
[epoch 20] step 6/44: loss=0.6195 
[epoch 20] step 8/44: loss=0.6375 
[epoch 20] step 10/44: loss=0.6442 
[epoch 20] step 12/44: loss=0.6419 
[epoch 20] step 14/44: loss=0.6342 
[epoch 20] step 16/44: loss=0.6262 
[epoch 20] step 18/44: loss=0.6197 
[epoch 20] step 20/44: loss=0.6145 
[epoch 20] step 22/44: loss=0.6122 
[epoch 20] step 24/44: loss=0.6128 
[epoch 20] step 26/44: loss=0.6100 
[epoch 20] step 28/44: loss=0.6109 
[epoch 20] step 30/44: loss=0.6104 
[epoch 20] step 32/44: loss=0.6127 
[epoch 20] step 34/44: loss=0.6123 
[epoch 20] step 36/44: loss=0.6132 
[epoch 20] step 38/44: loss=0.6135 
[epoch 20] step 40/44: loss=0.6118 
[epoch 20] step 42/44: loss=0.6111 
[epoch 20] step 44/44: loss=0.6123 
[epoch 20] train_loss(avg per step)=1.2246 lambda[min,max]=[0.376127,1.000000]
[epoch 20] val_loss=1.6625 qwk=('0.3026', '0.2948', '0.1876') averageQWK=0.2617 macroEMD=0.3020 tailR0=('0.3929', '0.2500', '0.0000') tailR0avg=0.2143
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    16   12   38   28    4
     9    8   63   71    4
     0    1   10   46    2
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    9    0
     3   36   15   27    1
     1   37   28   98    2
     0    1    6   54    0
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   30   45   29    0
     0   27   93   60    0
     0    1   14   21    0
     0    0    0    0    0
[epoch 21] step 2/44: loss=0.6439 
[epoch 21] step 4/44: loss=0.6361 
[epoch 21] step 6/44: loss=0.6374 
[epoch 21] step 8/44: loss=0.6438 
[epoch 21] step 10/44: loss=0.6419 
[epoch 21] step 12/44: loss=0.6388 
[epoch 21] step 14/44: loss=0.6325 
[epoch 21] step 16/44: loss=0.6289 
[epoch 21] step 18/44: loss=0.6236 
[epoch 21] step 20/44: loss=0.6205 
[epoch 21] step 22/44: loss=0.6146 
[epoch 21] step 24/44: loss=0.6133 
[epoch 21] step 26/44: loss=0.6116 
[epoch 21] step 28/44: loss=0.6107 
[epoch 21] step 30/44: loss=0.6078 
[epoch 21] step 32/44: loss=0.6061 
[epoch 21] step 34/44: loss=0.6034 
[epoch 21] step 36/44: loss=0.6047 
[epoch 21] step 38/44: loss=0.6044 
[epoch 21] step 40/44: loss=0.6051 
[epoch 21] step 42/44: loss=0.6051 
[epoch 21] step 44/44: loss=0.6047 
[epoch 21] train_loss(avg per step)=1.2095 lambda[min,max]=[0.397644,1.000000]
[epoch 21] val_loss=1.6243 qwk=('0.3045', '0.2770', '0.2851') averageQWK=0.2889 macroEMD=0.3027 tailR0=('0.2262', '0.0000', '0.0000') tailR0avg=0.0754
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    12   16   38   30    2
     5   11   61   75    3
     0    1    9   48    1
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    9    0
     5   24   23   30    0
     1   26   38  100    1
     0    0    5   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   39   53   12    0
     0   40  105   35    0
     0    2   16   18    0
     0    0    0    0    0
[epoch 22] step 2/44: loss=0.5619 
[epoch 22] step 4/44: loss=0.5843 
[epoch 22] step 6/44: loss=0.5839 
[epoch 22] step 8/44: loss=0.5893 
[epoch 22] step 10/44: loss=0.5868 
[epoch 22] step 12/44: loss=0.5874 
[epoch 22] step 14/44: loss=0.5828 
[epoch 22] step 16/44: loss=0.5769 
[epoch 22] step 18/44: loss=0.5771 
[epoch 22] step 20/44: loss=0.5775 
[epoch 22] step 22/44: loss=0.5816 
[epoch 22] step 24/44: loss=0.5819 
[epoch 22] step 26/44: loss=0.5833 
[epoch 22] step 28/44: loss=0.5832 
[epoch 22] step 30/44: loss=0.5858 
[epoch 22] step 32/44: loss=0.5869 
[epoch 22] step 34/44: loss=0.5885 
[epoch 22] step 36/44: loss=0.5896 
[epoch 22] step 38/44: loss=0.5900 
[epoch 22] step 40/44: loss=0.5902 
[epoch 22] step 42/44: loss=0.5895 
[epoch 22] step 44/44: loss=0.5876 
[epoch 22] train_loss(avg per step)=1.1752 lambda[min,max]=[0.379053,1.000000]
[epoch 22] val_loss=1.6580 qwk=('0.2644', '0.2550', '0.2131') averageQWK=0.2442 macroEMD=0.3079 tailR0=('0.3095', '0.0000', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    12   15   30   38    3
     5   12   43   91    4
     0    1    8   50    0
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    9    0
     3   23   23   33    0
     1   23   39  102    1
     0    0    5   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   26   55   23    0
     0   20  105   55    0
     0    1   14   21    0
     0    0    0    0    0
[epoch 23] step 2/44: loss=0.6410 
[epoch 23] step 4/44: loss=0.6211 
[epoch 23] step 6/44: loss=0.5991 
[epoch 23] step 8/44: loss=0.5928 
[epoch 23] step 10/44: loss=0.5813 
[epoch 23] step 12/44: loss=0.5854 
[epoch 23] step 14/44: loss=0.5830 
[epoch 23] step 16/44: loss=0.5856 
[epoch 23] step 18/44: loss=0.5889 
[epoch 23] step 20/44: loss=0.5877 
[epoch 23] step 22/44: loss=0.5876 
[epoch 23] step 24/44: loss=0.5880 
[epoch 23] step 26/44: loss=0.5868 
[epoch 23] step 28/44: loss=0.5845 
[epoch 23] step 30/44: loss=0.5837 
[epoch 23] step 32/44: loss=0.5836 
[epoch 23] step 34/44: loss=0.5827 
[epoch 23] step 36/44: loss=0.5830 
[epoch 23] step 38/44: loss=0.5827 
[epoch 23] step 40/44: loss=0.5811 
[epoch 23] step 42/44: loss=0.5815 
[epoch 23] step 44/44: loss=0.5840 
[epoch 23] train_loss(avg per step)=1.1681 lambda[min,max]=[0.359196,1.000000]
[epoch 23] val_loss=1.6897 qwk=('0.2525', '0.2434', '0.2061') averageQWK=0.2340 macroEMD=0.3072 tailR0=('0.3214', '0.0000', '0.0000') tailR0avg=0.1071
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    0    5    0
    10   19   27   37    5
     6   16   36   92    5
     0    1    8   48    2
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0   10    0
     3   28   13   38    0
     1   30   23  111    1
     0    0    3   58    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   32   39   33    0
     0   26   89   65    0
     0    1    8   27    0
     0    0    0    0    0
[epoch 24] step 2/44: loss=0.6275 
[epoch 24] step 4/44: loss=0.6096 
[epoch 24] step 6/44: loss=0.6075 
[epoch 24] step 8/44: loss=0.6022 
[epoch 24] step 10/44: loss=0.5973 
[epoch 24] step 12/44: loss=0.5904 
[epoch 24] step 14/44: loss=0.5872 
[epoch 24] step 16/44: loss=0.5877 
[epoch 24] step 18/44: loss=0.5841 
[epoch 24] step 20/44: loss=0.5857 
[epoch 24] step 22/44: loss=0.5821 
[epoch 24] step 24/44: loss=0.5849 
[epoch 24] step 26/44: loss=0.5842 
[epoch 24] step 28/44: loss=0.5825 
[epoch 24] step 30/44: loss=0.5837 
[epoch 24] step 32/44: loss=0.5850 
[epoch 24] step 34/44: loss=0.5850 
[epoch 24] step 36/44: loss=0.5833 
[epoch 24] step 38/44: loss=0.5828 
[epoch 24] step 40/44: loss=0.5808 
[epoch 24] step 42/44: loss=0.5824 
[epoch 24] step 44/44: loss=0.5821 
[epoch 24] train_loss(avg per step)=1.1643 lambda[min,max]=[0.358065,1.000000]
[epoch 24] val_loss=1.6673 qwk=('0.2718', '0.2590', '0.2279') averageQWK=0.2529 macroEMD=0.3078 tailR0=('0.3095', '0.0000', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    13   17   31   32    5
     7   14   51   78    5
     0    1   10   46    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    9    0
     4   27   13   38    0
     1   29   26  108    2
     0    0    3   58    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   26   50   28    0
     0   18   97   65    0
     0    0    9   27    0
     0    0    0    0    0
[epoch 25] step 2/44: loss=0.5725 
[epoch 25] step 4/44: loss=0.5700 
[epoch 25] step 6/44: loss=0.5737 
[epoch 25] step 8/44: loss=0.5773 
[epoch 25] step 10/44: loss=0.5732 
[epoch 25] step 12/44: loss=0.5795 
[epoch 25] step 14/44: loss=0.5797 
[epoch 25] step 16/44: loss=0.5773 
[epoch 25] step 18/44: loss=0.5767 
[epoch 25] step 20/44: loss=0.5784 
[epoch 25] step 22/44: loss=0.5794 
[epoch 25] step 24/44: loss=0.5782 
[epoch 25] step 26/44: loss=0.5787 
[epoch 25] step 28/44: loss=0.5796 
[epoch 25] step 30/44: loss=0.5780 
[epoch 25] step 32/44: loss=0.5767 
[epoch 25] step 34/44: loss=0.5756 
[epoch 25] step 36/44: loss=0.5742 
[epoch 25] step 38/44: loss=0.5735 
[epoch 25] step 40/44: loss=0.5713 
[epoch 25] step 42/44: loss=0.5707 
[epoch 25] step 44/44: loss=0.5725 
[epoch 25] train_loss(avg per step)=1.1450 lambda[min,max]=[0.344535,1.000000]
[epoch 25] val_loss=1.6114 qwk=('0.3250', '0.2979', '0.2849') averageQWK=0.3026 macroEMD=0.3033 tailR0=('0.3095', '0.0000', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    17   14   36   29    2
     8   10   59   75    3
     0    1    9   47    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    9    0
     3   33   19   27    0
     1   35   35   94    1
     0    0    7   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   34   58   12    0
     0   30  116   34    0
     0    1   18   17    0
     0    0    0    0    0
[epoch 26] step 2/44: loss=0.5641 
[epoch 26] step 4/44: loss=0.5797 
[epoch 26] step 6/44: loss=0.5674 
[epoch 26] step 8/44: loss=0.5764 
[epoch 26] step 10/44: loss=0.5795 
[epoch 26] step 12/44: loss=0.5810 
[epoch 26] step 14/44: loss=0.5839 
[epoch 26] step 16/44: loss=0.5808 
[epoch 26] step 18/44: loss=0.5809 
[epoch 26] step 20/44: loss=0.5788 
[epoch 26] step 22/44: loss=0.5777 
[epoch 26] step 24/44: loss=0.5761 
[epoch 26] step 26/44: loss=0.5738 
[epoch 26] step 28/44: loss=0.5737 
[epoch 26] step 30/44: loss=0.5751 
[epoch 26] step 32/44: loss=0.5741 
[epoch 26] step 34/44: loss=0.5733 
[epoch 26] step 36/44: loss=0.5729 
[epoch 26] step 38/44: loss=0.5714 
[epoch 26] step 40/44: loss=0.5697 
[epoch 26] step 42/44: loss=0.5687 
[epoch 26] step 44/44: loss=0.5660 
[epoch 26] train_loss(avg per step)=1.1321 lambda[min,max]=[0.376596,1.000000]
[epoch 26] val_loss=1.6437 qwk=('0.2771', '0.2616', '0.2821') averageQWK=0.2736 macroEMD=0.3064 tailR0=('0.3095', '0.0000', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    17    9   35   33    4
     8    8   50   84    5
     0    1    9   47    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    9    0
     3   27   18   34    0
     0   29   29  106    2
     0    0    6   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   30   57   17    0
     0   29  104   47    0
     0    0   14   22    0
     0    0    0    0    0
[epoch 27] step 2/44: loss=0.5665 
[epoch 27] step 4/44: loss=0.5661 
[epoch 27] step 6/44: loss=0.5796 
[epoch 27] step 8/44: loss=0.5782 
[epoch 27] step 10/44: loss=0.5761 
[epoch 27] step 12/44: loss=0.5718 
[epoch 27] step 14/44: loss=0.5712 
[epoch 27] step 16/44: loss=0.5701 
[epoch 27] step 18/44: loss=0.5671 
[epoch 27] step 20/44: loss=0.5618 
[epoch 27] step 22/44: loss=0.5602 
[epoch 27] step 24/44: loss=0.5589 
[epoch 27] step 26/44: loss=0.5566 
[epoch 27] step 28/44: loss=0.5550 
[epoch 27] step 30/44: loss=0.5560 
[epoch 27] step 32/44: loss=0.5576 
[epoch 27] step 34/44: loss=0.5591 
[epoch 27] step 36/44: loss=0.5602 
[epoch 27] step 38/44: loss=0.5595 
[epoch 27] step 40/44: loss=0.5608 
[epoch 27] step 42/44: loss=0.5633 
[epoch 27] step 44/44: loss=0.5621 
[epoch 27] train_loss(avg per step)=1.1242 lambda[min,max]=[0.369519,1.000000]
[epoch 27] val_loss=1.6708 qwk=('0.2820', '0.2569', '0.2291') averageQWK=0.2560 macroEMD=0.3076 tailR0=('0.3095', '0.0000', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    16   12   29   39    2
     7    7   46   91    4
     0    1    8   48    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    9    0
     3   26   21   30    2
     0   28   33  102    3
     0    0    6   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   28   48   28    0
     0   22   90   68    0
     0    0   11   25    0
     0    0    0    0    0
[epoch 28] step 2/44: loss=0.5932 
[epoch 28] step 4/44: loss=0.5874 
[epoch 28] step 6/44: loss=0.5877 
[epoch 28] step 8/44: loss=0.5862 
[epoch 28] step 10/44: loss=0.5897 
[epoch 28] step 12/44: loss=0.5853 
[epoch 28] step 14/44: loss=0.5754 
[epoch 28] step 16/44: loss=0.5694 
[epoch 28] step 18/44: loss=0.5667 
[epoch 28] step 20/44: loss=0.5632 
[epoch 28] step 22/44: loss=0.5619 
[epoch 28] step 24/44: loss=0.5591 
[epoch 28] step 26/44: loss=0.5562 
[epoch 28] step 28/44: loss=0.5561 
[epoch 28] step 30/44: loss=0.5575 
[epoch 28] step 32/44: loss=0.5578 
[epoch 28] step 34/44: loss=0.5593 
[epoch 28] step 36/44: loss=0.5599 
[epoch 28] step 38/44: loss=0.5589 
[epoch 28] step 40/44: loss=0.5603 
[epoch 28] step 42/44: loss=0.5619 
[epoch 28] step 44/44: loss=0.5627 
[epoch 28] train_loss(avg per step)=1.1254 lambda[min,max]=[0.394363,1.000000]
[epoch 28] val_loss=1.6449 qwk=('0.2674', '0.2871', '0.2266') averageQWK=0.2604 macroEMD=0.3048 tailR0=('0.2381', '0.2500', '0.0000') tailR0avg=0.1627
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    0    5    0
    13   14   33   33    5
     6    9   53   82    5
     0    1    8   48    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    8    0
     3   27   27   24    1
     1   30   45   86    4
     0    1    8   52    0
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   25   54   25    0
     0   21   96   63    0
     0    0   12   24    0
     0    0    0    0    0
[epoch 29] step 2/44: loss=0.5277 
[epoch 29] step 4/44: loss=0.5361 
[epoch 29] step 6/44: loss=0.5417 
[epoch 29] step 8/44: loss=0.5356 
[epoch 29] step 10/44: loss=0.5338 
[epoch 29] step 12/44: loss=0.5387 
[epoch 29] step 14/44: loss=0.5389 
[epoch 29] step 16/44: loss=0.5408 
[epoch 29] step 18/44: loss=0.5467 
[epoch 29] step 20/44: loss=0.5502 
[epoch 29] step 22/44: loss=0.5504 
[epoch 29] step 24/44: loss=0.5514 
[epoch 29] step 26/44: loss=0.5516 
[epoch 29] step 28/44: loss=0.5540 
[epoch 29] step 30/44: loss=0.5548 
[epoch 29] step 32/44: loss=0.5555 
[epoch 29] step 34/44: loss=0.5574 
[epoch 29] step 36/44: loss=0.5575 
[epoch 29] step 38/44: loss=0.5577 
[epoch 29] step 40/44: loss=0.5549 
[epoch 29] step 42/44: loss=0.5540 
[epoch 29] step 44/44: loss=0.5549 
[epoch 29] train_loss(avg per step)=1.1099 lambda[min,max]=[0.378181,1.000000]
[epoch 29] val_loss=1.6444 qwk=('0.2829', '0.2515', '0.2548') averageQWK=0.2631 macroEMD=0.3080 tailR0=('0.2381', '0.0000', '0.0000') tailR0avg=0.0794
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    0    5    0
    13   16   32   34    3
     5   15   45   87    3
     0    1    8   49    1
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    9    0
     3   28   15   36    0
     0   30   30  104    2
     0    1    5   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   32   50   22    0
     0   29  101   50    0
     0    1   11   24    0
     0    0    0    0    0
[epoch 30] step 2/44: loss=0.5909 
[epoch 30] step 4/44: loss=0.5703 
[epoch 30] step 6/44: loss=0.5573 
[epoch 30] step 8/44: loss=0.5551 
[epoch 30] step 10/44: loss=0.5486 
[epoch 30] step 12/44: loss=0.5458 
[epoch 30] step 14/44: loss=0.5466 
[epoch 30] step 16/44: loss=0.5477 
[epoch 30] step 18/44: loss=0.5517 
[epoch 30] step 20/44: loss=0.5545 
[epoch 30] step 22/44: loss=0.5572 
[epoch 30] step 24/44: loss=0.5587 
[epoch 30] step 26/44: loss=0.5606 
[epoch 30] step 28/44: loss=0.5581 
[epoch 30] step 30/44: loss=0.5570 
[epoch 30] step 32/44: loss=0.5567 
[epoch 30] step 34/44: loss=0.5556 
[epoch 30] step 36/44: loss=0.5555 
[epoch 30] step 38/44: loss=0.5550 
[epoch 30] step 40/44: loss=0.5544 
[epoch 30] step 42/44: loss=0.5545 
[epoch 30] step 44/44: loss=0.5569 
[epoch 30] train_loss(avg per step)=1.1138 lambda[min,max]=[0.392346,1.000000]
[epoch 30] val_loss=1.6512 qwk=('0.3154', '0.2621', '0.2291') averageQWK=0.2689 macroEMD=0.3088 tailR0=('0.3095', '0.0000', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    14   15   38   28    3
     6    8   56   81    4
     0    1    8   49    1
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    9    0
     4   28   20   29    1
     2   29   34   98    3
     0    1    7   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   26   51   27    0
     0   23   93   64    0
     0    0   10   26    0
     0    0    0    0    0
[epoch 31] step 2/44: loss=0.5231 
[epoch 31] step 4/44: loss=0.5336 
[epoch 31] step 6/44: loss=0.5261 
[epoch 31] step 8/44: loss=0.5275 
[epoch 31] step 10/44: loss=0.5233 
[epoch 31] step 12/44: loss=0.5224 
[epoch 31] step 14/44: loss=0.5223 
[epoch 31] step 16/44: loss=0.5303 
[epoch 31] step 18/44: loss=0.5352 
[epoch 31] step 20/44: loss=0.5372 
[epoch 31] step 22/44: loss=0.5415 
[epoch 31] step 24/44: loss=0.5415 
[epoch 31] step 26/44: loss=0.5432 
[epoch 31] step 28/44: loss=0.5434 
[epoch 31] step 30/44: loss=0.5438 
[epoch 31] step 32/44: loss=0.5448 
[epoch 31] step 34/44: loss=0.5456 
[epoch 31] step 36/44: loss=0.5462 
[epoch 31] step 38/44: loss=0.5448 
[epoch 31] step 40/44: loss=0.5453 
[epoch 31] step 42/44: loss=0.5452 
[epoch 31] step 44/44: loss=0.5441 
[epoch 31] train_loss(avg per step)=1.0881 lambda[min,max]=[0.375873,1.000000]
[epoch 31] val_loss=1.6185 qwk=('0.3135', '0.2775', '0.2679') averageQWK=0.2863 macroEMD=0.3063 tailR0=('0.3095', '0.0000', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    14   15   37   29    3
     5   10   58   78    4
     0    1    8   49    1
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    9    0
     3   31   17   31    0
     1   30   28  105    2
     0    0    7   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   31   53   20    0
     0   27  101   52    0
     0    0   13   23    0
     0    0    0    0    0
[epoch 32] step 2/44: loss=0.5455 
[epoch 32] step 4/44: loss=0.5443 
[epoch 32] step 6/44: loss=0.5402 
[epoch 32] step 8/44: loss=0.5420 
[epoch 32] step 10/44: loss=0.5502 
[epoch 32] step 12/44: loss=0.5511 
[epoch 32] step 14/44: loss=0.5523 
[epoch 32] step 16/44: loss=0.5524 
[epoch 32] step 18/44: loss=0.5524 
[epoch 32] step 20/44: loss=0.5531 
[epoch 32] step 22/44: loss=0.5504 
[epoch 32] step 24/44: loss=0.5499 
[epoch 32] step 26/44: loss=0.5499 
[epoch 32] step 28/44: loss=0.5506 
[epoch 32] step 30/44: loss=0.5502 
[epoch 32] step 32/44: loss=0.5494 
[epoch 32] step 34/44: loss=0.5519 
[epoch 32] step 36/44: loss=0.5506 
[epoch 32] step 38/44: loss=0.5485 
[epoch 32] step 40/44: loss=0.5481 
[epoch 32] step 42/44: loss=0.5469 
[epoch 32] step 44/44: loss=0.5464 
[epoch 32] train_loss(avg per step)=1.0928 lambda[min,max]=[0.375252,1.000000]
[epoch 32] val_loss=1.6388 qwk=('0.2789', '0.2447', '0.2489') averageQWK=0.2575 macroEMD=0.3082 tailR0=('0.3095', '0.0000', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    13   16   32   32    5
     5   12   48   85    5
     0    1    8   49    1
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    9    0
     3   27   17   34    1
     0   28   30  105    3
     0    1    6   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   30   51   23    0
     0   25   96   59    0
     0    0   12   24    0
     0    0    0    0    0
[epoch 33] step 2/44: loss=0.5891 
[epoch 33] step 4/44: loss=0.5598 
[epoch 33] step 6/44: loss=0.5602 
[epoch 33] step 8/44: loss=0.5573 
[epoch 33] step 10/44: loss=0.5602 
[epoch 33] step 12/44: loss=0.5588 
[epoch 33] step 14/44: loss=0.5489 
[epoch 33] step 16/44: loss=0.5489 
[epoch 33] step 18/44: loss=0.5487 
[epoch 33] step 20/44: loss=0.5496 
[epoch 33] step 22/44: loss=0.5484 
[epoch 33] step 24/44: loss=0.5476 
[epoch 33] step 26/44: loss=0.5484 
[epoch 33] step 28/44: loss=0.5479 
[epoch 33] step 30/44: loss=0.5480 
[epoch 33] step 32/44: loss=0.5492 
[epoch 33] step 34/44: loss=0.5495 
[epoch 33] step 36/44: loss=0.5507 
[epoch 33] step 38/44: loss=0.5521 
[epoch 33] step 40/44: loss=0.5527 
[epoch 33] step 42/44: loss=0.5539 
[epoch 33] step 44/44: loss=0.5533 
[epoch 33] train_loss(avg per step)=1.1066 lambda[min,max]=[0.381614,1.000000]
[epoch 33] val_loss=1.6496 qwk=('0.2995', '0.2697', '0.2397') averageQWK=0.2696 macroEMD=0.3069 tailR0=('0.3095', '0.0000', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    13   16   37   27    5
     5   15   51   80    4
     0    1    8   48    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    9    0
     3   32   13   34    0
     0   31   28  105    2
     0    1    5   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   33   50   21    0
     0   29  100   51    0
     0    1   15   20    0
     0    0    0    0    0
[epoch 34] step 2/44: loss=0.5341 
[epoch 34] step 4/44: loss=0.5553 
[epoch 34] step 6/44: loss=0.5599 
[epoch 34] step 8/44: loss=0.5514 
[epoch 34] step 10/44: loss=0.5522 
[epoch 34] step 12/44: loss=0.5537 
[epoch 34] step 14/44: loss=0.5523 
[epoch 34] step 16/44: loss=0.5491 
[epoch 34] step 18/44: loss=0.5470 
[epoch 34] step 20/44: loss=0.5462 
[epoch 34] step 22/44: loss=0.5459 
[epoch 34] step 24/44: loss=0.5460 
[epoch 34] step 26/44: loss=0.5454 
[epoch 34] step 28/44: loss=0.5438 
[epoch 34] step 30/44: loss=0.5435 
[epoch 34] step 32/44: loss=0.5439 
[epoch 34] step 34/44: loss=0.5435 
[epoch 34] step 36/44: loss=0.5409 
[epoch 34] step 38/44: loss=0.5391 
[epoch 34] step 40/44: loss=0.5392 
[epoch 34] step 42/44: loss=0.5404 
[epoch 34] step 44/44: loss=0.5402 
[epoch 34] train_loss(avg per step)=1.0804 lambda[min,max]=[0.355731,1.000000]
[epoch 34] val_loss=1.6387 qwk=('0.2979', '0.2406', '0.2740') averageQWK=0.2708 macroEMD=0.3063 tailR0=('0.3095', '0.0000', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    13   16   37   27    5
     6   12   52   80    5
     0    1    8   48    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    9    0
     3   30   12   35    2
     0   33   25  105    3
     0    1    5   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   33   50   21    0
     0   29   94   57    0
     0    0   12   24    0
     0    0    0    0    0
[epoch 35] step 2/44: loss=0.5434 
[epoch 35] step 4/44: loss=0.5392 
[epoch 35] step 6/44: loss=0.5431 
[epoch 35] step 8/44: loss=0.5455 
[epoch 35] step 10/44: loss=0.5461 
[epoch 35] step 12/44: loss=0.5450 
[epoch 35] step 14/44: loss=0.5483 
[epoch 35] step 16/44: loss=0.5435 
[epoch 35] step 18/44: loss=0.5435 
[epoch 35] step 20/44: loss=0.5461 
[epoch 35] step 22/44: loss=0.5456 
[epoch 35] step 24/44: loss=0.5435 
[epoch 35] step 26/44: loss=0.5425 
[epoch 35] step 28/44: loss=0.5422 
[epoch 35] step 30/44: loss=0.5418 
[epoch 35] step 32/44: loss=0.5423 
[epoch 35] step 34/44: loss=0.5417 
[epoch 35] step 36/44: loss=0.5418 
[epoch 35] step 38/44: loss=0.5421 
[epoch 35] step 40/44: loss=0.5417 
[epoch 35] step 42/44: loss=0.5431 
[epoch 35] step 44/44: loss=0.5435 
[epoch 35] train_loss(avg per step)=1.0869 lambda[min,max]=[0.372157,1.000000]
[epoch 35] val_loss=1.6401 qwk=('0.2962', '0.2615', '0.2514') averageQWK=0.2697 macroEMD=0.3067 tailR0=('0.3095', '0.2500', '0.0000') tailR0avg=0.1865
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    13   16   36   28    5
     6   11   53   81    4
     0    1    8   48    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    9    0
     3   30   16   32    1
     0   31   32  100    3
     0    1    7   53    0
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   29   52   23    0
     0   27   93   60    0
     0    0   12   24    0
     0    0    0    0    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold2/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold2/metrics.json
Done.
