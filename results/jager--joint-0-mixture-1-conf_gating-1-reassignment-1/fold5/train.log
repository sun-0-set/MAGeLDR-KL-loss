[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.4998 
[epoch 1] step 4/44: loss=0.5086 
[epoch 1] step 6/44: loss=0.5140 
[epoch 1] step 8/44: loss=0.5155 
[epoch 1] step 10/44: loss=0.5185 
[epoch 1] step 12/44: loss=0.5181 
[epoch 1] step 14/44: loss=0.5188 
[epoch 1] step 16/44: loss=0.5204 
[epoch 1] step 18/44: loss=0.5231 
[epoch 1] step 20/44: loss=0.5289 
[epoch 1] step 22/44: loss=0.5327 
[epoch 1] step 24/44: loss=0.5368 
[epoch 1] step 26/44: loss=0.5423 
[epoch 1] step 28/44: loss=0.5464 
[epoch 1] step 30/44: loss=0.5501 
[epoch 1] step 32/44: loss=0.5541 
[epoch 1] step 34/44: loss=0.5581 
[epoch 1] step 36/44: loss=0.5612 
[epoch 1] step 38/44: loss=0.5642 
[epoch 1] step 40/44: loss=0.5662 
[epoch 1] step 42/44: loss=0.5689 
[epoch 1] step 44/44: loss=0.5732 
[epoch 1] train_loss(avg per step)=1.1465 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=0.8070 qwk=('0.1476', '0.2329', '0.0539') averageQWK=0.1448 macroEMD=0.3547 tailR0=('0.0000', '0.0714', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    0    6    0
     0   12    0   40    0
     0   16    0   98    0
     0   21    0  118    0
     0    0    0    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    5    1    0
    13    0   20   22    0
    14    0   21   79    0
    16    0   11  116    0
     0    0    0    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    3   62    0    0
     0    4  139    0    0
     0    0  110    0    0
     0    0    3    0    0
[epoch 2] step 2/44: loss=0.6820 
[epoch 2] step 4/44: loss=0.7007 
[epoch 2] step 6/44: loss=0.7079 
[epoch 2] step 8/44: loss=0.7266 
[epoch 2] step 10/44: loss=0.7483 
[epoch 2] step 12/44: loss=0.7648 
[epoch 2] step 14/44: loss=0.7837 
[epoch 2] step 16/44: loss=0.7945 
[epoch 2] step 18/44: loss=0.8064 
[epoch 2] step 20/44: loss=0.8090 
[epoch 2] step 22/44: loss=0.8115 
[epoch 2] step 24/44: loss=0.8112 
[epoch 2] step 26/44: loss=0.8109 
[epoch 2] step 28/44: loss=0.8102 
[epoch 2] step 30/44: loss=0.8111 
[epoch 2] step 32/44: loss=0.8090 
[epoch 2] step 34/44: loss=0.8096 
[epoch 2] step 36/44: loss=0.8104 
[epoch 2] step 38/44: loss=0.8127 
[epoch 2] step 40/44: loss=0.8151 
[epoch 2] step 42/44: loss=0.8164 
[epoch 2] step 44/44: loss=0.8189 
[epoch 2] train_loss(avg per step)=1.6379 lambda[min,max]=[0.506250,1.000000]
[epoch 2] val_loss=1.5028 qwk=('0.5526', '0.4388', '0.6078') averageQWK=0.5331 macroEMD=0.3554 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     0   13   35    4    0
     0    7   61   46    0
     0    0   33  106    0
     0    1    0    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    0    0
     0    0   47    8    0
     0    0   49   65    0
     0    0   17  126    0
     0    0    0    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   52   12    1    0
     0   40   87   16    0
     0    3   54   53    0
     0    0    2    1    0
[epoch 3] step 2/44: loss=0.7226 
[epoch 3] step 4/44: loss=0.7410 
[epoch 3] step 6/44: loss=0.7415 
[epoch 3] step 8/44: loss=0.7460 
[epoch 3] step 10/44: loss=0.7506 
[epoch 3] step 12/44: loss=0.7568 
[epoch 3] step 14/44: loss=0.7650 
[epoch 3] step 16/44: loss=0.7710 
[epoch 3] step 18/44: loss=0.7821 
[epoch 3] step 20/44: loss=0.7938 
[epoch 3] step 22/44: loss=0.8005 
[epoch 3] step 24/44: loss=0.8083 
[epoch 3] step 26/44: loss=0.8126 
[epoch 3] step 28/44: loss=0.8150 
[epoch 3] step 30/44: loss=0.8145 
[epoch 3] step 32/44: loss=0.8136 
[epoch 3] step 34/44: loss=0.8127 
[epoch 3] step 36/44: loss=0.8110 
[epoch 3] step 38/44: loss=0.8115 
[epoch 3] step 40/44: loss=0.8144 
[epoch 3] step 42/44: loss=0.8164 
[epoch 3] step 44/44: loss=0.8181 
[epoch 3] train_loss(avg per step)=1.6362 lambda[min,max]=[0.505739,1.000000]
[epoch 3] val_loss=1.4040 qwk=('0.5041', '0.3550', '0.5186') averageQWK=0.4592 macroEMD=0.3245 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3   10    0    0
     0    3   43    6    0
     0    0   57   57    0
     0    0   14  125    0
     0    0    1    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    0    0
     0    0   39   16    0
     0    0   29   85    0
     0    0   12  131    0
     0    0    0    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0   14   47    4    0
     0    7   58   78    0
     0    0   13   97    0
     0    0    0    3    0
[epoch 4] step 2/44: loss=0.8380 
[epoch 4] step 4/44: loss=0.8204 
[epoch 4] step 6/44: loss=0.8103 
[epoch 4] step 8/44: loss=0.8059 
[epoch 4] step 10/44: loss=0.7999 
[epoch 4] step 12/44: loss=0.7959 
[epoch 4] step 14/44: loss=0.7968 
[epoch 4] step 16/44: loss=0.8028 
[epoch 4] step 18/44: loss=0.8070 
[epoch 4] step 20/44: loss=0.8106 
[epoch 4] step 22/44: loss=0.8144 
[epoch 4] step 24/44: loss=0.8178 
[epoch 4] step 26/44: loss=0.8219 
[epoch 4] step 28/44: loss=0.8255 
[epoch 4] step 30/44: loss=0.8239 
[epoch 4] step 32/44: loss=0.8264 
[epoch 4] step 34/44: loss=0.8268 
[epoch 4] step 36/44: loss=0.8234 
[epoch 4] step 38/44: loss=0.8226 
[epoch 4] step 40/44: loss=0.8203 
[epoch 4] step 42/44: loss=0.8185 
[epoch 4] step 44/44: loss=0.8165 
[epoch 4] train_loss(avg per step)=1.6331 lambda[min,max]=[0.500314,1.000000]
[epoch 4] val_loss=1.4453 qwk=('0.5325', '0.4849', '0.5884') averageQWK=0.5353 macroEMD=0.3163 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    4    0    0
     0    8   42    2    0
     0    6   92   16    0
     0    0   57   82    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     0    6   49    0    0
     0    0   92   22    0
     0    0   61   82    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   50   15    0    0
     0   53   63   27    0
     0   13   25   72    0
     0    0    0    3    0
[epoch 5] step 2/44: loss=0.8669 
[epoch 5] step 4/44: loss=0.8530 
[epoch 5] step 6/44: loss=0.8427 
[epoch 5] step 8/44: loss=0.8346 
[epoch 5] step 10/44: loss=0.8378 
[epoch 5] step 12/44: loss=0.8376 
[epoch 5] step 14/44: loss=0.8372 
[epoch 5] step 16/44: loss=0.8381 
[epoch 5] step 18/44: loss=0.8341 
[epoch 5] step 20/44: loss=0.8307 
[epoch 5] step 22/44: loss=0.8298 
[epoch 5] step 24/44: loss=0.8276 
[epoch 5] step 26/44: loss=0.8259 
[epoch 5] step 28/44: loss=0.8238 
[epoch 5] step 30/44: loss=0.8249 
[epoch 5] step 32/44: loss=0.8266 
[epoch 5] step 34/44: loss=0.8255 
[epoch 5] step 36/44: loss=0.8244 
[epoch 5] step 38/44: loss=0.8224 
[epoch 5] step 40/44: loss=0.8188 
[epoch 5] step 42/44: loss=0.8161 
[epoch 5] step 44/44: loss=0.8154 
[epoch 5] train_loss(avg per step)=1.6308 lambda[min,max]=[0.500032,1.000000]
[epoch 5] val_loss=1.4193 qwk=('0.5078', '0.4489', '0.4945') averageQWK=0.4837 macroEMD=0.3047 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    0    0
     0    3   42    7    0
     0    1   57   56    0
     0    0   17  122    0
     0    0    1    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    0    0
     0    0   49    6    0
     0    0   59   55    0
     0    0   22  121    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    8   56    1    0
     0    6   99   38    0
     0    0   31   79    0
     0    0    0    3    0
[epoch 6] step 2/44: loss=0.7813 
[epoch 6] step 4/44: loss=0.7836 
[epoch 6] step 6/44: loss=0.7784 
[epoch 6] step 8/44: loss=0.7807 
[epoch 6] step 10/44: loss=0.7747 
[epoch 6] step 12/44: loss=0.7816 
[epoch 6] step 14/44: loss=0.7910 
[epoch 6] step 16/44: loss=0.7903 
[epoch 6] step 18/44: loss=0.7931 
[epoch 6] step 20/44: loss=0.7892 
[epoch 6] step 22/44: loss=0.7868 
[epoch 6] step 24/44: loss=0.7884 
[epoch 6] step 26/44: loss=0.7902 
[epoch 6] step 28/44: loss=0.7906 
[epoch 6] step 30/44: loss=0.7887 
[epoch 6] step 32/44: loss=0.7903 
[epoch 6] step 34/44: loss=0.7926 
[epoch 6] step 36/44: loss=0.7939 
[epoch 6] step 38/44: loss=0.7939 
[epoch 6] step 40/44: loss=0.7942 
[epoch 6] step 42/44: loss=0.7923 
[epoch 6] step 44/44: loss=0.7941 
[epoch 6] train_loss(avg per step)=1.5882 lambda[min,max]=[0.500001,1.000000]
[epoch 6] val_loss=1.3727 qwk=('0.5258', '0.4565', '0.5223') averageQWK=0.5015 macroEMD=0.2959 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    0    0
     0    3   47    2    0
     0    1   93   20    0
     0    0   39  100    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    0    0
     0    0   55    0    0
     0    0   86   28    0
     0    0   47   96    0
     0    0    2    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   13   51    1    0
     0    7  113   23    0
     0    0   37   73    0
     0    0    0    3    0
[epoch 7] step 2/44: loss=0.8532 
[epoch 7] step 4/44: loss=0.8394 
[epoch 7] step 6/44: loss=0.8355 
[epoch 7] step 8/44: loss=0.8231 
[epoch 7] step 10/44: loss=0.8196 
[epoch 7] step 12/44: loss=0.8182 
[epoch 7] step 14/44: loss=0.8135 
[epoch 7] step 16/44: loss=0.8060 
[epoch 7] step 18/44: loss=0.8049 
[epoch 7] step 20/44: loss=0.7987 
[epoch 7] step 22/44: loss=0.7939 
[epoch 7] step 24/44: loss=0.7897 
[epoch 7] step 26/44: loss=0.7877 
[epoch 7] step 28/44: loss=0.7870 
[epoch 7] step 30/44: loss=0.7860 
[epoch 7] step 32/44: loss=0.7878 
[epoch 7] step 34/44: loss=0.7841 
[epoch 7] step 36/44: loss=0.7825 
[epoch 7] step 38/44: loss=0.7816 
[epoch 7] step 40/44: loss=0.7829 
[epoch 7] step 42/44: loss=0.7836 
[epoch 7] step 44/44: loss=0.7850 
[epoch 7] train_loss(avg per step)=1.5701 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.3990 qwk=('0.5199', '0.5773', '0.5570') averageQWK=0.5514 macroEMD=0.2960 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     0    9   40    2    1
     0    6   83   25    0
     0    0   45   94    0
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    0    0
     0   20   33    2    0
     0   10   70   34    0
     0    2   40  101    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0   20   44    1    0
     0   14   96   33    0
     0    0   35   75    0
     0    0    0    3    0
[epoch 8] step 2/44: loss=0.8013 
[epoch 8] step 4/44: loss=0.7808 
[epoch 8] step 6/44: loss=0.7731 
[epoch 8] step 8/44: loss=0.7674 
[epoch 8] step 10/44: loss=0.7656 
[epoch 8] step 12/44: loss=0.7711 
[epoch 8] step 14/44: loss=0.7723 
[epoch 8] step 16/44: loss=0.7757 
[epoch 8] step 18/44: loss=0.7825 
[epoch 8] step 20/44: loss=0.7860 
[epoch 8] step 22/44: loss=0.7849 
[epoch 8] step 24/44: loss=0.7864 
[epoch 8] step 26/44: loss=0.7873 
[epoch 8] step 28/44: loss=0.7891 
[epoch 8] step 30/44: loss=0.7859 
[epoch 8] step 32/44: loss=0.7833 
[epoch 8] step 34/44: loss=0.7802 
[epoch 8] step 36/44: loss=0.7807 
[epoch 8] step 38/44: loss=0.7814 
[epoch 8] step 40/44: loss=0.7818 
[epoch 8] step 42/44: loss=0.7802 
[epoch 8] step 44/44: loss=0.7791 
[epoch 8] train_loss(avg per step)=1.5582 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.4171 qwk=('0.6328', '0.5575', '0.5543') averageQWK=0.5815 macroEMD=0.2945 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   13    0    0    0
     0   18   31    2    1
     0   16   68   30    0
     0    0   28  111    0
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     0   10   44    1    0
     0    2   76   36    0
     0    0   35  108    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0   18   46    1    0
     0   19   96   28    0
     0    1   34   75    0
     0    0    0    3    0
[epoch 9] step 2/44: loss=0.7101 
[epoch 9] step 4/44: loss=0.7113 
[epoch 9] step 6/44: loss=0.7298 
[epoch 9] step 8/44: loss=0.7416 
[epoch 9] step 10/44: loss=0.7466 
[epoch 9] step 12/44: loss=0.7516 
[epoch 9] step 14/44: loss=0.7553 
[epoch 9] step 16/44: loss=0.7660 
[epoch 9] step 18/44: loss=0.7666 
[epoch 9] step 20/44: loss=0.7638 
[epoch 9] step 22/44: loss=0.7668 
[epoch 9] step 24/44: loss=0.7698 
[epoch 9] step 26/44: loss=0.7643 
[epoch 9] step 28/44: loss=0.7598 
[epoch 9] step 30/44: loss=0.7612 
[epoch 9] step 32/44: loss=0.7628 
[epoch 9] step 34/44: loss=0.7635 
[epoch 9] step 36/44: loss=0.7648 
[epoch 9] step 38/44: loss=0.7651 
[epoch 9] step 40/44: loss=0.7639 
[epoch 9] step 42/44: loss=0.7640 
[epoch 9] step 44/44: loss=0.7635 
[epoch 9] train_loss(avg per step)=1.5270 lambda[min,max]=[0.488548,1.000000]
[epoch 9] val_loss=1.4220 qwk=('0.4821', '0.5063', '0.4917') averageQWK=0.4934 macroEMD=0.2993 tailR0=('0.0556', '0.0000', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    9    0    0
     0    3   44    4    1
     0    2   68   44    0
     0    0   27  111    1
     0    0    3    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     0    5   46    4    0
     0    1   65   48    0
     0    0   25  118    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    7   57    1    0
     0    2   95   46    0
     0    0   28   82    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=0.7642 
[epoch 10] step 4/44: loss=0.7804 
[epoch 10] step 6/44: loss=0.7617 
[epoch 10] step 8/44: loss=0.7649 
[epoch 10] step 10/44: loss=0.7561 
[epoch 10] step 12/44: loss=0.7545 
[epoch 10] step 14/44: loss=0.7506 
[epoch 10] step 16/44: loss=0.7500 
[epoch 10] step 18/44: loss=0.7511 
[epoch 10] step 20/44: loss=0.7486 
[epoch 10] step 22/44: loss=0.7468 
[epoch 10] step 24/44: loss=0.7513 
[epoch 10] step 26/44: loss=0.7504 
[epoch 10] step 28/44: loss=0.7513 
[epoch 10] step 30/44: loss=0.7530 
[epoch 10] step 32/44: loss=0.7560 
[epoch 10] step 34/44: loss=0.7549 
[epoch 10] step 36/44: loss=0.7569 
[epoch 10] step 38/44: loss=0.7582 
[epoch 10] step 40/44: loss=0.7573 
[epoch 10] step 42/44: loss=0.7581 
[epoch 10] step 44/44: loss=0.7582 
[epoch 10] train_loss(avg per step)=1.5164 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.4236 qwk=('0.5462', '0.5283', '0.5713') averageQWK=0.5486 macroEMD=0.2977 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     0    8   42    2    0
     0    5   83   26    0
     0    0   44   95    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     0   11   38    6    0
     0    2   54   58    0
     0    0   19  124    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0   27   37    1    0
     0   21   81   41    0
     0    1   30   79    0
     0    0    0    3    0
[epoch 11] step 2/44: loss=0.6995 
[epoch 11] step 4/44: loss=0.6911 
[epoch 11] step 6/44: loss=0.7051 
[epoch 11] step 8/44: loss=0.6941 
[epoch 11] step 10/44: loss=0.7024 
[epoch 11] step 12/44: loss=0.7118 
[epoch 11] step 14/44: loss=0.7185 
[epoch 11] step 16/44: loss=0.7240 
[epoch 11] step 18/44: loss=0.7296 
[epoch 11] step 20/44: loss=0.7318 
[epoch 11] step 22/44: loss=0.7339 
[epoch 11] step 24/44: loss=0.7329 
[epoch 11] step 26/44: loss=0.7310 
[epoch 11] step 28/44: loss=0.7318 
[epoch 11] step 30/44: loss=0.7311 
[epoch 11] step 32/44: loss=0.7329 
[epoch 11] step 34/44: loss=0.7360 
[epoch 11] step 36/44: loss=0.7390 
[epoch 11] step 38/44: loss=0.7394 
[epoch 11] step 40/44: loss=0.7407 
[epoch 11] step 42/44: loss=0.7401 
[epoch 11] step 44/44: loss=0.7440 
[epoch 11] train_loss(avg per step)=1.4881 lambda[min,max]=[0.463501,1.000000]
[epoch 11] val_loss=1.4088 qwk=('0.4931', '0.5151', '0.4644') averageQWK=0.4909 macroEMD=0.2963 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    9    0    0
     0    3   46    3    0
     0    2   75   37    0
     0    0   33  106    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     0    5   48    2    0
     0    2   72   40    0
     0    0   32  111    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    7   57    1    0
     0    4  103   36    0
     0    0   38   72    0
     0    0    0    3    0
[epoch 12] step 2/44: loss=0.7193 
[epoch 12] step 4/44: loss=0.7153 
[epoch 12] step 6/44: loss=0.7016 
[epoch 12] step 8/44: loss=0.7108 
[epoch 12] step 10/44: loss=0.7037 
[epoch 12] step 12/44: loss=0.7059 
[epoch 12] step 14/44: loss=0.7082 
[epoch 12] step 16/44: loss=0.7068 
[epoch 12] step 18/44: loss=0.7047 
[epoch 12] step 20/44: loss=0.7009 
[epoch 12] step 22/44: loss=0.7051 
[epoch 12] step 24/44: loss=0.7094 
[epoch 12] step 26/44: loss=0.7091 
[epoch 12] step 28/44: loss=0.7103 
[epoch 12] step 30/44: loss=0.7134 
[epoch 12] step 32/44: loss=0.7139 
[epoch 12] step 34/44: loss=0.7151 
[epoch 12] step 36/44: loss=0.7139 
[epoch 12] step 38/44: loss=0.7143 
[epoch 12] step 40/44: loss=0.7144 
[epoch 12] step 42/44: loss=0.7160 
[epoch 12] step 44/44: loss=0.7194 
[epoch 12] train_loss(avg per step)=1.4388 lambda[min,max]=[0.459982,1.000000]
[epoch 12] val_loss=1.3922 qwk=('0.5588', '0.5847', '0.5370') averageQWK=0.5602 macroEMD=0.2925 tailR0=('0.0556', '0.0000', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     0    7   43    2    0
     0    4   81   29    0
     0    0   39   99    1
     0    0    3    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   16   36    3    0
     0    8   60   46    0
     0    0   25  118    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0   14   50    1    0
     0   12  107   24    0
     0    0   38   72    0
     0    0    0    3    0
[epoch 13] step 2/44: loss=0.7249 
[epoch 13] step 4/44: loss=0.7250 
[epoch 13] step 6/44: loss=0.7173 
[epoch 13] step 8/44: loss=0.7243 
[epoch 13] step 10/44: loss=0.7297 
[epoch 13] step 12/44: loss=0.7261 
[epoch 13] step 14/44: loss=0.7218 
[epoch 13] step 16/44: loss=0.7172 
[epoch 13] step 18/44: loss=0.7145 
[epoch 13] step 20/44: loss=0.7137 
[epoch 13] step 22/44: loss=0.7151 
[epoch 13] step 24/44: loss=0.7170 
[epoch 13] step 26/44: loss=0.7161 
[epoch 13] step 28/44: loss=0.7151 
[epoch 13] step 30/44: loss=0.7118 
[epoch 13] step 32/44: loss=0.7077 
[epoch 13] step 34/44: loss=0.7053 
[epoch 13] step 36/44: loss=0.7045 
[epoch 13] step 38/44: loss=0.7054 
[epoch 13] step 40/44: loss=0.7067 
[epoch 13] step 42/44: loss=0.7084 
[epoch 13] step 44/44: loss=0.7093 
[epoch 13] train_loss(avg per step)=1.4186 lambda[min,max]=[0.458816,1.000000]
[epoch 13] val_loss=1.3995 qwk=('0.5519', '0.5666', '0.5371') averageQWK=0.5518 macroEMD=0.2899 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     0    9   40    3    0
     0    4   78   32    0
     0    0   38  100    1
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   15   37    3    0
     0    7   66   41    0
     0    0   33  110    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0   18   46    1    0
     0   11   99   33    0
     0    0   36   74    0
     0    0    0    3    0
[epoch 14] step 2/44: loss=0.7203 
[epoch 14] step 4/44: loss=0.7086 
[epoch 14] step 6/44: loss=0.7095 
[epoch 14] step 8/44: loss=0.7011 
[epoch 14] step 10/44: loss=0.6925 
[epoch 14] step 12/44: loss=0.6881 
[epoch 14] step 14/44: loss=0.6874 
[epoch 14] step 16/44: loss=0.6860 
[epoch 14] step 18/44: loss=0.6864 
[epoch 14] step 20/44: loss=0.6848 
[epoch 14] step 22/44: loss=0.6851 
[epoch 14] step 24/44: loss=0.6888 
[epoch 14] step 26/44: loss=0.6900 
[epoch 14] step 28/44: loss=0.6907 
[epoch 14] step 30/44: loss=0.6934 
[epoch 14] step 32/44: loss=0.6956 
[epoch 14] step 34/44: loss=0.6968 
[epoch 14] step 36/44: loss=0.6970 
[epoch 14] step 38/44: loss=0.6967 
[epoch 14] step 40/44: loss=0.6946 
[epoch 14] step 42/44: loss=0.6949 
[epoch 14] step 44/44: loss=0.6947 
[epoch 14] train_loss(avg per step)=1.3893 lambda[min,max]=[0.423908,1.000000]
[epoch 14] val_loss=1.4020 qwk=('0.5710', '0.5880', '0.5227') averageQWK=0.5606 macroEMD=0.2904 tailR0=('0.0940', '0.0000', '0.0000') tailR0avg=0.0313
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    5    0    0
     0    7   43    2    0
     0    3   80   31    0
     0    0   39   97    3
     0    0    2    6    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   18   32    5    0
     0   10   56   48    0
     0    0   20  123    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0   15   48    2    0
     0    9   91   43    0
     0    0   30   80    0
     0    0    0    3    0
[epoch 15] step 2/44: loss=0.6707 
[epoch 15] step 4/44: loss=0.6624 
[epoch 15] step 6/44: loss=0.6730 
[epoch 15] step 8/44: loss=0.6735 
[epoch 15] step 10/44: loss=0.6741 
[epoch 15] step 12/44: loss=0.6801 
[epoch 15] step 14/44: loss=0.6835 
[epoch 15] step 16/44: loss=0.6847 
[epoch 15] step 18/44: loss=0.6814 
[epoch 15] step 20/44: loss=0.6835 
[epoch 15] step 22/44: loss=0.6825 
[epoch 15] step 24/44: loss=0.6799 
[epoch 15] step 26/44: loss=0.6795 
[epoch 15] step 28/44: loss=0.6761 
[epoch 15] step 30/44: loss=0.6746 
[epoch 15] step 32/44: loss=0.6760 
[epoch 15] step 34/44: loss=0.6760 
[epoch 15] step 36/44: loss=0.6768 
[epoch 15] step 38/44: loss=0.6796 
[epoch 15] step 40/44: loss=0.6788 
[epoch 15] step 42/44: loss=0.6786 
[epoch 15] step 44/44: loss=0.6792 
[epoch 15] train_loss(avg per step)=1.3584 lambda[min,max]=[0.397125,1.000000]
[epoch 15] val_loss=1.4038 qwk=('0.5758', '0.5624', '0.5344') averageQWK=0.5576 macroEMD=0.2923 tailR0=('0.1325', '0.0000', '0.0000') tailR0avg=0.0442
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    6    0    0
     1    6   43    2    0
     0    5   76   33    0
     0    0   35  101    3
     0    0    2    6    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     3   15   34    3    0
     0   12   63   39    0
     0    2   34  107    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0   17   48    0    0
     0   10  111   22    0
     0    0   43   67    0
     0    0    0    3    0
[epoch 16] step 2/44: loss=0.6991 
[epoch 16] step 4/44: loss=0.6898 
[epoch 16] step 6/44: loss=0.6935 
[epoch 16] step 8/44: loss=0.6867 
[epoch 16] step 10/44: loss=0.6817 
[epoch 16] step 12/44: loss=0.6734 
[epoch 16] step 14/44: loss=0.6703 
[epoch 16] step 16/44: loss=0.6704 
[epoch 16] step 18/44: loss=0.6717 
[epoch 16] step 20/44: loss=0.6715 
[epoch 16] step 22/44: loss=0.6717 
[epoch 16] step 24/44: loss=0.6737 
[epoch 16] step 26/44: loss=0.6758 
[epoch 16] step 28/44: loss=0.6753 
[epoch 16] step 30/44: loss=0.6727 
[epoch 16] step 32/44: loss=0.6694 
[epoch 16] step 34/44: loss=0.6673 
[epoch 16] step 36/44: loss=0.6657 
[epoch 16] step 38/44: loss=0.6641 
[epoch 16] step 40/44: loss=0.6640 
[epoch 16] step 42/44: loss=0.6639 
[epoch 16] step 44/44: loss=0.6647 
[epoch 16] train_loss(avg per step)=1.3294 lambda[min,max]=[0.434229,1.000000]
[epoch 16] val_loss=1.3933 qwk=('0.5373', '0.5641', '0.5454') averageQWK=0.5489 macroEMD=0.2962 tailR0=('0.0556', '0.0000', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    6    0    0
     0    4   46    2    0
     0    3   88   23    0
     0    0   45   94    0
     0    0    2    6    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   12   39    4    0
     0    4   66   44    0
     0    0   26  117    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0   14   51    0    0
     0   10  107   26    0
     0    0   35   75    0
     0    0    0    3    0
[epoch 17] step 2/44: loss=0.6786 
[epoch 17] step 4/44: loss=0.6697 
[epoch 17] step 6/44: loss=0.6754 
[epoch 17] step 8/44: loss=0.6704 
[epoch 17] step 10/44: loss=0.6639 
[epoch 17] step 12/44: loss=0.6577 
[epoch 17] step 14/44: loss=0.6587 
[epoch 17] step 16/44: loss=0.6566 
[epoch 17] step 18/44: loss=0.6528 
[epoch 17] step 20/44: loss=0.6463 
[epoch 17] step 22/44: loss=0.6449 
[epoch 17] step 24/44: loss=0.6418 
[epoch 17] step 26/44: loss=0.6437 
[epoch 17] step 28/44: loss=0.6453 
[epoch 17] step 30/44: loss=0.6466 
[epoch 17] step 32/44: loss=0.6497 
[epoch 17] step 34/44: loss=0.6514 
[epoch 17] step 36/44: loss=0.6494 
[epoch 17] step 38/44: loss=0.6490 
[epoch 17] step 40/44: loss=0.6490 
[epoch 17] step 42/44: loss=0.6498 
[epoch 17] step 44/44: loss=0.6498 
[epoch 17] train_loss(avg per step)=1.2996 lambda[min,max]=[0.379976,1.000000]
[epoch 17] val_loss=1.4029 qwk=('0.5384', '0.5106', '0.5208') averageQWK=0.5233 macroEMD=0.2967 tailR0=('0.0556', '0.0000', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    7    0    0
     0    5   41    6    0
     0    3   65   46    0
     0    0   23  113    3
     0    0    1    7    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     1    6   42    6    0
     0    3   53   58    0
     0    0   19  124    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   21   44    0    0
     0   12  112   19    0
     0    2   41   67    0
     0    0    1    2    0
[epoch 18] step 2/44: loss=0.6945 
[epoch 18] step 4/44: loss=0.6775 
[epoch 18] step 6/44: loss=0.6661 
[epoch 18] step 8/44: loss=0.6577 
[epoch 18] step 10/44: loss=0.6473 
[epoch 18] step 12/44: loss=0.6412 
[epoch 18] step 14/44: loss=0.6427 
[epoch 18] step 16/44: loss=0.6377 
[epoch 18] step 18/44: loss=0.6388 
[epoch 18] step 20/44: loss=0.6393 
[epoch 18] step 22/44: loss=0.6385 
[epoch 18] step 24/44: loss=0.6387 
[epoch 18] step 26/44: loss=0.6379 
[epoch 18] step 28/44: loss=0.6362 
[epoch 18] step 30/44: loss=0.6378 
[epoch 18] step 32/44: loss=0.6391 
[epoch 18] step 34/44: loss=0.6386 
[epoch 18] step 36/44: loss=0.6390 
[epoch 18] step 38/44: loss=0.6373 
[epoch 18] step 40/44: loss=0.6334 
[epoch 18] step 42/44: loss=0.6327 
[epoch 18] step 44/44: loss=0.6339 
[epoch 18] train_loss(avg per step)=1.2677 lambda[min,max]=[0.370942,1.000000]
[epoch 18] val_loss=1.4054 qwk=('0.5725', '0.5577', '0.5209') averageQWK=0.5504 macroEMD=0.2973 tailR0=('0.0556', '0.0000', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    4    0    0
     0   13   37    2    0
     0   11   76   27    0
     0    2   39   97    1
     0    0    3    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   18   34    3    0
     0    7   66   41    0
     0    1   37  105    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0   20   45    0    0
     0   13  115   15    0
     0    2   44   64    0
     0    0    1    2    0
[epoch 19] step 2/44: loss=0.6629 
[epoch 19] step 4/44: loss=0.6626 
[epoch 19] step 6/44: loss=0.6649 
[epoch 19] step 8/44: loss=0.6542 
[epoch 19] step 10/44: loss=0.6530 
[epoch 19] step 12/44: loss=0.6427 
[epoch 19] step 14/44: loss=0.6399 
[epoch 19] step 16/44: loss=0.6381 
[epoch 19] step 18/44: loss=0.6373 
[epoch 19] step 20/44: loss=0.6335 
[epoch 19] step 22/44: loss=0.6344 
[epoch 19] step 24/44: loss=0.6336 
[epoch 19] step 26/44: loss=0.6325 
[epoch 19] step 28/44: loss=0.6342 
[epoch 19] step 30/44: loss=0.6344 
[epoch 19] step 32/44: loss=0.6326 
[epoch 19] step 34/44: loss=0.6305 
[epoch 19] step 36/44: loss=0.6295 
[epoch 19] step 38/44: loss=0.6248 
[epoch 19] step 40/44: loss=0.6238 
[epoch 19] step 42/44: loss=0.6240 
[epoch 19] step 44/44: loss=0.6244 
[epoch 19] train_loss(avg per step)=1.2488 lambda[min,max]=[0.380055,1.000000]
[epoch 19] val_loss=1.3943 qwk=('0.5404', '0.5492', '0.5112') averageQWK=0.5336 macroEMD=0.2986 tailR0=('0.0556', '0.0000', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     0    6   45    1    0
     0    4   89   21    0
     0    0   48   89    2
     0    0    4    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   13   38    4    0
     0    5   70   39    0
     0    0   35  108    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0   21   44    0    0
     0   18  107   18    0
     0    5   39   66    0
     0    0    1    2    0
[epoch 20] step 2/44: loss=0.6253 
[epoch 20] step 4/44: loss=0.6267 
[epoch 20] step 6/44: loss=0.6284 
[epoch 20] step 8/44: loss=0.6243 
[epoch 20] step 10/44: loss=0.6243 
[epoch 20] step 12/44: loss=0.6260 
[epoch 20] step 14/44: loss=0.6260 
[epoch 20] step 16/44: loss=0.6282 
[epoch 20] step 18/44: loss=0.6268 
[epoch 20] step 20/44: loss=0.6197 
[epoch 20] step 22/44: loss=0.6203 
[epoch 20] step 24/44: loss=0.6220 
[epoch 20] step 26/44: loss=0.6224 
[epoch 20] step 28/44: loss=0.6206 
[epoch 20] step 30/44: loss=0.6189 
[epoch 20] step 32/44: loss=0.6170 
[epoch 20] step 34/44: loss=0.6170 
[epoch 20] step 36/44: loss=0.6132 
[epoch 20] step 38/44: loss=0.6110 
[epoch 20] step 40/44: loss=0.6091 
[epoch 20] step 42/44: loss=0.6105 
[epoch 20] step 44/44: loss=0.6109 
[epoch 20] train_loss(avg per step)=1.2218 lambda[min,max]=[0.377250,1.000000]
[epoch 20] val_loss=1.4033 qwk=('0.5934', '0.5406', '0.5325') averageQWK=0.5555 macroEMD=0.2953 tailR0=('0.1325', '0.0000', '0.0833') tailR0avg=0.0719
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    7    4    0    0
     1   10   36    5    0
     0    7   64   43    0
     0    2   23  111    3
     0    0    1    7    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     3   15   31    6    0
     0   10   47   57    0
     0    4   17  122    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    5    0    0
     0   14   51    0    0
     0    6  118   19    0
     0    0   42   68    0
     0    0    1    2    0
[epoch 21] step 2/44: loss=0.6439 
[epoch 21] step 4/44: loss=0.6618 
[epoch 21] step 6/44: loss=0.6588 
[epoch 21] step 8/44: loss=0.6480 
[epoch 21] step 10/44: loss=0.6396 
[epoch 21] step 12/44: loss=0.6280 
[epoch 21] step 14/44: loss=0.6324 
[epoch 21] step 16/44: loss=0.6270 
[epoch 21] step 18/44: loss=0.6194 
[epoch 21] step 20/44: loss=0.6143 
[epoch 21] step 22/44: loss=0.6146 
[epoch 21] step 24/44: loss=0.6121 
[epoch 21] step 26/44: loss=0.6091 
[epoch 21] step 28/44: loss=0.6063 
[epoch 21] step 30/44: loss=0.6052 
[epoch 21] step 32/44: loss=0.6059 
[epoch 21] step 34/44: loss=0.6084 
[epoch 21] step 36/44: loss=0.6083 
[epoch 21] step 38/44: loss=0.6091 
[epoch 21] step 40/44: loss=0.6071 
[epoch 21] step 42/44: loss=0.6051 
[epoch 21] step 44/44: loss=0.6026 
[epoch 21] train_loss(avg per step)=1.2052 lambda[min,max]=[0.366876,1.000000]
[epoch 21] val_loss=1.3988 qwk=('0.5725', '0.5332', '0.5493') averageQWK=0.5517 macroEMD=0.2987 tailR0=('0.0000', '0.0000', '0.0833') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    3    0    0
     0   11   38    3    0
     0   10   75   29    0
     0    2   37   99    1
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   18   33    4    0
     0    9   67   38    0
     0    3   38  102    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    5    0    0
     0   14   51    0    0
     0    8  114   21    0
     0    0   39   71    0
     0    0    0    3    0
[epoch 22] step 2/44: loss=0.6497 
[epoch 22] step 4/44: loss=0.6103 
[epoch 22] step 6/44: loss=0.6070 
[epoch 22] step 8/44: loss=0.6040 
[epoch 22] step 10/44: loss=0.5986 
[epoch 22] step 12/44: loss=0.5878 
[epoch 22] step 14/44: loss=0.5876 
[epoch 22] step 16/44: loss=0.5817 
[epoch 22] step 18/44: loss=0.5876 
[epoch 22] step 20/44: loss=0.5886 
[epoch 22] step 22/44: loss=0.5913 
[epoch 22] step 24/44: loss=0.5931 
[epoch 22] step 26/44: loss=0.5936 
[epoch 22] step 28/44: loss=0.5928 
[epoch 22] step 30/44: loss=0.5898 
[epoch 22] step 32/44: loss=0.5890 
[epoch 22] step 34/44: loss=0.5875 
[epoch 22] step 36/44: loss=0.5870 
[epoch 22] step 38/44: loss=0.5852 
[epoch 22] step 40/44: loss=0.5848 
[epoch 22] step 42/44: loss=0.5842 
[epoch 22] step 44/44: loss=0.5857 
[epoch 22] train_loss(avg per step)=1.1715 lambda[min,max]=[0.366190,1.000000]
[epoch 22] val_loss=1.3794 qwk=('0.5362', '0.5485', '0.5060') averageQWK=0.5302 macroEMD=0.2992 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    6    0    0
     0    5   45    2    0
     0    6   81   27    0
     0    1   39   98    1
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     0   15   35    5    0
     0    5   63   46    0
     0    0   28  115    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   15   50    0    0
     0    9  115   19    0
     0    1   41   68    0
     0    0    1    2    0
[epoch 23] step 2/44: loss=0.6290 
[epoch 23] step 4/44: loss=0.6139 
[epoch 23] step 6/44: loss=0.6066 
[epoch 23] step 8/44: loss=0.6054 
[epoch 23] step 10/44: loss=0.6091 
[epoch 23] step 12/44: loss=0.6062 
[epoch 23] step 14/44: loss=0.6038 
[epoch 23] step 16/44: loss=0.6025 
[epoch 23] step 18/44: loss=0.5993 
[epoch 23] step 20/44: loss=0.5976 
[epoch 23] step 22/44: loss=0.5924 
[epoch 23] step 24/44: loss=0.5897 
[epoch 23] step 26/44: loss=0.5888 
[epoch 23] step 28/44: loss=0.5889 
[epoch 23] step 30/44: loss=0.5896 
[epoch 23] step 32/44: loss=0.5908 
[epoch 23] step 34/44: loss=0.5921 
[epoch 23] step 36/44: loss=0.5924 
[epoch 23] step 38/44: loss=0.5924 
[epoch 23] step 40/44: loss=0.5929 
[epoch 23] step 42/44: loss=0.5900 
[epoch 23] step 44/44: loss=0.5881 
[epoch 23] train_loss(avg per step)=1.1763 lambda[min,max]=[0.369006,1.000000]
[epoch 23] val_loss=1.3922 qwk=('0.5339', '0.5321', '0.5049') averageQWK=0.5236 macroEMD=0.3019 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    7    0    0
     0    6   45    1    0
     0    5   79   30    0
     0    1   39   96    3
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   19   31    5    0
     0   12   50   52    0
     0    6   19  118    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   15   50    0    0
     0    6  125   12    0
     0    0   48   62    0
     0    0    1    2    0
[epoch 24] step 2/44: loss=0.5970 
[epoch 24] step 4/44: loss=0.5725 
[epoch 24] step 6/44: loss=0.5641 
[epoch 24] step 8/44: loss=0.5622 
[epoch 24] step 10/44: loss=0.5558 
[epoch 24] step 12/44: loss=0.5532 
[epoch 24] step 14/44: loss=0.5544 
[epoch 24] step 16/44: loss=0.5533 
[epoch 24] step 18/44: loss=0.5569 
[epoch 24] step 20/44: loss=0.5566 
[epoch 24] step 22/44: loss=0.5580 
[epoch 24] step 24/44: loss=0.5622 
[epoch 24] step 26/44: loss=0.5654 
[epoch 24] step 28/44: loss=0.5706 
[epoch 24] step 30/44: loss=0.5707 
[epoch 24] step 32/44: loss=0.5745 
[epoch 24] step 34/44: loss=0.5750 
[epoch 24] step 36/44: loss=0.5776 
[epoch 24] step 38/44: loss=0.5777 
[epoch 24] step 40/44: loss=0.5774 
[epoch 24] step 42/44: loss=0.5770 
[epoch 24] step 44/44: loss=0.5768 
[epoch 24] train_loss(avg per step)=1.1536 lambda[min,max]=[0.379316,1.000000]
[epoch 24] val_loss=1.3918 qwk=('0.5699', '0.5331', '0.5226') averageQWK=0.5419 macroEMD=0.3025 tailR0=('0.0000', '0.0000', '0.0833') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    4    0    0
     1   11   38    2    0
     0   13   72   29    0
     0    3   35  101    0
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   21   32    2    0
     0   10   69   35    0
     0    3   46   94    0
     0    0    2    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    5    0    0
     0   12   53    0    0
     0    7  120   16    0
     0    0   43   67    0
     0    0    1    2    0
[epoch 25] step 2/44: loss=0.5724 
[epoch 25] step 4/44: loss=0.5744 
[epoch 25] step 6/44: loss=0.5684 
[epoch 25] step 8/44: loss=0.5586 
[epoch 25] step 10/44: loss=0.5549 
[epoch 25] step 12/44: loss=0.5544 
[epoch 25] step 14/44: loss=0.5593 
[epoch 25] step 16/44: loss=0.5622 
[epoch 25] step 18/44: loss=0.5661 
[epoch 25] step 20/44: loss=0.5689 
[epoch 25] step 22/44: loss=0.5696 
[epoch 25] step 24/44: loss=0.5722 
[epoch 25] step 26/44: loss=0.5713 
[epoch 25] step 28/44: loss=0.5706 
[epoch 25] step 30/44: loss=0.5699 
[epoch 25] step 32/44: loss=0.5698 
[epoch 25] step 34/44: loss=0.5690 
[epoch 25] step 36/44: loss=0.5671 
[epoch 25] step 38/44: loss=0.5669 
[epoch 25] step 40/44: loss=0.5673 
[epoch 25] step 42/44: loss=0.5668 
[epoch 25] step 44/44: loss=0.5683 
[epoch 25] train_loss(avg per step)=1.1367 lambda[min,max]=[0.363479,1.000000]
[epoch 25] val_loss=1.3954 qwk=('0.5335', '0.5480', '0.5119') averageQWK=0.5311 macroEMD=0.2976 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    0    0
     1    3   45    3    0
     0    5   73   36    0
     0    1   28  110    0
     0    0    1    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   22   26    7    0
     0   14   41   59    0
     0    4   14  125    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   13   52    0    0
     0    7  108   28    0
     0    0   39   71    0
     0    0    0    3    0
[epoch 26] step 2/44: loss=0.5744 
[epoch 26] step 4/44: loss=0.5702 
[epoch 26] step 6/44: loss=0.5747 
[epoch 26] step 8/44: loss=0.5648 
[epoch 26] step 10/44: loss=0.5651 
[epoch 26] step 12/44: loss=0.5570 
[epoch 26] step 14/44: loss=0.5551 
[epoch 26] step 16/44: loss=0.5497 
[epoch 26] step 18/44: loss=0.5522 
[epoch 26] step 20/44: loss=0.5489 
[epoch 26] step 22/44: loss=0.5477 
[epoch 26] step 24/44: loss=0.5515 
[epoch 26] step 26/44: loss=0.5547 
[epoch 26] step 28/44: loss=0.5552 
[epoch 26] step 30/44: loss=0.5574 
[epoch 26] step 32/44: loss=0.5575 
[epoch 26] step 34/44: loss=0.5558 
[epoch 26] step 36/44: loss=0.5557 
[epoch 26] step 38/44: loss=0.5583 
[epoch 26] step 40/44: loss=0.5577 
[epoch 26] step 42/44: loss=0.5593 
[epoch 26] step 44/44: loss=0.5585 
[epoch 26] train_loss(avg per step)=1.1170 lambda[min,max]=[0.355291,1.000000]
[epoch 26] val_loss=1.3998 qwk=('0.5734', '0.5607', '0.4932') averageQWK=0.5425 macroEMD=0.2962 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    3    0    0
     0   11   38    3    0
     0   13   66   35    0
     0    2   32  103    2
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    0    0
     0   25   26    4    0
     0   22   45   47    0
     0    7   21  115    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   14   51    0    0
     0    7  121   15    0
     0    1   45   64    0
     0    0    1    2    0
[epoch 27] step 2/44: loss=0.5413 
[epoch 27] step 4/44: loss=0.5682 
[epoch 27] step 6/44: loss=0.5716 
[epoch 27] step 8/44: loss=0.5726 
[epoch 27] step 10/44: loss=0.5645 
[epoch 27] step 12/44: loss=0.5689 
[epoch 27] step 14/44: loss=0.5676 
[epoch 27] step 16/44: loss=0.5682 
[epoch 27] step 18/44: loss=0.5639 
[epoch 27] step 20/44: loss=0.5624 
[epoch 27] step 22/44: loss=0.5633 
[epoch 27] step 24/44: loss=0.5606 
[epoch 27] step 26/44: loss=0.5590 
[epoch 27] step 28/44: loss=0.5592 
[epoch 27] step 30/44: loss=0.5585 
[epoch 27] step 32/44: loss=0.5574 
[epoch 27] step 34/44: loss=0.5571 
[epoch 27] step 36/44: loss=0.5574 
[epoch 27] step 38/44: loss=0.5567 
[epoch 27] step 40/44: loss=0.5565 
[epoch 27] step 42/44: loss=0.5566 
[epoch 27] step 44/44: loss=0.5569 
[epoch 27] train_loss(avg per step)=1.1139 lambda[min,max]=[0.359870,1.000000]
[epoch 27] val_loss=1.3918 qwk=('0.5840', '0.5512', '0.5373') averageQWK=0.5575 macroEMD=0.2969 tailR0=('0.0769', '0.0000', '0.0833') tailR0avg=0.0534
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    7    4    0    0
     1   10   39    2    0
     0   11   73   30    0
     0    2   36   98    3
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     2   17   33    3    0
     0    8   63   43    0
     0    3   34  106    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    5    0    0
     0   17   48    0    0
     0    9  112   22    0
     0    0   42   68    0
     0    0    1    2    0
[epoch 28] step 2/44: loss=0.5662 
[epoch 28] step 4/44: loss=0.5651 
[epoch 28] step 6/44: loss=0.5579 
[epoch 28] step 8/44: loss=0.5586 
[epoch 28] step 10/44: loss=0.5603 
[epoch 28] step 12/44: loss=0.5584 
[epoch 28] step 14/44: loss=0.5583 
[epoch 28] step 16/44: loss=0.5626 
[epoch 28] step 18/44: loss=0.5635 
[epoch 28] step 20/44: loss=0.5652 
[epoch 28] step 22/44: loss=0.5658 
[epoch 28] step 24/44: loss=0.5657 
[epoch 28] step 26/44: loss=0.5641 
[epoch 28] step 28/44: loss=0.5617 
[epoch 28] step 30/44: loss=0.5599 
[epoch 28] step 32/44: loss=0.5603 
[epoch 28] step 34/44: loss=0.5575 
[epoch 28] step 36/44: loss=0.5571 
[epoch 28] step 38/44: loss=0.5577 
[epoch 28] step 40/44: loss=0.5595 
[epoch 28] step 42/44: loss=0.5591 
[epoch 28] step 44/44: loss=0.5598 
[epoch 28] train_loss(avg per step)=1.1195 lambda[min,max]=[0.360910,1.000000]
[epoch 28] val_loss=1.3940 qwk=('0.5560', '0.5605', '0.5257') averageQWK=0.5474 macroEMD=0.2957 tailR0=('0.0000', '0.0000', '0.0833') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     1    4   46    1    0
     0    6   90   18    0
     0    0   47   92    0
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     1   19   32    3    0
     0   13   57   44    0
     0    4   27  112    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    5    0    0
     0   15   50    0    0
     0    7  114   22    0
     0    0   43   67    0
     0    0    1    2    0
[epoch 29] step 2/44: loss=0.5484 
[epoch 29] step 4/44: loss=0.5222 
[epoch 29] step 6/44: loss=0.5393 
[epoch 29] step 8/44: loss=0.5467 
[epoch 29] step 10/44: loss=0.5481 
[epoch 29] step 12/44: loss=0.5489 
[epoch 29] step 14/44: loss=0.5513 
[epoch 29] step 16/44: loss=0.5526 
[epoch 29] step 18/44: loss=0.5575 
[epoch 29] step 20/44: loss=0.5541 
[epoch 29] step 22/44: loss=0.5506 
[epoch 29] step 24/44: loss=0.5516 
[epoch 29] step 26/44: loss=0.5521 
[epoch 29] step 28/44: loss=0.5547 
[epoch 29] step 30/44: loss=0.5535 
[epoch 29] step 32/44: loss=0.5518 
[epoch 29] step 34/44: loss=0.5509 
[epoch 29] step 36/44: loss=0.5507 
[epoch 29] step 38/44: loss=0.5495 
[epoch 29] step 40/44: loss=0.5491 
[epoch 29] step 42/44: loss=0.5507 
[epoch 29] step 44/44: loss=0.5495 
[epoch 29] train_loss(avg per step)=1.0991 lambda[min,max]=[0.343909,1.000000]
[epoch 29] val_loss=1.3826 qwk=('0.5382', '0.5509', '0.5244') averageQWK=0.5378 macroEMD=0.2948 tailR0=('0.0385', '0.0000', '0.0000') tailR0avg=0.0128
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    7    0    0
     1    2   47    2    0
     0    3   76   35    0
     0    0   34  104    1
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     2   16   32    5    0
     0    9   49   56    0
     0    2   19  122    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   18   47    0    0
     0    8  113   22    0
     0    0   42   68    0
     0    0    1    2    0
[epoch 30] step 2/44: loss=0.5646 
[epoch 30] step 4/44: loss=0.5660 
[epoch 30] step 6/44: loss=0.5651 
[epoch 30] step 8/44: loss=0.5656 
[epoch 30] step 10/44: loss=0.5686 
[epoch 30] step 12/44: loss=0.5673 
[epoch 30] step 14/44: loss=0.5665 
[epoch 30] step 16/44: loss=0.5663 
[epoch 30] step 18/44: loss=0.5684 
[epoch 30] step 20/44: loss=0.5705 
[epoch 30] step 22/44: loss=0.5680 
[epoch 30] step 24/44: loss=0.5625 
[epoch 30] step 26/44: loss=0.5615 
[epoch 30] step 28/44: loss=0.5589 
[epoch 30] step 30/44: loss=0.5570 
[epoch 30] step 32/44: loss=0.5563 
[epoch 30] step 34/44: loss=0.5553 
[epoch 30] step 36/44: loss=0.5551 
[epoch 30] step 38/44: loss=0.5547 
[epoch 30] step 40/44: loss=0.5518 
[epoch 30] step 42/44: loss=0.5492 
[epoch 30] step 44/44: loss=0.5493 
[epoch 30] train_loss(avg per step)=1.0986 lambda[min,max]=[0.386211,1.000000]
[epoch 30] val_loss=1.4014 qwk=('0.5775', '0.5490', '0.5303') averageQWK=0.5523 macroEMD=0.2916 tailR0=('0.0385', '0.0000', '0.0833') tailR0avg=0.0406
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    8    4    0    0
     1   10   38    3    0
     0   11   70   33    0
     0    3   29  105    2
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     2   19   30    4    0
     0   16   47   51    0
     0    4   25  114    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    5    0    0
     0   16   49    0    0
     0    9  111   23    0
     0    0   42   68    0
     0    0    1    2    0
[epoch 31] step 2/44: loss=0.5812 
[epoch 31] step 4/44: loss=0.5726 
[epoch 31] step 6/44: loss=0.5712 
[epoch 31] step 8/44: loss=0.5663 
[epoch 31] step 10/44: loss=0.5727 
[epoch 31] step 12/44: loss=0.5743 
[epoch 31] step 14/44: loss=0.5717 
[epoch 31] step 16/44: loss=0.5685 
[epoch 31] step 18/44: loss=0.5693 
[epoch 31] step 20/44: loss=0.5698 
[epoch 31] step 22/44: loss=0.5676 
[epoch 31] step 24/44: loss=0.5668 
[epoch 31] step 26/44: loss=0.5657 
[epoch 31] step 28/44: loss=0.5644 
[epoch 31] step 30/44: loss=0.5618 
[epoch 31] step 32/44: loss=0.5605 
[epoch 31] step 34/44: loss=0.5588 
[epoch 31] step 36/44: loss=0.5588 
[epoch 31] step 38/44: loss=0.5579 
[epoch 31] step 40/44: loss=0.5556 
[epoch 31] step 42/44: loss=0.5542 
[epoch 31] step 44/44: loss=0.5516 
[epoch 31] train_loss(avg per step)=1.1031 lambda[min,max]=[0.368593,1.000000]
[epoch 31] val_loss=1.4059 qwk=('0.5381', '0.5546', '0.4989') averageQWK=0.5305 macroEMD=0.2958 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    6    0    0
     1    6   42    3    0
     0    7   70   37    0
     0    1   33  104    1
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   20   31    4    0
     0   12   53   49    0
     0    3   26  114    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   13   52    0    0
     0    6  114   23    0
     0    0   42   68    0
     0    0    1    2    0
[epoch 32] step 2/44: loss=0.5683 
[epoch 32] step 4/44: loss=0.5781 
[epoch 32] step 6/44: loss=0.5690 
[epoch 32] step 8/44: loss=0.5599 
[epoch 32] step 10/44: loss=0.5566 
[epoch 32] step 12/44: loss=0.5587 
[epoch 32] step 14/44: loss=0.5589 
[epoch 32] step 16/44: loss=0.5486 
[epoch 32] step 18/44: loss=0.5474 
[epoch 32] step 20/44: loss=0.5444 
[epoch 32] step 22/44: loss=0.5480 
[epoch 32] step 24/44: loss=0.5469 
[epoch 32] step 26/44: loss=0.5460 
[epoch 32] step 28/44: loss=0.5477 
[epoch 32] step 30/44: loss=0.5459 
[epoch 32] step 32/44: loss=0.5461 
[epoch 32] step 34/44: loss=0.5464 
[epoch 32] step 36/44: loss=0.5448 
[epoch 32] step 38/44: loss=0.5468 
[epoch 32] step 40/44: loss=0.5468 
[epoch 32] step 42/44: loss=0.5468 
[epoch 32] step 44/44: loss=0.5477 
[epoch 32] train_loss(avg per step)=1.0954 lambda[min,max]=[0.356353,1.000000]
[epoch 32] val_loss=1.4042 qwk=('0.5400', '0.5589', '0.4985') averageQWK=0.5324 macroEMD=0.2946 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    7    0    0
     0    7   43    2    0
     0    6   77   31    0
     0    0   38  100    1
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   22   29    4    0
     0   14   48   52    0
     0    5   19  119    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   14   51    0    0
     0    7  113   23    0
     0    0   43   67    0
     0    0    1    2    0
[epoch 33] step 2/44: loss=0.6036 
[epoch 33] step 4/44: loss=0.5750 
[epoch 33] step 6/44: loss=0.5596 
[epoch 33] step 8/44: loss=0.5499 
[epoch 33] step 10/44: loss=0.5514 
[epoch 33] step 12/44: loss=0.5480 
[epoch 33] step 14/44: loss=0.5472 
[epoch 33] step 16/44: loss=0.5443 
[epoch 33] step 18/44: loss=0.5403 
[epoch 33] step 20/44: loss=0.5377 
[epoch 33] step 22/44: loss=0.5401 
[epoch 33] step 24/44: loss=0.5397 
[epoch 33] step 26/44: loss=0.5388 
[epoch 33] step 28/44: loss=0.5392 
[epoch 33] step 30/44: loss=0.5410 
[epoch 33] step 32/44: loss=0.5397 
[epoch 33] step 34/44: loss=0.5387 
[epoch 33] step 36/44: loss=0.5407 
[epoch 33] step 38/44: loss=0.5413 
[epoch 33] step 40/44: loss=0.5410 
[epoch 33] step 42/44: loss=0.5411 
[epoch 33] step 44/44: loss=0.5433 
[epoch 33] train_loss(avg per step)=1.0866 lambda[min,max]=[0.384620,1.000000]
[epoch 33] val_loss=1.4031 qwk=('0.5602', '0.5579', '0.4965') averageQWK=0.5382 macroEMD=0.2940 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    4    0    0
     0   10   39    3    0
     0   11   67   36    0
     0    2   32  104    1
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   22   29    4    0
     0   15   50   49    0
     0    4   24  115    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   13   52    0    0
     0    8  112   23    0
     0    0   42   68    0
     0    0    1    2    0
[epoch 34] step 2/44: loss=0.5342 
[epoch 34] step 4/44: loss=0.5425 
[epoch 34] step 6/44: loss=0.5262 
[epoch 34] step 8/44: loss=0.5257 
[epoch 34] step 10/44: loss=0.5247 
[epoch 34] step 12/44: loss=0.5297 
[epoch 34] step 14/44: loss=0.5313 
[epoch 34] step 16/44: loss=0.5331 
[epoch 34] step 18/44: loss=0.5380 
[epoch 34] step 20/44: loss=0.5414 
[epoch 34] step 22/44: loss=0.5411 
[epoch 34] step 24/44: loss=0.5415 
[epoch 34] step 26/44: loss=0.5444 
[epoch 34] step 28/44: loss=0.5441 
[epoch 34] step 30/44: loss=0.5426 
[epoch 34] step 32/44: loss=0.5447 
[epoch 34] step 34/44: loss=0.5440 
[epoch 34] step 36/44: loss=0.5430 
[epoch 34] step 38/44: loss=0.5420 
[epoch 34] step 40/44: loss=0.5414 
[epoch 34] step 42/44: loss=0.5398 
[epoch 34] step 44/44: loss=0.5390 
[epoch 34] train_loss(avg per step)=1.0780 lambda[min,max]=[0.381469,1.000000]
[epoch 34] val_loss=1.3975 qwk=('0.5700', '0.5568', '0.5045') averageQWK=0.5438 macroEMD=0.2957 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     1    7   43    1    0
     0    6   76   32    0
     0    0   38   99    2
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   20   32    3    0
     0   12   55   47    0
     0    4   26  113    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   15   50    0    0
     0    8  113   22    0
     0    0   43   67    0
     0    0    1    2    0
[epoch 35] step 2/44: loss=0.5226 
[epoch 35] step 4/44: loss=0.5502 
[epoch 35] step 6/44: loss=0.5551 
[epoch 35] step 8/44: loss=0.5506 
[epoch 35] step 10/44: loss=0.5496 
[epoch 35] step 12/44: loss=0.5469 
[epoch 35] step 14/44: loss=0.5453 
[epoch 35] step 16/44: loss=0.5392 
[epoch 35] step 18/44: loss=0.5413 
[epoch 35] step 20/44: loss=0.5412 
[epoch 35] step 22/44: loss=0.5396 
[epoch 35] step 24/44: loss=0.5384 
[epoch 35] step 26/44: loss=0.5398 
[epoch 35] step 28/44: loss=0.5401 
[epoch 35] step 30/44: loss=0.5388 
[epoch 35] step 32/44: loss=0.5409 
[epoch 35] step 34/44: loss=0.5412 
[epoch 35] step 36/44: loss=0.5399 
[epoch 35] step 38/44: loss=0.5418 
[epoch 35] step 40/44: loss=0.5432 
[epoch 35] step 42/44: loss=0.5439 
[epoch 35] step 44/44: loss=0.5438 
[epoch 35] train_loss(avg per step)=1.0877 lambda[min,max]=[0.385749,1.000000]
[epoch 35] val_loss=1.4062 qwk=('0.5616', '0.5647', '0.5025') averageQWK=0.5429 macroEMD=0.2948 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     1    8   42    1    0
     0    9   71   34    0
     0    1   37   99    2
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   22   30    3    0
     0   14   52   48    0
     0    4   25  114    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   15   50    0    0
     0    8  112   23    0
     0    0   43   67    0
     0    0    1    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold5/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold5/metrics.json
Done.
