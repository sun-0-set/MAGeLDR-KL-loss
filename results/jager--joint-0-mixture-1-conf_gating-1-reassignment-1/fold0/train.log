[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.4929 
[epoch 1] step 4/44: loss=0.4994 
[epoch 1] step 6/44: loss=0.4997 
[epoch 1] step 8/44: loss=0.5056 
[epoch 1] step 10/44: loss=0.5115 
[epoch 1] step 12/44: loss=0.5134 
[epoch 1] step 14/44: loss=0.5155 
[epoch 1] step 16/44: loss=0.5183 
[epoch 1] step 18/44: loss=0.5227 
[epoch 1] step 20/44: loss=0.5242 
[epoch 1] step 22/44: loss=0.5274 
[epoch 1] step 24/44: loss=0.5309 
[epoch 1] step 26/44: loss=0.5353 
[epoch 1] step 28/44: loss=0.5378 
[epoch 1] step 30/44: loss=0.5423 
[epoch 1] step 32/44: loss=0.5452 
[epoch 1] step 34/44: loss=0.5478 
[epoch 1] step 36/44: loss=0.5505 
[epoch 1] step 38/44: loss=0.5535 
[epoch 1] step 40/44: loss=0.5572 
[epoch 1] step 42/44: loss=0.5595 
[epoch 1] step 44/44: loss=0.5628 
[epoch 1] train_loss(avg per step)=1.1256 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=0.8289 qwk=('0.0031', '-0.0009', '-0.0574') averageQWK=-0.0184 macroEMD=0.3648 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    4    0
     0    0    0   15    0
     0    3    0   75    0
     0   13    0  149    0
     0    0    0   64    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   16    0    0
     2    0   63    1    0
     6    0  196    3    0
     0    0   30    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   22    0    0
     0   29   82    0    0
     0   68  113    0    0
     0    0    1    0    0
[epoch 2] step 2/44: loss=0.6999 
[epoch 2] step 4/44: loss=0.7132 
[epoch 2] step 6/44: loss=0.7358 
[epoch 2] step 8/44: loss=0.7457 
[epoch 2] step 10/44: loss=0.7570 
[epoch 2] step 12/44: loss=0.7796 
[epoch 2] step 14/44: loss=0.7991 
[epoch 2] step 16/44: loss=0.8161 
[epoch 2] step 18/44: loss=0.8255 
[epoch 2] step 20/44: loss=0.8305 
[epoch 2] step 22/44: loss=0.8334 
[epoch 2] step 24/44: loss=0.8324 
[epoch 2] step 26/44: loss=0.8312 
[epoch 2] step 28/44: loss=0.8279 
[epoch 2] step 30/44: loss=0.8263 
[epoch 2] step 32/44: loss=0.8249 
[epoch 2] step 34/44: loss=0.8266 
[epoch 2] step 36/44: loss=0.8293 
[epoch 2] step 38/44: loss=0.8316 
[epoch 2] step 40/44: loss=0.8325 
[epoch 2] step 42/44: loss=0.8305 
[epoch 2] step 44/44: loss=0.8304 
[epoch 2] train_loss(avg per step)=1.6607 lambda[min,max]=[0.508709,1.000000]
[epoch 2] val_loss=1.4907 qwk=('0.2511', '0.1949', '0.1196') averageQWK=0.1885 macroEMD=0.3561 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    1    0
     0    8    2    5    0
     0   10   10   58    0
     0   11   14  137    0
     0    7    3   54    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0    7    9    0
     0    0   10   56    0
     0    0   28  177    0
     0    0    4   26    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    0   29    0    0
     0    0  103    8    0
     0    0  149   32    0
     0    0    1    0    0
[epoch 3] step 2/44: loss=0.7874 
[epoch 3] step 4/44: loss=0.7587 
[epoch 3] step 6/44: loss=0.7557 
[epoch 3] step 8/44: loss=0.7692 
[epoch 3] step 10/44: loss=0.7686 
[epoch 3] step 12/44: loss=0.7718 
[epoch 3] step 14/44: loss=0.7784 
[epoch 3] step 16/44: loss=0.7863 
[epoch 3] step 18/44: loss=0.7917 
[epoch 3] step 20/44: loss=0.7973 
[epoch 3] step 22/44: loss=0.8008 
[epoch 3] step 24/44: loss=0.8059 
[epoch 3] step 26/44: loss=0.8058 
[epoch 3] step 28/44: loss=0.8076 
[epoch 3] step 30/44: loss=0.8095 
[epoch 3] step 32/44: loss=0.8099 
[epoch 3] step 34/44: loss=0.8092 
[epoch 3] step 36/44: loss=0.8097 
[epoch 3] step 38/44: loss=0.8132 
[epoch 3] step 40/44: loss=0.8145 
[epoch 3] step 42/44: loss=0.8149 
[epoch 3] step 44/44: loss=0.8172 
[epoch 3] train_loss(avg per step)=1.6344 lambda[min,max]=[0.506201,1.000000]
[epoch 3] val_loss=1.6024 qwk=('0.0690', '0.1027', '0.1700') averageQWK=0.1139 macroEMD=0.3470 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   13    0    0
     0    1   72    5    0
     0    2  139   21    0
     0    1   59    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   16    0    0
     0    0   54   12    0
     0    0  160   45    0
     0    0   19   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   12   17    0    0
     0    8  102    1    0
     0    4  170    7    0
     0    0    1    0    0
[epoch 4] step 2/44: loss=0.8508 
[epoch 4] step 4/44: loss=0.8476 
[epoch 4] step 6/44: loss=0.8444 
[epoch 4] step 8/44: loss=0.8384 
[epoch 4] step 10/44: loss=0.8404 
[epoch 4] step 12/44: loss=0.8425 
[epoch 4] step 14/44: loss=0.8453 
[epoch 4] step 16/44: loss=0.8416 
[epoch 4] step 18/44: loss=0.8326 
[epoch 4] step 20/44: loss=0.8270 
[epoch 4] step 22/44: loss=0.8277 
[epoch 4] step 24/44: loss=0.8293 
[epoch 4] step 26/44: loss=0.8297 
[epoch 4] step 28/44: loss=0.8267 
[epoch 4] step 30/44: loss=0.8221 
[epoch 4] step 32/44: loss=0.8216 
[epoch 4] step 34/44: loss=0.8161 
[epoch 4] step 36/44: loss=0.8147 
[epoch 4] step 38/44: loss=0.8120 
[epoch 4] step 40/44: loss=0.8097 
[epoch 4] step 42/44: loss=0.8078 
[epoch 4] step 44/44: loss=0.8080 
[epoch 4] train_loss(avg per step)=1.6159 lambda[min,max]=[0.500493,1.000000]
[epoch 4] val_loss=1.4578 qwk=('0.2071', '0.3118', '0.3390') averageQWK=0.2860 macroEMD=0.3196 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   11    2    0
     0    5   40   33    0
     0    2   58  102    0
     0    3   27   34    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   13    3    0
     0    0   31   35    0
     0    0   56  149    0
     0    0    6   24    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   17    0    0
     0    8   83   20    0
     0    3  119   59    0
     0    0    0    1    0
[epoch 5] step 2/44: loss=0.8331 
[epoch 5] step 4/44: loss=0.8570 
[epoch 5] step 6/44: loss=0.8613 
[epoch 5] step 8/44: loss=0.8552 
[epoch 5] step 10/44: loss=0.8506 
[epoch 5] step 12/44: loss=0.8510 
[epoch 5] step 14/44: loss=0.8429 
[epoch 5] step 16/44: loss=0.8394 
[epoch 5] step 18/44: loss=0.8384 
[epoch 5] step 20/44: loss=0.8385 
[epoch 5] step 22/44: loss=0.8372 
[epoch 5] step 24/44: loss=0.8373 
[epoch 5] step 26/44: loss=0.8416 
[epoch 5] step 28/44: loss=0.8411 
[epoch 5] step 30/44: loss=0.8407 
[epoch 5] step 32/44: loss=0.8380 
[epoch 5] step 34/44: loss=0.8376 
[epoch 5] step 36/44: loss=0.8345 
[epoch 5] step 38/44: loss=0.8293 
[epoch 5] step 40/44: loss=0.8276 
[epoch 5] step 42/44: loss=0.8235 
[epoch 5] step 44/44: loss=0.8204 
[epoch 5] train_loss(avg per step)=1.6407 lambda[min,max]=[0.500027,1.000000]
[epoch 5] val_loss=1.5946 qwk=('0.1571', '0.1605', '0.3724') averageQWK=0.2300 macroEMD=0.3281 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   12    0    0
     0    4   59   15    0
     0    2  106   54    0
     0    3   41   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   16    0    0
     0    1   52   13    0
     0    0  149   56    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20    9    0    0
     0   19   76   16    0
     0   12  109   60    0
     0    0    0    1    0
[epoch 6] step 2/44: loss=0.7281 
[epoch 6] step 4/44: loss=0.7567 
[epoch 6] step 6/44: loss=0.7624 
[epoch 6] step 8/44: loss=0.7638 
[epoch 6] step 10/44: loss=0.7708 
[epoch 6] step 12/44: loss=0.7736 
[epoch 6] step 14/44: loss=0.7723 
[epoch 6] step 16/44: loss=0.7713 
[epoch 6] step 18/44: loss=0.7795 
[epoch 6] step 20/44: loss=0.7870 
[epoch 6] step 22/44: loss=0.7917 
[epoch 6] step 24/44: loss=0.7976 
[epoch 6] step 26/44: loss=0.8010 
[epoch 6] step 28/44: loss=0.8033 
[epoch 6] step 30/44: loss=0.8055 
[epoch 6] step 32/44: loss=0.8074 
[epoch 6] step 34/44: loss=0.8039 
[epoch 6] step 36/44: loss=0.8035 
[epoch 6] step 38/44: loss=0.8003 
[epoch 6] step 40/44: loss=0.7987 
[epoch 6] step 42/44: loss=0.7978 
[epoch 6] step 44/44: loss=0.7958 
[epoch 6] train_loss(avg per step)=1.5917 lambda[min,max]=[0.500002,1.000000]
[epoch 6] val_loss=1.6162 qwk=('0.1840', '0.2788', '0.3340') averageQWK=0.2656 macroEMD=0.3288 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    7    0    0
     0   12   60    6    0
     0   10  109   43    0
     0    5   43   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    8    8    0    0
     0    9   48    9    0
     0   12  130   63    0
     0    1   17   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0   10   98    3    0
     0    3  141   37    0
     0    0    0    1    0
[epoch 7] step 2/44: loss=0.7641 
[epoch 7] step 4/44: loss=0.7809 
[epoch 7] step 6/44: loss=0.7678 
[epoch 7] step 8/44: loss=0.7751 
[epoch 7] step 10/44: loss=0.7880 
[epoch 7] step 12/44: loss=0.7916 
[epoch 7] step 14/44: loss=0.7873 
[epoch 7] step 16/44: loss=0.7874 
[epoch 7] step 18/44: loss=0.7841 
[epoch 7] step 20/44: loss=0.7908 
[epoch 7] step 22/44: loss=0.7905 
[epoch 7] step 24/44: loss=0.7888 
[epoch 7] step 26/44: loss=0.7906 
[epoch 7] step 28/44: loss=0.7897 
[epoch 7] step 30/44: loss=0.7929 
[epoch 7] step 32/44: loss=0.7913 
[epoch 7] step 34/44: loss=0.7899 
[epoch 7] step 36/44: loss=0.7888 
[epoch 7] step 38/44: loss=0.7884 
[epoch 7] step 40/44: loss=0.7876 
[epoch 7] step 42/44: loss=0.7904 
[epoch 7] step 44/44: loss=0.7900 
[epoch 7] train_loss(avg per step)=1.5800 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.4964 qwk=('0.1967', '0.2263', '0.3091') averageQWK=0.2440 macroEMD=0.3078 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    0   14    1    0
     0    0   54   24    0
     0    0   80   82    0
     0    0   32   32    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   13    3    0
     0    0   39   27    0
     0    0   89  116    0
     0    0    9   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   10   19    0    0
     0    3  101    7    0
     0    2  131   48    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=0.7779 
[epoch 8] step 4/44: loss=0.7819 
[epoch 8] step 6/44: loss=0.7852 
[epoch 8] step 8/44: loss=0.7802 
[epoch 8] step 10/44: loss=0.7771 
[epoch 8] step 12/44: loss=0.7756 
[epoch 8] step 14/44: loss=0.7659 
[epoch 8] step 16/44: loss=0.7657 
[epoch 8] step 18/44: loss=0.7630 
[epoch 8] step 20/44: loss=0.7648 
[epoch 8] step 22/44: loss=0.7656 
[epoch 8] step 24/44: loss=0.7619 
[epoch 8] step 26/44: loss=0.7609 
[epoch 8] step 28/44: loss=0.7633 
[epoch 8] step 30/44: loss=0.7649 
[epoch 8] step 32/44: loss=0.7657 
[epoch 8] step 34/44: loss=0.7640 
[epoch 8] step 36/44: loss=0.7640 
[epoch 8] step 38/44: loss=0.7667 
[epoch 8] step 40/44: loss=0.7682 
[epoch 8] step 42/44: loss=0.7700 
[epoch 8] step 44/44: loss=0.7684 
[epoch 8] train_loss(avg per step)=1.5368 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.4819 qwk=('0.2946', '0.3937', '0.4326') averageQWK=0.3736 macroEMD=0.3042 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    2   13    0    0
     0    1   54   22    1
     0    1   59   99    3
     0    1   24   38    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    5    9    2    0
     0    7   35   24    0
     0    2   72  131    0
     0    1    7   22    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   17    0    0
     0    7   92   12    0
     0    3  102   76    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=0.7681 
[epoch 9] step 4/44: loss=0.7627 
[epoch 9] step 6/44: loss=0.7559 
[epoch 9] step 8/44: loss=0.7622 
[epoch 9] step 10/44: loss=0.7606 
[epoch 9] step 12/44: loss=0.7461 
[epoch 9] step 14/44: loss=0.7448 
[epoch 9] step 16/44: loss=0.7429 
[epoch 9] step 18/44: loss=0.7433 
[epoch 9] step 20/44: loss=0.7483 
[epoch 9] step 22/44: loss=0.7505 
[epoch 9] step 24/44: loss=0.7548 
[epoch 9] step 26/44: loss=0.7587 
[epoch 9] step 28/44: loss=0.7600 
[epoch 9] step 30/44: loss=0.7596 
[epoch 9] step 32/44: loss=0.7593 
[epoch 9] step 34/44: loss=0.7606 
[epoch 9] step 36/44: loss=0.7584 
[epoch 9] step 38/44: loss=0.7574 
[epoch 9] step 40/44: loss=0.7576 
[epoch 9] step 42/44: loss=0.7580 
[epoch 9] step 44/44: loss=0.7583 
[epoch 9] train_loss(avg per step)=1.5166 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.5524 qwk=('0.2603', '0.2381', '0.3360') averageQWK=0.2781 macroEMD=0.3094 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    3   48   25    2
     0    1   60   98    3
     0    1   27   35    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    1   15    0    0
     0    5   43   18    0
     0    1  125   79    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0    6  101    4    0
     0    1  143   37    0
     0    0    1    0    0
[epoch 10] step 2/44: loss=0.7744 
[epoch 10] step 4/44: loss=0.7667 
[epoch 10] step 6/44: loss=0.7605 
[epoch 10] step 8/44: loss=0.7520 
[epoch 10] step 10/44: loss=0.7516 
[epoch 10] step 12/44: loss=0.7520 
[epoch 10] step 14/44: loss=0.7516 
[epoch 10] step 16/44: loss=0.7505 
[epoch 10] step 18/44: loss=0.7483 
[epoch 10] step 20/44: loss=0.7525 
[epoch 10] step 22/44: loss=0.7551 
[epoch 10] step 24/44: loss=0.7529 
[epoch 10] step 26/44: loss=0.7570 
[epoch 10] step 28/44: loss=0.7568 
[epoch 10] step 30/44: loss=0.7558 
[epoch 10] step 32/44: loss=0.7537 
[epoch 10] step 34/44: loss=0.7548 
[epoch 10] step 36/44: loss=0.7545 
[epoch 10] step 38/44: loss=0.7556 
[epoch 10] step 40/44: loss=0.7570 
[epoch 10] step 42/44: loss=0.7579 
[epoch 10] step 44/44: loss=0.7587 
[epoch 10] train_loss(avg per step)=1.5173 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.6016 qwk=('0.2589', '0.2917', '0.2818') averageQWK=0.2775 macroEMD=0.3103 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    7    0    0
     0   13   47   18    0
     0    4   90   68    0
     0    3   34   26    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    9    0    0
     0    9   46   11    0
     0    6  128   71    0
     0    1   16   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0    9   98    4    0
     0    4  148   29    0
     0    0    1    0    0
[epoch 11] step 2/44: loss=0.7574 
[epoch 11] step 4/44: loss=0.7510 
[epoch 11] step 6/44: loss=0.7501 
[epoch 11] step 8/44: loss=0.7411 
[epoch 11] step 10/44: loss=0.7345 
[epoch 11] step 12/44: loss=0.7295 
[epoch 11] step 14/44: loss=0.7238 
[epoch 11] step 16/44: loss=0.7256 
[epoch 11] step 18/44: loss=0.7312 
[epoch 11] step 20/44: loss=0.7365 
[epoch 11] step 22/44: loss=0.7417 
[epoch 11] step 24/44: loss=0.7415 
[epoch 11] step 26/44: loss=0.7455 
[epoch 11] step 28/44: loss=0.7483 
[epoch 11] step 30/44: loss=0.7514 
[epoch 11] step 32/44: loss=0.7530 
[epoch 11] step 34/44: loss=0.7544 
[epoch 11] step 36/44: loss=0.7574 
[epoch 11] step 38/44: loss=0.7587 
[epoch 11] step 40/44: loss=0.7572 
[epoch 11] step 42/44: loss=0.7542 
[epoch 11] step 44/44: loss=0.7505 
[epoch 11] train_loss(avg per step)=1.5009 lambda[min,max]=[0.430979,1.000000]
[epoch 11] val_loss=1.5556 qwk=('0.1989', '0.2798', '0.3656') averageQWK=0.2814 macroEMD=0.3076 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   11    0    0
     0    5   60   13    0
     0    1  103   57    1
     0    1   43   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    2   12    2    0
     0    5   45   16    0
     0    1  110   94    0
     0    0   13   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   13    0    0
     0   15   89    7    0
     0    5  126   50    0
     0    0    1    0    0
[epoch 12] step 2/44: loss=0.6865 
[epoch 12] step 4/44: loss=0.6884 
[epoch 12] step 6/44: loss=0.6928 
[epoch 12] step 8/44: loss=0.6901 
[epoch 12] step 10/44: loss=0.7039 
[epoch 12] step 12/44: loss=0.7175 
[epoch 12] step 14/44: loss=0.7186 
[epoch 12] step 16/44: loss=0.7220 
[epoch 12] step 18/44: loss=0.7238 
[epoch 12] step 20/44: loss=0.7205 
[epoch 12] step 22/44: loss=0.7215 
[epoch 12] step 24/44: loss=0.7245 
[epoch 12] step 26/44: loss=0.7246 
[epoch 12] step 28/44: loss=0.7279 
[epoch 12] step 30/44: loss=0.7322 
[epoch 12] step 32/44: loss=0.7312 
[epoch 12] step 34/44: loss=0.7300 
[epoch 12] step 36/44: loss=0.7287 
[epoch 12] step 38/44: loss=0.7294 
[epoch 12] step 40/44: loss=0.7275 
[epoch 12] step 42/44: loss=0.7267 
[epoch 12] step 44/44: loss=0.7279 
[epoch 12] train_loss(avg per step)=1.4557 lambda[min,max]=[0.452889,1.000000]
[epoch 12] val_loss=1.6781 qwk=('0.1829', '0.2341', '0.2649') averageQWK=0.2273 macroEMD=0.3109 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    9    6    0    0
     0   16   55    5    2
     0    8  119   28    7
     0    2   51   10    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    9    7    0    0
     0   15   46    5    0
     0   15  143   47    0
     0    2   20    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   19   10    0    0
     0   35   73    3    0
     0   19  138   24    0
     0    0    1    0    0
[epoch 13] step 2/44: loss=0.6806 
[epoch 13] step 4/44: loss=0.6942 
[epoch 13] step 6/44: loss=0.7037 
[epoch 13] step 8/44: loss=0.7156 
[epoch 13] step 10/44: loss=0.7197 
[epoch 13] step 12/44: loss=0.7211 
[epoch 13] step 14/44: loss=0.7158 
[epoch 13] step 16/44: loss=0.7062 
[epoch 13] step 18/44: loss=0.7039 
[epoch 13] step 20/44: loss=0.7055 
[epoch 13] step 22/44: loss=0.7067 
[epoch 13] step 24/44: loss=0.7098 
[epoch 13] step 26/44: loss=0.7123 
[epoch 13] step 28/44: loss=0.7128 
[epoch 13] step 30/44: loss=0.7156 
[epoch 13] step 32/44: loss=0.7167 
[epoch 13] step 34/44: loss=0.7197 
[epoch 13] step 36/44: loss=0.7222 
[epoch 13] step 38/44: loss=0.7215 
[epoch 13] step 40/44: loss=0.7215 
[epoch 13] step 42/44: loss=0.7202 
[epoch 13] step 44/44: loss=0.7210 
[epoch 13] train_loss(avg per step)=1.4420 lambda[min,max]=[0.437792,1.000000]
[epoch 13] val_loss=1.5794 qwk=('0.1948', '0.2291', '0.3148') averageQWK=0.2462 macroEMD=0.3134 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   12    0    0
     0    7   56   13    2
     0    1  100   53    8
     0    1   41   19    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    3   13    0    0
     0    7   49   10    0
     0    2  139   63    1
     0    1   17   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   12    0    0
     0   14   93    4    0
     0    5  145   31    0
     0    0    1    0    0
[epoch 14] step 2/44: loss=0.7068 
[epoch 14] step 4/44: loss=0.7017 
[epoch 14] step 6/44: loss=0.7126 
[epoch 14] step 8/44: loss=0.7051 
[epoch 14] step 10/44: loss=0.6930 
[epoch 14] step 12/44: loss=0.6922 
[epoch 14] step 14/44: loss=0.6866 
[epoch 14] step 16/44: loss=0.6846 
[epoch 14] step 18/44: loss=0.6876 
[epoch 14] step 20/44: loss=0.6889 
[epoch 14] step 22/44: loss=0.6898 
[epoch 14] step 24/44: loss=0.6930 
[epoch 14] step 26/44: loss=0.6935 
[epoch 14] step 28/44: loss=0.6928 
[epoch 14] step 30/44: loss=0.6947 
[epoch 14] step 32/44: loss=0.6960 
[epoch 14] step 34/44: loss=0.6972 
[epoch 14] step 36/44: loss=0.7015 
[epoch 14] step 38/44: loss=0.7037 
[epoch 14] step 40/44: loss=0.7057 
[epoch 14] step 42/44: loss=0.7063 
[epoch 14] step 44/44: loss=0.7063 
[epoch 14] train_loss(avg per step)=1.4126 lambda[min,max]=[0.422616,1.000000]
[epoch 14] val_loss=1.6164 qwk=('0.1910', '0.2064', '0.2775') averageQWK=0.2250 macroEMD=0.3174 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4   10    1    0
     0    9   52   16    1
     0    2   99   56    5
     0    0   42   21    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    3   13    0    0
     0    6   54    6    0
     0    1  146   57    1
     0    0   23    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   11    0    0
     0   34   73    4    0
     0   19  130   32    0
     0    0    1    0    0
[epoch 15] step 2/44: loss=0.7204 
[epoch 15] step 4/44: loss=0.7138 
[epoch 15] step 6/44: loss=0.7050 
[epoch 15] step 8/44: loss=0.7012 
[epoch 15] step 10/44: loss=0.6972 
[epoch 15] step 12/44: loss=0.6941 
[epoch 15] step 14/44: loss=0.6889 
[epoch 15] step 16/44: loss=0.6935 
[epoch 15] step 18/44: loss=0.6886 
[epoch 15] step 20/44: loss=0.6862 
[epoch 15] step 22/44: loss=0.6864 
[epoch 15] step 24/44: loss=0.6903 
[epoch 15] step 26/44: loss=0.6913 
[epoch 15] step 28/44: loss=0.6960 
[epoch 15] step 30/44: loss=0.6989 
[epoch 15] step 32/44: loss=0.6974 
[epoch 15] step 34/44: loss=0.6974 
[epoch 15] step 36/44: loss=0.6982 
[epoch 15] step 38/44: loss=0.6963 
[epoch 15] step 40/44: loss=0.6929 
[epoch 15] step 42/44: loss=0.6904 
[epoch 15] step 44/44: loss=0.6874 
[epoch 15] train_loss(avg per step)=1.3747 lambda[min,max]=[0.391643,1.000000]
[epoch 15] val_loss=1.5090 qwk=('0.2704', '0.2881', '0.3748') averageQWK=0.3111 macroEMD=0.3060 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4   10    1    0
     0    7   46   25    0
     0    1   75   82    4
     0    1   27   35    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    3   10    3    0
     0    5   34   27    0
     0    1   91  113    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   12    0    0
     0   22   82    7    0
     0    9  119   53    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=0.6939 
[epoch 16] step 4/44: loss=0.6818 
[epoch 16] step 6/44: loss=0.6803 
[epoch 16] step 8/44: loss=0.6821 
[epoch 16] step 10/44: loss=0.6817 
[epoch 16] step 12/44: loss=0.6819 
[epoch 16] step 14/44: loss=0.6846 
[epoch 16] step 16/44: loss=0.6831 
[epoch 16] step 18/44: loss=0.6816 
[epoch 16] step 20/44: loss=0.6773 
[epoch 16] step 22/44: loss=0.6758 
[epoch 16] step 24/44: loss=0.6754 
[epoch 16] step 26/44: loss=0.6764 
[epoch 16] step 28/44: loss=0.6790 
[epoch 16] step 30/44: loss=0.6807 
[epoch 16] step 32/44: loss=0.6825 
[epoch 16] step 34/44: loss=0.6811 
[epoch 16] step 36/44: loss=0.6796 
[epoch 16] step 38/44: loss=0.6783 
[epoch 16] step 40/44: loss=0.6775 
[epoch 16] step 42/44: loss=0.6755 
[epoch 16] step 44/44: loss=0.6736 
[epoch 16] train_loss(avg per step)=1.3471 lambda[min,max]=[0.378336,1.000000]
[epoch 16] val_loss=1.5896 qwk=('0.1763', '0.2279', '0.2986') averageQWK=0.2343 macroEMD=0.3156 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   11    0    0
     0   13   51   14    0
     0    3  112   46    1
     0    4   41   18    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    8    8    0    0
     0    9   52    5    0
     0    5  143   56    1
     0    1   23    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   15   14    0    0
     0   10   97    4    0
     0    4  142   35    0
     0    0    1    0    0
[epoch 17] step 2/44: loss=0.6878 
[epoch 17] step 4/44: loss=0.6979 
[epoch 17] step 6/44: loss=0.7193 
[epoch 17] step 8/44: loss=0.7125 
[epoch 17] step 10/44: loss=0.7047 
[epoch 17] step 12/44: loss=0.6958 
[epoch 17] step 14/44: loss=0.6917 
[epoch 17] step 16/44: loss=0.6877 
[epoch 17] step 18/44: loss=0.6871 
[epoch 17] step 20/44: loss=0.6845 
[epoch 17] step 22/44: loss=0.6824 
[epoch 17] step 24/44: loss=0.6765 
[epoch 17] step 26/44: loss=0.6728 
[epoch 17] step 28/44: loss=0.6722 
[epoch 17] step 30/44: loss=0.6698 
[epoch 17] step 32/44: loss=0.6687 
[epoch 17] step 34/44: loss=0.6689 
[epoch 17] step 36/44: loss=0.6697 
[epoch 17] step 38/44: loss=0.6699 
[epoch 17] step 40/44: loss=0.6716 
[epoch 17] step 42/44: loss=0.6732 
[epoch 17] step 44/44: loss=0.6726 
[epoch 17] train_loss(avg per step)=1.3452 lambda[min,max]=[0.398788,1.000000]
[epoch 17] val_loss=1.5773 qwk=('0.2485', '0.2524', '0.3004') averageQWK=0.2671 macroEMD=0.3139 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4   11    0    0
     0   11   49   18    0
     0    3   80   73    6
     0    3   31   29    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    5   11    0    0
     0    6   51    9    0
     0    1  139   64    1
     0    0   19   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   19   89    3    0
     0    7  142   32    0
     0    0    1    0    0
[epoch 18] step 2/44: loss=0.6526 
[epoch 18] step 4/44: loss=0.6607 
[epoch 18] step 6/44: loss=0.6582 
[epoch 18] step 8/44: loss=0.6610 
[epoch 18] step 10/44: loss=0.6646 
[epoch 18] step 12/44: loss=0.6665 
[epoch 18] step 14/44: loss=0.6620 
[epoch 18] step 16/44: loss=0.6600 
[epoch 18] step 18/44: loss=0.6590 
[epoch 18] step 20/44: loss=0.6551 
[epoch 18] step 22/44: loss=0.6498 
[epoch 18] step 24/44: loss=0.6507 
[epoch 18] step 26/44: loss=0.6491 
[epoch 18] step 28/44: loss=0.6489 
[epoch 18] step 30/44: loss=0.6502 
[epoch 18] step 32/44: loss=0.6520 
[epoch 18] step 34/44: loss=0.6527 
[epoch 18] step 36/44: loss=0.6529 
[epoch 18] step 38/44: loss=0.6522 
[epoch 18] step 40/44: loss=0.6504 
[epoch 18] step 42/44: loss=0.6512 
[epoch 18] step 44/44: loss=0.6507 
[epoch 18] train_loss(avg per step)=1.3013 lambda[min,max]=[0.385571,1.000000]
[epoch 18] val_loss=1.4909 qwk=('0.3346', '0.3121', '0.4420') averageQWK=0.3629 macroEMD=0.3036 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     1    3   10    1    0
     0    8   43   26    1
     0    2   49  108    3
     0    2   19   42    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    3   13    0    0
     0    5   45   16    0
     0    1  112   91    1
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   11    0    0
     0   15   89    7    0
     0    3  117   61    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=0.6599 
[epoch 19] step 4/44: loss=0.6518 
[epoch 19] step 6/44: loss=0.6536 
[epoch 19] step 8/44: loss=0.6569 
[epoch 19] step 10/44: loss=0.6560 
[epoch 19] step 12/44: loss=0.6612 
[epoch 19] step 14/44: loss=0.6629 
[epoch 19] step 16/44: loss=0.6647 
[epoch 19] step 18/44: loss=0.6602 
[epoch 19] step 20/44: loss=0.6548 
[epoch 19] step 22/44: loss=0.6520 
[epoch 19] step 24/44: loss=0.6484 
[epoch 19] step 26/44: loss=0.6494 
[epoch 19] step 28/44: loss=0.6456 
[epoch 19] step 30/44: loss=0.6434 
[epoch 19] step 32/44: loss=0.6419 
[epoch 19] step 34/44: loss=0.6419 
[epoch 19] step 36/44: loss=0.6406 
[epoch 19] step 38/44: loss=0.6382 
[epoch 19] step 40/44: loss=0.6384 
[epoch 19] step 42/44: loss=0.6386 
[epoch 19] step 44/44: loss=0.6382 
[epoch 19] train_loss(avg per step)=1.2764 lambda[min,max]=[0.389422,1.000000]
[epoch 19] val_loss=1.5304 qwk=('0.2854', '0.2799', '0.3676') averageQWK=0.3110 macroEMD=0.3107 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0   11   44   23    0
     0    2   82   78    0
     0    2   26   35    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    8    8    0    0
     0   12   46    8    0
     0    3  142   60    0
     0    1   18   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   13   16    0    0
     0    8   98    5    0
     0    1  129   51    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=0.6559 
[epoch 20] step 4/44: loss=0.6646 
[epoch 20] step 6/44: loss=0.6642 
[epoch 20] step 8/44: loss=0.6583 
[epoch 20] step 10/44: loss=0.6518 
[epoch 20] step 12/44: loss=0.6453 
[epoch 20] step 14/44: loss=0.6428 
[epoch 20] step 16/44: loss=0.6401 
[epoch 20] step 18/44: loss=0.6378 
[epoch 20] step 20/44: loss=0.6391 
[epoch 20] step 22/44: loss=0.6393 
[epoch 20] step 24/44: loss=0.6398 
[epoch 20] step 26/44: loss=0.6393 
[epoch 20] step 28/44: loss=0.6363 
[epoch 20] step 30/44: loss=0.6362 
[epoch 20] step 32/44: loss=0.6353 
[epoch 20] step 34/44: loss=0.6336 
[epoch 20] step 36/44: loss=0.6337 
[epoch 20] step 38/44: loss=0.6339 
[epoch 20] step 40/44: loss=0.6346 
[epoch 20] step 42/44: loss=0.6346 
[epoch 20] step 44/44: loss=0.6361 
[epoch 20] train_loss(avg per step)=1.2721 lambda[min,max]=[0.392156,1.000000]
[epoch 20] val_loss=1.5804 qwk=('0.1706', '0.2693', '0.3236') averageQWK=0.2545 macroEMD=0.3111 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    7    7    1    0
     0   11   48   19    0
     0    2  103   52    5
     0    2   45   16    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    7    9    0    0
     0    8   50    8    0
     0    3  136   66    0
     0    1   17   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   11    0    0
     0   21   86    4    0
     0    8  139   34    0
     0    0    1    0    0
[epoch 21] step 2/44: loss=0.6608 
[epoch 21] step 4/44: loss=0.6446 
[epoch 21] step 6/44: loss=0.6376 
[epoch 21] step 8/44: loss=0.6313 
[epoch 21] step 10/44: loss=0.6324 
[epoch 21] step 12/44: loss=0.6283 
[epoch 21] step 14/44: loss=0.6272 
[epoch 21] step 16/44: loss=0.6285 
[epoch 21] step 18/44: loss=0.6243 
[epoch 21] step 20/44: loss=0.6237 
[epoch 21] step 22/44: loss=0.6235 
[epoch 21] step 24/44: loss=0.6226 
[epoch 21] step 26/44: loss=0.6183 
[epoch 21] step 28/44: loss=0.6137 
[epoch 21] step 30/44: loss=0.6123 
[epoch 21] step 32/44: loss=0.6141 
[epoch 21] step 34/44: loss=0.6149 
[epoch 21] step 36/44: loss=0.6172 
[epoch 21] step 38/44: loss=0.6189 
[epoch 21] step 40/44: loss=0.6185 
[epoch 21] step 42/44: loss=0.6207 
[epoch 21] step 44/44: loss=0.6227 
[epoch 21] train_loss(avg per step)=1.2453 lambda[min,max]=[0.350662,1.000000]
[epoch 21] val_loss=1.5173 qwk=('0.1314', '0.2661', '0.3917') averageQWK=0.2630 macroEMD=0.3098 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    4   57   16    1
     0    1  110   47    4
     0    1   45   17    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    3   13    0    0
     0    6   48   12    0
     0    2  122   80    1
     0    0   17   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   13    0    0
     0   17   89    5    0
     0    6  121   54    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=0.6407 
[epoch 22] step 4/44: loss=0.6327 
[epoch 22] step 6/44: loss=0.6267 
[epoch 22] step 8/44: loss=0.6220 
[epoch 22] step 10/44: loss=0.6200 
[epoch 22] step 12/44: loss=0.6162 
[epoch 22] step 14/44: loss=0.6111 
[epoch 22] step 16/44: loss=0.6049 
[epoch 22] step 18/44: loss=0.6041 
[epoch 22] step 20/44: loss=0.6027 
[epoch 22] step 22/44: loss=0.6046 
[epoch 22] step 24/44: loss=0.6029 
[epoch 22] step 26/44: loss=0.6034 
[epoch 22] step 28/44: loss=0.6033 
[epoch 22] step 30/44: loss=0.6084 
[epoch 22] step 32/44: loss=0.6070 
[epoch 22] step 34/44: loss=0.6064 
[epoch 22] step 36/44: loss=0.6076 
[epoch 22] step 38/44: loss=0.6082 
[epoch 22] step 40/44: loss=0.6100 
[epoch 22] step 42/44: loss=0.6086 
[epoch 22] step 44/44: loss=0.6101 
[epoch 22] train_loss(avg per step)=1.2201 lambda[min,max]=[0.375735,1.000000]
[epoch 22] val_loss=1.4969 qwk=('0.1813', '0.3089', '0.3231') averageQWK=0.2711 macroEMD=0.3139 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4   10    1    0
     0    6   51   21    0
     0    2   96   62    2
     0    0   41   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    8    8    0    0
     0    8   39   19    0
     0    2  112   91    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   10   19    0    0
     0    6  100    5    0
     0    1  133   47    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=0.6458 
[epoch 23] step 4/44: loss=0.6189 
[epoch 23] step 6/44: loss=0.6071 
[epoch 23] step 8/44: loss=0.6084 
[epoch 23] step 10/44: loss=0.6135 
[epoch 23] step 12/44: loss=0.6126 
[epoch 23] step 14/44: loss=0.6112 
[epoch 23] step 16/44: loss=0.6070 
[epoch 23] step 18/44: loss=0.6060 
[epoch 23] step 20/44: loss=0.6022 
[epoch 23] step 22/44: loss=0.6023 
[epoch 23] step 24/44: loss=0.6020 
[epoch 23] step 26/44: loss=0.6024 
[epoch 23] step 28/44: loss=0.6041 
[epoch 23] step 30/44: loss=0.6046 
[epoch 23] step 32/44: loss=0.6053 
[epoch 23] step 34/44: loss=0.6047 
[epoch 23] step 36/44: loss=0.6005 
[epoch 23] step 38/44: loss=0.6015 
[epoch 23] step 40/44: loss=0.6046 
[epoch 23] step 42/44: loss=0.6058 
[epoch 23] step 44/44: loss=0.6063 
[epoch 23] train_loss(avg per step)=1.2126 lambda[min,max]=[0.385444,1.000000]
[epoch 23] val_loss=1.5105 qwk=('0.0965', '0.2895', '0.3709') averageQWK=0.2523 macroEMD=0.3140 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    3   57   17    1
     0    0  114   41    7
     0    0   53    9    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    5   11    0    0
     0    7   48   11    0
     0    2  121   81    1
     0    0   17   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   14   15    0    0
     0   13   92    6    0
     0    3  125   53    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=0.6362 
[epoch 24] step 4/44: loss=0.6150 
[epoch 24] step 6/44: loss=0.6031 
[epoch 24] step 8/44: loss=0.6053 
[epoch 24] step 10/44: loss=0.6125 
[epoch 24] step 12/44: loss=0.6082 
[epoch 24] step 14/44: loss=0.6044 
[epoch 24] step 16/44: loss=0.6029 
[epoch 24] step 18/44: loss=0.6030 
[epoch 24] step 20/44: loss=0.5999 
[epoch 24] step 22/44: loss=0.5991 
[epoch 24] step 24/44: loss=0.5962 
[epoch 24] step 26/44: loss=0.5932 
[epoch 24] step 28/44: loss=0.5915 
[epoch 24] step 30/44: loss=0.5922 
[epoch 24] step 32/44: loss=0.5951 
[epoch 24] step 34/44: loss=0.5956 
[epoch 24] step 36/44: loss=0.5943 
[epoch 24] step 38/44: loss=0.5946 
[epoch 24] step 40/44: loss=0.5949 
[epoch 24] step 42/44: loss=0.5971 
[epoch 24] step 44/44: loss=0.6001 
[epoch 24] train_loss(avg per step)=1.2003 lambda[min,max]=[0.383657,1.000000]
[epoch 24] val_loss=1.4900 qwk=('0.2342', '0.3258', '0.3738') averageQWK=0.3113 macroEMD=0.3055 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    7   49   22    0
     0    2   77   79    4
     0    1   34   26    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    4   12    0    0
     0    6   45   15    0
     0    2  109   94    0
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   10   96    5    0
     0    4  128   49    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=0.6323 
[epoch 25] step 4/44: loss=0.6239 
[epoch 25] step 6/44: loss=0.6246 
[epoch 25] step 8/44: loss=0.6080 
[epoch 25] step 10/44: loss=0.5915 
[epoch 25] step 12/44: loss=0.5799 
[epoch 25] step 14/44: loss=0.5801 
[epoch 25] step 16/44: loss=0.5756 
[epoch 25] step 18/44: loss=0.5775 
[epoch 25] step 20/44: loss=0.5766 
[epoch 25] step 22/44: loss=0.5784 
[epoch 25] step 24/44: loss=0.5799 
[epoch 25] step 26/44: loss=0.5789 
[epoch 25] step 28/44: loss=0.5799 
[epoch 25] step 30/44: loss=0.5811 
[epoch 25] step 32/44: loss=0.5833 
[epoch 25] step 34/44: loss=0.5863 
[epoch 25] step 36/44: loss=0.5888 
[epoch 25] step 38/44: loss=0.5895 
[epoch 25] step 40/44: loss=0.5896 
[epoch 25] step 42/44: loss=0.5892 
[epoch 25] step 44/44: loss=0.5881 
[epoch 25] train_loss(avg per step)=1.1762 lambda[min,max]=[0.388377,1.000000]
[epoch 25] val_loss=1.5172 qwk=('0.1361', '0.3096', '0.3256') averageQWK=0.2571 macroEMD=0.3222 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     1    3   56   18    0
     0    1  108   50    3
     0    0   48   14    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    7    9    0    0
     0    5   53    8    0
     0    2  126   77    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   16   13    0    0
     0   13   93    5    0
     0    4  137   40    0
     0    0    1    0    0
[epoch 26] step 2/44: loss=0.5826 
[epoch 26] step 4/44: loss=0.5572 
[epoch 26] step 6/44: loss=0.5650 
[epoch 26] step 8/44: loss=0.5712 
[epoch 26] step 10/44: loss=0.5809 
[epoch 26] step 12/44: loss=0.5875 
[epoch 26] step 14/44: loss=0.5885 
[epoch 26] step 16/44: loss=0.5890 
[epoch 26] step 18/44: loss=0.5874 
[epoch 26] step 20/44: loss=0.5904 
[epoch 26] step 22/44: loss=0.5903 
[epoch 26] step 24/44: loss=0.5886 
[epoch 26] step 26/44: loss=0.5873 
[epoch 26] step 28/44: loss=0.5843 
[epoch 26] step 30/44: loss=0.5861 
[epoch 26] step 32/44: loss=0.5864 
[epoch 26] step 34/44: loss=0.5859 
[epoch 26] step 36/44: loss=0.5845 
[epoch 26] step 38/44: loss=0.5859 
[epoch 26] step 40/44: loss=0.5862 
[epoch 26] step 42/44: loss=0.5849 
[epoch 26] step 44/44: loss=0.5850 
[epoch 26] train_loss(avg per step)=1.1699 lambda[min,max]=[0.381047,1.000000]
[epoch 26] val_loss=1.5029 qwk=('0.2059', '0.3215', '0.3883') averageQWK=0.3052 macroEMD=0.3129 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     1    3   10    1    0
     0    7   51   20    0
     0    2   90   68    2
     0    1   38   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    3    0    0
     0    5   11    0    0
     0    5   49   12    0
     0    2  114   89    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   15   91    5    0
     0    4  125   52    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=0.5852 
[epoch 27] step 4/44: loss=0.5910 
[epoch 27] step 6/44: loss=0.5874 
[epoch 27] step 8/44: loss=0.5765 
[epoch 27] step 10/44: loss=0.5808 
[epoch 27] step 12/44: loss=0.5827 
[epoch 27] step 14/44: loss=0.5866 
[epoch 27] step 16/44: loss=0.5856 
[epoch 27] step 18/44: loss=0.5803 
[epoch 27] step 20/44: loss=0.5779 
[epoch 27] step 22/44: loss=0.5772 
[epoch 27] step 24/44: loss=0.5765 
[epoch 27] step 26/44: loss=0.5765 
[epoch 27] step 28/44: loss=0.5753 
[epoch 27] step 30/44: loss=0.5727 
[epoch 27] step 32/44: loss=0.5714 
[epoch 27] step 34/44: loss=0.5739 
[epoch 27] step 36/44: loss=0.5753 
[epoch 27] step 38/44: loss=0.5764 
[epoch 27] step 40/44: loss=0.5764 
[epoch 27] step 42/44: loss=0.5766 
[epoch 27] step 44/44: loss=0.5788 
[epoch 27] train_loss(avg per step)=1.1575 lambda[min,max]=[0.363425,1.000000]
[epoch 27] val_loss=1.5016 qwk=('0.2043', '0.3128', '0.3609') averageQWK=0.2927 macroEMD=0.3147 tailR0=('0.0234', '0.0833', '0.0000') tailR0avg=0.0356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    6   49   22    1
     0    2   83   71    6
     0    1   36   24    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    3    0    0
     0    4   12    0    0
     0    5   40   21    0
     0    1  108   94    2
     0    0   13   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   13   16    0    0
     0   11   95    5    0
     0    3  126   52    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=0.6225 
[epoch 28] step 4/44: loss=0.6033 
[epoch 28] step 6/44: loss=0.6030 
[epoch 28] step 8/44: loss=0.6056 
[epoch 28] step 10/44: loss=0.6005 
[epoch 28] step 12/44: loss=0.5896 
[epoch 28] step 14/44: loss=0.5847 
[epoch 28] step 16/44: loss=0.5812 
[epoch 28] step 18/44: loss=0.5845 
[epoch 28] step 20/44: loss=0.5782 
[epoch 28] step 22/44: loss=0.5755 
[epoch 28] step 24/44: loss=0.5751 
[epoch 28] step 26/44: loss=0.5758 
[epoch 28] step 28/44: loss=0.5749 
[epoch 28] step 30/44: loss=0.5747 
[epoch 28] step 32/44: loss=0.5762 
[epoch 28] step 34/44: loss=0.5757 
[epoch 28] step 36/44: loss=0.5759 
[epoch 28] step 38/44: loss=0.5785 
[epoch 28] step 40/44: loss=0.5791 
[epoch 28] step 42/44: loss=0.5789 
[epoch 28] step 44/44: loss=0.5797 
[epoch 28] train_loss(avg per step)=1.1595 lambda[min,max]=[0.364012,1.000000]
[epoch 28] val_loss=1.5518 qwk=('0.1917', '0.3429', '0.3612') averageQWK=0.2986 macroEMD=0.3134 tailR0=('0.0156', '0.0833', '0.0000') tailR0avg=0.0330
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5   10    0    0
     0   16   44   18    0
     0    4  101   51    6
     0    3   43   16    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    8    8    0    0
     0   11   48    7    0
     0    5  120   80    0
     0    2   14   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   16   13    0    0
     0   14   92    5    0
     0    6  125   50    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=0.5853 
[epoch 29] step 4/44: loss=0.5751 
[epoch 29] step 6/44: loss=0.5800 
[epoch 29] step 8/44: loss=0.5751 
[epoch 29] step 10/44: loss=0.5697 
[epoch 29] step 12/44: loss=0.5724 
[epoch 29] step 14/44: loss=0.5723 
[epoch 29] step 16/44: loss=0.5733 
[epoch 29] step 18/44: loss=0.5748 
[epoch 29] step 20/44: loss=0.5748 
[epoch 29] step 22/44: loss=0.5725 
[epoch 29] step 24/44: loss=0.5739 
[epoch 29] step 26/44: loss=0.5761 
[epoch 29] step 28/44: loss=0.5772 
[epoch 29] step 30/44: loss=0.5776 
[epoch 29] step 32/44: loss=0.5782 
[epoch 29] step 34/44: loss=0.5780 
[epoch 29] step 36/44: loss=0.5774 
[epoch 29] step 38/44: loss=0.5759 
[epoch 29] step 40/44: loss=0.5743 
[epoch 29] step 42/44: loss=0.5736 
[epoch 29] step 44/44: loss=0.5728 
[epoch 29] train_loss(avg per step)=1.1456 lambda[min,max]=[0.379667,1.000000]
[epoch 29] val_loss=1.5307 qwk=('0.1938', '0.3302', '0.3737') averageQWK=0.2993 macroEMD=0.3157 tailR0=('0.0156', '0.0833', '0.0000') tailR0avg=0.0330
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   10    2    0
     0   10   47   20    1
     0    4   85   68    5
     0    2   37   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    8    8    0    0
     0   11   42   13    0
     0    3  119   82    1
     0    2   13   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   16   13    0    0
     0   13   93    5    0
     0    5  124   52    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=0.5354 
[epoch 30] step 4/44: loss=0.5472 
[epoch 30] step 6/44: loss=0.5510 
[epoch 30] step 8/44: loss=0.5486 
[epoch 30] step 10/44: loss=0.5504 
[epoch 30] step 12/44: loss=0.5493 
[epoch 30] step 14/44: loss=0.5542 
[epoch 30] step 16/44: loss=0.5558 
[epoch 30] step 18/44: loss=0.5558 
[epoch 30] step 20/44: loss=0.5573 
[epoch 30] step 22/44: loss=0.5589 
[epoch 30] step 24/44: loss=0.5606 
[epoch 30] step 26/44: loss=0.5603 
[epoch 30] step 28/44: loss=0.5620 
[epoch 30] step 30/44: loss=0.5637 
[epoch 30] step 32/44: loss=0.5641 
[epoch 30] step 34/44: loss=0.5669 
[epoch 30] step 36/44: loss=0.5657 
[epoch 30] step 38/44: loss=0.5640 
[epoch 30] step 40/44: loss=0.5648 
[epoch 30] step 42/44: loss=0.5668 
[epoch 30] step 44/44: loss=0.5698 
[epoch 30] train_loss(avg per step)=1.1396 lambda[min,max]=[0.352272,1.000000]
[epoch 30] val_loss=1.4970 qwk=('0.2176', '0.3537', '0.3765') averageQWK=0.3159 macroEMD=0.3137 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    5   53   20    0
     0    1   87   72    2
     0    1   34   28    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    3    0    0
     0    5   11    0    0
     0    7   38   21    0
     0    2  101  102    0
     0    1    8   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   17   12    0    0
     0   17   89    5    0
     0    8  118   55    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=0.5594 
[epoch 31] step 4/44: loss=0.5669 
[epoch 31] step 6/44: loss=0.5742 
[epoch 31] step 8/44: loss=0.5691 
[epoch 31] step 10/44: loss=0.5683 
[epoch 31] step 12/44: loss=0.5671 
[epoch 31] step 14/44: loss=0.5698 
[epoch 31] step 16/44: loss=0.5658 
[epoch 31] step 18/44: loss=0.5641 
[epoch 31] step 20/44: loss=0.5662 
[epoch 31] step 22/44: loss=0.5673 
[epoch 31] step 24/44: loss=0.5712 
[epoch 31] step 26/44: loss=0.5691 
[epoch 31] step 28/44: loss=0.5712 
[epoch 31] step 30/44: loss=0.5726 
[epoch 31] step 32/44: loss=0.5713 
[epoch 31] step 34/44: loss=0.5698 
[epoch 31] step 36/44: loss=0.5682 
[epoch 31] step 38/44: loss=0.5682 
[epoch 31] step 40/44: loss=0.5668 
[epoch 31] step 42/44: loss=0.5655 
[epoch 31] step 44/44: loss=0.5637 
[epoch 31] train_loss(avg per step)=1.1274 lambda[min,max]=[0.356557,1.000000]
[epoch 31] val_loss=1.5083 qwk=('0.2088', '0.3358', '0.3625') averageQWK=0.3024 macroEMD=0.3163 tailR0=('0.0234', '0.0833', '0.0000') tailR0avg=0.0356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     1    3   54   20    0
     0    1   88   67    6
     0    0   39   22    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    3    0    0
     0    5   11    0    0
     0    8   39   19    0
     1    2  101  101    0
     0    1   10   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   17   12    0    0
     0   18   88    5    0
     0    7  125   49    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=0.5553 
[epoch 32] step 4/44: loss=0.5404 
[epoch 32] step 6/44: loss=0.5553 
[epoch 32] step 8/44: loss=0.5634 
[epoch 32] step 10/44: loss=0.5586 
[epoch 32] step 12/44: loss=0.5623 
[epoch 32] step 14/44: loss=0.5686 
[epoch 32] step 16/44: loss=0.5757 
[epoch 32] step 18/44: loss=0.5764 
[epoch 32] step 20/44: loss=0.5737 
[epoch 32] step 22/44: loss=0.5743 
[epoch 32] step 24/44: loss=0.5745 
[epoch 32] step 26/44: loss=0.5719 
[epoch 32] step 28/44: loss=0.5703 
[epoch 32] step 30/44: loss=0.5708 
[epoch 32] step 32/44: loss=0.5686 
[epoch 32] step 34/44: loss=0.5685 
[epoch 32] step 36/44: loss=0.5709 
[epoch 32] step 38/44: loss=0.5695 
[epoch 32] step 40/44: loss=0.5709 
[epoch 32] step 42/44: loss=0.5703 
[epoch 32] step 44/44: loss=0.5728 
[epoch 32] train_loss(avg per step)=1.1455 lambda[min,max]=[0.375848,1.000000]
[epoch 32] val_loss=1.5220 qwk=('0.1463', '0.3460', '0.3774') averageQWK=0.2899 macroEMD=0.3154 tailR0=('0.0234', '0.0833', '0.0000') tailR0avg=0.0356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     1    4   54   18    1
     0    1  102   53    6
     1    1   42   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    3    0    0
     0    6   10    0    0
     0    8   43   15    0
     0    2  114   89    0
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   17   12    0    0
     0   16   90    5    0
     0    6  123   52    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=0.5712 
[epoch 33] step 4/44: loss=0.5581 
[epoch 33] step 6/44: loss=0.5509 
[epoch 33] step 8/44: loss=0.5411 
[epoch 33] step 10/44: loss=0.5450 
[epoch 33] step 12/44: loss=0.5501 
[epoch 33] step 14/44: loss=0.5536 
[epoch 33] step 16/44: loss=0.5546 
[epoch 33] step 18/44: loss=0.5548 
[epoch 33] step 20/44: loss=0.5539 
[epoch 33] step 22/44: loss=0.5576 
[epoch 33] step 24/44: loss=0.5571 
[epoch 33] step 26/44: loss=0.5576 
[epoch 33] step 28/44: loss=0.5577 
[epoch 33] step 30/44: loss=0.5585 
[epoch 33] step 32/44: loss=0.5589 
[epoch 33] step 34/44: loss=0.5602 
[epoch 33] step 36/44: loss=0.5618 
[epoch 33] step 38/44: loss=0.5610 
[epoch 33] step 40/44: loss=0.5602 
[epoch 33] step 42/44: loss=0.5577 
[epoch 33] step 44/44: loss=0.5589 
[epoch 33] train_loss(avg per step)=1.1177 lambda[min,max]=[0.363710,1.000000]
[epoch 33] val_loss=1.5058 qwk=('0.1733', '0.3408', '0.3546') averageQWK=0.2896 macroEMD=0.3159 tailR0=('0.0156', '0.0833', '0.0000') tailR0avg=0.0330
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     1    4   54   19    0
     0    2   96   60    4
     0    1   41   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    3    0    0
     0    6   10    0    0
     0    7   42   17    0
     0    2  112   91    0
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   14   15    0    0
     0   12   95    4    0
     0    3  131   47    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=0.5626 
[epoch 34] step 4/44: loss=0.5878 
[epoch 34] step 6/44: loss=0.5735 
[epoch 34] step 8/44: loss=0.5773 
[epoch 34] step 10/44: loss=0.5680 
[epoch 34] step 12/44: loss=0.5681 
[epoch 34] step 14/44: loss=0.5703 
[epoch 34] step 16/44: loss=0.5741 
[epoch 34] step 18/44: loss=0.5788 
[epoch 34] step 20/44: loss=0.5776 
[epoch 34] step 22/44: loss=0.5744 
[epoch 34] step 24/44: loss=0.5728 
[epoch 34] step 26/44: loss=0.5713 
[epoch 34] step 28/44: loss=0.5684 
[epoch 34] step 30/44: loss=0.5683 
[epoch 34] step 32/44: loss=0.5696 
[epoch 34] step 34/44: loss=0.5710 
[epoch 34] step 36/44: loss=0.5694 
[epoch 34] step 38/44: loss=0.5683 
[epoch 34] step 40/44: loss=0.5695 
[epoch 34] step 42/44: loss=0.5688 
[epoch 34] step 44/44: loss=0.5693 
[epoch 34] train_loss(avg per step)=1.1386 lambda[min,max]=[0.370620,1.000000]
[epoch 34] val_loss=1.5252 qwk=('0.1798', '0.3407', '0.3574') averageQWK=0.2926 macroEMD=0.3157 tailR0=('0.0156', '0.0833', '0.0000') tailR0avg=0.0330
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     1    4   54   19    0
     0    2   90   66    4
     0    1   41   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    3    0    0
     0    6   10    0    0
     0    9   39   18    0
     0    2  112   91    0
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   16   13    0    0
     0   15   91    5    0
     0    5  129   47    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=0.5719 
[epoch 35] step 4/44: loss=0.5636 
[epoch 35] step 6/44: loss=0.5534 
[epoch 35] step 8/44: loss=0.5488 
[epoch 35] step 10/44: loss=0.5415 
[epoch 35] step 12/44: loss=0.5441 
[epoch 35] step 14/44: loss=0.5446 
[epoch 35] step 16/44: loss=0.5469 
[epoch 35] step 18/44: loss=0.5453 
[epoch 35] step 20/44: loss=0.5426 
[epoch 35] step 22/44: loss=0.5414 
[epoch 35] step 24/44: loss=0.5462 
[epoch 35] step 26/44: loss=0.5452 
[epoch 35] step 28/44: loss=0.5453 
[epoch 35] step 30/44: loss=0.5447 
[epoch 35] step 32/44: loss=0.5456 
[epoch 35] step 34/44: loss=0.5468 
[epoch 35] step 36/44: loss=0.5463 
[epoch 35] step 38/44: loss=0.5468 
[epoch 35] step 40/44: loss=0.5480 
[epoch 35] step 42/44: loss=0.5494 
[epoch 35] step 44/44: loss=0.5515 
[epoch 35] train_loss(avg per step)=1.1029 lambda[min,max]=[0.362182,1.000000]
[epoch 35] val_loss=1.5255 qwk=('0.1869', '0.3246', '0.3686') averageQWK=0.2934 macroEMD=0.3152 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   11    1    0
     0    8   51   19    0
     0    3   86   70    3
     0    3   38   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    3    0    0
     0    8    8    0    0
     0   10   46   10    0
     0    3  122   80    0
     0    0   17   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   17   12    0    0
     0   15   91    5    0
     0    5  128   48    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-1/fold0/metrics.json
Done.
