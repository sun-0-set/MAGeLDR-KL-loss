[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.9120 
[epoch 1] step 4/44: loss=0.9212 
[epoch 1] step 6/44: loss=0.9207 
[epoch 1] step 8/44: loss=0.9269 
[epoch 1] step 10/44: loss=0.9308 
[epoch 1] step 12/44: loss=0.9292 
[epoch 1] step 14/44: loss=0.9275 
[epoch 1] step 16/44: loss=0.9273 
[epoch 1] step 18/44: loss=0.9271 
[epoch 1] step 20/44: loss=0.9220 
[epoch 1] step 22/44: loss=0.9215 
[epoch 1] step 24/44: loss=0.9201 
[epoch 1] step 26/44: loss=0.9204 
[epoch 1] step 28/44: loss=0.9169 
[epoch 1] step 30/44: loss=0.9156 
[epoch 1] step 32/44: loss=0.9119 
[epoch 1] step 34/44: loss=0.9096 
[epoch 1] step 36/44: loss=0.9052 
[epoch 1] step 38/44: loss=0.8995 
[epoch 1] step 40/44: loss=0.8947 
[epoch 1] step 42/44: loss=0.8871 
[epoch 1] step 44/44: loss=0.8801 
[epoch 1] val_loss=1.3815 qwk=('-0.0210', '0.0020', '-0.0648') averageQWK=-0.0279 macroEMD=0.3623 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    4    0
     0    0    0   15    0
     0    0    0   78    0
     0    8    0  154    0
     0    0    0   64    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   16    0    0
     1    0   56    9    0
     6    0  171   28    0
     0    0   29    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    4   25    0    0
     0   12   99    0    0
     0   42  139    0    0
     0    0    1    0    0
[epoch 2] step 2/44: loss=0.7080 
[epoch 2] step 4/44: loss=0.6983 
[epoch 2] step 6/44: loss=0.7051 
[epoch 2] step 8/44: loss=0.6879 
[epoch 2] step 10/44: loss=0.6751 
[epoch 2] step 12/44: loss=0.6776 
[epoch 2] step 14/44: loss=0.6769 
[epoch 2] step 16/44: loss=0.6744 
[epoch 2] step 18/44: loss=0.6681 
[epoch 2] step 20/44: loss=0.6621 
[epoch 2] step 22/44: loss=0.6592 
[epoch 2] step 24/44: loss=0.6561 
[epoch 2] step 26/44: loss=0.6529 
[epoch 2] step 28/44: loss=0.6534 
[epoch 2] step 30/44: loss=0.6476 
[epoch 2] step 32/44: loss=0.6428 
[epoch 2] step 34/44: loss=0.6410 
[epoch 2] step 36/44: loss=0.6375 
[epoch 2] step 38/44: loss=0.6357 
[epoch 2] step 40/44: loss=0.6321 
[epoch 2] step 42/44: loss=0.6272 
[epoch 2] step 44/44: loss=0.6242 
[epoch 2] val_loss=1.4513 qwk=('0.0226', '0.0317', '0.0436') averageQWK=0.0326 macroEMD=0.3143 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    0   13    2    0
     0    0   66   12    0
     0    0  123   39    0
     0    0   59    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   13    3    0
     0    0   53   13    0
     0    0  163   42    0
     0    0   23    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    0   29    0    0
     0    0  111    0    0
     0    0  172    9    0
     0    0    1    0    0
[epoch 3] step 2/44: loss=0.5926 
[epoch 3] step 4/44: loss=0.5562 
[epoch 3] step 6/44: loss=0.5712 
[epoch 3] step 8/44: loss=0.5749 
[epoch 3] step 10/44: loss=0.5746 
[epoch 3] step 12/44: loss=0.5650 
[epoch 3] step 14/44: loss=0.5687 
[epoch 3] step 16/44: loss=0.5632 
[epoch 3] step 18/44: loss=0.5567 
[epoch 3] step 20/44: loss=0.5586 
[epoch 3] step 22/44: loss=0.5581 
[epoch 3] step 24/44: loss=0.5578 
[epoch 3] step 26/44: loss=0.5518 
[epoch 3] step 28/44: loss=0.5498 
[epoch 3] step 30/44: loss=0.5479 
[epoch 3] step 32/44: loss=0.5435 
[epoch 3] step 34/44: loss=0.5413 
[epoch 3] step 36/44: loss=0.5383 
[epoch 3] step 38/44: loss=0.5354 
[epoch 3] step 40/44: loss=0.5367 
[epoch 3] step 42/44: loss=0.5337 
[epoch 3] step 44/44: loss=0.5284 
[epoch 3] val_loss=1.5011 qwk=('0.1532', '0.1755', '0.2667') averageQWK=0.1985 macroEMD=0.2749 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   13    0    0
     0    0   67   11    0
     0    0  112   50    0
     0    1   45   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   14    2    0
     0    0   48   18    0
     0    0  113   92    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   12    0    0
     0   13   94    4    0
     0    9  148   24    0
     0    0    1    0    0
[epoch 4] step 2/44: loss=0.5134 
[epoch 4] step 4/44: loss=0.4995 
[epoch 4] step 6/44: loss=0.4976 
[epoch 4] step 8/44: loss=0.4981 
[epoch 4] step 10/44: loss=0.4950 
[epoch 4] step 12/44: loss=0.4929 
[epoch 4] step 14/44: loss=0.4977 
[epoch 4] step 16/44: loss=0.4936 
[epoch 4] step 18/44: loss=0.4879 
[epoch 4] step 20/44: loss=0.4880 
[epoch 4] step 22/44: loss=0.4964 
[epoch 4] step 24/44: loss=0.5050 
[epoch 4] step 26/44: loss=0.5031 
[epoch 4] step 28/44: loss=0.5047 
[epoch 4] step 30/44: loss=0.4972 
[epoch 4] step 32/44: loss=0.4981 
[epoch 4] step 34/44: loss=0.4978 
[epoch 4] step 36/44: loss=0.5007 
[epoch 4] step 38/44: loss=0.4989 
[epoch 4] step 40/44: loss=0.4962 
[epoch 4] step 42/44: loss=0.4947 
[epoch 4] step 44/44: loss=0.4947 
[epoch 4] val_loss=1.4334 qwk=('0.1863', '0.1755', '0.2216') averageQWK=0.1945 macroEMD=0.2679 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   13    0    0
     0    1   57   20    0
     0    0   98   64    0
     0    1   37   26    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   16    0    0
     0    0   48   18    0
     0    0  124   81    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   17    0    0
     0    6  102    3    0
     0    5  156   20    0
     0    0    1    0    0
[epoch 5] step 2/44: loss=0.4282 
[epoch 5] step 4/44: loss=0.4398 
[epoch 5] step 6/44: loss=0.4734 
[epoch 5] step 8/44: loss=0.4706 
[epoch 5] step 10/44: loss=0.4695 
[epoch 5] step 12/44: loss=0.4704 
[epoch 5] step 14/44: loss=0.4680 
[epoch 5] step 16/44: loss=0.4661 
[epoch 5] step 18/44: loss=0.4606 
[epoch 5] step 20/44: loss=0.4566 
[epoch 5] step 22/44: loss=0.4608 
[epoch 5] step 24/44: loss=0.4582 
[epoch 5] step 26/44: loss=0.4599 
[epoch 5] step 28/44: loss=0.4557 
[epoch 5] step 30/44: loss=0.4538 
[epoch 5] step 32/44: loss=0.4515 
[epoch 5] step 34/44: loss=0.4513 
[epoch 5] step 36/44: loss=0.4516 
[epoch 5] step 38/44: loss=0.4482 
[epoch 5] step 40/44: loss=0.4491 
[epoch 5] step 42/44: loss=0.4530 
[epoch 5] step 44/44: loss=0.4509 
[epoch 5] val_loss=1.5390 qwk=('0.1959', '0.1786', '0.3055') averageQWK=0.2267 macroEMD=0.2563 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   11    0    0
     0    3   64   11    0
     0    1  114   47    0
     0    0   43   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    0   16    0    0
     0    0   54   12    0
     0    0  148   57    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   11    0    0
     0   15   92    4    0
     0   12  135   34    0
     0    0    0    1    0
[epoch 6] step 2/44: loss=0.4346 
[epoch 6] step 4/44: loss=0.4295 
[epoch 6] step 6/44: loss=0.4208 
[epoch 6] step 8/44: loss=0.4200 
[epoch 6] step 10/44: loss=0.4212 
[epoch 6] step 12/44: loss=0.4262 
[epoch 6] step 14/44: loss=0.4190 
[epoch 6] step 16/44: loss=0.4176 
[epoch 6] step 18/44: loss=0.4206 
[epoch 6] step 20/44: loss=0.4186 
[epoch 6] step 22/44: loss=0.4181 
[epoch 6] step 24/44: loss=0.4189 
[epoch 6] step 26/44: loss=0.4168 
[epoch 6] step 28/44: loss=0.4210 
[epoch 6] step 30/44: loss=0.4236 
[epoch 6] step 32/44: loss=0.4301 
[epoch 6] step 34/44: loss=0.4267 
[epoch 6] step 36/44: loss=0.4272 
[epoch 6] step 38/44: loss=0.4224 
[epoch 6] step 40/44: loss=0.4212 
[epoch 6] step 42/44: loss=0.4191 
[epoch 6] step 44/44: loss=0.4159 
[epoch 6] val_loss=1.7124 qwk=('0.2004', '0.2713', '0.2732') averageQWK=0.2483 macroEMD=0.2537 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    7    0    0
     0   14   58    6    0
     0    7  110   45    0
     0    5   42   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    9    0    0
     0   10   49    7    0
     0    4  147   54    0
     0    1   18   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   17   92    2    0
     0    7  150   24    0
     0    0    1    0    0
[epoch 7] step 2/44: loss=0.4186 
[epoch 7] step 4/44: loss=0.4310 
[epoch 7] step 6/44: loss=0.4093 
[epoch 7] step 8/44: loss=0.4030 
[epoch 7] step 10/44: loss=0.3964 
[epoch 7] step 12/44: loss=0.3940 
[epoch 7] step 14/44: loss=0.3879 
[epoch 7] step 16/44: loss=0.3893 
[epoch 7] step 18/44: loss=0.3856 
[epoch 7] step 20/44: loss=0.3905 
[epoch 7] step 22/44: loss=0.3870 
[epoch 7] step 24/44: loss=0.3856 
[epoch 7] step 26/44: loss=0.3830 
[epoch 7] step 28/44: loss=0.3813 
[epoch 7] step 30/44: loss=0.3815 
[epoch 7] step 32/44: loss=0.3787 
[epoch 7] step 34/44: loss=0.3817 
[epoch 7] step 36/44: loss=0.3797 
[epoch 7] step 38/44: loss=0.3788 
[epoch 7] step 40/44: loss=0.3781 
[epoch 7] step 42/44: loss=0.3746 
[epoch 7] step 44/44: loss=0.3718 
[epoch 7] val_loss=1.3020 qwk=('0.2533', '0.3243', '0.2973') averageQWK=0.2916 macroEMD=0.2404 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    0   43   34    1
     0    0   46  116    0
     0    0   27   37    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    1   13    2    0
     0    1   37   28    0
     0    0   83  122    0
     0    0    9   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    4   25    0    0
     0    3   93   15    0
     0    0  118   63    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=0.3938 
[epoch 8] step 4/44: loss=0.3618 
[epoch 8] step 6/44: loss=0.3705 
[epoch 8] step 8/44: loss=0.3667 
[epoch 8] step 10/44: loss=0.3538 
[epoch 8] step 12/44: loss=0.3559 
[epoch 8] step 14/44: loss=0.3494 
[epoch 8] step 16/44: loss=0.3504 
[epoch 8] step 18/44: loss=0.3503 
[epoch 8] step 20/44: loss=0.3542 
[epoch 8] step 22/44: loss=0.3492 
[epoch 8] step 24/44: loss=0.3489 
[epoch 8] step 26/44: loss=0.3447 
[epoch 8] step 28/44: loss=0.3470 
[epoch 8] step 30/44: loss=0.3448 
[epoch 8] step 32/44: loss=0.3451 
[epoch 8] step 34/44: loss=0.3424 
[epoch 8] step 36/44: loss=0.3400 
[epoch 8] step 38/44: loss=0.3412 
[epoch 8] step 40/44: loss=0.3407 
[epoch 8] step 42/44: loss=0.3383 
[epoch 8] step 44/44: loss=0.3364 
[epoch 8] val_loss=1.5525 qwk=('0.2656', '0.3144', '0.3350') averageQWK=0.3050 macroEMD=0.2327 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   11    0    0
     0    7   52   17    2
     0    1   80   76    5
     0    0   35   27    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    5   10    1    0
     0    7   39   20    0
     0    1  111   93    0
     0    0   13   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   16    0    0
     0    7   97    7    0
     0    0  139   42    0
     0    0    1    0    0
[epoch 9] step 2/44: loss=0.3360 
[epoch 9] step 4/44: loss=0.3313 
[epoch 9] step 6/44: loss=0.3120 
[epoch 9] step 8/44: loss=0.2999 
[epoch 9] step 10/44: loss=0.2963 
[epoch 9] step 12/44: loss=0.2897 
[epoch 9] step 14/44: loss=0.2934 
[epoch 9] step 16/44: loss=0.2947 
[epoch 9] step 18/44: loss=0.2989 
[epoch 9] step 20/44: loss=0.2994 
[epoch 9] step 22/44: loss=0.3038 
[epoch 9] step 24/44: loss=0.3132 
[epoch 9] step 26/44: loss=0.3161 
[epoch 9] step 28/44: loss=0.3149 
[epoch 9] step 30/44: loss=0.3152 
[epoch 9] step 32/44: loss=0.3151 
[epoch 9] step 34/44: loss=0.3152 
[epoch 9] step 36/44: loss=0.3141 
[epoch 9] step 38/44: loss=0.3159 
[epoch 9] step 40/44: loss=0.3132 
[epoch 9] step 42/44: loss=0.3149 
[epoch 9] step 44/44: loss=0.3182 
[epoch 9] val_loss=1.4335 qwk=('0.2388', '0.2618', '0.2375') averageQWK=0.2460 macroEMD=0.2547 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    2   11    2    0
     0    1   43   32    2
     0    0   48  112    2
     0    0   27   36    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    1   13    2    0
     0    2   37   27    0
     0    0   92  113    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    4   25    0    0
     0    3  100    8    0
     0    0  135   46    0
     0    0    1    0    0
[epoch 10] step 2/44: loss=0.3164 
[epoch 10] step 4/44: loss=0.3304 
[epoch 10] step 6/44: loss=0.3164 
[epoch 10] step 8/44: loss=0.3230 
[epoch 10] step 10/44: loss=0.3184 
[epoch 10] step 12/44: loss=0.3144 
[epoch 10] step 14/44: loss=0.3142 
[epoch 10] step 16/44: loss=0.3150 
[epoch 10] step 18/44: loss=0.3127 
[epoch 10] step 20/44: loss=0.3079 
[epoch 10] step 22/44: loss=0.3041 
[epoch 10] step 24/44: loss=0.3054 
[epoch 10] step 26/44: loss=0.3055 
[epoch 10] step 28/44: loss=0.3003 
[epoch 10] step 30/44: loss=0.2978 
[epoch 10] step 32/44: loss=0.2953 
[epoch 10] step 34/44: loss=0.2926 
[epoch 10] step 36/44: loss=0.2895 
[epoch 10] step 38/44: loss=0.2867 
[epoch 10] step 40/44: loss=0.2858 
[epoch 10] step 42/44: loss=0.2822 
[epoch 10] step 44/44: loss=0.2800 
[epoch 10] val_loss=1.7160 qwk=('0.3040', '0.3026', '0.3203') averageQWK=0.3090 macroEMD=0.2243 tailR0=('0.0312', '0.0000', '0.0000') tailR0avg=0.0104
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    7    0    0
     0    8   52   15    3
     0    4   73   78    7
     0    1   32   27    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5   11    0    0
     0    7   44   15    0
     0    2  132   71    0
     0    0   14   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0    9   91   11    0
     0    3  134   44    0
     0    0    1    0    0
[epoch 11] step 2/44: loss=0.1971 
[epoch 11] step 4/44: loss=0.2386 
[epoch 11] step 6/44: loss=0.2666 
[epoch 11] step 8/44: loss=0.2686 
[epoch 11] step 10/44: loss=0.2665 
[epoch 11] step 12/44: loss=0.2682 
[epoch 11] step 14/44: loss=0.2659 
[epoch 11] step 16/44: loss=0.2662 
[epoch 11] step 18/44: loss=0.2663 
[epoch 11] step 20/44: loss=0.2623 
[epoch 11] step 22/44: loss=0.2632 
[epoch 11] step 24/44: loss=0.2614 
[epoch 11] step 26/44: loss=0.2616 
[epoch 11] step 28/44: loss=0.2641 
[epoch 11] step 30/44: loss=0.2644 
[epoch 11] step 32/44: loss=0.2637 
[epoch 11] step 34/44: loss=0.2626 
[epoch 11] step 36/44: loss=0.2647 
[epoch 11] step 38/44: loss=0.2624 
[epoch 11] step 40/44: loss=0.2596 
[epoch 11] step 42/44: loss=0.2605 
[epoch 11] step 44/44: loss=0.2616 
[epoch 11] val_loss=1.8381 qwk=('0.1950', '0.2989', '0.3811') averageQWK=0.2917 macroEMD=0.2307 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5   10    0    0
     0    7   60   10    1
     0    1  111   47    3
     0    0   47   16    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5   11    0    0
     0    8   45   13    0
     0    1  130   74    0
     0    0   17   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   15   91    5    0
     0    4  127   50    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=0.2377 
[epoch 12] step 4/44: loss=0.2501 
[epoch 12] step 6/44: loss=0.2452 
[epoch 12] step 8/44: loss=0.2425 
[epoch 12] step 10/44: loss=0.2304 
[epoch 12] step 12/44: loss=0.2341 
[epoch 12] step 14/44: loss=0.2363 
[epoch 12] step 16/44: loss=0.2367 
[epoch 12] step 18/44: loss=0.2393 
[epoch 12] step 20/44: loss=0.2382 
[epoch 12] step 22/44: loss=0.2388 
[epoch 12] step 24/44: loss=0.2329 
[epoch 12] step 26/44: loss=0.2344 
[epoch 12] step 28/44: loss=0.2341 
[epoch 12] step 30/44: loss=0.2349 
[epoch 12] step 32/44: loss=0.2351 
[epoch 12] step 34/44: loss=0.2351 
[epoch 12] step 36/44: loss=0.2314 
[epoch 12] step 38/44: loss=0.2295 
[epoch 12] step 40/44: loss=0.2304 
[epoch 12] step 42/44: loss=0.2316 
[epoch 12] step 44/44: loss=0.2323 
[epoch 12] val_loss=1.4875 qwk=('0.3658', '0.4345', '0.4370') averageQWK=0.4125 macroEMD=0.2123 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    9    0    0
     0    7   45   23    3
     0    1   50  105    6
     0    0   23   39    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5   11    0    0
     0    6   33   27    0
     0    1   71  133    0
     0    0    8   22    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0    8   91   12    0
     0    3  105   73    0
     0    0    0    1    0
[epoch 13] step 2/44: loss=0.2266 
[epoch 13] step 4/44: loss=0.2093 
[epoch 13] step 6/44: loss=0.2024 
[epoch 13] step 8/44: loss=0.2100 
[epoch 13] step 10/44: loss=0.2132 
[epoch 13] step 12/44: loss=0.2103 
[epoch 13] step 14/44: loss=0.2121 
[epoch 13] step 16/44: loss=0.2107 
[epoch 13] step 18/44: loss=0.2106 
[epoch 13] step 20/44: loss=0.2067 
[epoch 13] step 22/44: loss=0.2071 
[epoch 13] step 24/44: loss=0.2068 
[epoch 13] step 26/44: loss=0.2075 
[epoch 13] step 28/44: loss=0.2060 
[epoch 13] step 30/44: loss=0.2084 
[epoch 13] step 32/44: loss=0.2051 
[epoch 13] step 34/44: loss=0.2057 
[epoch 13] step 36/44: loss=0.2062 
[epoch 13] step 38/44: loss=0.2071 
[epoch 13] step 40/44: loss=0.2059 
[epoch 13] step 42/44: loss=0.2055 
[epoch 13] step 44/44: loss=0.2060 
[epoch 13] val_loss=2.0085 qwk=('0.2316', '0.2717', '0.2739') averageQWK=0.2590 macroEMD=0.2362 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   11    0    0
     0    4   61   12    1
     0    1   94   64    3
     0    1   38   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   12    0    0
     0    8   46   12    0
     0    1  138   66    0
     0    1   16   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   13    0    0
     0   18   90    3    0
     0   10  144   27    0
     0    0    1    0    0
[epoch 14] step 2/44: loss=0.1623 
[epoch 14] step 4/44: loss=0.1712 
[epoch 14] step 6/44: loss=0.1704 
[epoch 14] step 8/44: loss=0.1736 
[epoch 14] step 10/44: loss=0.1719 
[epoch 14] step 12/44: loss=0.1721 
[epoch 14] step 14/44: loss=0.1733 
[epoch 14] step 16/44: loss=0.1751 
[epoch 14] step 18/44: loss=0.1792 
[epoch 14] step 20/44: loss=0.1809 
[epoch 14] step 22/44: loss=0.1824 
[epoch 14] step 24/44: loss=0.1827 
[epoch 14] step 26/44: loss=0.1834 
[epoch 14] step 28/44: loss=0.1812 
[epoch 14] step 30/44: loss=0.1792 
[epoch 14] step 32/44: loss=0.1777 
[epoch 14] step 34/44: loss=0.1771 
[epoch 14] step 36/44: loss=0.1761 
[epoch 14] step 38/44: loss=0.1780 
[epoch 14] step 40/44: loss=0.1763 
[epoch 14] step 42/44: loss=0.1766 
[epoch 14] step 44/44: loss=0.1760 
[epoch 14] val_loss=1.9641 qwk=('0.2867', '0.3477', '0.3157') averageQWK=0.3167 macroEMD=0.2235 tailR0=('0.0078', '0.1667', '0.0000') tailR0avg=0.0582
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5   10    0    0
     0   10   50   17    1
     0    1   76   83    2
     0    1   33   29    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     0    3   13    0    0
     0    9   42   15    0
     0    0  116   89    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   17    0    0
     0   12   93    6    0
     0    5  134   42    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=0.1935 
[epoch 15] step 4/44: loss=0.1706 
[epoch 15] step 6/44: loss=0.1749 
[epoch 15] step 8/44: loss=0.1620 
[epoch 15] step 10/44: loss=0.1630 
[epoch 15] step 12/44: loss=0.1613 
[epoch 15] step 14/44: loss=0.1610 
[epoch 15] step 16/44: loss=0.1592 
[epoch 15] step 18/44: loss=0.1545 
[epoch 15] step 20/44: loss=0.1538 
[epoch 15] step 22/44: loss=0.1517 
[epoch 15] step 24/44: loss=0.1517 
[epoch 15] step 26/44: loss=0.1514 
[epoch 15] step 28/44: loss=0.1519 
[epoch 15] step 30/44: loss=0.1519 
[epoch 15] step 32/44: loss=0.1518 
[epoch 15] step 34/44: loss=0.1535 
[epoch 15] step 36/44: loss=0.1518 
[epoch 15] step 38/44: loss=0.1518 
[epoch 15] step 40/44: loss=0.1525 
[epoch 15] step 42/44: loss=0.1520 
[epoch 15] step 44/44: loss=0.1513 
[epoch 15] val_loss=2.1220 qwk=('0.2399', '0.2882', '0.2986') averageQWK=0.2756 macroEMD=0.2268 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    9    0    0
     0    7   60   10    1
     0    1  106   53    2
     0    1   39   23    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6   10    0    0
     0    8   47   11    0
     0    1  136   68    0
     0    0   19   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   10   19    0    0
     0    9   96    6    0
     0    5  133   43    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=0.1138 
[epoch 16] step 4/44: loss=0.1325 
[epoch 16] step 6/44: loss=0.1281 
[epoch 16] step 8/44: loss=0.1285 
[epoch 16] step 10/44: loss=0.1304 
[epoch 16] step 12/44: loss=0.1285 
[epoch 16] step 14/44: loss=0.1313 
[epoch 16] step 16/44: loss=0.1269 
[epoch 16] step 18/44: loss=0.1271 
[epoch 16] step 20/44: loss=0.1261 
[epoch 16] step 22/44: loss=0.1276 
[epoch 16] step 24/44: loss=0.1278 
[epoch 16] step 26/44: loss=0.1288 
[epoch 16] step 28/44: loss=0.1277 
[epoch 16] step 30/44: loss=0.1276 
[epoch 16] step 32/44: loss=0.1294 
[epoch 16] step 34/44: loss=0.1297 
[epoch 16] step 36/44: loss=0.1289 
[epoch 16] step 38/44: loss=0.1287 
[epoch 16] step 40/44: loss=0.1300 
[epoch 16] step 42/44: loss=0.1300 
[epoch 16] step 44/44: loss=0.1312 
[epoch 16] val_loss=2.1789 qwk=('0.2380', '0.2719', '0.3300') averageQWK=0.2800 macroEMD=0.2265 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    9    0    0
     0    9   57   11    1
     0    3   98   57    4
     0    1   40   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    6   10    0    0
     0   11   45   10    0
     0    1  142   57    5
     0    0   23    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   10   19    0    0
     0    7   97    7    0
     0    4  126   51    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=0.1056 
[epoch 17] step 4/44: loss=0.1037 
[epoch 17] step 6/44: loss=0.1058 
[epoch 17] step 8/44: loss=0.1069 
[epoch 17] step 10/44: loss=0.1095 
[epoch 17] step 12/44: loss=0.1062 
[epoch 17] step 14/44: loss=0.1040 
[epoch 17] step 16/44: loss=0.1045 
[epoch 17] step 18/44: loss=0.1047 
[epoch 17] step 20/44: loss=0.1055 
[epoch 17] step 22/44: loss=0.1074 
[epoch 17] step 24/44: loss=0.1079 
[epoch 17] step 26/44: loss=0.1080 
[epoch 17] step 28/44: loss=0.1090 
[epoch 17] step 30/44: loss=0.1081 
[epoch 17] step 32/44: loss=0.1075 
[epoch 17] step 34/44: loss=0.1079 
[epoch 17] step 36/44: loss=0.1081 
[epoch 17] step 38/44: loss=0.1082 
[epoch 17] step 40/44: loss=0.1085 
[epoch 17] step 42/44: loss=0.1090 
[epoch 17] step 44/44: loss=0.1084 
[epoch 17] val_loss=2.1518 qwk=('0.2738', '0.3340', '0.2908') averageQWK=0.2996 macroEMD=0.2294 tailR0=('0.1328', '0.1667', '0.0000') tailR0avg=0.0998
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0    5    9    1    0
     0    6   55   16    1
     0    0   82   78    2
     0    1   34   28    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    3    0    0
     0    4   12    0    0
     0    7   39   20    0
     0    0  106   99    0
     0    0   14   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    8   21    0    0
     0    5   99    7    0
     0    3  129   49    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=0.0973 
[epoch 18] step 4/44: loss=0.0909 
[epoch 18] step 6/44: loss=0.0903 
[epoch 18] step 8/44: loss=0.0933 
[epoch 18] step 10/44: loss=0.0975 
[epoch 18] step 12/44: loss=0.0963 
[epoch 18] step 14/44: loss=0.0947 
[epoch 18] step 16/44: loss=0.0942 
[epoch 18] step 18/44: loss=0.0919 
[epoch 18] step 20/44: loss=0.0920 
[epoch 18] step 22/44: loss=0.0925 
[epoch 18] step 24/44: loss=0.0921 
[epoch 18] step 26/44: loss=0.0910 
[epoch 18] step 28/44: loss=0.0919 
[epoch 18] step 30/44: loss=0.0929 
[epoch 18] step 32/44: loss=0.0928 
[epoch 18] step 34/44: loss=0.0925 
[epoch 18] step 36/44: loss=0.0917 
[epoch 18] step 38/44: loss=0.0921 
[epoch 18] step 40/44: loss=0.0914 
[epoch 18] step 42/44: loss=0.0916 
[epoch 18] step 44/44: loss=0.0930 
[epoch 18] val_loss=2.2700 qwk=('0.3074', '0.2633', '0.2883') averageQWK=0.2864 macroEMD=0.2325 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    8    1    0
     0    9   44   24    1
     0    1   62   96    3
     0    1   28   34    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    5   11    0    0
     0    7   48   11    0
     0    0  140   65    0
     0    0   19   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    8   21    0    0
     0    5  101    5    0
     0    2  134   45    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=0.0650 
[epoch 19] step 4/44: loss=0.0764 
[epoch 19] step 6/44: loss=0.0757 
[epoch 19] step 8/44: loss=0.0765 
[epoch 19] step 10/44: loss=0.0758 
[epoch 19] step 12/44: loss=0.0770 
[epoch 19] step 14/44: loss=0.0775 
[epoch 19] step 16/44: loss=0.0750 
[epoch 19] step 18/44: loss=0.0759 
[epoch 19] step 20/44: loss=0.0741 
[epoch 19] step 22/44: loss=0.0754 
[epoch 19] step 24/44: loss=0.0739 
[epoch 19] step 26/44: loss=0.0736 
[epoch 19] step 28/44: loss=0.0727 
[epoch 19] step 30/44: loss=0.0748 
[epoch 19] step 32/44: loss=0.0762 
[epoch 19] step 34/44: loss=0.0773 
[epoch 19] step 36/44: loss=0.0769 
[epoch 19] step 38/44: loss=0.0759 
[epoch 19] step 40/44: loss=0.0765 
[epoch 19] step 42/44: loss=0.0766 
[epoch 19] step 44/44: loss=0.0751 
[epoch 19] val_loss=2.1716 qwk=('0.2818', '0.3479', '0.3164') averageQWK=0.3154 macroEMD=0.2152 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    5   47   25    1
     0    0   64   95    3
     0    1   28   34    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    4   12    0    0
     0    7   39   20    0
     0    0  104  101    0
     0    0   13   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    8   21    0    0
     0    8   90   13    0
     0    5  113   63    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=0.0559 
[epoch 20] step 4/44: loss=0.0571 
[epoch 20] step 6/44: loss=0.0634 
[epoch 20] step 8/44: loss=0.0617 
[epoch 20] step 10/44: loss=0.0601 
[epoch 20] step 12/44: loss=0.0607 
[epoch 20] step 14/44: loss=0.0604 
[epoch 20] step 16/44: loss=0.0595 
[epoch 20] step 18/44: loss=0.0607 
[epoch 20] step 20/44: loss=0.0628 
[epoch 20] step 22/44: loss=0.0638 
[epoch 20] step 24/44: loss=0.0627 
[epoch 20] step 26/44: loss=0.0629 
[epoch 20] step 28/44: loss=0.0637 
[epoch 20] step 30/44: loss=0.0642 
[epoch 20] step 32/44: loss=0.0647 
[epoch 20] step 34/44: loss=0.0634 
[epoch 20] step 36/44: loss=0.0634 
[epoch 20] step 38/44: loss=0.0630 
[epoch 20] step 40/44: loss=0.0632 
[epoch 20] step 42/44: loss=0.0626 
[epoch 20] step 44/44: loss=0.0621 
[epoch 20] val_loss=2.6496 qwk=('0.2423', '0.3082', '0.2397') averageQWK=0.2634 macroEMD=0.2263 tailR0=('0.0000', '0.0833', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5   10    0    0
     0    8   56   13    1
     0    1   91   69    1
     0    2   36   26    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    7    9    0    0
     0    8   46   12    0
     0    0  129   76    0
     0    0   19   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    9   20    0    0
     0   10   96    5    0
     0    5  140   36    0
     0    0    1    0    0
[epoch 21] step 2/44: loss=0.0497 
[epoch 21] step 4/44: loss=0.0484 
[epoch 21] step 6/44: loss=0.0510 
[epoch 21] step 8/44: loss=0.0489 
[epoch 21] step 10/44: loss=0.0484 
[epoch 21] step 12/44: loss=0.0489 
[epoch 21] step 14/44: loss=0.0495 
[epoch 21] step 16/44: loss=0.0490 
[epoch 21] step 18/44: loss=0.0488 
[epoch 21] step 20/44: loss=0.0476 
[epoch 21] step 22/44: loss=0.0473 
[epoch 21] step 24/44: loss=0.0472 
[epoch 21] step 26/44: loss=0.0481 
[epoch 21] step 28/44: loss=0.0477 
[epoch 21] step 30/44: loss=0.0469 
[epoch 21] step 32/44: loss=0.0475 
[epoch 21] step 34/44: loss=0.0478 
[epoch 21] step 36/44: loss=0.0476 
[epoch 21] step 38/44: loss=0.0478 
[epoch 21] step 40/44: loss=0.0478 
[epoch 21] step 42/44: loss=0.0477 
[epoch 21] step 44/44: loss=0.0476 
[epoch 21] val_loss=2.5263 qwk=('0.2395', '0.3117', '0.3149') averageQWK=0.2887 macroEMD=0.2136 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    6    1    0
     0   12   51   14    1
     0    4   88   67    3
     0    4   35   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    7    9    0    0
     0   11   36   19    0
     0    5  108   92    0
     0    2   13   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   16    0    0
     0   15   87    9    0
     0   11  119   51    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=0.0448 
[epoch 22] step 4/44: loss=0.0462 
[epoch 22] step 6/44: loss=0.0461 
[epoch 22] step 8/44: loss=0.0439 
[epoch 22] step 10/44: loss=0.0415 
[epoch 22] step 12/44: loss=0.0427 
[epoch 22] step 14/44: loss=0.0434 
[epoch 22] step 16/44: loss=0.0432 
[epoch 22] step 18/44: loss=0.0425 
[epoch 22] step 20/44: loss=0.0429 
[epoch 22] step 22/44: loss=0.0427 
[epoch 22] step 24/44: loss=0.0425 
[epoch 22] step 26/44: loss=0.0423 
[epoch 22] step 28/44: loss=0.0414 
[epoch 22] step 30/44: loss=0.0408 
[epoch 22] step 32/44: loss=0.0409 
[epoch 22] step 34/44: loss=0.0408 
[epoch 22] step 36/44: loss=0.0410 
[epoch 22] step 38/44: loss=0.0409 
[epoch 22] step 40/44: loss=0.0418 
[epoch 22] step 42/44: loss=0.0413 
[epoch 22] step 44/44: loss=0.0405 
[epoch 22] val_loss=2.8969 qwk=('0.1912', '0.3337', '0.3360') averageQWK=0.2870 macroEMD=0.2104 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    9    0    0
     0    7   59   11    1
     0    1  111   48    2
     0    2   44   17    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    7    9    0    0
     0   10   44   12    0
     0    3  120   82    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   11   17    0    0
     0   14   91    6    0
     0    6  128   47    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=0.0375 
[epoch 23] step 4/44: loss=0.0322 
[epoch 23] step 6/44: loss=0.0312 
[epoch 23] step 8/44: loss=0.0298 
[epoch 23] step 10/44: loss=0.0293 
[epoch 23] step 12/44: loss=0.0286 
[epoch 23] step 14/44: loss=0.0310 
[epoch 23] step 16/44: loss=0.0299 
[epoch 23] step 18/44: loss=0.0306 
[epoch 23] step 20/44: loss=0.0319 
[epoch 23] step 22/44: loss=0.0320 
[epoch 23] step 24/44: loss=0.0322 
[epoch 23] step 26/44: loss=0.0318 
[epoch 23] step 28/44: loss=0.0330 
[epoch 23] step 30/44: loss=0.0334 
[epoch 23] step 32/44: loss=0.0333 
[epoch 23] step 34/44: loss=0.0330 
[epoch 23] step 36/44: loss=0.0334 
[epoch 23] step 38/44: loss=0.0337 
[epoch 23] step 40/44: loss=0.0341 
[epoch 23] step 42/44: loss=0.0341 
[epoch 23] step 44/44: loss=0.0342 
[epoch 23] val_loss=3.0825 qwk=('0.2340', '0.2776', '0.3125') averageQWK=0.2747 macroEMD=0.2144 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    7    0    0
     0   12   53   12    1
     0    4  102   54    2
     0    3   38   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    7    9    0    0
     0    9   48    9    0
     0    4  138   63    0
     0    0   20   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0   16   92    3    0
     0    9  133   39    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=0.0285 
[epoch 24] step 4/44: loss=0.0278 
[epoch 24] step 6/44: loss=0.0270 
[epoch 24] step 8/44: loss=0.0272 
[epoch 24] step 10/44: loss=0.0275 
[epoch 24] step 12/44: loss=0.0268 
[epoch 24] step 14/44: loss=0.0270 
[epoch 24] step 16/44: loss=0.0278 
[epoch 24] step 18/44: loss=0.0272 
[epoch 24] step 20/44: loss=0.0270 
[epoch 24] step 22/44: loss=0.0270 
[epoch 24] step 24/44: loss=0.0275 
[epoch 24] step 26/44: loss=0.0266 
[epoch 24] step 28/44: loss=0.0265 
[epoch 24] step 30/44: loss=0.0268 
[epoch 24] step 32/44: loss=0.0270 
[epoch 24] step 34/44: loss=0.0268 
[epoch 24] step 36/44: loss=0.0271 
[epoch 24] step 38/44: loss=0.0269 
[epoch 24] step 40/44: loss=0.0269 
[epoch 24] step 42/44: loss=0.0267 
[epoch 24] step 44/44: loss=0.0266 
[epoch 24] val_loss=2.5929 qwk=('0.2495', '0.3955', '0.3688') averageQWK=0.3379 macroEMD=0.2028 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7    8    0    0
     0    6   55   16    1
     0    1   88   71    2
     0    2   36   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    8    8    0    0
     0   11   33   22    0
     0    7   84  114    0
     0    0   10   20    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   17    0    0
     0   11   91    9    0
     0    6  114   61    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=0.0186 
[epoch 25] step 4/44: loss=0.0206 
[epoch 25] step 6/44: loss=0.0223 
[epoch 25] step 8/44: loss=0.0229 
[epoch 25] step 10/44: loss=0.0205 
[epoch 25] step 12/44: loss=0.0210 
[epoch 25] step 14/44: loss=0.0219 
[epoch 25] step 16/44: loss=0.0209 
[epoch 25] step 18/44: loss=0.0216 
[epoch 25] step 20/44: loss=0.0218 
[epoch 25] step 22/44: loss=0.0222 
[epoch 25] step 24/44: loss=0.0221 
[epoch 25] step 26/44: loss=0.0218 
[epoch 25] step 28/44: loss=0.0221 
[epoch 25] step 30/44: loss=0.0232 
[epoch 25] step 32/44: loss=0.0232 
[epoch 25] step 34/44: loss=0.0228 
[epoch 25] step 36/44: loss=0.0228 
[epoch 25] step 38/44: loss=0.0233 
[epoch 25] step 40/44: loss=0.0233 
[epoch 25] step 42/44: loss=0.0232 
[epoch 25] step 44/44: loss=0.0230 
[epoch 25] val_loss=2.9844 qwk=('0.2362', '0.3270', '0.3345') averageQWK=0.2993 macroEMD=0.2152 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    7    0    0
     0   13   48   16    1
     0    4   94   62    2
     0    4   35   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    7    9    0    0
     0    9   43   14    0
     0    2  117   85    1
     0    1   15   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     2    6   21    0    0
     0    8   94    9    0
     0    4  122   55    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=0.0140 
[epoch 26] step 4/44: loss=0.0162 
[epoch 26] step 6/44: loss=0.0179 
[epoch 26] step 8/44: loss=0.0178 
[epoch 26] step 10/44: loss=0.0183 
[epoch 26] step 12/44: loss=0.0181 
[epoch 26] step 14/44: loss=0.0185 
[epoch 26] step 16/44: loss=0.0184 
[epoch 26] step 18/44: loss=0.0191 
[epoch 26] step 20/44: loss=0.0196 
[epoch 26] step 22/44: loss=0.0189 
[epoch 26] step 24/44: loss=0.0186 
[epoch 26] step 26/44: loss=0.0188 
[epoch 26] step 28/44: loss=0.0190 
[epoch 26] step 30/44: loss=0.0187 
[epoch 26] step 32/44: loss=0.0184 
[epoch 26] step 34/44: loss=0.0181 
[epoch 26] step 36/44: loss=0.0182 
[epoch 26] step 38/44: loss=0.0180 
[epoch 26] step 40/44: loss=0.0179 
[epoch 26] step 42/44: loss=0.0186 
[epoch 26] step 44/44: loss=0.0184 
[epoch 26] val_loss=2.9842 qwk=('0.2159', '0.3636', '0.3080') averageQWK=0.2958 macroEMD=0.2177 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5   10    0    0
     0    6   57   14    1
     0    1  101   57    3
     0    2   38   23    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    7    9    0    0
     0   10   34   22    0
     0    7   86  112    0
     0    1    9   20    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   10   18    0    0
     0   11   97    3    0
     0    5  135   41    0
     0    0    1    0    0
[epoch 27] step 2/44: loss=0.0168 
[epoch 27] step 4/44: loss=0.0156 
[epoch 27] step 6/44: loss=0.0156 
[epoch 27] step 8/44: loss=0.0149 
[epoch 27] step 10/44: loss=0.0145 
[epoch 27] step 12/44: loss=0.0146 
[epoch 27] step 14/44: loss=0.0146 
[epoch 27] step 16/44: loss=0.0149 
[epoch 27] step 18/44: loss=0.0163 
[epoch 27] step 20/44: loss=0.0170 
[epoch 27] step 22/44: loss=0.0171 
[epoch 27] step 24/44: loss=0.0169 
[epoch 27] step 26/44: loss=0.0166 
[epoch 27] step 28/44: loss=0.0161 
[epoch 27] step 30/44: loss=0.0158 
[epoch 27] step 32/44: loss=0.0157 
[epoch 27] step 34/44: loss=0.0157 
[epoch 27] step 36/44: loss=0.0160 
[epoch 27] step 38/44: loss=0.0160 
[epoch 27] step 40/44: loss=0.0158 
[epoch 27] step 42/44: loss=0.0156 
[epoch 27] step 44/44: loss=0.0155 
[epoch 27] val_loss=3.1370 qwk=('0.2415', '0.3363', '0.3364') averageQWK=0.3047 macroEMD=0.2186 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7    8    0    0
     0   12   50   15    1
     0    3   98   58    3
     0    3   35   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    7    9    0    0
     0    8   43   15    0
     0    3  111   91    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   10   18    0    0
     0   13   93    5    0
     0    5  129   47    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=0.0127 
[epoch 28] step 4/44: loss=0.0115 
[epoch 28] step 6/44: loss=0.0124 
[epoch 28] step 8/44: loss=0.0135 
[epoch 28] step 10/44: loss=0.0149 
[epoch 28] step 12/44: loss=0.0149 
[epoch 28] step 14/44: loss=0.0144 
[epoch 28] step 16/44: loss=0.0143 
[epoch 28] step 18/44: loss=0.0138 
[epoch 28] step 20/44: loss=0.0139 
[epoch 28] step 22/44: loss=0.0140 
[epoch 28] step 24/44: loss=0.0139 
[epoch 28] step 26/44: loss=0.0136 
[epoch 28] step 28/44: loss=0.0136 
[epoch 28] step 30/44: loss=0.0132 
[epoch 28] step 32/44: loss=0.0136 
[epoch 28] step 34/44: loss=0.0138 
[epoch 28] step 36/44: loss=0.0137 
[epoch 28] step 38/44: loss=0.0138 
[epoch 28] step 40/44: loss=0.0138 
[epoch 28] step 42/44: loss=0.0135 
[epoch 28] step 44/44: loss=0.0135 
[epoch 28] val_loss=3.2937 qwk=('0.1881', '0.3128', '0.3353') averageQWK=0.2787 macroEMD=0.2099 tailR0=('0.0000', '0.0833', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7    8    0    0
     0   12   53   12    1
     0    4  110   46    2
     0    4   41   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    7    9    0    0
     0    9   42   15    0
     0    4  117   84    0
     0    1   15   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     2    9   18    0    0
     0   12   93    6    0
     0    6  127   48    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=0.0118 
[epoch 29] step 4/44: loss=0.0114 
[epoch 29] step 6/44: loss=0.0109 
[epoch 29] step 8/44: loss=0.0104 
[epoch 29] step 10/44: loss=0.0107 
[epoch 29] step 12/44: loss=0.0105 
[epoch 29] step 14/44: loss=0.0099 
[epoch 29] step 16/44: loss=0.0098 
[epoch 29] step 18/44: loss=0.0099 
[epoch 29] step 20/44: loss=0.0102 
[epoch 29] step 22/44: loss=0.0102 
[epoch 29] step 24/44: loss=0.0102 
[epoch 29] step 26/44: loss=0.0102 
[epoch 29] step 28/44: loss=0.0102 
[epoch 29] step 30/44: loss=0.0100 
[epoch 29] step 32/44: loss=0.0100 
[epoch 29] step 34/44: loss=0.0099 
[epoch 29] step 36/44: loss=0.0104 
[epoch 29] step 38/44: loss=0.0105 
[epoch 29] step 40/44: loss=0.0109 
[epoch 29] step 42/44: loss=0.0110 
[epoch 29] step 44/44: loss=0.0111 
[epoch 29] val_loss=3.2347 qwk=('0.2425', '0.3183', '0.3586') averageQWK=0.3065 macroEMD=0.2088 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    7    0    0
     0    9   55   12    2
     0    2   98   59    3
     0    2   38   23    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    6   10    0    0
     0    9   40   17    0
     0    4  111   90    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   11   17    0    0
     0   12   92    7    0
     0    5  123   53    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=0.0073 
[epoch 30] step 4/44: loss=0.0074 
[epoch 30] step 6/44: loss=0.0119 
[epoch 30] step 8/44: loss=0.0111 
[epoch 30] step 10/44: loss=0.0106 
[epoch 30] step 12/44: loss=0.0101 
[epoch 30] step 14/44: loss=0.0099 
[epoch 30] step 16/44: loss=0.0101 
[epoch 30] step 18/44: loss=0.0103 
[epoch 30] step 20/44: loss=0.0101 
[epoch 30] step 22/44: loss=0.0103 
[epoch 30] step 24/44: loss=0.0103 
[epoch 30] step 26/44: loss=0.0101 
[epoch 30] step 28/44: loss=0.0100 
[epoch 30] step 30/44: loss=0.0099 
[epoch 30] step 32/44: loss=0.0099 
[epoch 30] step 34/44: loss=0.0096 
[epoch 30] step 36/44: loss=0.0096 
[epoch 30] step 38/44: loss=0.0095 
[epoch 30] step 40/44: loss=0.0095 
[epoch 30] step 42/44: loss=0.0095 
[epoch 30] step 44/44: loss=0.0095 
[epoch 30] val_loss=3.4079 qwk=('0.1883', '0.3127', '0.3197') averageQWK=0.2736 macroEMD=0.2198 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   11    0    0
     0    5   60   12    1
     0    1  108   51    2
     0    2   41   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    6   10    0    0
     0    8   42   16    0
     0    5  110   90    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   16    0    0
     0   12   96    3    0
     0    5  135   41    0
     0    0    1    0    0
[epoch 31] step 2/44: loss=0.0072 
[epoch 31] step 4/44: loss=0.0073 
[epoch 31] step 6/44: loss=0.0074 
[epoch 31] step 8/44: loss=0.0067 
[epoch 31] step 10/44: loss=0.0069 
[epoch 31] step 12/44: loss=0.0079 
[epoch 31] step 14/44: loss=0.0082 
[epoch 31] step 16/44: loss=0.0084 
[epoch 31] step 18/44: loss=0.0083 
[epoch 31] step 20/44: loss=0.0082 
[epoch 31] step 22/44: loss=0.0081 
[epoch 31] step 24/44: loss=0.0082 
[epoch 31] step 26/44: loss=0.0082 
[epoch 31] step 28/44: loss=0.0081 
[epoch 31] step 30/44: loss=0.0084 
[epoch 31] step 32/44: loss=0.0083 
[epoch 31] step 34/44: loss=0.0085 
[epoch 31] step 36/44: loss=0.0087 
[epoch 31] step 38/44: loss=0.0089 
[epoch 31] step 40/44: loss=0.0089 
[epoch 31] step 42/44: loss=0.0088 
[epoch 31] step 44/44: loss=0.0087 
[epoch 31] val_loss=3.2436 qwk=('0.2448', '0.3163', '0.3574') averageQWK=0.3062 macroEMD=0.2076 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    7    0    0
     0   11   50   16    1
     0    4   93   63    2
     0    3   35   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    5   11    0    0
     0    9   42   15    0
     0    5  113   87    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   11   17    0    0
     0   10   92    9    0
     0    5  121   55    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=0.0068 
[epoch 32] step 4/44: loss=0.0082 
[epoch 32] step 6/44: loss=0.0087 
[epoch 32] step 8/44: loss=0.0082 
[epoch 32] step 10/44: loss=0.0079 
[epoch 32] step 12/44: loss=0.0077 
[epoch 32] step 14/44: loss=0.0080 
[epoch 32] step 16/44: loss=0.0079 
[epoch 32] step 18/44: loss=0.0081 
[epoch 32] step 20/44: loss=0.0086 
[epoch 32] step 22/44: loss=0.0085 
[epoch 32] step 24/44: loss=0.0085 
[epoch 32] step 26/44: loss=0.0082 
[epoch 32] step 28/44: loss=0.0082 
[epoch 32] step 30/44: loss=0.0082 
[epoch 32] step 32/44: loss=0.0080 
[epoch 32] step 34/44: loss=0.0079 
[epoch 32] step 36/44: loss=0.0077 
[epoch 32] step 38/44: loss=0.0076 
[epoch 32] step 40/44: loss=0.0076 
[epoch 32] step 42/44: loss=0.0076 
[epoch 32] step 44/44: loss=0.0076 
[epoch 32] val_loss=3.3672 qwk=('0.2447', '0.3199', '0.3464') averageQWK=0.3037 macroEMD=0.2112 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7    8    0    0
     0    9   52   16    1
     0    2   95   63    2
     0    2   36   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    5   11    0    0
     0    9   41   16    0
     0    3  115   87    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   11   17    0    0
     0   11   94    6    0
     0    5  127   49    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=0.0105 
[epoch 33] step 4/44: loss=0.0085 
[epoch 33] step 6/44: loss=0.0077 
[epoch 33] step 8/44: loss=0.0071 
[epoch 33] step 10/44: loss=0.0075 
[epoch 33] step 12/44: loss=0.0080 
[epoch 33] step 14/44: loss=0.0079 
[epoch 33] step 16/44: loss=0.0079 
[epoch 33] step 18/44: loss=0.0079 
[epoch 33] step 20/44: loss=0.0078 
[epoch 33] step 22/44: loss=0.0079 
[epoch 33] step 24/44: loss=0.0077 
[epoch 33] step 26/44: loss=0.0075 
[epoch 33] step 28/44: loss=0.0075 
[epoch 33] step 30/44: loss=0.0075 
[epoch 33] step 32/44: loss=0.0074 
[epoch 33] step 34/44: loss=0.0073 
[epoch 33] step 36/44: loss=0.0074 
[epoch 33] step 38/44: loss=0.0073 
[epoch 33] step 40/44: loss=0.0072 
[epoch 33] step 42/44: loss=0.0072 
[epoch 33] step 44/44: loss=0.0071 
[epoch 33] val_loss=3.4043 qwk=('0.2362', '0.3108', '0.3547') averageQWK=0.3006 macroEMD=0.2111 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    7    0    0
     0   12   49   16    1
     0    4   97   59    2
     0    4   34   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    6   10    0    0
     0    8   42   16    0
     0    4  116   85    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   11   17    0    0
     0   12   93    6    0
     0    5  125   51    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=0.0062 
[epoch 34] step 4/44: loss=0.0058 
[epoch 34] step 6/44: loss=0.0054 
[epoch 34] step 8/44: loss=0.0058 
[epoch 34] step 10/44: loss=0.0060 
[epoch 34] step 12/44: loss=0.0060 
[epoch 34] step 14/44: loss=0.0060 
[epoch 34] step 16/44: loss=0.0063 
[epoch 34] step 18/44: loss=0.0064 
[epoch 34] step 20/44: loss=0.0064 
[epoch 34] step 22/44: loss=0.0066 
[epoch 34] step 24/44: loss=0.0066 
[epoch 34] step 26/44: loss=0.0065 
[epoch 34] step 28/44: loss=0.0064 
[epoch 34] step 30/44: loss=0.0068 
[epoch 34] step 32/44: loss=0.0067 
[epoch 34] step 34/44: loss=0.0067 
[epoch 34] step 36/44: loss=0.0066 
[epoch 34] step 38/44: loss=0.0065 
[epoch 34] step 40/44: loss=0.0066 
[epoch 34] step 42/44: loss=0.0066 
[epoch 34] step 44/44: loss=0.0065 
[epoch 34] val_loss=3.4180 qwk=('0.2402', '0.3182', '0.3435') averageQWK=0.3006 macroEMD=0.2129 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7    8    0    0
     0   10   53   14    1
     0    3   99   58    2
     0    2   37   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    6   10    0    0
     0    9   41   16    0
     0    4  113   88    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   10   18    0    0
     0   10   95    6    0
     0    4  128   49    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=0.0049 
[epoch 35] step 4/44: loss=0.0059 
[epoch 35] step 6/44: loss=0.0062 
[epoch 35] step 8/44: loss=0.0060 
[epoch 35] step 10/44: loss=0.0059 
[epoch 35] step 12/44: loss=0.0061 
[epoch 35] step 14/44: loss=0.0067 
[epoch 35] step 16/44: loss=0.0066 
[epoch 35] step 18/44: loss=0.0065 
[epoch 35] step 20/44: loss=0.0068 
[epoch 35] step 22/44: loss=0.0069 
[epoch 35] step 24/44: loss=0.0068 
[epoch 35] step 26/44: loss=0.0068 
[epoch 35] step 28/44: loss=0.0068 
[epoch 35] step 30/44: loss=0.0068 
[epoch 35] step 32/44: loss=0.0067 
[epoch 35] step 34/44: loss=0.0066 
[epoch 35] step 36/44: loss=0.0065 
[epoch 35] step 38/44: loss=0.0065 
[epoch 35] step 40/44: loss=0.0065 
[epoch 35] step 42/44: loss=0.0064 
[epoch 35] step 44/44: loss=0.0064 
[epoch 35] val_loss=3.4024 qwk=('0.2381', '0.3292', '0.3474') averageQWK=0.3049 macroEMD=0.2099 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7    8    0    0
     0   10   53   14    1
     0    4   98   58    2
     0    2   37   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    6   10    0    0
     0    9   41   16    0
     0    5  108   92    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   11   17    0    0
     0   12   93    6    0
     0    5  127   49    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/ce/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/ce/fold0/metrics.json
Done.
