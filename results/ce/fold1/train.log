[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.9683 
[epoch 1] step 4/44: loss=0.9465 
[epoch 1] step 6/44: loss=0.9353 
[epoch 1] step 8/44: loss=0.9360 
[epoch 1] step 10/44: loss=0.9425 
[epoch 1] step 12/44: loss=0.9372 
[epoch 1] step 14/44: loss=0.9373 
[epoch 1] step 16/44: loss=0.9383 
[epoch 1] step 18/44: loss=0.9376 
[epoch 1] step 20/44: loss=0.9367 
[epoch 1] step 22/44: loss=0.9362 
[epoch 1] step 24/44: loss=0.9363 
[epoch 1] step 26/44: loss=0.9343 
[epoch 1] step 28/44: loss=0.9334 
[epoch 1] step 30/44: loss=0.9309 
[epoch 1] step 32/44: loss=0.9280 
[epoch 1] step 34/44: loss=0.9242 
[epoch 1] step 36/44: loss=0.9197 
[epoch 1] step 38/44: loss=0.9134 
[epoch 1] step 40/44: loss=0.9073 
[epoch 1] step 42/44: loss=0.9017 
[epoch 1] step 44/44: loss=0.8945 
[epoch 1] val_loss=1.3584 qwk=('0.0251', '0.2548', '0.0976') averageQWK=0.1259 macroEMD=0.3624 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    9    0
     0    3    0   38    0
     0    9    0  113    0
     0    8    1  132    0
     0    1    0   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    2    0
     2    0   21   16    0
     4    0   56   44    0
     5    0   39  119    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    5    0    0
     0   20   32    0    0
     0   45  111    2    0
     0   32   73    4    1
     0    1    2    0    0
[epoch 2] step 2/44: loss=0.7502 
[epoch 2] step 4/44: loss=0.7300 
[epoch 2] step 6/44: loss=0.7229 
[epoch 2] step 8/44: loss=0.7027 
[epoch 2] step 10/44: loss=0.6913 
[epoch 2] step 12/44: loss=0.6882 
[epoch 2] step 14/44: loss=0.6859 
[epoch 2] step 16/44: loss=0.6794 
[epoch 2] step 18/44: loss=0.6763 
[epoch 2] step 20/44: loss=0.6715 
[epoch 2] step 22/44: loss=0.6704 
[epoch 2] step 24/44: loss=0.6686 
[epoch 2] step 26/44: loss=0.6660 
[epoch 2] step 28/44: loss=0.6640 
[epoch 2] step 30/44: loss=0.6641 
[epoch 2] step 32/44: loss=0.6611 
[epoch 2] step 34/44: loss=0.6582 
[epoch 2] step 36/44: loss=0.6559 
[epoch 2] step 38/44: loss=0.6546 
[epoch 2] step 40/44: loss=0.6511 
[epoch 2] step 42/44: loss=0.6482 
[epoch 2] step 44/44: loss=0.6428 
[epoch 2] val_loss=1.1752 qwk=('0.4396', '0.4375', '0.0079') averageQWK=0.2950 macroEMD=0.3154 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    1    0
     0    0   35    6    0
     0    0   64   58    0
     0    0   20  121    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    1    0
     0    0   38    1    0
     0    0   89   15    0
     0    0   57  106    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    0   52    0    0
     0    0  158    0    0
     0    0  109    1    0
     0    0    3    0    0
[epoch 3] step 2/44: loss=0.5793 
[epoch 3] step 4/44: loss=0.5870 
[epoch 3] step 6/44: loss=0.5924 
[epoch 3] step 8/44: loss=0.5857 
[epoch 3] step 10/44: loss=0.5858 
[epoch 3] step 12/44: loss=0.5780 
[epoch 3] step 14/44: loss=0.5808 
[epoch 3] step 16/44: loss=0.5765 
[epoch 3] step 18/44: loss=0.5794 
[epoch 3] step 20/44: loss=0.5764 
[epoch 3] step 22/44: loss=0.5697 
[epoch 3] step 24/44: loss=0.5670 
[epoch 3] step 26/44: loss=0.5653 
[epoch 3] step 28/44: loss=0.5614 
[epoch 3] step 30/44: loss=0.5641 
[epoch 3] step 32/44: loss=0.5621 
[epoch 3] step 34/44: loss=0.5562 
[epoch 3] step 36/44: loss=0.5511 
[epoch 3] step 38/44: loss=0.5461 
[epoch 3] step 40/44: loss=0.5478 
[epoch 3] step 42/44: loss=0.5481 
[epoch 3] step 44/44: loss=0.5438 
[epoch 3] val_loss=1.1993 qwk=('0.2566', '0.2809', '0.2606') averageQWK=0.2661 macroEMD=0.2890 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    3    0
     0    0   20   21    0
     0    0   26   96    0
     0    0    7  134    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    4    0
     0    0   19   20    0
     0    0   32   72    0
     0    0   12  151    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    3    0
     0    1   28   23    0
     0    1   44  113    0
     0    0    5  105    0
     0    0    0    3    0
[epoch 4] step 2/44: loss=0.5158 
[epoch 4] step 4/44: loss=0.5111 
[epoch 4] step 6/44: loss=0.5080 
[epoch 4] step 8/44: loss=0.5169 
[epoch 4] step 10/44: loss=0.5095 
[epoch 4] step 12/44: loss=0.5077 
[epoch 4] step 14/44: loss=0.5114 
[epoch 4] step 16/44: loss=0.5006 
[epoch 4] step 18/44: loss=0.4970 
[epoch 4] step 20/44: loss=0.5017 
[epoch 4] step 22/44: loss=0.5013 
[epoch 4] step 24/44: loss=0.5012 
[epoch 4] step 26/44: loss=0.5011 
[epoch 4] step 28/44: loss=0.5001 
[epoch 4] step 30/44: loss=0.4979 
[epoch 4] step 32/44: loss=0.4960 
[epoch 4] step 34/44: loss=0.4939 
[epoch 4] step 36/44: loss=0.4919 
[epoch 4] step 38/44: loss=0.4937 
[epoch 4] step 40/44: loss=0.4978 
[epoch 4] step 42/44: loss=0.4941 
[epoch 4] step 44/44: loss=0.5021 
[epoch 4] val_loss=1.1819 qwk=('0.3461', '0.4269', '0.3492') averageQWK=0.3741 macroEMD=0.2563 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    4   37    0    0
     0    0  116    6    0
     0    0   90   51    0
     0    0    9   12    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     0   10   29    0    0
     0   17   76   11    0
     0    6   92   65    0
     0    0    6   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    8   43    1    0
     0   11  136   11    0
     0    4   66   40    0
     0    0    1    2    0
[epoch 5] step 2/44: loss=0.4604 
[epoch 5] step 4/44: loss=0.4834 
[epoch 5] step 6/44: loss=0.4747 
[epoch 5] step 8/44: loss=0.4951 
[epoch 5] step 10/44: loss=0.4948 
[epoch 5] step 12/44: loss=0.4883 
[epoch 5] step 14/44: loss=0.4857 
[epoch 5] step 16/44: loss=0.4828 
[epoch 5] step 18/44: loss=0.4738 
[epoch 5] step 20/44: loss=0.4696 
[epoch 5] step 22/44: loss=0.4660 
[epoch 5] step 24/44: loss=0.4620 
[epoch 5] step 26/44: loss=0.4608 
[epoch 5] step 28/44: loss=0.4619 
[epoch 5] step 30/44: loss=0.4665 
[epoch 5] step 32/44: loss=0.4670 
[epoch 5] step 34/44: loss=0.4611 
[epoch 5] step 36/44: loss=0.4638 
[epoch 5] step 38/44: loss=0.4631 
[epoch 5] step 40/44: loss=0.4633 
[epoch 5] step 42/44: loss=0.4618 
[epoch 5] step 44/44: loss=0.4580 
[epoch 5] val_loss=1.2188 qwk=('0.3571', '0.2636', '0.3859') averageQWK=0.3355 macroEMD=0.2750 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    3   23   15    0
     0    0   39   83    0
     0    0   11  130    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    4    0
     0    1   15   23    0
     0    0   33   71    0
     0    0   13  150    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   38   12    0
     0    4   76   78    0
     0    0   14   96    0
     0    0    0    3    0
[epoch 6] step 2/44: loss=0.4710 
[epoch 6] step 4/44: loss=0.4582 
[epoch 6] step 6/44: loss=0.4636 
[epoch 6] step 8/44: loss=0.4522 
[epoch 6] step 10/44: loss=0.4563 
[epoch 6] step 12/44: loss=0.4739 
[epoch 6] step 14/44: loss=0.4798 
[epoch 6] step 16/44: loss=0.4711 
[epoch 6] step 18/44: loss=0.4611 
[epoch 6] step 20/44: loss=0.4611 
[epoch 6] step 22/44: loss=0.4656 
[epoch 6] step 24/44: loss=0.4580 
[epoch 6] step 26/44: loss=0.4495 
[epoch 6] step 28/44: loss=0.4483 
[epoch 6] step 30/44: loss=0.4444 
[epoch 6] step 32/44: loss=0.4414 
[epoch 6] step 34/44: loss=0.4411 
[epoch 6] step 36/44: loss=0.4418 
[epoch 6] step 38/44: loss=0.4395 
[epoch 6] step 40/44: loss=0.4378 
[epoch 6] step 42/44: loss=0.4364 
[epoch 6] step 44/44: loss=0.4313 
[epoch 6] val_loss=1.0919 qwk=('0.5247', '0.4752', '0.4409') averageQWK=0.4803 macroEMD=0.2451 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    0    0
     0    9   28    4    0
     0    3   66   53    0
     0    0   24  117    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    1    0
     0    3   34    2    0
     0    5   69   30    0
     0    0   42  121    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    6   42    4    0
     0    8  118   32    0
     0    0   39   71    0
     0    0    0    3    0
[epoch 7] step 2/44: loss=0.3809 
[epoch 7] step 4/44: loss=0.3903 
[epoch 7] step 6/44: loss=0.3853 
[epoch 7] step 8/44: loss=0.3780 
[epoch 7] step 10/44: loss=0.3792 
[epoch 7] step 12/44: loss=0.3795 
[epoch 7] step 14/44: loss=0.3811 
[epoch 7] step 16/44: loss=0.3832 
[epoch 7] step 18/44: loss=0.3819 
[epoch 7] step 20/44: loss=0.3927 
[epoch 7] step 22/44: loss=0.3880 
[epoch 7] step 24/44: loss=0.3922 
[epoch 7] step 26/44: loss=0.3955 
[epoch 7] step 28/44: loss=0.3935 
[epoch 7] step 30/44: loss=0.3948 
[epoch 7] step 32/44: loss=0.3918 
[epoch 7] step 34/44: loss=0.3934 
[epoch 7] step 36/44: loss=0.3928 
[epoch 7] step 38/44: loss=0.3904 
[epoch 7] step 40/44: loss=0.3893 
[epoch 7] step 42/44: loss=0.3892 
[epoch 7] step 44/44: loss=0.3969 
[epoch 7] val_loss=1.3381 qwk=('0.4261', '0.2905', '0.3544') averageQWK=0.3570 macroEMD=0.2648 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    3   28   10    0
     0    0   48   71    3
     0    0   16  120    5
     0    0    0   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    6    0
     0    2   18   19    0
     0    4   37   63    0
     0    0   18  145    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    1    0
     0    2   36   14    0
     0    6   73   79    0
     0    1   15   94    0
     0    0    0    3    0
[epoch 8] step 2/44: loss=0.3198 
[epoch 8] step 4/44: loss=0.3365 
[epoch 8] step 6/44: loss=0.3407 
[epoch 8] step 8/44: loss=0.3344 
[epoch 8] step 10/44: loss=0.3341 
[epoch 8] step 12/44: loss=0.3357 
[epoch 8] step 14/44: loss=0.3401 
[epoch 8] step 16/44: loss=0.3418 
[epoch 8] step 18/44: loss=0.3432 
[epoch 8] step 20/44: loss=0.3411 
[epoch 8] step 22/44: loss=0.3421 
[epoch 8] step 24/44: loss=0.3450 
[epoch 8] step 26/44: loss=0.3466 
[epoch 8] step 28/44: loss=0.3455 
[epoch 8] step 30/44: loss=0.3456 
[epoch 8] step 32/44: loss=0.3463 
[epoch 8] step 34/44: loss=0.3475 
[epoch 8] step 36/44: loss=0.3481 
[epoch 8] step 38/44: loss=0.3471 
[epoch 8] step 40/44: loss=0.3481 
[epoch 8] step 42/44: loss=0.3493 
[epoch 8] step 44/44: loss=0.3552 
[epoch 8] val_loss=1.4558 qwk=('0.3437', '0.2444', '0.3847') averageQWK=0.3243 macroEMD=0.2679 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    5    0
     0    5   21   15    0
     0    1   39   82    0
     0    0   11  130    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    6    0
     0    4    8   27    0
     0    1   33   70    0
     0    0   12  151    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    1    0
     0    5   36   11    0
     0   10   67   81    0
     0    2   12   96    0
     0    0    0    3    0
[epoch 9] step 2/44: loss=0.4139 
[epoch 9] step 4/44: loss=0.3667 
[epoch 9] step 6/44: loss=0.3338 
[epoch 9] step 8/44: loss=0.3530 
[epoch 9] step 10/44: loss=0.3417 
[epoch 9] step 12/44: loss=0.3339 
[epoch 9] step 14/44: loss=0.3367 
[epoch 9] step 16/44: loss=0.3348 
[epoch 9] step 18/44: loss=0.3341 
[epoch 9] step 20/44: loss=0.3271 
[epoch 9] step 22/44: loss=0.3234 
[epoch 9] step 24/44: loss=0.3220 
[epoch 9] step 26/44: loss=0.3203 
[epoch 9] step 28/44: loss=0.3219 
[epoch 9] step 30/44: loss=0.3192 
[epoch 9] step 32/44: loss=0.3185 
[epoch 9] step 34/44: loss=0.3135 
[epoch 9] step 36/44: loss=0.3134 
[epoch 9] step 38/44: loss=0.3144 
[epoch 9] step 40/44: loss=0.3149 
[epoch 9] step 42/44: loss=0.3169 
[epoch 9] step 44/44: loss=0.3140 
[epoch 9] val_loss=1.3443 qwk=('0.4389', '0.3397', '0.4162') averageQWK=0.3983 macroEMD=0.2498 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    3    0
     0    8   21   12    0
     0    1   52   68    1
     0    0   18  119    4
     0    0    1   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    4    0
     0    4   20   15    0
     0    7   44   53    0
     0    0   26  137    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    4   43    5    0
     0   14   95   49    0
     0    3   25   82    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=0.2635 
[epoch 10] step 4/44: loss=0.2795 
[epoch 10] step 6/44: loss=0.2736 
[epoch 10] step 8/44: loss=0.2906 
[epoch 10] step 10/44: loss=0.2897 
[epoch 10] step 12/44: loss=0.2807 
[epoch 10] step 14/44: loss=0.2823 
[epoch 10] step 16/44: loss=0.2884 
[epoch 10] step 18/44: loss=0.2912 
[epoch 10] step 20/44: loss=0.2906 
[epoch 10] step 22/44: loss=0.2868 
[epoch 10] step 24/44: loss=0.2814 
[epoch 10] step 26/44: loss=0.2790 
[epoch 10] step 28/44: loss=0.2771 
[epoch 10] step 30/44: loss=0.2751 
[epoch 10] step 32/44: loss=0.2752 
[epoch 10] step 34/44: loss=0.2723 
[epoch 10] step 36/44: loss=0.2730 
[epoch 10] step 38/44: loss=0.2728 
[epoch 10] step 40/44: loss=0.2710 
[epoch 10] step 42/44: loss=0.2714 
[epoch 10] step 44/44: loss=0.2714 
[epoch 10] val_loss=1.5059 qwk=('0.4630', '0.3648', '0.3734') averageQWK=0.4004 macroEMD=0.2468 tailR0=('0.1190', '0.0312', '0.0000') tailR0avg=0.0501
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    2    0
     0    6   27    8    0
     0    3   51   68    0
     0    0   20  119    2
     0    0    1   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    4    0
     0    4   24   11    0
     0    4   44   56    0
     0    0   27  136    0
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    1    0
     0    3   37   12    0
     0    9   82   67    0
     0    2   16   92    0
     0    0    0    3    0
[epoch 11] step 2/44: loss=0.3099 
[epoch 11] step 4/44: loss=0.2685 
[epoch 11] step 6/44: loss=0.2458 
[epoch 11] step 8/44: loss=0.2494 
[epoch 11] step 10/44: loss=0.2420 
[epoch 11] step 12/44: loss=0.2404 
[epoch 11] step 14/44: loss=0.2454 
[epoch 11] step 16/44: loss=0.2465 
[epoch 11] step 18/44: loss=0.2512 
[epoch 11] step 20/44: loss=0.2494 
[epoch 11] step 22/44: loss=0.2508 
[epoch 11] step 24/44: loss=0.2539 
[epoch 11] step 26/44: loss=0.2560 
[epoch 11] step 28/44: loss=0.2560 
[epoch 11] step 30/44: loss=0.2550 
[epoch 11] step 32/44: loss=0.2541 
[epoch 11] step 34/44: loss=0.2575 
[epoch 11] step 36/44: loss=0.2564 
[epoch 11] step 38/44: loss=0.2548 
[epoch 11] step 40/44: loss=0.2545 
[epoch 11] step 42/44: loss=0.2532 
[epoch 11] step 44/44: loss=0.2505 
[epoch 11] val_loss=1.6034 qwk=('0.4263', '0.3169', '0.3472') averageQWK=0.3635 macroEMD=0.2598 tailR0=('0.1429', '0.0625', '0.0000') tailR0avg=0.0685
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    3    0
     0    6   22   13    0
     0    2   40   80    0
     0    0   13  123    5
     0    0    0   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    5    0
     0    2   18   19    0
     0    3   40   61    0
     0    0   19  144    0
     0    0    0   14    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    2    0
     0    3   36   13    0
     0   10   79   69    0
     0    1   17   92    0
     0    0    0    3    0
[epoch 12] step 2/44: loss=0.2415 
[epoch 12] step 4/44: loss=0.2679 
[epoch 12] step 6/44: loss=0.2556 
[epoch 12] step 8/44: loss=0.2544 
[epoch 12] step 10/44: loss=0.2436 
[epoch 12] step 12/44: loss=0.2324 
[epoch 12] step 14/44: loss=0.2307 
[epoch 12] step 16/44: loss=0.2279 
[epoch 12] step 18/44: loss=0.2276 
[epoch 12] step 20/44: loss=0.2266 
[epoch 12] step 22/44: loss=0.2263 
[epoch 12] step 24/44: loss=0.2220 
[epoch 12] step 26/44: loss=0.2212 
[epoch 12] step 28/44: loss=0.2247 
[epoch 12] step 30/44: loss=0.2243 
[epoch 12] step 32/44: loss=0.2236 
[epoch 12] step 34/44: loss=0.2247 
[epoch 12] step 36/44: loss=0.2225 
[epoch 12] step 38/44: loss=0.2254 
[epoch 12] step 40/44: loss=0.2233 
[epoch 12] step 42/44: loss=0.2232 
[epoch 12] step 44/44: loss=0.2188 
[epoch 12] val_loss=1.5390 qwk=('0.4699', '0.4032', '0.3995') averageQWK=0.4242 macroEMD=0.2426 tailR0=('0.1190', '0.0312', '0.0000') tailR0avg=0.0501
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    3    0
     0    6   28    7    0
     0    3   60   59    0
     0    0   20  118    3
     0    0    2   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    4   30    5    0
     0    5   58   40    1
     0    1   41  120    1
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   48    2    0
     0    9  114   35    0
     0    2   38   70    0
     0    0    0    3    0
[epoch 13] step 2/44: loss=0.2288 
[epoch 13] step 4/44: loss=0.2083 
[epoch 13] step 6/44: loss=0.2041 
[epoch 13] step 8/44: loss=0.2094 
[epoch 13] step 10/44: loss=0.2040 
[epoch 13] step 12/44: loss=0.1998 
[epoch 13] step 14/44: loss=0.1996 
[epoch 13] step 16/44: loss=0.2081 
[epoch 13] step 18/44: loss=0.2025 
[epoch 13] step 20/44: loss=0.2013 
[epoch 13] step 22/44: loss=0.2012 
[epoch 13] step 24/44: loss=0.2004 
[epoch 13] step 26/44: loss=0.2043 
[epoch 13] step 28/44: loss=0.2023 
[epoch 13] step 30/44: loss=0.2011 
[epoch 13] step 32/44: loss=0.2009 
[epoch 13] step 34/44: loss=0.2002 
[epoch 13] step 36/44: loss=0.2002 
[epoch 13] step 38/44: loss=0.1991 
[epoch 13] step 40/44: loss=0.1988 
[epoch 13] step 42/44: loss=0.1994 
[epoch 13] step 44/44: loss=0.2007 
[epoch 13] val_loss=1.5796 qwk=('0.5250', '0.3898', '0.3796') averageQWK=0.4315 macroEMD=0.2367 tailR0=('0.1429', '0.0312', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0    9   26    6    0
     0    5   69   47    1
     0    2   22  110    7
     0    0    1   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    5   25    9    0
     0    7   53   44    0
     0    3   34  125    1
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    1    0
     0    3   45    4    0
     0   12  108   38    0
     0    3   33   74    0
     0    0    0    3    0
[epoch 14] step 2/44: loss=0.1881 
[epoch 14] step 4/44: loss=0.1943 
[epoch 14] step 6/44: loss=0.1875 
[epoch 14] step 8/44: loss=0.1886 
[epoch 14] step 10/44: loss=0.1863 
[epoch 14] step 12/44: loss=0.1921 
[epoch 14] step 14/44: loss=0.1900 
[epoch 14] step 16/44: loss=0.1892 
[epoch 14] step 18/44: loss=0.1883 
[epoch 14] step 20/44: loss=0.1863 
[epoch 14] step 22/44: loss=0.1830 
[epoch 14] step 24/44: loss=0.1833 
[epoch 14] step 26/44: loss=0.1842 
[epoch 14] step 28/44: loss=0.1843 
[epoch 14] step 30/44: loss=0.1818 
[epoch 14] step 32/44: loss=0.1834 
[epoch 14] step 34/44: loss=0.1858 
[epoch 14] step 36/44: loss=0.1860 
[epoch 14] step 38/44: loss=0.1840 
[epoch 14] step 40/44: loss=0.1835 
[epoch 14] step 42/44: loss=0.1832 
[epoch 14] step 44/44: loss=0.1802 
[epoch 14] val_loss=1.5589 qwk=('0.4979', '0.3728', '0.4490') averageQWK=0.4399 macroEMD=0.2391 tailR0=('0.0952', '0.0312', '0.0000') tailR0avg=0.0422
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    2    0
     0    8   23   10    0
     0    4   65   53    0
     0    0   18  122    1
     0    0    0   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    5   19   15    0
     0    4   50   50    0
     0    1   25  137    0
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    4   44    4    0
     0   14   98   46    0
     0    3   25   82    0
     0    0    0    3    0
[epoch 15] step 2/44: loss=0.1667 
[epoch 15] step 4/44: loss=0.1533 
[epoch 15] step 6/44: loss=0.1511 
[epoch 15] step 8/44: loss=0.1578 
[epoch 15] step 10/44: loss=0.1619 
[epoch 15] step 12/44: loss=0.1616 
[epoch 15] step 14/44: loss=0.1655 
[epoch 15] step 16/44: loss=0.1616 
[epoch 15] step 18/44: loss=0.1597 
[epoch 15] step 20/44: loss=0.1571 
[epoch 15] step 22/44: loss=0.1618 
[epoch 15] step 24/44: loss=0.1630 
[epoch 15] step 26/44: loss=0.1606 
[epoch 15] step 28/44: loss=0.1603 
[epoch 15] step 30/44: loss=0.1590 
[epoch 15] step 32/44: loss=0.1582 
[epoch 15] step 34/44: loss=0.1616 
[epoch 15] step 36/44: loss=0.1618 
[epoch 15] step 38/44: loss=0.1607 
[epoch 15] step 40/44: loss=0.1604 
[epoch 15] step 42/44: loss=0.1590 
[epoch 15] step 44/44: loss=0.1552 
[epoch 15] val_loss=1.6291 qwk=('0.5306', '0.4128', '0.4127') averageQWK=0.4520 macroEMD=0.2381 tailR0=('0.1429', '0.1250', '0.0000') tailR0avg=0.0893
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0    7   29    5    0
     0    3   74   44    1
     0    0   25  109    7
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    4   25   10    0
     0    5   55   43    1
     0    1   34  124    4
     0    0    2   10    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    1    0
     0    6   38    8    0
     0   10  105   43    0
     0    0   28   82    0
     0    0    0    3    0
[epoch 16] step 2/44: loss=0.1639 
[epoch 16] step 4/44: loss=0.1670 
[epoch 16] step 6/44: loss=0.1629 
[epoch 16] step 8/44: loss=0.1582 
[epoch 16] step 10/44: loss=0.1509 
[epoch 16] step 12/44: loss=0.1504 
[epoch 16] step 14/44: loss=0.1464 
[epoch 16] step 16/44: loss=0.1455 
[epoch 16] step 18/44: loss=0.1453 
[epoch 16] step 20/44: loss=0.1446 
[epoch 16] step 22/44: loss=0.1457 
[epoch 16] step 24/44: loss=0.1403 
[epoch 16] step 26/44: loss=0.1400 
[epoch 16] step 28/44: loss=0.1366 
[epoch 16] step 30/44: loss=0.1379 
[epoch 16] step 32/44: loss=0.1380 
[epoch 16] step 34/44: loss=0.1388 
[epoch 16] step 36/44: loss=0.1355 
[epoch 16] step 38/44: loss=0.1348 
[epoch 16] step 40/44: loss=0.1352 
[epoch 16] step 42/44: loss=0.1347 
[epoch 16] step 44/44: loss=0.1317 
[epoch 16] val_loss=1.7043 qwk=('0.5150', '0.3781', '0.4254') averageQWK=0.4395 macroEMD=0.2352 tailR0=('0.0952', '0.0312', '0.0000') tailR0avg=0.0422
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0    8   27    6    0
     0    5   67   50    0
     0    1   23  115    2
     0    0    1   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    4   27    8    0
     0    2   57   45    0
     0    1   37  125    0
     0    0    3   12    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    1    0
     0   11   34    7    0
     0   32   85   41    0
     0    3   29   78    0
     0    0    0    3    0
[epoch 17] step 2/44: loss=0.1259 
[epoch 17] step 4/44: loss=0.1173 
[epoch 17] step 6/44: loss=0.1242 
[epoch 17] step 8/44: loss=0.1282 
[epoch 17] step 10/44: loss=0.1331 
[epoch 17] step 12/44: loss=0.1349 
[epoch 17] step 14/44: loss=0.1303 
[epoch 17] step 16/44: loss=0.1305 
[epoch 17] step 18/44: loss=0.1288 
[epoch 17] step 20/44: loss=0.1271 
[epoch 17] step 22/44: loss=0.1259 
[epoch 17] step 24/44: loss=0.1239 
[epoch 17] step 26/44: loss=0.1224 
[epoch 17] step 28/44: loss=0.1204 
[epoch 17] step 30/44: loss=0.1185 
[epoch 17] step 32/44: loss=0.1189 
[epoch 17] step 34/44: loss=0.1180 
[epoch 17] step 36/44: loss=0.1170 
[epoch 17] step 38/44: loss=0.1185 
[epoch 17] step 40/44: loss=0.1179 
[epoch 17] step 42/44: loss=0.1170 
[epoch 17] step 44/44: loss=0.1144 
[epoch 17] val_loss=1.8558 qwk=('0.4632', '0.4100', '0.3899') averageQWK=0.4211 macroEMD=0.2398 tailR0=('0.0952', '0.0312', '0.0000') tailR0avg=0.0422
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    6   25   10    0
     0    3   57   62    0
     0    0   17  121    3
     0    0    0   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    3   30    6    0
     0    3   60   41    0
     0    0   40  122    1
     0    0    3   12    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    3   45    4    0
     0   12  106   40    0
     0    3   33   74    0
     0    0    0    3    0
[epoch 18] step 2/44: loss=0.1241 
[epoch 18] step 4/44: loss=0.1154 
[epoch 18] step 6/44: loss=0.1105 
[epoch 18] step 8/44: loss=0.1089 
[epoch 18] step 10/44: loss=0.1112 
[epoch 18] step 12/44: loss=0.1119 
[epoch 18] step 14/44: loss=0.1092 
[epoch 18] step 16/44: loss=0.1110 
[epoch 18] step 18/44: loss=0.1124 
[epoch 18] step 20/44: loss=0.1103 
[epoch 18] step 22/44: loss=0.1099 
[epoch 18] step 24/44: loss=0.1095 
[epoch 18] step 26/44: loss=0.1098 
[epoch 18] step 28/44: loss=0.1088 
[epoch 18] step 30/44: loss=0.1076 
[epoch 18] step 32/44: loss=0.1055 
[epoch 18] step 34/44: loss=0.1040 
[epoch 18] step 36/44: loss=0.1048 
[epoch 18] step 38/44: loss=0.1063 
[epoch 18] step 40/44: loss=0.1065 
[epoch 18] step 42/44: loss=0.1051 
[epoch 18] step 44/44: loss=0.1040 
[epoch 18] val_loss=1.7950 qwk=('0.5503', '0.4753', '0.4674') averageQWK=0.4977 macroEMD=0.2227 tailR0=('0.1429', '0.0938', '0.0000') tailR0avg=0.0789
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    1    0
     0   10   28    3    0
     0    6   82   34    0
     0    0   38  100    3
     0    0    3   12    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    2    0
     0    8   27    4    0
     0   13   56   34    1
     0    3   43  116    1
     0    0    2   11    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    1    0
     0   14   34    4    0
     0   33   84   41    0
     0    3   29   78    0
     0    0    0    3    0
[epoch 19] step 2/44: loss=0.0951 
[epoch 19] step 4/44: loss=0.0879 
[epoch 19] step 6/44: loss=0.0942 
[epoch 19] step 8/44: loss=0.1030 
[epoch 19] step 10/44: loss=0.1022 
[epoch 19] step 12/44: loss=0.1004 
[epoch 19] step 14/44: loss=0.0992 
[epoch 19] step 16/44: loss=0.0966 
[epoch 19] step 18/44: loss=0.0938 
[epoch 19] step 20/44: loss=0.0926 
[epoch 19] step 22/44: loss=0.0924 
[epoch 19] step 24/44: loss=0.0932 
[epoch 19] step 26/44: loss=0.0943 
[epoch 19] step 28/44: loss=0.0940 
[epoch 19] step 30/44: loss=0.0930 
[epoch 19] step 32/44: loss=0.0911 
[epoch 19] step 34/44: loss=0.0910 
[epoch 19] step 36/44: loss=0.0907 
[epoch 19] step 38/44: loss=0.0899 
[epoch 19] step 40/44: loss=0.0893 
[epoch 19] step 42/44: loss=0.0880 
[epoch 19] step 44/44: loss=0.0860 
[epoch 19] val_loss=1.8844 qwk=('0.4945', '0.3012', '0.4179') averageQWK=0.4046 macroEMD=0.2420 tailR0=('0.1905', '0.0938', '0.0000') tailR0avg=0.0947
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    1
     0    3   34    3    1
     0    0   79   41    2
     0    0   29  103    9
     0    0    1   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    4    0
     0    3   14   22    0
     0    2   41   60    1
     0    1   19  142    1
     0    0    1   12    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    1    0
     0    7   38    7    0
     0   16   95   47    0
     0    1   27   82    0
     0    0    0    3    0
[epoch 20] step 2/44: loss=0.0868 
[epoch 20] step 4/44: loss=0.0888 
[epoch 20] step 6/44: loss=0.0848 
[epoch 20] step 8/44: loss=0.0856 
[epoch 20] step 10/44: loss=0.0822 
[epoch 20] step 12/44: loss=0.0845 
[epoch 20] step 14/44: loss=0.0847 
[epoch 20] step 16/44: loss=0.0830 
[epoch 20] step 18/44: loss=0.0798 
[epoch 20] step 20/44: loss=0.0801 
[epoch 20] step 22/44: loss=0.0798 
[epoch 20] step 24/44: loss=0.0814 
[epoch 20] step 26/44: loss=0.0791 
[epoch 20] step 28/44: loss=0.0779 
[epoch 20] step 30/44: loss=0.0786 
[epoch 20] step 32/44: loss=0.0779 
[epoch 20] step 34/44: loss=0.0782 
[epoch 20] step 36/44: loss=0.0776 
[epoch 20] step 38/44: loss=0.0773 
[epoch 20] step 40/44: loss=0.0761 
[epoch 20] step 42/44: loss=0.0761 
[epoch 20] step 44/44: loss=0.0742 
[epoch 20] val_loss=2.0196 qwk=('0.4822', '0.3928', '0.3810') averageQWK=0.4187 macroEMD=0.2417 tailR0=('0.1190', '0.0312', '0.0000') tailR0avg=0.0501
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     1    7   25    8    0
     0    4   59   59    0
     0    0   21  116    4
     0    0    1   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    5   25    9    0
     0    9   45   49    1
     0    1   33  129    0
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    1    0
     0    4   43    5    0
     0   14  101   43    0
     0    2   30   78    0
     0    0    0    3    0
[epoch 21] step 2/44: loss=0.0398 
[epoch 21] step 4/44: loss=0.0419 
[epoch 21] step 6/44: loss=0.0447 
[epoch 21] step 8/44: loss=0.0474 
[epoch 21] step 10/44: loss=0.0504 
[epoch 21] step 12/44: loss=0.0508 
[epoch 21] step 14/44: loss=0.0510 
[epoch 21] step 16/44: loss=0.0525 
[epoch 21] step 18/44: loss=0.0550 
[epoch 21] step 20/44: loss=0.0561 
[epoch 21] step 22/44: loss=0.0565 
[epoch 21] step 24/44: loss=0.0561 
[epoch 21] step 26/44: loss=0.0557 
[epoch 21] step 28/44: loss=0.0550 
[epoch 21] step 30/44: loss=0.0556 
[epoch 21] step 32/44: loss=0.0569 
[epoch 21] step 34/44: loss=0.0576 
[epoch 21] step 36/44: loss=0.0575 
[epoch 21] step 38/44: loss=0.0571 
[epoch 21] step 40/44: loss=0.0572 
[epoch 21] step 42/44: loss=0.0565 
[epoch 21] step 44/44: loss=0.0556 
[epoch 21] val_loss=2.0017 qwk=('0.5177', '0.3921', '0.4193') averageQWK=0.4430 macroEMD=0.2340 tailR0=('0.2143', '0.0625', '0.0000') tailR0avg=0.0923
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    0    1
     0    6   31    3    1
     0    4   74   42    2
     0    0   29  100   12
     0    0    0   12    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    4    0
     0    4   24   11    0
     0    6   51   46    1
     0    1   29  133    0
     0    0    1   13    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    1    0
     0    6   41    5    0
     0   18   94   46    0
     0    1   29   80    0
     0    0    0    3    0
[epoch 22] step 2/44: loss=0.0338 
[epoch 22] step 4/44: loss=0.0437 
[epoch 22] step 6/44: loss=0.0470 
[epoch 22] step 8/44: loss=0.0469 
[epoch 22] step 10/44: loss=0.0458 
[epoch 22] step 12/44: loss=0.0461 
[epoch 22] step 14/44: loss=0.0444 
[epoch 22] step 16/44: loss=0.0443 
[epoch 22] step 18/44: loss=0.0437 
[epoch 22] step 20/44: loss=0.0443 
[epoch 22] step 22/44: loss=0.0456 
[epoch 22] step 24/44: loss=0.0465 
[epoch 22] step 26/44: loss=0.0463 
[epoch 22] step 28/44: loss=0.0478 
[epoch 22] step 30/44: loss=0.0470 
[epoch 22] step 32/44: loss=0.0476 
[epoch 22] step 34/44: loss=0.0493 
[epoch 22] step 36/44: loss=0.0493 
[epoch 22] step 38/44: loss=0.0499 
[epoch 22] step 40/44: loss=0.0495 
[epoch 22] step 42/44: loss=0.0495 
[epoch 22] step 44/44: loss=0.0496 
[epoch 22] val_loss=2.0420 qwk=('0.5160', '0.4053', '0.4197') averageQWK=0.4470 macroEMD=0.2294 tailR0=('0.1429', '0.0938', '0.0000') tailR0avg=0.0789
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    1    0
     0   10   29    2    0
     0   10   74   36    2
     0    2   43   89    7
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    7   22   10    0
     0   13   45   45    1
     0    5   27  131    0
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    1    0
     0   10   37    5    0
     0   23   85   50    0
     0    3   26   81    0
     0    0    0    3    0
[epoch 23] step 2/44: loss=0.0568 
[epoch 23] step 4/44: loss=0.0567 
[epoch 23] step 6/44: loss=0.0499 
[epoch 23] step 8/44: loss=0.0507 
[epoch 23] step 10/44: loss=0.0488 
[epoch 23] step 12/44: loss=0.0479 
[epoch 23] step 14/44: loss=0.0455 
[epoch 23] step 16/44: loss=0.0435 
[epoch 23] step 18/44: loss=0.0422 
[epoch 23] step 20/44: loss=0.0411 
[epoch 23] step 22/44: loss=0.0417 
[epoch 23] step 24/44: loss=0.0423 
[epoch 23] step 26/44: loss=0.0416 
[epoch 23] step 28/44: loss=0.0413 
[epoch 23] step 30/44: loss=0.0414 
[epoch 23] step 32/44: loss=0.0407 
[epoch 23] step 34/44: loss=0.0406 
[epoch 23] step 36/44: loss=0.0395 
[epoch 23] step 38/44: loss=0.0400 
[epoch 23] step 40/44: loss=0.0396 
[epoch 23] step 42/44: loss=0.0405 
[epoch 23] step 44/44: loss=0.0400 
[epoch 23] val_loss=2.1906 qwk=('0.5113', '0.4242', '0.3971') averageQWK=0.4442 macroEMD=0.2340 tailR0=('0.1429', '0.1250', '0.0000') tailR0avg=0.0893
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0    7   28    5    1
     0    4   76   39    3
     0    0   28  102   11
     0    0    1   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    4   27    8    0
     0    6   53   44    1
     0    1   33  127    2
     0    0    2   10    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    1    0
     0    6   40    6    0
     0   15   94   49    0
     0    1   27   82    0
     0    0    0    3    0
[epoch 24] step 2/44: loss=0.0379 
[epoch 24] step 4/44: loss=0.0335 
[epoch 24] step 6/44: loss=0.0316 
[epoch 24] step 8/44: loss=0.0347 
[epoch 24] step 10/44: loss=0.0357 
[epoch 24] step 12/44: loss=0.0367 
[epoch 24] step 14/44: loss=0.0369 
[epoch 24] step 16/44: loss=0.0368 
[epoch 24] step 18/44: loss=0.0372 
[epoch 24] step 20/44: loss=0.0386 
[epoch 24] step 22/44: loss=0.0386 
[epoch 24] step 24/44: loss=0.0387 
[epoch 24] step 26/44: loss=0.0388 
[epoch 24] step 28/44: loss=0.0376 
[epoch 24] step 30/44: loss=0.0374 
[epoch 24] step 32/44: loss=0.0374 
[epoch 24] step 34/44: loss=0.0365 
[epoch 24] step 36/44: loss=0.0362 
[epoch 24] step 38/44: loss=0.0355 
[epoch 24] step 40/44: loss=0.0351 
[epoch 24] step 42/44: loss=0.0356 
[epoch 24] step 44/44: loss=0.0344 
[epoch 24] val_loss=2.3165 qwk=('0.5008', '0.4238', '0.3812') averageQWK=0.4353 macroEMD=0.2356 tailR0=('0.1190', '0.1875', '0.0000') tailR0avg=0.1022
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    6   29    5    1
     0    2   68   52    0
     0    0   20  119    2
     0    0    0   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    4   29    6    0
     0    2   64   37    1
     0    0   45  112    6
     0    0    3    7    6
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    1    0
     0    5   40    7    0
     0   14   92   52    0
     0    1   27   82    0
     0    0    0    3    0
[epoch 25] step 2/44: loss=0.0443 
[epoch 25] step 4/44: loss=0.0359 
[epoch 25] step 6/44: loss=0.0336 
[epoch 25] step 8/44: loss=0.0331 
[epoch 25] step 10/44: loss=0.0318 
[epoch 25] step 12/44: loss=0.0319 
[epoch 25] step 14/44: loss=0.0331 
[epoch 25] step 16/44: loss=0.0328 
[epoch 25] step 18/44: loss=0.0311 
[epoch 25] step 20/44: loss=0.0294 
[epoch 25] step 22/44: loss=0.0292 
[epoch 25] step 24/44: loss=0.0292 
[epoch 25] step 26/44: loss=0.0291 
[epoch 25] step 28/44: loss=0.0290 
[epoch 25] step 30/44: loss=0.0286 
[epoch 25] step 32/44: loss=0.0293 
[epoch 25] step 34/44: loss=0.0299 
[epoch 25] step 36/44: loss=0.0299 
[epoch 25] step 38/44: loss=0.0295 
[epoch 25] step 40/44: loss=0.0294 
[epoch 25] step 42/44: loss=0.0291 
[epoch 25] step 44/44: loss=0.0285 
[epoch 25] val_loss=2.2466 qwk=('0.4920', '0.3805', '0.3801') averageQWK=0.4175 macroEMD=0.2362 tailR0=('0.1190', '0.0312', '0.0000') tailR0avg=0.0501
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   31    2    1
     0    3   79   39    1
     0    0   36  100    5
     0    0    3   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    4   26    9    0
     0   10   52   41    1
     0    1   38  124    0
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    1    0
     0    3   44    5    0
     0   11  104   43    0
     0    1   32   77    0
     0    0    0    3    0
[epoch 26] step 2/44: loss=0.0229 
[epoch 26] step 4/44: loss=0.0198 
[epoch 26] step 6/44: loss=0.0213 
[epoch 26] step 8/44: loss=0.0224 
[epoch 26] step 10/44: loss=0.0224 
[epoch 26] step 12/44: loss=0.0223 
[epoch 26] step 14/44: loss=0.0223 
[epoch 26] step 16/44: loss=0.0235 
[epoch 26] step 18/44: loss=0.0235 
[epoch 26] step 20/44: loss=0.0242 
[epoch 26] step 22/44: loss=0.0238 
[epoch 26] step 24/44: loss=0.0240 
[epoch 26] step 26/44: loss=0.0243 
[epoch 26] step 28/44: loss=0.0250 
[epoch 26] step 30/44: loss=0.0250 
[epoch 26] step 32/44: loss=0.0255 
[epoch 26] step 34/44: loss=0.0250 
[epoch 26] step 36/44: loss=0.0243 
[epoch 26] step 38/44: loss=0.0241 
[epoch 26] step 40/44: loss=0.0238 
[epoch 26] step 42/44: loss=0.0239 
[epoch 26] step 44/44: loss=0.0242 
[epoch 26] val_loss=2.3245 qwk=('0.5200', '0.3878', '0.3924') averageQWK=0.4334 macroEMD=0.2341 tailR0=('0.1190', '0.0938', '0.0000') tailR0avg=0.0709
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    9   29    3    0
     0    5   76   39    2
     0    0   33  101    7
     0    0    2   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    4   28    7    0
     0    8   57   38    1
     0    1   44  118    0
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    1    0
     0    5   41    6    0
     0   13   98   47    0
     0    1   28   81    0
     0    0    0    3    0
[epoch 27] step 2/44: loss=0.0134 
[epoch 27] step 4/44: loss=0.0214 
[epoch 27] step 6/44: loss=0.0209 
[epoch 27] step 8/44: loss=0.0194 
[epoch 27] step 10/44: loss=0.0194 
[epoch 27] step 12/44: loss=0.0194 
[epoch 27] step 14/44: loss=0.0199 
[epoch 27] step 16/44: loss=0.0216 
[epoch 27] step 18/44: loss=0.0217 
[epoch 27] step 20/44: loss=0.0209 
[epoch 27] step 22/44: loss=0.0207 
[epoch 27] step 24/44: loss=0.0207 
[epoch 27] step 26/44: loss=0.0210 
[epoch 27] step 28/44: loss=0.0211 
[epoch 27] step 30/44: loss=0.0209 
[epoch 27] step 32/44: loss=0.0211 
[epoch 27] step 34/44: loss=0.0217 
[epoch 27] step 36/44: loss=0.0216 
[epoch 27] step 38/44: loss=0.0216 
[epoch 27] step 40/44: loss=0.0217 
[epoch 27] step 42/44: loss=0.0214 
[epoch 27] step 44/44: loss=0.0210 
[epoch 27] val_loss=2.3577 qwk=('0.4564', '0.3624', '0.3860') averageQWK=0.4016 macroEMD=0.2416 tailR0=('0.1429', '0.0938', '0.0000') tailR0avg=0.0789
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    5   30    5    1
     0    1   74   45    2
     0    0   29  105    7
     0    0    3   12    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    3   23   13    0
     0    6   51   46    1
     0    1   30  131    1
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    1    0
     0    5   42    5    0
     0   17   99   42    0
     0    1   35   74    0
     0    0    0    3    0
[epoch 28] step 2/44: loss=0.0156 
[epoch 28] step 4/44: loss=0.0149 
[epoch 28] step 6/44: loss=0.0151 
[epoch 28] step 8/44: loss=0.0158 
[epoch 28] step 10/44: loss=0.0161 
[epoch 28] step 12/44: loss=0.0161 
[epoch 28] step 14/44: loss=0.0159 
[epoch 28] step 16/44: loss=0.0162 
[epoch 28] step 18/44: loss=0.0165 
[epoch 28] step 20/44: loss=0.0168 
[epoch 28] step 22/44: loss=0.0173 
[epoch 28] step 24/44: loss=0.0180 
[epoch 28] step 26/44: loss=0.0176 
[epoch 28] step 28/44: loss=0.0173 
[epoch 28] step 30/44: loss=0.0174 
[epoch 28] step 32/44: loss=0.0174 
[epoch 28] step 34/44: loss=0.0171 
[epoch 28] step 36/44: loss=0.0169 
[epoch 28] step 38/44: loss=0.0169 
[epoch 28] step 40/44: loss=0.0171 
[epoch 28] step 42/44: loss=0.0170 
[epoch 28] step 44/44: loss=0.0169 
[epoch 28] val_loss=2.3879 qwk=('0.4986', '0.4091', '0.4047') averageQWK=0.4375 macroEMD=0.2339 tailR0=('0.1429', '0.0938', '0.0000') tailR0avg=0.0789
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    6   31    3    1
     0    4   76   40    2
     0    0   31  104    6
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    4   26    9    0
     0    7   55   41    1
     0    1   32  130    0
     0    0    2   11    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    1    0
     0    6   41    5    0
     0   19   96   43    0
     0    2   31   77    0
     0    0    0    3    0
[epoch 29] step 2/44: loss=0.0109 
[epoch 29] step 4/44: loss=0.0119 
[epoch 29] step 6/44: loss=0.0120 
[epoch 29] step 8/44: loss=0.0125 
[epoch 29] step 10/44: loss=0.0131 
[epoch 29] step 12/44: loss=0.0133 
[epoch 29] step 14/44: loss=0.0136 
[epoch 29] step 16/44: loss=0.0142 
[epoch 29] step 18/44: loss=0.0140 
[epoch 29] step 20/44: loss=0.0142 
[epoch 29] step 22/44: loss=0.0143 
[epoch 29] step 24/44: loss=0.0140 
[epoch 29] step 26/44: loss=0.0139 
[epoch 29] step 28/44: loss=0.0135 
[epoch 29] step 30/44: loss=0.0138 
[epoch 29] step 32/44: loss=0.0142 
[epoch 29] step 34/44: loss=0.0144 
[epoch 29] step 36/44: loss=0.0144 
[epoch 29] step 38/44: loss=0.0143 
[epoch 29] step 40/44: loss=0.0143 
[epoch 29] step 42/44: loss=0.0150 
[epoch 29] step 44/44: loss=0.0148 
[epoch 29] val_loss=2.3976 qwk=('0.4934', '0.4127', '0.4169') averageQWK=0.4410 macroEMD=0.2330 tailR0=('0.1190', '0.0625', '0.0000') tailR0avg=0.0605
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   30    3    1
     0    4   77   40    1
     0    0   32  105    4
     0    0    3   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    5   25    9    0
     0    6   54   44    0
     0    1   34  128    0
     0    0    2   12    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    1    0
     0    7   40    5    0
     0   20   95   43    0
     0    2   29   79    0
     0    0    0    3    0
[epoch 30] step 2/44: loss=0.0089 
[epoch 30] step 4/44: loss=0.0105 
[epoch 30] step 6/44: loss=0.0118 
[epoch 30] step 8/44: loss=0.0125 
[epoch 30] step 10/44: loss=0.0128 
[epoch 30] step 12/44: loss=0.0126 
[epoch 30] step 14/44: loss=0.0132 
[epoch 30] step 16/44: loss=0.0135 
[epoch 30] step 18/44: loss=0.0136 
[epoch 30] step 20/44: loss=0.0135 
[epoch 30] step 22/44: loss=0.0132 
[epoch 30] step 24/44: loss=0.0132 
[epoch 30] step 26/44: loss=0.0143 
[epoch 30] step 28/44: loss=0.0139 
[epoch 30] step 30/44: loss=0.0140 
[epoch 30] step 32/44: loss=0.0139 
[epoch 30] step 34/44: loss=0.0138 
[epoch 30] step 36/44: loss=0.0135 
[epoch 30] step 38/44: loss=0.0136 
[epoch 30] step 40/44: loss=0.0133 
[epoch 30] step 42/44: loss=0.0130 
[epoch 30] step 44/44: loss=0.0127 
[epoch 30] val_loss=2.4589 qwk=('0.4842', '0.4192', '0.3960') averageQWK=0.4331 macroEMD=0.2362 tailR0=('0.1429', '0.0938', '0.0000') tailR0avg=0.0789
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    5   31    4    1
     0    3   74   43    2
     0    0   28  109    4
     0    0    1   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    4   28    7    0
     0    5   58   41    0
     0    1   33  129    0
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    1    0
     0    5   41    6    0
     0   16   96   46    0
     0    1   27   82    0
     0    0    0    3    0
[epoch 31] step 2/44: loss=0.0085 
[epoch 31] step 4/44: loss=0.0113 
[epoch 31] step 6/44: loss=0.0119 
[epoch 31] step 8/44: loss=0.0115 
[epoch 31] step 10/44: loss=0.0120 
[epoch 31] step 12/44: loss=0.0139 
[epoch 31] step 14/44: loss=0.0132 
[epoch 31] step 16/44: loss=0.0128 
[epoch 31] step 18/44: loss=0.0123 
[epoch 31] step 20/44: loss=0.0119 
[epoch 31] step 22/44: loss=0.0118 
[epoch 31] step 24/44: loss=0.0119 
[epoch 31] step 26/44: loss=0.0118 
[epoch 31] step 28/44: loss=0.0117 
[epoch 31] step 30/44: loss=0.0116 
[epoch 31] step 32/44: loss=0.0115 
[epoch 31] step 34/44: loss=0.0117 
[epoch 31] step 36/44: loss=0.0115 
[epoch 31] step 38/44: loss=0.0114 
[epoch 31] step 40/44: loss=0.0113 
[epoch 31] step 42/44: loss=0.0113 
[epoch 31] step 44/44: loss=0.0111 
[epoch 31] val_loss=2.4942 qwk=('0.4924', '0.4081', '0.4224') averageQWK=0.4410 macroEMD=0.2341 tailR0=('0.1429', '0.0625', '0.0000') tailR0avg=0.0685
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    5   31    4    1
     0    2   77   41    2
     0    0   27  108    6
     0    0    1   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    4   26    9    0
     0    7   51   45    1
     0    1   30  132    0
     0    0    1   13    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    1    0
     0    7   39    6    0
     0   20   95   43    0
     0    1   31   78    0
     0    0    0    3    0
[epoch 32] step 2/44: loss=0.0099 
[epoch 32] step 4/44: loss=0.0118 
[epoch 32] step 6/44: loss=0.0106 
[epoch 32] step 8/44: loss=0.0098 
[epoch 32] step 10/44: loss=0.0103 
[epoch 32] step 12/44: loss=0.0097 
[epoch 32] step 14/44: loss=0.0097 
[epoch 32] step 16/44: loss=0.0096 
[epoch 32] step 18/44: loss=0.0096 
[epoch 32] step 20/44: loss=0.0094 
[epoch 32] step 22/44: loss=0.0094 
[epoch 32] step 24/44: loss=0.0101 
[epoch 32] step 26/44: loss=0.0101 
[epoch 32] step 28/44: loss=0.0100 
[epoch 32] step 30/44: loss=0.0097 
[epoch 32] step 32/44: loss=0.0098 
[epoch 32] step 34/44: loss=0.0100 
[epoch 32] step 36/44: loss=0.0100 
[epoch 32] step 38/44: loss=0.0101 
[epoch 32] step 40/44: loss=0.0100 
[epoch 32] step 42/44: loss=0.0099 
[epoch 32] step 44/44: loss=0.0102 
[epoch 32] val_loss=2.5299 qwk=('0.4862', '0.3963', '0.3898') averageQWK=0.4241 macroEMD=0.2351 tailR0=('0.1429', '0.0938', '0.0000') tailR0avg=0.0789
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    5   31    4    1
     0    4   75   41    2
     0    0   29  106    6
     0    0    1   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    4   26    9    0
     0    7   55   41    1
     0    1   34  127    1
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    1    0
     0    5   39    8    0
     0   15   91   52    0
     0    1   23   86    0
     0    0    0    3    0
[epoch 33] step 2/44: loss=0.0097 
[epoch 33] step 4/44: loss=0.0095 
[epoch 33] step 6/44: loss=0.0094 
[epoch 33] step 8/44: loss=0.0099 
[epoch 33] step 10/44: loss=0.0094 
[epoch 33] step 12/44: loss=0.0098 
[epoch 33] step 14/44: loss=0.0104 
[epoch 33] step 16/44: loss=0.0099 
[epoch 33] step 18/44: loss=0.0096 
[epoch 33] step 20/44: loss=0.0094 
[epoch 33] step 22/44: loss=0.0097 
[epoch 33] step 24/44: loss=0.0093 
[epoch 33] step 26/44: loss=0.0091 
[epoch 33] step 28/44: loss=0.0089 
[epoch 33] step 30/44: loss=0.0089 
[epoch 33] step 32/44: loss=0.0088 
[epoch 33] step 34/44: loss=0.0090 
[epoch 33] step 36/44: loss=0.0089 
[epoch 33] step 38/44: loss=0.0088 
[epoch 33] step 40/44: loss=0.0089 
[epoch 33] step 42/44: loss=0.0089 
[epoch 33] step 44/44: loss=0.0086 
[epoch 33] val_loss=2.5045 qwk=('0.4837', '0.4282', '0.3892') averageQWK=0.4337 macroEMD=0.2328 tailR0=('0.1429', '0.0625', '0.0000') tailR0avg=0.0685
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    5   31    4    1
     0    4   76   40    2
     0    0   32  104    5
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    5   25    9    0
     0    9   52   43    0
     0    1   33  129    0
     0    0    2   12    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    1    0
     0    6   41    5    0
     0   18   96   44    0
     0    2   32   76    0
     0    0    0    3    0
[epoch 34] step 2/44: loss=0.0073 
[epoch 34] step 4/44: loss=0.0069 
[epoch 34] step 6/44: loss=0.0092 
[epoch 34] step 8/44: loss=0.0094 
[epoch 34] step 10/44: loss=0.0094 
[epoch 34] step 12/44: loss=0.0095 
[epoch 34] step 14/44: loss=0.0096 
[epoch 34] step 16/44: loss=0.0092 
[epoch 34] step 18/44: loss=0.0089 
[epoch 34] step 20/44: loss=0.0086 
[epoch 34] step 22/44: loss=0.0084 
[epoch 34] step 24/44: loss=0.0082 
[epoch 34] step 26/44: loss=0.0081 
[epoch 34] step 28/44: loss=0.0079 
[epoch 34] step 30/44: loss=0.0078 
[epoch 34] step 32/44: loss=0.0081 
[epoch 34] step 34/44: loss=0.0080 
[epoch 34] step 36/44: loss=0.0082 
[epoch 34] step 38/44: loss=0.0083 
[epoch 34] step 40/44: loss=0.0083 
[epoch 34] step 42/44: loss=0.0083 
[epoch 34] step 44/44: loss=0.0088 
[epoch 34] val_loss=2.5195 qwk=('0.4836', '0.4018', '0.3777') averageQWK=0.4210 macroEMD=0.2348 tailR0=('0.1429', '0.0625', '0.0000') tailR0avg=0.0685
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    5   31    4    1
     0    3   77   40    2
     0    0   32  105    4
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    4   26    9    0
     0    8   54   42    0
     0    1   34  128    0
     0    0    2   12    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    1    0
     0    5   41    6    0
     0   17   97   44    0
     0    2   32   76    0
     0    0    0    3    0
[epoch 35] step 2/44: loss=0.0066 
[epoch 35] step 4/44: loss=0.0080 
[epoch 35] step 6/44: loss=0.0094 
[epoch 35] step 8/44: loss=0.0089 
[epoch 35] step 10/44: loss=0.0088 
[epoch 35] step 12/44: loss=0.0096 
[epoch 35] step 14/44: loss=0.0093 
[epoch 35] step 16/44: loss=0.0093 
[epoch 35] step 18/44: loss=0.0093 
[epoch 35] step 20/44: loss=0.0089 
[epoch 35] step 22/44: loss=0.0086 
[epoch 35] step 24/44: loss=0.0084 
[epoch 35] step 26/44: loss=0.0082 
[epoch 35] step 28/44: loss=0.0080 
[epoch 35] step 30/44: loss=0.0079 
[epoch 35] step 32/44: loss=0.0080 
[epoch 35] step 34/44: loss=0.0079 
[epoch 35] step 36/44: loss=0.0081 
[epoch 35] step 38/44: loss=0.0080 
[epoch 35] step 40/44: loss=0.0080 
[epoch 35] step 42/44: loss=0.0085 
[epoch 35] step 44/44: loss=0.0087 
[epoch 35] val_loss=2.5347 qwk=('0.4890', '0.3931', '0.3775') averageQWK=0.4199 macroEMD=0.2346 tailR0=('0.1429', '0.0625', '0.0000') tailR0avg=0.0685
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    5   31    4    1
     0    4   76   40    2
     0    0   30  107    4
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    4   26    9    0
     0    8   55   41    0
     0    1   35  127    0
     0    0    3   11    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    1    0
     0    5   41    6    0
     0   17   97   44    0
     0    1   32   77    0
     0    0    0    3    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/ce/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/ce/fold1/metrics.json
Done.
