[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.9392 
[epoch 1] step 4/44: loss=0.9408 
[epoch 1] step 6/44: loss=0.9413 
[epoch 1] step 8/44: loss=0.9467 
[epoch 1] step 10/44: loss=0.9487 
[epoch 1] step 12/44: loss=0.9468 
[epoch 1] step 14/44: loss=0.9502 
[epoch 1] step 16/44: loss=0.9483 
[epoch 1] step 18/44: loss=0.9491 
[epoch 1] step 20/44: loss=0.9504 
[epoch 1] step 22/44: loss=0.9496 
[epoch 1] step 24/44: loss=0.9508 
[epoch 1] step 26/44: loss=0.9482 
[epoch 1] step 28/44: loss=0.9443 
[epoch 1] step 30/44: loss=0.9434 
[epoch 1] step 32/44: loss=0.9395 
[epoch 1] step 34/44: loss=0.9353 
[epoch 1] step 36/44: loss=0.9320 
[epoch 1] step 38/44: loss=0.9280 
[epoch 1] step 40/44: loss=0.9225 
[epoch 1] step 42/44: loss=0.9170 
[epoch 1] step 44/44: loss=0.9117 
[epoch 1] val_loss=1.6155 qwk=('-0.1842', '-0.0076', '0.0205') averageQWK=-0.0571 macroEMD=0.3842 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    3    0
     0    2   50   46    0
     0    5  106   44    0
     0    0   52    7    0
     0    0    6    0    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   14    0    0
     1    0   81    0    0
     1    0  165    0    0
     1    0   60    0    0
     0    0    2    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    0    5
     0   10    6    2   86
     0    5    6    2  167
     0    2    1    0   33
     0    0    0    0    0
[epoch 2] step 2/44: loss=0.8009 
[epoch 2] step 4/44: loss=0.7800 
[epoch 2] step 6/44: loss=0.7656 
[epoch 2] step 8/44: loss=0.7538 
[epoch 2] step 10/44: loss=0.7442 
[epoch 2] step 12/44: loss=0.7318 
[epoch 2] step 14/44: loss=0.7207 
[epoch 2] step 16/44: loss=0.7214 
[epoch 2] step 18/44: loss=0.7088 
[epoch 2] step 20/44: loss=0.7063 
[epoch 2] step 22/44: loss=0.7048 
[epoch 2] step 24/44: loss=0.6978 
[epoch 2] step 26/44: loss=0.6928 
[epoch 2] step 28/44: loss=0.6896 
[epoch 2] step 30/44: loss=0.6865 
[epoch 2] step 32/44: loss=0.6833 
[epoch 2] step 34/44: loss=0.6790 
[epoch 2] step 36/44: loss=0.6776 
[epoch 2] step 38/44: loss=0.6755 
[epoch 2] step 40/44: loss=0.6707 
[epoch 2] step 42/44: loss=0.6692 
[epoch 2] step 44/44: loss=0.6655 
[epoch 2] val_loss=1.2389 qwk=('0.1443', '0.2467', '0.0209') averageQWK=0.1373 macroEMD=0.3153 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    6    0
     0    0   49   49    0
     0    0   46  109    0
     0    0    3   56    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    3    0
     0    0   75    7    0
     0    0  138   28    0
     0    0   23   38    0
     0    0    1    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    0  103    1    0
     0    0  180    0    0
     0    0   34    2    0
     0    0    0    0    0
[epoch 3] step 2/44: loss=0.5849 
[epoch 3] step 4/44: loss=0.5858 
[epoch 3] step 6/44: loss=0.5842 
[epoch 3] step 8/44: loss=0.5989 
[epoch 3] step 10/44: loss=0.5911 
[epoch 3] step 12/44: loss=0.5913 
[epoch 3] step 14/44: loss=0.5844 
[epoch 3] step 16/44: loss=0.5726 
[epoch 3] step 18/44: loss=0.5705 
[epoch 3] step 20/44: loss=0.5679 
[epoch 3] step 22/44: loss=0.5591 
[epoch 3] step 24/44: loss=0.5564 
[epoch 3] step 26/44: loss=0.5607 
[epoch 3] step 28/44: loss=0.5604 
[epoch 3] step 30/44: loss=0.5650 
[epoch 3] step 32/44: loss=0.5629 
[epoch 3] step 34/44: loss=0.5572 
[epoch 3] step 36/44: loss=0.5580 
[epoch 3] step 38/44: loss=0.5570 
[epoch 3] step 40/44: loss=0.5588 
[epoch 3] step 42/44: loss=0.5583 
[epoch 3] step 44/44: loss=0.5563 
[epoch 3] val_loss=1.4112 qwk=('0.1456', '0.2018', '0.1813') averageQWK=0.1763 macroEMD=0.2994 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    6    0
     0    3   42   53    0
     0    1   43  111    0
     0    0    3   56    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    6    0
     0    0   53   29    0
     0    0   62  104    0
     0    0    5   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0    0   75   29    0
     0    0   83   97    0
     0    0    7   29    0
     0    0    0    0    0
[epoch 4] step 2/44: loss=0.5571 
[epoch 4] step 4/44: loss=0.5291 
[epoch 4] step 6/44: loss=0.5328 
[epoch 4] step 8/44: loss=0.5225 
[epoch 4] step 10/44: loss=0.5228 
[epoch 4] step 12/44: loss=0.5241 
[epoch 4] step 14/44: loss=0.5202 
[epoch 4] step 16/44: loss=0.5189 
[epoch 4] step 18/44: loss=0.5163 
[epoch 4] step 20/44: loss=0.5187 
[epoch 4] step 22/44: loss=0.5136 
[epoch 4] step 24/44: loss=0.5123 
[epoch 4] step 26/44: loss=0.5129 
[epoch 4] step 28/44: loss=0.5114 
[epoch 4] step 30/44: loss=0.5079 
[epoch 4] step 32/44: loss=0.5050 
[epoch 4] step 34/44: loss=0.5043 
[epoch 4] step 36/44: loss=0.5037 
[epoch 4] step 38/44: loss=0.5022 
[epoch 4] step 40/44: loss=0.5008 
[epoch 4] step 42/44: loss=0.4987 
[epoch 4] step 44/44: loss=0.4971 
[epoch 4] val_loss=1.4740 qwk=('0.2047', '0.1682', '0.1776') averageQWK=0.1835 macroEMD=0.2920 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     0    7   51   40    0
     0    3   62   90    0
     0    0    8   51    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    6    0
     0    0   45   37    0
     0    0   61  105    0
     0    0    5   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    3    2    0
     0    3   74   27    0
     0    0   88   92    0
     0    0    9   27    0
     0    0    0    0    0
[epoch 5] step 2/44: loss=0.4566 
[epoch 5] step 4/44: loss=0.4628 
[epoch 5] step 6/44: loss=0.4679 
[epoch 5] step 8/44: loss=0.4680 
[epoch 5] step 10/44: loss=0.4670 
[epoch 5] step 12/44: loss=0.4605 
[epoch 5] step 14/44: loss=0.4629 
[epoch 5] step 16/44: loss=0.4614 
[epoch 5] step 18/44: loss=0.4660 
[epoch 5] step 20/44: loss=0.4651 
[epoch 5] step 22/44: loss=0.4632 
[epoch 5] step 24/44: loss=0.4625 
[epoch 5] step 26/44: loss=0.4718 
[epoch 5] step 28/44: loss=0.4733 
[epoch 5] step 30/44: loss=0.4683 
[epoch 5] step 32/44: loss=0.4675 
[epoch 5] step 34/44: loss=0.4652 
[epoch 5] step 36/44: loss=0.4663 
[epoch 5] step 38/44: loss=0.4686 
[epoch 5] step 40/44: loss=0.4654 
[epoch 5] step 42/44: loss=0.4650 
[epoch 5] step 44/44: loss=0.4643 
[epoch 5] val_loss=1.2012 qwk=('0.3377', '0.3018', '0.3390') averageQWK=0.3262 macroEMD=0.2717 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    4    0
     0   41   43   14    0
     0   25   82   48    0
     0    3   24   32    0
     0    0    1    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    6    0
     0   23   39   20    0
     0   19   66   81    0
     0    0   11   50    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   47   48    9    0
     0   43  101   36    0
     0    0   18   18    0
     0    0    0    0    0
[epoch 6] step 2/44: loss=0.4795 
[epoch 6] step 4/44: loss=0.4578 
[epoch 6] step 6/44: loss=0.4566 
[epoch 6] step 8/44: loss=0.4464 
[epoch 6] step 10/44: loss=0.4339 
[epoch 6] step 12/44: loss=0.4380 
[epoch 6] step 14/44: loss=0.4421 
[epoch 6] step 16/44: loss=0.4364 
[epoch 6] step 18/44: loss=0.4295 
[epoch 6] step 20/44: loss=0.4310 
[epoch 6] step 22/44: loss=0.4292 
[epoch 6] step 24/44: loss=0.4300 
[epoch 6] step 26/44: loss=0.4278 
[epoch 6] step 28/44: loss=0.4275 
[epoch 6] step 30/44: loss=0.4267 
[epoch 6] step 32/44: loss=0.4249 
[epoch 6] step 34/44: loss=0.4258 
[epoch 6] step 36/44: loss=0.4219 
[epoch 6] step 38/44: loss=0.4220 
[epoch 6] step 40/44: loss=0.4230 
[epoch 6] step 42/44: loss=0.4244 
[epoch 6] step 44/44: loss=0.4227 
[epoch 6] val_loss=1.5902 qwk=('0.2321', '0.1505', '0.2330') averageQWK=0.2052 macroEMD=0.2857 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0   26   29   43    0
     0    9   48   98    0
     0    1    8   50    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    8    0
     0    1   43   38    0
     0    0   63  103    0
     0    0    5   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0   20   56   28    0
     0    6   90   84    0
     0    0    9   27    0
     0    0    0    0    0
[epoch 7] step 2/44: loss=0.4882 
[epoch 7] step 4/44: loss=0.4631 
[epoch 7] step 6/44: loss=0.4652 
[epoch 7] step 8/44: loss=0.4634 
[epoch 7] step 10/44: loss=0.4633 
[epoch 7] step 12/44: loss=0.4583 
[epoch 7] step 14/44: loss=0.4486 
[epoch 7] step 16/44: loss=0.4398 
[epoch 7] step 18/44: loss=0.4375 
[epoch 7] step 20/44: loss=0.4297 
[epoch 7] step 22/44: loss=0.4272 
[epoch 7] step 24/44: loss=0.4351 
[epoch 7] step 26/44: loss=0.4348 
[epoch 7] step 28/44: loss=0.4310 
[epoch 7] step 30/44: loss=0.4323 
[epoch 7] step 32/44: loss=0.4377 
[epoch 7] step 34/44: loss=0.4415 
[epoch 7] step 36/44: loss=0.4403 
[epoch 7] step 38/44: loss=0.4391 
[epoch 7] step 40/44: loss=0.4411 
[epoch 7] step 42/44: loss=0.4408 
[epoch 7] step 44/44: loss=0.4360 
[epoch 7] val_loss=1.4833 qwk=('0.2307', '0.2310', '0.2404') averageQWK=0.2341 macroEMD=0.2799 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0   24   36   38    0
     0   10   63   82    0
     0    1   12   46    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    7    0
     0   19   29   34    0
     0   11   55  100    0
     0    0    9   52    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   25   54   25    0
     0   15   92   73    0
     0    0   12   24    0
     0    0    0    0    0
[epoch 8] step 2/44: loss=0.3522 
[epoch 8] step 4/44: loss=0.3695 
[epoch 8] step 6/44: loss=0.3755 
[epoch 8] step 8/44: loss=0.3911 
[epoch 8] step 10/44: loss=0.3823 
[epoch 8] step 12/44: loss=0.3851 
[epoch 8] step 14/44: loss=0.3980 
[epoch 8] step 16/44: loss=0.4022 
[epoch 8] step 18/44: loss=0.3956 
[epoch 8] step 20/44: loss=0.3911 
[epoch 8] step 22/44: loss=0.3934 
[epoch 8] step 24/44: loss=0.3941 
[epoch 8] step 26/44: loss=0.3977 
[epoch 8] step 28/44: loss=0.3947 
[epoch 8] step 30/44: loss=0.3934 
[epoch 8] step 32/44: loss=0.3941 
[epoch 8] step 34/44: loss=0.3921 
[epoch 8] step 36/44: loss=0.3899 
[epoch 8] step 38/44: loss=0.3910 
[epoch 8] step 40/44: loss=0.3898 
[epoch 8] step 42/44: loss=0.3878 
[epoch 8] step 44/44: loss=0.3875 
[epoch 8] val_loss=1.2201 qwk=('0.3029', '0.3305', '0.3434') averageQWK=0.3256 macroEMD=0.2570 tailR0=('0.1667', '0.0000', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    2    1
     0   30   54   14    0
     0   14  107   33    1
     0    1   33   23    2
     0    0    1    3    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    5    0
     0   34   34   14    0
     0   29   72   65    0
     0    1   22   38    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   50   47    7    0
     0   42  116   22    0
     0    0   24   12    0
     0    0    0    0    0
[epoch 9] step 2/44: loss=0.3670 
[epoch 9] step 4/44: loss=0.3824 
[epoch 9] step 6/44: loss=0.3751 
[epoch 9] step 8/44: loss=0.3741 
[epoch 9] step 10/44: loss=0.3716 
[epoch 9] step 12/44: loss=0.3585 
[epoch 9] step 14/44: loss=0.3608 
[epoch 9] step 16/44: loss=0.3591 
[epoch 9] step 18/44: loss=0.3565 
[epoch 9] step 20/44: loss=0.3553 
[epoch 9] step 22/44: loss=0.3529 
[epoch 9] step 24/44: loss=0.3507 
[epoch 9] step 26/44: loss=0.3495 
[epoch 9] step 28/44: loss=0.3473 
[epoch 9] step 30/44: loss=0.3449 
[epoch 9] step 32/44: loss=0.3457 
[epoch 9] step 34/44: loss=0.3438 
[epoch 9] step 36/44: loss=0.3445 
[epoch 9] step 38/44: loss=0.3445 
[epoch 9] step 40/44: loss=0.3452 
[epoch 9] step 42/44: loss=0.3457 
[epoch 9] step 44/44: loss=0.3460 
[epoch 9] val_loss=1.6507 qwk=('0.2788', '0.2792', '0.2641') averageQWK=0.2740 macroEMD=0.2634 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     0   30   33   35    0
     0    9   64   82    0
     0    1   11   47    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    6    0
     0   22   32   28    0
     0   16   65   85    0
     0    0   11   50    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   43   34   27    0
     0   38   73   69    0
     0    0   11   25    0
     0    0    0    0    0
[epoch 10] step 2/44: loss=0.2908 
[epoch 10] step 4/44: loss=0.3271 
[epoch 10] step 6/44: loss=0.3184 
[epoch 10] step 8/44: loss=0.3071 
[epoch 10] step 10/44: loss=0.3056 
[epoch 10] step 12/44: loss=0.3026 
[epoch 10] step 14/44: loss=0.3012 
[epoch 10] step 16/44: loss=0.3020 
[epoch 10] step 18/44: loss=0.3055 
[epoch 10] step 20/44: loss=0.3073 
[epoch 10] step 22/44: loss=0.3103 
[epoch 10] step 24/44: loss=0.3172 
[epoch 10] step 26/44: loss=0.3177 
[epoch 10] step 28/44: loss=0.3194 
[epoch 10] step 30/44: loss=0.3196 
[epoch 10] step 32/44: loss=0.3193 
[epoch 10] step 34/44: loss=0.3194 
[epoch 10] step 36/44: loss=0.3184 
[epoch 10] step 38/44: loss=0.3160 
[epoch 10] step 40/44: loss=0.3139 
[epoch 10] step 42/44: loss=0.3128 
[epoch 10] step 44/44: loss=0.3154 
[epoch 10] val_loss=1.6140 qwk=('0.2622', '0.2721', '0.2366') averageQWK=0.2570 macroEMD=0.2663 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0   30   44   24    0
     0   14   72   69    0
     0    1   22   36    0
     0    0    1    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    7    0
     0   22   38   22    0
     0   13   75   78    0
     0    0   18   43    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   27   61   16    0
     0   22  116   42    0
     0    0   18   18    0
     0    0    0    0    0
[epoch 11] step 2/44: loss=0.3104 
[epoch 11] step 4/44: loss=0.3189 
[epoch 11] step 6/44: loss=0.2980 
[epoch 11] step 8/44: loss=0.2985 
[epoch 11] step 10/44: loss=0.2852 
[epoch 11] step 12/44: loss=0.2986 
[epoch 11] step 14/44: loss=0.2995 
[epoch 11] step 16/44: loss=0.2963 
[epoch 11] step 18/44: loss=0.2965 
[epoch 11] step 20/44: loss=0.3094 
[epoch 11] step 22/44: loss=0.3206 
[epoch 11] step 24/44: loss=0.3189 
[epoch 11] step 26/44: loss=0.3189 
[epoch 11] step 28/44: loss=0.3216 
[epoch 11] step 30/44: loss=0.3218 
[epoch 11] step 32/44: loss=0.3193 
[epoch 11] step 34/44: loss=0.3166 
[epoch 11] step 36/44: loss=0.3164 
[epoch 11] step 38/44: loss=0.3154 
[epoch 11] step 40/44: loss=0.3148 
[epoch 11] step 42/44: loss=0.3118 
[epoch 11] step 44/44: loss=0.3087 
[epoch 11] val_loss=1.5925 qwk=('0.2906', '0.2782', '0.2500') averageQWK=0.2729 macroEMD=0.2615 tailR0=('0.2500', '0.0000', '0.0000') tailR0avg=0.0833
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    4    1
     0   36   30   31    1
     0   24   54   73    4
     0    1   12   44    2
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    7    0
     0   29   28   25    0
     0   27   57   82    0
     0    1   13   47    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   32   59   13    0
     0   33  103   44    0
     0    0   19   17    0
     0    0    0    0    0
[epoch 12] step 2/44: loss=0.2577 
[epoch 12] step 4/44: loss=0.2705 
[epoch 12] step 6/44: loss=0.2738 
[epoch 12] step 8/44: loss=0.2595 
[epoch 12] step 10/44: loss=0.2732 
[epoch 12] step 12/44: loss=0.2739 
[epoch 12] step 14/44: loss=0.2756 
[epoch 12] step 16/44: loss=0.2691 
[epoch 12] step 18/44: loss=0.2681 
[epoch 12] step 20/44: loss=0.2667 
[epoch 12] step 22/44: loss=0.2643 
[epoch 12] step 24/44: loss=0.2649 
[epoch 12] step 26/44: loss=0.2653 
[epoch 12] step 28/44: loss=0.2661 
[epoch 12] step 30/44: loss=0.2659 
[epoch 12] step 32/44: loss=0.2662 
[epoch 12] step 34/44: loss=0.2664 
[epoch 12] step 36/44: loss=0.2666 
[epoch 12] step 38/44: loss=0.2669 
[epoch 12] step 40/44: loss=0.2653 
[epoch 12] step 42/44: loss=0.2639 
[epoch 12] step 44/44: loss=0.2612 
[epoch 12] val_loss=1.4864 qwk=('0.3413', '0.3270', '0.3300') averageQWK=0.3328 macroEMD=0.2504 tailR0=('0.3333', '0.0357', '0.0000') tailR0avg=0.1230
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    3    1
     0   46   30   20    2
     0   35   54   58    8
     0    2   18   31    8
     0    0    1    1    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    6    0
     1   36   24   21    0
     0   38   54   74    0
     0    1   15   43    2
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   45   51    8    0
     0   37  112   31    0
     0    0   21   15    0
     0    0    0    0    0
[epoch 13] step 2/44: loss=0.2602 
[epoch 13] step 4/44: loss=0.2425 
[epoch 13] step 6/44: loss=0.2436 
[epoch 13] step 8/44: loss=0.2549 
[epoch 13] step 10/44: loss=0.2580 
[epoch 13] step 12/44: loss=0.2561 
[epoch 13] step 14/44: loss=0.2522 
[epoch 13] step 16/44: loss=0.2475 
[epoch 13] step 18/44: loss=0.2516 
[epoch 13] step 20/44: loss=0.2474 
[epoch 13] step 22/44: loss=0.2469 
[epoch 13] step 24/44: loss=0.2440 
[epoch 13] step 26/44: loss=0.2436 
[epoch 13] step 28/44: loss=0.2434 
[epoch 13] step 30/44: loss=0.2431 
[epoch 13] step 32/44: loss=0.2392 
[epoch 13] step 34/44: loss=0.2398 
[epoch 13] step 36/44: loss=0.2378 
[epoch 13] step 38/44: loss=0.2374 
[epoch 13] step 40/44: loss=0.2374 
[epoch 13] step 42/44: loss=0.2380 
[epoch 13] step 44/44: loss=0.2364 
[epoch 13] val_loss=1.7338 qwk=('0.2970', '0.3005', '0.2481') averageQWK=0.2819 macroEMD=0.2567 tailR0=('0.2500', '0.0357', '0.0000') tailR0avg=0.0952
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    4    1
     2   33   34   28    1
     0   20   60   71    4
     0    1   15   41    2
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    6    0
     1   27   30   24    0
     1   18   72   75    0
     0    1   14   46    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   29   59   16    0
     0   28  109   43    0
     0    0   16   20    0
     0    0    0    0    0
[epoch 14] step 2/44: loss=0.2092 
[epoch 14] step 4/44: loss=0.2047 
[epoch 14] step 6/44: loss=0.2017 
[epoch 14] step 8/44: loss=0.2019 
[epoch 14] step 10/44: loss=0.2045 
[epoch 14] step 12/44: loss=0.1999 
[epoch 14] step 14/44: loss=0.2016 
[epoch 14] step 16/44: loss=0.2005 
[epoch 14] step 18/44: loss=0.2020 
[epoch 14] step 20/44: loss=0.2000 
[epoch 14] step 22/44: loss=0.2010 
[epoch 14] step 24/44: loss=0.2035 
[epoch 14] step 26/44: loss=0.2041 
[epoch 14] step 28/44: loss=0.2051 
[epoch 14] step 30/44: loss=0.2036 
[epoch 14] step 32/44: loss=0.2053 
[epoch 14] step 34/44: loss=0.2096 
[epoch 14] step 36/44: loss=0.2069 
[epoch 14] step 38/44: loss=0.2053 
[epoch 14] step 40/44: loss=0.2044 
[epoch 14] step 42/44: loss=0.2044 
[epoch 14] step 44/44: loss=0.2036 
[epoch 14] val_loss=1.6658 qwk=('0.3422', '0.3465', '0.2821') averageQWK=0.3236 macroEMD=0.2447 tailR0=('0.0000', '0.0357', '0.0000') tailR0avg=0.0119
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    5    0
     4   39   33   22    0
     0   29   65   61    0
     0    1   17   41    0
     0    0    1    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    5    0
     3   32   28   19    0
     4   28   70   64    0
     0    0   15   46    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   36   60    8    0
     0   32  122   26    0
     0    0   23   13    0
     0    0    0    0    0
[epoch 15] step 2/44: loss=0.1895 
[epoch 15] step 4/44: loss=0.2012 
[epoch 15] step 6/44: loss=0.1952 
[epoch 15] step 8/44: loss=0.1866 
[epoch 15] step 10/44: loss=0.1871 
[epoch 15] step 12/44: loss=0.1907 
[epoch 15] step 14/44: loss=0.1901 
[epoch 15] step 16/44: loss=0.1927 
[epoch 15] step 18/44: loss=0.1987 
[epoch 15] step 20/44: loss=0.1963 
[epoch 15] step 22/44: loss=0.1962 
[epoch 15] step 24/44: loss=0.1980 
[epoch 15] step 26/44: loss=0.1973 
[epoch 15] step 28/44: loss=0.1949 
[epoch 15] step 30/44: loss=0.1935 
[epoch 15] step 32/44: loss=0.1945 
[epoch 15] step 34/44: loss=0.1929 
[epoch 15] step 36/44: loss=0.1892 
[epoch 15] step 38/44: loss=0.1904 
[epoch 15] step 40/44: loss=0.1876 
[epoch 15] step 42/44: loss=0.1883 
[epoch 15] step 44/44: loss=0.1853 
[epoch 15] val_loss=1.9907 qwk=('0.3123', '0.3264', '0.3393') averageQWK=0.3260 macroEMD=0.2470 tailR0=('0.0833', '0.0357', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    5    0
     6   29   32   30    1
     0   22   50   82    1
     0    1   11   46    1
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    7    0
     2   32   21   26    1
     2   25   51   88    0
     0    0    5   55    1
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   35   59   10    0
     0   33  103   44    0
     0    0   12   24    0
     0    0    0    0    0
[epoch 16] step 2/44: loss=0.1850 
[epoch 16] step 4/44: loss=0.1589 
[epoch 16] step 6/44: loss=0.1592 
[epoch 16] step 8/44: loss=0.1564 
[epoch 16] step 10/44: loss=0.1600 
[epoch 16] step 12/44: loss=0.1626 
[epoch 16] step 14/44: loss=0.1661 
[epoch 16] step 16/44: loss=0.1718 
[epoch 16] step 18/44: loss=0.1717 
[epoch 16] step 20/44: loss=0.1727 
[epoch 16] step 22/44: loss=0.1739 
[epoch 16] step 24/44: loss=0.1757 
[epoch 16] step 26/44: loss=0.1770 
[epoch 16] step 28/44: loss=0.1771 
[epoch 16] step 30/44: loss=0.1761 
[epoch 16] step 32/44: loss=0.1729 
[epoch 16] step 34/44: loss=0.1725 
[epoch 16] step 36/44: loss=0.1733 
[epoch 16] step 38/44: loss=0.1726 
[epoch 16] step 40/44: loss=0.1729 
[epoch 16] step 42/44: loss=0.1728 
[epoch 16] step 44/44: loss=0.1735 
[epoch 16] val_loss=1.8101 qwk=('0.3211', '0.2990', '0.2331') averageQWK=0.2844 macroEMD=0.2488 tailR0=('0.1667', '0.0357', '0.0000') tailR0avg=0.0675
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     3   33   38   24    0
     0   24   68   61    2
     0    1   19   37    2
     0    0    1    3    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    7    0
     1   34   20   26    1
     2   26   55   83    0
     0    2    8   50    1
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   27   66   11    0
     0   23  124   33    0
     0    0   22   14    0
     0    0    0    0    0
[epoch 17] step 2/44: loss=0.1384 
[epoch 17] step 4/44: loss=0.1411 
[epoch 17] step 6/44: loss=0.1524 
[epoch 17] step 8/44: loss=0.1487 
[epoch 17] step 10/44: loss=0.1460 
[epoch 17] step 12/44: loss=0.1460 
[epoch 17] step 14/44: loss=0.1460 
[epoch 17] step 16/44: loss=0.1441 
[epoch 17] step 18/44: loss=0.1449 
[epoch 17] step 20/44: loss=0.1483 
[epoch 17] step 22/44: loss=0.1462 
[epoch 17] step 24/44: loss=0.1465 
[epoch 17] step 26/44: loss=0.1479 
[epoch 17] step 28/44: loss=0.1497 
[epoch 17] step 30/44: loss=0.1518 
[epoch 17] step 32/44: loss=0.1515 
[epoch 17] step 34/44: loss=0.1508 
[epoch 17] step 36/44: loss=0.1494 
[epoch 17] step 38/44: loss=0.1477 
[epoch 17] step 40/44: loss=0.1490 
[epoch 17] step 42/44: loss=0.1494 
[epoch 17] step 44/44: loss=0.1485 
[epoch 17] val_loss=1.7750 qwk=('0.3700', '0.3685', '0.2895') averageQWK=0.3427 macroEMD=0.2403 tailR0=('0.1667', '0.1071', '0.0000') tailR0avg=0.0913
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    4    0
     9   38   26   25    0
     3   29   52   71    0
     0    1   16   41    1
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    3    5    0
    11   25   29   16    1
     4   34   68   60    0
     0    2   13   46    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   38   55   11    0
     0   37  105   38    0
     0    1   17   18    0
     0    0    0    0    0
[epoch 18] step 2/44: loss=0.1225 
[epoch 18] step 4/44: loss=0.1236 
[epoch 18] step 6/44: loss=0.1168 
[epoch 18] step 8/44: loss=0.1294 
[epoch 18] step 10/44: loss=0.1348 
[epoch 18] step 12/44: loss=0.1315 
[epoch 18] step 14/44: loss=0.1303 
[epoch 18] step 16/44: loss=0.1301 
[epoch 18] step 18/44: loss=0.1289 
[epoch 18] step 20/44: loss=0.1270 
[epoch 18] step 22/44: loss=0.1259 
[epoch 18] step 24/44: loss=0.1264 
[epoch 18] step 26/44: loss=0.1262 
[epoch 18] step 28/44: loss=0.1268 
[epoch 18] step 30/44: loss=0.1261 
[epoch 18] step 32/44: loss=0.1252 
[epoch 18] step 34/44: loss=0.1260 
[epoch 18] step 36/44: loss=0.1259 
[epoch 18] step 38/44: loss=0.1251 
[epoch 18] step 40/44: loss=0.1254 
[epoch 18] step 42/44: loss=0.1252 
[epoch 18] step 44/44: loss=0.1255 
[epoch 18] val_loss=2.1026 qwk=('0.2660', '0.3053', '0.2316') averageQWK=0.2676 macroEMD=0.2523 tailR0=('0.0000', '0.0357', '0.0000') tailR0avg=0.0119
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    5    0
     3   35   24   36    0
     1   24   45   85    0
     0    1   15   42    1
     0    0    1    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    6    0
     1   24   35   21    1
     2   17   72   75    0
     0    0   13   48    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0   30   60   14    0
     0   28  112   40    0
     0    0   19   17    0
     0    0    0    0    0
[epoch 19] step 2/44: loss=0.1087 
[epoch 19] step 4/44: loss=0.1173 
[epoch 19] step 6/44: loss=0.1117 
[epoch 19] step 8/44: loss=0.1065 
[epoch 19] step 10/44: loss=0.1046 
[epoch 19] step 12/44: loss=0.1039 
[epoch 19] step 14/44: loss=0.1048 
[epoch 19] step 16/44: loss=0.1061 
[epoch 19] step 18/44: loss=0.1081 
[epoch 19] step 20/44: loss=0.1084 
[epoch 19] step 22/44: loss=0.1080 
[epoch 19] step 24/44: loss=0.1071 
[epoch 19] step 26/44: loss=0.1066 
[epoch 19] step 28/44: loss=0.1059 
[epoch 19] step 30/44: loss=0.1048 
[epoch 19] step 32/44: loss=0.1056 
[epoch 19] step 34/44: loss=0.1047 
[epoch 19] step 36/44: loss=0.1058 
[epoch 19] step 38/44: loss=0.1049 
[epoch 19] step 40/44: loss=0.1056 
[epoch 19] step 42/44: loss=0.1055 
[epoch 19] step 44/44: loss=0.1037 
[epoch 19] val_loss=1.7834 qwk=('0.3521', '0.3510', '0.2500') averageQWK=0.3177 macroEMD=0.2407 tailR0=('0.1667', '0.0357', '0.0000') tailR0avg=0.0675
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    2    1
     6   38   31   23    0
     2   25   54   73    1
     0    1   19   37    2
     0    0    1    3    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    5    4    0
     3   28   36   15    0
     4   23   88   51    0
     0    1   18   42    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   29   67    8    0
     0   28  126   26    0
     0    0   22   14    0
     0    0    0    0    0
[epoch 20] step 2/44: loss=0.1066 
[epoch 20] step 4/44: loss=0.1010 
[epoch 20] step 6/44: loss=0.0993 
[epoch 20] step 8/44: loss=0.0972 
[epoch 20] step 10/44: loss=0.0951 
[epoch 20] step 12/44: loss=0.0925 
[epoch 20] step 14/44: loss=0.0897 
[epoch 20] step 16/44: loss=0.0909 
[epoch 20] step 18/44: loss=0.0924 
[epoch 20] step 20/44: loss=0.0929 
[epoch 20] step 22/44: loss=0.0906 
[epoch 20] step 24/44: loss=0.0890 
[epoch 20] step 26/44: loss=0.0890 
[epoch 20] step 28/44: loss=0.0880 
[epoch 20] step 30/44: loss=0.0888 
[epoch 20] step 32/44: loss=0.0893 
[epoch 20] step 34/44: loss=0.0895 
[epoch 20] step 36/44: loss=0.0900 
[epoch 20] step 38/44: loss=0.0889 
[epoch 20] step 40/44: loss=0.0887 
[epoch 20] step 42/44: loss=0.0892 
[epoch 20] step 44/44: loss=0.0888 
[epoch 20] val_loss=2.3385 qwk=('0.2824', '0.2952', '0.2364') averageQWK=0.2713 macroEMD=0.2529 tailR0=('0.2500', '0.0357', '0.0000') tailR0avg=0.0952
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    4    1
     6   30   28   34    0
     1   23   44   83    4
     0    1   14   41    3
     0    0    1    2    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    7    0
     1   29   22   29    1
     3   24   50   89    0
     0    0    5   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0   24   63   17    0
     0   17  121   42    0
     0    0   15   21    0
     0    0    0    0    0
[epoch 21] step 2/44: loss=0.0860 
[epoch 21] step 4/44: loss=0.0709 
[epoch 21] step 6/44: loss=0.0713 
[epoch 21] step 8/44: loss=0.0698 
[epoch 21] step 10/44: loss=0.0716 
[epoch 21] step 12/44: loss=0.0771 
[epoch 21] step 14/44: loss=0.0748 
[epoch 21] step 16/44: loss=0.0739 
[epoch 21] step 18/44: loss=0.0740 
[epoch 21] step 20/44: loss=0.0725 
[epoch 21] step 22/44: loss=0.0708 
[epoch 21] step 24/44: loss=0.0700 
[epoch 21] step 26/44: loss=0.0695 
[epoch 21] step 28/44: loss=0.0689 
[epoch 21] step 30/44: loss=0.0687 
[epoch 21] step 32/44: loss=0.0699 
[epoch 21] step 34/44: loss=0.0685 
[epoch 21] step 36/44: loss=0.0674 
[epoch 21] step 38/44: loss=0.0676 
[epoch 21] step 40/44: loss=0.0670 
[epoch 21] step 42/44: loss=0.0671 
[epoch 21] step 44/44: loss=0.0660 
[epoch 21] val_loss=2.3784 qwk=('0.2807', '0.2914', '0.2776') averageQWK=0.2833 macroEMD=0.2538 tailR0=('0.2500', '0.0714', '0.0000') tailR0avg=0.1071
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    4    1
     5   27   34   32    0
     2   15   53   81    4
     0    1   17   34    7
     0    0    1    2    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    2    7    0
     3   28   17   33    1
     4   29   40   93    0
     0    0    4   55    2
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   30   57   17    0
     0   25  108   47    0
     0    0   14   22    0
     0    0    0    0    0
[epoch 22] step 2/44: loss=0.0517 
[epoch 22] step 4/44: loss=0.0498 
[epoch 22] step 6/44: loss=0.0520 
[epoch 22] step 8/44: loss=0.0521 
[epoch 22] step 10/44: loss=0.0535 
[epoch 22] step 12/44: loss=0.0560 
[epoch 22] step 14/44: loss=0.0549 
[epoch 22] step 16/44: loss=0.0540 
[epoch 22] step 18/44: loss=0.0549 
[epoch 22] step 20/44: loss=0.0554 
[epoch 22] step 22/44: loss=0.0542 
[epoch 22] step 24/44: loss=0.0539 
[epoch 22] step 26/44: loss=0.0534 
[epoch 22] step 28/44: loss=0.0529 
[epoch 22] step 30/44: loss=0.0531 
[epoch 22] step 32/44: loss=0.0530 
[epoch 22] step 34/44: loss=0.0537 
[epoch 22] step 36/44: loss=0.0542 
[epoch 22] step 38/44: loss=0.0533 
[epoch 22] step 40/44: loss=0.0531 
[epoch 22] step 42/44: loss=0.0535 
[epoch 22] step 44/44: loss=0.0546 
[epoch 22] val_loss=2.3525 qwk=('0.3266', '0.3312', '0.2782') averageQWK=0.3120 macroEMD=0.2434 tailR0=('0.0714', '0.0714', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    1    4    0
     7   29   34   28    0
     3   16   57   77    2
     0    1   15   41    2
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    2    7    0
     3   27   29   22    1
     4   19   64   79    0
     0    0    7   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     1   25   69    9    0
     0   21  133   26    0
     0    0   18   18    0
     0    0    0    0    0
[epoch 23] step 2/44: loss=0.0420 
[epoch 23] step 4/44: loss=0.0427 
[epoch 23] step 6/44: loss=0.0424 
[epoch 23] step 8/44: loss=0.0408 
[epoch 23] step 10/44: loss=0.0436 
[epoch 23] step 12/44: loss=0.0426 
[epoch 23] step 14/44: loss=0.0423 
[epoch 23] step 16/44: loss=0.0430 
[epoch 23] step 18/44: loss=0.0421 
[epoch 23] step 20/44: loss=0.0423 
[epoch 23] step 22/44: loss=0.0419 
[epoch 23] step 24/44: loss=0.0415 
[epoch 23] step 26/44: loss=0.0423 
[epoch 23] step 28/44: loss=0.0427 
[epoch 23] step 30/44: loss=0.0444 
[epoch 23] step 32/44: loss=0.0448 
[epoch 23] step 34/44: loss=0.0446 
[epoch 23] step 36/44: loss=0.0444 
[epoch 23] step 38/44: loss=0.0448 
[epoch 23] step 40/44: loss=0.0452 
[epoch 23] step 42/44: loss=0.0447 
[epoch 23] step 44/44: loss=0.0442 
[epoch 23] val_loss=2.3801 qwk=('0.3075', '0.3138', '0.2836') averageQWK=0.3016 macroEMD=0.2396 tailR0=('0.1667', '0.0357', '0.0000') tailR0avg=0.0675
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    4    0
     4   30   31   33    0
     2   16   49   85    3
     0    1   13   43    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    7    0
     3   22   34   22    1
     4   13   76   73    0
     0    0    8   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   29   67    8    0
     0   29  127   24    0
     0    0   19   17    0
     0    0    0    0    0
[epoch 24] step 2/44: loss=0.0280 
[epoch 24] step 4/44: loss=0.0340 
[epoch 24] step 6/44: loss=0.0354 
[epoch 24] step 8/44: loss=0.0326 
[epoch 24] step 10/44: loss=0.0356 
[epoch 24] step 12/44: loss=0.0363 
[epoch 24] step 14/44: loss=0.0377 
[epoch 24] step 16/44: loss=0.0358 
[epoch 24] step 18/44: loss=0.0355 
[epoch 24] step 20/44: loss=0.0360 
[epoch 24] step 22/44: loss=0.0358 
[epoch 24] step 24/44: loss=0.0362 
[epoch 24] step 26/44: loss=0.0356 
[epoch 24] step 28/44: loss=0.0367 
[epoch 24] step 30/44: loss=0.0368 
[epoch 24] step 32/44: loss=0.0374 
[epoch 24] step 34/44: loss=0.0374 
[epoch 24] step 36/44: loss=0.0378 
[epoch 24] step 38/44: loss=0.0392 
[epoch 24] step 40/44: loss=0.0398 
[epoch 24] step 42/44: loss=0.0391 
[epoch 24] step 44/44: loss=0.0402 
[epoch 24] val_loss=2.5135 qwk=('0.3189', '0.2993', '0.2552') averageQWK=0.2911 macroEMD=0.2469 tailR0=('0.1667', '0.0357', '0.0000') tailR0avg=0.0675
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    3    1
     3   30   43   22    0
     1   20   65   66    3
     0    1   18   38    2
     0    0    1    3    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    7    0
     1   29   23   28    1
     2   26   43   95    0
     0    0    5   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0   27   67   10    0
     0   20  133   27    0
     0    0   19   17    0
     0    0    0    0    0
[epoch 25] step 2/44: loss=0.0265 
[epoch 25] step 4/44: loss=0.0349 
[epoch 25] step 6/44: loss=0.0328 
[epoch 25] step 8/44: loss=0.0308 
[epoch 25] step 10/44: loss=0.0308 
[epoch 25] step 12/44: loss=0.0293 
[epoch 25] step 14/44: loss=0.0289 
[epoch 25] step 16/44: loss=0.0286 
[epoch 25] step 18/44: loss=0.0315 
[epoch 25] step 20/44: loss=0.0325 
[epoch 25] step 22/44: loss=0.0334 
[epoch 25] step 24/44: loss=0.0337 
[epoch 25] step 26/44: loss=0.0335 
[epoch 25] step 28/44: loss=0.0331 
[epoch 25] step 30/44: loss=0.0339 
[epoch 25] step 32/44: loss=0.0342 
[epoch 25] step 34/44: loss=0.0341 
[epoch 25] step 36/44: loss=0.0338 
[epoch 25] step 38/44: loss=0.0336 
[epoch 25] step 40/44: loss=0.0331 
[epoch 25] step 42/44: loss=0.0337 
[epoch 25] step 44/44: loss=0.0330 
[epoch 25] val_loss=2.7668 qwk=('0.2770', '0.2773', '0.2495') averageQWK=0.2679 macroEMD=0.2534 tailR0=('0.0000', '0.0357', '0.0000') tailR0avg=0.0119
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    5    0
     4   26   39   29    0
     2   16   63   73    1
     0    1   16   40    2
     0    0    1    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    7    0
     2   27   20   32    1
     4   23   42   97    0
     0    1    3   57    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     1   23   64   16    0
     0   14  130   36    0
     0    0   15   21    0
     0    0    0    0    0
[epoch 26] step 2/44: loss=0.0273 
[epoch 26] step 4/44: loss=0.0282 
[epoch 26] step 6/44: loss=0.0266 
[epoch 26] step 8/44: loss=0.0260 
[epoch 26] step 10/44: loss=0.0249 
[epoch 26] step 12/44: loss=0.0242 
[epoch 26] step 14/44: loss=0.0239 
[epoch 26] step 16/44: loss=0.0254 
[epoch 26] step 18/44: loss=0.0257 
[epoch 26] step 20/44: loss=0.0269 
[epoch 26] step 22/44: loss=0.0272 
[epoch 26] step 24/44: loss=0.0269 
[epoch 26] step 26/44: loss=0.0268 
[epoch 26] step 28/44: loss=0.0261 
[epoch 26] step 30/44: loss=0.0256 
[epoch 26] step 32/44: loss=0.0255 
[epoch 26] step 34/44: loss=0.0257 
[epoch 26] step 36/44: loss=0.0255 
[epoch 26] step 38/44: loss=0.0253 
[epoch 26] step 40/44: loss=0.0251 
[epoch 26] step 42/44: loss=0.0249 
[epoch 26] step 44/44: loss=0.0248 
[epoch 26] val_loss=2.6087 qwk=('0.3258', '0.3077', '0.2928') averageQWK=0.3087 macroEMD=0.2412 tailR0=('0.1667', '0.0357', '0.0000') tailR0avg=0.0675
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    3    1
     4   37   29   28    0
     3   23   54   70    5
     0    1   15   40    3
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    7    0
     2   26   31   22    1
     2   28   60   76    0
     0    0    9   52    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   29   70    5    0
     0   28  127   25    0
     0    0   21   15    0
     0    0    0    0    0
[epoch 27] step 2/44: loss=0.0271 
[epoch 27] step 4/44: loss=0.0265 
[epoch 27] step 6/44: loss=0.0235 
[epoch 27] step 8/44: loss=0.0228 
[epoch 27] step 10/44: loss=0.0244 
[epoch 27] step 12/44: loss=0.0243 
[epoch 27] step 14/44: loss=0.0247 
[epoch 27] step 16/44: loss=0.0261 
[epoch 27] step 18/44: loss=0.0261 
[epoch 27] step 20/44: loss=0.0261 
[epoch 27] step 22/44: loss=0.0252 
[epoch 27] step 24/44: loss=0.0245 
[epoch 27] step 26/44: loss=0.0244 
[epoch 27] step 28/44: loss=0.0240 
[epoch 27] step 30/44: loss=0.0234 
[epoch 27] step 32/44: loss=0.0228 
[epoch 27] step 34/44: loss=0.0226 
[epoch 27] step 36/44: loss=0.0227 
[epoch 27] step 38/44: loss=0.0224 
[epoch 27] step 40/44: loss=0.0223 
[epoch 27] step 42/44: loss=0.0220 
[epoch 27] step 44/44: loss=0.0216 
[epoch 27] val_loss=2.9045 qwk=('0.2751', '0.2899', '0.2749') averageQWK=0.2799 macroEMD=0.2516 tailR0=('0.1667', '0.0357', '0.0000') tailR0avg=0.0675
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    4    1
     4   29   32   33    0
     2   17   54   79    3
     0    1   15   40    3
     0    0    1    3    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    7    0
     2   23   29   27    1
     2   20   56   88    0
     0    0    7   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   27   69    8    0
     0   20  132   28    0
     0    0   20   16    0
     0    0    0    0    0
[epoch 28] step 2/44: loss=0.0196 
[epoch 28] step 4/44: loss=0.0163 
[epoch 28] step 6/44: loss=0.0170 
[epoch 28] step 8/44: loss=0.0177 
[epoch 28] step 10/44: loss=0.0167 
[epoch 28] step 12/44: loss=0.0178 
[epoch 28] step 14/44: loss=0.0181 
[epoch 28] step 16/44: loss=0.0176 
[epoch 28] step 18/44: loss=0.0179 
[epoch 28] step 20/44: loss=0.0173 
[epoch 28] step 22/44: loss=0.0172 
[epoch 28] step 24/44: loss=0.0177 
[epoch 28] step 26/44: loss=0.0185 
[epoch 28] step 28/44: loss=0.0182 
[epoch 28] step 30/44: loss=0.0179 
[epoch 28] step 32/44: loss=0.0178 
[epoch 28] step 34/44: loss=0.0179 
[epoch 28] step 36/44: loss=0.0184 
[epoch 28] step 38/44: loss=0.0184 
[epoch 28] step 40/44: loss=0.0186 
[epoch 28] step 42/44: loss=0.0188 
[epoch 28] step 44/44: loss=0.0186 
[epoch 28] val_loss=2.8540 qwk=('0.3075', '0.2822', '0.2559') averageQWK=0.2819 macroEMD=0.2463 tailR0=('0.0833', '0.0357', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    4    0
     4   29   38   27    0
     3   14   68   69    1
     0    1   17   39    2
     0    0    1    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    7    0
     2   28   22   29    1
     2   32   50   82    0
     0    0    8   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   28   71    5    0
     0   24  140   16    0
     0    0   24   12    0
     0    0    0    0    0
[epoch 29] step 2/44: loss=0.0161 
[epoch 29] step 4/44: loss=0.0198 
[epoch 29] step 6/44: loss=0.0210 
[epoch 29] step 8/44: loss=0.0224 
[epoch 29] step 10/44: loss=0.0201 
[epoch 29] step 12/44: loss=0.0200 
[epoch 29] step 14/44: loss=0.0190 
[epoch 29] step 16/44: loss=0.0186 
[epoch 29] step 18/44: loss=0.0182 
[epoch 29] step 20/44: loss=0.0181 
[epoch 29] step 22/44: loss=0.0189 
[epoch 29] step 24/44: loss=0.0188 
[epoch 29] step 26/44: loss=0.0181 
[epoch 29] step 28/44: loss=0.0177 
[epoch 29] step 30/44: loss=0.0177 
[epoch 29] step 32/44: loss=0.0179 
[epoch 29] step 34/44: loss=0.0183 
[epoch 29] step 36/44: loss=0.0184 
[epoch 29] step 38/44: loss=0.0187 
[epoch 29] step 40/44: loss=0.0186 
[epoch 29] step 42/44: loss=0.0183 
[epoch 29] step 44/44: loss=0.0194 
[epoch 29] val_loss=2.9251 qwk=('0.3127', '0.2910', '0.2757') averageQWK=0.2931 macroEMD=0.2453 tailR0=('0.2381', '0.0714', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    1    3    1
     6   29   36   27    0
     3   18   62   69    3
     0    1   17   39    2
     0    0    1    3    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    2    7    0
     3   25   23   30    1
     3   31   40   92    0
     0    0    4   57    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   30   66    8    0
     0   31  127   22    0
     0    0   20   16    0
     0    0    0    0    0
[epoch 30] step 2/44: loss=0.0130 
[epoch 30] step 4/44: loss=0.0130 
[epoch 30] step 6/44: loss=0.0132 
[epoch 30] step 8/44: loss=0.0130 
[epoch 30] step 10/44: loss=0.0128 
[epoch 30] step 12/44: loss=0.0126 
[epoch 30] step 14/44: loss=0.0122 
[epoch 30] step 16/44: loss=0.0121 
[epoch 30] step 18/44: loss=0.0123 
[epoch 30] step 20/44: loss=0.0127 
[epoch 30] step 22/44: loss=0.0126 
[epoch 30] step 24/44: loss=0.0130 
[epoch 30] step 26/44: loss=0.0128 
[epoch 30] step 28/44: loss=0.0129 
[epoch 30] step 30/44: loss=0.0130 
[epoch 30] step 32/44: loss=0.0133 
[epoch 30] step 34/44: loss=0.0137 
[epoch 30] step 36/44: loss=0.0134 
[epoch 30] step 38/44: loss=0.0133 
[epoch 30] step 40/44: loss=0.0133 
[epoch 30] step 42/44: loss=0.0135 
[epoch 30] step 44/44: loss=0.0132 
[epoch 30] val_loss=3.0845 qwk=('0.2709', '0.2927', '0.2760') averageQWK=0.2799 macroEMD=0.2495 tailR0=('0.2381', '0.0714', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    0    4    1
     6   25   34   33    0
     3   16   57   76    3
     0    1   16   40    2
     0    0    1    3    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    2    7    0
     3   25   21   32    1
     3   20   48   95    0
     0    0    4   57    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   27   67   10    0
     0   20  132   28    0
     0    0   18   18    0
     0    0    0    0    0
[epoch 31] step 2/44: loss=0.0073 
[epoch 31] step 4/44: loss=0.0075 
[epoch 31] step 6/44: loss=0.0084 
[epoch 31] step 8/44: loss=0.0090 
[epoch 31] step 10/44: loss=0.0111 
[epoch 31] step 12/44: loss=0.0116 
[epoch 31] step 14/44: loss=0.0121 
[epoch 31] step 16/44: loss=0.0120 
[epoch 31] step 18/44: loss=0.0117 
[epoch 31] step 20/44: loss=0.0116 
[epoch 31] step 22/44: loss=0.0114 
[epoch 31] step 24/44: loss=0.0115 
[epoch 31] step 26/44: loss=0.0115 
[epoch 31] step 28/44: loss=0.0115 
[epoch 31] step 30/44: loss=0.0114 
[epoch 31] step 32/44: loss=0.0113 
[epoch 31] step 34/44: loss=0.0112 
[epoch 31] step 36/44: loss=0.0113 
[epoch 31] step 38/44: loss=0.0114 
[epoch 31] step 40/44: loss=0.0112 
[epoch 31] step 42/44: loss=0.0115 
[epoch 31] step 44/44: loss=0.0113 
[epoch 31] val_loss=3.0190 qwk=('0.2874', '0.2963', '0.2643') averageQWK=0.2827 macroEMD=0.2468 tailR0=('0.0833', '0.0357', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    4    1
     5   32   31   30    0
     2   20   58   72    3
     0    1   16   40    2
     0    0    1    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    7    0
     2   25   28   26    1
     2   21   59   84    0
     0    0    8   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   27   65   12    0
     0   23  124   33    0
     0    0   17   19    0
     0    0    0    0    0
[epoch 32] step 2/44: loss=0.0096 
[epoch 32] step 4/44: loss=0.0118 
[epoch 32] step 6/44: loss=0.0108 
[epoch 32] step 8/44: loss=0.0101 
[epoch 32] step 10/44: loss=0.0106 
[epoch 32] step 12/44: loss=0.0115 
[epoch 32] step 14/44: loss=0.0120 
[epoch 32] step 16/44: loss=0.0122 
[epoch 32] step 18/44: loss=0.0117 
[epoch 32] step 20/44: loss=0.0115 
[epoch 32] step 22/44: loss=0.0111 
[epoch 32] step 24/44: loss=0.0111 
[epoch 32] step 26/44: loss=0.0109 
[epoch 32] step 28/44: loss=0.0110 
[epoch 32] step 30/44: loss=0.0108 
[epoch 32] step 32/44: loss=0.0106 
[epoch 32] step 34/44: loss=0.0106 
[epoch 32] step 36/44: loss=0.0104 
[epoch 32] step 38/44: loss=0.0103 
[epoch 32] step 40/44: loss=0.0102 
[epoch 32] step 42/44: loss=0.0101 
[epoch 32] step 44/44: loss=0.0102 
[epoch 32] val_loss=2.9725 qwk=('0.2899', '0.2953', '0.2544') averageQWK=0.2799 macroEMD=0.2488 tailR0=('0.0833', '0.0357', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    4    1
     4   31   32   31    0
     2   20   55   75    3
     0    1   14   42    2
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    7    0
     2   21   34   24    1
     2   19   65   80    0
     0    0    8   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0   27   67   10    0
     0   20  135   25    0
     0    0   19   17    0
     0    0    0    0    0
[epoch 33] step 2/44: loss=0.0158 
[epoch 33] step 4/44: loss=0.0112 
[epoch 33] step 6/44: loss=0.0113 
[epoch 33] step 8/44: loss=0.0109 
[epoch 33] step 10/44: loss=0.0104 
[epoch 33] step 12/44: loss=0.0102 
[epoch 33] step 14/44: loss=0.0107 
[epoch 33] step 16/44: loss=0.0104 
[epoch 33] step 18/44: loss=0.0099 
[epoch 33] step 20/44: loss=0.0095 
[epoch 33] step 22/44: loss=0.0094 
[epoch 33] step 24/44: loss=0.0094 
[epoch 33] step 26/44: loss=0.0095 
[epoch 33] step 28/44: loss=0.0094 
[epoch 33] step 30/44: loss=0.0095 
[epoch 33] step 32/44: loss=0.0095 
[epoch 33] step 34/44: loss=0.0094 
[epoch 33] step 36/44: loss=0.0092 
[epoch 33] step 38/44: loss=0.0092 
[epoch 33] step 40/44: loss=0.0091 
[epoch 33] step 42/44: loss=0.0090 
[epoch 33] step 44/44: loss=0.0090 
[epoch 33] val_loss=3.1980 qwk=('0.2702', '0.2702', '0.2479') averageQWK=0.2628 macroEMD=0.2522 tailR0=('0.1667', '0.0357', '0.0000') tailR0avg=0.0675
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    4    1
     4   27   35   32    0
     2   18   57   75    3
     0    1   15   41    2
     0    0    1    3    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    7    0
     2   24   23   32    1
     2   25   45   94    0
     0    0    6   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0   26   67   11    0
     0   22  127   31    0
     0    0   18   18    0
     0    0    0    0    0
[epoch 34] step 2/44: loss=0.0052 
[epoch 34] step 4/44: loss=0.0084 
[epoch 34] step 6/44: loss=0.0087 
[epoch 34] step 8/44: loss=0.0079 
[epoch 34] step 10/44: loss=0.0074 
[epoch 34] step 12/44: loss=0.0077 
[epoch 34] step 14/44: loss=0.0077 
[epoch 34] step 16/44: loss=0.0075 
[epoch 34] step 18/44: loss=0.0074 
[epoch 34] step 20/44: loss=0.0074 
[epoch 34] step 22/44: loss=0.0078 
[epoch 34] step 24/44: loss=0.0077 
[epoch 34] step 26/44: loss=0.0077 
[epoch 34] step 28/44: loss=0.0078 
[epoch 34] step 30/44: loss=0.0079 
[epoch 34] step 32/44: loss=0.0078 
[epoch 34] step 34/44: loss=0.0080 
[epoch 34] step 36/44: loss=0.0079 
[epoch 34] step 38/44: loss=0.0080 
[epoch 34] step 40/44: loss=0.0081 
[epoch 34] step 42/44: loss=0.0083 
[epoch 34] step 44/44: loss=0.0084 
[epoch 34] val_loss=3.1703 qwk=('0.2642', '0.2804', '0.2520') averageQWK=0.2655 macroEMD=0.2511 tailR0=('0.0833', '0.0357', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    4    1
     4   27   35   32    0
     2   17   58   75    3
     0    1   15   41    2
     0    0    1    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    7    0
     2   24   25   30    1
     2   23   48   93    0
     0    0    6   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0   26   67   11    0
     0   20  130   30    0
     0    0   18   18    0
     0    0    0    0    0
[epoch 35] step 2/44: loss=0.0094 
[epoch 35] step 4/44: loss=0.0088 
[epoch 35] step 6/44: loss=0.0097 
[epoch 35] step 8/44: loss=0.0088 
[epoch 35] step 10/44: loss=0.0097 
[epoch 35] step 12/44: loss=0.0097 
[epoch 35] step 14/44: loss=0.0092 
[epoch 35] step 16/44: loss=0.0091 
[epoch 35] step 18/44: loss=0.0091 
[epoch 35] step 20/44: loss=0.0090 
[epoch 35] step 22/44: loss=0.0086 
[epoch 35] step 24/44: loss=0.0084 
[epoch 35] step 26/44: loss=0.0082 
[epoch 35] step 28/44: loss=0.0086 
[epoch 35] step 30/44: loss=0.0085 
[epoch 35] step 32/44: loss=0.0085 
[epoch 35] step 34/44: loss=0.0085 
[epoch 35] step 36/44: loss=0.0084 
[epoch 35] step 38/44: loss=0.0084 
[epoch 35] step 40/44: loss=0.0083 
[epoch 35] step 42/44: loss=0.0082 
[epoch 35] step 44/44: loss=0.0081 
[epoch 35] val_loss=3.1542 qwk=('0.2652', '0.2866', '0.2609') averageQWK=0.2709 macroEMD=0.2509 tailR0=('0.0833', '0.0357', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    4    1
     4   27   35   32    0
     2   16   59   75    3
     0    1   15   41    2
     0    0    1    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    7    0
     2   23   28   28    1
     2   19   57   88    0
     0    0    7   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0   26   68   10    0
     0   19  132   29    0
     0    0   18   18    0
     0    0    0    0    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/ce/fold2/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/ce/fold2/metrics.json
Done.
