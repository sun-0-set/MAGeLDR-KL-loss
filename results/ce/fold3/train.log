[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.9370 
[epoch 1] step 4/44: loss=0.9421 
[epoch 1] step 6/44: loss=0.9323 
[epoch 1] step 8/44: loss=0.9222 
[epoch 1] step 10/44: loss=0.9321 
[epoch 1] step 12/44: loss=0.9332 
[epoch 1] step 14/44: loss=0.9301 
[epoch 1] step 16/44: loss=0.9313 
[epoch 1] step 18/44: loss=0.9349 
[epoch 1] step 20/44: loss=0.9377 
[epoch 1] step 22/44: loss=0.9368 
[epoch 1] step 24/44: loss=0.9370 
[epoch 1] step 26/44: loss=0.9367 
[epoch 1] step 28/44: loss=0.9343 
[epoch 1] step 30/44: loss=0.9313 
[epoch 1] step 32/44: loss=0.9294 
[epoch 1] step 34/44: loss=0.9271 
[epoch 1] step 36/44: loss=0.9258 
[epoch 1] step 38/44: loss=0.9220 
[epoch 1] step 40/44: loss=0.9174 
[epoch 1] step 42/44: loss=0.9123 
[epoch 1] step 44/44: loss=0.9054 
[epoch 1] val_loss=1.6576 qwk=('-0.1889', '-0.0881', '0.2222') averageQWK=-0.0183 macroEMD=0.3940 tailR0=('0.0000', '0.0000', '0.3333') tailR0avg=0.1111
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    8    0
     0   18    0   22    0
     0   51    7   70    0
     0   68   13   41    0
     0   12    8    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
    14    0   28    6    0
    51    0   44   18    0
    78    0   45   25    0
     5    0    5    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   61    0    3
     0    7  128    1   15
     0    1   77    7   14
     0    0    1    0    2
[epoch 2] step 2/44: loss=0.8229 
[epoch 2] step 4/44: loss=0.7974 
[epoch 2] step 6/44: loss=0.7804 
[epoch 2] step 8/44: loss=0.7694 
[epoch 2] step 10/44: loss=0.7626 
[epoch 2] step 12/44: loss=0.7551 
[epoch 2] step 14/44: loss=0.7417 
[epoch 2] step 16/44: loss=0.7315 
[epoch 2] step 18/44: loss=0.7197 
[epoch 2] step 20/44: loss=0.7125 
[epoch 2] step 22/44: loss=0.7083 
[epoch 2] step 24/44: loss=0.7040 
[epoch 2] step 26/44: loss=0.6987 
[epoch 2] step 28/44: loss=0.6932 
[epoch 2] step 30/44: loss=0.6910 
[epoch 2] step 32/44: loss=0.6903 
[epoch 2] step 34/44: loss=0.6880 
[epoch 2] step 36/44: loss=0.6838 
[epoch 2] step 38/44: loss=0.6821 
[epoch 2] step 40/44: loss=0.6777 
[epoch 2] step 42/44: loss=0.6768 
[epoch 2] step 44/44: loss=0.6728 
[epoch 2] val_loss=1.1688 qwk=('0.0340', '0.4098', '0.3826') averageQWK=0.2755 macroEMD=0.3233 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    0    0
     0    0   40    0    0
     0    0  127    1    0
     0    0  121    1    0
     0    0   24    3    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   46    2    0
     0    0   86   27    0
     0    0   63   85    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    6   64    1    0
     0    0  136   15    0
     0    0   54   45    0
     0    0    2    1    0
[epoch 3] step 2/44: loss=0.6285 
[epoch 3] step 4/44: loss=0.6295 
[epoch 3] step 6/44: loss=0.6296 
[epoch 3] step 8/44: loss=0.6186 
[epoch 3] step 10/44: loss=0.6102 
[epoch 3] step 12/44: loss=0.6145 
[epoch 3] step 14/44: loss=0.6171 
[epoch 3] step 16/44: loss=0.6160 
[epoch 3] step 18/44: loss=0.6102 
[epoch 3] step 20/44: loss=0.6064 
[epoch 3] step 22/44: loss=0.5975 
[epoch 3] step 24/44: loss=0.6024 
[epoch 3] step 26/44: loss=0.5984 
[epoch 3] step 28/44: loss=0.5949 
[epoch 3] step 30/44: loss=0.5913 
[epoch 3] step 32/44: loss=0.5885 
[epoch 3] step 34/44: loss=0.5854 
[epoch 3] step 36/44: loss=0.5819 
[epoch 3] step 38/44: loss=0.5799 
[epoch 3] step 40/44: loss=0.5768 
[epoch 3] step 42/44: loss=0.5727 
[epoch 3] step 44/44: loss=0.5686 
[epoch 3] val_loss=1.1301 qwk=('0.4658', '0.3551', '0.3701') averageQWK=0.3970 macroEMD=0.2630 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    8   32    0    0
     0    4  109   15    0
     0    1   79   42    0
     0    0    5   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   46    2    0
     0    0   98   15    0
     0    0   79   69    0
     0    0    2    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   40    0    0
     0   26  121    4    0
     0    2   86   11    0
     0    0    1    2    0
[epoch 4] step 2/44: loss=0.5530 
[epoch 4] step 4/44: loss=0.5323 
[epoch 4] step 6/44: loss=0.5201 
[epoch 4] step 8/44: loss=0.5218 
[epoch 4] step 10/44: loss=0.5068 
[epoch 4] step 12/44: loss=0.5098 
[epoch 4] step 14/44: loss=0.5077 
[epoch 4] step 16/44: loss=0.5019 
[epoch 4] step 18/44: loss=0.5080 
[epoch 4] step 20/44: loss=0.5133 
[epoch 4] step 22/44: loss=0.5102 
[epoch 4] step 24/44: loss=0.5149 
[epoch 4] step 26/44: loss=0.5192 
[epoch 4] step 28/44: loss=0.5175 
[epoch 4] step 30/44: loss=0.5157 
[epoch 4] step 32/44: loss=0.5141 
[epoch 4] step 34/44: loss=0.5121 
[epoch 4] step 36/44: loss=0.5134 
[epoch 4] step 38/44: loss=0.5102 
[epoch 4] step 40/44: loss=0.5083 
[epoch 4] step 42/44: loss=0.5051 
[epoch 4] step 44/44: loss=0.5024 
[epoch 4] val_loss=1.0752 qwk=('0.4843', '0.5162', '0.5603') averageQWK=0.5203 macroEMD=0.2432 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    9   30    1    0
     0    3  110   15    0
     0    0   67   55    0
     0    0    8   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   20   28    0    0
     0   19   80   14    0
     0    5   80   63    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   30   41    0    0
     0   16  125   10    0
     0    0   53   46    0
     0    0    1    2    0
[epoch 5] step 2/44: loss=0.4566 
[epoch 5] step 4/44: loss=0.4494 
[epoch 5] step 6/44: loss=0.4589 
[epoch 5] step 8/44: loss=0.4597 
[epoch 5] step 10/44: loss=0.4608 
[epoch 5] step 12/44: loss=0.4585 
[epoch 5] step 14/44: loss=0.4643 
[epoch 5] step 16/44: loss=0.4661 
[epoch 5] step 18/44: loss=0.4690 
[epoch 5] step 20/44: loss=0.4689 
[epoch 5] step 22/44: loss=0.4731 
[epoch 5] step 24/44: loss=0.4835 
[epoch 5] step 26/44: loss=0.4781 
[epoch 5] step 28/44: loss=0.4793 
[epoch 5] step 30/44: loss=0.4802 
[epoch 5] step 32/44: loss=0.4827 
[epoch 5] step 34/44: loss=0.4825 
[epoch 5] step 36/44: loss=0.4803 
[epoch 5] step 38/44: loss=0.4788 
[epoch 5] step 40/44: loss=0.4748 
[epoch 5] step 42/44: loss=0.4743 
[epoch 5] step 44/44: loss=0.4752 
[epoch 5] val_loss=0.9932 qwk=('0.5436', '0.5325', '0.5847') averageQWK=0.5536 macroEMD=0.2250 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   11   27    2    0
     0    5  102   21    0
     0    0   52   70    0
     0    0    5   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   19   23    6    0
     0   14   75   24    0
     0    3   58   87    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   47    0    0
     0    4  136   11    0
     0    0   45   54    0
     0    0    1    2    0
[epoch 6] step 2/44: loss=0.4053 
[epoch 6] step 4/44: loss=0.3860 
[epoch 6] step 6/44: loss=0.4150 
[epoch 6] step 8/44: loss=0.4133 
[epoch 6] step 10/44: loss=0.4114 
[epoch 6] step 12/44: loss=0.4077 
[epoch 6] step 14/44: loss=0.4168 
[epoch 6] step 16/44: loss=0.4178 
[epoch 6] step 18/44: loss=0.4198 
[epoch 6] step 20/44: loss=0.4181 
[epoch 6] step 22/44: loss=0.4204 
[epoch 6] step 24/44: loss=0.4217 
[epoch 6] step 26/44: loss=0.4240 
[epoch 6] step 28/44: loss=0.4251 
[epoch 6] step 30/44: loss=0.4215 
[epoch 6] step 32/44: loss=0.4203 
[epoch 6] step 34/44: loss=0.4213 
[epoch 6] step 36/44: loss=0.4252 
[epoch 6] step 38/44: loss=0.4274 
[epoch 6] step 40/44: loss=0.4262 
[epoch 6] step 42/44: loss=0.4278 
[epoch 6] step 44/44: loss=0.4264 
[epoch 6] val_loss=1.0461 qwk=('0.5685', '0.5393', '0.6183') averageQWK=0.5754 macroEMD=0.2170 tailR0=('0.0556', '0.0000', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   20   17    3    0
     0   30   75   22    1
     0    6   39   75    2
     0    0    3   21    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   27   16    5    0
     0   32   58   23    0
     0    9   50   89    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   49   22    0    0
     0   44   86   21    0
     0    2   38   59    0
     0    0    1    2    0
[epoch 7] step 2/44: loss=0.4006 
[epoch 7] step 4/44: loss=0.3898 
[epoch 7] step 6/44: loss=0.3918 
[epoch 7] step 8/44: loss=0.3981 
[epoch 7] step 10/44: loss=0.3918 
[epoch 7] step 12/44: loss=0.3860 
[epoch 7] step 14/44: loss=0.3848 
[epoch 7] step 16/44: loss=0.3839 
[epoch 7] step 18/44: loss=0.3908 
[epoch 7] step 20/44: loss=0.3883 
[epoch 7] step 22/44: loss=0.3861 
[epoch 7] step 24/44: loss=0.3834 
[epoch 7] step 26/44: loss=0.3820 
[epoch 7] step 28/44: loss=0.3808 
[epoch 7] step 30/44: loss=0.3833 
[epoch 7] step 32/44: loss=0.3818 
[epoch 7] step 34/44: loss=0.3812 
[epoch 7] step 36/44: loss=0.3822 
[epoch 7] step 38/44: loss=0.3829 
[epoch 7] step 40/44: loss=0.3833 
[epoch 7] step 42/44: loss=0.3851 
[epoch 7] step 44/44: loss=0.3829 
[epoch 7] val_loss=1.0803 qwk=('0.5271', '0.5124', '0.5749') averageQWK=0.5381 macroEMD=0.2136 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   13   25    2    0
     0   12   97   19    0
     0    1   61   60    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   15   28    5    0
     0   10   80   23    0
     0    3   62   83    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   47   24    0    0
     0   45   95   11    0
     0    1   55   43    0
     0    0    1    2    0
[epoch 8] step 2/44: loss=0.3695 
[epoch 8] step 4/44: loss=0.3455 
[epoch 8] step 6/44: loss=0.3294 
[epoch 8] step 8/44: loss=0.3356 
[epoch 8] step 10/44: loss=0.3332 
[epoch 8] step 12/44: loss=0.3332 
[epoch 8] step 14/44: loss=0.3449 
[epoch 8] step 16/44: loss=0.3510 
[epoch 8] step 18/44: loss=0.3553 
[epoch 8] step 20/44: loss=0.3522 
[epoch 8] step 22/44: loss=0.3534 
[epoch 8] step 24/44: loss=0.3521 
[epoch 8] step 26/44: loss=0.3542 
[epoch 8] step 28/44: loss=0.3501 
[epoch 8] step 30/44: loss=0.3487 
[epoch 8] step 32/44: loss=0.3483 
[epoch 8] step 34/44: loss=0.3477 
[epoch 8] step 36/44: loss=0.3480 
[epoch 8] step 38/44: loss=0.3480 
[epoch 8] step 40/44: loss=0.3466 
[epoch 8] step 42/44: loss=0.3485 
[epoch 8] step 44/44: loss=0.3490 
[epoch 8] val_loss=1.1198 qwk=('0.5325', '0.4910', '0.5314') averageQWK=0.5183 macroEMD=0.2122 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   12   25    3    0
     0   13   94   21    0
     0    1   56   65    0
     0    0    3   24    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    9   35    4    0
     0    8   84   21    0
     0    2   66   80    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   52   19    0    0
     0   52   89   10    0
     0    4   59   36    0
     0    0    2    1    0
[epoch 9] step 2/44: loss=0.3270 
[epoch 9] step 4/44: loss=0.3260 
[epoch 9] step 6/44: loss=0.3243 
[epoch 9] step 8/44: loss=0.3361 
[epoch 9] step 10/44: loss=0.3572 
[epoch 9] step 12/44: loss=0.3447 
[epoch 9] step 14/44: loss=0.3388 
[epoch 9] step 16/44: loss=0.3411 
[epoch 9] step 18/44: loss=0.3419 
[epoch 9] step 20/44: loss=0.3387 
[epoch 9] step 22/44: loss=0.3356 
[epoch 9] step 24/44: loss=0.3303 
[epoch 9] step 26/44: loss=0.3343 
[epoch 9] step 28/44: loss=0.3311 
[epoch 9] step 30/44: loss=0.3273 
[epoch 9] step 32/44: loss=0.3247 
[epoch 9] step 34/44: loss=0.3223 
[epoch 9] step 36/44: loss=0.3205 
[epoch 9] step 38/44: loss=0.3188 
[epoch 9] step 40/44: loss=0.3157 
[epoch 9] step 42/44: loss=0.3152 
[epoch 9] step 44/44: loss=0.3121 
[epoch 9] val_loss=1.1483 qwk=('0.4874', '0.4941', '0.5427') averageQWK=0.5081 macroEMD=0.2067 tailR0=('0.0185', '0.0000', '0.0000') tailR0avg=0.0062
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    4   30    6    0
     0    4   89   35    0
     0    0   42   80    0
     0    0    3   23    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    6   34    8    0
     0    4   67   42    0
     0    0   42  106    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   46    3    0
     0    7  117   27    0
     0    0   37   62    0
     0    0    1    2    0
[epoch 10] step 2/44: loss=0.2907 
[epoch 10] step 4/44: loss=0.3076 
[epoch 10] step 6/44: loss=0.3041 
[epoch 10] step 8/44: loss=0.2940 
[epoch 10] step 10/44: loss=0.2953 
[epoch 10] step 12/44: loss=0.3025 
[epoch 10] step 14/44: loss=0.3017 
[epoch 10] step 16/44: loss=0.2932 
[epoch 10] step 18/44: loss=0.2913 
[epoch 10] step 20/44: loss=0.2918 
[epoch 10] step 22/44: loss=0.2881 
[epoch 10] step 24/44: loss=0.2896 
[epoch 10] step 26/44: loss=0.2865 
[epoch 10] step 28/44: loss=0.2862 
[epoch 10] step 30/44: loss=0.2874 
[epoch 10] step 32/44: loss=0.2862 
[epoch 10] step 34/44: loss=0.2844 
[epoch 10] step 36/44: loss=0.2843 
[epoch 10] step 38/44: loss=0.2853 
[epoch 10] step 40/44: loss=0.2839 
[epoch 10] step 42/44: loss=0.2806 
[epoch 10] step 44/44: loss=0.2799 
[epoch 10] val_loss=1.2207 qwk=('0.4944', '0.4926', '0.5333') averageQWK=0.5068 macroEMD=0.2004 tailR0=('0.0185', '0.0000', '0.0000') tailR0avg=0.0062
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    3   33    4    0
     0    3   83   41    1
     0    0   39   83    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    3   36    9    0
     0    4   66   43    0
     0    0   34  114    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   32    8    0
     0   18   81   52    0
     0    1   22   76    0
     0    0    1    2    0
[epoch 11] step 2/44: loss=0.2847 
[epoch 11] step 4/44: loss=0.2668 
[epoch 11] step 6/44: loss=0.2610 
[epoch 11] step 8/44: loss=0.2569 
[epoch 11] step 10/44: loss=0.2574 
[epoch 11] step 12/44: loss=0.2561 
[epoch 11] step 14/44: loss=0.2489 
[epoch 11] step 16/44: loss=0.2474 
[epoch 11] step 18/44: loss=0.2560 
[epoch 11] step 20/44: loss=0.2512 
[epoch 11] step 22/44: loss=0.2479 
[epoch 11] step 24/44: loss=0.2476 
[epoch 11] step 26/44: loss=0.2513 
[epoch 11] step 28/44: loss=0.2482 
[epoch 11] step 30/44: loss=0.2483 
[epoch 11] step 32/44: loss=0.2480 
[epoch 11] step 34/44: loss=0.2476 
[epoch 11] step 36/44: loss=0.2459 
[epoch 11] step 38/44: loss=0.2462 
[epoch 11] step 40/44: loss=0.2467 
[epoch 11] step 42/44: loss=0.2461 
[epoch 11] step 44/44: loss=0.2466 
[epoch 11] val_loss=1.2544 qwk=('0.4605', '0.4586', '0.4779') averageQWK=0.4656 macroEMD=0.2128 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    3   32    5    0
     0    3   92   33    0
     0    0   51   71    0
     0    0    3   24    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   37    7    0
     0    5   76   32    0
     0    0   55   93    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   53    0    0
     0    6  127   18    0
     0    0   53   46    0
     0    0    2    1    0
[epoch 12] step 2/44: loss=0.1868 
[epoch 12] step 4/44: loss=0.2205 
[epoch 12] step 6/44: loss=0.2186 
[epoch 12] step 8/44: loss=0.2254 
[epoch 12] step 10/44: loss=0.2257 
[epoch 12] step 12/44: loss=0.2341 
[epoch 12] step 14/44: loss=0.2327 
[epoch 12] step 16/44: loss=0.2300 
[epoch 12] step 18/44: loss=0.2279 
[epoch 12] step 20/44: loss=0.2259 
[epoch 12] step 22/44: loss=0.2274 
[epoch 12] step 24/44: loss=0.2290 
[epoch 12] step 26/44: loss=0.2315 
[epoch 12] step 28/44: loss=0.2321 
[epoch 12] step 30/44: loss=0.2353 
[epoch 12] step 32/44: loss=0.2319 
[epoch 12] step 34/44: loss=0.2295 
[epoch 12] step 36/44: loss=0.2263 
[epoch 12] step 38/44: loss=0.2240 
[epoch 12] step 40/44: loss=0.2239 
[epoch 12] step 42/44: loss=0.2229 
[epoch 12] step 44/44: loss=0.2223 
[epoch 12] val_loss=1.2697 qwk=('0.4657', '0.4973', '0.5225') averageQWK=0.4951 macroEMD=0.1974 tailR0=('0.0185', '0.0500', '0.0000') tailR0avg=0.0228
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    1    0
     0    4   27    9    0
     0    4   68   55    1
     0    0   28   94    0
     0    0    0   26    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    9   27   12    0
     0    6   56   51    0
     0    0   28  120    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   23   43    5    0
     0    6  118   27    0
     0    0   39   60    0
     0    0    1    2    0
[epoch 13] step 2/44: loss=0.2109 
[epoch 13] step 4/44: loss=0.1937 
[epoch 13] step 6/44: loss=0.1927 
[epoch 13] step 8/44: loss=0.1961 
[epoch 13] step 10/44: loss=0.1938 
[epoch 13] step 12/44: loss=0.1926 
[epoch 13] step 14/44: loss=0.1914 
[epoch 13] step 16/44: loss=0.1878 
[epoch 13] step 18/44: loss=0.1904 
[epoch 13] step 20/44: loss=0.1876 
[epoch 13] step 22/44: loss=0.1904 
[epoch 13] step 24/44: loss=0.1890 
[epoch 13] step 26/44: loss=0.1920 
[epoch 13] step 28/44: loss=0.1931 
[epoch 13] step 30/44: loss=0.1924 
[epoch 13] step 32/44: loss=0.1900 
[epoch 13] step 34/44: loss=0.1890 
[epoch 13] step 36/44: loss=0.1875 
[epoch 13] step 38/44: loss=0.1879 
[epoch 13] step 40/44: loss=0.1903 
[epoch 13] step 42/44: loss=0.1917 
[epoch 13] step 44/44: loss=0.1931 
[epoch 13] val_loss=1.3667 qwk=('0.4406', '0.4642', '0.5178') averageQWK=0.4742 macroEMD=0.2122 tailR0=('0.0741', '0.0500', '0.0000') tailR0avg=0.0414
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    0    0
     0    1   33    6    0
     0    1   85   40    2
     0    0   43   77    2
     0    0    3   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    1   37   10    0
     0    2   62   49    0
     0    0   32  115    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   32   38    1    0
     0   18  122   11    0
     0    1   56   42    0
     0    0    2    1    0
[epoch 14] step 2/44: loss=0.1731 
[epoch 14] step 4/44: loss=0.1594 
[epoch 14] step 6/44: loss=0.1607 
[epoch 14] step 8/44: loss=0.1663 
[epoch 14] step 10/44: loss=0.1679 
[epoch 14] step 12/44: loss=0.1679 
[epoch 14] step 14/44: loss=0.1642 
[epoch 14] step 16/44: loss=0.1636 
[epoch 14] step 18/44: loss=0.1668 
[epoch 14] step 20/44: loss=0.1679 
[epoch 14] step 22/44: loss=0.1649 
[epoch 14] step 24/44: loss=0.1648 
[epoch 14] step 26/44: loss=0.1651 
[epoch 14] step 28/44: loss=0.1626 
[epoch 14] step 30/44: loss=0.1648 
[epoch 14] step 32/44: loss=0.1653 
[epoch 14] step 34/44: loss=0.1643 
[epoch 14] step 36/44: loss=0.1636 
[epoch 14] step 38/44: loss=0.1655 
[epoch 14] step 40/44: loss=0.1639 
[epoch 14] step 42/44: loss=0.1657 
[epoch 14] step 44/44: loss=0.1638 
[epoch 14] val_loss=1.3603 qwk=('0.5166', '0.5654', '0.5315') averageQWK=0.5378 macroEMD=0.1879 tailR0=('0.1111', '0.1000', '0.0000') tailR0avg=0.0704
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    9   23    8    0
     0    6   72   49    1
     0    0   37   83    2
     0    0    1   20    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   12   31    5    0
     0    7   75   31    0
     0    0   45  101    2
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   25   43    3    0
     0   10  116   25    0
     0    1   40   58    0
     0    0    1    2    0
[epoch 15] step 2/44: loss=0.1492 
[epoch 15] step 4/44: loss=0.1609 
[epoch 15] step 6/44: loss=0.1595 
[epoch 15] step 8/44: loss=0.1572 
[epoch 15] step 10/44: loss=0.1510 
[epoch 15] step 12/44: loss=0.1493 
[epoch 15] step 14/44: loss=0.1496 
[epoch 15] step 16/44: loss=0.1454 
[epoch 15] step 18/44: loss=0.1465 
[epoch 15] step 20/44: loss=0.1447 
[epoch 15] step 22/44: loss=0.1447 
[epoch 15] step 24/44: loss=0.1465 
[epoch 15] step 26/44: loss=0.1458 
[epoch 15] step 28/44: loss=0.1446 
[epoch 15] step 30/44: loss=0.1452 
[epoch 15] step 32/44: loss=0.1478 
[epoch 15] step 34/44: loss=0.1462 
[epoch 15] step 36/44: loss=0.1457 
[epoch 15] step 38/44: loss=0.1460 
[epoch 15] step 40/44: loss=0.1454 
[epoch 15] step 42/44: loss=0.1455 
[epoch 15] step 44/44: loss=0.1439 
[epoch 15] val_loss=1.5137 qwk=('0.4583', '0.5251', '0.5173') averageQWK=0.5002 macroEMD=0.1970 tailR0=('0.0810', '0.1333', '0.0000') tailR0avg=0.0715
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     0    4   31    5    0
     0    4   94   30    0
     0    0   54   68    0
     0    0    4   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    6   36    6    0
     0    4   84   25    0
     0    0   51   97    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   40    0    0
     0   23  113   15    0
     0    1   56   42    0
     0    0    1    2    0
[epoch 16] step 2/44: loss=0.1363 
[epoch 16] step 4/44: loss=0.1358 
[epoch 16] step 6/44: loss=0.1309 
[epoch 16] step 8/44: loss=0.1273 
[epoch 16] step 10/44: loss=0.1283 
[epoch 16] step 12/44: loss=0.1275 
[epoch 16] step 14/44: loss=0.1338 
[epoch 16] step 16/44: loss=0.1314 
[epoch 16] step 18/44: loss=0.1309 
[epoch 16] step 20/44: loss=0.1324 
[epoch 16] step 22/44: loss=0.1284 
[epoch 16] step 24/44: loss=0.1272 
[epoch 16] step 26/44: loss=0.1262 
[epoch 16] step 28/44: loss=0.1274 
[epoch 16] step 30/44: loss=0.1250 
[epoch 16] step 32/44: loss=0.1240 
[epoch 16] step 34/44: loss=0.1225 
[epoch 16] step 36/44: loss=0.1224 
[epoch 16] step 38/44: loss=0.1234 
[epoch 16] step 40/44: loss=0.1231 
[epoch 16] step 42/44: loss=0.1226 
[epoch 16] step 44/44: loss=0.1220 
[epoch 16] val_loss=1.5109 qwk=('0.4758', '0.4589', '0.5460') averageQWK=0.4936 macroEMD=0.1963 tailR0=('0.1736', '0.1833', '0.0000') tailR0avg=0.1190
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     0    1   31    7    1
     0    1   80   45    2
     0    0   35   84    3
     0    0    1   20    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    2   32   14    0
     0    4   49   59    1
     0    0   21  125    2
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   35   35    1    0
     0   30  104   17    0
     0    1   49   49    0
     0    0    1    2    0
[epoch 17] step 2/44: loss=0.0935 
[epoch 17] step 4/44: loss=0.0977 
[epoch 17] step 6/44: loss=0.1075 
[epoch 17] step 8/44: loss=0.1081 
[epoch 17] step 10/44: loss=0.1065 
[epoch 17] step 12/44: loss=0.1061 
[epoch 17] step 14/44: loss=0.1081 
[epoch 17] step 16/44: loss=0.1045 
[epoch 17] step 18/44: loss=0.1032 
[epoch 17] step 20/44: loss=0.1043 
[epoch 17] step 22/44: loss=0.1056 
[epoch 17] step 24/44: loss=0.1051 
[epoch 17] step 26/44: loss=0.1081 
[epoch 17] step 28/44: loss=0.1057 
[epoch 17] step 30/44: loss=0.1053 
[epoch 17] step 32/44: loss=0.1054 
[epoch 17] step 34/44: loss=0.1043 
[epoch 17] step 36/44: loss=0.1050 
[epoch 17] step 38/44: loss=0.1046 
[epoch 17] step 40/44: loss=0.1041 
[epoch 17] step 42/44: loss=0.1046 
[epoch 17] step 44/44: loss=0.1045 
[epoch 17] val_loss=1.6729 qwk=('0.4533', '0.4831', '0.4754') averageQWK=0.4706 macroEMD=0.1987 tailR0=('0.0810', '0.1333', '0.0000') tailR0avg=0.0715
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     0    2   29    9    0
     0    1   64   62    1
     0    0   27   95    0
     0    0    0   26    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    2   37    9    0
     0    3   65   44    1
     0    0   34  114    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   49    6    0
     0    2  112   37    0
     0    0   36   63    0
     0    0    1    2    0
[epoch 18] step 2/44: loss=0.0885 
[epoch 18] step 4/44: loss=0.0930 
[epoch 18] step 6/44: loss=0.0995 
[epoch 18] step 8/44: loss=0.1047 
[epoch 18] step 10/44: loss=0.1035 
[epoch 18] step 12/44: loss=0.0988 
[epoch 18] step 14/44: loss=0.0986 
[epoch 18] step 16/44: loss=0.0978 
[epoch 18] step 18/44: loss=0.0957 
[epoch 18] step 20/44: loss=0.0970 
[epoch 18] step 22/44: loss=0.0959 
[epoch 18] step 24/44: loss=0.0951 
[epoch 18] step 26/44: loss=0.0933 
[epoch 18] step 28/44: loss=0.0935 
[epoch 18] step 30/44: loss=0.0912 
[epoch 18] step 32/44: loss=0.0904 
[epoch 18] step 34/44: loss=0.0908 
[epoch 18] step 36/44: loss=0.0905 
[epoch 18] step 38/44: loss=0.0906 
[epoch 18] step 40/44: loss=0.0901 
[epoch 18] step 42/44: loss=0.0893 
[epoch 18] step 44/44: loss=0.0894 
[epoch 18] val_loss=1.6392 qwk=('0.4642', '0.4947', '0.5464') averageQWK=0.5018 macroEMD=0.1907 tailR0=('0.1181', '0.1333', '0.0000') tailR0avg=0.0838
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    5   28    7    0
     0    4   79   44    1
     0    0   46   76    0
     0    0    3   21    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    6   33    9    0
     0    4   65   44    0
     0    0   39  109    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   30   40    1    0
     0   24  103   24    0
     0    1   42   56    0
     0    0    1    2    0
[epoch 19] step 2/44: loss=0.0855 
[epoch 19] step 4/44: loss=0.0770 
[epoch 19] step 6/44: loss=0.0761 
[epoch 19] step 8/44: loss=0.0728 
[epoch 19] step 10/44: loss=0.0748 
[epoch 19] step 12/44: loss=0.0788 
[epoch 19] step 14/44: loss=0.0795 
[epoch 19] step 16/44: loss=0.0773 
[epoch 19] step 18/44: loss=0.0754 
[epoch 19] step 20/44: loss=0.0757 
[epoch 19] step 22/44: loss=0.0770 
[epoch 19] step 24/44: loss=0.0781 
[epoch 19] step 26/44: loss=0.0777 
[epoch 19] step 28/44: loss=0.0772 
[epoch 19] step 30/44: loss=0.0780 
[epoch 19] step 32/44: loss=0.0771 
[epoch 19] step 34/44: loss=0.0759 
[epoch 19] step 36/44: loss=0.0750 
[epoch 19] step 38/44: loss=0.0741 
[epoch 19] step 40/44: loss=0.0739 
[epoch 19] step 42/44: loss=0.0733 
[epoch 19] step 44/44: loss=0.0746 
[epoch 19] val_loss=1.7378 qwk=('0.4849', '0.5029', '0.5431') averageQWK=0.5103 macroEMD=0.1922 tailR0=('0.1181', '0.1333', '0.0000') tailR0avg=0.0838
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    5   27    8    0
     0    4   71   52    1
     0    0   36   86    0
     0    0    1   23    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    4   36    8    0
     0    3   73   37    0
     0    0   41  107    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   23   47    1    0
     0    6  124   21    0
     0    0   45   54    0
     0    0    1    2    0
[epoch 20] step 2/44: loss=0.0685 
[epoch 20] step 4/44: loss=0.0651 
[epoch 20] step 6/44: loss=0.0684 
[epoch 20] step 8/44: loss=0.0725 
[epoch 20] step 10/44: loss=0.0672 
[epoch 20] step 12/44: loss=0.0661 
[epoch 20] step 14/44: loss=0.0644 
[epoch 20] step 16/44: loss=0.0640 
[epoch 20] step 18/44: loss=0.0642 
[epoch 20] step 20/44: loss=0.0640 
[epoch 20] step 22/44: loss=0.0646 
[epoch 20] step 24/44: loss=0.0644 
[epoch 20] step 26/44: loss=0.0653 
[epoch 20] step 28/44: loss=0.0638 
[epoch 20] step 30/44: loss=0.0647 
[epoch 20] step 32/44: loss=0.0638 
[epoch 20] step 34/44: loss=0.0640 
[epoch 20] step 36/44: loss=0.0634 
[epoch 20] step 38/44: loss=0.0623 
[epoch 20] step 40/44: loss=0.0623 
[epoch 20] step 42/44: loss=0.0622 
[epoch 20] step 44/44: loss=0.0625 
[epoch 20] val_loss=1.7538 qwk=('0.4918', '0.4940', '0.5396') averageQWK=0.5084 macroEMD=0.1878 tailR0=('0.1551', '0.1333', '0.0000') tailR0avg=0.0961
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     1    2   29    8    0
     0    2   75   50    1
     0    0   36   86    0
     0    0    0   22    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    4   34   10    0
     0    4   59   49    1
     0    1   25  122    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   27   41    3    0
     0   14  109   28    0
     0    2   35   62    0
     0    0    1    2    0
[epoch 21] step 2/44: loss=0.0595 
[epoch 21] step 4/44: loss=0.0603 
[epoch 21] step 6/44: loss=0.0581 
[epoch 21] step 8/44: loss=0.0596 
[epoch 21] step 10/44: loss=0.0597 
[epoch 21] step 12/44: loss=0.0583 
[epoch 21] step 14/44: loss=0.0575 
[epoch 21] step 16/44: loss=0.0562 
[epoch 21] step 18/44: loss=0.0560 
[epoch 21] step 20/44: loss=0.0550 
[epoch 21] step 22/44: loss=0.0548 
[epoch 21] step 24/44: loss=0.0549 
[epoch 21] step 26/44: loss=0.0548 
[epoch 21] step 28/44: loss=0.0550 
[epoch 21] step 30/44: loss=0.0546 
[epoch 21] step 32/44: loss=0.0544 
[epoch 21] step 34/44: loss=0.0542 
[epoch 21] step 36/44: loss=0.0535 
[epoch 21] step 38/44: loss=0.0531 
[epoch 21] step 40/44: loss=0.0524 
[epoch 21] step 42/44: loss=0.0522 
[epoch 21] step 44/44: loss=0.0523 
[epoch 21] val_loss=1.8560 qwk=('0.4915', '0.5304', '0.5313') averageQWK=0.5177 macroEMD=0.1927 tailR0=('0.0995', '0.1333', '0.0000') tailR0avg=0.0776
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    5   29    6    0
     0    2   83   42    1
     0    0   42   80    0
     0    0    2   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    7   33    8    0
     0    3   68   42    0
     0    0   34  113    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   38   33    0    0
     0   37  102   12    0
     0    2   55   42    0
     0    0    1    2    0
[epoch 22] step 2/44: loss=0.0369 
[epoch 22] step 4/44: loss=0.0417 
[epoch 22] step 6/44: loss=0.0409 
[epoch 22] step 8/44: loss=0.0405 
[epoch 22] step 10/44: loss=0.0411 
[epoch 22] step 12/44: loss=0.0422 
[epoch 22] step 14/44: loss=0.0421 
[epoch 22] step 16/44: loss=0.0421 
[epoch 22] step 18/44: loss=0.0427 
[epoch 22] step 20/44: loss=0.0420 
[epoch 22] step 22/44: loss=0.0423 
[epoch 22] step 24/44: loss=0.0433 
[epoch 22] step 26/44: loss=0.0426 
[epoch 22] step 28/44: loss=0.0438 
[epoch 22] step 30/44: loss=0.0430 
[epoch 22] step 32/44: loss=0.0425 
[epoch 22] step 34/44: loss=0.0431 
[epoch 22] step 36/44: loss=0.0428 
[epoch 22] step 38/44: loss=0.0429 
[epoch 22] step 40/44: loss=0.0431 
[epoch 22] step 42/44: loss=0.0428 
[epoch 22] step 44/44: loss=0.0434 
[epoch 22] val_loss=1.8344 qwk=('0.4937', '0.5255', '0.5495') averageQWK=0.5229 macroEMD=0.1823 tailR0=('0.0995', '0.0833', '0.5000') tailR0avg=0.2276
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     1    7   25    7    0
     0    7   78   42    1
     0    0   44   78    0
     0    0    2   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0   10   29    9    0
     0    6   66   41    0
     0    1   33  114    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    0    0    0
     0   31   39    1    0
     0   27  106   18    0
     0    1   46   52    0
     0    0    1    2    0
[epoch 23] step 2/44: loss=0.0471 
[epoch 23] step 4/44: loss=0.0409 
[epoch 23] step 6/44: loss=0.0405 
[epoch 23] step 8/44: loss=0.0387 
[epoch 23] step 10/44: loss=0.0366 
[epoch 23] step 12/44: loss=0.0377 
[epoch 23] step 14/44: loss=0.0376 
[epoch 23] step 16/44: loss=0.0377 
[epoch 23] step 18/44: loss=0.0364 
[epoch 23] step 20/44: loss=0.0360 
[epoch 23] step 22/44: loss=0.0364 
[epoch 23] step 24/44: loss=0.0359 
[epoch 23] step 26/44: loss=0.0362 
[epoch 23] step 28/44: loss=0.0368 
[epoch 23] step 30/44: loss=0.0373 
[epoch 23] step 32/44: loss=0.0364 
[epoch 23] step 34/44: loss=0.0367 
[epoch 23] step 36/44: loss=0.0371 
[epoch 23] step 38/44: loss=0.0368 
[epoch 23] step 40/44: loss=0.0369 
[epoch 23] step 42/44: loss=0.0370 
[epoch 23] step 44/44: loss=0.0369 
[epoch 23] val_loss=1.9249 qwk=('0.4864', '0.5067', '0.5450') averageQWK=0.5127 macroEMD=0.1872 tailR0=('0.0995', '0.1333', '0.0000') tailR0avg=0.0776
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    6   25    9    0
     0    4   73   50    1
     0    0   37   85    0
     0    0    0   25    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    5   34    9    0
     0    5   70   38    0
     0    0   38  110    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   27   44    0    0
     0   14  119   18    0
     0    1   47   51    0
     0    0    1    2    0
[epoch 24] step 2/44: loss=0.0255 
[epoch 24] step 4/44: loss=0.0273 
[epoch 24] step 6/44: loss=0.0266 
[epoch 24] step 8/44: loss=0.0252 
[epoch 24] step 10/44: loss=0.0261 
[epoch 24] step 12/44: loss=0.0270 
[epoch 24] step 14/44: loss=0.0282 
[epoch 24] step 16/44: loss=0.0289 
[epoch 24] step 18/44: loss=0.0302 
[epoch 24] step 20/44: loss=0.0298 
[epoch 24] step 22/44: loss=0.0301 
[epoch 24] step 24/44: loss=0.0305 
[epoch 24] step 26/44: loss=0.0301 
[epoch 24] step 28/44: loss=0.0308 
[epoch 24] step 30/44: loss=0.0307 
[epoch 24] step 32/44: loss=0.0305 
[epoch 24] step 34/44: loss=0.0306 
[epoch 24] step 36/44: loss=0.0305 
[epoch 24] step 38/44: loss=0.0304 
[epoch 24] step 40/44: loss=0.0301 
[epoch 24] step 42/44: loss=0.0305 
[epoch 24] step 44/44: loss=0.0303 
[epoch 24] val_loss=1.9886 qwk=('0.4698', '0.4756', '0.5432') averageQWK=0.4962 macroEMD=0.1989 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     0    3   30    7    0
     0    3   76   48    1
     0    0   36   86    0
     0    0    1   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    3   34   11    0
     0    3   66   44    0
     0    1   28  119    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   40    0    0
     0   23  108   20    0
     0    1   48   50    0
     0    0    1    2    0
[epoch 25] step 2/44: loss=0.0233 
[epoch 25] step 4/44: loss=0.0270 
[epoch 25] step 6/44: loss=0.0285 
[epoch 25] step 8/44: loss=0.0266 
[epoch 25] step 10/44: loss=0.0269 
[epoch 25] step 12/44: loss=0.0281 
[epoch 25] step 14/44: loss=0.0278 
[epoch 25] step 16/44: loss=0.0276 
[epoch 25] step 18/44: loss=0.0264 
[epoch 25] step 20/44: loss=0.0269 
[epoch 25] step 22/44: loss=0.0258 
[epoch 25] step 24/44: loss=0.0261 
[epoch 25] step 26/44: loss=0.0262 
[epoch 25] step 28/44: loss=0.0259 
[epoch 25] step 30/44: loss=0.0260 
[epoch 25] step 32/44: loss=0.0258 
[epoch 25] step 34/44: loss=0.0260 
[epoch 25] step 36/44: loss=0.0260 
[epoch 25] step 38/44: loss=0.0257 
[epoch 25] step 40/44: loss=0.0254 
[epoch 25] step 42/44: loss=0.0254 
[epoch 25] step 44/44: loss=0.0250 
[epoch 25] val_loss=2.1430 qwk=('0.4359', '0.4837', '0.5122') averageQWK=0.4773 macroEMD=0.2004 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    3    1    0
     0    3   30    7    0
     0    1   84   43    0
     0    0   46   76    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    3   36    9    0
     0    3   71   39    0
     0    1   34  113    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   25   46    0    0
     0   12  125   14    0
     0    1   54   44    0
     0    0    1    2    0
[epoch 26] step 2/44: loss=0.0154 
[epoch 26] step 4/44: loss=0.0188 
[epoch 26] step 6/44: loss=0.0176 
[epoch 26] step 8/44: loss=0.0172 
[epoch 26] step 10/44: loss=0.0190 
[epoch 26] step 12/44: loss=0.0192 
[epoch 26] step 14/44: loss=0.0196 
[epoch 26] step 16/44: loss=0.0198 
[epoch 26] step 18/44: loss=0.0205 
[epoch 26] step 20/44: loss=0.0214 
[epoch 26] step 22/44: loss=0.0221 
[epoch 26] step 24/44: loss=0.0216 
[epoch 26] step 26/44: loss=0.0219 
[epoch 26] step 28/44: loss=0.0222 
[epoch 26] step 30/44: loss=0.0217 
[epoch 26] step 32/44: loss=0.0215 
[epoch 26] step 34/44: loss=0.0213 
[epoch 26] step 36/44: loss=0.0213 
[epoch 26] step 38/44: loss=0.0211 
[epoch 26] step 40/44: loss=0.0211 
[epoch 26] step 42/44: loss=0.0211 
[epoch 26] step 44/44: loss=0.0209 
[epoch 26] val_loss=2.0740 qwk=('0.4652', '0.5120', '0.5474') averageQWK=0.5082 macroEMD=0.1909 tailR0=('0.0810', '0.1333', '0.0000') tailR0avg=0.0715
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    1    0
     0    5   27    8    0
     0    4   72   51    1
     0    0   38   84    0
     0    0    0   26    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    6   32   10    0
     0    3   68   42    0
     0    0   33  115    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   27   44    0    0
     0   14  118   19    0
     0    1   46   52    0
     0    0    1    2    0
[epoch 27] step 2/44: loss=0.0171 
[epoch 27] step 4/44: loss=0.0164 
[epoch 27] step 6/44: loss=0.0158 
[epoch 27] step 8/44: loss=0.0170 
[epoch 27] step 10/44: loss=0.0169 
[epoch 27] step 12/44: loss=0.0166 
[epoch 27] step 14/44: loss=0.0164 
[epoch 27] step 16/44: loss=0.0157 
[epoch 27] step 18/44: loss=0.0167 
[epoch 27] step 20/44: loss=0.0167 
[epoch 27] step 22/44: loss=0.0171 
[epoch 27] step 24/44: loss=0.0168 
[epoch 27] step 26/44: loss=0.0167 
[epoch 27] step 28/44: loss=0.0167 
[epoch 27] step 30/44: loss=0.0169 
[epoch 27] step 32/44: loss=0.0165 
[epoch 27] step 34/44: loss=0.0166 
[epoch 27] step 36/44: loss=0.0164 
[epoch 27] step 38/44: loss=0.0162 
[epoch 27] step 40/44: loss=0.0160 
[epoch 27] step 42/44: loss=0.0163 
[epoch 27] step 44/44: loss=0.0162 
[epoch 27] val_loss=2.1532 qwk=('0.4734', '0.4784', '0.5691') averageQWK=0.5070 macroEMD=0.1912 tailR0=('0.0995', '0.0500', '0.0000') tailR0avg=0.0498
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    2    1    0
     0    4   28    8    0
     0    4   71   52    1
     0    0   32   90    0
     0    0    1   24    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    2   37    9    0
     0    3   72   37    1
     0    0   38  109    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   27   44    0    0
     0   16  117   18    0
     0    1   41   57    0
     0    0    1    2    0
[epoch 28] step 2/44: loss=0.0151 
[epoch 28] step 4/44: loss=0.0148 
[epoch 28] step 6/44: loss=0.0136 
[epoch 28] step 8/44: loss=0.0139 
[epoch 28] step 10/44: loss=0.0150 
[epoch 28] step 12/44: loss=0.0146 
[epoch 28] step 14/44: loss=0.0148 
[epoch 28] step 16/44: loss=0.0151 
[epoch 28] step 18/44: loss=0.0154 
[epoch 28] step 20/44: loss=0.0155 
[epoch 28] step 22/44: loss=0.0156 
[epoch 28] step 24/44: loss=0.0151 
[epoch 28] step 26/44: loss=0.0152 
[epoch 28] step 28/44: loss=0.0155 
[epoch 28] step 30/44: loss=0.0156 
[epoch 28] step 32/44: loss=0.0155 
[epoch 28] step 34/44: loss=0.0153 
[epoch 28] step 36/44: loss=0.0151 
[epoch 28] step 38/44: loss=0.0149 
[epoch 28] step 40/44: loss=0.0148 
[epoch 28] step 42/44: loss=0.0145 
[epoch 28] step 44/44: loss=0.0147 
[epoch 28] val_loss=2.1948 qwk=('0.4882', '0.4980', '0.5233') averageQWK=0.5031 macroEMD=0.1942 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    5   29    6    0
     0    4   81   42    1
     0    0   41   81    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7   33    8    0
     0    5   77   31    0
     0    1   44  103    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   45    0    0
     0   17  117   17    0
     0    1   50   48    0
     0    0    1    2    0
[epoch 29] step 2/44: loss=0.0092 
[epoch 29] step 4/44: loss=0.0121 
[epoch 29] step 6/44: loss=0.0129 
[epoch 29] step 8/44: loss=0.0125 
[epoch 29] step 10/44: loss=0.0132 
[epoch 29] step 12/44: loss=0.0134 
[epoch 29] step 14/44: loss=0.0132 
[epoch 29] step 16/44: loss=0.0133 
[epoch 29] step 18/44: loss=0.0132 
[epoch 29] step 20/44: loss=0.0129 
[epoch 29] step 22/44: loss=0.0127 
[epoch 29] step 24/44: loss=0.0124 
[epoch 29] step 26/44: loss=0.0124 
[epoch 29] step 28/44: loss=0.0123 
[epoch 29] step 30/44: loss=0.0119 
[epoch 29] step 32/44: loss=0.0125 
[epoch 29] step 34/44: loss=0.0123 
[epoch 29] step 36/44: loss=0.0125 
[epoch 29] step 38/44: loss=0.0124 
[epoch 29] step 40/44: loss=0.0125 
[epoch 29] step 42/44: loss=0.0123 
[epoch 29] step 44/44: loss=0.0122 
[epoch 29] val_loss=2.2551 qwk=('0.4500', '0.4835', '0.5295') averageQWK=0.4876 macroEMD=0.1986 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    3    1    0
     0    4   28    8    0
     0    1   75   51    1
     0    0   38   84    0
     0    0    0   26    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    2   37    9    0
     0    3   72   38    0
     0    0   36  112    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   45    0    0
     0   16  118   17    0
     0    1   49   49    0
     0    0    1    2    0
[epoch 30] step 2/44: loss=0.0098 
[epoch 30] step 4/44: loss=0.0090 
[epoch 30] step 6/44: loss=0.0095 
[epoch 30] step 8/44: loss=0.0117 
[epoch 30] step 10/44: loss=0.0118 
[epoch 30] step 12/44: loss=0.0113 
[epoch 30] step 14/44: loss=0.0119 
[epoch 30] step 16/44: loss=0.0115 
[epoch 30] step 18/44: loss=0.0117 
[epoch 30] step 20/44: loss=0.0117 
[epoch 30] step 22/44: loss=0.0115 
[epoch 30] step 24/44: loss=0.0111 
[epoch 30] step 26/44: loss=0.0109 
[epoch 30] step 28/44: loss=0.0107 
[epoch 30] step 30/44: loss=0.0106 
[epoch 30] step 32/44: loss=0.0105 
[epoch 30] step 34/44: loss=0.0104 
[epoch 30] step 36/44: loss=0.0107 
[epoch 30] step 38/44: loss=0.0107 
[epoch 30] step 40/44: loss=0.0107 
[epoch 30] step 42/44: loss=0.0107 
[epoch 30] step 44/44: loss=0.0106 
[epoch 30] val_loss=2.2642 qwk=('0.4864', '0.4975', '0.5301') averageQWK=0.5047 macroEMD=0.1911 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    5   28    7    0
     0    4   77   46    1
     0    0   36   86    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6   34    8    0
     0    5   72   36    0
     0    1   39  108    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   45    0    0
     0   11  122   18    0
     0    1   50   48    0
     0    0    1    2    0
[epoch 31] step 2/44: loss=0.0108 
[epoch 31] step 4/44: loss=0.0089 
[epoch 31] step 6/44: loss=0.0087 
[epoch 31] step 8/44: loss=0.0092 
[epoch 31] step 10/44: loss=0.0088 
[epoch 31] step 12/44: loss=0.0089 
[epoch 31] step 14/44: loss=0.0092 
[epoch 31] step 16/44: loss=0.0090 
[epoch 31] step 18/44: loss=0.0091 
[epoch 31] step 20/44: loss=0.0093 
[epoch 31] step 22/44: loss=0.0093 
[epoch 31] step 24/44: loss=0.0103 
[epoch 31] step 26/44: loss=0.0102 
[epoch 31] step 28/44: loss=0.0104 
[epoch 31] step 30/44: loss=0.0103 
[epoch 31] step 32/44: loss=0.0101 
[epoch 31] step 34/44: loss=0.0099 
[epoch 31] step 36/44: loss=0.0098 
[epoch 31] step 38/44: loss=0.0098 
[epoch 31] step 40/44: loss=0.0099 
[epoch 31] step 42/44: loss=0.0099 
[epoch 31] step 44/44: loss=0.0098 
[epoch 31] val_loss=2.2883 qwk=('0.4665', '0.5091', '0.5237') averageQWK=0.4998 macroEMD=0.1929 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    2   30    8    0
     0    4   72   51    1
     0    0   34   88    0
     0    0    1   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6   33    9    0
     0    5   69   39    0
     0    1   31  116    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   28   43    0    0
     0   24  110   17    0
     0    1   50   48    0
     0    0    1    2    0
[epoch 32] step 2/44: loss=0.0073 
[epoch 32] step 4/44: loss=0.0071 
[epoch 32] step 6/44: loss=0.0077 
[epoch 32] step 8/44: loss=0.0074 
[epoch 32] step 10/44: loss=0.0075 
[epoch 32] step 12/44: loss=0.0079 
[epoch 32] step 14/44: loss=0.0078 
[epoch 32] step 16/44: loss=0.0086 
[epoch 32] step 18/44: loss=0.0085 
[epoch 32] step 20/44: loss=0.0088 
[epoch 32] step 22/44: loss=0.0087 
[epoch 32] step 24/44: loss=0.0092 
[epoch 32] step 26/44: loss=0.0091 
[epoch 32] step 28/44: loss=0.0092 
[epoch 32] step 30/44: loss=0.0091 
[epoch 32] step 32/44: loss=0.0092 
[epoch 32] step 34/44: loss=0.0091 
[epoch 32] step 36/44: loss=0.0090 
[epoch 32] step 38/44: loss=0.0089 
[epoch 32] step 40/44: loss=0.0087 
[epoch 32] step 42/44: loss=0.0088 
[epoch 32] step 44/44: loss=0.0089 
[epoch 32] val_loss=2.3206 qwk=('0.4786', '0.4777', '0.5424') averageQWK=0.4996 macroEMD=0.1920 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    3   28    9    0
     0    3   73   51    1
     0    0   32   90    0
     0    0    0   26    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5   34    9    0
     0    4   76   33    0
     0    1   43  104    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   45    0    0
     0   12  123   16    0
     0    1   48   50    0
     0    0    1    2    0
[epoch 33] step 2/44: loss=0.0076 
[epoch 33] step 4/44: loss=0.0067 
[epoch 33] step 6/44: loss=0.0076 
[epoch 33] step 8/44: loss=0.0075 
[epoch 33] step 10/44: loss=0.0078 
[epoch 33] step 12/44: loss=0.0075 
[epoch 33] step 14/44: loss=0.0074 
[epoch 33] step 16/44: loss=0.0072 
[epoch 33] step 18/44: loss=0.0071 
[epoch 33] step 20/44: loss=0.0069 
[epoch 33] step 22/44: loss=0.0075 
[epoch 33] step 24/44: loss=0.0077 
[epoch 33] step 26/44: loss=0.0076 
[epoch 33] step 28/44: loss=0.0076 
[epoch 33] step 30/44: loss=0.0076 
[epoch 33] step 32/44: loss=0.0076 
[epoch 33] step 34/44: loss=0.0077 
[epoch 33] step 36/44: loss=0.0078 
[epoch 33] step 38/44: loss=0.0077 
[epoch 33] step 40/44: loss=0.0078 
[epoch 33] step 42/44: loss=0.0077 
[epoch 33] step 44/44: loss=0.0076 
[epoch 33] val_loss=2.3266 qwk=('0.4784', '0.4735', '0.5309') averageQWK=0.4943 macroEMD=0.1932 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    4   29    7    0
     0    4   77   46    1
     0    0   37   85    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5   34    9    0
     0    5   72   36    0
     0    1   42  105    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   45    0    0
     0   15  119   17    0
     0    1   49   49    0
     0    0    1    2    0
[epoch 34] step 2/44: loss=0.0060 
[epoch 34] step 4/44: loss=0.0056 
[epoch 34] step 6/44: loss=0.0068 
[epoch 34] step 8/44: loss=0.0071 
[epoch 34] step 10/44: loss=0.0069 
[epoch 34] step 12/44: loss=0.0068 
[epoch 34] step 14/44: loss=0.0067 
[epoch 34] step 16/44: loss=0.0066 
[epoch 34] step 18/44: loss=0.0066 
[epoch 34] step 20/44: loss=0.0064 
[epoch 34] step 22/44: loss=0.0064 
[epoch 34] step 24/44: loss=0.0067 
[epoch 34] step 26/44: loss=0.0069 
[epoch 34] step 28/44: loss=0.0067 
[epoch 34] step 30/44: loss=0.0069 
[epoch 34] step 32/44: loss=0.0072 
[epoch 34] step 34/44: loss=0.0072 
[epoch 34] step 36/44: loss=0.0072 
[epoch 34] step 38/44: loss=0.0071 
[epoch 34] step 40/44: loss=0.0071 
[epoch 34] step 42/44: loss=0.0071 
[epoch 34] step 44/44: loss=0.0070 
[epoch 34] val_loss=2.3472 qwk=('0.4925', '0.4900', '0.5453') averageQWK=0.5093 macroEMD=0.1938 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    4   29    7    0
     0    2   75   50    1
     0    0   35   87    0
     0    0    0   26    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   35    9    0
     0    3   73   37    0
     0    0   38  110    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   45    0    0
     0   12  120   19    0
     0    1   46   52    0
     0    0    1    2    0
[epoch 35] step 2/44: loss=0.0065 
[epoch 35] step 4/44: loss=0.0059 
[epoch 35] step 6/44: loss=0.0068 
[epoch 35] step 8/44: loss=0.0061 
[epoch 35] step 10/44: loss=0.0059 
[epoch 35] step 12/44: loss=0.0060 
[epoch 35] step 14/44: loss=0.0059 
[epoch 35] step 16/44: loss=0.0060 
[epoch 35] step 18/44: loss=0.0065 
[epoch 35] step 20/44: loss=0.0067 
[epoch 35] step 22/44: loss=0.0067 
[epoch 35] step 24/44: loss=0.0066 
[epoch 35] step 26/44: loss=0.0066 
[epoch 35] step 28/44: loss=0.0065 
[epoch 35] step 30/44: loss=0.0065 
[epoch 35] step 32/44: loss=0.0067 
[epoch 35] step 34/44: loss=0.0066 
[epoch 35] step 36/44: loss=0.0066 
[epoch 35] step 38/44: loss=0.0065 
[epoch 35] step 40/44: loss=0.0065 
[epoch 35] step 42/44: loss=0.0069 
[epoch 35] step 44/44: loss=0.0068 
[epoch 35] val_loss=2.3333 qwk=('0.4803', '0.5059', '0.5422') averageQWK=0.5095 macroEMD=0.1940 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    4   29    7    0
     0    2   76   49    1
     0    0   37   85    0
     0    0    1   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5   34    9    0
     0    3   73   37    0
     0    0   35  113    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   45    0    0
     0   14  118   19    0
     0    1   46   52    0
     0    0    1    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/ce/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/ce/fold3/metrics.json
Done.
