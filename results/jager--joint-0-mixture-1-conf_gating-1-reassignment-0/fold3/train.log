[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.5056 
[epoch 1] step 4/44: loss=0.5119 
[epoch 1] step 6/44: loss=0.5075 
[epoch 1] step 8/44: loss=0.5036 
[epoch 1] step 10/44: loss=0.5129 
[epoch 1] step 12/44: loss=0.5164 
[epoch 1] step 14/44: loss=0.5182 
[epoch 1] step 16/44: loss=0.5230 
[epoch 1] step 18/44: loss=0.5295 
[epoch 1] step 20/44: loss=0.5358 
[epoch 1] step 22/44: loss=0.5402 
[epoch 1] step 24/44: loss=0.5449 
[epoch 1] step 26/44: loss=0.5495 
[epoch 1] step 28/44: loss=0.5526 
[epoch 1] step 30/44: loss=0.5556 
[epoch 1] step 32/44: loss=0.5589 
[epoch 1] step 34/44: loss=0.5618 
[epoch 1] step 36/44: loss=0.5653 
[epoch 1] step 38/44: loss=0.5670 
[epoch 1] step 40/44: loss=0.5683 
[epoch 1] step 42/44: loss=0.5701 
[epoch 1] step 44/44: loss=0.5716 
[epoch 1] train_loss(avg per step)=1.1432 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=0.8606 qwk=('-0.0636', '0.0318', '0.1132') averageQWK=0.0272 macroEMD=0.3691 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    8    0
     0    3    0   37    0
     0   18    0  110    0
     0   26    0   96    0
     0    1    0   26    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   40    8    0
    11    0   74   28    0
    14    0   92   42    0
     0    0    4    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   11   60    0    0
     0    9  142    0    0
     0    2   96    1    0
     0    0    3    0    0
[epoch 2] step 2/44: loss=0.5634 
[epoch 2] step 4/44: loss=0.5572 
[epoch 2] step 6/44: loss=0.5553 
[epoch 2] step 8/44: loss=0.5519 
[epoch 2] step 10/44: loss=0.5631 
[epoch 2] step 12/44: loss=0.5660 
[epoch 2] step 14/44: loss=0.5638 
[epoch 2] step 16/44: loss=0.5607 
[epoch 2] step 18/44: loss=0.5588 
[epoch 2] step 20/44: loss=0.5591 
[epoch 2] step 22/44: loss=0.5597 
[epoch 2] step 24/44: loss=0.5611 
[epoch 2] step 26/44: loss=0.5630 
[epoch 2] step 28/44: loss=0.5631 
[epoch 2] step 30/44: loss=0.5663 
[epoch 2] step 32/44: loss=0.5698 
[epoch 2] step 34/44: loss=0.5711 
[epoch 2] step 36/44: loss=0.5711 
[epoch 2] step 38/44: loss=0.5725 
[epoch 2] step 40/44: loss=0.5714 
[epoch 2] step 42/44: loss=0.5720 
[epoch 2] step 44/44: loss=0.5703 
[epoch 2] train_loss(avg per step)=1.1407 lambda[min,max]=[0.503230,1.000000]
[epoch 2] val_loss=1.1247 qwk=('0.3513', '0.4195', '0.5144') averageQWK=0.4284 macroEMD=0.3132 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    0    0
     0    0   39    1    0
     0    0  111   17    0
     0    0   71   51    0
     0    0    7   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   41    7    0
     0    0   67   46    0
     0    0   36  112    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    9   60    2    0
     0    0  126   25    0
     0    0   33   66    0
     0    0    0    3    0
[epoch 3] step 2/44: loss=0.6022 
[epoch 3] step 4/44: loss=0.5880 
[epoch 3] step 6/44: loss=0.5806 
[epoch 3] step 8/44: loss=0.5650 
[epoch 3] step 10/44: loss=0.5523 
[epoch 3] step 12/44: loss=0.5524 
[epoch 3] step 14/44: loss=0.5504 
[epoch 3] step 16/44: loss=0.5493 
[epoch 3] step 18/44: loss=0.5481 
[epoch 3] step 20/44: loss=0.5423 
[epoch 3] step 22/44: loss=0.5376 
[epoch 3] step 24/44: loss=0.5408 
[epoch 3] step 26/44: loss=0.5370 
[epoch 3] step 28/44: loss=0.5324 
[epoch 3] step 30/44: loss=0.5289 
[epoch 3] step 32/44: loss=0.5303 
[epoch 3] step 34/44: loss=0.5270 
[epoch 3] step 36/44: loss=0.5252 
[epoch 3] step 38/44: loss=0.5251 
[epoch 3] step 40/44: loss=0.5260 
[epoch 3] step 42/44: loss=0.5252 
[epoch 3] step 44/44: loss=0.5235 
[epoch 3] train_loss(avg per step)=1.0470 lambda[min,max]=[0.503432,1.000000]
[epoch 3] val_loss=1.2232 qwk=('0.3953', '0.2619', '0.1006') averageQWK=0.2526 macroEMD=0.3073 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   31    9    0    0
     0   68   54    6    0
     0   17   80   25    0
     0    2   12   13    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   48    0    0
     0    0  102   11    0
     0    0  105   43    0
     0    0    3    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    5   66    0    0
     0    0  150    1    0
     0    0   94    5    0
     0    0    3    0    0
[epoch 4] step 2/44: loss=0.5600 
[epoch 4] step 4/44: loss=0.5383 
[epoch 4] step 6/44: loss=0.5219 
[epoch 4] step 8/44: loss=0.5224 
[epoch 4] step 10/44: loss=0.5103 
[epoch 4] step 12/44: loss=0.5104 
[epoch 4] step 14/44: loss=0.5129 
[epoch 4] step 16/44: loss=0.5080 
[epoch 4] step 18/44: loss=0.5025 
[epoch 4] step 20/44: loss=0.5090 
[epoch 4] step 22/44: loss=0.5035 
[epoch 4] step 24/44: loss=0.4990 
[epoch 4] step 26/44: loss=0.5010 
[epoch 4] step 28/44: loss=0.5021 
[epoch 4] step 30/44: loss=0.5019 
[epoch 4] step 32/44: loss=0.4992 
[epoch 4] step 34/44: loss=0.4978 
[epoch 4] step 36/44: loss=0.4988 
[epoch 4] step 38/44: loss=0.4972 
[epoch 4] step 40/44: loss=0.4947 
[epoch 4] step 42/44: loss=0.4910 
[epoch 4] step 44/44: loss=0.4893 
[epoch 4] train_loss(avg per step)=0.9785 lambda[min,max]=[0.501219,1.000000]
[epoch 4] val_loss=1.0218 qwk=('0.4763', '0.3992', '0.5422') averageQWK=0.4726 macroEMD=0.2669 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    4   34    2    0
     0    2  109   17    0
     0    0   62   60    0
     0    0    5   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   43    5    0
     0    0   89   24    0
     0    0   58   90    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   45    0    0
     0   15  117   19    0
     0    0   46   53    0
     0    0    2    1    0
[epoch 5] step 2/44: loss=0.4362 
[epoch 5] step 4/44: loss=0.4415 
[epoch 5] step 6/44: loss=0.4545 
[epoch 5] step 8/44: loss=0.4513 
[epoch 5] step 10/44: loss=0.4561 
[epoch 5] step 12/44: loss=0.4576 
[epoch 5] step 14/44: loss=0.4581 
[epoch 5] step 16/44: loss=0.4544 
[epoch 5] step 18/44: loss=0.4569 
[epoch 5] step 20/44: loss=0.4596 
[epoch 5] step 22/44: loss=0.4583 
[epoch 5] step 24/44: loss=0.4636 
[epoch 5] step 26/44: loss=0.4613 
[epoch 5] step 28/44: loss=0.4640 
[epoch 5] step 30/44: loss=0.4630 
[epoch 5] step 32/44: loss=0.4657 
[epoch 5] step 34/44: loss=0.4665 
[epoch 5] step 36/44: loss=0.4650 
[epoch 5] step 38/44: loss=0.4654 
[epoch 5] step 40/44: loss=0.4659 
[epoch 5] step 42/44: loss=0.4644 
[epoch 5] step 44/44: loss=0.4639 
[epoch 5] train_loss(avg per step)=0.9278 lambda[min,max]=[0.500057,1.000000]
[epoch 5] val_loss=0.9787 qwk=('0.4906', '0.4647', '0.5923') averageQWK=0.5159 macroEMD=0.2471 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    0    0
     0    4   34    2    0
     0    2   96   30    0
     0    0   47   75    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   36    8    0
     0    2   73   38    0
     0    0   47  101    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   46    1    0
     0    6  113   32    0
     0    0   30   69    0
     0    0    1    2    0
[epoch 6] step 2/44: loss=0.4149 
[epoch 6] step 4/44: loss=0.4059 
[epoch 6] step 6/44: loss=0.4217 
[epoch 6] step 8/44: loss=0.4259 
[epoch 6] step 10/44: loss=0.4293 
[epoch 6] step 12/44: loss=0.4298 
[epoch 6] step 14/44: loss=0.4338 
[epoch 6] step 16/44: loss=0.4348 
[epoch 6] step 18/44: loss=0.4369 
[epoch 6] step 20/44: loss=0.4331 
[epoch 6] step 22/44: loss=0.4351 
[epoch 6] step 24/44: loss=0.4352 
[epoch 6] step 26/44: loss=0.4336 
[epoch 6] step 28/44: loss=0.4330 
[epoch 6] step 30/44: loss=0.4276 
[epoch 6] step 32/44: loss=0.4278 
[epoch 6] step 34/44: loss=0.4298 
[epoch 6] step 36/44: loss=0.4331 
[epoch 6] step 38/44: loss=0.4379 
[epoch 6] step 40/44: loss=0.4381 
[epoch 6] step 42/44: loss=0.4384 
[epoch 6] step 44/44: loss=0.4380 
[epoch 6] train_loss(avg per step)=0.8759 lambda[min,max]=[0.500007,1.000000]
[epoch 6] val_loss=1.0201 qwk=('0.5344', '0.5106', '0.5672') averageQWK=0.5374 macroEMD=0.2395 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   17   16    7    0
     0   13   67   48    0
     0    1   32   89    0
     0    0    3   24    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   15   24    9    0
     0   12   62   39    0
     0    3   41  104    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   23   47    1    0
     0    8  103   40    0
     0    0   30   69    0
     0    0    1    2    0
[epoch 7] step 2/44: loss=0.3857 
[epoch 7] step 4/44: loss=0.3863 
[epoch 7] step 6/44: loss=0.3922 
[epoch 7] step 8/44: loss=0.3988 
[epoch 7] step 10/44: loss=0.3927 
[epoch 7] step 12/44: loss=0.3806 
[epoch 7] step 14/44: loss=0.3788 
[epoch 7] step 16/44: loss=0.3810 
[epoch 7] step 18/44: loss=0.3842 
[epoch 7] step 20/44: loss=0.3788 
[epoch 7] step 22/44: loss=0.3771 
[epoch 7] step 24/44: loss=0.3768 
[epoch 7] step 26/44: loss=0.3756 
[epoch 7] step 28/44: loss=0.3767 
[epoch 7] step 30/44: loss=0.3792 
[epoch 7] step 32/44: loss=0.3776 
[epoch 7] step 34/44: loss=0.3789 
[epoch 7] step 36/44: loss=0.3800 
[epoch 7] step 38/44: loss=0.3817 
[epoch 7] step 40/44: loss=0.3853 
[epoch 7] step 42/44: loss=0.3881 
[epoch 7] step 44/44: loss=0.3876 
[epoch 7] train_loss(avg per step)=0.7751 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.0011 qwk=('0.5365', '0.4985', '0.5533') averageQWK=0.5294 macroEMD=0.2368 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    7   30    3    0
     0    6   86   36    0
     0    0   39   83    0
     0    0    3   24    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    7   32    9    0
     0    4   67   42    0
     0    1   37  110    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   45    0    0
     0   14  115   22    0
     0    0   45   54    0
     0    0    1    2    0
[epoch 8] step 2/44: loss=0.3313 
[epoch 8] step 4/44: loss=0.3389 
[epoch 8] step 6/44: loss=0.3385 
[epoch 8] step 8/44: loss=0.3429 
[epoch 8] step 10/44: loss=0.3364 
[epoch 8] step 12/44: loss=0.3358 
[epoch 8] step 14/44: loss=0.3424 
[epoch 8] step 16/44: loss=0.3434 
[epoch 8] step 18/44: loss=0.3487 
[epoch 8] step 20/44: loss=0.3431 
[epoch 8] step 22/44: loss=0.3405 
[epoch 8] step 24/44: loss=0.3404 
[epoch 8] step 26/44: loss=0.3416 
[epoch 8] step 28/44: loss=0.3390 
[epoch 8] step 30/44: loss=0.3385 
[epoch 8] step 32/44: loss=0.3378 
[epoch 8] step 34/44: loss=0.3367 
[epoch 8] step 36/44: loss=0.3350 
[epoch 8] step 38/44: loss=0.3352 
[epoch 8] step 40/44: loss=0.3328 
[epoch 8] step 42/44: loss=0.3339 
[epoch 8] step 44/44: loss=0.3354 
[epoch 8] train_loss(avg per step)=0.6709 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.0051 qwk=('0.5644', '0.5341', '0.5965') averageQWK=0.5650 macroEMD=0.2245 tailR0=('0.0370', '0.0000', '0.0000') tailR0avg=0.0123
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   15   22    3    0
     0   13   83   31    1
     0    1   46   73    2
     0    0    3   22    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   15   26    7    0
     0   11   68   34    0
     0    1   48   99    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   37   33    1    0
     0   26  103   22    0
     0    1   38   60    0
     0    0    1    2    0
[epoch 9] step 2/44: loss=0.2827 
[epoch 9] step 4/44: loss=0.3149 
[epoch 9] step 6/44: loss=0.3404 
[epoch 9] step 8/44: loss=0.3305 
[epoch 9] step 10/44: loss=0.3278 
[epoch 9] step 12/44: loss=0.3083 
[epoch 9] step 14/44: loss=0.3054 
[epoch 9] step 16/44: loss=0.3096 
[epoch 9] step 18/44: loss=0.3037 
[epoch 9] step 20/44: loss=0.3061 
[epoch 9] step 22/44: loss=0.3044 
[epoch 9] step 24/44: loss=0.3029 
[epoch 9] step 26/44: loss=0.3079 
[epoch 9] step 28/44: loss=0.3041 
[epoch 9] step 30/44: loss=0.3021 
[epoch 9] step 32/44: loss=0.2981 
[epoch 9] step 34/44: loss=0.2954 
[epoch 9] step 36/44: loss=0.2946 
[epoch 9] step 38/44: loss=0.2952 
[epoch 9] step 40/44: loss=0.2930 
[epoch 9] step 42/44: loss=0.2938 
[epoch 9] step 44/44: loss=0.2913 
[epoch 9] train_loss(avg per step)=0.5827 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.0194 qwk=('0.5596', '0.5320', '0.5440') averageQWK=0.5452 macroEMD=0.2279 tailR0=('0.0370', '0.0000', '0.0000') tailR0avg=0.0123
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   14   22    4    0
     0   13   80   35    0
     0    1   43   75    3
     0    0    3   22    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   16   25    7    0
     0   14   64   35    0
     0    2   46  100    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   40    0    0
     0   22  114   15    0
     0    1   48   50    0
     0    0    2    1    0
[epoch 10] step 2/44: loss=0.2656 
[epoch 10] step 4/44: loss=0.2929 
[epoch 10] step 6/44: loss=0.2672 
[epoch 10] step 8/44: loss=0.2507 
[epoch 10] step 10/44: loss=0.2502 
[epoch 10] step 12/44: loss=0.2508 
[epoch 10] step 14/44: loss=0.2550 
[epoch 10] step 16/44: loss=0.2484 
[epoch 10] step 18/44: loss=0.2470 
[epoch 10] step 20/44: loss=0.2480 
[epoch 10] step 22/44: loss=0.2443 
[epoch 10] step 24/44: loss=0.2458 
[epoch 10] step 26/44: loss=0.2451 
[epoch 10] step 28/44: loss=0.2478 
[epoch 10] step 30/44: loss=0.2494 
[epoch 10] step 32/44: loss=0.2467 
[epoch 10] step 34/44: loss=0.2454 
[epoch 10] step 36/44: loss=0.2463 
[epoch 10] step 38/44: loss=0.2471 
[epoch 10] step 40/44: loss=0.2449 
[epoch 10] step 42/44: loss=0.2423 
[epoch 10] step 44/44: loss=0.2419 
[epoch 10] train_loss(avg per step)=0.4837 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.0296 qwk=('0.5575', '0.5325', '0.5815') averageQWK=0.5572 macroEMD=0.2328 tailR0=('0.0185', '0.0000', '0.0000') tailR0avg=0.0062
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   13   24    3    0
     0   12   84   32    0
     0    2   42   77    1
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   13   30    5    0
     0    9   73   31    0
     0    2   50   96    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   43   26    2    0
     0   33   90   28    0
     0    2   38   59    0
     0    0    1    2    0
[epoch 11] step 2/44: loss=0.2451 
[epoch 11] step 4/44: loss=0.2343 
[epoch 11] step 6/44: loss=0.2206 
[epoch 11] step 8/44: loss=0.2175 
[epoch 11] step 10/44: loss=0.2059 
[epoch 11] step 12/44: loss=0.2000 
[epoch 11] step 14/44: loss=0.1966 
[epoch 11] step 16/44: loss=0.1979 
[epoch 11] step 18/44: loss=0.2045 
[epoch 11] step 20/44: loss=0.2034 
[epoch 11] step 22/44: loss=0.2053 
[epoch 11] step 24/44: loss=0.2048 
[epoch 11] step 26/44: loss=0.2108 
[epoch 11] step 28/44: loss=0.2102 
[epoch 11] step 30/44: loss=0.2100 
[epoch 11] step 32/44: loss=0.2110 
[epoch 11] step 34/44: loss=0.2086 
[epoch 11] step 36/44: loss=0.2077 
[epoch 11] step 38/44: loss=0.2112 
[epoch 11] step 40/44: loss=0.2139 
[epoch 11] step 42/44: loss=0.2124 
[epoch 11] step 44/44: loss=0.2119 
[epoch 11] train_loss(avg per step)=0.4237 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=1.0173 qwk=('0.5241', '0.4941', '0.5195') averageQWK=0.5126 macroEMD=0.2337 tailR0=('0.0370', '0.0000', '0.0000') tailR0avg=0.0123
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    4   33    3    0
     0    2   92   34    0
     0    0   47   73    2
     0    0    2   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    6   34    8    0
     0    5   69   39    0
     0    0   44  104    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   51    0    0
     0    6  121   24    0
     0    0   47   52    0
     0    0    1    2    0
[epoch 12] step 2/44: loss=0.1164 
[epoch 12] step 4/44: loss=0.1580 
[epoch 12] step 6/44: loss=0.1634 
[epoch 12] step 8/44: loss=0.1798 
[epoch 12] step 10/44: loss=0.1841 
[epoch 12] step 12/44: loss=0.1910 
[epoch 12] step 14/44: loss=0.1853 
[epoch 12] step 16/44: loss=0.1786 
[epoch 12] step 18/44: loss=0.1791 
[epoch 12] step 20/44: loss=0.1811 
[epoch 12] step 22/44: loss=0.1837 
[epoch 12] step 24/44: loss=0.1845 
[epoch 12] step 26/44: loss=0.1852 
[epoch 12] step 28/44: loss=0.1874 
[epoch 12] step 30/44: loss=0.1923 
[epoch 12] step 32/44: loss=0.1907 
[epoch 12] step 34/44: loss=0.1880 
[epoch 12] step 36/44: loss=0.1838 
[epoch 12] step 38/44: loss=0.1805 
[epoch 12] step 40/44: loss=0.1803 
[epoch 12] step 42/44: loss=0.1806 
[epoch 12] step 44/44: loss=0.1797 
[epoch 12] train_loss(avg per step)=0.3594 lambda[min,max]=[0.496935,1.000000]
[epoch 12] val_loss=1.0632 qwk=('0.5079', '0.5127', '0.4965') averageQWK=0.5057 macroEMD=0.2287 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    5   26    9    0
     0    5   71   52    0
     0    0   26   96    0
     0    0    0   27    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   11   25   12    0
     0    6   51   56    0
     0    1   24  123    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   51    0    0
     0    9  128   14    0
     0    0   55   44    0
     0    0    1    2    0
[epoch 13] step 2/44: loss=0.1652 
[epoch 13] step 4/44: loss=0.1439 
[epoch 13] step 6/44: loss=0.1516 
[epoch 13] step 8/44: loss=0.1563 
[epoch 13] step 10/44: loss=0.1513 
[epoch 13] step 12/44: loss=0.1526 
[epoch 13] step 14/44: loss=0.1528 
[epoch 13] step 16/44: loss=0.1456 
[epoch 13] step 18/44: loss=0.1470 
[epoch 13] step 20/44: loss=0.1442 
[epoch 13] step 22/44: loss=0.1445 
[epoch 13] step 24/44: loss=0.1433 
[epoch 13] step 26/44: loss=0.1469 
[epoch 13] step 28/44: loss=0.1476 
[epoch 13] step 30/44: loss=0.1469 
[epoch 13] step 32/44: loss=0.1452 
[epoch 13] step 34/44: loss=0.1446 
[epoch 13] step 36/44: loss=0.1442 
[epoch 13] step 38/44: loss=0.1441 
[epoch 13] step 40/44: loss=0.1457 
[epoch 13] step 42/44: loss=0.1464 
[epoch 13] step 44/44: loss=0.1476 
[epoch 13] train_loss(avg per step)=0.2952 lambda[min,max]=[0.496337,1.000000]
[epoch 13] val_loss=1.0466 qwk=('0.5126', '0.5018', '0.5164') averageQWK=0.5103 macroEMD=0.2304 tailR0=('0.0741', '0.0000', '0.0000') tailR0avg=0.0247
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0    9   26    5    0
     0    9   81   36    2
     0    1   48   70    3
     0    0    3   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   11   28    9    0
     0    7   74   32    0
     0    1   49   98    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   28   43    0    0
     0   12  127   12    0
     0    0   57   42    0
     0    1    0    2    0
[epoch 14] step 2/44: loss=0.0896 
[epoch 14] step 4/44: loss=0.1011 
[epoch 14] step 6/44: loss=0.1082 
[epoch 14] step 8/44: loss=0.1158 
[epoch 14] step 10/44: loss=0.1219 
[epoch 14] step 12/44: loss=0.1226 
[epoch 14] step 14/44: loss=0.1155 
[epoch 14] step 16/44: loss=0.1089 
[epoch 14] step 18/44: loss=0.1092 
[epoch 14] step 20/44: loss=0.1072 
[epoch 14] step 22/44: loss=0.1046 
[epoch 14] step 24/44: loss=0.1036 
[epoch 14] step 26/44: loss=0.1036 
[epoch 14] step 28/44: loss=0.1020 
[epoch 14] step 30/44: loss=0.1036 
[epoch 14] step 32/44: loss=0.1045 
[epoch 14] step 34/44: loss=0.1053 
[epoch 14] step 36/44: loss=0.1068 
[epoch 14] step 38/44: loss=0.1077 
[epoch 14] step 40/44: loss=0.1074 
[epoch 14] step 42/44: loss=0.1101 
[epoch 14] step 44/44: loss=0.1090 
[epoch 14] train_loss(avg per step)=0.2180 lambda[min,max]=[0.435274,1.000000]
[epoch 14] val_loss=1.0971 qwk=('0.5654', '0.5195', '0.5038') averageQWK=0.5295 macroEMD=0.2187 tailR0=('0.0370', '0.0000', '0.0000') tailR0avg=0.0123
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   11   24    5    0
     0   13   76   39    0
     0    1   36   84    1
     0    0    1   24    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   17   23    8    0
     0   15   70   28    0
     0    2   54   92    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   21   50    0    0
     0   12  123   16    0
     0    0   53   46    0
     0    0    1    2    0
[epoch 15] step 2/44: loss=0.0625 
[epoch 15] step 4/44: loss=0.0920 
[epoch 15] step 6/44: loss=0.0967 
[epoch 15] step 8/44: loss=0.0943 
[epoch 15] step 10/44: loss=0.0891 
[epoch 15] step 12/44: loss=0.0882 
[epoch 15] step 14/44: loss=0.0865 
[epoch 15] step 16/44: loss=0.0788 
[epoch 15] step 18/44: loss=0.0799 
[epoch 15] step 20/44: loss=0.0847 
[epoch 15] step 22/44: loss=0.0881 
[epoch 15] step 24/44: loss=0.0912 
[epoch 15] step 26/44: loss=0.0922 
[epoch 15] step 28/44: loss=0.0911 
[epoch 15] step 30/44: loss=0.0932 
[epoch 15] step 32/44: loss=0.0970 
[epoch 15] step 34/44: loss=0.0982 
[epoch 15] step 36/44: loss=0.0980 
[epoch 15] step 38/44: loss=0.0971 
[epoch 15] step 40/44: loss=0.0977 
[epoch 15] step 42/44: loss=0.0984 
[epoch 15] step 44/44: loss=0.0961 
[epoch 15] train_loss(avg per step)=0.1922 lambda[min,max]=[0.394649,1.000000]
[epoch 15] val_loss=1.1026 qwk=('0.5322', '0.5121', '0.4719') averageQWK=0.5054 macroEMD=0.2282 tailR0=('0.0185', '0.0000', '0.0000') tailR0avg=0.0062
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   10   25    5    0
     0   11   83   34    0
     0    1   46   74    1
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   13   28    7    0
     0   10   75   28    0
     0    1   53   94    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   33   38    0    0
     0   20  123    8    0
     0    1   66   32    0
     0    1    1    1    0
[epoch 16] step 2/44: loss=0.1034 
[epoch 16] step 4/44: loss=0.0932 
[epoch 16] step 6/44: loss=0.0723 
[epoch 16] step 8/44: loss=0.0707 
[epoch 16] step 10/44: loss=0.0705 
[epoch 16] step 12/44: loss=0.0685 
[epoch 16] step 14/44: loss=0.0765 
[epoch 16] step 16/44: loss=0.0752 
[epoch 16] step 18/44: loss=0.0718 
[epoch 16] step 20/44: loss=0.0765 
[epoch 16] step 22/44: loss=0.0704 
[epoch 16] step 24/44: loss=0.0713 
[epoch 16] step 26/44: loss=0.0686 
[epoch 16] step 28/44: loss=0.0703 
[epoch 16] step 30/44: loss=0.0667 
[epoch 16] step 32/44: loss=0.0646 
[epoch 16] step 34/44: loss=0.0615 
[epoch 16] step 36/44: loss=0.0620 
[epoch 16] step 38/44: loss=0.0622 
[epoch 16] step 40/44: loss=0.0621 
[epoch 16] step 42/44: loss=0.0623 
[epoch 16] step 44/44: loss=0.0634 
[epoch 16] train_loss(avg per step)=0.1269 lambda[min,max]=[0.365968,1.000000]
[epoch 16] val_loss=1.1115 qwk=('0.5484', '0.5234', '0.4817') averageQWK=0.5178 macroEMD=0.2275 tailR0=('0.1296', '0.0000', '0.0000') tailR0avg=0.0432
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   10   28    2    0
     0   10   97   20    1
     0    1   62   56    3
     0    0    4   16    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   16   26    6    0
     0   15   78   20    0
     0    3   59   86    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   40    0    0
     0   20  121   10    0
     0    0   66   33    0
     0    1    0    2    0
[epoch 17] step 2/44: loss=0.0256 
[epoch 17] step 4/44: loss=0.0241 
[epoch 17] step 6/44: loss=0.0408 
[epoch 17] step 8/44: loss=0.0373 
[epoch 17] step 10/44: loss=0.0341 
[epoch 17] step 12/44: loss=0.0332 
[epoch 17] step 14/44: loss=0.0338 
[epoch 17] step 16/44: loss=0.0324 
[epoch 17] step 18/44: loss=0.0315 
[epoch 17] step 20/44: loss=0.0341 
[epoch 17] step 22/44: loss=0.0347 
[epoch 17] step 24/44: loss=0.0306 
[epoch 17] step 26/44: loss=0.0330 
[epoch 17] step 28/44: loss=0.0315 
[epoch 17] step 30/44: loss=0.0308 
[epoch 17] step 32/44: loss=0.0319 
[epoch 17] step 34/44: loss=0.0297 
[epoch 17] step 36/44: loss=0.0300 
[epoch 17] step 38/44: loss=0.0301 
[epoch 17] step 40/44: loss=0.0289 
[epoch 17] step 42/44: loss=0.0312 
[epoch 17] step 44/44: loss=0.0327 
[epoch 17] train_loss(avg per step)=0.0654 lambda[min,max]=[0.386760,1.000000]
[epoch 17] val_loss=1.1209 qwk=('0.5670', '0.5118', '0.5104') averageQWK=0.5297 macroEMD=0.2221 tailR0=('0.1111', '0.1000', '0.0000') tailR0avg=0.0704
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   10   24    6    0
     0    9   65   54    0
     0    0   33   83    6
     0    0    0   21    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   13   23   12    0
     0   12   57   44    0
     0    2   30  115    1
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   25   44    2    0
     0   10  116   25    0
     0    0   46   53    0
     0    1    0    2    0
[epoch 18] step 2/44: loss=0.0165 
[epoch 18] step 4/44: loss=0.0402 
[epoch 18] step 6/44: loss=0.0328 
[epoch 18] step 8/44: loss=0.0320 
[epoch 18] step 10/44: loss=0.0291 
[epoch 18] step 12/44: loss=0.0298 
[epoch 18] step 14/44: loss=0.0319 
[epoch 18] step 16/44: loss=0.0313 
[epoch 18] step 18/44: loss=0.0299 
[epoch 18] step 20/44: loss=0.0289 
[epoch 18] step 22/44: loss=0.0270 
[epoch 18] step 24/44: loss=0.0256 
[epoch 18] step 26/44: loss=0.0234 
[epoch 18] step 28/44: loss=0.0227 
[epoch 18] step 30/44: loss=0.0226 
[epoch 18] step 32/44: loss=0.0207 
[epoch 18] step 34/44: loss=0.0210 
[epoch 18] step 36/44: loss=0.0223 
[epoch 18] step 38/44: loss=0.0236 
[epoch 18] step 40/44: loss=0.0234 
[epoch 18] step 42/44: loss=0.0224 
[epoch 18] step 44/44: loss=0.0220 
[epoch 18] train_loss(avg per step)=0.0440 lambda[min,max]=[0.403602,1.000000]
[epoch 18] val_loss=1.2009 qwk=('0.4780', '0.5016', '0.4622') averageQWK=0.4806 macroEMD=0.2308 tailR0=('0.1111', '0.0000', '0.0000') tailR0avg=0.0370
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   11   27    2    0
     1   12  100   15    0
     0    0   78   41    3
     0    0   10   11    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     1   14   25    8    0
     1   13   72   27    0
     0    3   51   94    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   43   28    0    0
     0   33  111    7    0
     0    5   66   28    0
     0    1    1    1    0
[epoch 19] step 2/44: loss=0.0274 
[epoch 19] step 4/44: loss=0.0135 
[epoch 19] step 6/44: loss=-0.0012 
[epoch 19] step 8/44: loss=-0.0068 
[epoch 19] step 10/44: loss=0.0084 
[epoch 19] step 12/44: loss=0.0133 
[epoch 19] step 14/44: loss=0.0092 
[epoch 19] step 16/44: loss=0.0046 
[epoch 19] step 18/44: loss=0.0022 
[epoch 19] step 20/44: loss=0.0001 
[epoch 19] step 22/44: loss=0.0029 
[epoch 19] step 24/44: loss=0.0039 
[epoch 19] step 26/44: loss=0.0026 
[epoch 19] step 28/44: loss=0.0017 
[epoch 19] step 30/44: loss=0.0014 
[epoch 19] step 32/44: loss=-0.0018 
[epoch 19] step 34/44: loss=-0.0023 
[epoch 19] step 36/44: loss=-0.0041 
[epoch 19] step 38/44: loss=-0.0047 
[epoch 19] step 40/44: loss=-0.0043 
[epoch 19] step 42/44: loss=-0.0047 
[epoch 19] step 44/44: loss=-0.0032 
[epoch 19] train_loss(avg per step)=-0.0064 lambda[min,max]=[0.363666,1.000000]
[epoch 19] val_loss=1.2132 qwk=('0.5288', '0.5043', '0.4196') averageQWK=0.4842 macroEMD=0.2240 tailR0=('0.1481', '0.1000', '0.0000') tailR0avg=0.0827
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    5   30    5    0
     0    4   81   43    0
     0    0   43   75    4
     0    0    3   16    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7   33    8    0
     0    6   78   29    0
     0    0   50   98    0
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   56    1    0
     0    6  125   20    0
     0    0   56   43    0
     0    1    0    2    0
[epoch 20] step 2/44: loss=-0.0124 
[epoch 20] step 4/44: loss=-0.0220 
[epoch 20] step 6/44: loss=-0.0157 
[epoch 20] step 8/44: loss=-0.0108 
[epoch 20] step 10/44: loss=-0.0149 
[epoch 20] step 12/44: loss=-0.0129 
[epoch 20] step 14/44: loss=-0.0137 
[epoch 20] step 16/44: loss=-0.0172 
[epoch 20] step 18/44: loss=-0.0168 
[epoch 20] step 20/44: loss=-0.0172 
[epoch 20] step 22/44: loss=-0.0165 
[epoch 20] step 24/44: loss=-0.0181 
[epoch 20] step 26/44: loss=-0.0182 
[epoch 20] step 28/44: loss=-0.0206 
[epoch 20] step 30/44: loss=-0.0203 
[epoch 20] step 32/44: loss=-0.0218 
[epoch 20] step 34/44: loss=-0.0212 
[epoch 20] step 36/44: loss=-0.0228 
[epoch 20] step 38/44: loss=-0.0233 
[epoch 20] step 40/44: loss=-0.0223 
[epoch 20] step 42/44: loss=-0.0224 
[epoch 20] step 44/44: loss=-0.0206 
[epoch 20] train_loss(avg per step)=-0.0413 lambda[min,max]=[0.401978,1.000000]
[epoch 20] val_loss=1.1987 qwk=('0.5517', '0.5081', '0.4917') averageQWK=0.5172 macroEMD=0.2114 tailR0=('0.1296', '0.0500', '0.0000') tailR0avg=0.0599
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0    8   27    5    0
     0    7   80   41    0
     0    0   45   76    1
     0    0    2   18    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    9   31    8    0
     0    7   84   22    0
     0    0   55   93    0
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   49    0    0
     0    8  121   22    0
     0    0   52   47    0
     0    1    0    2    0
[epoch 21] step 2/44: loss=-0.0390 
[epoch 21] step 4/44: loss=-0.0331 
[epoch 21] step 6/44: loss=-0.0354 
[epoch 21] step 8/44: loss=-0.0280 
[epoch 21] step 10/44: loss=-0.0307 
[epoch 21] step 12/44: loss=-0.0304 
[epoch 21] step 14/44: loss=-0.0311 
[epoch 21] step 16/44: loss=-0.0334 
[epoch 21] step 18/44: loss=-0.0333 
[epoch 21] step 20/44: loss=-0.0344 
[epoch 21] step 22/44: loss=-0.0334 
[epoch 21] step 24/44: loss=-0.0321 
[epoch 21] step 26/44: loss=-0.0327 
[epoch 21] step 28/44: loss=-0.0321 
[epoch 21] step 30/44: loss=-0.0323 
[epoch 21] step 32/44: loss=-0.0330 
[epoch 21] step 34/44: loss=-0.0339 
[epoch 21] step 36/44: loss=-0.0337 
[epoch 21] step 38/44: loss=-0.0347 
[epoch 21] step 40/44: loss=-0.0358 
[epoch 21] step 42/44: loss=-0.0354 
[epoch 21] step 44/44: loss=-0.0369 
[epoch 21] train_loss(avg per step)=-0.0738 lambda[min,max]=[0.358487,1.000000]
[epoch 21] val_loss=1.2375 qwk=('0.5493', '0.5302', '0.4342') averageQWK=0.5046 macroEMD=0.2113 tailR0=('0.1551', '0.1000', '0.0000') tailR0avg=0.0850
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     0    8   29    3    0
     0    8   83   37    0
     0    0   50   70    2
     0    0    3   19    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   16   26    6    0
     1   12   78   22    0
     0    3   55   90    0
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   19   52    0    0
     0    7  134   10    0
     0    0   62   37    0
     0    1    1    1    0
[epoch 22] step 2/44: loss=-0.0464 
[epoch 22] step 4/44: loss=-0.0475 
[epoch 22] step 6/44: loss=-0.0444 
[epoch 22] step 8/44: loss=-0.0480 
[epoch 22] step 10/44: loss=-0.0469 
[epoch 22] step 12/44: loss=-0.0451 
[epoch 22] step 14/44: loss=-0.0439 
[epoch 22] step 16/44: loss=-0.0446 
[epoch 22] step 18/44: loss=-0.0435 
[epoch 22] step 20/44: loss=-0.0442 
[epoch 22] step 22/44: loss=-0.0443 
[epoch 22] step 24/44: loss=-0.0438 
[epoch 22] step 26/44: loss=-0.0455 
[epoch 22] step 28/44: loss=-0.0453 
[epoch 22] step 30/44: loss=-0.0467 
[epoch 22] step 32/44: loss=-0.0463 
[epoch 22] step 34/44: loss=-0.0456 
[epoch 22] step 36/44: loss=-0.0458 
[epoch 22] step 38/44: loss=-0.0459 
[epoch 22] step 40/44: loss=-0.0465 
[epoch 22] step 42/44: loss=-0.0473 
[epoch 22] step 44/44: loss=-0.0481 
[epoch 22] train_loss(avg per step)=-0.0962 lambda[min,max]=[0.365203,1.000000]
[epoch 22] val_loss=1.2301 qwk=('0.5629', '0.4903', '0.4701') averageQWK=0.5078 macroEMD=0.2134 tailR0=('0.1852', '0.1000', '0.0000') tailR0avg=0.0951
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0    9   28    3    0
     0    8   90   29    1
     0    0   57   59    6
     0    0    3   14   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    8   28   12    0
     1    7   69   36    0
     0    0   40  107    1
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   23   48    0    0
     0   11  128   12    0
     0    1   58   40    0
     0    1    0    2    0
[epoch 23] step 2/44: loss=-0.0554 
[epoch 23] step 4/44: loss=-0.0593 
[epoch 23] step 6/44: loss=-0.0570 
[epoch 23] step 8/44: loss=-0.0600 
[epoch 23] step 10/44: loss=-0.0600 
[epoch 23] step 12/44: loss=-0.0596 
[epoch 23] step 14/44: loss=-0.0587 
[epoch 23] step 16/44: loss=-0.0560 
[epoch 23] step 18/44: loss=-0.0582 
[epoch 23] step 20/44: loss=-0.0573 
[epoch 23] step 22/44: loss=-0.0559 
[epoch 23] step 24/44: loss=-0.0578 
[epoch 23] step 26/44: loss=-0.0571 
[epoch 23] step 28/44: loss=-0.0570 
[epoch 23] step 30/44: loss=-0.0576 
[epoch 23] step 32/44: loss=-0.0587 
[epoch 23] step 34/44: loss=-0.0574 
[epoch 23] step 36/44: loss=-0.0569 
[epoch 23] step 38/44: loss=-0.0572 
[epoch 23] step 40/44: loss=-0.0569 
[epoch 23] step 42/44: loss=-0.0569 
[epoch 23] step 44/44: loss=-0.0569 
[epoch 23] train_loss(avg per step)=-0.1139 lambda[min,max]=[0.366581,1.000000]
[epoch 23] val_loss=1.3244 qwk=('0.5285', '0.4769', '0.4165') averageQWK=0.4740 macroEMD=0.2145 tailR0=('0.1481', '0.1000', '0.0000') tailR0avg=0.0827
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    7   28    5    0
     0    6   82   40    0
     0    0   51   69    2
     0    0    2   17    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7   32    9    0
     0    7   80   25    1
     0    2   51   92    3
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   57    0    0
     0    6  127   18    0
     0    0   59   40    0
     0    1    0    2    0
[epoch 24] step 2/44: loss=-0.0529 
[epoch 24] step 4/44: loss=-0.0649 
[epoch 24] step 6/44: loss=-0.0632 
[epoch 24] step 8/44: loss=-0.0676 
[epoch 24] step 10/44: loss=-0.0654 
[epoch 24] step 12/44: loss=-0.0653 
[epoch 24] step 14/44: loss=-0.0646 
[epoch 24] step 16/44: loss=-0.0640 
[epoch 24] step 18/44: loss=-0.0633 
[epoch 24] step 20/44: loss=-0.0645 
[epoch 24] step 22/44: loss=-0.0651 
[epoch 24] step 24/44: loss=-0.0648 
[epoch 24] step 26/44: loss=-0.0647 
[epoch 24] step 28/44: loss=-0.0646 
[epoch 24] step 30/44: loss=-0.0653 
[epoch 24] step 32/44: loss=-0.0657 
[epoch 24] step 34/44: loss=-0.0658 
[epoch 24] step 36/44: loss=-0.0653 
[epoch 24] step 38/44: loss=-0.0653 
[epoch 24] step 40/44: loss=-0.0657 
[epoch 24] step 42/44: loss=-0.0653 
[epoch 24] step 44/44: loss=-0.0659 
[epoch 24] train_loss(avg per step)=-0.1319 lambda[min,max]=[0.392001,1.000000]
[epoch 24] val_loss=1.2972 qwk=('0.5393', '0.5105', '0.4630') averageQWK=0.5043 macroEMD=0.2094 tailR0=('0.1921', '0.1000', '0.0000') tailR0avg=0.0974
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1    6   29    4    0
     0    5   85   38    0
     0    0   50   70    2
     0    0    3   17    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   14   26    8    0
     2    9   76   25    1
     0    2   51   95    0
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   23   48    0    0
     0    7  132   12    0
     0    0   63   36    0
     0    1    0    2    0
[epoch 25] step 2/44: loss=-0.0782 
[epoch 25] step 4/44: loss=-0.0775 
[epoch 25] step 6/44: loss=-0.0746 
[epoch 25] step 8/44: loss=-0.0781 
[epoch 25] step 10/44: loss=-0.0768 
[epoch 25] step 12/44: loss=-0.0755 
[epoch 25] step 14/44: loss=-0.0773 
[epoch 25] step 16/44: loss=-0.0770 
[epoch 25] step 18/44: loss=-0.0783 
[epoch 25] step 20/44: loss=-0.0778 
[epoch 25] step 22/44: loss=-0.0785 
[epoch 25] step 24/44: loss=-0.0778 
[epoch 25] step 26/44: loss=-0.0764 
[epoch 25] step 28/44: loss=-0.0768 
[epoch 25] step 30/44: loss=-0.0767 
[epoch 25] step 32/44: loss=-0.0771 
[epoch 25] step 34/44: loss=-0.0765 
[epoch 25] step 36/44: loss=-0.0761 
[epoch 25] step 38/44: loss=-0.0763 
[epoch 25] step 40/44: loss=-0.0764 
[epoch 25] step 42/44: loss=-0.0758 
[epoch 25] step 44/44: loss=-0.0761 
[epoch 25] train_loss(avg per step)=-0.1521 lambda[min,max]=[0.403857,1.000000]
[epoch 25] val_loss=1.2893 qwk=('0.5461', '0.5541', '0.5065') averageQWK=0.5356 macroEMD=0.2028 tailR0=('0.2106', '0.1833', '0.5000') tailR0avg=0.2980
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     1    7   29    3    0
     0    7   87   33    1
     0    0   58   60    4
     0    0    3   16    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    0    0
     1   16   23    8    0
     1   11   69   31    1
     0    2   44  102    0
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    0    0    0
     0   24   47    0    0
     0    9  125   17    0
     0    0   55   44    0
     0    1    0    2    0
[epoch 26] step 2/44: loss=-0.0913 
[epoch 26] step 4/44: loss=-0.0888 
[epoch 26] step 6/44: loss=-0.0856 
[epoch 26] step 8/44: loss=-0.0866 
[epoch 26] step 10/44: loss=-0.0857 
[epoch 26] step 12/44: loss=-0.0879 
[epoch 26] step 14/44: loss=-0.0872 
[epoch 26] step 16/44: loss=-0.0867 
[epoch 26] step 18/44: loss=-0.0837 
[epoch 26] step 20/44: loss=-0.0833 
[epoch 26] step 22/44: loss=-0.0828 
[epoch 26] step 24/44: loss=-0.0832 
[epoch 26] step 26/44: loss=-0.0831 
[epoch 26] step 28/44: loss=-0.0816 
[epoch 26] step 30/44: loss=-0.0820 
[epoch 26] step 32/44: loss=-0.0828 
[epoch 26] step 34/44: loss=-0.0827 
[epoch 26] step 36/44: loss=-0.0824 
[epoch 26] step 38/44: loss=-0.0824 
[epoch 26] step 40/44: loss=-0.0824 
[epoch 26] step 42/44: loss=-0.0822 
[epoch 26] step 44/44: loss=-0.0828 
[epoch 26] train_loss(avg per step)=-0.1656 lambda[min,max]=[0.359786,1.000000]
[epoch 26] val_loss=1.3128 qwk=('0.5429', '0.5300', '0.4977') averageQWK=0.5235 macroEMD=0.2014 tailR0=('0.2106', '0.0500', '0.5000') tailR0avg=0.2535
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     1    7   28    4    0
     0    7   76   44    1
     0    0   48   69    5
     0    0    3   16    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   15   25    8    0
     0   10   72   31    0
     0    3   42  102    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    0    0    0
     1   15   53    2    0
     0    7  113   31    0
     0    0   39   60    0
     0    1    0    2    0
[epoch 27] step 2/44: loss=-0.0954 
[epoch 27] step 4/44: loss=-0.0891 
[epoch 27] step 6/44: loss=-0.0863 
[epoch 27] step 8/44: loss=-0.0865 
[epoch 27] step 10/44: loss=-0.0856 
[epoch 27] step 12/44: loss=-0.0847 
[epoch 27] step 14/44: loss=-0.0862 
[epoch 27] step 16/44: loss=-0.0874 
[epoch 27] step 18/44: loss=-0.0860 
[epoch 27] step 20/44: loss=-0.0869 
[epoch 27] step 22/44: loss=-0.0870 
[epoch 27] step 24/44: loss=-0.0865 
[epoch 27] step 26/44: loss=-0.0873 
[epoch 27] step 28/44: loss=-0.0870 
[epoch 27] step 30/44: loss=-0.0858 
[epoch 27] step 32/44: loss=-0.0867 
[epoch 27] step 34/44: loss=-0.0857 
[epoch 27] step 36/44: loss=-0.0860 
[epoch 27] step 38/44: loss=-0.0863 
[epoch 27] step 40/44: loss=-0.0862 
[epoch 27] step 42/44: loss=-0.0860 
[epoch 27] step 44/44: loss=-0.0863 
[epoch 27] train_loss(avg per step)=-0.1727 lambda[min,max]=[0.368245,1.000000]
[epoch 27] val_loss=1.3420 qwk=('0.5106', '0.4937', '0.4485') averageQWK=0.4843 macroEMD=0.2113 tailR0=('0.1111', '0.1000', '0.0000') tailR0avg=0.0704
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     1    5   30    4    0
     0    3   85   40    0
     0    0   53   65    4
     0    0    3   18    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6   35    7    0
     0    8   82   22    1
     0    2   51   93    2
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   56    0    0
     0    5  129   17    0
     0    0   55   44    0
     0    1    0    2    0
[epoch 28] step 2/44: loss=-0.1001 
[epoch 28] step 4/44: loss=-0.0967 
[epoch 28] step 6/44: loss=-0.0954 
[epoch 28] step 8/44: loss=-0.0955 
[epoch 28] step 10/44: loss=-0.0957 
[epoch 28] step 12/44: loss=-0.0927 
[epoch 28] step 14/44: loss=-0.0901 
[epoch 28] step 16/44: loss=-0.0875 
[epoch 28] step 18/44: loss=-0.0868 
[epoch 28] step 20/44: loss=-0.0880 
[epoch 28] step 22/44: loss=-0.0881 
[epoch 28] step 24/44: loss=-0.0891 
[epoch 28] step 26/44: loss=-0.0887 
[epoch 28] step 28/44: loss=-0.0878 
[epoch 28] step 30/44: loss=-0.0882 
[epoch 28] step 32/44: loss=-0.0877 
[epoch 28] step 34/44: loss=-0.0876 
[epoch 28] step 36/44: loss=-0.0879 
[epoch 28] step 38/44: loss=-0.0883 
[epoch 28] step 40/44: loss=-0.0886 
[epoch 28] step 42/44: loss=-0.0891 
[epoch 28] step 44/44: loss=-0.0892 
[epoch 28] train_loss(avg per step)=-0.1785 lambda[min,max]=[0.361930,1.000000]
[epoch 28] val_loss=1.3466 qwk=('0.5540', '0.5186', '0.4839') averageQWK=0.5188 macroEMD=0.2038 tailR0=('0.1481', '0.1000', '0.0000') tailR0avg=0.0827
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    9   27    4    0
     0    7   79   42    0
     0    0   46   72    4
     0    0    2   17    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   10   32    6    0
     0    9   84   19    1
     0    1   57   88    2
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   53    1    0
     0    8  121   22    0
     0    0   46   53    0
     0    1    0    2    0
[epoch 29] step 2/44: loss=-0.0998 
[epoch 29] step 4/44: loss=-0.0978 
[epoch 29] step 6/44: loss=-0.0950 
[epoch 29] step 8/44: loss=-0.0943 
[epoch 29] step 10/44: loss=-0.0949 
[epoch 29] step 12/44: loss=-0.0929 
[epoch 29] step 14/44: loss=-0.0920 
[epoch 29] step 16/44: loss=-0.0901 
[epoch 29] step 18/44: loss=-0.0906 
[epoch 29] step 20/44: loss=-0.0903 
[epoch 29] step 22/44: loss=-0.0914 
[epoch 29] step 24/44: loss=-0.0922 
[epoch 29] step 26/44: loss=-0.0903 
[epoch 29] step 28/44: loss=-0.0904 
[epoch 29] step 30/44: loss=-0.0912 
[epoch 29] step 32/44: loss=-0.0913 
[epoch 29] step 34/44: loss=-0.0916 
[epoch 29] step 36/44: loss=-0.0909 
[epoch 29] step 38/44: loss=-0.0907 
[epoch 29] step 40/44: loss=-0.0906 
[epoch 29] step 42/44: loss=-0.0910 
[epoch 29] step 44/44: loss=-0.0915 
[epoch 29] train_loss(avg per step)=-0.1831 lambda[min,max]=[0.367305,1.000000]
[epoch 29] val_loss=1.3320 qwk=('0.5512', '0.5382', '0.4827') averageQWK=0.5240 macroEMD=0.2026 tailR0=('0.2292', '0.0500', '0.5000') tailR0avg=0.2597
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1   10   25    4    0
     0    9   82   36    1
     0    0   54   64    4
     0    0    3   15    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     1   17   21    9    0
     1   12   67   33    0
     0    3   39  104    2
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    0    0    0
     1   18   51    1    0
     0    9  121   21    0
     0    0   51   48    0
     0    1    0    2    0
[epoch 30] step 2/44: loss=-0.1064 
[epoch 30] step 4/44: loss=-0.1028 
[epoch 30] step 6/44: loss=-0.1020 
[epoch 30] step 8/44: loss=-0.1007 
[epoch 30] step 10/44: loss=-0.0982 
[epoch 30] step 12/44: loss=-0.0988 
[epoch 30] step 14/44: loss=-0.0982 
[epoch 30] step 16/44: loss=-0.0987 
[epoch 30] step 18/44: loss=-0.0982 
[epoch 30] step 20/44: loss=-0.0970 
[epoch 30] step 22/44: loss=-0.0969 
[epoch 30] step 24/44: loss=-0.0973 
[epoch 30] step 26/44: loss=-0.0970 
[epoch 30] step 28/44: loss=-0.0971 
[epoch 30] step 30/44: loss=-0.0971 
[epoch 30] step 32/44: loss=-0.0969 
[epoch 30] step 34/44: loss=-0.0970 
[epoch 30] step 36/44: loss=-0.0971 
[epoch 30] step 38/44: loss=-0.0974 
[epoch 30] step 40/44: loss=-0.0971 
[epoch 30] step 42/44: loss=-0.0970 
[epoch 30] step 44/44: loss=-0.0973 
[epoch 30] train_loss(avg per step)=-0.1945 lambda[min,max]=[0.358794,1.000000]
[epoch 30] val_loss=1.3232 qwk=('0.5342', '0.5126', '0.4753') averageQWK=0.5074 macroEMD=0.2083 tailR0=('0.2106', '0.0500', '0.0000') tailR0avg=0.0869
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     2    4   30    4    0
     1    3   90   34    0
     0    0   55   62    5
     0    0    3   16    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   14   24   10    0
     1   11   62   39    0
     0    2   37  107    2
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   45    2    0
     0   13  117   21    0
     0    0   53   46    0
     0    1    0    2    0
[epoch 31] step 2/44: loss=-0.1009 
[epoch 31] step 4/44: loss=-0.1011 
[epoch 31] step 6/44: loss=-0.0983 
[epoch 31] step 8/44: loss=-0.0987 
[epoch 31] step 10/44: loss=-0.1001 
[epoch 31] step 12/44: loss=-0.0981 
[epoch 31] step 14/44: loss=-0.0985 
[epoch 31] step 16/44: loss=-0.0986 
[epoch 31] step 18/44: loss=-0.0986 
[epoch 31] step 20/44: loss=-0.0984 
[epoch 31] step 22/44: loss=-0.0990 
[epoch 31] step 24/44: loss=-0.0988 
[epoch 31] step 26/44: loss=-0.0985 
[epoch 31] step 28/44: loss=-0.0982 
[epoch 31] step 30/44: loss=-0.0984 
[epoch 31] step 32/44: loss=-0.0987 
[epoch 31] step 34/44: loss=-0.0986 
[epoch 31] step 36/44: loss=-0.0986 
[epoch 31] step 38/44: loss=-0.0987 
[epoch 31] step 40/44: loss=-0.0988 
[epoch 31] step 42/44: loss=-0.0991 
[epoch 31] step 44/44: loss=-0.0988 
[epoch 31] train_loss(avg per step)=-0.1977 lambda[min,max]=[0.392182,1.000000]
[epoch 31] val_loss=1.3590 qwk=('0.5275', '0.5390', '0.4615') averageQWK=0.5093 macroEMD=0.2083 tailR0=('0.1736', '0.0500', '0.0000') tailR0avg=0.0745
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1    6   29    4    0
     0    3   90   35    0
     0    0   55   65    2
     0    0    3   18    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   14   28    6    0
     0   11   76   26    0
     0    3   46   98    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   49    0    0
     0   10  128   13    0
     0    0   61   38    0
     0    1    0    2    0
[epoch 32] step 2/44: loss=-0.1036 
[epoch 32] step 4/44: loss=-0.1033 
[epoch 32] step 6/44: loss=-0.1015 
[epoch 32] step 8/44: loss=-0.1019 
[epoch 32] step 10/44: loss=-0.1028 
[epoch 32] step 12/44: loss=-0.1024 
[epoch 32] step 14/44: loss=-0.1030 
[epoch 32] step 16/44: loss=-0.1010 
[epoch 32] step 18/44: loss=-0.1013 
[epoch 32] step 20/44: loss=-0.1011 
[epoch 32] step 22/44: loss=-0.1015 
[epoch 32] step 24/44: loss=-0.1011 
[epoch 32] step 26/44: loss=-0.1007 
[epoch 32] step 28/44: loss=-0.1006 
[epoch 32] step 30/44: loss=-0.1004 
[epoch 32] step 32/44: loss=-0.1004 
[epoch 32] step 34/44: loss=-0.1008 
[epoch 32] step 36/44: loss=-0.1005 
[epoch 32] step 38/44: loss=-0.1007 
[epoch 32] step 40/44: loss=-0.1010 
[epoch 32] step 42/44: loss=-0.1008 
[epoch 32] step 44/44: loss=-0.1006 
[epoch 32] train_loss(avg per step)=-0.2011 lambda[min,max]=[0.384276,1.000000]
[epoch 32] val_loss=1.3560 qwk=('0.5268', '0.5061', '0.4700') averageQWK=0.5010 macroEMD=0.2094 tailR0=('0.2292', '0.0500', '0.0000') tailR0avg=0.0931
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1    3   32    4    0
     0    3   90   35    0
     0    0   56   62    4
     0    0    3   15    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    9   29   10    0
     0    7   73   33    0
     0    0   43  104    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   19   52    0    0
     0    9  126   16    0
     0    0   55   44    0
     0    1    0    2    0
[epoch 33] step 2/44: loss=-0.1005 
[epoch 33] step 4/44: loss=-0.0982 
[epoch 33] step 6/44: loss=-0.1003 
[epoch 33] step 8/44: loss=-0.1001 
[epoch 33] step 10/44: loss=-0.1003 
[epoch 33] step 12/44: loss=-0.1008 
[epoch 33] step 14/44: loss=-0.1010 
[epoch 33] step 16/44: loss=-0.1014 
[epoch 33] step 18/44: loss=-0.1014 
[epoch 33] step 20/44: loss=-0.1015 
[epoch 33] step 22/44: loss=-0.1008 
[epoch 33] step 24/44: loss=-0.1006 
[epoch 33] step 26/44: loss=-0.1007 
[epoch 33] step 28/44: loss=-0.1008 
[epoch 33] step 30/44: loss=-0.1004 
[epoch 33] step 32/44: loss=-0.1005 
[epoch 33] step 34/44: loss=-0.1007 
[epoch 33] step 36/44: loss=-0.1000 
[epoch 33] step 38/44: loss=-0.1004 
[epoch 33] step 40/44: loss=-0.1002 
[epoch 33] step 42/44: loss=-0.1005 
[epoch 33] step 44/44: loss=-0.1007 
[epoch 33] train_loss(avg per step)=-0.2014 lambda[min,max]=[0.365380,1.000000]
[epoch 33] val_loss=1.3540 qwk=('0.5326', '0.5369', '0.4786') averageQWK=0.5160 macroEMD=0.2067 tailR0=('0.1921', '0.0500', '0.0000') tailR0avg=0.0807
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1    4   31    4    0
     0    3   85   40    0
     0    0   48   70    4
     0    0    3   17    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   11   28    9    0
     0   10   72   31    0
     0    0   40  107    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   49    2    0
     0    9  119   23    0
     0    0   48   51    0
     0    1    0    2    0
[epoch 34] step 2/44: loss=-0.1044 
[epoch 34] step 4/44: loss=-0.1042 
[epoch 34] step 6/44: loss=-0.1046 
[epoch 34] step 8/44: loss=-0.1038 
[epoch 34] step 10/44: loss=-0.1023 
[epoch 34] step 12/44: loss=-0.1030 
[epoch 34] step 14/44: loss=-0.1035 
[epoch 34] step 16/44: loss=-0.1037 
[epoch 34] step 18/44: loss=-0.1036 
[epoch 34] step 20/44: loss=-0.1038 
[epoch 34] step 22/44: loss=-0.1033 
[epoch 34] step 24/44: loss=-0.1029 
[epoch 34] step 26/44: loss=-0.1027 
[epoch 34] step 28/44: loss=-0.1029 
[epoch 34] step 30/44: loss=-0.1026 
[epoch 34] step 32/44: loss=-0.1025 
[epoch 34] step 34/44: loss=-0.1027 
[epoch 34] step 36/44: loss=-0.1029 
[epoch 34] step 38/44: loss=-0.1030 
[epoch 34] step 40/44: loss=-0.1025 
[epoch 34] step 42/44: loss=-0.1025 
[epoch 34] step 44/44: loss=-0.1026 
[epoch 34] train_loss(avg per step)=-0.2053 lambda[min,max]=[0.418473,1.000000]
[epoch 34] val_loss=1.3692 qwk=('0.5392', '0.5275', '0.4612') averageQWK=0.5093 macroEMD=0.2067 tailR0=('0.2292', '0.0500', '0.0000') tailR0avg=0.0931
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1    5   31    3    0
     0    3   92   33    0
     0    0   59   59    4
     0    0    3   15    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   13   27    8    0
     0   11   76   26    0
     0    1   49   97    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   18   51    1    0
     0    9  120   22    0
     0    0   53   46    0
     0    1    0    2    0
[epoch 35] step 2/44: loss=-0.1000 
[epoch 35] step 4/44: loss=-0.1042 
[epoch 35] step 6/44: loss=-0.1029 
[epoch 35] step 8/44: loss=-0.1043 
[epoch 35] step 10/44: loss=-0.1050 
[epoch 35] step 12/44: loss=-0.1046 
[epoch 35] step 14/44: loss=-0.1047 
[epoch 35] step 16/44: loss=-0.1046 
[epoch 35] step 18/44: loss=-0.1043 
[epoch 35] step 20/44: loss=-0.1043 
[epoch 35] step 22/44: loss=-0.1045 
[epoch 35] step 24/44: loss=-0.1046 
[epoch 35] step 26/44: loss=-0.1045 
[epoch 35] step 28/44: loss=-0.1043 
[epoch 35] step 30/44: loss=-0.1044 
[epoch 35] step 32/44: loss=-0.1039 
[epoch 35] step 34/44: loss=-0.1038 
[epoch 35] step 36/44: loss=-0.1039 
[epoch 35] step 38/44: loss=-0.1040 
[epoch 35] step 40/44: loss=-0.1042 
[epoch 35] step 42/44: loss=-0.1035 
[epoch 35] step 44/44: loss=-0.1037 
[epoch 35] train_loss(avg per step)=-0.2074 lambda[min,max]=[0.393448,1.000000]
[epoch 35] val_loss=1.3651 qwk=('0.5332', '0.5392', '0.4623') averageQWK=0.5115 macroEMD=0.2066 tailR0=('0.2292', '0.0500', '0.0000') tailR0avg=0.0931
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1    5   30    4    0
     0    3   90   35    0
     0    0   57   61    4
     0    0    3   15    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   13   27    8    0
     0   10   75   28    0
     0    0   47  100    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   18   50    2    0
     0    9  120   22    0
     0    0   51   48    0
     0    1    0    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-0/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-0/fold3/metrics.json
Done.
