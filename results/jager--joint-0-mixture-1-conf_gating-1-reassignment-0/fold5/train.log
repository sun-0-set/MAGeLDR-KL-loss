[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.4998 
[epoch 1] step 4/44: loss=0.5086 
[epoch 1] step 6/44: loss=0.5141 
[epoch 1] step 8/44: loss=0.5157 
[epoch 1] step 10/44: loss=0.5187 
[epoch 1] step 12/44: loss=0.5183 
[epoch 1] step 14/44: loss=0.5192 
[epoch 1] step 16/44: loss=0.5210 
[epoch 1] step 18/44: loss=0.5236 
[epoch 1] step 20/44: loss=0.5295 
[epoch 1] step 22/44: loss=0.5337 
[epoch 1] step 24/44: loss=0.5379 
[epoch 1] step 26/44: loss=0.5435 
[epoch 1] step 28/44: loss=0.5476 
[epoch 1] step 30/44: loss=0.5514 
[epoch 1] step 32/44: loss=0.5552 
[epoch 1] step 34/44: loss=0.5592 
[epoch 1] step 36/44: loss=0.5621 
[epoch 1] step 38/44: loss=0.5658 
[epoch 1] step 40/44: loss=0.5674 
[epoch 1] step 42/44: loss=0.5696 
[epoch 1] step 44/44: loss=0.5725 
[epoch 1] train_loss(avg per step)=1.1451 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=0.7898 qwk=('0.0512', '0.2076', '0.0929') averageQWK=0.1172 macroEMD=0.3577 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0   10    0
     0    5    0   47    0
     0    6    0  108    0
     0   11    0  128    0
     0    0    0    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    1    0
     3    0   40   12    0
     3    0   50   61    0
    11    0   31  101    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    7   58    0    0
     0    5  138    0    0
     0    0  110    0    0
     0    0    3    0    0
[epoch 2] step 2/44: loss=0.5763 
[epoch 2] step 4/44: loss=0.5709 
[epoch 2] step 6/44: loss=0.5608 
[epoch 2] step 8/44: loss=0.5620 
[epoch 2] step 10/44: loss=0.5642 
[epoch 2] step 12/44: loss=0.5647 
[epoch 2] step 14/44: loss=0.5682 
[epoch 2] step 16/44: loss=0.5644 
[epoch 2] step 18/44: loss=0.5708 
[epoch 2] step 20/44: loss=0.5701 
[epoch 2] step 22/44: loss=0.5736 
[epoch 2] step 24/44: loss=0.5743 
[epoch 2] step 26/44: loss=0.5761 
[epoch 2] step 28/44: loss=0.5779 
[epoch 2] step 30/44: loss=0.5804 
[epoch 2] step 32/44: loss=0.5801 
[epoch 2] step 34/44: loss=0.5825 
[epoch 2] step 36/44: loss=0.5831 
[epoch 2] step 38/44: loss=0.5824 
[epoch 2] step 40/44: loss=0.5824 
[epoch 2] step 42/44: loss=0.5838 
[epoch 2] step 44/44: loss=0.5850 
[epoch 2] train_loss(avg per step)=1.1699 lambda[min,max]=[0.506338,1.000000]
[epoch 2] val_loss=1.1474 qwk=('0.3575', '0.4283', '0.1918') averageQWK=0.3258 macroEMD=0.3219 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   11    0    0
     0    1   50    1    0
     0    0   96   18    0
     0    0   68   71    0
     0    0    6    3    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    0    0
     0    0   46    9    0
     0    0   46   68    0
     0    0   16  127    0
     0    0    0    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   65    0    0
     0    0  138    5    0
     0    0   86   24    0
     0    0    2    1    0
[epoch 3] step 2/44: loss=0.5815 
[epoch 3] step 4/44: loss=0.5919 
[epoch 3] step 6/44: loss=0.6053 
[epoch 3] step 8/44: loss=0.5995 
[epoch 3] step 10/44: loss=0.5928 
[epoch 3] step 12/44: loss=0.5883 
[epoch 3] step 14/44: loss=0.5849 
[epoch 3] step 16/44: loss=0.5757 
[epoch 3] step 18/44: loss=0.5752 
[epoch 3] step 20/44: loss=0.5725 
[epoch 3] step 22/44: loss=0.5682 
[epoch 3] step 24/44: loss=0.5641 
[epoch 3] step 26/44: loss=0.5621 
[epoch 3] step 28/44: loss=0.5635 
[epoch 3] step 30/44: loss=0.5640 
[epoch 3] step 32/44: loss=0.5647 
[epoch 3] step 34/44: loss=0.5629 
[epoch 3] step 36/44: loss=0.5587 
[epoch 3] step 38/44: loss=0.5586 
[epoch 3] step 40/44: loss=0.5550 
[epoch 3] step 42/44: loss=0.5544 
[epoch 3] step 44/44: loss=0.5530 
[epoch 3] train_loss(avg per step)=1.1059 lambda[min,max]=[0.503543,1.000000]
[epoch 3] val_loss=0.9929 qwk=('0.5326', '0.4909', '0.4115') averageQWK=0.4784 macroEMD=0.2812 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    6    0    0
     0    6   44    2    0
     0    2   89   23    0
     0    0   45   94    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    0    0
     0    0   55    0    0
     0    0   88   26    0
     0    0   42  101    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   13   52    0    0
     0    4  128   11    0
     0    0   63   47    0
     0    0    2    1    0
[epoch 4] step 2/44: loss=0.5193 
[epoch 4] step 4/44: loss=0.5095 
[epoch 4] step 6/44: loss=0.5127 
[epoch 4] step 8/44: loss=0.5098 
[epoch 4] step 10/44: loss=0.5100 
[epoch 4] step 12/44: loss=0.5064 
[epoch 4] step 14/44: loss=0.5017 
[epoch 4] step 16/44: loss=0.5035 
[epoch 4] step 18/44: loss=0.5057 
[epoch 4] step 20/44: loss=0.5067 
[epoch 4] step 22/44: loss=0.5068 
[epoch 4] step 24/44: loss=0.5084 
[epoch 4] step 26/44: loss=0.5063 
[epoch 4] step 28/44: loss=0.5052 
[epoch 4] step 30/44: loss=0.5011 
[epoch 4] step 32/44: loss=0.5017 
[epoch 4] step 34/44: loss=0.5017 
[epoch 4] step 36/44: loss=0.4981 
[epoch 4] step 38/44: loss=0.4951 
[epoch 4] step 40/44: loss=0.4902 
[epoch 4] step 42/44: loss=0.4885 
[epoch 4] step 44/44: loss=0.4880 
[epoch 4] train_loss(avg per step)=0.9759 lambda[min,max]=[0.500786,1.000000]
[epoch 4] val_loss=0.9604 qwk=('0.5331', '0.3866', '0.6206') averageQWK=0.5134 macroEMD=0.2594 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    0    0
     0    9   43    0    0
     0    3   96   15    0
     0    0   46   93    0
     0    1    3    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    0    0
     0    0   55    0    0
     0    0   97   17    0
     0    0   68   75    0
     0    0    3    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0   44   20    1    0
     0   36   83   24    0
     0    4   35   71    0
     0    0    0    3    0
[epoch 5] step 2/44: loss=0.5280 
[epoch 5] step 4/44: loss=0.5029 
[epoch 5] step 6/44: loss=0.4872 
[epoch 5] step 8/44: loss=0.4777 
[epoch 5] step 10/44: loss=0.4761 
[epoch 5] step 12/44: loss=0.4715 
[epoch 5] step 14/44: loss=0.4670 
[epoch 5] step 16/44: loss=0.4651 
[epoch 5] step 18/44: loss=0.4609 
[epoch 5] step 20/44: loss=0.4578 
[epoch 5] step 22/44: loss=0.4578 
[epoch 5] step 24/44: loss=0.4568 
[epoch 5] step 26/44: loss=0.4527 
[epoch 5] step 28/44: loss=0.4540 
[epoch 5] step 30/44: loss=0.4568 
[epoch 5] step 32/44: loss=0.4594 
[epoch 5] step 34/44: loss=0.4573 
[epoch 5] step 36/44: loss=0.4552 
[epoch 5] step 38/44: loss=0.4602 
[epoch 5] step 40/44: loss=0.4638 
[epoch 5] step 42/44: loss=0.4636 
[epoch 5] step 44/44: loss=0.4656 
[epoch 5] train_loss(avg per step)=0.9311 lambda[min,max]=[0.500092,1.000000]
[epoch 5] val_loss=1.1117 qwk=('0.3670', '0.3876', '0.4661') averageQWK=0.4069 macroEMD=0.2618 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   12    0    0
     0    0   35   17    0
     0    1   27   86    0
     0    0    7  132    0
     0    0    1    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     0    0   42   13    0
     0    0   34   80    0
     0    0   15  128    0
     0    0    0    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    4   56    5    0
     0    1   60   82    0
     0    0    8  102    0
     0    0    0    3    0
[epoch 6] step 2/44: loss=0.4693 
[epoch 6] step 4/44: loss=0.4675 
[epoch 6] step 6/44: loss=0.4559 
[epoch 6] step 8/44: loss=0.4800 
[epoch 6] step 10/44: loss=0.5024 
[epoch 6] step 12/44: loss=0.5050 
[epoch 6] step 14/44: loss=0.4979 
[epoch 6] step 16/44: loss=0.4897 
[epoch 6] step 18/44: loss=0.4849 
[epoch 6] step 20/44: loss=0.4760 
[epoch 6] step 22/44: loss=0.4695 
[epoch 6] step 24/44: loss=0.4664 
[epoch 6] step 26/44: loss=0.4662 
[epoch 6] step 28/44: loss=0.4608 
[epoch 6] step 30/44: loss=0.4588 
[epoch 6] step 32/44: loss=0.4561 
[epoch 6] step 34/44: loss=0.4558 
[epoch 6] step 36/44: loss=0.4520 
[epoch 6] step 38/44: loss=0.4486 
[epoch 6] step 40/44: loss=0.4482 
[epoch 6] step 42/44: loss=0.4446 
[epoch 6] step 44/44: loss=0.4409 
[epoch 6] train_loss(avg per step)=0.8818 lambda[min,max]=[0.500004,1.000000]
[epoch 6] val_loss=0.9268 qwk=('0.4746', '0.4486', '0.4767') averageQWK=0.4666 macroEMD=0.2508 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    9    0    0
     0    4   46    2    0
     0    1   95   18    0
     0    0   53   86    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    0    0
     0    0   55    0    0
     0    0   85   29    0
     0    0   51   92    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   20   45    0    0
     0   11  122   10    0
     0    0   57   53    0
     0    0    2    1    0
[epoch 7] step 2/44: loss=0.4491 
[epoch 7] step 4/44: loss=0.3915 
[epoch 7] step 6/44: loss=0.3937 
[epoch 7] step 8/44: loss=0.4001 
[epoch 7] step 10/44: loss=0.4063 
[epoch 7] step 12/44: loss=0.4073 
[epoch 7] step 14/44: loss=0.4031 
[epoch 7] step 16/44: loss=0.3976 
[epoch 7] step 18/44: loss=0.3968 
[epoch 7] step 20/44: loss=0.3974 
[epoch 7] step 22/44: loss=0.3990 
[epoch 7] step 24/44: loss=0.3965 
[epoch 7] step 26/44: loss=0.3946 
[epoch 7] step 28/44: loss=0.3931 
[epoch 7] step 30/44: loss=0.3907 
[epoch 7] step 32/44: loss=0.3956 
[epoch 7] step 34/44: loss=0.3951 
[epoch 7] step 36/44: loss=0.3923 
[epoch 7] step 38/44: loss=0.3912 
[epoch 7] step 40/44: loss=0.3905 
[epoch 7] step 42/44: loss=0.3903 
[epoch 7] step 44/44: loss=0.3938 
[epoch 7] train_loss(avg per step)=0.7875 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=0.9700 qwk=('0.5307', '0.5296', '0.5539') averageQWK=0.5381 macroEMD=0.2377 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    4    0    0
     0   13   37    2    0
     0    8   92   14    0
     0    0   59   80    0
     0    1    3    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    0    0
     0   19   35    1    0
     0   17   70   27    0
     0    3   59   81    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   32   33    0    0
     0   26  107   10    0
     0    3   56   51    0
     0    0    1    2    0
[epoch 8] step 2/44: loss=0.3949 
[epoch 8] step 4/44: loss=0.3532 
[epoch 8] step 6/44: loss=0.3551 
[epoch 8] step 8/44: loss=0.3598 
[epoch 8] step 10/44: loss=0.3683 
[epoch 8] step 12/44: loss=0.3659 
[epoch 8] step 14/44: loss=0.3741 
[epoch 8] step 16/44: loss=0.3881 
[epoch 8] step 18/44: loss=0.3922 
[epoch 8] step 20/44: loss=0.3864 
[epoch 8] step 22/44: loss=0.3840 
[epoch 8] step 24/44: loss=0.3849 
[epoch 8] step 26/44: loss=0.3840 
[epoch 8] step 28/44: loss=0.3793 
[epoch 8] step 30/44: loss=0.3802 
[epoch 8] step 32/44: loss=0.3783 
[epoch 8] step 34/44: loss=0.3803 
[epoch 8] step 36/44: loss=0.3795 
[epoch 8] step 38/44: loss=0.3776 
[epoch 8] step 40/44: loss=0.3752 
[epoch 8] step 42/44: loss=0.3728 
[epoch 8] step 44/44: loss=0.3707 
[epoch 8] train_loss(avg per step)=0.7414 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.0072 qwk=('0.4365', '0.4189', '0.4893') averageQWK=0.4483 macroEMD=0.2532 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    0    0
     0    8   43    1    0
     0    5   96   13    0
     0    0   68   71    0
     0    1    4    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     0    8   47    0    0
     0    1   92   21    0
     0    0   73   70    0
     0    0    3    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0   30   35    0    0
     0   23  110   10    0
     0    3   60   47    0
     0    0    2    1    0
[epoch 9] step 2/44: loss=0.3897 
[epoch 9] step 4/44: loss=0.3549 
[epoch 9] step 6/44: loss=0.3412 
[epoch 9] step 8/44: loss=0.3355 
[epoch 9] step 10/44: loss=0.3438 
[epoch 9] step 12/44: loss=0.3411 
[epoch 9] step 14/44: loss=0.3363 
[epoch 9] step 16/44: loss=0.3327 
[epoch 9] step 18/44: loss=0.3331 
[epoch 9] step 20/44: loss=0.3303 
[epoch 9] step 22/44: loss=0.3279 
[epoch 9] step 24/44: loss=0.3232 
[epoch 9] step 26/44: loss=0.3194 
[epoch 9] step 28/44: loss=0.3168 
[epoch 9] step 30/44: loss=0.3197 
[epoch 9] step 32/44: loss=0.3185 
[epoch 9] step 34/44: loss=0.3191 
[epoch 9] step 36/44: loss=0.3184 
[epoch 9] step 38/44: loss=0.3189 
[epoch 9] step 40/44: loss=0.3203 
[epoch 9] step 42/44: loss=0.3234 
[epoch 9] step 44/44: loss=0.3238 
[epoch 9] train_loss(avg per step)=0.6476 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=0.9514 qwk=('0.4921', '0.5345', '0.5021') averageQWK=0.5096 macroEMD=0.2394 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    7    0    0
     0    6   44    2    0
     0    4   87   23    0
     0    0   50   89    0
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     0   11   44    0    0
     0    3   76   35    0
     0    2   40  101    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    9   55    1    0
     0    6  107   30    0
     0    0   34   76    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=0.3105 
[epoch 10] step 4/44: loss=0.3097 
[epoch 10] step 6/44: loss=0.2976 
[epoch 10] step 8/44: loss=0.2962 
[epoch 10] step 10/44: loss=0.2902 
[epoch 10] step 12/44: loss=0.2891 
[epoch 10] step 14/44: loss=0.2863 
[epoch 10] step 16/44: loss=0.2854 
[epoch 10] step 18/44: loss=0.2837 
[epoch 10] step 20/44: loss=0.2860 
[epoch 10] step 22/44: loss=0.2832 
[epoch 10] step 24/44: loss=0.2816 
[epoch 10] step 26/44: loss=0.2808 
[epoch 10] step 28/44: loss=0.2802 
[epoch 10] step 30/44: loss=0.2814 
[epoch 10] step 32/44: loss=0.2761 
[epoch 10] step 34/44: loss=0.2743 
[epoch 10] step 36/44: loss=0.2748 
[epoch 10] step 38/44: loss=0.2731 
[epoch 10] step 40/44: loss=0.2719 
[epoch 10] step 42/44: loss=0.2749 
[epoch 10] step 44/44: loss=0.2764 
[epoch 10] train_loss(avg per step)=0.5529 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=0.9668 qwk=('0.5555', '0.5614', '0.5749') averageQWK=0.5639 macroEMD=0.2289 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     0   13   37    2    0
     0    9   88   17    0
     0    1   46   92    0
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   15   40    0    0
     0   10   66   38    0
     0    3   34  106    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0   29   35    1    0
     0   19  100   24    0
     0    2   38   70    0
     0    0    1    2    0
[epoch 11] step 2/44: loss=0.2420 
[epoch 11] step 4/44: loss=0.2241 
[epoch 11] step 6/44: loss=0.2194 
[epoch 11] step 8/44: loss=0.2209 
[epoch 11] step 10/44: loss=0.2168 
[epoch 11] step 12/44: loss=0.2203 
[epoch 11] step 14/44: loss=0.2240 
[epoch 11] step 16/44: loss=0.2308 
[epoch 11] step 18/44: loss=0.2351 
[epoch 11] step 20/44: loss=0.2339 
[epoch 11] step 22/44: loss=0.2317 
[epoch 11] step 24/44: loss=0.2308 
[epoch 11] step 26/44: loss=0.2284 
[epoch 11] step 28/44: loss=0.2324 
[epoch 11] step 30/44: loss=0.2304 
[epoch 11] step 32/44: loss=0.2328 
[epoch 11] step 34/44: loss=0.2330 
[epoch 11] step 36/44: loss=0.2318 
[epoch 11] step 38/44: loss=0.2334 
[epoch 11] step 40/44: loss=0.2324 
[epoch 11] step 42/44: loss=0.2319 
[epoch 11] step 44/44: loss=0.2323 
[epoch 11] train_loss(avg per step)=0.4647 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=1.1186 qwk=('0.4489', '0.4359', '0.4881') averageQWK=0.4576 macroEMD=0.2510 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   11    0    0
     0    2   41    9    0
     0    0   58   56    0
     0    0   18  121    0
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    0    0
     0    6   39   10    0
     0    2   51   61    0
     0    0   22  121    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    6   57    2    0
     0    4   81   58    0
     0    0   20   90    0
     0    0    0    3    0
[epoch 12] step 2/44: loss=0.2251 
[epoch 12] step 4/44: loss=0.2291 
[epoch 12] step 6/44: loss=0.2142 
[epoch 12] step 8/44: loss=0.2114 
[epoch 12] step 10/44: loss=0.2160 
[epoch 12] step 12/44: loss=0.2149 
[epoch 12] step 14/44: loss=0.2097 
[epoch 12] step 16/44: loss=0.2097 
[epoch 12] step 18/44: loss=0.2061 
[epoch 12] step 20/44: loss=0.2078 
[epoch 12] step 22/44: loss=0.2117 
[epoch 12] step 24/44: loss=0.2072 
[epoch 12] step 26/44: loss=0.2082 
[epoch 12] step 28/44: loss=0.2069 
[epoch 12] step 30/44: loss=0.2066 
[epoch 12] step 32/44: loss=0.2065 
[epoch 12] step 34/44: loss=0.2067 
[epoch 12] step 36/44: loss=0.2063 
[epoch 12] step 38/44: loss=0.2046 
[epoch 12] step 40/44: loss=0.2052 
[epoch 12] step 42/44: loss=0.2026 
[epoch 12] step 44/44: loss=0.2070 
[epoch 12] train_loss(avg per step)=0.4139 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=1.0039 qwk=('0.5205', '0.5518', '0.5286') averageQWK=0.5336 macroEMD=0.2328 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    7    0    0
     0    7   42    2    1
     0    2   92   20    0
     0    0   45   90    4
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   12   41    2    0
     0    4   62   48    0
     0    3   23  117    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   14   50    1    0
     0    8  109   26    0
     0    0   35   75    0
     0    0    0    3    0
[epoch 13] step 2/44: loss=0.1646 
[epoch 13] step 4/44: loss=0.1746 
[epoch 13] step 6/44: loss=0.1676 
[epoch 13] step 8/44: loss=0.1663 
[epoch 13] step 10/44: loss=0.1611 
[epoch 13] step 12/44: loss=0.1544 
[epoch 13] step 14/44: loss=0.1518 
[epoch 13] step 16/44: loss=0.1493 
[epoch 13] step 18/44: loss=0.1517 
[epoch 13] step 20/44: loss=0.1498 
[epoch 13] step 22/44: loss=0.1517 
[epoch 13] step 24/44: loss=0.1544 
[epoch 13] step 26/44: loss=0.1566 
[epoch 13] step 28/44: loss=0.1587 
[epoch 13] step 30/44: loss=0.1602 
[epoch 13] step 32/44: loss=0.1611 
[epoch 13] step 34/44: loss=0.1613 
[epoch 13] step 36/44: loss=0.1607 
[epoch 13] step 38/44: loss=0.1605 
[epoch 13] step 40/44: loss=0.1607 
[epoch 13] step 42/44: loss=0.1609 
[epoch 13] step 44/44: loss=0.1623 
[epoch 13] train_loss(avg per step)=0.3247 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=1.0647 qwk=('0.4275', '0.5258', '0.5457') averageQWK=0.4997 macroEMD=0.2422 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    9    0    0
     0    4   45    2    1
     0    2   96   16    0
     0    0   60   77    2
     0    0    4    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     0   10   43    2    0
     0    3   63   48    0
     0    2   25  116    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0   29   35    1    0
     0   24   87   32    0
     0    3   32   75    0
     0    0    1    2    0
[epoch 14] step 2/44: loss=0.1830 
[epoch 14] step 4/44: loss=0.1560 
[epoch 14] step 6/44: loss=0.1556 
[epoch 14] step 8/44: loss=0.1450 
[epoch 14] step 10/44: loss=0.1340 
[epoch 14] step 12/44: loss=0.1329 
[epoch 14] step 14/44: loss=0.1297 
[epoch 14] step 16/44: loss=0.1246 
[epoch 14] step 18/44: loss=0.1191 
[epoch 14] step 20/44: loss=0.1217 
[epoch 14] step 22/44: loss=0.1255 
[epoch 14] step 24/44: loss=0.1262 
[epoch 14] step 26/44: loss=0.1283 
[epoch 14] step 28/44: loss=0.1289 
[epoch 14] step 30/44: loss=0.1277 
[epoch 14] step 32/44: loss=0.1274 
[epoch 14] step 34/44: loss=0.1261 
[epoch 14] step 36/44: loss=0.1257 
[epoch 14] step 38/44: loss=0.1259 
[epoch 14] step 40/44: loss=0.1261 
[epoch 14] step 42/44: loss=0.1262 
[epoch 14] step 44/44: loss=0.1257 
[epoch 14] train_loss(avg per step)=0.2513 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=1.0268 qwk=('0.5442', '0.5850', '0.5257') averageQWK=0.5517 macroEMD=0.2308 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    6    0    0
     0    7   43    2    0
     0    3   89   22    0
     0    1   43   95    0
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   12   42    1    0
     0    3   67   44    0
     0    1   24  118    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   16   48    1    0
     0   10  104   29    0
     0    0   36   74    0
     0    0    0    3    0
[epoch 15] step 2/44: loss=0.1108 
[epoch 15] step 4/44: loss=0.1027 
[epoch 15] step 6/44: loss=0.1121 
[epoch 15] step 8/44: loss=0.1060 
[epoch 15] step 10/44: loss=0.1015 
[epoch 15] step 12/44: loss=0.1013 
[epoch 15] step 14/44: loss=0.0958 
[epoch 15] step 16/44: loss=0.0902 
[epoch 15] step 18/44: loss=0.0888 
[epoch 15] step 20/44: loss=0.0906 
[epoch 15] step 22/44: loss=0.0888 
[epoch 15] step 24/44: loss=0.0885 
[epoch 15] step 26/44: loss=0.0875 
[epoch 15] step 28/44: loss=0.0893 
[epoch 15] step 30/44: loss=0.0900 
[epoch 15] step 32/44: loss=0.0895 
[epoch 15] step 34/44: loss=0.0901 
[epoch 15] step 36/44: loss=0.0908 
[epoch 15] step 38/44: loss=0.0901 
[epoch 15] step 40/44: loss=0.0899 
[epoch 15] step 42/44: loss=0.0890 
[epoch 15] step 44/44: loss=0.0899 
[epoch 15] train_loss(avg per step)=0.1797 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=1.0935 qwk=('0.4491', '0.5406', '0.4939') averageQWK=0.4946 macroEMD=0.2397 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    8    0    0
     0    8   42    2    0
     0    2  101   11    0
     0    0   64   73    2
     0    1    6    2    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     1   11   43    0    0
     0    3   76   35    0
     0    1   40  102    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0   23   42    0    0
     0   16  117   10    0
     0    1   58   51    0
     0    0    2    1    0
[epoch 16] step 2/44: loss=0.0628 
[epoch 16] step 4/44: loss=0.0448 
[epoch 16] step 6/44: loss=0.0436 
[epoch 16] step 8/44: loss=0.0415 
[epoch 16] step 10/44: loss=0.0482 
[epoch 16] step 12/44: loss=0.0553 
[epoch 16] step 14/44: loss=0.0593 
[epoch 16] step 16/44: loss=0.0569 
[epoch 16] step 18/44: loss=0.0584 
[epoch 16] step 20/44: loss=0.0617 
[epoch 16] step 22/44: loss=0.0603 
[epoch 16] step 24/44: loss=0.0601 
[epoch 16] step 26/44: loss=0.0636 
[epoch 16] step 28/44: loss=0.0628 
[epoch 16] step 30/44: loss=0.0627 
[epoch 16] step 32/44: loss=0.0625 
[epoch 16] step 34/44: loss=0.0609 
[epoch 16] step 36/44: loss=0.0615 
[epoch 16] step 38/44: loss=0.0605 
[epoch 16] step 40/44: loss=0.0603 
[epoch 16] step 42/44: loss=0.0611 
[epoch 16] step 44/44: loss=0.0615 
[epoch 16] train_loss(avg per step)=0.1230 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=1.1317 qwk=('0.4668', '0.5236', '0.4898') averageQWK=0.4934 macroEMD=0.2396 tailR0=('0.0385', '0.0000', '0.0000') tailR0avg=0.0128
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    7    0    0
     0    6   45    1    0
     0    0   99   15    0
     0    0   65   74    0
     0    0    5    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     1    9   45    0    0
     0    3   73   38    0
     0    0   43  100    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   12   53    0    0
     0    7  114   22    0
     0    0   43   67    0
     0    0    1    2    0
[epoch 17] step 2/44: loss=0.0433 
[epoch 17] step 4/44: loss=0.0430 
[epoch 17] step 6/44: loss=0.0508 
[epoch 17] step 8/44: loss=0.0405 
[epoch 17] step 10/44: loss=0.0394 
[epoch 17] step 12/44: loss=0.0378 
[epoch 17] step 14/44: loss=0.0351 
[epoch 17] step 16/44: loss=0.0330 
[epoch 17] step 18/44: loss=0.0346 
[epoch 17] step 20/44: loss=0.0369 
[epoch 17] step 22/44: loss=0.0371 
[epoch 17] step 24/44: loss=0.0346 
[epoch 17] step 26/44: loss=0.0338 
[epoch 17] step 28/44: loss=0.0353 
[epoch 17] step 30/44: loss=0.0354 
[epoch 17] step 32/44: loss=0.0345 
[epoch 17] step 34/44: loss=0.0345 
[epoch 17] step 36/44: loss=0.0365 
[epoch 17] step 38/44: loss=0.0369 
[epoch 17] step 40/44: loss=0.0357 
[epoch 17] step 42/44: loss=0.0376 
[epoch 17] step 44/44: loss=0.0385 
[epoch 17] train_loss(avg per step)=0.0770 lambda[min,max]=[0.495936,1.000000]
[epoch 17] val_loss=1.1420 qwk=('0.4975', '0.5175', '0.5229') averageQWK=0.5127 macroEMD=0.2338 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    9    0    0
     1    5   41    4    1
     0    1   84   29    0
     0    0   41   98    0
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     2    7   40    6    0
     0    2   60   52    0
     0    0   24  119    0
     0    0    0    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0   21   44    0    0
     0   13  114   16    0
     0    1   47   62    0
     0    0    1    2    0
[epoch 18] step 2/44: loss=0.0745 
[epoch 18] step 4/44: loss=0.0385 
[epoch 18] step 6/44: loss=0.0265 
[epoch 18] step 8/44: loss=0.0317 
[epoch 18] step 10/44: loss=0.0332 
[epoch 18] step 12/44: loss=0.0251 
[epoch 18] step 14/44: loss=0.0309 
[epoch 18] step 16/44: loss=0.0314 
[epoch 18] step 18/44: loss=0.0300 
[epoch 18] step 20/44: loss=0.0287 
[epoch 18] step 22/44: loss=0.0265 
[epoch 18] step 24/44: loss=0.0245 
[epoch 18] step 26/44: loss=0.0275 
[epoch 18] step 28/44: loss=0.0287 
[epoch 18] step 30/44: loss=0.0273 
[epoch 18] step 32/44: loss=0.0251 
[epoch 18] step 34/44: loss=0.0246 
[epoch 18] step 36/44: loss=0.0224 
[epoch 18] step 38/44: loss=0.0209 
[epoch 18] step 40/44: loss=0.0203 
[epoch 18] step 42/44: loss=0.0208 
[epoch 18] step 44/44: loss=0.0203 
[epoch 18] train_loss(avg per step)=0.0406 lambda[min,max]=[0.449573,1.000000]
[epoch 18] val_loss=1.1739 qwk=('0.4756', '0.5258', '0.5107') averageQWK=0.5040 macroEMD=0.2347 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    9    0    0
     0    6   41    4    1
     0    1   83   30    0
     0    0   44   94    1
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     2    7   43    3    0
     0    2   65   47    0
     0    0   29  114    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   12   52    1    0
     0   12   97   34    0
     0    0   32   78    0
     0    0    0    3    0
[epoch 19] step 2/44: loss=-0.0140 
[epoch 19] step 4/44: loss=-0.0247 
[epoch 19] step 6/44: loss=-0.0200 
[epoch 19] step 8/44: loss=-0.0251 
[epoch 19] step 10/44: loss=-0.0174 
[epoch 19] step 12/44: loss=-0.0082 
[epoch 19] step 14/44: loss=-0.0114 
[epoch 19] step 16/44: loss=-0.0133 
[epoch 19] step 18/44: loss=-0.0128 
[epoch 19] step 20/44: loss=-0.0117 
[epoch 19] step 22/44: loss=-0.0130 
[epoch 19] step 24/44: loss=-0.0122 
[epoch 19] step 26/44: loss=-0.0124 
[epoch 19] step 28/44: loss=-0.0121 
[epoch 19] step 30/44: loss=-0.0088 
[epoch 19] step 32/44: loss=-0.0075 
[epoch 19] step 34/44: loss=-0.0069 
[epoch 19] step 36/44: loss=-0.0066 
[epoch 19] step 38/44: loss=-0.0080 
[epoch 19] step 40/44: loss=-0.0083 
[epoch 19] step 42/44: loss=-0.0085 
[epoch 19] step 44/44: loss=-0.0081 
[epoch 19] train_loss(avg per step)=-0.0163 lambda[min,max]=[0.449291,1.000000]
[epoch 19] val_loss=1.1898 qwk=('0.5136', '0.5305', '0.5252') averageQWK=0.5231 macroEMD=0.2345 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    7    0    0
     1   11   39    1    0
     0    3   92   19    0
     0    0   62   75    2
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     3    6   45    1    0
     0    2   71   41    0
     0    0   34  109    0
     0    0    2    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0   21   44    0    0
     0   13  113   17    0
     0    1   46   63    0
     0    0    1    2    0
[epoch 20] step 2/44: loss=-0.0018 
[epoch 20] step 4/44: loss=-0.0081 
[epoch 20] step 6/44: loss=-0.0080 
[epoch 20] step 8/44: loss=-0.0117 
[epoch 20] step 10/44: loss=-0.0187 
[epoch 20] step 12/44: loss=-0.0199 
[epoch 20] step 14/44: loss=-0.0172 
[epoch 20] step 16/44: loss=-0.0200 
[epoch 20] step 18/44: loss=-0.0198 
[epoch 20] step 20/44: loss=-0.0183 
[epoch 20] step 22/44: loss=-0.0212 
[epoch 20] step 24/44: loss=-0.0225 
[epoch 20] step 26/44: loss=-0.0218 
[epoch 20] step 28/44: loss=-0.0192 
[epoch 20] step 30/44: loss=-0.0192 
[epoch 20] step 32/44: loss=-0.0193 
[epoch 20] step 34/44: loss=-0.0212 
[epoch 20] step 36/44: loss=-0.0231 
[epoch 20] step 38/44: loss=-0.0230 
[epoch 20] step 40/44: loss=-0.0230 
[epoch 20] step 42/44: loss=-0.0249 
[epoch 20] step 44/44: loss=-0.0242 
[epoch 20] train_loss(avg per step)=-0.0485 lambda[min,max]=[0.418867,1.000000]
[epoch 20] val_loss=1.2140 qwk=('0.5316', '0.5115', '0.4955') averageQWK=0.5128 macroEMD=0.2325 tailR0=('0.0385', '0.0000', '0.0000') tailR0avg=0.0128
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    6    0    0
     1   14   35    2    0
     0   10   83   21    0
     0    0   56   83    0
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     3    9   43    0    0
     0    6   78   30    0
     0    3   47   93    0
     0    0    2    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     1   10   54    0    0
     0    8  117   18    0
     0    0   45   65    0
     0    0    0    3    0
[epoch 21] step 2/44: loss=-0.0096 
[epoch 21] step 4/44: loss=0.0092 
[epoch 21] step 6/44: loss=-0.0064 
[epoch 21] step 8/44: loss=-0.0071 
[epoch 21] step 10/44: loss=-0.0073 
[epoch 21] step 12/44: loss=-0.0066 
[epoch 21] step 14/44: loss=-0.0052 
[epoch 21] step 16/44: loss=-0.0098 
[epoch 21] step 18/44: loss=-0.0142 
[epoch 21] step 20/44: loss=-0.0174 
[epoch 21] step 22/44: loss=-0.0151 
[epoch 21] step 24/44: loss=-0.0149 
[epoch 21] step 26/44: loss=-0.0145 
[epoch 21] step 28/44: loss=-0.0137 
[epoch 21] step 30/44: loss=-0.0146 
[epoch 21] step 32/44: loss=-0.0174 
[epoch 21] step 34/44: loss=-0.0184 
[epoch 21] step 36/44: loss=-0.0191 
[epoch 21] step 38/44: loss=-0.0197 
[epoch 21] step 40/44: loss=-0.0187 
[epoch 21] step 42/44: loss=-0.0199 
[epoch 21] step 44/44: loss=-0.0216 
[epoch 21] train_loss(avg per step)=-0.0432 lambda[min,max]=[0.479041,1.000000]
[epoch 21] val_loss=1.2848 qwk=('0.5042', '0.5226', '0.5015') averageQWK=0.5094 macroEMD=0.2347 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    9    0    0
     1    4   43    4    0
     0    2   78   34    0
     0    0   37  102    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     3    7   41    4    0
     0    2   64   48    0
     0    0   29  114    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     1    8   56    0    0
     0    6   97   40    0
     0    0   32   78    0
     0    0    0    3    0
[epoch 22] step 2/44: loss=-0.0274 
[epoch 22] step 4/44: loss=-0.0405 
[epoch 22] step 6/44: loss=-0.0423 
[epoch 22] step 8/44: loss=-0.0386 
[epoch 22] step 10/44: loss=-0.0411 
[epoch 22] step 12/44: loss=-0.0400 
[epoch 22] step 14/44: loss=-0.0404 
[epoch 22] step 16/44: loss=-0.0428 
[epoch 22] step 18/44: loss=-0.0426 
[epoch 22] step 20/44: loss=-0.0442 
[epoch 22] step 22/44: loss=-0.0467 
[epoch 22] step 24/44: loss=-0.0475 
[epoch 22] step 26/44: loss=-0.0487 
[epoch 22] step 28/44: loss=-0.0505 
[epoch 22] step 30/44: loss=-0.0497 
[epoch 22] step 32/44: loss=-0.0505 
[epoch 22] step 34/44: loss=-0.0507 
[epoch 22] step 36/44: loss=-0.0506 
[epoch 22] step 38/44: loss=-0.0511 
[epoch 22] step 40/44: loss=-0.0515 
[epoch 22] step 42/44: loss=-0.0514 
[epoch 22] step 44/44: loss=-0.0503 
[epoch 22] train_loss(avg per step)=-0.1005 lambda[min,max]=[0.430099,1.000000]
[epoch 22] val_loss=1.2518 qwk=('0.4935', '0.5103', '0.5037') averageQWK=0.5025 macroEMD=0.2324 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    0    0
     0    7   42    3    0
     0    3   89   22    0
     0    0   50   89    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     0    9   42    4    0
     0    2   68   44    0
     0    0   32  111    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   13   52    0    0
     0   12  102   29    0
     0    0   39   71    0
     0    0    0    3    0
[epoch 23] step 2/44: loss=-0.0684 
[epoch 23] step 4/44: loss=-0.0689 
[epoch 23] step 6/44: loss=-0.0683 
[epoch 23] step 8/44: loss=-0.0682 
[epoch 23] step 10/44: loss=-0.0683 
[epoch 23] step 12/44: loss=-0.0646 
[epoch 23] step 14/44: loss=-0.0626 
[epoch 23] step 16/44: loss=-0.0611 
[epoch 23] step 18/44: loss=-0.0615 
[epoch 23] step 20/44: loss=-0.0589 
[epoch 23] step 22/44: loss=-0.0572 
[epoch 23] step 24/44: loss=-0.0571 
[epoch 23] step 26/44: loss=-0.0568 
[epoch 23] step 28/44: loss=-0.0579 
[epoch 23] step 30/44: loss=-0.0565 
[epoch 23] step 32/44: loss=-0.0578 
[epoch 23] step 34/44: loss=-0.0564 
[epoch 23] step 36/44: loss=-0.0554 
[epoch 23] step 38/44: loss=-0.0548 
[epoch 23] step 40/44: loss=-0.0554 
[epoch 23] step 42/44: loss=-0.0565 
[epoch 23] step 44/44: loss=-0.0580 
[epoch 23] train_loss(avg per step)=-0.1160 lambda[min,max]=[0.400748,1.000000]
[epoch 23] val_loss=1.2569 qwk=('0.5395', '0.5147', '0.4950') averageQWK=0.5164 macroEMD=0.2303 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    7    0    0
     1    7   40    4    0
     0    3   82   29    0
     0    0   39  100    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     3    7   42    3    0
     0    4   72   38    0
     0    2   34  107    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   12   53    0    0
     0   11  105   27    0
     0    0   41   69    0
     0    0    0    3    0
[epoch 24] step 2/44: loss=-0.0682 
[epoch 24] step 4/44: loss=-0.0668 
[epoch 24] step 6/44: loss=-0.0736 
[epoch 24] step 8/44: loss=-0.0717 
[epoch 24] step 10/44: loss=-0.0704 
[epoch 24] step 12/44: loss=-0.0720 
[epoch 24] step 14/44: loss=-0.0703 
[epoch 24] step 16/44: loss=-0.0703 
[epoch 24] step 18/44: loss=-0.0693 
[epoch 24] step 20/44: loss=-0.0687 
[epoch 24] step 22/44: loss=-0.0701 
[epoch 24] step 24/44: loss=-0.0703 
[epoch 24] step 26/44: loss=-0.0703 
[epoch 24] step 28/44: loss=-0.0706 
[epoch 24] step 30/44: loss=-0.0705 
[epoch 24] step 32/44: loss=-0.0698 
[epoch 24] step 34/44: loss=-0.0700 
[epoch 24] step 36/44: loss=-0.0700 
[epoch 24] step 38/44: loss=-0.0694 
[epoch 24] step 40/44: loss=-0.0686 
[epoch 24] step 42/44: loss=-0.0679 
[epoch 24] step 44/44: loss=-0.0679 
[epoch 24] train_loss(avg per step)=-0.1358 lambda[min,max]=[0.447129,1.000000]
[epoch 24] val_loss=1.2880 qwk=('0.5349', '0.5225', '0.5090') averageQWK=0.5221 macroEMD=0.2303 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    8    0    0
     1    7   39    5    0
     0    3   79   32    0
     0    0   36  103    0
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     3    5   45    2    0
     0    0   75   39    0
     0    0   37  106    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   13   52    0    0
     0    9  108   26    0
     0    0   40   70    0
     0    0    0    3    0
[epoch 25] step 2/44: loss=-0.0724 
[epoch 25] step 4/44: loss=-0.0639 
[epoch 25] step 6/44: loss=-0.0722 
[epoch 25] step 8/44: loss=-0.0719 
[epoch 25] step 10/44: loss=-0.0712 
[epoch 25] step 12/44: loss=-0.0723 
[epoch 25] step 14/44: loss=-0.0707 
[epoch 25] step 16/44: loss=-0.0741 
[epoch 25] step 18/44: loss=-0.0738 
[epoch 25] step 20/44: loss=-0.0755 
[epoch 25] step 22/44: loss=-0.0757 
[epoch 25] step 24/44: loss=-0.0764 
[epoch 25] step 26/44: loss=-0.0761 
[epoch 25] step 28/44: loss=-0.0761 
[epoch 25] step 30/44: loss=-0.0759 
[epoch 25] step 32/44: loss=-0.0764 
[epoch 25] step 34/44: loss=-0.0768 
[epoch 25] step 36/44: loss=-0.0775 
[epoch 25] step 38/44: loss=-0.0775 
[epoch 25] step 40/44: loss=-0.0779 
[epoch 25] step 42/44: loss=-0.0772 
[epoch 25] step 44/44: loss=-0.0771 
[epoch 25] train_loss(avg per step)=-0.1542 lambda[min,max]=[0.357457,1.000000]
[epoch 25] val_loss=1.3323 qwk=('0.5201', '0.4763', '0.4981') averageQWK=0.4982 macroEMD=0.2325 tailR0=('0.0385', '0.0000', '0.0000') tailR0avg=0.0128
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    8    0    0
     0    7   42    3    0
     0    2   84   28    0
     0    0   41   98    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     0    6   47    2    0
     0    0   79   35    0
     0    0   45   98    0
     0    0    2    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   11   54    0    0
     0    9  101   33    0
     0    0   37   73    0
     0    0    0    3    0
[epoch 26] step 2/44: loss=-0.0819 
[epoch 26] step 4/44: loss=-0.0832 
[epoch 26] step 6/44: loss=-0.0833 
[epoch 26] step 8/44: loss=-0.0800 
[epoch 26] step 10/44: loss=-0.0800 
[epoch 26] step 12/44: loss=-0.0787 
[epoch 26] step 14/44: loss=-0.0792 
[epoch 26] step 16/44: loss=-0.0775 
[epoch 26] step 18/44: loss=-0.0783 
[epoch 26] step 20/44: loss=-0.0791 
[epoch 26] step 22/44: loss=-0.0779 
[epoch 26] step 24/44: loss=-0.0763 
[epoch 26] step 26/44: loss=-0.0767 
[epoch 26] step 28/44: loss=-0.0767 
[epoch 26] step 30/44: loss=-0.0764 
[epoch 26] step 32/44: loss=-0.0765 
[epoch 26] step 34/44: loss=-0.0767 
[epoch 26] step 36/44: loss=-0.0772 
[epoch 26] step 38/44: loss=-0.0775 
[epoch 26] step 40/44: loss=-0.0776 
[epoch 26] step 42/44: loss=-0.0773 
[epoch 26] step 44/44: loss=-0.0779 
[epoch 26] train_loss(avg per step)=-0.1559 lambda[min,max]=[0.425525,1.000000]
[epoch 26] val_loss=1.2895 qwk=('0.5000', '0.4990', '0.5058') averageQWK=0.5016 macroEMD=0.2300 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    0    0
     0    8   40    4    0
     0    2   84   28    0
     0    0   44   95    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     0   10   43    2    0
     0    2   74   38    0
     0    0   45   98    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   12   53    0    0
     0    9  109   25    0
     0    0   40   70    0
     0    0    0    3    0
[epoch 27] step 2/44: loss=-0.0849 
[epoch 27] step 4/44: loss=-0.0867 
[epoch 27] step 6/44: loss=-0.0853 
[epoch 27] step 8/44: loss=-0.0849 
[epoch 27] step 10/44: loss=-0.0840 
[epoch 27] step 12/44: loss=-0.0846 
[epoch 27] step 14/44: loss=-0.0844 
[epoch 27] step 16/44: loss=-0.0838 
[epoch 27] step 18/44: loss=-0.0838 
[epoch 27] step 20/44: loss=-0.0848 
[epoch 27] step 22/44: loss=-0.0845 
[epoch 27] step 24/44: loss=-0.0851 
[epoch 27] step 26/44: loss=-0.0861 
[epoch 27] step 28/44: loss=-0.0855 
[epoch 27] step 30/44: loss=-0.0861 
[epoch 27] step 32/44: loss=-0.0861 
[epoch 27] step 34/44: loss=-0.0868 
[epoch 27] step 36/44: loss=-0.0857 
[epoch 27] step 38/44: loss=-0.0855 
[epoch 27] step 40/44: loss=-0.0860 
[epoch 27] step 42/44: loss=-0.0857 
[epoch 27] step 44/44: loss=-0.0866 
[epoch 27] train_loss(avg per step)=-0.1731 lambda[min,max]=[0.404800,1.000000]
[epoch 27] val_loss=1.3103 qwk=('0.5328', '0.5147', '0.5273') averageQWK=0.5250 macroEMD=0.2278 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    8    0    0
     1    8   41    2    0
     0    1   85   28    0
     0    0   45   94    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     1    7   44    3    0
     0    1   70   43    0
     0    0   33  110    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   17   48    0    0
     0   12  106   25    0
     0    0   40   70    0
     0    0    0    3    0
[epoch 28] step 2/44: loss=-0.1028 
[epoch 28] step 4/44: loss=-0.0972 
[epoch 28] step 6/44: loss=-0.0950 
[epoch 28] step 8/44: loss=-0.0943 
[epoch 28] step 10/44: loss=-0.0915 
[epoch 28] step 12/44: loss=-0.0916 
[epoch 28] step 14/44: loss=-0.0912 
[epoch 28] step 16/44: loss=-0.0913 
[epoch 28] step 18/44: loss=-0.0924 
[epoch 28] step 20/44: loss=-0.0904 
[epoch 28] step 22/44: loss=-0.0894 
[epoch 28] step 24/44: loss=-0.0902 
[epoch 28] step 26/44: loss=-0.0902 
[epoch 28] step 28/44: loss=-0.0895 
[epoch 28] step 30/44: loss=-0.0896 
[epoch 28] step 32/44: loss=-0.0892 
[epoch 28] step 34/44: loss=-0.0888 
[epoch 28] step 36/44: loss=-0.0888 
[epoch 28] step 38/44: loss=-0.0885 
[epoch 28] step 40/44: loss=-0.0884 
[epoch 28] step 42/44: loss=-0.0870 
[epoch 28] step 44/44: loss=-0.0876 
[epoch 28] train_loss(avg per step)=-0.1752 lambda[min,max]=[0.382363,1.000000]
[epoch 28] val_loss=1.3345 qwk=('0.5190', '0.5166', '0.5089') averageQWK=0.5148 macroEMD=0.2321 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    8    0    0
     1    7   41    3    0
     0    1   92   21    0
     0    0   50   88    1
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     3    5   44    3    0
     0    1   69   44    0
     0    0   33  110    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   19   46    0    0
     0   12  116   15    0
     0    1   46   63    0
     0    0    1    2    0
[epoch 29] step 2/44: loss=-0.0915 
[epoch 29] step 4/44: loss=-0.0886 
[epoch 29] step 6/44: loss=-0.0896 
[epoch 29] step 8/44: loss=-0.0876 
[epoch 29] step 10/44: loss=-0.0886 
[epoch 29] step 12/44: loss=-0.0907 
[epoch 29] step 14/44: loss=-0.0912 
[epoch 29] step 16/44: loss=-0.0902 
[epoch 29] step 18/44: loss=-0.0914 
[epoch 29] step 20/44: loss=-0.0914 
[epoch 29] step 22/44: loss=-0.0920 
[epoch 29] step 24/44: loss=-0.0908 
[epoch 29] step 26/44: loss=-0.0907 
[epoch 29] step 28/44: loss=-0.0907 
[epoch 29] step 30/44: loss=-0.0904 
[epoch 29] step 32/44: loss=-0.0912 
[epoch 29] step 34/44: loss=-0.0920 
[epoch 29] step 36/44: loss=-0.0925 
[epoch 29] step 38/44: loss=-0.0923 
[epoch 29] step 40/44: loss=-0.0928 
[epoch 29] step 42/44: loss=-0.0930 
[epoch 29] step 44/44: loss=-0.0932 
[epoch 29] train_loss(avg per step)=-0.1863 lambda[min,max]=[0.383769,1.000000]
[epoch 29] val_loss=1.3340 qwk=('0.5261', '0.5193', '0.5056') averageQWK=0.5170 macroEMD=0.2277 tailR0=('0.1154', '0.0000', '0.0000') tailR0avg=0.0385
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    8    0    0
     1    8   39    3    1
     0    3   81   30    0
     0    0   40   99    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     3    7   42    3    0
     0    2   68   44    0
     0    1   32  110    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   15   50    0    0
     0   11  108   24    0
     0    0   41   69    0
     0    0    1    2    0
[epoch 30] step 2/44: loss=-0.0881 
[epoch 30] step 4/44: loss=-0.0890 
[epoch 30] step 6/44: loss=-0.0945 
[epoch 30] step 8/44: loss=-0.0940 
[epoch 30] step 10/44: loss=-0.0947 
[epoch 30] step 12/44: loss=-0.0925 
[epoch 30] step 14/44: loss=-0.0935 
[epoch 30] step 16/44: loss=-0.0942 
[epoch 30] step 18/44: loss=-0.0937 
[epoch 30] step 20/44: loss=-0.0943 
[epoch 30] step 22/44: loss=-0.0952 
[epoch 30] step 24/44: loss=-0.0943 
[epoch 30] step 26/44: loss=-0.0944 
[epoch 30] step 28/44: loss=-0.0942 
[epoch 30] step 30/44: loss=-0.0946 
[epoch 30] step 32/44: loss=-0.0952 
[epoch 30] step 34/44: loss=-0.0954 
[epoch 30] step 36/44: loss=-0.0956 
[epoch 30] step 38/44: loss=-0.0956 
[epoch 30] step 40/44: loss=-0.0953 
[epoch 30] step 42/44: loss=-0.0954 
[epoch 30] step 44/44: loss=-0.0951 
[epoch 30] train_loss(avg per step)=-0.1903 lambda[min,max]=[0.443144,1.000000]
[epoch 30] val_loss=1.3380 qwk=('0.4943', '0.5246', '0.5229') averageQWK=0.5139 macroEMD=0.2286 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    8    0    0
     1    7   41    3    0
     0    2   86   26    0
     0    0   54   85    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     2    8   41    4    0
     0    3   65   46    0
     0    0   32  111    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0   18   47    0    0
     0   12  109   22    0
     0    1   41   68    0
     0    0    1    2    0
[epoch 31] step 2/44: loss=-0.0925 
[epoch 31] step 4/44: loss=-0.0973 
[epoch 31] step 6/44: loss=-0.0957 
[epoch 31] step 8/44: loss=-0.0937 
[epoch 31] step 10/44: loss=-0.0944 
[epoch 31] step 12/44: loss=-0.0964 
[epoch 31] step 14/44: loss=-0.0972 
[epoch 31] step 16/44: loss=-0.0973 
[epoch 31] step 18/44: loss=-0.0979 
[epoch 31] step 20/44: loss=-0.0982 
[epoch 31] step 22/44: loss=-0.0973 
[epoch 31] step 24/44: loss=-0.0974 
[epoch 31] step 26/44: loss=-0.0972 
[epoch 31] step 28/44: loss=-0.0972 
[epoch 31] step 30/44: loss=-0.0976 
[epoch 31] step 32/44: loss=-0.0979 
[epoch 31] step 34/44: loss=-0.0983 
[epoch 31] step 36/44: loss=-0.0982 
[epoch 31] step 38/44: loss=-0.0988 
[epoch 31] step 40/44: loss=-0.0987 
[epoch 31] step 42/44: loss=-0.0979 
[epoch 31] step 44/44: loss=-0.0982 
[epoch 31] train_loss(avg per step)=-0.1965 lambda[min,max]=[0.393604,1.000000]
[epoch 31] val_loss=1.3820 qwk=('0.5291', '0.4904', '0.5099') averageQWK=0.5098 macroEMD=0.2293 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    8    0    0
     1    4   44    3    0
     0    2   81   31    0
     0    0   39  100    0
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     3    3   44    5    0
     0    0   63   51    0
     0    0   29  114    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   15   50    0    0
     0   12  100   31    0
     0    0   39   71    0
     0    0    0    3    0
[epoch 32] step 2/44: loss=-0.1056 
[epoch 32] step 4/44: loss=-0.0992 
[epoch 32] step 6/44: loss=-0.0998 
[epoch 32] step 8/44: loss=-0.0985 
[epoch 32] step 10/44: loss=-0.0994 
[epoch 32] step 12/44: loss=-0.0996 
[epoch 32] step 14/44: loss=-0.0993 
[epoch 32] step 16/44: loss=-0.1003 
[epoch 32] step 18/44: loss=-0.0999 
[epoch 32] step 20/44: loss=-0.0999 
[epoch 32] step 22/44: loss=-0.1003 
[epoch 32] step 24/44: loss=-0.0998 
[epoch 32] step 26/44: loss=-0.1002 
[epoch 32] step 28/44: loss=-0.1004 
[epoch 32] step 30/44: loss=-0.1002 
[epoch 32] step 32/44: loss=-0.0997 
[epoch 32] step 34/44: loss=-0.0996 
[epoch 32] step 36/44: loss=-0.0993 
[epoch 32] step 38/44: loss=-0.0994 
[epoch 32] step 40/44: loss=-0.0992 
[epoch 32] step 42/44: loss=-0.0991 
[epoch 32] step 44/44: loss=-0.0995 
[epoch 32] train_loss(avg per step)=-0.1989 lambda[min,max]=[0.426103,1.000000]
[epoch 32] val_loss=1.3749 qwk=('0.5125', '0.5027', '0.5136') averageQWK=0.5096 macroEMD=0.2314 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    8    0    0
     1    6   42    3    0
     0    2   84   28    0
     0    0   46   93    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     1    6   45    3    0
     0    1   70   43    0
     0    0   35  108    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   14   51    0    0
     0   11  107   25    0
     0    0   40   70    0
     0    0    0    3    0
[epoch 33] step 2/44: loss=-0.0982 
[epoch 33] step 4/44: loss=-0.0969 
[epoch 33] step 6/44: loss=-0.0988 
[epoch 33] step 8/44: loss=-0.0980 
[epoch 33] step 10/44: loss=-0.0984 
[epoch 33] step 12/44: loss=-0.0988 
[epoch 33] step 14/44: loss=-0.0981 
[epoch 33] step 16/44: loss=-0.0985 
[epoch 33] step 18/44: loss=-0.0991 
[epoch 33] step 20/44: loss=-0.1000 
[epoch 33] step 22/44: loss=-0.1002 
[epoch 33] step 24/44: loss=-0.1003 
[epoch 33] step 26/44: loss=-0.1006 
[epoch 33] step 28/44: loss=-0.1004 
[epoch 33] step 30/44: loss=-0.1006 
[epoch 33] step 32/44: loss=-0.1007 
[epoch 33] step 34/44: loss=-0.1007 
[epoch 33] step 36/44: loss=-0.1008 
[epoch 33] step 38/44: loss=-0.1008 
[epoch 33] step 40/44: loss=-0.1010 
[epoch 33] step 42/44: loss=-0.1011 
[epoch 33] step 44/44: loss=-0.1003 
[epoch 33] train_loss(avg per step)=-0.2006 lambda[min,max]=[0.439049,1.000000]
[epoch 33] val_loss=1.3706 qwk=('0.5124', '0.5133', '0.5053') averageQWK=0.5104 macroEMD=0.2297 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    8    0    0
     1    7   41    3    0
     0    2   85   27    0
     0    0   48   91    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     1    8   43    3    0
     0    2   68   44    0
     0    0   34  109    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   12   53    0    0
     0   11  108   24    0
     0    0   40   70    0
     0    0    0    3    0
[epoch 34] step 2/44: loss=-0.1065 
[epoch 34] step 4/44: loss=-0.1065 
[epoch 34] step 6/44: loss=-0.1048 
[epoch 34] step 8/44: loss=-0.1037 
[epoch 34] step 10/44: loss=-0.1031 
[epoch 34] step 12/44: loss=-0.1036 
[epoch 34] step 14/44: loss=-0.1041 
[epoch 34] step 16/44: loss=-0.1022 
[epoch 34] step 18/44: loss=-0.1025 
[epoch 34] step 20/44: loss=-0.1029 
[epoch 34] step 22/44: loss=-0.1023 
[epoch 34] step 24/44: loss=-0.1015 
[epoch 34] step 26/44: loss=-0.1016 
[epoch 34] step 28/44: loss=-0.1020 
[epoch 34] step 30/44: loss=-0.1020 
[epoch 34] step 32/44: loss=-0.1023 
[epoch 34] step 34/44: loss=-0.1018 
[epoch 34] step 36/44: loss=-0.1018 
[epoch 34] step 38/44: loss=-0.1017 
[epoch 34] step 40/44: loss=-0.1017 
[epoch 34] step 42/44: loss=-0.1018 
[epoch 34] step 44/44: loss=-0.1018 
[epoch 34] train_loss(avg per step)=-0.2036 lambda[min,max]=[0.377873,1.000000]
[epoch 34] val_loss=1.3746 qwk=('0.5170', '0.5127', '0.5134') averageQWK=0.5143 macroEMD=0.2286 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    8    0    0
     1    7   41    3    0
     0    2   84   28    0
     0    0   46   93    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     3    4   45    3    0
     0    1   71   42    0
     0    0   34  109    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   15   50    0    0
     0   12  104   27    0
     0    0   40   70    0
     0    0    0    3    0
[epoch 35] step 2/44: loss=-0.0902 
[epoch 35] step 4/44: loss=-0.0975 
[epoch 35] step 6/44: loss=-0.0978 
[epoch 35] step 8/44: loss=-0.0976 
[epoch 35] step 10/44: loss=-0.0981 
[epoch 35] step 12/44: loss=-0.0997 
[epoch 35] step 14/44: loss=-0.1005 
[epoch 35] step 16/44: loss=-0.1007 
[epoch 35] step 18/44: loss=-0.1011 
[epoch 35] step 20/44: loss=-0.1013 
[epoch 35] step 22/44: loss=-0.1015 
[epoch 35] step 24/44: loss=-0.1018 
[epoch 35] step 26/44: loss=-0.1014 
[epoch 35] step 28/44: loss=-0.1018 
[epoch 35] step 30/44: loss=-0.1020 
[epoch 35] step 32/44: loss=-0.1020 
[epoch 35] step 34/44: loss=-0.1022 
[epoch 35] step 36/44: loss=-0.1021 
[epoch 35] step 38/44: loss=-0.1024 
[epoch 35] step 40/44: loss=-0.1024 
[epoch 35] step 42/44: loss=-0.1024 
[epoch 35] step 44/44: loss=-0.1026 
[epoch 35] train_loss(avg per step)=-0.2052 lambda[min,max]=[0.436635,1.000000]
[epoch 35] val_loss=1.3788 qwk=('0.5236', '0.5105', '0.4975') averageQWK=0.5105 macroEMD=0.2287 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    8    0    0
     1    7   41    3    0
     0    2   84   28    0
     0    0   44   95    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     3    4   45    3    0
     0    1   70   43    0
     0    0   34  109    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   12   53    0    0
     0   11  104   28    0
     0    0   40   70    0
     0    0    0    3    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-0/fold5/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-0/fold5/metrics.json
Done.
