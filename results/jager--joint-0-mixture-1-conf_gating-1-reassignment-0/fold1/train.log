[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.5294 
[epoch 1] step 4/44: loss=0.5153 
[epoch 1] step 6/44: loss=0.5095 
[epoch 1] step 8/44: loss=0.5119 
[epoch 1] step 10/44: loss=0.5183 
[epoch 1] step 12/44: loss=0.5170 
[epoch 1] step 14/44: loss=0.5210 
[epoch 1] step 16/44: loss=0.5255 
[epoch 1] step 18/44: loss=0.5289 
[epoch 1] step 20/44: loss=0.5318 
[epoch 1] step 22/44: loss=0.5373 
[epoch 1] step 24/44: loss=0.5411 
[epoch 1] step 26/44: loss=0.5443 
[epoch 1] step 28/44: loss=0.5487 
[epoch 1] step 30/44: loss=0.5525 
[epoch 1] step 32/44: loss=0.5560 
[epoch 1] step 34/44: loss=0.5590 
[epoch 1] step 36/44: loss=0.5624 
[epoch 1] step 38/44: loss=0.5642 
[epoch 1] step 40/44: loss=0.5674 
[epoch 1] step 42/44: loss=0.5699 
[epoch 1] step 44/44: loss=0.5721 
[epoch 1] train_loss(avg per step)=1.1442 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=0.8195 qwk=('0.0600', '0.0961', '0.0888') averageQWK=0.0817 macroEMD=0.3661 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    9    0
     0    4    0   37    0
     0   16    0  106    0
     0   11    0  130    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    0    0
     3    0   36    0    0
     6    0   94    4    0
     8    0  138   17    0
     0    0   11    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   20   32    0    0
     0   38  120    0    0
     0   26   84    0    0
     0    1    2    0    0
[epoch 2] step 2/44: loss=0.6027 
[epoch 2] step 4/44: loss=0.5873 
[epoch 2] step 6/44: loss=0.5947 
[epoch 2] step 8/44: loss=0.5891 
[epoch 2] step 10/44: loss=0.5819 
[epoch 2] step 12/44: loss=0.5829 
[epoch 2] step 14/44: loss=0.5842 
[epoch 2] step 16/44: loss=0.5819 
[epoch 2] step 18/44: loss=0.5835 
[epoch 2] step 20/44: loss=0.5832 
[epoch 2] step 22/44: loss=0.5854 
[epoch 2] step 24/44: loss=0.5888 
[epoch 2] step 26/44: loss=0.5901 
[epoch 2] step 28/44: loss=0.5908 
[epoch 2] step 30/44: loss=0.5925 
[epoch 2] step 32/44: loss=0.5911 
[epoch 2] step 34/44: loss=0.5903 
[epoch 2] step 36/44: loss=0.5880 
[epoch 2] step 38/44: loss=0.5871 
[epoch 2] step 40/44: loss=0.5864 
[epoch 2] step 42/44: loss=0.5861 
[epoch 2] step 44/44: loss=0.5836 
[epoch 2] train_loss(avg per step)=1.1671 lambda[min,max]=[0.505771,1.000000]
[epoch 2] val_loss=1.1090 qwk=('0.4636', '0.4530', '0.0773') averageQWK=0.3313 macroEMD=0.3188 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    0   37    4    0
     0    0   80   42    0
     0    0   30  111    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    1    0
     0    0   33    6    0
     0    0   76   28    0
     0    0   32  131    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    1   51    0    0
     0    0  157    1    0
     0    0  101    9    0
     0    0    3    0    0
[epoch 3] step 2/44: loss=0.5773 
[epoch 3] step 4/44: loss=0.5780 
[epoch 3] step 6/44: loss=0.5762 
[epoch 3] step 8/44: loss=0.5657 
[epoch 3] step 10/44: loss=0.5644 
[epoch 3] step 12/44: loss=0.5607 
[epoch 3] step 14/44: loss=0.5597 
[epoch 3] step 16/44: loss=0.5537 
[epoch 3] step 18/44: loss=0.5549 
[epoch 3] step 20/44: loss=0.5508 
[epoch 3] step 22/44: loss=0.5485 
[epoch 3] step 24/44: loss=0.5487 
[epoch 3] step 26/44: loss=0.5469 
[epoch 3] step 28/44: loss=0.5437 
[epoch 3] step 30/44: loss=0.5457 
[epoch 3] step 32/44: loss=0.5447 
[epoch 3] step 34/44: loss=0.5388 
[epoch 3] step 36/44: loss=0.5372 
[epoch 3] step 38/44: loss=0.5330 
[epoch 3] step 40/44: loss=0.5342 
[epoch 3] step 42/44: loss=0.5327 
[epoch 3] step 44/44: loss=0.5261 
[epoch 3] train_loss(avg per step)=1.0523 lambda[min,max]=[0.505422,1.000000]
[epoch 3] val_loss=1.0029 qwk=('0.4433', '0.4336', '0.4231') averageQWK=0.4333 macroEMD=0.2734 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    0   35    6    0
     0    0   69   53    0
     0    0   24  117    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    2    0
     0    0   32    7    0
     0    0   62   42    0
     0    0   26  137    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    4   39    9    0
     0    5   97   56    0
     0    0   23   87    0
     0    0    0    3    0
[epoch 4] step 2/44: loss=0.4815 
[epoch 4] step 4/44: loss=0.4868 
[epoch 4] step 6/44: loss=0.4786 
[epoch 4] step 8/44: loss=0.4888 
[epoch 4] step 10/44: loss=0.4896 
[epoch 4] step 12/44: loss=0.4868 
[epoch 4] step 14/44: loss=0.4888 
[epoch 4] step 16/44: loss=0.4832 
[epoch 4] step 18/44: loss=0.4813 
[epoch 4] step 20/44: loss=0.4797 
[epoch 4] step 22/44: loss=0.4774 
[epoch 4] step 24/44: loss=0.4783 
[epoch 4] step 26/44: loss=0.4779 
[epoch 4] step 28/44: loss=0.4812 
[epoch 4] step 30/44: loss=0.4839 
[epoch 4] step 32/44: loss=0.4833 
[epoch 4] step 34/44: loss=0.4863 
[epoch 4] step 36/44: loss=0.4885 
[epoch 4] step 38/44: loss=0.4913 
[epoch 4] step 40/44: loss=0.4964 
[epoch 4] step 42/44: loss=0.4996 
[epoch 4] step 44/44: loss=0.5115 
[epoch 4] train_loss(avg per step)=1.0229 lambda[min,max]=[0.501253,1.000000]
[epoch 4] val_loss=1.0383 qwk=('0.5213', '0.4816', '0.3568') averageQWK=0.4532 macroEMD=0.2646 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    9   32    0    0
     0    5   85   32    0
     0    0   45   96    0
     0    0    2   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    1    0
     0    1   36    2    0
     0    3   67   34    0
     0    0   39  124    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   50    1    0
     0    3  136   19    0
     0    0   59   51    0
     0    0    0    3    0
[epoch 5] step 2/44: loss=0.3914 
[epoch 5] step 4/44: loss=0.4165 
[epoch 5] step 6/44: loss=0.4410 
[epoch 5] step 8/44: loss=0.4607 
[epoch 5] step 10/44: loss=0.4588 
[epoch 5] step 12/44: loss=0.4565 
[epoch 5] step 14/44: loss=0.4603 
[epoch 5] step 16/44: loss=0.4608 
[epoch 5] step 18/44: loss=0.4579 
[epoch 5] step 20/44: loss=0.4557 
[epoch 5] step 22/44: loss=0.4542 
[epoch 5] step 24/44: loss=0.4532 
[epoch 5] step 26/44: loss=0.4533 
[epoch 5] step 28/44: loss=0.4545 
[epoch 5] step 30/44: loss=0.4594 
[epoch 5] step 32/44: loss=0.4581 
[epoch 5] step 34/44: loss=0.4542 
[epoch 5] step 36/44: loss=0.4562 
[epoch 5] step 38/44: loss=0.4563 
[epoch 5] step 40/44: loss=0.4546 
[epoch 5] step 42/44: loss=0.4532 
[epoch 5] step 44/44: loss=0.4554 
[epoch 5] train_loss(avg per step)=0.9108 lambda[min,max]=[0.500081,1.000000]
[epoch 5] val_loss=1.0272 qwk=('0.4986', '0.4519', '0.5143') averageQWK=0.4883 macroEMD=0.2533 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    0    0
     0    9   26    6    0
     0    5   62   55    0
     0    0   26  115    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    1    0
     0    0   35    4    0
     0    0   67   37    0
     0    0   36  127    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   17   29    6    0
     0   26   84   48    0
     0    2   23   85    0
     0    0    0    3    0
[epoch 6] step 2/44: loss=0.4453 
[epoch 6] step 4/44: loss=0.4284 
[epoch 6] step 6/44: loss=0.4341 
[epoch 6] step 8/44: loss=0.4287 
[epoch 6] step 10/44: loss=0.4299 
[epoch 6] step 12/44: loss=0.4266 
[epoch 6] step 14/44: loss=0.4295 
[epoch 6] step 16/44: loss=0.4229 
[epoch 6] step 18/44: loss=0.4222 
[epoch 6] step 20/44: loss=0.4191 
[epoch 6] step 22/44: loss=0.4245 
[epoch 6] step 24/44: loss=0.4202 
[epoch 6] step 26/44: loss=0.4150 
[epoch 6] step 28/44: loss=0.4148 
[epoch 6] step 30/44: loss=0.4106 
[epoch 6] step 32/44: loss=0.4123 
[epoch 6] step 34/44: loss=0.4122 
[epoch 6] step 36/44: loss=0.4158 
[epoch 6] step 38/44: loss=0.4170 
[epoch 6] step 40/44: loss=0.4165 
[epoch 6] step 42/44: loss=0.4160 
[epoch 6] step 44/44: loss=0.4135 
[epoch 6] train_loss(avg per step)=0.8270 lambda[min,max]=[0.500006,1.000000]
[epoch 6] val_loss=1.0541 qwk=('0.5768', '0.5030', '0.4613') averageQWK=0.5137 macroEMD=0.2505 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   18   22    1    0
     0   28   58   36    0
     0    3   34  104    0
     0    0    3   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    1    0
     0    7   30    2    0
     0   14   65   25    0
     0    3   45  115    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0   17   32    3    0
     0   26  106   26    0
     0    4   42   64    0
     0    0    0    3    0
[epoch 7] step 2/44: loss=0.4290 
[epoch 7] step 4/44: loss=0.4156 
[epoch 7] step 6/44: loss=0.3910 
[epoch 7] step 8/44: loss=0.3927 
[epoch 7] step 10/44: loss=0.3930 
[epoch 7] step 12/44: loss=0.4010 
[epoch 7] step 14/44: loss=0.4010 
[epoch 7] step 16/44: loss=0.3959 
[epoch 7] step 18/44: loss=0.3899 
[epoch 7] step 20/44: loss=0.3933 
[epoch 7] step 22/44: loss=0.3861 
[epoch 7] step 24/44: loss=0.3883 
[epoch 7] step 26/44: loss=0.3923 
[epoch 7] step 28/44: loss=0.3891 
[epoch 7] step 30/44: loss=0.3881 
[epoch 7] step 32/44: loss=0.3831 
[epoch 7] step 34/44: loss=0.3862 
[epoch 7] step 36/44: loss=0.3847 
[epoch 7] step 38/44: loss=0.3819 
[epoch 7] step 40/44: loss=0.3821 
[epoch 7] step 42/44: loss=0.3795 
[epoch 7] step 44/44: loss=0.3772 
[epoch 7] train_loss(avg per step)=0.7545 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.0093 qwk=('0.5071', '0.4945', '0.4420') averageQWK=0.4812 macroEMD=0.2490 tailR0=('0.0952', '0.0000', '0.0000') tailR0avg=0.0317
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    0    0
     0    7   32    2    0
     0    2   93   26    1
     0    0   47   89    5
     0    0    5   12    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0    7   25    7    0
     0    8   51   45    0
     0    0   28  135    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    7   41    4    0
     0   14  109   35    0
     0    1   40   69    0
     0    0    0    3    0
[epoch 8] step 2/44: loss=0.2947 
[epoch 8] step 4/44: loss=0.3061 
[epoch 8] step 6/44: loss=0.3153 
[epoch 8] step 8/44: loss=0.3050 
[epoch 8] step 10/44: loss=0.3067 
[epoch 8] step 12/44: loss=0.3123 
[epoch 8] step 14/44: loss=0.3180 
[epoch 8] step 16/44: loss=0.3226 
[epoch 8] step 18/44: loss=0.3281 
[epoch 8] step 20/44: loss=0.3250 
[epoch 8] step 22/44: loss=0.3275 
[epoch 8] step 24/44: loss=0.3316 
[epoch 8] step 26/44: loss=0.3324 
[epoch 8] step 28/44: loss=0.3317 
[epoch 8] step 30/44: loss=0.3324 
[epoch 8] step 32/44: loss=0.3335 
[epoch 8] step 34/44: loss=0.3349 
[epoch 8] step 36/44: loss=0.3346 
[epoch 8] step 38/44: loss=0.3339 
[epoch 8] step 40/44: loss=0.3358 
[epoch 8] step 42/44: loss=0.3374 
[epoch 8] step 44/44: loss=0.3415 
[epoch 8] train_loss(avg per step)=0.6829 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.1682 qwk=('0.4308', '0.3418', '0.4475') averageQWK=0.4067 macroEMD=0.2545 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0    8   21   12    0
     0    2   38   82    0
     0    0   11  130    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    4    0
     0    4   17   18    0
     0    5   33   66    0
     0    0   17  146    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    5   38    9    0
     0   11   69   78    0
     0    0   13   97    0
     0    0    0    3    0
[epoch 9] step 2/44: loss=0.3573 
[epoch 9] step 4/44: loss=0.3097 
[epoch 9] step 6/44: loss=0.2878 
[epoch 9] step 8/44: loss=0.3236 
[epoch 9] step 10/44: loss=0.3153 
[epoch 9] step 12/44: loss=0.3100 
[epoch 9] step 14/44: loss=0.3129 
[epoch 9] step 16/44: loss=0.3128 
[epoch 9] step 18/44: loss=0.3153 
[epoch 9] step 20/44: loss=0.3138 
[epoch 9] step 22/44: loss=0.3117 
[epoch 9] step 24/44: loss=0.3109 
[epoch 9] step 26/44: loss=0.3105 
[epoch 9] step 28/44: loss=0.3129 
[epoch 9] step 30/44: loss=0.3120 
[epoch 9] step 32/44: loss=0.3121 
[epoch 9] step 34/44: loss=0.3061 
[epoch 9] step 36/44: loss=0.3047 
[epoch 9] step 38/44: loss=0.3050 
[epoch 9] step 40/44: loss=0.3057 
[epoch 9] step 42/44: loss=0.3087 
[epoch 9] step 44/44: loss=0.3090 
[epoch 9] train_loss(avg per step)=0.6179 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.1764 qwk=('0.4513', '0.3376', '0.4188') averageQWK=0.4025 macroEMD=0.2624 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    7   24   10    0
     0    2   47   73    0
     0    0   13  124    4
     0    0    0   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    5    0
     0    3   18   18    0
     0    4   40   60    0
     0    0   13  150    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    4   38   10    0
     0    9   71   78    0
     0    0   13   97    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=0.2865 
[epoch 10] step 4/44: loss=0.2899 
[epoch 10] step 6/44: loss=0.2708 
[epoch 10] step 8/44: loss=0.2892 
[epoch 10] step 10/44: loss=0.2851 
[epoch 10] step 12/44: loss=0.2774 
[epoch 10] step 14/44: loss=0.2794 
[epoch 10] step 16/44: loss=0.2882 
[epoch 10] step 18/44: loss=0.2934 
[epoch 10] step 20/44: loss=0.2897 
[epoch 10] step 22/44: loss=0.2858 
[epoch 10] step 24/44: loss=0.2834 
[epoch 10] step 26/44: loss=0.2814 
[epoch 10] step 28/44: loss=0.2786 
[epoch 10] step 30/44: loss=0.2747 
[epoch 10] step 32/44: loss=0.2746 
[epoch 10] step 34/44: loss=0.2721 
[epoch 10] step 36/44: loss=0.2705 
[epoch 10] step 38/44: loss=0.2703 
[epoch 10] step 40/44: loss=0.2687 
[epoch 10] step 42/44: loss=0.2686 
[epoch 10] step 44/44: loss=0.2718 
[epoch 10] train_loss(avg per step)=0.5435 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.2345 qwk=('0.3976', '0.3648', '0.3913') averageQWK=0.3846 macroEMD=0.2621 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    4    0
     0    5   25   11    0
     0    2   42   77    1
     0    0   12  126    3
     0    0    0   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    4    0
     0    3   21   15    0
     0    4   42   58    0
     0    0   17  146    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    2    0
     0    3   38   11    0
     0   11   60   87    0
     0    0   10  100    0
     0    0    0    3    0
[epoch 11] step 2/44: loss=0.3513 
[epoch 11] step 4/44: loss=0.2745 
[epoch 11] step 6/44: loss=0.2445 
[epoch 11] step 8/44: loss=0.2547 
[epoch 11] step 10/44: loss=0.2497 
[epoch 11] step 12/44: loss=0.2431 
[epoch 11] step 14/44: loss=0.2444 
[epoch 11] step 16/44: loss=0.2456 
[epoch 11] step 18/44: loss=0.2511 
[epoch 11] step 20/44: loss=0.2477 
[epoch 11] step 22/44: loss=0.2430 
[epoch 11] step 24/44: loss=0.2466 
[epoch 11] step 26/44: loss=0.2448 
[epoch 11] step 28/44: loss=0.2428 
[epoch 11] step 30/44: loss=0.2425 
[epoch 11] step 32/44: loss=0.2417 
[epoch 11] step 34/44: loss=0.2424 
[epoch 11] step 36/44: loss=0.2430 
[epoch 11] step 38/44: loss=0.2432 
[epoch 11] step 40/44: loss=0.2413 
[epoch 11] step 42/44: loss=0.2413 
[epoch 11] step 44/44: loss=0.2390 
[epoch 11] train_loss(avg per step)=0.4781 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=1.0895 qwk=('0.4543', '0.3836', '0.4577') averageQWK=0.4319 macroEMD=0.2479 tailR0=('0.0476', '0.0000', '0.0000') tailR0avg=0.0159
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    9   25    7    0
     0    5   66   51    0
     0    0   33  104    4
     0    0    3   16    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    2   27   10    0
     0    9   49   46    0
     0    1   34  128    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   15   35    2    0
     0   22  104   32    0
     0    4   46   60    0
     0    0    0    3    0
[epoch 12] step 2/44: loss=0.1662 
[epoch 12] step 4/44: loss=0.2223 
[epoch 12] step 6/44: loss=0.2125 
[epoch 12] step 8/44: loss=0.2173 
[epoch 12] step 10/44: loss=0.2159 
[epoch 12] step 12/44: loss=0.2052 
[epoch 12] step 14/44: loss=0.2000 
[epoch 12] step 16/44: loss=0.2001 
[epoch 12] step 18/44: loss=0.2006 
[epoch 12] step 20/44: loss=0.1985 
[epoch 12] step 22/44: loss=0.1982 
[epoch 12] step 24/44: loss=0.1956 
[epoch 12] step 26/44: loss=0.1959 
[epoch 12] step 28/44: loss=0.1998 
[epoch 12] step 30/44: loss=0.2004 
[epoch 12] step 32/44: loss=0.1988 
[epoch 12] step 34/44: loss=0.2027 
[epoch 12] step 36/44: loss=0.2021 
[epoch 12] step 38/44: loss=0.2043 
[epoch 12] step 40/44: loss=0.2024 
[epoch 12] step 42/44: loss=0.2013 
[epoch 12] step 44/44: loss=0.1969 
[epoch 12] train_loss(avg per step)=0.3939 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=1.0897 qwk=('0.4610', '0.4049', '0.4283') averageQWK=0.4314 macroEMD=0.2485 tailR0=('0.0476', '0.0000', '0.0000') tailR0avg=0.0159
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0    8   23   10    0
     0    5   49   68    0
     0    0   17  124    0
     0    0    1   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    2    0
     0    4   23   12    0
     0    8   48   48    0
     0    0   30  133    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    6   43    3    0
     0   15  113   30    0
     0    1   43   66    0
     0    0    0    3    0
[epoch 13] step 2/44: loss=0.2324 
[epoch 13] step 4/44: loss=0.2109 
[epoch 13] step 6/44: loss=0.1953 
[epoch 13] step 8/44: loss=0.1994 
[epoch 13] step 10/44: loss=0.1911 
[epoch 13] step 12/44: loss=0.1846 
[epoch 13] step 14/44: loss=0.1847 
[epoch 13] step 16/44: loss=0.1896 
[epoch 13] step 18/44: loss=0.1823 
[epoch 13] step 20/44: loss=0.1804 
[epoch 13] step 22/44: loss=0.1793 
[epoch 13] step 24/44: loss=0.1782 
[epoch 13] step 26/44: loss=0.1791 
[epoch 13] step 28/44: loss=0.1761 
[epoch 13] step 30/44: loss=0.1744 
[epoch 13] step 32/44: loss=0.1759 
[epoch 13] step 34/44: loss=0.1757 
[epoch 13] step 36/44: loss=0.1750 
[epoch 13] step 38/44: loss=0.1731 
[epoch 13] step 40/44: loss=0.1732 
[epoch 13] step 42/44: loss=0.1743 
[epoch 13] step 44/44: loss=0.1709 
[epoch 13] train_loss(avg per step)=0.3418 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=1.1240 qwk=('0.4435', '0.3830', '0.3952') averageQWK=0.4073 macroEMD=0.2555 tailR0=('0.1667', '0.0000', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    6   27    8    0
     0    2   69   50    1
     0    0   37   96    8
     0    0    2   12    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    3   27    9    0
     0    4   50   50    0
     0    0   35  128    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   44    6    0
     0    6  110   42    0
     0    0   35   75    0
     0    0    0    3    0
[epoch 14] step 2/44: loss=0.1510 
[epoch 14] step 4/44: loss=0.1751 
[epoch 14] step 6/44: loss=0.1710 
[epoch 14] step 8/44: loss=0.1646 
[epoch 14] step 10/44: loss=0.1686 
[epoch 14] step 12/44: loss=0.1735 
[epoch 14] step 14/44: loss=0.1746 
[epoch 14] step 16/44: loss=0.1772 
[epoch 14] step 18/44: loss=0.1749 
[epoch 14] step 20/44: loss=0.1700 
[epoch 14] step 22/44: loss=0.1648 
[epoch 14] step 24/44: loss=0.1669 
[epoch 14] step 26/44: loss=0.1674 
[epoch 14] step 28/44: loss=0.1664 
[epoch 14] step 30/44: loss=0.1620 
[epoch 14] step 32/44: loss=0.1614 
[epoch 14] step 34/44: loss=0.1629 
[epoch 14] step 36/44: loss=0.1639 
[epoch 14] step 38/44: loss=0.1627 
[epoch 14] step 40/44: loss=0.1616 
[epoch 14] step 42/44: loss=0.1592 
[epoch 14] step 44/44: loss=0.1616 
[epoch 14] train_loss(avg per step)=0.3232 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=1.1332 qwk=('0.4764', '0.4140', '0.4406') averageQWK=0.4437 macroEMD=0.2469 tailR0=('0.0952', '0.0625', '0.0000') tailR0avg=0.0526
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    8   27    6    0
     0    4   73   45    0
     0    0   37  102    2
     0    0    2   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    5   30    4    0
     0    6   71   26    1
     0    0   56  106    1
     0    0    4   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    8   38    6    0
     0   20   92   46    0
     0    1   27   82    0
     0    0    0    3    0
[epoch 15] step 2/44: loss=0.1537 
[epoch 15] step 4/44: loss=0.1468 
[epoch 15] step 6/44: loss=0.1421 
[epoch 15] step 8/44: loss=0.1453 
[epoch 15] step 10/44: loss=0.1512 
[epoch 15] step 12/44: loss=0.1442 
[epoch 15] step 14/44: loss=0.1459 
[epoch 15] step 16/44: loss=0.1407 
[epoch 15] step 18/44: loss=0.1377 
[epoch 15] step 20/44: loss=0.1319 
[epoch 15] step 22/44: loss=0.1363 
[epoch 15] step 24/44: loss=0.1324 
[epoch 15] step 26/44: loss=0.1302 
[epoch 15] step 28/44: loss=0.1283 
[epoch 15] step 30/44: loss=0.1270 
[epoch 15] step 32/44: loss=0.1248 
[epoch 15] step 34/44: loss=0.1250 
[epoch 15] step 36/44: loss=0.1240 
[epoch 15] step 38/44: loss=0.1238 
[epoch 15] step 40/44: loss=0.1222 
[epoch 15] step 42/44: loss=0.1198 
[epoch 15] step 44/44: loss=0.1148 
[epoch 15] train_loss(avg per step)=0.2296 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=1.1782 qwk=('0.4854', '0.4153', '0.4662') averageQWK=0.4556 macroEMD=0.2390 tailR0=('0.1667', '0.0312', '0.0000') tailR0avg=0.0660
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    9   32    0    0
     0    7   93   22    0
     0    0   63   72    6
     0    0    6    8    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    2    0
     0    6   29    4    0
     0    8   71   25    0
     0    0   62  100    1
     0    0    4   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    5    0    0
     0   28   22    2    0
     0   44   91   23    0
     0    6   55   49    0
     0    0    0    3    0
[epoch 16] step 2/44: loss=0.1657 
[epoch 16] step 4/44: loss=0.1586 
[epoch 16] step 6/44: loss=0.1432 
[epoch 16] step 8/44: loss=0.1333 
[epoch 16] step 10/44: loss=0.1240 
[epoch 16] step 12/44: loss=0.1293 
[epoch 16] step 14/44: loss=0.1199 
[epoch 16] step 16/44: loss=0.1209 
[epoch 16] step 18/44: loss=0.1182 
[epoch 16] step 20/44: loss=0.1156 
[epoch 16] step 22/44: loss=0.1196 
[epoch 16] step 24/44: loss=0.1152 
[epoch 16] step 26/44: loss=0.1172 
[epoch 16] step 28/44: loss=0.1124 
[epoch 16] step 30/44: loss=0.1126 
[epoch 16] step 32/44: loss=0.1134 
[epoch 16] step 34/44: loss=0.1130 
[epoch 16] step 36/44: loss=0.1087 
[epoch 16] step 38/44: loss=0.1061 
[epoch 16] step 40/44: loss=0.1055 
[epoch 16] step 42/44: loss=0.1040 
[epoch 16] step 44/44: loss=0.0986 
[epoch 16] train_loss(avg per step)=0.1971 lambda[min,max]=[0.498527,1.000000]
[epoch 16] val_loss=1.1783 qwk=('0.5236', '0.4330', '0.4592') averageQWK=0.4720 macroEMD=0.2418 tailR0=('0.1667', '0.0312', '0.0000') tailR0avg=0.0660
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0   10   28    3    0
     0    6   71   43    2
     0    0   31  103    7
     0    0    3   11    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    2    0
     0    4   31    4    0
     0    9   65   29    1
     0    0   47  115    1
     0    0    4   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   14   34    4    0
     0   23   92   43    0
     0    3   36   71    0
     0    0    0    3    0
[epoch 17] step 2/44: loss=0.0573 
[epoch 17] step 4/44: loss=0.0621 
[epoch 17] step 6/44: loss=0.0759 
[epoch 17] step 8/44: loss=0.0788 
[epoch 17] step 10/44: loss=0.0826 
[epoch 17] step 12/44: loss=0.0859 
[epoch 17] step 14/44: loss=0.0849 
[epoch 17] step 16/44: loss=0.0881 
[epoch 17] step 18/44: loss=0.0859 
[epoch 17] step 20/44: loss=0.0831 
[epoch 17] step 22/44: loss=0.0844 
[epoch 17] step 24/44: loss=0.0820 
[epoch 17] step 26/44: loss=0.0794 
[epoch 17] step 28/44: loss=0.0772 
[epoch 17] step 30/44: loss=0.0737 
[epoch 17] step 32/44: loss=0.0736 
[epoch 17] step 34/44: loss=0.0711 
[epoch 17] step 36/44: loss=0.0694 
[epoch 17] step 38/44: loss=0.0698 
[epoch 17] step 40/44: loss=0.0700 
[epoch 17] step 42/44: loss=0.0703 
[epoch 17] step 44/44: loss=0.0658 
[epoch 17] train_loss(avg per step)=0.1317 lambda[min,max]=[0.499960,1.000000]
[epoch 17] val_loss=1.2912 qwk=('0.4820', '0.4577', '0.4167') averageQWK=0.4522 macroEMD=0.2460 tailR0=('0.2143', '0.1250', '0.0000') tailR0avg=0.1131
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0    8   26    6    1
     0    3   65   52    2
     0    0   34   94   13
     0    0    2   10    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    1    0
     0    4   31    4    0
     0    5   67   30    2
     0    0   49  110    4
     0    0    3    9    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    5   44    3    0
     0   13  105   40    0
     0    0   41   69    0
     0    0    0    3    0
[epoch 18] step 2/44: loss=0.0704 
[epoch 18] step 4/44: loss=0.0627 
[epoch 18] step 6/44: loss=0.0601 
[epoch 18] step 8/44: loss=0.0587 
[epoch 18] step 10/44: loss=0.0616 
[epoch 18] step 12/44: loss=0.0665 
[epoch 18] step 14/44: loss=0.0682 
[epoch 18] step 16/44: loss=0.0737 
[epoch 18] step 18/44: loss=0.0731 
[epoch 18] step 20/44: loss=0.0694 
[epoch 18] step 22/44: loss=0.0712 
[epoch 18] step 24/44: loss=0.0697 
[epoch 18] step 26/44: loss=0.0692 
[epoch 18] step 28/44: loss=0.0665 
[epoch 18] step 30/44: loss=0.0637 
[epoch 18] step 32/44: loss=0.0608 
[epoch 18] step 34/44: loss=0.0596 
[epoch 18] step 36/44: loss=0.0600 
[epoch 18] step 38/44: loss=0.0578 
[epoch 18] step 40/44: loss=0.0571 
[epoch 18] step 42/44: loss=0.0550 
[epoch 18] step 44/44: loss=0.0530 
[epoch 18] train_loss(avg per step)=0.1060 lambda[min,max]=[0.477245,1.000000]
[epoch 18] val_loss=1.2779 qwk=('0.4973', '0.4185', '0.4256') averageQWK=0.4472 macroEMD=0.2452 tailR0=('0.1429', '0.1250', '0.0000') tailR0avg=0.0893
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    1    0
     0    9   29    3    0
     0    7   73   40    2
     0    0   41   90   10
     0    0    5   10    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    5   29    5    0
     0   11   63   28    2
     0    0   61   95    7
     0    0    4    8    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    5   43    4    0
     0   12  100   46    0
     0    0   35   75    0
     0    0    0    3    0
[epoch 19] step 2/44: loss=0.0210 
[epoch 19] step 4/44: loss=0.0161 
[epoch 19] step 6/44: loss=0.0268 
[epoch 19] step 8/44: loss=0.0351 
[epoch 19] step 10/44: loss=0.0376 
[epoch 19] step 12/44: loss=0.0392 
[epoch 19] step 14/44: loss=0.0413 
[epoch 19] step 16/44: loss=0.0347 
[epoch 19] step 18/44: loss=0.0314 
[epoch 19] step 20/44: loss=0.0317 
[epoch 19] step 22/44: loss=0.0291 
[epoch 19] step 24/44: loss=0.0307 
[epoch 19] step 26/44: loss=0.0314 
[epoch 19] step 28/44: loss=0.0308 
[epoch 19] step 30/44: loss=0.0291 
[epoch 19] step 32/44: loss=0.0267 
[epoch 19] step 34/44: loss=0.0270 
[epoch 19] step 36/44: loss=0.0282 
[epoch 19] step 38/44: loss=0.0288 
[epoch 19] step 40/44: loss=0.0290 
[epoch 19] step 42/44: loss=0.0280 
[epoch 19] step 44/44: loss=0.0255 
[epoch 19] train_loss(avg per step)=0.0511 lambda[min,max]=[0.461470,1.000000]
[epoch 19] val_loss=1.2728 qwk=('0.4745', '0.3831', '0.4243') averageQWK=0.4273 macroEMD=0.2486 tailR0=('0.1429', '0.0312', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   27    7    0
     0    4   72   46    0
     0    0   35   97    9
     0    0    3   12    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    2    0
     0    5   23   11    0
     0    6   56   41    1
     0    0   42  119    2
     0    0    3   12    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    6   44    2    0
     0   14  104   40    0
     0    1   42   67    0
     0    0    0    3    0
[epoch 20] step 2/44: loss=-0.0179 
[epoch 20] step 4/44: loss=-0.0068 
[epoch 20] step 6/44: loss=-0.0010 
[epoch 20] step 8/44: loss=0.0012 
[epoch 20] step 10/44: loss=0.0007 
[epoch 20] step 12/44: loss=0.0024 
[epoch 20] step 14/44: loss=0.0064 
[epoch 20] step 16/44: loss=0.0036 
[epoch 20] step 18/44: loss=0.0014 
[epoch 20] step 20/44: loss=0.0012 
[epoch 20] step 22/44: loss=0.0014 
[epoch 20] step 24/44: loss=0.0063 
[epoch 20] step 26/44: loss=0.0028 
[epoch 20] step 28/44: loss=0.0007 
[epoch 20] step 30/44: loss=0.0022 
[epoch 20] step 32/44: loss=0.0017 
[epoch 20] step 34/44: loss=0.0024 
[epoch 20] step 36/44: loss=0.0024 
[epoch 20] step 38/44: loss=0.0024 
[epoch 20] step 40/44: loss=0.0015 
[epoch 20] step 42/44: loss=0.0022 
[epoch 20] step 44/44: loss=-0.0005 
[epoch 20] train_loss(avg per step)=-0.0009 lambda[min,max]=[0.480858,1.000000]
[epoch 20] val_loss=1.3616 qwk=('0.4637', '0.3393', '0.3844') averageQWK=0.3958 macroEMD=0.2534 tailR0=('0.1190', '0.0000', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     2    2   32    5    0
     0    2   70   50    0
     0    0   35  101    5
     0    0    3   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    5   17   17    0
     1    6   39   57    1
     0    0   29  132    2
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    5   43    4    0
     0   17  106   35    0
     0    0   48   62    0
     0    0    1    2    0
[epoch 21] step 2/44: loss=-0.0395 
[epoch 21] step 4/44: loss=-0.0286 
[epoch 21] step 6/44: loss=-0.0282 
[epoch 21] step 8/44: loss=-0.0228 
[epoch 21] step 10/44: loss=-0.0140 
[epoch 21] step 12/44: loss=-0.0133 
[epoch 21] step 14/44: loss=-0.0148 
[epoch 21] step 16/44: loss=-0.0145 
[epoch 21] step 18/44: loss=-0.0148 
[epoch 21] step 20/44: loss=-0.0161 
[epoch 21] step 22/44: loss=-0.0185 
[epoch 21] step 24/44: loss=-0.0207 
[epoch 21] step 26/44: loss=-0.0219 
[epoch 21] step 28/44: loss=-0.0222 
[epoch 21] step 30/44: loss=-0.0215 
[epoch 21] step 32/44: loss=-0.0210 
[epoch 21] step 34/44: loss=-0.0212 
[epoch 21] step 36/44: loss=-0.0196 
[epoch 21] step 38/44: loss=-0.0184 
[epoch 21] step 40/44: loss=-0.0183 
[epoch 21] step 42/44: loss=-0.0187 
[epoch 21] step 44/44: loss=-0.0204 
[epoch 21] train_loss(avg per step)=-0.0407 lambda[min,max]=[0.465023,1.000000]
[epoch 21] val_loss=1.3757 qwk=('0.4879', '0.4515', '0.4264') averageQWK=0.4553 macroEMD=0.2551 tailR0=('0.2857', '0.2188', '0.0000') tailR0avg=0.1682
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    6   31    4    0
     0    2   74   40    6
     0    0   40   78   23
     0    0    3    6   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    2    0
     0    3   27    9    0
     0    3   59   41    1
     0    0   34  115   14
     0    0    3    6    7
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    5   43    4    0
     0   14   98   46    0
     0    0   37   73    0
     0    0    0    3    0
[epoch 22] step 2/44: loss=-0.0454 
[epoch 22] step 4/44: loss=-0.0353 
[epoch 22] step 6/44: loss=-0.0325 
[epoch 22] step 8/44: loss=-0.0353 
[epoch 22] step 10/44: loss=-0.0352 
[epoch 22] step 12/44: loss=-0.0375 
[epoch 22] step 14/44: loss=-0.0388 
[epoch 22] step 16/44: loss=-0.0407 
[epoch 22] step 18/44: loss=-0.0376 
[epoch 22] step 20/44: loss=-0.0366 
[epoch 22] step 22/44: loss=-0.0300 
[epoch 22] step 24/44: loss=-0.0295 
[epoch 22] step 26/44: loss=-0.0297 
[epoch 22] step 28/44: loss=-0.0306 
[epoch 22] step 30/44: loss=-0.0330 
[epoch 22] step 32/44: loss=-0.0324 
[epoch 22] step 34/44: loss=-0.0290 
[epoch 22] step 36/44: loss=-0.0293 
[epoch 22] step 38/44: loss=-0.0297 
[epoch 22] step 40/44: loss=-0.0292 
[epoch 22] step 42/44: loss=-0.0289 
[epoch 22] step 44/44: loss=-0.0232 
[epoch 22] train_loss(avg per step)=-0.0464 lambda[min,max]=[0.389360,1.000000]
[epoch 22] val_loss=1.3712 qwk=('0.4956', '0.3983', '0.4640') averageQWK=0.4526 macroEMD=0.2458 tailR0=('0.1905', '0.0625', '0.0000') tailR0avg=0.0843
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    9   31    1    0
     0    4   78   37    3
     0    0   47   81   13
     0    0    4    9    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     1    5   19   14    0
     1    5   45   52    1
     0    0   27  132    4
     0    0    1   13    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   15   31    6    0
     0   24   87   47    0
     0    2   33   75    0
     0    0    0    3    0
[epoch 23] step 2/44: loss=-0.0342 
[epoch 23] step 4/44: loss=-0.0306 
[epoch 23] step 6/44: loss=-0.0376 
[epoch 23] step 8/44: loss=-0.0408 
[epoch 23] step 10/44: loss=-0.0378 
[epoch 23] step 12/44: loss=-0.0393 
[epoch 23] step 14/44: loss=-0.0395 
[epoch 23] step 16/44: loss=-0.0415 
[epoch 23] step 18/44: loss=-0.0441 
[epoch 23] step 20/44: loss=-0.0438 
[epoch 23] step 22/44: loss=-0.0423 
[epoch 23] step 24/44: loss=-0.0418 
[epoch 23] step 26/44: loss=-0.0419 
[epoch 23] step 28/44: loss=-0.0421 
[epoch 23] step 30/44: loss=-0.0419 
[epoch 23] step 32/44: loss=-0.0433 
[epoch 23] step 34/44: loss=-0.0440 
[epoch 23] step 36/44: loss=-0.0462 
[epoch 23] step 38/44: loss=-0.0456 
[epoch 23] step 40/44: loss=-0.0453 
[epoch 23] step 42/44: loss=-0.0444 
[epoch 23] step 44/44: loss=-0.0454 
[epoch 23] train_loss(avg per step)=-0.0908 lambda[min,max]=[0.369086,1.000000]
[epoch 23] val_loss=1.3997 qwk=('0.4966', '0.3469', '0.4245') averageQWK=0.4227 macroEMD=0.2521 tailR0=('0.1905', '0.0625', '0.0000') tailR0avg=0.0843
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     1    7   32    1    0
     0    5   74   40    3
     0    0   46   83   12
     0    0    3   10    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     1    4   19   15    0
     1    6   46   50    1
     0    1   34  126    2
     0    0    3   11    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    7   41    4    0
     0   21   95   42    0
     0    0   40   70    0
     0    0    0    3    0
[epoch 24] step 2/44: loss=-0.0566 
[epoch 24] step 4/44: loss=-0.0680 
[epoch 24] step 6/44: loss=-0.0706 
[epoch 24] step 8/44: loss=-0.0595 
[epoch 24] step 10/44: loss=-0.0594 
[epoch 24] step 12/44: loss=-0.0596 
[epoch 24] step 14/44: loss=-0.0602 
[epoch 24] step 16/44: loss=-0.0588 
[epoch 24] step 18/44: loss=-0.0563 
[epoch 24] step 20/44: loss=-0.0534 
[epoch 24] step 22/44: loss=-0.0530 
[epoch 24] step 24/44: loss=-0.0540 
[epoch 24] step 26/44: loss=-0.0542 
[epoch 24] step 28/44: loss=-0.0561 
[epoch 24] step 30/44: loss=-0.0553 
[epoch 24] step 32/44: loss=-0.0536 
[epoch 24] step 34/44: loss=-0.0545 
[epoch 24] step 36/44: loss=-0.0546 
[epoch 24] step 38/44: loss=-0.0546 
[epoch 24] step 40/44: loss=-0.0536 
[epoch 24] step 42/44: loss=-0.0531 
[epoch 24] step 44/44: loss=-0.0546 
[epoch 24] train_loss(avg per step)=-0.1093 lambda[min,max]=[0.414573,1.000000]
[epoch 24] val_loss=1.3772 qwk=('0.4898', '0.3623', '0.4333') averageQWK=0.4285 macroEMD=0.2503 tailR0=('0.1452', '0.0000', '0.0000') tailR0avg=0.0484
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    5   31    3    0
     0    5   70   46    1
     0    0   37   98    6
     0    0    3   14    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     1    4   21   13    0
     1    5   49   48    1
     0    0   36  125    2
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0   11   38    3    0
     0   17  107   34    0
     0    0   46   64    0
     0    0    1    2    0
[epoch 25] step 2/44: loss=-0.0452 
[epoch 25] step 4/44: loss=-0.0527 
[epoch 25] step 6/44: loss=-0.0512 
[epoch 25] step 8/44: loss=-0.0522 
[epoch 25] step 10/44: loss=-0.0570 
[epoch 25] step 12/44: loss=-0.0567 
[epoch 25] step 14/44: loss=-0.0540 
[epoch 25] step 16/44: loss=-0.0542 
[epoch 25] step 18/44: loss=-0.0570 
[epoch 25] step 20/44: loss=-0.0595 
[epoch 25] step 22/44: loss=-0.0609 
[epoch 25] step 24/44: loss=-0.0607 
[epoch 25] step 26/44: loss=-0.0611 
[epoch 25] step 28/44: loss=-0.0611 
[epoch 25] step 30/44: loss=-0.0609 
[epoch 25] step 32/44: loss=-0.0605 
[epoch 25] step 34/44: loss=-0.0596 
[epoch 25] step 36/44: loss=-0.0595 
[epoch 25] step 38/44: loss=-0.0601 
[epoch 25] step 40/44: loss=-0.0605 
[epoch 25] step 42/44: loss=-0.0608 
[epoch 25] step 44/44: loss=-0.0618 
[epoch 25] train_loss(avg per step)=-0.1236 lambda[min,max]=[0.397689,1.000000]
[epoch 25] val_loss=1.4170 qwk=('0.4998', '0.3495', '0.4109') averageQWK=0.4201 macroEMD=0.2527 tailR0=('0.2643', '0.0312', '0.0000') tailR0avg=0.0985
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    6   32    1    0
     0    4   79   36    3
     0    0   53   77   11
     0    0    3    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    4    0
     1    5   17   16    0
     1    9   44   49    1
     0    2   31  128    2
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    9   40    3    0
     0   19  109   30    0
     0    0   50   60    0
     0    0    1    2    0
[epoch 26] step 2/44: loss=-0.0755 
[epoch 26] step 4/44: loss=-0.0807 
[epoch 26] step 6/44: loss=-0.0765 
[epoch 26] step 8/44: loss=-0.0728 
[epoch 26] step 10/44: loss=-0.0709 
[epoch 26] step 12/44: loss=-0.0705 
[epoch 26] step 14/44: loss=-0.0686 
[epoch 26] step 16/44: loss=-0.0665 
[epoch 26] step 18/44: loss=-0.0675 
[epoch 26] step 20/44: loss=-0.0652 
[epoch 26] step 22/44: loss=-0.0663 
[epoch 26] step 24/44: loss=-0.0660 
[epoch 26] step 26/44: loss=-0.0659 
[epoch 26] step 28/44: loss=-0.0659 
[epoch 26] step 30/44: loss=-0.0670 
[epoch 26] step 32/44: loss=-0.0660 
[epoch 26] step 34/44: loss=-0.0666 
[epoch 26] step 36/44: loss=-0.0682 
[epoch 26] step 38/44: loss=-0.0674 
[epoch 26] step 40/44: loss=-0.0684 
[epoch 26] step 42/44: loss=-0.0686 
[epoch 26] step 44/44: loss=-0.0691 
[epoch 26] train_loss(avg per step)=-0.1382 lambda[min,max]=[0.465629,1.000000]
[epoch 26] val_loss=1.4215 qwk=('0.4477', '0.3183', '0.4065') averageQWK=0.3908 macroEMD=0.2546 tailR0=('0.1667', '0.0000', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    6   30    5    0
     0    3   71   45    3
     0    0   40   90   11
     0    0    3   11    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    5   14   20    0
     1    4   45   53    1
     0    1   29  131    2
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0   11   37    4    0
     0   18  104   36    0
     0    1   47   62    0
     0    0    1    2    0
[epoch 27] step 2/44: loss=-0.0824 
[epoch 27] step 4/44: loss=-0.0730 
[epoch 27] step 6/44: loss=-0.0779 
[epoch 27] step 8/44: loss=-0.0802 
[epoch 27] step 10/44: loss=-0.0801 
[epoch 27] step 12/44: loss=-0.0792 
[epoch 27] step 14/44: loss=-0.0793 
[epoch 27] step 16/44: loss=-0.0781 
[epoch 27] step 18/44: loss=-0.0755 
[epoch 27] step 20/44: loss=-0.0763 
[epoch 27] step 22/44: loss=-0.0757 
[epoch 27] step 24/44: loss=-0.0752 
[epoch 27] step 26/44: loss=-0.0750 
[epoch 27] step 28/44: loss=-0.0746 
[epoch 27] step 30/44: loss=-0.0736 
[epoch 27] step 32/44: loss=-0.0729 
[epoch 27] step 34/44: loss=-0.0715 
[epoch 27] step 36/44: loss=-0.0709 
[epoch 27] step 38/44: loss=-0.0709 
[epoch 27] step 40/44: loss=-0.0712 
[epoch 27] step 42/44: loss=-0.0719 
[epoch 27] step 44/44: loss=-0.0723 
[epoch 27] train_loss(avg per step)=-0.1446 lambda[min,max]=[0.421609,1.000000]
[epoch 27] val_loss=1.4606 qwk=('0.4991', '0.3886', '0.4125') averageQWK=0.4334 macroEMD=0.2529 tailR0=('0.3357', '0.1250', '0.0000') tailR0avg=0.1536
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     1    5   32    2    1
     0    2   82   32    6
     0    0   46   78   17
     0    0    2    7   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     1    3   23   12    0
     1    3   55   43    2
     0    1   37  115   10
     0    0    2   10    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0   11   34    7    0
     0   19   87   52    0
     0    1   34   75    0
     0    0    1    2    0
[epoch 28] step 2/44: loss=-0.0836 
[epoch 28] step 4/44: loss=-0.0789 
[epoch 28] step 6/44: loss=-0.0790 
[epoch 28] step 8/44: loss=-0.0789 
[epoch 28] step 10/44: loss=-0.0789 
[epoch 28] step 12/44: loss=-0.0801 
[epoch 28] step 14/44: loss=-0.0811 
[epoch 28] step 16/44: loss=-0.0806 
[epoch 28] step 18/44: loss=-0.0807 
[epoch 28] step 20/44: loss=-0.0804 
[epoch 28] step 22/44: loss=-0.0808 
[epoch 28] step 24/44: loss=-0.0790 
[epoch 28] step 26/44: loss=-0.0796 
[epoch 28] step 28/44: loss=-0.0801 
[epoch 28] step 30/44: loss=-0.0794 
[epoch 28] step 32/44: loss=-0.0789 
[epoch 28] step 34/44: loss=-0.0794 
[epoch 28] step 36/44: loss=-0.0796 
[epoch 28] step 38/44: loss=-0.0796 
[epoch 28] step 40/44: loss=-0.0794 
[epoch 28] step 42/44: loss=-0.0795 
[epoch 28] step 44/44: loss=-0.0794 
[epoch 28] train_loss(avg per step)=-0.1587 lambda[min,max]=[0.395757,1.000000]
[epoch 28] val_loss=1.4218 qwk=('0.4377', '0.3761', '0.4303') averageQWK=0.4147 macroEMD=0.2544 tailR0=('0.1190', '0.0938', '0.0000') tailR0avg=0.0709
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    6   31    4    0
     0    2   68   50    2
     0    0   40   93    8
     0    0    3   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    4   25   10    0
     1    0   60   42    1
     0    1   45  110    7
     0    0    2   11    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   12   38    2    0
     0   18  116   24    0
     0    1   56   53    0
     0    0    1    2    0
[epoch 29] step 2/44: loss=-0.0882 
[epoch 29] step 4/44: loss=-0.0835 
[epoch 29] step 6/44: loss=-0.0814 
[epoch 29] step 8/44: loss=-0.0836 
[epoch 29] step 10/44: loss=-0.0820 
[epoch 29] step 12/44: loss=-0.0828 
[epoch 29] step 14/44: loss=-0.0825 
[epoch 29] step 16/44: loss=-0.0810 
[epoch 29] step 18/44: loss=-0.0813 
[epoch 29] step 20/44: loss=-0.0808 
[epoch 29] step 22/44: loss=-0.0807 
[epoch 29] step 24/44: loss=-0.0807 
[epoch 29] step 26/44: loss=-0.0816 
[epoch 29] step 28/44: loss=-0.0817 
[epoch 29] step 30/44: loss=-0.0818 
[epoch 29] step 32/44: loss=-0.0807 
[epoch 29] step 34/44: loss=-0.0805 
[epoch 29] step 36/44: loss=-0.0808 
[epoch 29] step 38/44: loss=-0.0812 
[epoch 29] step 40/44: loss=-0.0815 
[epoch 29] step 42/44: loss=-0.0808 
[epoch 29] step 44/44: loss=-0.0816 
[epoch 29] train_loss(avg per step)=-0.1632 lambda[min,max]=[0.353806,1.000000]
[epoch 29] val_loss=1.4542 qwk=('0.4656', '0.3779', '0.3876') averageQWK=0.4104 macroEMD=0.2520 tailR0=('0.2643', '0.0312', '0.0000') tailR0avg=0.0985
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     0    5   31    4    1
     0    2   74   42    4
     0    0   39   92   10
     0    0    3    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    5   20   14    0
     0    6   48   49    1
     0    0   33  126    4
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    5   44    3    0
     0   17  106   35    0
     0    0   49   61    0
     0    0    1    2    0
[epoch 30] step 2/44: loss=-0.0980 
[epoch 30] step 4/44: loss=-0.0966 
[epoch 30] step 6/44: loss=-0.0941 
[epoch 30] step 8/44: loss=-0.0933 
[epoch 30] step 10/44: loss=-0.0906 
[epoch 30] step 12/44: loss=-0.0886 
[epoch 30] step 14/44: loss=-0.0883 
[epoch 30] step 16/44: loss=-0.0867 
[epoch 30] step 18/44: loss=-0.0864 
[epoch 30] step 20/44: loss=-0.0863 
[epoch 30] step 22/44: loss=-0.0861 
[epoch 30] step 24/44: loss=-0.0865 
[epoch 30] step 26/44: loss=-0.0855 
[epoch 30] step 28/44: loss=-0.0860 
[epoch 30] step 30/44: loss=-0.0857 
[epoch 30] step 32/44: loss=-0.0856 
[epoch 30] step 34/44: loss=-0.0857 
[epoch 30] step 36/44: loss=-0.0863 
[epoch 30] step 38/44: loss=-0.0860 
[epoch 30] step 40/44: loss=-0.0867 
[epoch 30] step 42/44: loss=-0.0870 
[epoch 30] step 44/44: loss=-0.0877 
[epoch 30] train_loss(avg per step)=-0.1754 lambda[min,max]=[0.431383,1.000000]
[epoch 30] val_loss=1.4617 qwk=('0.4278', '0.3642', '0.4419') averageQWK=0.4113 macroEMD=0.2526 tailR0=('0.1190', '0.0000', '0.0000') tailR0avg=0.0397
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    8   24    8    1
     0    3   60   57    2
     0    0   29  104    8
     0    0    2   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    4   19   16    0
     1    4   50   48    1
     0    0   31  130    2
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   12   35    5    0
     0   22   96   40    0
     0    1   43   66    0
     0    0    0    3    0
[epoch 31] step 2/44: loss=-0.0926 
[epoch 31] step 4/44: loss=-0.0876 
[epoch 31] step 6/44: loss=-0.0898 
[epoch 31] step 8/44: loss=-0.0910 
[epoch 31] step 10/44: loss=-0.0884 
[epoch 31] step 12/44: loss=-0.0871 
[epoch 31] step 14/44: loss=-0.0887 
[epoch 31] step 16/44: loss=-0.0895 
[epoch 31] step 18/44: loss=-0.0893 
[epoch 31] step 20/44: loss=-0.0899 
[epoch 31] step 22/44: loss=-0.0897 
[epoch 31] step 24/44: loss=-0.0887 
[epoch 31] step 26/44: loss=-0.0890 
[epoch 31] step 28/44: loss=-0.0892 
[epoch 31] step 30/44: loss=-0.0896 
[epoch 31] step 32/44: loss=-0.0891 
[epoch 31] step 34/44: loss=-0.0887 
[epoch 31] step 36/44: loss=-0.0892 
[epoch 31] step 38/44: loss=-0.0895 
[epoch 31] step 40/44: loss=-0.0900 
[epoch 31] step 42/44: loss=-0.0905 
[epoch 31] step 44/44: loss=-0.0909 
[epoch 31] train_loss(avg per step)=-0.1819 lambda[min,max]=[0.369302,1.000000]
[epoch 31] val_loss=1.4533 qwk=('0.5104', '0.3838', '0.4317') averageQWK=0.4420 macroEMD=0.2475 tailR0=('0.2381', '0.0625', '0.0000') tailR0avg=0.1002
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   33    1    0
     0    2   77   39    4
     0    0   41   87   13
     0    0    3    8   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    4   22   13    0
     1    3   55   44    1
     0    0   37  121    5
     0    0    2   12    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0   11   36    5    0
     0   17  103   38    0
     0    1   41   68    0
     0    0    0    3    0
[epoch 32] step 2/44: loss=-0.0938 
[epoch 32] step 4/44: loss=-0.0942 
[epoch 32] step 6/44: loss=-0.0937 
[epoch 32] step 8/44: loss=-0.0952 
[epoch 32] step 10/44: loss=-0.0940 
[epoch 32] step 12/44: loss=-0.0952 
[epoch 32] step 14/44: loss=-0.0951 
[epoch 32] step 16/44: loss=-0.0947 
[epoch 32] step 18/44: loss=-0.0942 
[epoch 32] step 20/44: loss=-0.0935 
[epoch 32] step 22/44: loss=-0.0928 
[epoch 32] step 24/44: loss=-0.0917 
[epoch 32] step 26/44: loss=-0.0916 
[epoch 32] step 28/44: loss=-0.0916 
[epoch 32] step 30/44: loss=-0.0923 
[epoch 32] step 32/44: loss=-0.0927 
[epoch 32] step 34/44: loss=-0.0927 
[epoch 32] step 36/44: loss=-0.0925 
[epoch 32] step 38/44: loss=-0.0921 
[epoch 32] step 40/44: loss=-0.0926 
[epoch 32] step 42/44: loss=-0.0924 
[epoch 32] step 44/44: loss=-0.0923 
[epoch 32] train_loss(avg per step)=-0.1846 lambda[min,max]=[0.363679,1.000000]
[epoch 32] val_loss=1.4631 qwk=('0.5012', '0.3687', '0.4072') averageQWK=0.4257 macroEMD=0.2484 tailR0=('0.2167', '0.0312', '0.0000') tailR0avg=0.0826
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     1    6   33    1    0
     0    2   76   40    4
     0    0   41   90   10
     0    0    3   11    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     1    4   19   15    0
     1    8   45   49    1
     0    0   34  127    2
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    8   40    4    0
     0   18  106   34    0
     0    1   44   65    0
     0    0    1    2    0
[epoch 33] step 2/44: loss=-0.0981 
[epoch 33] step 4/44: loss=-0.0959 
[epoch 33] step 6/44: loss=-0.0946 
[epoch 33] step 8/44: loss=-0.0948 
[epoch 33] step 10/44: loss=-0.0948 
[epoch 33] step 12/44: loss=-0.0931 
[epoch 33] step 14/44: loss=-0.0919 
[epoch 33] step 16/44: loss=-0.0935 
[epoch 33] step 18/44: loss=-0.0943 
[epoch 33] step 20/44: loss=-0.0943 
[epoch 33] step 22/44: loss=-0.0942 
[epoch 33] step 24/44: loss=-0.0949 
[epoch 33] step 26/44: loss=-0.0956 
[epoch 33] step 28/44: loss=-0.0962 
[epoch 33] step 30/44: loss=-0.0962 
[epoch 33] step 32/44: loss=-0.0956 
[epoch 33] step 34/44: loss=-0.0955 
[epoch 33] step 36/44: loss=-0.0953 
[epoch 33] step 38/44: loss=-0.0958 
[epoch 33] step 40/44: loss=-0.0954 
[epoch 33] step 42/44: loss=-0.0955 
[epoch 33] step 44/44: loss=-0.0960 
[epoch 33] train_loss(avg per step)=-0.1921 lambda[min,max]=[0.349582,1.000000]
[epoch 33] val_loss=1.4770 qwk=('0.4757', '0.3762', '0.4404') averageQWK=0.4308 macroEMD=0.2482 tailR0=('0.1429', '0.0312', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     1    7   29    4    0
     0    3   72   44    3
     0    0   39   94    8
     0    0    3   12    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     1    5   17   16    0
     1    9   43   50    1
     0    0   30  131    2
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   13   35    4    0
     0   20  102   36    0
     0    1   46   63    0
     0    0    1    2    0
[epoch 34] step 2/44: loss=-0.1004 
[epoch 34] step 4/44: loss=-0.0992 
[epoch 34] step 6/44: loss=-0.0946 
[epoch 34] step 8/44: loss=-0.0933 
[epoch 34] step 10/44: loss=-0.0941 
[epoch 34] step 12/44: loss=-0.0938 
[epoch 34] step 14/44: loss=-0.0924 
[epoch 34] step 16/44: loss=-0.0936 
[epoch 34] step 18/44: loss=-0.0947 
[epoch 34] step 20/44: loss=-0.0955 
[epoch 34] step 22/44: loss=-0.0960 
[epoch 34] step 24/44: loss=-0.0958 
[epoch 34] step 26/44: loss=-0.0959 
[epoch 34] step 28/44: loss=-0.0965 
[epoch 34] step 30/44: loss=-0.0969 
[epoch 34] step 32/44: loss=-0.0971 
[epoch 34] step 34/44: loss=-0.0974 
[epoch 34] step 36/44: loss=-0.0971 
[epoch 34] step 38/44: loss=-0.0966 
[epoch 34] step 40/44: loss=-0.0967 
[epoch 34] step 42/44: loss=-0.0965 
[epoch 34] step 44/44: loss=-0.0968 
[epoch 34] train_loss(avg per step)=-0.1936 lambda[min,max]=[0.388855,1.000000]
[epoch 34] val_loss=1.4880 qwk=('0.4646', '0.3793', '0.4223') averageQWK=0.4221 macroEMD=0.2518 tailR0=('0.1905', '0.0625', '0.0000') tailR0avg=0.0843
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     1    6   30    3    1
     0    2   73   43    4
     0    0   41   89   11
     0    0    3   10    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     1    4   19   15    0
     1    5   48   49    1
     0    0   33  125    5
     0    0    2   12    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0   11   37    4    0
     0   18  107   33    0
     0    1   47   62    0
     0    0    1    2    0
[epoch 35] step 2/44: loss=-0.0991 
[epoch 35] step 4/44: loss=-0.0925 
[epoch 35] step 6/44: loss=-0.0916 
[epoch 35] step 8/44: loss=-0.0936 
[epoch 35] step 10/44: loss=-0.0943 
[epoch 35] step 12/44: loss=-0.0931 
[epoch 35] step 14/44: loss=-0.0943 
[epoch 35] step 16/44: loss=-0.0943 
[epoch 35] step 18/44: loss=-0.0949 
[epoch 35] step 20/44: loss=-0.0957 
[epoch 35] step 22/44: loss=-0.0964 
[epoch 35] step 24/44: loss=-0.0965 
[epoch 35] step 26/44: loss=-0.0969 
[epoch 35] step 28/44: loss=-0.0970 
[epoch 35] step 30/44: loss=-0.0972 
[epoch 35] step 32/44: loss=-0.0972 
[epoch 35] step 34/44: loss=-0.0973 
[epoch 35] step 36/44: loss=-0.0970 
[epoch 35] step 38/44: loss=-0.0972 
[epoch 35] step 40/44: loss=-0.0970 
[epoch 35] step 42/44: loss=-0.0965 
[epoch 35] step 44/44: loss=-0.0954 
[epoch 35] train_loss(avg per step)=-0.1908 lambda[min,max]=[0.431908,1.000000]
[epoch 35] val_loss=1.4950 qwk=('0.4717', '0.3695', '0.4167') averageQWK=0.4193 macroEMD=0.2512 tailR0=('0.1905', '0.0312', '0.0000') tailR0avg=0.0739
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     1    7   29    3    1
     0    2   73   43    4
     0    0   40   90   11
     0    0    3   10    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     1    4   19   15    0
     1    5   47   50    1
     0    0   33  127    3
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    9   39    4    0
     0   18  102   38    0
     0    1   44   65    0
     0    0    1    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-0/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-1-reassignment-0/fold1/metrics.json
Done.
