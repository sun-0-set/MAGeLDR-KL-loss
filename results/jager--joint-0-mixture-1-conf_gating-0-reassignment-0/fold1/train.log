[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.7449 
[epoch 1] step 4/44: loss=0.7177 
[epoch 1] step 6/44: loss=0.7085 
[epoch 1] step 8/44: loss=0.7058 
[epoch 1] step 10/44: loss=0.7113 
[epoch 1] step 12/44: loss=0.7055 
[epoch 1] step 14/44: loss=0.7070 
[epoch 1] step 16/44: loss=0.7089 
[epoch 1] step 18/44: loss=0.7082 
[epoch 1] step 20/44: loss=0.7072 
[epoch 1] step 22/44: loss=0.7103 
[epoch 1] step 24/44: loss=0.7094 
[epoch 1] step 26/44: loss=0.7080 
[epoch 1] step 28/44: loss=0.7079 
[epoch 1] step 30/44: loss=0.7068 
[epoch 1] step 32/44: loss=0.7059 
[epoch 1] step 34/44: loss=0.7055 
[epoch 1] step 36/44: loss=0.7042 
[epoch 1] step 38/44: loss=0.7018 
[epoch 1] step 40/44: loss=0.7013 
[epoch 1] step 42/44: loss=0.7002 
[epoch 1] step 44/44: loss=0.7005 
[epoch 1] train_loss(avg per step)=1.4010 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.3134 qwk=('0.0361', '0.0955', '0.0957') averageQWK=0.0758 macroEMD=0.3668 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    9    0
     0    4    0   37    0
     0   15    0  107    0
     0   12    0  129    0
     0    1    0   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    0    0
     3    0   35    1    0
     5    0   95    4    0
     6    0  142   15    0
     0    0   11    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   19   33    0    0
     0   28  130    0    0
     0   23   87    0    0
     0    1    2    0    0
[epoch 2] step 2/44: loss=0.6736 
[epoch 2] step 4/44: loss=0.6685 
[epoch 2] step 6/44: loss=0.6723 
[epoch 2] step 8/44: loss=0.6666 
[epoch 2] step 10/44: loss=0.6584 
[epoch 2] step 12/44: loss=0.6591 
[epoch 2] step 14/44: loss=0.6596 
[epoch 2] step 16/44: loss=0.6563 
[epoch 2] step 18/44: loss=0.6566 
[epoch 2] step 20/44: loss=0.6542 
[epoch 2] step 22/44: loss=0.6546 
[epoch 2] step 24/44: loss=0.6559 
[epoch 2] step 26/44: loss=0.6542 
[epoch 2] step 28/44: loss=0.6518 
[epoch 2] step 30/44: loss=0.6504 
[epoch 2] step 32/44: loss=0.6466 
[epoch 2] step 34/44: loss=0.6428 
[epoch 2] step 36/44: loss=0.6372 
[epoch 2] step 38/44: loss=0.6346 
[epoch 2] step 40/44: loss=0.6320 
[epoch 2] step 42/44: loss=0.6310 
[epoch 2] step 44/44: loss=0.6283 
[epoch 2] train_loss(avg per step)=1.2565 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.1390 qwk=('0.4341', '0.4380', '0.0605') averageQWK=0.3109 macroEMD=0.3192 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    1    0
     0    0   34    7    0
     0    0   65   57    0
     0    0   20  121    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    1    0
     0    0   32    7    0
     0    0   68   36    0
     0    0   28  135    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    0   52    0    0
     0    0  157    1    0
     0    0  102    8    0
     0    0    3    0    0
[epoch 3] step 2/44: loss=0.5716 
[epoch 3] step 4/44: loss=0.5777 
[epoch 3] step 6/44: loss=0.5745 
[epoch 3] step 8/44: loss=0.5676 
[epoch 3] step 10/44: loss=0.5643 
[epoch 3] step 12/44: loss=0.5605 
[epoch 3] step 14/44: loss=0.5593 
[epoch 3] step 16/44: loss=0.5535 
[epoch 3] step 18/44: loss=0.5543 
[epoch 3] step 20/44: loss=0.5500 
[epoch 3] step 22/44: loss=0.5462 
[epoch 3] step 24/44: loss=0.5442 
[epoch 3] step 26/44: loss=0.5433 
[epoch 3] step 28/44: loss=0.5403 
[epoch 3] step 30/44: loss=0.5436 
[epoch 3] step 32/44: loss=0.5422 
[epoch 3] step 34/44: loss=0.5370 
[epoch 3] step 36/44: loss=0.5352 
[epoch 3] step 38/44: loss=0.5319 
[epoch 3] step 40/44: loss=0.5334 
[epoch 3] step 42/44: loss=0.5325 
[epoch 3] step 44/44: loss=0.5271 
[epoch 3] train_loss(avg per step)=1.0542 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=1.0788 qwk=('0.4553', '0.4095', '0.4121') averageQWK=0.4256 macroEMD=0.2759 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    0   37    4    0
     0    0   62   60    0
     0    0   20  121    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   11    2    0
     0    0   30    9    0
     0    0   52   52    0
     0    0   21  142    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   40   10    0
     0    3   85   70    0
     0    0   14   96    0
     0    0    0    3    0
[epoch 4] step 2/44: loss=0.4936 
[epoch 4] step 4/44: loss=0.4865 
[epoch 4] step 6/44: loss=0.4947 
[epoch 4] step 8/44: loss=0.5074 
[epoch 4] step 10/44: loss=0.5009 
[epoch 4] step 12/44: loss=0.4955 
[epoch 4] step 14/44: loss=0.4947 
[epoch 4] step 16/44: loss=0.4874 
[epoch 4] step 18/44: loss=0.4865 
[epoch 4] step 20/44: loss=0.4841 
[epoch 4] step 22/44: loss=0.4853 
[epoch 4] step 24/44: loss=0.4877 
[epoch 4] step 26/44: loss=0.4868 
[epoch 4] step 28/44: loss=0.4861 
[epoch 4] step 30/44: loss=0.4872 
[epoch 4] step 32/44: loss=0.4869 
[epoch 4] step 34/44: loss=0.4865 
[epoch 4] step 36/44: loss=0.4875 
[epoch 4] step 38/44: loss=0.4926 
[epoch 4] step 40/44: loss=0.4969 
[epoch 4] step 42/44: loss=0.4947 
[epoch 4] step 44/44: loss=0.5019 
[epoch 4] train_loss(avg per step)=1.0038 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=1.1341 qwk=('0.4086', '0.3712', '0.3626') averageQWK=0.3808 macroEMD=0.2645 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    0    0
     0   11   30    0    0
     0    8  104   10    0
     0    0   83   58    0
     0    0   11   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   12    0    0
     0    3   35    1    0
     0    3   88   13    0
     0    0   87   76    0
     0    0    5   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0    5   47    0    0
     0   10  141    7    0
     0    2   73   35    0
     0    0    1    2    0
[epoch 5] step 2/44: loss=0.4503 
[epoch 5] step 4/44: loss=0.4599 
[epoch 5] step 6/44: loss=0.4665 
[epoch 5] step 8/44: loss=0.4859 
[epoch 5] step 10/44: loss=0.4829 
[epoch 5] step 12/44: loss=0.4748 
[epoch 5] step 14/44: loss=0.4848 
[epoch 5] step 16/44: loss=0.4898 
[epoch 5] step 18/44: loss=0.4859 
[epoch 5] step 20/44: loss=0.4805 
[epoch 5] step 22/44: loss=0.4812 
[epoch 5] step 24/44: loss=0.4797 
[epoch 5] step 26/44: loss=0.4783 
[epoch 5] step 28/44: loss=0.4783 
[epoch 5] step 30/44: loss=0.4815 
[epoch 5] step 32/44: loss=0.4807 
[epoch 5] step 34/44: loss=0.4743 
[epoch 5] step 36/44: loss=0.4756 
[epoch 5] step 38/44: loss=0.4756 
[epoch 5] step 40/44: loss=0.4759 
[epoch 5] step 42/44: loss=0.4735 
[epoch 5] step 44/44: loss=0.4729 
[epoch 5] train_loss(avg per step)=0.9458 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=1.1195 qwk=('0.3829', '0.3306', '0.4081') averageQWK=0.3739 macroEMD=0.2747 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    3   25   13    0
     0    0   44   78    0
     0    0   11  130    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    4    0
     0    0   24   15    0
     0    0   44   60    0
     0    0   17  146    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   44    7    0
     0    3   98   57    0
     0    0   24   86    0
     0    0    0    3    0
[epoch 6] step 2/44: loss=0.4550 
[epoch 6] step 4/44: loss=0.4285 
[epoch 6] step 6/44: loss=0.4344 
[epoch 6] step 8/44: loss=0.4314 
[epoch 6] step 10/44: loss=0.4339 
[epoch 6] step 12/44: loss=0.4308 
[epoch 6] step 14/44: loss=0.4342 
[epoch 6] step 16/44: loss=0.4293 
[epoch 6] step 18/44: loss=0.4321 
[epoch 6] step 20/44: loss=0.4316 
[epoch 6] step 22/44: loss=0.4351 
[epoch 6] step 24/44: loss=0.4307 
[epoch 6] step 26/44: loss=0.4234 
[epoch 6] step 28/44: loss=0.4233 
[epoch 6] step 30/44: loss=0.4194 
[epoch 6] step 32/44: loss=0.4192 
[epoch 6] step 34/44: loss=0.4196 
[epoch 6] step 36/44: loss=0.4218 
[epoch 6] step 38/44: loss=0.4233 
[epoch 6] step 40/44: loss=0.4247 
[epoch 6] step 42/44: loss=0.4236 
[epoch 6] step 44/44: loss=0.4191 
[epoch 6] train_loss(avg per step)=0.8382 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=1.1213 qwk=('0.5316', '0.4208', '0.4677') averageQWK=0.4734 macroEMD=0.2547 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    1    0
     0   16   17    8    0
     0    9   49   64    0
     0    0   15  126    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    5   26    8    0
     0    8   42   54    0
     0    1   24  138    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0   10   36    6    0
     0   17   84   57    0
     0    1   21   88    0
     0    0    0    3    0
[epoch 7] step 2/44: loss=0.3818 
[epoch 7] step 4/44: loss=0.3763 
[epoch 7] step 6/44: loss=0.3615 
[epoch 7] step 8/44: loss=0.3685 
[epoch 7] step 10/44: loss=0.3764 
[epoch 7] step 12/44: loss=0.3842 
[epoch 7] step 14/44: loss=0.3898 
[epoch 7] step 16/44: loss=0.3862 
[epoch 7] step 18/44: loss=0.3844 
[epoch 7] step 20/44: loss=0.3914 
[epoch 7] step 22/44: loss=0.3852 
[epoch 7] step 24/44: loss=0.3861 
[epoch 7] step 26/44: loss=0.3896 
[epoch 7] step 28/44: loss=0.3872 
[epoch 7] step 30/44: loss=0.3873 
[epoch 7] step 32/44: loss=0.3834 
[epoch 7] step 34/44: loss=0.3853 
[epoch 7] step 36/44: loss=0.3846 
[epoch 7] step 38/44: loss=0.3824 
[epoch 7] step 40/44: loss=0.3815 
[epoch 7] step 42/44: loss=0.3799 
[epoch 7] step 44/44: loss=0.3883 
[epoch 7] train_loss(avg per step)=0.7766 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.1579 qwk=('0.5065', '0.4609', '0.4388') averageQWK=0.4687 macroEMD=0.2516 tailR0=('0.1905', '0.0000', '0.0000') tailR0avg=0.0635
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     0   10   28    3    0
     0    8   68   37    9
     0    1   34   98    8
     0    0    3   10    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    3    0
     0    8   22    9    0
     0   13   46   45    0
     0    6   23  134    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   14   31    7    0
     0   24   60   74    0
     0    5   18   87    0
     0    0    0    3    0
[epoch 8] step 2/44: loss=0.3248 
[epoch 8] step 4/44: loss=0.3115 
[epoch 8] step 6/44: loss=0.3246 
[epoch 8] step 8/44: loss=0.3138 
[epoch 8] step 10/44: loss=0.3199 
[epoch 8] step 12/44: loss=0.3255 
[epoch 8] step 14/44: loss=0.3290 
[epoch 8] step 16/44: loss=0.3323 
[epoch 8] step 18/44: loss=0.3321 
[epoch 8] step 20/44: loss=0.3291 
[epoch 8] step 22/44: loss=0.3290 
[epoch 8] step 24/44: loss=0.3312 
[epoch 8] step 26/44: loss=0.3312 
[epoch 8] step 28/44: loss=0.3293 
[epoch 8] step 30/44: loss=0.3286 
[epoch 8] step 32/44: loss=0.3298 
[epoch 8] step 34/44: loss=0.3306 
[epoch 8] step 36/44: loss=0.3305 
[epoch 8] step 38/44: loss=0.3298 
[epoch 8] step 40/44: loss=0.3321 
[epoch 8] step 42/44: loss=0.3346 
[epoch 8] step 44/44: loss=0.3381 
[epoch 8] train_loss(avg per step)=0.6761 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.1923 qwk=('0.4420', '0.3625', '0.4109') averageQWK=0.4051 macroEMD=0.2570 tailR0=('0.0238', '0.0000', '0.0000') tailR0avg=0.0079
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    7   24   10    0
     0    2   56   64    0
     0    0   18  123    0
     0    0    0   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    4    0
     0    4   22   13    0
     0    7   39   58    0
     0    0   25  138    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    1    0
     0    3   40    9    0
     0   10   77   71    0
     0    1   15   94    0
     0    0    0    3    0
[epoch 9] step 2/44: loss=0.3261 
[epoch 9] step 4/44: loss=0.2900 
[epoch 9] step 6/44: loss=0.2751 
[epoch 9] step 8/44: loss=0.3011 
[epoch 9] step 10/44: loss=0.2958 
[epoch 9] step 12/44: loss=0.2940 
[epoch 9] step 14/44: loss=0.2987 
[epoch 9] step 16/44: loss=0.3040 
[epoch 9] step 18/44: loss=0.3077 
[epoch 9] step 20/44: loss=0.3039 
[epoch 9] step 22/44: loss=0.3017 
[epoch 9] step 24/44: loss=0.3003 
[epoch 9] step 26/44: loss=0.2970 
[epoch 9] step 28/44: loss=0.2980 
[epoch 9] step 30/44: loss=0.2953 
[epoch 9] step 32/44: loss=0.2955 
[epoch 9] step 34/44: loss=0.2907 
[epoch 9] step 36/44: loss=0.2893 
[epoch 9] step 38/44: loss=0.2895 
[epoch 9] step 40/44: loss=0.2895 
[epoch 9] step 42/44: loss=0.2919 
[epoch 9] step 44/44: loss=0.2927 
[epoch 9] train_loss(avg per step)=0.5853 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.2279 qwk=('0.4593', '0.3326', '0.4281') averageQWK=0.4066 macroEMD=0.2598 tailR0=('0.1905', '0.0000', '0.0000') tailR0avg=0.0635
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    3    0
     0    4   28    9    0
     0    1   58   59    4
     0    0   15  119    7
     0    0    0   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    5    0
     0    3   20   16    0
     0    3   39   62    0
     0    0   18  145    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0   11   31   10    0
     0   19   62   77    0
     0    4   12   94    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=0.2736 
[epoch 10] step 4/44: loss=0.2825 
[epoch 10] step 6/44: loss=0.2610 
[epoch 10] step 8/44: loss=0.2780 
[epoch 10] step 10/44: loss=0.2725 
[epoch 10] step 12/44: loss=0.2609 
[epoch 10] step 14/44: loss=0.2617 
[epoch 10] step 16/44: loss=0.2678 
[epoch 10] step 18/44: loss=0.2686 
[epoch 10] step 20/44: loss=0.2658 
[epoch 10] step 22/44: loss=0.2611 
[epoch 10] step 24/44: loss=0.2552 
[epoch 10] step 26/44: loss=0.2530 
[epoch 10] step 28/44: loss=0.2516 
[epoch 10] step 30/44: loss=0.2515 
[epoch 10] step 32/44: loss=0.2515 
[epoch 10] step 34/44: loss=0.2510 
[epoch 10] step 36/44: loss=0.2515 
[epoch 10] step 38/44: loss=0.2504 
[epoch 10] step 40/44: loss=0.2488 
[epoch 10] step 42/44: loss=0.2497 
[epoch 10] step 44/44: loss=0.2510 
[epoch 10] train_loss(avg per step)=0.5020 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.1745 qwk=('0.5414', '0.4506', '0.4896') averageQWK=0.4939 macroEMD=0.2399 tailR0=('0.0476', '0.0000', '0.0000') tailR0avg=0.0159
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    2    0
     0   15   22    4    0
     0   15   58   49    0
     0    1   27  111    2
     0    0    0   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    4    0
     0    9   22    8    0
     0   20   39   45    0
     0    4   26  133    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   16   31    5    0
     0   20   81   57    0
     0    3   23   84    0
     0    0    0    3    0
[epoch 11] step 2/44: loss=0.3133 
[epoch 11] step 4/44: loss=0.2547 
[epoch 11] step 6/44: loss=0.2352 
[epoch 11] step 8/44: loss=0.2423 
[epoch 11] step 10/44: loss=0.2369 
[epoch 11] step 12/44: loss=0.2317 
[epoch 11] step 14/44: loss=0.2297 
[epoch 11] step 16/44: loss=0.2312 
[epoch 11] step 18/44: loss=0.2349 
[epoch 11] step 20/44: loss=0.2300 
[epoch 11] step 22/44: loss=0.2283 
[epoch 11] step 24/44: loss=0.2310 
[epoch 11] step 26/44: loss=0.2299 
[epoch 11] step 28/44: loss=0.2283 
[epoch 11] step 30/44: loss=0.2277 
[epoch 11] step 32/44: loss=0.2252 
[epoch 11] step 34/44: loss=0.2248 
[epoch 11] step 36/44: loss=0.2229 
[epoch 11] step 38/44: loss=0.2225 
[epoch 11] step 40/44: loss=0.2228 
[epoch 11] step 42/44: loss=0.2216 
[epoch 11] step 44/44: loss=0.2171 
[epoch 11] train_loss(avg per step)=0.4342 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=1.2027 qwk=('0.4110', '0.3490', '0.4226') averageQWK=0.3942 macroEMD=0.2596 tailR0=('0.0952', '0.0000', '0.0000') tailR0avg=0.0317
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    3    0
     0    5   24   12    0
     0    0   52   70    0
     0    0   18  121    2
     0    0    0   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    5    0
     0    2   25   12    0
     0    1   51   52    0
     0    0   25  138    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    1    0
     0    4   45    3    0
     0   12   95   51    0
     0    3   26   81    0
     0    0    0    3    0
[epoch 12] step 2/44: loss=0.1785 
[epoch 12] step 4/44: loss=0.2119 
[epoch 12] step 6/44: loss=0.2227 
[epoch 12] step 8/44: loss=0.2395 
[epoch 12] step 10/44: loss=0.2348 
[epoch 12] step 12/44: loss=0.2150 
[epoch 12] step 14/44: loss=0.2133 
[epoch 12] step 16/44: loss=0.2158 
[epoch 12] step 18/44: loss=0.2154 
[epoch 12] step 20/44: loss=0.2127 
[epoch 12] step 22/44: loss=0.2122 
[epoch 12] step 24/44: loss=0.2095 
[epoch 12] step 26/44: loss=0.2079 
[epoch 12] step 28/44: loss=0.2119 
[epoch 12] step 30/44: loss=0.2132 
[epoch 12] step 32/44: loss=0.2101 
[epoch 12] step 34/44: loss=0.2111 
[epoch 12] step 36/44: loss=0.2090 
[epoch 12] step 38/44: loss=0.2092 
[epoch 12] step 40/44: loss=0.2081 
[epoch 12] step 42/44: loss=0.2059 
[epoch 12] step 44/44: loss=0.2007 
[epoch 12] train_loss(avg per step)=0.4015 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=1.1496 qwk=('0.4576', '0.3764', '0.4939') averageQWK=0.4426 macroEMD=0.2489 tailR0=('0.1905', '0.0000', '0.0000') tailR0avg=0.0635
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    5   28    7    1
     0    0   73   44    5
     0    0   29  102   10
     0    0    2   11    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    4    0
     0    3   25   11    0
     0    2   57   45    0
     0    0   30  133    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   22   28    2    0
     0   26   98   34    0
     0    4   43   63    0
     0    0    0    3    0
[epoch 13] step 2/44: loss=0.1920 
[epoch 13] step 4/44: loss=0.1908 
[epoch 13] step 6/44: loss=0.1843 
[epoch 13] step 8/44: loss=0.1949 
[epoch 13] step 10/44: loss=0.1878 
[epoch 13] step 12/44: loss=0.1782 
[epoch 13] step 14/44: loss=0.1789 
[epoch 13] step 16/44: loss=0.1836 
[epoch 13] step 18/44: loss=0.1757 
[epoch 13] step 20/44: loss=0.1722 
[epoch 13] step 22/44: loss=0.1698 
[epoch 13] step 24/44: loss=0.1685 
[epoch 13] step 26/44: loss=0.1747 
[epoch 13] step 28/44: loss=0.1730 
[epoch 13] step 30/44: loss=0.1726 
[epoch 13] step 32/44: loss=0.1747 
[epoch 13] step 34/44: loss=0.1748 
[epoch 13] step 36/44: loss=0.1755 
[epoch 13] step 38/44: loss=0.1743 
[epoch 13] step 40/44: loss=0.1731 
[epoch 13] step 42/44: loss=0.1726 
[epoch 13] step 44/44: loss=0.1696 
[epoch 13] train_loss(avg per step)=0.3392 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=1.2857 qwk=('0.4410', '0.3329', '0.3702') averageQWK=0.3814 macroEMD=0.2614 tailR0=('0.1667', '0.0000', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    3    0
     0    5   26   10    0
     0    2   52   66    2
     0    0   18  117    6
     0    0    0   14    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    5    0
     0    3   20   16    0
     0    4   42   58    0
     0    0   21  142    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    2    0
     0    2   40   10    0
     0   10   76   72    0
     0    1   14   95    0
     0    0    0    3    0
[epoch 14] step 2/44: loss=0.1634 
[epoch 14] step 4/44: loss=0.1677 
[epoch 14] step 6/44: loss=0.1644 
[epoch 14] step 8/44: loss=0.1592 
[epoch 14] step 10/44: loss=0.1699 
[epoch 14] step 12/44: loss=0.1752 
[epoch 14] step 14/44: loss=0.1726 
[epoch 14] step 16/44: loss=0.1733 
[epoch 14] step 18/44: loss=0.1701 
[epoch 14] step 20/44: loss=0.1664 
[epoch 14] step 22/44: loss=0.1625 
[epoch 14] step 24/44: loss=0.1670 
[epoch 14] step 26/44: loss=0.1670 
[epoch 14] step 28/44: loss=0.1677 
[epoch 14] step 30/44: loss=0.1645 
[epoch 14] step 32/44: loss=0.1643 
[epoch 14] step 34/44: loss=0.1635 
[epoch 14] step 36/44: loss=0.1624 
[epoch 14] step 38/44: loss=0.1603 
[epoch 14] step 40/44: loss=0.1591 
[epoch 14] step 42/44: loss=0.1567 
[epoch 14] step 44/44: loss=0.1544 
[epoch 14] train_loss(avg per step)=0.3089 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=1.2227 qwk=('0.5118', '0.4184', '0.4614') averageQWK=0.4639 macroEMD=0.2424 tailR0=('0.1905', '0.0000', '0.0000') tailR0avg=0.0635
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0   10   23    8    0
     0    9   59   53    1
     0    0   25  110    6
     0    0    2   11    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    2    0
     0    6   24    9    0
     0   12   48   44    0
     0    0   37  126    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   11   36    5    0
     0   21   80   57    0
     0    4   22   84    0
     0    0    0    3    0
[epoch 15] step 2/44: loss=0.1427 
[epoch 15] step 4/44: loss=0.1250 
[epoch 15] step 6/44: loss=0.1252 
[epoch 15] step 8/44: loss=0.1348 
[epoch 15] step 10/44: loss=0.1418 
[epoch 15] step 12/44: loss=0.1369 
[epoch 15] step 14/44: loss=0.1378 
[epoch 15] step 16/44: loss=0.1323 
[epoch 15] step 18/44: loss=0.1309 
[epoch 15] step 20/44: loss=0.1254 
[epoch 15] step 22/44: loss=0.1313 
[epoch 15] step 24/44: loss=0.1285 
[epoch 15] step 26/44: loss=0.1252 
[epoch 15] step 28/44: loss=0.1244 
[epoch 15] step 30/44: loss=0.1239 
[epoch 15] step 32/44: loss=0.1199 
[epoch 15] step 34/44: loss=0.1203 
[epoch 15] step 36/44: loss=0.1195 
[epoch 15] step 38/44: loss=0.1191 
[epoch 15] step 40/44: loss=0.1178 
[epoch 15] step 42/44: loss=0.1148 
[epoch 15] step 44/44: loss=0.1091 
[epoch 15] train_loss(avg per step)=0.2181 lambda[min,max]=[0.486359,1.000000]
[epoch 15] val_loss=1.2473 qwk=('0.4939', '0.3323', '0.4431') averageQWK=0.4231 macroEMD=0.2511 tailR0=('0.2381', '0.0000', '0.0000') tailR0avg=0.0794
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    5   35    1    0
     0    1   87   30    4
     0    0   46   77   18
     0    0    5    6   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    5    0
     0    3   24   12    0
     0    5   48   51    0
     0    0   31  132    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0    4   42    6    0
     0   17   90   51    0
     0    2   28   80    0
     0    0    0    3    0
[epoch 16] step 2/44: loss=0.1200 
[epoch 16] step 4/44: loss=0.1043 
[epoch 16] step 6/44: loss=0.1040 
[epoch 16] step 8/44: loss=0.1069 
[epoch 16] step 10/44: loss=0.0987 
[epoch 16] step 12/44: loss=0.1038 
[epoch 16] step 14/44: loss=0.0997 
[epoch 16] step 16/44: loss=0.1008 
[epoch 16] step 18/44: loss=0.0988 
[epoch 16] step 20/44: loss=0.0997 
[epoch 16] step 22/44: loss=0.1030 
[epoch 16] step 24/44: loss=0.0972 
[epoch 16] step 26/44: loss=0.0973 
[epoch 16] step 28/44: loss=0.0944 
[epoch 16] step 30/44: loss=0.0950 
[epoch 16] step 32/44: loss=0.0942 
[epoch 16] step 34/44: loss=0.0945 
[epoch 16] step 36/44: loss=0.0914 
[epoch 16] step 38/44: loss=0.0901 
[epoch 16] step 40/44: loss=0.0898 
[epoch 16] step 42/44: loss=0.0890 
[epoch 16] step 44/44: loss=0.0848 
[epoch 16] train_loss(avg per step)=0.1696 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=1.2363 qwk=('0.4790', '0.3502', '0.5066') averageQWK=0.4453 macroEMD=0.2426 tailR0=('0.1667', '0.0000', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0   10   29    2    0
     0    8   81   31    2
     0    1   46   88    6
     0    0    5    9    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    4    0
     0    4   24   11    0
     0    7   53   44    0
     0    0   40  123    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0   23   26    3    0
     0   29   95   34    0
     0    4   38   68    0
     0    0    0    3    0
[epoch 17] step 2/44: loss=0.0619 
[epoch 17] step 4/44: loss=0.0579 
[epoch 17] step 6/44: loss=0.0718 
[epoch 17] step 8/44: loss=0.0810 
[epoch 17] step 10/44: loss=0.0823 
[epoch 17] step 12/44: loss=0.0835 
[epoch 17] step 14/44: loss=0.0764 
[epoch 17] step 16/44: loss=0.0799 
[epoch 17] step 18/44: loss=0.0784 
[epoch 17] step 20/44: loss=0.0756 
[epoch 17] step 22/44: loss=0.0736 
[epoch 17] step 24/44: loss=0.0712 
[epoch 17] step 26/44: loss=0.0683 
[epoch 17] step 28/44: loss=0.0664 
[epoch 17] step 30/44: loss=0.0626 
[epoch 17] step 32/44: loss=0.0634 
[epoch 17] step 34/44: loss=0.0606 
[epoch 17] step 36/44: loss=0.0591 
[epoch 17] step 38/44: loss=0.0585 
[epoch 17] step 40/44: loss=0.0573 
[epoch 17] step 42/44: loss=0.0575 
[epoch 17] step 44/44: loss=0.0531 
[epoch 17] train_loss(avg per step)=0.1063 lambda[min,max]=[0.485000,1.000000]
[epoch 17] val_loss=1.2675 qwk=('0.4561', '0.3832', '0.4136') averageQWK=0.4176 macroEMD=0.2503 tailR0=('0.1667', '0.0000', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    6   33    2    0
     0    3   88   29    2
     0    1   52   82    6
     0    0    4   10    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    5   26    8    0
     0    7   64   32    1
     0    1   51  109    2
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    2   44    6    0
     0    7   98   53    0
     0    0   29   81    0
     0    0    0    3    0
[epoch 18] step 2/44: loss=0.0780 
[epoch 18] step 4/44: loss=0.0557 
[epoch 18] step 6/44: loss=0.0558 
[epoch 18] step 8/44: loss=0.0506 
[epoch 18] step 10/44: loss=0.0535 
[epoch 18] step 12/44: loss=0.0535 
[epoch 18] step 14/44: loss=0.0477 
[epoch 18] step 16/44: loss=0.0474 
[epoch 18] step 18/44: loss=0.0484 
[epoch 18] step 20/44: loss=0.0477 
[epoch 18] step 22/44: loss=0.0486 
[epoch 18] step 24/44: loss=0.0469 
[epoch 18] step 26/44: loss=0.0474 
[epoch 18] step 28/44: loss=0.0456 
[epoch 18] step 30/44: loss=0.0446 
[epoch 18] step 32/44: loss=0.0413 
[epoch 18] step 34/44: loss=0.0377 
[epoch 18] step 36/44: loss=0.0373 
[epoch 18] step 38/44: loss=0.0361 
[epoch 18] step 40/44: loss=0.0365 
[epoch 18] step 42/44: loss=0.0348 
[epoch 18] step 44/44: loss=0.0325 
[epoch 18] train_loss(avg per step)=0.0650 lambda[min,max]=[0.402402,1.000000]
[epoch 18] val_loss=1.2789 qwk=('0.5152', '0.3930', '0.4853') averageQWK=0.4645 macroEMD=0.2431 tailR0=('0.2405', '0.0000', '0.0000') tailR0avg=0.0802
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     0    6   32    3    0
     0    3   78   41    0
     0    0   37  100    4
     0    0    2   11    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    6   25    8    0
     0   10   60   34    0
     0    0   57  105    1
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   19   29    4    0
     0   25   92   41    0
     0    2   38   70    0
     0    0    0    3    0
[epoch 19] step 2/44: loss=-0.0113 
[epoch 19] step 4/44: loss=-0.0084 
[epoch 19] step 6/44: loss=0.0068 
[epoch 19] step 8/44: loss=0.0168 
[epoch 19] step 10/44: loss=0.0220 
[epoch 19] step 12/44: loss=0.0241 
[epoch 19] step 14/44: loss=0.0264 
[epoch 19] step 16/44: loss=0.0237 
[epoch 19] step 18/44: loss=0.0235 
[epoch 19] step 20/44: loss=0.0246 
[epoch 19] step 22/44: loss=0.0217 
[epoch 19] step 24/44: loss=0.0223 
[epoch 19] step 26/44: loss=0.0216 
[epoch 19] step 28/44: loss=0.0207 
[epoch 19] step 30/44: loss=0.0187 
[epoch 19] step 32/44: loss=0.0155 
[epoch 19] step 34/44: loss=0.0157 
[epoch 19] step 36/44: loss=0.0161 
[epoch 19] step 38/44: loss=0.0154 
[epoch 19] step 40/44: loss=0.0149 
[epoch 19] step 42/44: loss=0.0146 
[epoch 19] step 44/44: loss=0.0118 
[epoch 19] train_loss(avg per step)=0.0237 lambda[min,max]=[0.401893,1.000000]
[epoch 19] val_loss=1.3282 qwk=('0.5169', '0.3550', '0.4300') averageQWK=0.4340 macroEMD=0.2518 tailR0=('0.2381', '0.0000', '0.0000') tailR0avg=0.0794
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    6   34    1    0
     0    1   92   27    2
     0    0   51   79   11
     0    0    3    8   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    4    0
     0    4   26    9    0
     0    1   59   43    1
     0    0   38  124    1
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    8   41    3    0
     0   18  108   32    0
     0    1   41   68    0
     0    0    0    3    0
[epoch 20] step 2/44: loss=-0.0074 
[epoch 20] step 4/44: loss=-0.0115 
[epoch 20] step 6/44: loss=-0.0030 
[epoch 20] step 8/44: loss=-0.0008 
[epoch 20] step 10/44: loss=-0.0065 
[epoch 20] step 12/44: loss=-0.0074 
[epoch 20] step 14/44: loss=-0.0056 
[epoch 20] step 16/44: loss=-0.0046 
[epoch 20] step 18/44: loss=-0.0088 
[epoch 20] step 20/44: loss=-0.0087 
[epoch 20] step 22/44: loss=-0.0089 
[epoch 20] step 24/44: loss=-0.0058 
[epoch 20] step 26/44: loss=-0.0085 
[epoch 20] step 28/44: loss=-0.0097 
[epoch 20] step 30/44: loss=-0.0078 
[epoch 20] step 32/44: loss=-0.0075 
[epoch 20] step 34/44: loss=-0.0063 
[epoch 20] step 36/44: loss=-0.0065 
[epoch 20] step 38/44: loss=-0.0054 
[epoch 20] step 40/44: loss=-0.0050 
[epoch 20] step 42/44: loss=-0.0045 
[epoch 20] step 44/44: loss=-0.0069 
[epoch 20] train_loss(avg per step)=-0.0139 lambda[min,max]=[0.429973,1.000000]
[epoch 20] val_loss=1.3462 qwk=('0.4886', '0.4017', '0.4221') averageQWK=0.4375 macroEMD=0.2522 tailR0=('0.1452', '0.0000', '0.0000') tailR0avg=0.0484
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     2    3   32    4    0
     0    1   75   45    1
     0    0   31  106    4
     0    0    2   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    4   27    8    0
     0    4   53   47    0
     0    0   35  127    1
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    6   41    5    0
     0   14  103   41    0
     0    0   37   73    0
     0    0    1    2    0
[epoch 21] step 2/44: loss=-0.0334 
[epoch 21] step 4/44: loss=-0.0345 
[epoch 21] step 6/44: loss=-0.0340 
[epoch 21] step 8/44: loss=-0.0271 
[epoch 21] step 10/44: loss=-0.0201 
[epoch 21] step 12/44: loss=-0.0204 
[epoch 21] step 14/44: loss=-0.0227 
[epoch 21] step 16/44: loss=-0.0241 
[epoch 21] step 18/44: loss=-0.0233 
[epoch 21] step 20/44: loss=-0.0217 
[epoch 21] step 22/44: loss=-0.0209 
[epoch 21] step 24/44: loss=-0.0236 
[epoch 21] step 26/44: loss=-0.0226 
[epoch 21] step 28/44: loss=-0.0241 
[epoch 21] step 30/44: loss=-0.0230 
[epoch 21] step 32/44: loss=-0.0226 
[epoch 21] step 34/44: loss=-0.0223 
[epoch 21] step 36/44: loss=-0.0223 
[epoch 21] step 38/44: loss=-0.0223 
[epoch 21] step 40/44: loss=-0.0220 
[epoch 21] step 42/44: loss=-0.0223 
[epoch 21] step 44/44: loss=-0.0224 
[epoch 21] train_loss(avg per step)=-0.0448 lambda[min,max]=[0.377255,1.000000]
[epoch 21] val_loss=1.4041 qwk=('0.4958', '0.3816', '0.4781') averageQWK=0.4518 macroEMD=0.2487 tailR0=('0.2881', '0.0312', '0.0000') tailR0avg=0.1064
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     3    4   33    1    0
     0    2   84   32    4
     0    0   52   79   10
     0    0    3    8   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    4    0
     1    3   24   11    0
     1    8   50   44    1
     0    0   34  128    1
     0    0    3   12    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   16   29    7    0
     0   23   77   58    0
     0    2   24   84    0
     0    0    0    3    0
[epoch 22] step 2/44: loss=-0.0380 
[epoch 22] step 4/44: loss=-0.0375 
[epoch 22] step 6/44: loss=-0.0397 
[epoch 22] step 8/44: loss=-0.0357 
[epoch 22] step 10/44: loss=-0.0358 
[epoch 22] step 12/44: loss=-0.0357 
[epoch 22] step 14/44: loss=-0.0356 
[epoch 22] step 16/44: loss=-0.0341 
[epoch 22] step 18/44: loss=-0.0362 
[epoch 22] step 20/44: loss=-0.0354 
[epoch 22] step 22/44: loss=-0.0308 
[epoch 22] step 24/44: loss=-0.0317 
[epoch 22] step 26/44: loss=-0.0319 
[epoch 22] step 28/44: loss=-0.0290 
[epoch 22] step 30/44: loss=-0.0312 
[epoch 22] step 32/44: loss=-0.0327 
[epoch 22] step 34/44: loss=-0.0295 
[epoch 22] step 36/44: loss=-0.0291 
[epoch 22] step 38/44: loss=-0.0290 
[epoch 22] step 40/44: loss=-0.0297 
[epoch 22] step 42/44: loss=-0.0293 
[epoch 22] step 44/44: loss=-0.0262 
[epoch 22] train_loss(avg per step)=-0.0525 lambda[min,max]=[0.453469,1.000000]
[epoch 22] val_loss=1.4020 qwk=('0.5118', '0.3549', '0.4525') averageQWK=0.4397 macroEMD=0.2510 tailR0=('0.2881', '0.0000', '0.0000') tailR0avg=0.0960
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     1    6   32    1    1
     0    2   85   31    4
     0    0   47   77   17
     0    0    2    9   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    5    0
     0    5   15   19    0
     0    8   38   58    0
     0    0   18  144    1
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0   10   38    4    0
     0   16  104   38    0
     0    0   42   68    0
     0    0    0    3    0
[epoch 23] step 2/44: loss=-0.0365 
[epoch 23] step 4/44: loss=-0.0390 
[epoch 23] step 6/44: loss=-0.0397 
[epoch 23] step 8/44: loss=-0.0410 
[epoch 23] step 10/44: loss=-0.0395 
[epoch 23] step 12/44: loss=-0.0411 
[epoch 23] step 14/44: loss=-0.0429 
[epoch 23] step 16/44: loss=-0.0453 
[epoch 23] step 18/44: loss=-0.0481 
[epoch 23] step 20/44: loss=-0.0483 
[epoch 23] step 22/44: loss=-0.0486 
[epoch 23] step 24/44: loss=-0.0481 
[epoch 23] step 26/44: loss=-0.0481 
[epoch 23] step 28/44: loss=-0.0477 
[epoch 23] step 30/44: loss=-0.0461 
[epoch 23] step 32/44: loss=-0.0477 
[epoch 23] step 34/44: loss=-0.0486 
[epoch 23] step 36/44: loss=-0.0505 
[epoch 23] step 38/44: loss=-0.0495 
[epoch 23] step 40/44: loss=-0.0505 
[epoch 23] step 42/44: loss=-0.0496 
[epoch 23] step 44/44: loss=-0.0505 
[epoch 23] train_loss(avg per step)=-0.1009 lambda[min,max]=[0.374378,1.000000]
[epoch 23] val_loss=1.4169 qwk=('0.5033', '0.3556', '0.4948') averageQWK=0.4513 macroEMD=0.2499 tailR0=('0.3357', '0.0000', '0.0000') tailR0avg=0.1119
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     3    3   33    1    1
     1    0   91   24    6
     0    0   51   71   19
     0    0    3    6   12
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    5    0
     1    4   16   18    0
     1    7   39   57    0
     0    0   19  143    1
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   19   29    4    0
     0   20   93   45    0
     0    2   35   73    0
     0    0    0    3    0
[epoch 24] step 2/44: loss=-0.0456 
[epoch 24] step 4/44: loss=-0.0527 
[epoch 24] step 6/44: loss=-0.0574 
[epoch 24] step 8/44: loss=-0.0559 
[epoch 24] step 10/44: loss=-0.0571 
[epoch 24] step 12/44: loss=-0.0561 
[epoch 24] step 14/44: loss=-0.0560 
[epoch 24] step 16/44: loss=-0.0519 
[epoch 24] step 18/44: loss=-0.0494 
[epoch 24] step 20/44: loss=-0.0474 
[epoch 24] step 22/44: loss=-0.0477 
[epoch 24] step 24/44: loss=-0.0495 
[epoch 24] step 26/44: loss=-0.0494 
[epoch 24] step 28/44: loss=-0.0512 
[epoch 24] step 30/44: loss=-0.0509 
[epoch 24] step 32/44: loss=-0.0502 
[epoch 24] step 34/44: loss=-0.0516 
[epoch 24] step 36/44: loss=-0.0525 
[epoch 24] step 38/44: loss=-0.0531 
[epoch 24] step 40/44: loss=-0.0536 
[epoch 24] step 42/44: loss=-0.0530 
[epoch 24] step 44/44: loss=-0.0546 
[epoch 24] train_loss(avg per step)=-0.1093 lambda[min,max]=[0.416770,1.000000]
[epoch 24] val_loss=1.3897 qwk=('0.5088', '0.4150', '0.4673') averageQWK=0.4637 macroEMD=0.2438 tailR0=('0.2643', '0.0000', '0.0000') tailR0avg=0.0881
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    4   34    1    0
     0    2   95   24    1
     0    0   60   76    5
     0    0    3    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    6   26    7    0
     0    7   61   36    0
     0    0   46  116    1
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0   11   39    2    0
     0   15  111   32    0
     0    0   46   64    0
     0    0    0    3    0
[epoch 25] step 2/44: loss=-0.0577 
[epoch 25] step 4/44: loss=-0.0639 
[epoch 25] step 6/44: loss=-0.0636 
[epoch 25] step 8/44: loss=-0.0648 
[epoch 25] step 10/44: loss=-0.0649 
[epoch 25] step 12/44: loss=-0.0633 
[epoch 25] step 14/44: loss=-0.0588 
[epoch 25] step 16/44: loss=-0.0578 
[epoch 25] step 18/44: loss=-0.0612 
[epoch 25] step 20/44: loss=-0.0633 
[epoch 25] step 22/44: loss=-0.0643 
[epoch 25] step 24/44: loss=-0.0651 
[epoch 25] step 26/44: loss=-0.0642 
[epoch 25] step 28/44: loss=-0.0649 
[epoch 25] step 30/44: loss=-0.0646 
[epoch 25] step 32/44: loss=-0.0642 
[epoch 25] step 34/44: loss=-0.0632 
[epoch 25] step 36/44: loss=-0.0625 
[epoch 25] step 38/44: loss=-0.0619 
[epoch 25] step 40/44: loss=-0.0617 
[epoch 25] step 42/44: loss=-0.0619 
[epoch 25] step 44/44: loss=-0.0627 
[epoch 25] train_loss(avg per step)=-0.1253 lambda[min,max]=[0.406060,1.000000]
[epoch 25] val_loss=1.4262 qwk=('0.4361', '0.3914', '0.4689') averageQWK=0.4321 macroEMD=0.2448 tailR0=('0.1452', '0.0000', '0.0000') tailR0avg=0.0484
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     1    6   33    1    0
     0    5   86   30    1
     0    2   51   83    5
     0    0    7   10    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    2    0
     0    4   29    6    0
     0    5   72   27    0
     0    0   60  103    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   15   35    2    0
     0   23  103   32    0
     0    3   43   64    0
     0    0    0    3    0
[epoch 26] step 2/44: loss=-0.0736 
[epoch 26] step 4/44: loss=-0.0712 
[epoch 26] step 6/44: loss=-0.0695 
[epoch 26] step 8/44: loss=-0.0717 
[epoch 26] step 10/44: loss=-0.0723 
[epoch 26] step 12/44: loss=-0.0716 
[epoch 26] step 14/44: loss=-0.0699 
[epoch 26] step 16/44: loss=-0.0696 
[epoch 26] step 18/44: loss=-0.0704 
[epoch 26] step 20/44: loss=-0.0703 
[epoch 26] step 22/44: loss=-0.0717 
[epoch 26] step 24/44: loss=-0.0720 
[epoch 26] step 26/44: loss=-0.0721 
[epoch 26] step 28/44: loss=-0.0717 
[epoch 26] step 30/44: loss=-0.0716 
[epoch 26] step 32/44: loss=-0.0695 
[epoch 26] step 34/44: loss=-0.0701 
[epoch 26] step 36/44: loss=-0.0715 
[epoch 26] step 38/44: loss=-0.0701 
[epoch 26] step 40/44: loss=-0.0708 
[epoch 26] step 42/44: loss=-0.0713 
[epoch 26] step 44/44: loss=-0.0714 
[epoch 26] train_loss(avg per step)=-0.1427 lambda[min,max]=[0.360290,1.000000]
[epoch 26] val_loss=1.4431 qwk=('0.4698', '0.3972', '0.5014') averageQWK=0.4562 macroEMD=0.2471 tailR0=('0.2405', '0.0000', '0.0000') tailR0avg=0.0802
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     1    6   27    7    0
     0    8   60   52    2
     0    2   30  101    8
     0    0    1   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    3   26   10    0
     0    6   50   48    0
     0    0   29  133    1
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   21   27    4    0
     0   24   88   46    0
     0    2   34   74    0
     0    0    0    3    0
[epoch 27] step 2/44: loss=-0.0930 
[epoch 27] step 4/44: loss=-0.0676 
[epoch 27] step 6/44: loss=-0.0738 
[epoch 27] step 8/44: loss=-0.0782 
[epoch 27] step 10/44: loss=-0.0782 
[epoch 27] step 12/44: loss=-0.0775 
[epoch 27] step 14/44: loss=-0.0785 
[epoch 27] step 16/44: loss=-0.0770 
[epoch 27] step 18/44: loss=-0.0751 
[epoch 27] step 20/44: loss=-0.0767 
[epoch 27] step 22/44: loss=-0.0758 
[epoch 27] step 24/44: loss=-0.0763 
[epoch 27] step 26/44: loss=-0.0762 
[epoch 27] step 28/44: loss=-0.0761 
[epoch 27] step 30/44: loss=-0.0763 
[epoch 27] step 32/44: loss=-0.0768 
[epoch 27] step 34/44: loss=-0.0764 
[epoch 27] step 36/44: loss=-0.0760 
[epoch 27] step 38/44: loss=-0.0755 
[epoch 27] step 40/44: loss=-0.0754 
[epoch 27] step 42/44: loss=-0.0763 
[epoch 27] step 44/44: loss=-0.0769 
[epoch 27] train_loss(avg per step)=-0.1538 lambda[min,max]=[0.350790,1.000000]
[epoch 27] val_loss=1.4423 qwk=('0.5011', '0.3758', '0.4936') averageQWK=0.4568 macroEMD=0.2499 tailR0=('0.2881', '0.0625', '0.0000') tailR0avg=0.1169
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     2    4   34    1    0
     0    0   89   29    4
     0    0   50   82    9
     0    0    3    8   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    4    0
     0    4   24   11    0
     0    3   54   46    1
     0    0   31  131    1
     0    0    2   12    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     1   12   33    6    0
     0   12   93   53    0
     0    0   29   81    0
     0    0    0    3    0
[epoch 28] step 2/44: loss=-0.0774 
[epoch 28] step 4/44: loss=-0.0820 
[epoch 28] step 6/44: loss=-0.0828 
[epoch 28] step 8/44: loss=-0.0839 
[epoch 28] step 10/44: loss=-0.0836 
[epoch 28] step 12/44: loss=-0.0831 
[epoch 28] step 14/44: loss=-0.0832 
[epoch 28] step 16/44: loss=-0.0822 
[epoch 28] step 18/44: loss=-0.0825 
[epoch 28] step 20/44: loss=-0.0831 
[epoch 28] step 22/44: loss=-0.0827 
[epoch 28] step 24/44: loss=-0.0820 
[epoch 28] step 26/44: loss=-0.0817 
[epoch 28] step 28/44: loss=-0.0824 
[epoch 28] step 30/44: loss=-0.0812 
[epoch 28] step 32/44: loss=-0.0815 
[epoch 28] step 34/44: loss=-0.0818 
[epoch 28] step 36/44: loss=-0.0820 
[epoch 28] step 38/44: loss=-0.0817 
[epoch 28] step 40/44: loss=-0.0816 
[epoch 28] step 42/44: loss=-0.0819 
[epoch 28] step 44/44: loss=-0.0802 
[epoch 28] train_loss(avg per step)=-0.1605 lambda[min,max]=[0.366721,1.000000]
[epoch 28] val_loss=1.4425 qwk=('0.4692', '0.3944', '0.4891') averageQWK=0.4509 macroEMD=0.2447 tailR0=('0.2167', '0.0000', '0.0000') tailR0avg=0.0722
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     1    4   35    1    0
     0    2   90   29    1
     0    0   54   82    5
     0    0    5    9    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    5   25    9    0
     0    7   55   42    0
     0    0   38  124    1
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   19   31    2    0
     0   23  108   27    0
     0    2   45   63    0
     0    0    1    2    0
[epoch 29] step 2/44: loss=-0.0960 
[epoch 29] step 4/44: loss=-0.0946 
[epoch 29] step 6/44: loss=-0.0931 
[epoch 29] step 8/44: loss=-0.0902 
[epoch 29] step 10/44: loss=-0.0893 
[epoch 29] step 12/44: loss=-0.0888 
[epoch 29] step 14/44: loss=-0.0877 
[epoch 29] step 16/44: loss=-0.0872 
[epoch 29] step 18/44: loss=-0.0875 
[epoch 29] step 20/44: loss=-0.0880 
[epoch 29] step 22/44: loss=-0.0875 
[epoch 29] step 24/44: loss=-0.0884 
[epoch 29] step 26/44: loss=-0.0893 
[epoch 29] step 28/44: loss=-0.0890 
[epoch 29] step 30/44: loss=-0.0887 
[epoch 29] step 32/44: loss=-0.0888 
[epoch 29] step 34/44: loss=-0.0878 
[epoch 29] step 36/44: loss=-0.0880 
[epoch 29] step 38/44: loss=-0.0885 
[epoch 29] step 40/44: loss=-0.0888 
[epoch 29] step 42/44: loss=-0.0884 
[epoch 29] step 44/44: loss=-0.0888 
[epoch 29] train_loss(avg per step)=-0.1777 lambda[min,max]=[0.377958,1.000000]
[epoch 29] val_loss=1.4544 qwk=('0.4989', '0.3856', '0.4769') averageQWK=0.4538 macroEMD=0.2457 tailR0=('0.2881', '0.0000', '0.0000') tailR0avg=0.0960
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     2    4   33    2    0
     0    6   83   31    2
     0    1   48   83    9
     0    0    3    8   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    4    0
     0    5   24   10    0
     0    9   53   42    0
     0    0   38  124    1
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   15   34    3    0
     0   17  107   34    0
     0    2   40   68    0
     0    0    1    2    0
[epoch 30] step 2/44: loss=-0.0975 
[epoch 30] step 4/44: loss=-0.0975 
[epoch 30] step 6/44: loss=-0.0959 
[epoch 30] step 8/44: loss=-0.0963 
[epoch 30] step 10/44: loss=-0.0938 
[epoch 30] step 12/44: loss=-0.0938 
[epoch 30] step 14/44: loss=-0.0941 
[epoch 30] step 16/44: loss=-0.0930 
[epoch 30] step 18/44: loss=-0.0931 
[epoch 30] step 20/44: loss=-0.0929 
[epoch 30] step 22/44: loss=-0.0921 
[epoch 30] step 24/44: loss=-0.0920 
[epoch 30] step 26/44: loss=-0.0904 
[epoch 30] step 28/44: loss=-0.0911 
[epoch 30] step 30/44: loss=-0.0912 
[epoch 30] step 32/44: loss=-0.0911 
[epoch 30] step 34/44: loss=-0.0913 
[epoch 30] step 36/44: loss=-0.0917 
[epoch 30] step 38/44: loss=-0.0906 
[epoch 30] step 40/44: loss=-0.0910 
[epoch 30] step 42/44: loss=-0.0914 
[epoch 30] step 44/44: loss=-0.0916 
[epoch 30] train_loss(avg per step)=-0.1833 lambda[min,max]=[0.373296,1.000000]
[epoch 30] val_loss=1.4670 qwk=('0.4845', '0.3833', '0.4719') averageQWK=0.4466 macroEMD=0.2442 tailR0=('0.2881', '0.0000', '0.0000') tailR0avg=0.0960
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     2    3   34    2    0
     0    5   85   30    2
     0    1   50   80   10
     0    0    4    7   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    4    0
     0    5   25    9    0
     0    7   53   44    0
     0    0   36  126    1
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   21   28    3    0
     0   26  104   28    0
     0    3   46   61    0
     0    0    1    2    0
[epoch 31] step 2/44: loss=-0.0913 
[epoch 31] step 4/44: loss=-0.0908 
[epoch 31] step 6/44: loss=-0.0951 
[epoch 31] step 8/44: loss=-0.0961 
[epoch 31] step 10/44: loss=-0.0946 
[epoch 31] step 12/44: loss=-0.0933 
[epoch 31] step 14/44: loss=-0.0938 
[epoch 31] step 16/44: loss=-0.0943 
[epoch 31] step 18/44: loss=-0.0942 
[epoch 31] step 20/44: loss=-0.0949 
[epoch 31] step 22/44: loss=-0.0952 
[epoch 31] step 24/44: loss=-0.0940 
[epoch 31] step 26/44: loss=-0.0944 
[epoch 31] step 28/44: loss=-0.0945 
[epoch 31] step 30/44: loss=-0.0947 
[epoch 31] step 32/44: loss=-0.0944 
[epoch 31] step 34/44: loss=-0.0934 
[epoch 31] step 36/44: loss=-0.0936 
[epoch 31] step 38/44: loss=-0.0937 
[epoch 31] step 40/44: loss=-0.0937 
[epoch 31] step 42/44: loss=-0.0935 
[epoch 31] step 44/44: loss=-0.0935 
[epoch 31] train_loss(avg per step)=-0.1870 lambda[min,max]=[0.415834,1.000000]
[epoch 31] val_loss=1.4900 qwk=('0.5046', '0.3922', '0.4753') averageQWK=0.4574 macroEMD=0.2446 tailR0=('0.2881', '0.0000', '0.0000') tailR0avg=0.0960
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     1    5   33    2    0
     0    3   87   30    2
     0    0   49   84    8
     0    0    3    8   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    4    0
     0    5   25    9    0
     0    4   55   45    0
     0    0   32  130    1
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   10   38    4    0
     0   17   92   49    0
     0    0   34   76    0
     0    0    0    3    0
[epoch 32] step 2/44: loss=-0.0992 
[epoch 32] step 4/44: loss=-0.0985 
[epoch 32] step 6/44: loss=-0.0995 
[epoch 32] step 8/44: loss=-0.1002 
[epoch 32] step 10/44: loss=-0.1000 
[epoch 32] step 12/44: loss=-0.1001 
[epoch 32] step 14/44: loss=-0.0977 
[epoch 32] step 16/44: loss=-0.0967 
[epoch 32] step 18/44: loss=-0.0953 
[epoch 32] step 20/44: loss=-0.0957 
[epoch 32] step 22/44: loss=-0.0946 
[epoch 32] step 24/44: loss=-0.0940 
[epoch 32] step 26/44: loss=-0.0944 
[epoch 32] step 28/44: loss=-0.0945 
[epoch 32] step 30/44: loss=-0.0950 
[epoch 32] step 32/44: loss=-0.0953 
[epoch 32] step 34/44: loss=-0.0953 
[epoch 32] step 36/44: loss=-0.0954 
[epoch 32] step 38/44: loss=-0.0954 
[epoch 32] step 40/44: loss=-0.0957 
[epoch 32] step 42/44: loss=-0.0956 
[epoch 32] step 44/44: loss=-0.0955 
[epoch 32] train_loss(avg per step)=-0.1911 lambda[min,max]=[0.382999,1.000000]
[epoch 32] val_loss=1.4914 qwk=('0.5018', '0.3846', '0.4888') averageQWK=0.4584 macroEMD=0.2418 tailR0=('0.2405', '0.0000', '0.0000') tailR0avg=0.0802
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     1    5   33    2    0
     0    4   83   33    2
     0    1   41   91    8
     0    0    3   10    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    5   26    8    0
     0    5   64   35    0
     0    0   49  113    1
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   17   31    4    0
     0   18  100   40    0
     0    2   37   71    0
     0    0    0    3    0
[epoch 33] step 2/44: loss=-0.0918 
[epoch 33] step 4/44: loss=-0.0934 
[epoch 33] step 6/44: loss=-0.0909 
[epoch 33] step 8/44: loss=-0.0928 
[epoch 33] step 10/44: loss=-0.0946 
[epoch 33] step 12/44: loss=-0.0945 
[epoch 33] step 14/44: loss=-0.0929 
[epoch 33] step 16/44: loss=-0.0927 
[epoch 33] step 18/44: loss=-0.0937 
[epoch 33] step 20/44: loss=-0.0941 
[epoch 33] step 22/44: loss=-0.0940 
[epoch 33] step 24/44: loss=-0.0950 
[epoch 33] step 26/44: loss=-0.0959 
[epoch 33] step 28/44: loss=-0.0965 
[epoch 33] step 30/44: loss=-0.0967 
[epoch 33] step 32/44: loss=-0.0967 
[epoch 33] step 34/44: loss=-0.0965 
[epoch 33] step 36/44: loss=-0.0961 
[epoch 33] step 38/44: loss=-0.0965 
[epoch 33] step 40/44: loss=-0.0962 
[epoch 33] step 42/44: loss=-0.0963 
[epoch 33] step 44/44: loss=-0.0968 
[epoch 33] train_loss(avg per step)=-0.1935 lambda[min,max]=[0.388891,1.000000]
[epoch 33] val_loss=1.4823 qwk=('0.4987', '0.3665', '0.4989') averageQWK=0.4547 macroEMD=0.2441 tailR0=('0.2643', '0.0000', '0.0000') tailR0avg=0.0881
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     2    3   33    3    0
     0    4   85   31    2
     0    0   45   88    8
     0    0    3    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    5    0
     0    5   24   10    0
     0    5   54   45    0
     0    0   34  128    1
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   17   32    3    0
     0   19  108   31    0
     0    2   40   68    0
     0    0    0    3    0
[epoch 34] step 2/44: loss=-0.1016 
[epoch 34] step 4/44: loss=-0.0980 
[epoch 34] step 6/44: loss=-0.0945 
[epoch 34] step 8/44: loss=-0.0957 
[epoch 34] step 10/44: loss=-0.0965 
[epoch 34] step 12/44: loss=-0.0970 
[epoch 34] step 14/44: loss=-0.0962 
[epoch 34] step 16/44: loss=-0.0972 
[epoch 34] step 18/44: loss=-0.0974 
[epoch 34] step 20/44: loss=-0.0972 
[epoch 34] step 22/44: loss=-0.0977 
[epoch 34] step 24/44: loss=-0.0980 
[epoch 34] step 26/44: loss=-0.0983 
[epoch 34] step 28/44: loss=-0.0988 
[epoch 34] step 30/44: loss=-0.0992 
[epoch 34] step 32/44: loss=-0.0993 
[epoch 34] step 34/44: loss=-0.0997 
[epoch 34] step 36/44: loss=-0.0996 
[epoch 34] step 38/44: loss=-0.0990 
[epoch 34] step 40/44: loss=-0.0993 
[epoch 34] step 42/44: loss=-0.0993 
[epoch 34] step 44/44: loss=-0.0996 
[epoch 34] train_loss(avg per step)=-0.1991 lambda[min,max]=[0.359912,1.000000]
[epoch 34] val_loss=1.4861 qwk=('0.4883', '0.3864', '0.4858') averageQWK=0.4535 macroEMD=0.2437 tailR0=('0.2643', '0.0000', '0.0000') tailR0avg=0.0881
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     1    5   33    2    0
     0    4   87   29    2
     0    1   51   80    9
     0    0    3    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    5    0
     0    6   25    8    0
     0    5   57   42    0
     0    0   40  122    1
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   17   32    3    0
     0   20  100   38    0
     0    2   40   68    0
     0    0    0    3    0
[epoch 35] step 2/44: loss=-0.1003 
[epoch 35] step 4/44: loss=-0.0996 
[epoch 35] step 6/44: loss=-0.0960 
[epoch 35] step 8/44: loss=-0.0966 
[epoch 35] step 10/44: loss=-0.0972 
[epoch 35] step 12/44: loss=-0.0955 
[epoch 35] step 14/44: loss=-0.0968 
[epoch 35] step 16/44: loss=-0.0974 
[epoch 35] step 18/44: loss=-0.0974 
[epoch 35] step 20/44: loss=-0.0983 
[epoch 35] step 22/44: loss=-0.0991 
[epoch 35] step 24/44: loss=-0.0998 
[epoch 35] step 26/44: loss=-0.1001 
[epoch 35] step 28/44: loss=-0.1003 
[epoch 35] step 30/44: loss=-0.0999 
[epoch 35] step 32/44: loss=-0.1000 
[epoch 35] step 34/44: loss=-0.1003 
[epoch 35] step 36/44: loss=-0.1002 
[epoch 35] step 38/44: loss=-0.1004 
[epoch 35] step 40/44: loss=-0.0997 
[epoch 35] step 42/44: loss=-0.0992 
[epoch 35] step 44/44: loss=-0.0976 
[epoch 35] train_loss(avg per step)=-0.1952 lambda[min,max]=[0.359589,1.000000]
[epoch 35] val_loss=1.4882 qwk=('0.5017', '0.3878', '0.4909') averageQWK=0.4601 macroEMD=0.2438 tailR0=('0.2643', '0.0000', '0.0000') tailR0avg=0.0881
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     2    4   34    1    0
     0    4   88   28    2
     0    0   53   79    9
     0    0    3    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    5    0
     0    6   24    9    0
     0    5   57   42    0
     0    0   37  125    1
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   17   32    3    0
     0   20  103   35    0
     0    2   40   68    0
     0    0    0    3    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold1/metrics.json
Done.
