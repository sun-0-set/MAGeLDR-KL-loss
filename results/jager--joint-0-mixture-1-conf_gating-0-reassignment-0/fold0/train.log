[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.6937 
[epoch 1] step 4/44: loss=0.7018 
[epoch 1] step 6/44: loss=0.7036 
[epoch 1] step 8/44: loss=0.7077 
[epoch 1] step 10/44: loss=0.7127 
[epoch 1] step 12/44: loss=0.7136 
[epoch 1] step 14/44: loss=0.7117 
[epoch 1] step 16/44: loss=0.7107 
[epoch 1] step 18/44: loss=0.7102 
[epoch 1] step 20/44: loss=0.7079 
[epoch 1] step 22/44: loss=0.7066 
[epoch 1] step 24/44: loss=0.7058 
[epoch 1] step 26/44: loss=0.7055 
[epoch 1] step 28/44: loss=0.7033 
[epoch 1] step 30/44: loss=0.7033 
[epoch 1] step 32/44: loss=0.7018 
[epoch 1] step 34/44: loss=0.6998 
[epoch 1] step 36/44: loss=0.6974 
[epoch 1] step 38/44: loss=0.6960 
[epoch 1] step 40/44: loss=0.6954 
[epoch 1] step 42/44: loss=0.6935 
[epoch 1] step 44/44: loss=0.6912 
[epoch 1] train_loss(avg per step)=1.3824 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.3797 qwk=('-0.0060', '-0.0095', '-0.0374') averageQWK=-0.0176 macroEMD=0.3652 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    4    0
     0    0    0   15    0
     0    2    0   76    0
     0   12    0  150    0
     0    0    0   64    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   16    0    0
     1    0   65    0    0
     7    0  197    1    0
     0    0   30    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   11   18    0    0
     0   40   71    0    0
     0   83   98    0    0
     0    0    1    0    0
[epoch 2] step 2/44: loss=0.6712 
[epoch 2] step 4/44: loss=0.6654 
[epoch 2] step 6/44: loss=0.6723 
[epoch 2] step 8/44: loss=0.6596 
[epoch 2] step 10/44: loss=0.6475 
[epoch 2] step 12/44: loss=0.6524 
[epoch 2] step 14/44: loss=0.6544 
[epoch 2] step 16/44: loss=0.6531 
[epoch 2] step 18/44: loss=0.6501 
[epoch 2] step 20/44: loss=0.6475 
[epoch 2] step 22/44: loss=0.6461 
[epoch 2] step 24/44: loss=0.6451 
[epoch 2] step 26/44: loss=0.6416 
[epoch 2] step 28/44: loss=0.6418 
[epoch 2] step 30/44: loss=0.6364 
[epoch 2] step 32/44: loss=0.6328 
[epoch 2] step 34/44: loss=0.6314 
[epoch 2] step 36/44: loss=0.6297 
[epoch 2] step 38/44: loss=0.6289 
[epoch 2] step 40/44: loss=0.6254 
[epoch 2] step 42/44: loss=0.6206 
[epoch 2] step 44/44: loss=0.6184 
[epoch 2] train_loss(avg per step)=1.2367 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.4207 qwk=('0.0331', '0.0208', '0.0872') averageQWK=0.0470 macroEMD=0.3280 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    1   61   16    0
     0    2  118   42    0
     0    2   58    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   13    3    0
     0    0   51   15    0
     0    0  155   50    0
     0    0   25    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    0   29    0    0
     0    1  107    3    0
     0    0  161   20    0
     0    0    1    0    0
[epoch 3] step 2/44: loss=0.5840 
[epoch 3] step 4/44: loss=0.5616 
[epoch 3] step 6/44: loss=0.5741 
[epoch 3] step 8/44: loss=0.5718 
[epoch 3] step 10/44: loss=0.5684 
[epoch 3] step 12/44: loss=0.5631 
[epoch 3] step 14/44: loss=0.5642 
[epoch 3] step 16/44: loss=0.5590 
[epoch 3] step 18/44: loss=0.5540 
[epoch 3] step 20/44: loss=0.5508 
[epoch 3] step 22/44: loss=0.5445 
[epoch 3] step 24/44: loss=0.5429 
[epoch 3] step 26/44: loss=0.5375 
[epoch 3] step 28/44: loss=0.5342 
[epoch 3] step 30/44: loss=0.5324 
[epoch 3] step 32/44: loss=0.5277 
[epoch 3] step 34/44: loss=0.5239 
[epoch 3] step 36/44: loss=0.5227 
[epoch 3] step 38/44: loss=0.5188 
[epoch 3] step 40/44: loss=0.5209 
[epoch 3] step 42/44: loss=0.5197 
[epoch 3] step 44/44: loss=0.5179 
[epoch 3] train_loss(avg per step)=1.0357 lambda[min,max]=[0.471351,1.000000]
[epoch 3] val_loss=1.5515 qwk=('0.1355', '0.1062', '0.1183') averageQWK=0.1200 macroEMD=0.3010 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0    9    5    1    0
     0   26   43    9    0
     0   19  101   42    0
     0   13   41   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   15    1    0
     0    0   56   10    0
     0    0  157   48    0
     0    0   19   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   22    0    0
     0    7  103    1    0
     0    6  165   10    0
     0    0    1    0    0
[epoch 4] step 2/44: loss=0.5373 
[epoch 4] step 4/44: loss=0.5010 
[epoch 4] step 6/44: loss=0.4940 
[epoch 4] step 8/44: loss=0.4914 
[epoch 4] step 10/44: loss=0.4863 
[epoch 4] step 12/44: loss=0.4835 
[epoch 4] step 14/44: loss=0.4889 
[epoch 4] step 16/44: loss=0.4850 
[epoch 4] step 18/44: loss=0.4804 
[epoch 4] step 20/44: loss=0.4835 
[epoch 4] step 22/44: loss=0.4899 
[epoch 4] step 24/44: loss=0.4950 
[epoch 4] step 26/44: loss=0.4934 
[epoch 4] step 28/44: loss=0.4951 
[epoch 4] step 30/44: loss=0.4885 
[epoch 4] step 32/44: loss=0.4895 
[epoch 4] step 34/44: loss=0.4904 
[epoch 4] step 36/44: loss=0.4939 
[epoch 4] step 38/44: loss=0.4947 
[epoch 4] step 40/44: loss=0.4932 
[epoch 4] step 42/44: loss=0.4924 
[epoch 4] step 44/44: loss=0.4924 
[epoch 4] train_loss(avg per step)=0.9849 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=1.4534 qwk=('0.1327', '0.1811', '0.2481') averageQWK=0.1873 macroEMD=0.2839 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    9   57   12    0
     0    3  115   44    0
     0    4   47   13    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    0   13    3    0
     0    0   46   20    0
     0    0  125   80    0
     0    0   13   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   23    6    0    0
     0   46   62    3    0
     0   34  121   26    0
     0    0    1    0    0
[epoch 5] step 2/44: loss=0.4522 
[epoch 5] step 4/44: loss=0.4682 
[epoch 5] step 6/44: loss=0.4975 
[epoch 5] step 8/44: loss=0.4980 
[epoch 5] step 10/44: loss=0.4931 
[epoch 5] step 12/44: loss=0.4898 
[epoch 5] step 14/44: loss=0.4906 
[epoch 5] step 16/44: loss=0.4973 
[epoch 5] step 18/44: loss=0.4966 
[epoch 5] step 20/44: loss=0.4909 
[epoch 5] step 22/44: loss=0.4908 
[epoch 5] step 24/44: loss=0.4889 
[epoch 5] step 26/44: loss=0.4915 
[epoch 5] step 28/44: loss=0.4870 
[epoch 5] step 30/44: loss=0.4882 
[epoch 5] step 32/44: loss=0.4876 
[epoch 5] step 34/44: loss=0.4889 
[epoch 5] step 36/44: loss=0.4898 
[epoch 5] step 38/44: loss=0.4851 
[epoch 5] step 40/44: loss=0.4854 
[epoch 5] step 42/44: loss=0.4871 
[epoch 5] step 44/44: loss=0.4851 
[epoch 5] train_loss(avg per step)=0.9702 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=1.5133 qwk=('0.0954', '0.0833', '0.2654') averageQWK=0.1481 macroEMD=0.2873 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    1   67   10    0
     0    0  134   28    0
     0    0   53   11    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   14    2    0
     0    0   58    8    0
     0    0  165   40    0
     0    0   22    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20    9    0    0
     0   19   91    1    0
     0   14  148   19    0
     0    0    1    0    0
[epoch 6] step 2/44: loss=0.4635 
[epoch 6] step 4/44: loss=0.4810 
[epoch 6] step 6/44: loss=0.4807 
[epoch 6] step 8/44: loss=0.4790 
[epoch 6] step 10/44: loss=0.4710 
[epoch 6] step 12/44: loss=0.4715 
[epoch 6] step 14/44: loss=0.4578 
[epoch 6] step 16/44: loss=0.4526 
[epoch 6] step 18/44: loss=0.4549 
[epoch 6] step 20/44: loss=0.4548 
[epoch 6] step 22/44: loss=0.4557 
[epoch 6] step 24/44: loss=0.4522 
[epoch 6] step 26/44: loss=0.4503 
[epoch 6] step 28/44: loss=0.4521 
[epoch 6] step 30/44: loss=0.4496 
[epoch 6] step 32/44: loss=0.4526 
[epoch 6] step 34/44: loss=0.4486 
[epoch 6] step 36/44: loss=0.4518 
[epoch 6] step 38/44: loss=0.4491 
[epoch 6] step 40/44: loss=0.4480 
[epoch 6] step 42/44: loss=0.4481 
[epoch 6] step 44/44: loss=0.4450 
[epoch 6] train_loss(avg per step)=0.8900 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=1.2352 qwk=('0.1912', '0.3516', '0.2675') averageQWK=0.2701 macroEMD=0.2685 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    5   52   21    0
     0    0   86   76    0
     0    3   34   27    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    1   12    3    0
     0    3   34   29    0
     0    0   78  127    0
     0    0    6   24    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    5   24    0    0
     0    3   94   14    0
     0    0  128   53    0
     0    0    0    1    0
[epoch 7] step 2/44: loss=0.4344 
[epoch 7] step 4/44: loss=0.4463 
[epoch 7] step 6/44: loss=0.4412 
[epoch 7] step 8/44: loss=0.4264 
[epoch 7] step 10/44: loss=0.4108 
[epoch 7] step 12/44: loss=0.4103 
[epoch 7] step 14/44: loss=0.4027 
[epoch 7] step 16/44: loss=0.4062 
[epoch 7] step 18/44: loss=0.4051 
[epoch 7] step 20/44: loss=0.4081 
[epoch 7] step 22/44: loss=0.4046 
[epoch 7] step 24/44: loss=0.4055 
[epoch 7] step 26/44: loss=0.4020 
[epoch 7] step 28/44: loss=0.3993 
[epoch 7] step 30/44: loss=0.4012 
[epoch 7] step 32/44: loss=0.3990 
[epoch 7] step 34/44: loss=0.4026 
[epoch 7] step 36/44: loss=0.4016 
[epoch 7] step 38/44: loss=0.4012 
[epoch 7] step 40/44: loss=0.4023 
[epoch 7] step 42/44: loss=0.4010 
[epoch 7] step 44/44: loss=0.3979 
[epoch 7] train_loss(avg per step)=0.7958 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.2751 qwk=('0.2101', '0.2477', '0.2397') averageQWK=0.2325 macroEMD=0.2584 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    1   14    0    0
     0    0   62   16    0
     0    0   83   79    0
     0    0   37   27    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    0   13    3    0
     0    0   40   26    0
     0    0  100  105    0
     0    0   10   20    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    6   23    0    0
     0    1  106    4    0
     0    0  142   39    0
     0    0    1    0    0
[epoch 8] step 2/44: loss=0.3251 
[epoch 8] step 4/44: loss=0.3287 
[epoch 8] step 6/44: loss=0.3613 
[epoch 8] step 8/44: loss=0.3675 
[epoch 8] step 10/44: loss=0.3561 
[epoch 8] step 12/44: loss=0.3609 
[epoch 8] step 14/44: loss=0.3564 
[epoch 8] step 16/44: loss=0.3568 
[epoch 8] step 18/44: loss=0.3578 
[epoch 8] step 20/44: loss=0.3592 
[epoch 8] step 22/44: loss=0.3566 
[epoch 8] step 24/44: loss=0.3573 
[epoch 8] step 26/44: loss=0.3532 
[epoch 8] step 28/44: loss=0.3536 
[epoch 8] step 30/44: loss=0.3519 
[epoch 8] step 32/44: loss=0.3510 
[epoch 8] step 34/44: loss=0.3477 
[epoch 8] step 36/44: loss=0.3445 
[epoch 8] step 38/44: loss=0.3441 
[epoch 8] step 40/44: loss=0.3444 
[epoch 8] step 42/44: loss=0.3425 
[epoch 8] step 44/44: loss=0.3425 
[epoch 8] train_loss(avg per step)=0.6849 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.5885 qwk=('0.1957', '0.2807', '0.2837') averageQWK=0.2533 macroEMD=0.2535 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    7    0    0
     0   16   52   10    0
     0    3  113   46    0
     0    5   43   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    8    8    0    0
     0   12   42   12    0
     0    5  139   61    0
     0    1   17   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   17   93    1    0
     0    5  153   23    0
     0    0    1    0    0
[epoch 9] step 2/44: loss=0.3485 
[epoch 9] step 4/44: loss=0.3406 
[epoch 9] step 6/44: loss=0.3090 
[epoch 9] step 8/44: loss=0.2941 
[epoch 9] step 10/44: loss=0.3022 
[epoch 9] step 12/44: loss=0.2988 
[epoch 9] step 14/44: loss=0.2996 
[epoch 9] step 16/44: loss=0.2951 
[epoch 9] step 18/44: loss=0.2915 
[epoch 9] step 20/44: loss=0.2923 
[epoch 9] step 22/44: loss=0.2908 
[epoch 9] step 24/44: loss=0.2917 
[epoch 9] step 26/44: loss=0.2947 
[epoch 9] step 28/44: loss=0.2953 
[epoch 9] step 30/44: loss=0.2948 
[epoch 9] step 32/44: loss=0.2945 
[epoch 9] step 34/44: loss=0.2960 
[epoch 9] step 36/44: loss=0.2947 
[epoch 9] step 38/44: loss=0.2911 
[epoch 9] step 40/44: loss=0.2877 
[epoch 9] step 42/44: loss=0.2893 
[epoch 9] step 44/44: loss=0.2891 
[epoch 9] train_loss(avg per step)=0.5783 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.6418 qwk=('0.2074', '0.2407', '0.3056') averageQWK=0.2512 macroEMD=0.2540 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7    8    0    0
     0   12   58    8    0
     0    3  114   45    0
     0    3   43   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    9    0    0
     0   13   46    7    0
     0    5  159   41    0
     0    1   20    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   12    0    0
     0   19   91    1    0
     0    5  152   24    0
     0    0    1    0    0
[epoch 10] step 2/44: loss=0.2878 
[epoch 10] step 4/44: loss=0.3052 
[epoch 10] step 6/44: loss=0.2826 
[epoch 10] step 8/44: loss=0.2821 
[epoch 10] step 10/44: loss=0.2734 
[epoch 10] step 12/44: loss=0.2700 
[epoch 10] step 14/44: loss=0.2741 
[epoch 10] step 16/44: loss=0.2676 
[epoch 10] step 18/44: loss=0.2636 
[epoch 10] step 20/44: loss=0.2653 
[epoch 10] step 22/44: loss=0.2634 
[epoch 10] step 24/44: loss=0.2632 
[epoch 10] step 26/44: loss=0.2661 
[epoch 10] step 28/44: loss=0.2643 
[epoch 10] step 30/44: loss=0.2629 
[epoch 10] step 32/44: loss=0.2635 
[epoch 10] step 34/44: loss=0.2627 
[epoch 10] step 36/44: loss=0.2616 
[epoch 10] step 38/44: loss=0.2595 
[epoch 10] step 40/44: loss=0.2609 
[epoch 10] step 42/44: loss=0.2574 
[epoch 10] step 44/44: loss=0.2547 
[epoch 10] train_loss(avg per step)=0.5093 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.4055 qwk=('0.2840', '0.3120', '0.3100') averageQWK=0.3020 macroEMD=0.2476 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5   10    0    0
     0    5   57   14    2
     0    2   86   68    6
     0    0   33   28    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    3   13    0    0
     0    5   42   19    0
     0    1  116   88    0
     0    0   13   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0    6   99    6    0
     0    4  140   37    0
     0    0    1    0    0
[epoch 11] step 2/44: loss=0.1883 
[epoch 11] step 4/44: loss=0.2045 
[epoch 11] step 6/44: loss=0.2099 
[epoch 11] step 8/44: loss=0.2162 
[epoch 11] step 10/44: loss=0.2132 
[epoch 11] step 12/44: loss=0.2191 
[epoch 11] step 14/44: loss=0.2192 
[epoch 11] step 16/44: loss=0.2185 
[epoch 11] step 18/44: loss=0.2178 
[epoch 11] step 20/44: loss=0.2147 
[epoch 11] step 22/44: loss=0.2190 
[epoch 11] step 24/44: loss=0.2165 
[epoch 11] step 26/44: loss=0.2179 
[epoch 11] step 28/44: loss=0.2173 
[epoch 11] step 30/44: loss=0.2136 
[epoch 11] step 32/44: loss=0.2111 
[epoch 11] step 34/44: loss=0.2103 
[epoch 11] step 36/44: loss=0.2126 
[epoch 11] step 38/44: loss=0.2122 
[epoch 11] step 40/44: loss=0.2094 
[epoch 11] step 42/44: loss=0.2100 
[epoch 11] step 44/44: loss=0.2115 
[epoch 11] train_loss(avg per step)=0.4230 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=1.6044 qwk=('0.1757', '0.2595', '0.3120') averageQWK=0.2491 macroEMD=0.2481 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5   10    0    0
     0    7   63    7    1
     0    2  119   40    1
     0    2   46   15    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   12    0    0
     0    5   51   10    0
     0    1  146   58    0
     0    0   18   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   11    0    0
     0   22   85    4    0
     0   11  135   35    0
     0    0    1    0    0
[epoch 12] step 2/44: loss=0.1916 
[epoch 12] step 4/44: loss=0.1989 
[epoch 12] step 6/44: loss=0.2026 
[epoch 12] step 8/44: loss=0.1965 
[epoch 12] step 10/44: loss=0.1832 
[epoch 12] step 12/44: loss=0.1890 
[epoch 12] step 14/44: loss=0.1871 
[epoch 12] step 16/44: loss=0.1861 
[epoch 12] step 18/44: loss=0.1882 
[epoch 12] step 20/44: loss=0.1902 
[epoch 12] step 22/44: loss=0.1904 
[epoch 12] step 24/44: loss=0.1839 
[epoch 12] step 26/44: loss=0.1875 
[epoch 12] step 28/44: loss=0.1837 
[epoch 12] step 30/44: loss=0.1822 
[epoch 12] step 32/44: loss=0.1811 
[epoch 12] step 34/44: loss=0.1810 
[epoch 12] step 36/44: loss=0.1783 
[epoch 12] step 38/44: loss=0.1779 
[epoch 12] step 40/44: loss=0.1790 
[epoch 12] step 42/44: loss=0.1802 
[epoch 12] step 44/44: loss=0.1832 
[epoch 12] train_loss(avg per step)=0.3664 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=1.6613 qwk=('0.2182', '0.1957', '0.3069') averageQWK=0.2403 macroEMD=0.2506 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5   10    0    0
     0    5   65    7    1
     0    2  117   42    1
     0    0   42   21    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   12    0    0
     0    5   54    7    0
     0    2  162   41    0
     0    0   24    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0    7  102    2    0
     0    2  150   29    0
     0    0    1    0    0
[epoch 13] step 2/44: loss=0.1430 
[epoch 13] step 4/44: loss=0.1367 
[epoch 13] step 6/44: loss=0.1424 
[epoch 13] step 8/44: loss=0.1612 
[epoch 13] step 10/44: loss=0.1639 
[epoch 13] step 12/44: loss=0.1661 
[epoch 13] step 14/44: loss=0.1725 
[epoch 13] step 16/44: loss=0.1703 
[epoch 13] step 18/44: loss=0.1692 
[epoch 13] step 20/44: loss=0.1642 
[epoch 13] step 22/44: loss=0.1638 
[epoch 13] step 24/44: loss=0.1623 
[epoch 13] step 26/44: loss=0.1639 
[epoch 13] step 28/44: loss=0.1638 
[epoch 13] step 30/44: loss=0.1646 
[epoch 13] step 32/44: loss=0.1605 
[epoch 13] step 34/44: loss=0.1598 
[epoch 13] step 36/44: loss=0.1601 
[epoch 13] step 38/44: loss=0.1621 
[epoch 13] step 40/44: loss=0.1594 
[epoch 13] step 42/44: loss=0.1583 
[epoch 13] step 44/44: loss=0.1578 
[epoch 13] train_loss(avg per step)=0.3156 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=1.4645 qwk=('0.2877', '0.3301', '0.3255') averageQWK=0.3144 macroEMD=0.2443 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    2   13    0    0
     0    5   56   15    2
     0    1   77   78    6
     0    0   29   32    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    3   13    0    0
     0    4   45   17    0
     0    1  107   97    0
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   13    0    0
     0   19   88    4    0
     0    7  136   38    0
     0    0    1    0    0
[epoch 14] step 2/44: loss=0.1065 
[epoch 14] step 4/44: loss=0.1146 
[epoch 14] step 6/44: loss=0.1156 
[epoch 14] step 8/44: loss=0.1254 
[epoch 14] step 10/44: loss=0.1224 
[epoch 14] step 12/44: loss=0.1174 
[epoch 14] step 14/44: loss=0.1207 
[epoch 14] step 16/44: loss=0.1242 
[epoch 14] step 18/44: loss=0.1244 
[epoch 14] step 20/44: loss=0.1248 
[epoch 14] step 22/44: loss=0.1282 
[epoch 14] step 24/44: loss=0.1300 
[epoch 14] step 26/44: loss=0.1307 
[epoch 14] step 28/44: loss=0.1260 
[epoch 14] step 30/44: loss=0.1246 
[epoch 14] step 32/44: loss=0.1225 
[epoch 14] step 34/44: loss=0.1215 
[epoch 14] step 36/44: loss=0.1212 
[epoch 14] step 38/44: loss=0.1233 
[epoch 14] step 40/44: loss=0.1212 
[epoch 14] step 42/44: loss=0.1209 
[epoch 14] step 44/44: loss=0.1176 
[epoch 14] train_loss(avg per step)=0.2351 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=1.6740 qwk=('0.2490', '0.2774', '0.2744') averageQWK=0.2669 macroEMD=0.2480 tailR0=('0.0156', '0.1667', '0.0000') tailR0avg=0.0608
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5   10    0    0
     0   12   56    8    2
     0    2  100   57    3
     0    3   35   24    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     0    6   10    0    0
     0   11   47    8    0
     0    4  143   58    0
     0    1   20    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   19   10    0    0
     0   32   76    3    0
     0   20  131   30    0
     0    0    1    0    0
[epoch 15] step 2/44: loss=0.1332 
[epoch 15] step 4/44: loss=0.1136 
[epoch 15] step 6/44: loss=0.1196 
[epoch 15] step 8/44: loss=0.1046 
[epoch 15] step 10/44: loss=0.1071 
[epoch 15] step 12/44: loss=0.1070 
[epoch 15] step 14/44: loss=0.1075 
[epoch 15] step 16/44: loss=0.1017 
[epoch 15] step 18/44: loss=0.1003 
[epoch 15] step 20/44: loss=0.0989 
[epoch 15] step 22/44: loss=0.0981 
[epoch 15] step 24/44: loss=0.0977 
[epoch 15] step 26/44: loss=0.0964 
[epoch 15] step 28/44: loss=0.0961 
[epoch 15] step 30/44: loss=0.0943 
[epoch 15] step 32/44: loss=0.0927 
[epoch 15] step 34/44: loss=0.0933 
[epoch 15] step 36/44: loss=0.0912 
[epoch 15] step 38/44: loss=0.0907 
[epoch 15] step 40/44: loss=0.0904 
[epoch 15] step 42/44: loss=0.0911 
[epoch 15] step 44/44: loss=0.0898 
[epoch 15] train_loss(avg per step)=0.1797 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=1.5780 qwk=('0.3093', '0.3055', '0.2909') averageQWK=0.3019 macroEMD=0.2363 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7    8    0    0
     0   10   55   12    1
     0    2   87   69    4
     0    2   29   32    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    9    0    0
     0   10   44   12    0
     0    5  130   70    0
     0    1   14   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    9   20    0    0
     0    6  100    5    0
     0    4  128   49    0
     0    0    1    0    0
[epoch 16] step 2/44: loss=0.0643 
[epoch 16] step 4/44: loss=0.0756 
[epoch 16] step 6/44: loss=0.0675 
[epoch 16] step 8/44: loss=0.0712 
[epoch 16] step 10/44: loss=0.0730 
[epoch 16] step 12/44: loss=0.0714 
[epoch 16] step 14/44: loss=0.0805 
[epoch 16] step 16/44: loss=0.0776 
[epoch 16] step 18/44: loss=0.0757 
[epoch 16] step 20/44: loss=0.0732 
[epoch 16] step 22/44: loss=0.0748 
[epoch 16] step 24/44: loss=0.0735 
[epoch 16] step 26/44: loss=0.0731 
[epoch 16] step 28/44: loss=0.0717 
[epoch 16] step 30/44: loss=0.0723 
[epoch 16] step 32/44: loss=0.0747 
[epoch 16] step 34/44: loss=0.0735 
[epoch 16] step 36/44: loss=0.0714 
[epoch 16] step 38/44: loss=0.0701 
[epoch 16] step 40/44: loss=0.0709 
[epoch 16] step 42/44: loss=0.0703 
[epoch 16] step 44/44: loss=0.0706 
[epoch 16] train_loss(avg per step)=0.1411 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=1.7167 qwk=('0.2136', '0.2642', '0.3192') averageQWK=0.2657 macroEMD=0.2442 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   11    0    0
     0    7   61    9    1
     0    2  110   46    4
     0    2   40   19    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    8    7    1    0
     0   11   42   13    0
     1    4  130   70    0
     0    1   19   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   21   86    4    0
     0    9  131   41    0
     0    0    1    0    0
[epoch 17] step 2/44: loss=0.0547 
[epoch 17] step 4/44: loss=0.0289 
[epoch 17] step 6/44: loss=0.0365 
[epoch 17] step 8/44: loss=0.0367 
[epoch 17] step 10/44: loss=0.0437 
[epoch 17] step 12/44: loss=0.0433 
[epoch 17] step 14/44: loss=0.0402 
[epoch 17] step 16/44: loss=0.0386 
[epoch 17] step 18/44: loss=0.0383 
[epoch 17] step 20/44: loss=0.0373 
[epoch 17] step 22/44: loss=0.0370 
[epoch 17] step 24/44: loss=0.0356 
[epoch 17] step 26/44: loss=0.0340 
[epoch 17] step 28/44: loss=0.0340 
[epoch 17] step 30/44: loss=0.0331 
[epoch 17] step 32/44: loss=0.0338 
[epoch 17] step 34/44: loss=0.0339 
[epoch 17] step 36/44: loss=0.0347 
[epoch 17] step 38/44: loss=0.0367 
[epoch 17] step 40/44: loss=0.0368 
[epoch 17] step 42/44: loss=0.0361 
[epoch 17] step 44/44: loss=0.0362 
[epoch 17] train_loss(avg per step)=0.0724 lambda[min,max]=[0.465192,1.000000]
[epoch 17] val_loss=1.7431 qwk=('0.2119', '0.2781', '0.2572') averageQWK=0.2491 macroEMD=0.2549 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   13    0    0
     0    6   61   10    1
     0    1  108   52    1
     0    2   36   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    9    0    0
     0    6   50   10    0
     1    1  140   63    0
     0    0   19   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   13   16    0    0
     0   14   93    4    0
     0    8  140   33    0
     0    0    1    0    0
[epoch 18] step 2/44: loss=-0.0065 
[epoch 18] step 4/44: loss=-0.0036 
[epoch 18] step 6/44: loss=0.0021 
[epoch 18] step 8/44: loss=0.0073 
[epoch 18] step 10/44: loss=0.0174 
[epoch 18] step 12/44: loss=0.0182 
[epoch 18] step 14/44: loss=0.0166 
[epoch 18] step 16/44: loss=0.0165 
[epoch 18] step 18/44: loss=0.0141 
[epoch 18] step 20/44: loss=0.0143 
[epoch 18] step 22/44: loss=0.0135 
[epoch 18] step 24/44: loss=0.0130 
[epoch 18] step 26/44: loss=0.0121 
[epoch 18] step 28/44: loss=0.0120 
[epoch 18] step 30/44: loss=0.0105 
[epoch 18] step 32/44: loss=0.0104 
[epoch 18] step 34/44: loss=0.0098 
[epoch 18] step 36/44: loss=0.0090 
[epoch 18] step 38/44: loss=0.0101 
[epoch 18] step 40/44: loss=0.0097 
[epoch 18] step 42/44: loss=0.0108 
[epoch 18] step 44/44: loss=0.0131 
[epoch 18] train_loss(avg per step)=0.0262 lambda[min,max]=[0.397156,1.000000]
[epoch 18] val_loss=1.6867 qwk=('0.2591', '0.2803', '0.3158') averageQWK=0.2851 macroEMD=0.2445 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   13    0    0
     0    6   59   12    1
     0    1   92   65    4
     0    2   30   31    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    9    0    0
     0    5   47   14    0
     1    4  129   71    0
     0    0   17   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   11    0    0
     0   25   80    6    0
     0   19  115   47    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=-0.0070 
[epoch 19] step 4/44: loss=-0.0061 
[epoch 19] step 6/44: loss=-0.0078 
[epoch 19] step 8/44: loss=-0.0128 
[epoch 19] step 10/44: loss=-0.0117 
[epoch 19] step 12/44: loss=-0.0089 
[epoch 19] step 14/44: loss=-0.0096 
[epoch 19] step 16/44: loss=-0.0116 
[epoch 19] step 18/44: loss=-0.0093 
[epoch 19] step 20/44: loss=-0.0110 
[epoch 19] step 22/44: loss=-0.0089 
[epoch 19] step 24/44: loss=-0.0090 
[epoch 19] step 26/44: loss=-0.0086 
[epoch 19] step 28/44: loss=-0.0103 
[epoch 19] step 30/44: loss=-0.0102 
[epoch 19] step 32/44: loss=-0.0112 
[epoch 19] step 34/44: loss=-0.0114 
[epoch 19] step 36/44: loss=-0.0107 
[epoch 19] step 38/44: loss=-0.0120 
[epoch 19] step 40/44: loss=-0.0119 
[epoch 19] step 42/44: loss=-0.0115 
[epoch 19] step 44/44: loss=-0.0133 
[epoch 19] train_loss(avg per step)=-0.0267 lambda[min,max]=[0.352482,1.000000]
[epoch 19] val_loss=1.6932 qwk=('0.2415', '0.2667', '0.3027') averageQWK=0.2703 macroEMD=0.2443 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   10    2    0
     0    6   52   19    1
     0    1   82   76    3
     0    2   30   30    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    3   13    0    0
     0    4   51   11    0
     0    0  134   71    0
     0    0   17   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   10   19    0    0
     0    7   99    5    0
     0    5  128   48    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=-0.0220 
[epoch 20] step 4/44: loss=-0.0311 
[epoch 20] step 6/44: loss=-0.0269 
[epoch 20] step 8/44: loss=-0.0281 
[epoch 20] step 10/44: loss=-0.0221 
[epoch 20] step 12/44: loss=-0.0231 
[epoch 20] step 14/44: loss=-0.0252 
[epoch 20] step 16/44: loss=-0.0286 
[epoch 20] step 18/44: loss=-0.0264 
[epoch 20] step 20/44: loss=-0.0247 
[epoch 20] step 22/44: loss=-0.0213 
[epoch 20] step 24/44: loss=-0.0226 
[epoch 20] step 26/44: loss=-0.0237 
[epoch 20] step 28/44: loss=-0.0227 
[epoch 20] step 30/44: loss=-0.0211 
[epoch 20] step 32/44: loss=-0.0213 
[epoch 20] step 34/44: loss=-0.0228 
[epoch 20] step 36/44: loss=-0.0234 
[epoch 20] step 38/44: loss=-0.0239 
[epoch 20] step 40/44: loss=-0.0240 
[epoch 20] step 42/44: loss=-0.0246 
[epoch 20] step 44/44: loss=-0.0256 
[epoch 20] train_loss(avg per step)=-0.0511 lambda[min,max]=[0.387370,1.000000]
[epoch 20] val_loss=1.9239 qwk=('0.2056', '0.2482', '0.2970') averageQWK=0.2503 macroEMD=0.2374 tailR0=('0.1328', '0.0000', '0.0000') tailR0avg=0.0443
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0    3   11    1    0
     0    7   57   13    1
     0    2   97   62    1
     0    2   39   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    9    0    0
     0    7   54    5    0
     0    4  154   47    0
     0    0   22    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   12    0    0
     0   13   95    3    0
     0   13  130   38    0
     0    0    1    0    0
[epoch 21] step 2/44: loss=-0.0435 
[epoch 21] step 4/44: loss=-0.0359 
[epoch 21] step 6/44: loss=-0.0416 
[epoch 21] step 8/44: loss=-0.0464 
[epoch 21] step 10/44: loss=-0.0477 
[epoch 21] step 12/44: loss=-0.0396 
[epoch 21] step 14/44: loss=-0.0393 
[epoch 21] step 16/44: loss=-0.0381 
[epoch 21] step 18/44: loss=-0.0387 
[epoch 21] step 20/44: loss=-0.0412 
[epoch 21] step 22/44: loss=-0.0415 
[epoch 21] step 24/44: loss=-0.0413 
[epoch 21] step 26/44: loss=-0.0413 
[epoch 21] step 28/44: loss=-0.0413 
[epoch 21] step 30/44: loss=-0.0415 
[epoch 21] step 32/44: loss=-0.0398 
[epoch 21] step 34/44: loss=-0.0404 
[epoch 21] step 36/44: loss=-0.0408 
[epoch 21] step 38/44: loss=-0.0412 
[epoch 21] step 40/44: loss=-0.0422 
[epoch 21] step 42/44: loss=-0.0424 
[epoch 21] step 44/44: loss=-0.0428 
[epoch 21] train_loss(avg per step)=-0.0857 lambda[min,max]=[0.370205,1.000000]
[epoch 21] val_loss=1.8002 qwk=('0.1655', '0.3612', '0.2567') averageQWK=0.2611 macroEMD=0.2423 tailR0=('0.1328', '0.1667', '0.0000') tailR0avg=0.0998
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0    2   13    0    0
     0    3   67    7    1
     0    0  121   38    3
     0    0   49   14    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     0    6    9    1    0
     0    6   45   15    0
     0    2  103  100    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    8   21    0    0
     0    5  102    4    0
     0    3  140   38    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=-0.0492 
[epoch 22] step 4/44: loss=-0.0463 
[epoch 22] step 6/44: loss=-0.0456 
[epoch 22] step 8/44: loss=-0.0505 
[epoch 22] step 10/44: loss=-0.0541 
[epoch 22] step 12/44: loss=-0.0529 
[epoch 22] step 14/44: loss=-0.0535 
[epoch 22] step 16/44: loss=-0.0547 
[epoch 22] step 18/44: loss=-0.0548 
[epoch 22] step 20/44: loss=-0.0523 
[epoch 22] step 22/44: loss=-0.0506 
[epoch 22] step 24/44: loss=-0.0485 
[epoch 22] step 26/44: loss=-0.0475 
[epoch 22] step 28/44: loss=-0.0488 
[epoch 22] step 30/44: loss=-0.0496 
[epoch 22] step 32/44: loss=-0.0483 
[epoch 22] step 34/44: loss=-0.0481 
[epoch 22] step 36/44: loss=-0.0481 
[epoch 22] step 38/44: loss=-0.0486 
[epoch 22] step 40/44: loss=-0.0478 
[epoch 22] step 42/44: loss=-0.0486 
[epoch 22] step 44/44: loss=-0.0498 
[epoch 22] train_loss(avg per step)=-0.0997 lambda[min,max]=[0.387591,1.000000]
[epoch 22] val_loss=1.8849 qwk=('0.1531', '0.3156', '0.3231') averageQWK=0.2639 macroEMD=0.2344 tailR0=('0.0078', '0.1667', '0.0000') tailR0avg=0.0582
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   11    1    0
     0    8   56   13    1
     0    3  111   44    4
     0    2   44   17    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     0    5   11    0    0
     0    7   49   10    0
     1    3  134   67    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0   10   95    6    0
     0    8  128   45    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=-0.0599 
[epoch 23] step 4/44: loss=-0.0684 
[epoch 23] step 6/44: loss=-0.0658 
[epoch 23] step 8/44: loss=-0.0633 
[epoch 23] step 10/44: loss=-0.0646 
[epoch 23] step 12/44: loss=-0.0650 
[epoch 23] step 14/44: loss=-0.0646 
[epoch 23] step 16/44: loss=-0.0671 
[epoch 23] step 18/44: loss=-0.0672 
[epoch 23] step 20/44: loss=-0.0645 
[epoch 23] step 22/44: loss=-0.0645 
[epoch 23] step 24/44: loss=-0.0647 
[epoch 23] step 26/44: loss=-0.0638 
[epoch 23] step 28/44: loss=-0.0629 
[epoch 23] step 30/44: loss=-0.0624 
[epoch 23] step 32/44: loss=-0.0623 
[epoch 23] step 34/44: loss=-0.0620 
[epoch 23] step 36/44: loss=-0.0626 
[epoch 23] step 38/44: loss=-0.0622 
[epoch 23] step 40/44: loss=-0.0614 
[epoch 23] step 42/44: loss=-0.0608 
[epoch 23] step 44/44: loss=-0.0612 
[epoch 23] train_loss(avg per step)=-0.1224 lambda[min,max]=[0.358431,1.000000]
[epoch 23] val_loss=1.7914 qwk=('0.1799', '0.3199', '0.3197') averageQWK=0.2732 macroEMD=0.2397 tailR0=('0.0234', '0.0833', '0.0000') tailR0avg=0.0356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   11    1    0
     0    7   56   12    3
     0    2  103   53    4
     0    3   38   20    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    8    6    2    0
     0    5   46   15    0
     1    2  119   83    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1    5   23    0    0
     0    6   99    6    0
     0    2  123   56    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=-0.0689 
[epoch 24] step 4/44: loss=-0.0723 
[epoch 24] step 6/44: loss=-0.0754 
[epoch 24] step 8/44: loss=-0.0742 
[epoch 24] step 10/44: loss=-0.0735 
[epoch 24] step 12/44: loss=-0.0740 
[epoch 24] step 14/44: loss=-0.0728 
[epoch 24] step 16/44: loss=-0.0727 
[epoch 24] step 18/44: loss=-0.0743 
[epoch 24] step 20/44: loss=-0.0724 
[epoch 24] step 22/44: loss=-0.0714 
[epoch 24] step 24/44: loss=-0.0702 
[epoch 24] step 26/44: loss=-0.0709 
[epoch 24] step 28/44: loss=-0.0710 
[epoch 24] step 30/44: loss=-0.0707 
[epoch 24] step 32/44: loss=-0.0704 
[epoch 24] step 34/44: loss=-0.0712 
[epoch 24] step 36/44: loss=-0.0714 
[epoch 24] step 38/44: loss=-0.0723 
[epoch 24] step 40/44: loss=-0.0719 
[epoch 24] step 42/44: loss=-0.0723 
[epoch 24] step 44/44: loss=-0.0722 
[epoch 24] train_loss(avg per step)=-0.1444 lambda[min,max]=[0.355156,1.000000]
[epoch 24] val_loss=1.9158 qwk=('0.1657', '0.2843', '0.3466') averageQWK=0.2655 macroEMD=0.2332 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   11    1    0
     0    6   58   13    1
     0    2  106   52    2
     0    2   42   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   12    0    0
     0    6   48   12    0
     1    1  132   71    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   14   14    0    0
     0    8   98    5    0
     0    6  131   44    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=-0.0854 
[epoch 25] step 4/44: loss=-0.0799 
[epoch 25] step 6/44: loss=-0.0786 
[epoch 25] step 8/44: loss=-0.0779 
[epoch 25] step 10/44: loss=-0.0822 
[epoch 25] step 12/44: loss=-0.0833 
[epoch 25] step 14/44: loss=-0.0818 
[epoch 25] step 16/44: loss=-0.0821 
[epoch 25] step 18/44: loss=-0.0808 
[epoch 25] step 20/44: loss=-0.0808 
[epoch 25] step 22/44: loss=-0.0808 
[epoch 25] step 24/44: loss=-0.0795 
[epoch 25] step 26/44: loss=-0.0793 
[epoch 25] step 28/44: loss=-0.0780 
[epoch 25] step 30/44: loss=-0.0764 
[epoch 25] step 32/44: loss=-0.0763 
[epoch 25] step 34/44: loss=-0.0765 
[epoch 25] step 36/44: loss=-0.0770 
[epoch 25] step 38/44: loss=-0.0772 
[epoch 25] step 40/44: loss=-0.0771 
[epoch 25] step 42/44: loss=-0.0768 
[epoch 25] step 44/44: loss=-0.0769 
[epoch 25] train_loss(avg per step)=-0.1539 lambda[min,max]=[0.424228,1.000000]
[epoch 25] val_loss=1.9139 qwk=('0.1326', '0.3291', '0.3197') averageQWK=0.2605 macroEMD=0.2352 tailR0=('0.0156', '0.1667', '0.0000') tailR0avg=0.0608
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   11    1    0
     0    7   57   12    2
     0    2  110   47    3
     0    2   48   12    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     0    8    8    0    0
     0    7   49   10    0
     0    2  139   64    0
     0    0   17   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1   13   15    0    0
     0   12   92    7    0
     0   13  113   55    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=-0.0950 
[epoch 26] step 4/44: loss=-0.0906 
[epoch 26] step 6/44: loss=-0.0908 
[epoch 26] step 8/44: loss=-0.0904 
[epoch 26] step 10/44: loss=-0.0912 
[epoch 26] step 12/44: loss=-0.0902 
[epoch 26] step 14/44: loss=-0.0887 
[epoch 26] step 16/44: loss=-0.0891 
[epoch 26] step 18/44: loss=-0.0875 
[epoch 26] step 20/44: loss=-0.0858 
[epoch 26] step 22/44: loss=-0.0867 
[epoch 26] step 24/44: loss=-0.0870 
[epoch 26] step 26/44: loss=-0.0871 
[epoch 26] step 28/44: loss=-0.0870 
[epoch 26] step 30/44: loss=-0.0876 
[epoch 26] step 32/44: loss=-0.0877 
[epoch 26] step 34/44: loss=-0.0879 
[epoch 26] step 36/44: loss=-0.0875 
[epoch 26] step 38/44: loss=-0.0869 
[epoch 26] step 40/44: loss=-0.0869 
[epoch 26] step 42/44: loss=-0.0858 
[epoch 26] step 44/44: loss=-0.0863 
[epoch 26] train_loss(avg per step)=-0.1726 lambda[min,max]=[0.416453,1.000000]
[epoch 26] val_loss=1.8247 qwk=('0.2078', '0.3940', '0.2811') averageQWK=0.2943 macroEMD=0.2348 tailR0=('0.0391', '0.1667', '0.0000') tailR0avg=0.0686
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    5   57   13    3
     0    1   96   60    5
     0    2   36   21    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     0    7    8    1    0
     0    6   42   18    0
     0    2   96  107    0
     0    0   13   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   10   18    0    0
     0    5  102    4    0
     0    5  139   37    0
     0    0    1    0    0
[epoch 27] step 2/44: loss=-0.0842 
[epoch 27] step 4/44: loss=-0.0906 
[epoch 27] step 6/44: loss=-0.0915 
[epoch 27] step 8/44: loss=-0.0902 
[epoch 27] step 10/44: loss=-0.0897 
[epoch 27] step 12/44: loss=-0.0904 
[epoch 27] step 14/44: loss=-0.0901 
[epoch 27] step 16/44: loss=-0.0893 
[epoch 27] step 18/44: loss=-0.0876 
[epoch 27] step 20/44: loss=-0.0875 
[epoch 27] step 22/44: loss=-0.0866 
[epoch 27] step 24/44: loss=-0.0875 
[epoch 27] step 26/44: loss=-0.0883 
[epoch 27] step 28/44: loss=-0.0894 
[epoch 27] step 30/44: loss=-0.0899 
[epoch 27] step 32/44: loss=-0.0894 
[epoch 27] step 34/44: loss=-0.0898 
[epoch 27] step 36/44: loss=-0.0893 
[epoch 27] step 38/44: loss=-0.0893 
[epoch 27] step 40/44: loss=-0.0890 
[epoch 27] step 42/44: loss=-0.0893 
[epoch 27] step 44/44: loss=-0.0897 
[epoch 27] train_loss(avg per step)=-0.1793 lambda[min,max]=[0.388077,1.000000]
[epoch 27] val_loss=1.8915 qwk=('0.2476', '0.3306', '0.2680') averageQWK=0.2821 macroEMD=0.2389 tailR0=('0.0234', '0.1667', '0.0000') tailR0avg=0.0634
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    7   54   14    3
     0    1   85   71    5
     0    2   30   29    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     0    3   13    0    0
     0    5   48   13    0
     0    1  122   82    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1   10   18    0    0
     0    6  101    4    0
     0    6  136   39    0
     0    0    1    0    0
[epoch 28] step 2/44: loss=-0.0936 
[epoch 28] step 4/44: loss=-0.0937 
[epoch 28] step 6/44: loss=-0.0896 
[epoch 28] step 8/44: loss=-0.0880 
[epoch 28] step 10/44: loss=-0.0885 
[epoch 28] step 12/44: loss=-0.0903 
[epoch 28] step 14/44: loss=-0.0911 
[epoch 28] step 16/44: loss=-0.0916 
[epoch 28] step 18/44: loss=-0.0925 
[epoch 28] step 20/44: loss=-0.0927 
[epoch 28] step 22/44: loss=-0.0928 
[epoch 28] step 24/44: loss=-0.0928 
[epoch 28] step 26/44: loss=-0.0931 
[epoch 28] step 28/44: loss=-0.0928 
[epoch 28] step 30/44: loss=-0.0932 
[epoch 28] step 32/44: loss=-0.0931 
[epoch 28] step 34/44: loss=-0.0930 
[epoch 28] step 36/44: loss=-0.0932 
[epoch 28] step 38/44: loss=-0.0933 
[epoch 28] step 40/44: loss=-0.0932 
[epoch 28] step 42/44: loss=-0.0934 
[epoch 28] step 44/44: loss=-0.0924 
[epoch 28] train_loss(avg per step)=-0.1848 lambda[min,max]=[0.349835,1.000000]
[epoch 28] val_loss=1.8219 qwk=('0.2096', '0.3877', '0.3116') averageQWK=0.3030 macroEMD=0.2355 tailR0=('0.0156', '0.1833', '0.0000') tailR0avg=0.0663
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   13    0    0
     0    6   57   13    2
     0    1   98   60    3
     0    2   36   24    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     0    8    8    0    0
     0    7   42   17    0
     0    1  108   96    0
     0    0   15   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1    7   21    0    0
     0    5   99    7    0
     0    4  123   54    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=-0.0959 
[epoch 29] step 4/44: loss=-0.0946 
[epoch 29] step 6/44: loss=-0.0949 
[epoch 29] step 8/44: loss=-0.0950 
[epoch 29] step 10/44: loss=-0.0939 
[epoch 29] step 12/44: loss=-0.0938 
[epoch 29] step 14/44: loss=-0.0953 
[epoch 29] step 16/44: loss=-0.0959 
[epoch 29] step 18/44: loss=-0.0959 
[epoch 29] step 20/44: loss=-0.0952 
[epoch 29] step 22/44: loss=-0.0954 
[epoch 29] step 24/44: loss=-0.0956 
[epoch 29] step 26/44: loss=-0.0954 
[epoch 29] step 28/44: loss=-0.0949 
[epoch 29] step 30/44: loss=-0.0950 
[epoch 29] step 32/44: loss=-0.0949 
[epoch 29] step 34/44: loss=-0.0954 
[epoch 29] step 36/44: loss=-0.0954 
[epoch 29] step 38/44: loss=-0.0952 
[epoch 29] step 40/44: loss=-0.0946 
[epoch 29] step 42/44: loss=-0.0948 
[epoch 29] step 44/44: loss=-0.0942 
[epoch 29] train_loss(avg per step)=-0.1883 lambda[min,max]=[0.405368,1.000000]
[epoch 29] val_loss=1.9488 qwk=('0.1525', '0.3548', '0.3360') averageQWK=0.2811 macroEMD=0.2345 tailR0=('0.0312', '0.0000', '0.0000') tailR0avg=0.0104
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   13    0    0
     0    6   59   10    3
     0    1  117   37    7
     0    2   45   13    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    8    8    0    0
     0    8   42   16    0
     0    2  111   92    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   11   17    0    0
     0    5  102    4    0
     0    5  130   46    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=-0.1064 
[epoch 30] step 4/44: loss=-0.1002 
[epoch 30] step 6/44: loss=-0.0930 
[epoch 30] step 8/44: loss=-0.0941 
[epoch 30] step 10/44: loss=-0.0940 
[epoch 30] step 12/44: loss=-0.0944 
[epoch 30] step 14/44: loss=-0.0950 
[epoch 30] step 16/44: loss=-0.0943 
[epoch 30] step 18/44: loss=-0.0924 
[epoch 30] step 20/44: loss=-0.0936 
[epoch 30] step 22/44: loss=-0.0939 
[epoch 30] step 24/44: loss=-0.0938 
[epoch 30] step 26/44: loss=-0.0945 
[epoch 30] step 28/44: loss=-0.0951 
[epoch 30] step 30/44: loss=-0.0948 
[epoch 30] step 32/44: loss=-0.0953 
[epoch 30] step 34/44: loss=-0.0957 
[epoch 30] step 36/44: loss=-0.0958 
[epoch 30] step 38/44: loss=-0.0958 
[epoch 30] step 40/44: loss=-0.0957 
[epoch 30] step 42/44: loss=-0.0959 
[epoch 30] step 44/44: loss=-0.0961 
[epoch 30] train_loss(avg per step)=-0.1922 lambda[min,max]=[0.358132,1.000000]
[epoch 30] val_loss=2.0304 qwk=('0.1660', '0.3152', '0.3188') averageQWK=0.2667 macroEMD=0.2364 tailR0=('0.0078', '0.1667', '0.0000') tailR0avg=0.0582
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    7   57   13    1
     0    1  110   47    4
     0    2   41   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     0    5   11    0    0
     0    7   50    9    0
     0    1  136   68    0
     0    0   18   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1   11   17    0    0
     0    7   99    5    0
     0    5  130   46    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=-0.1043 
[epoch 31] step 4/44: loss=-0.1029 
[epoch 31] step 6/44: loss=-0.1009 
[epoch 31] step 8/44: loss=-0.1021 
[epoch 31] step 10/44: loss=-0.1025 
[epoch 31] step 12/44: loss=-0.1005 
[epoch 31] step 14/44: loss=-0.1003 
[epoch 31] step 16/44: loss=-0.0998 
[epoch 31] step 18/44: loss=-0.1002 
[epoch 31] step 20/44: loss=-0.1002 
[epoch 31] step 22/44: loss=-0.1002 
[epoch 31] step 24/44: loss=-0.1004 
[epoch 31] step 26/44: loss=-0.1001 
[epoch 31] step 28/44: loss=-0.1002 
[epoch 31] step 30/44: loss=-0.1002 
[epoch 31] step 32/44: loss=-0.1002 
[epoch 31] step 34/44: loss=-0.1000 
[epoch 31] step 36/44: loss=-0.0999 
[epoch 31] step 38/44: loss=-0.0998 
[epoch 31] step 40/44: loss=-0.0999 
[epoch 31] step 42/44: loss=-0.0997 
[epoch 31] step 44/44: loss=-0.1000 
[epoch 31] train_loss(avg per step)=-0.1999 lambda[min,max]=[0.416813,1.000000]
[epoch 31] val_loss=2.0024 qwk=('0.1592', '0.3331', '0.3278') averageQWK=0.2734 macroEMD=0.2320 tailR0=('0.0078', '0.1667', '0.0000') tailR0avg=0.0582
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    6   57   14    1
     0    1  105   52    4
     0    2   42   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     0    6   10    0    0
     0    8   47   11    0
     0    1  135   69    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   12   16    0    0
     0    7   99    5    0
     0    5  134   42    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=-0.1071 
[epoch 32] step 4/44: loss=-0.1052 
[epoch 32] step 6/44: loss=-0.1029 
[epoch 32] step 8/44: loss=-0.1036 
[epoch 32] step 10/44: loss=-0.1050 
[epoch 32] step 12/44: loss=-0.1039 
[epoch 32] step 14/44: loss=-0.1027 
[epoch 32] step 16/44: loss=-0.1029 
[epoch 32] step 18/44: loss=-0.1020 
[epoch 32] step 20/44: loss=-0.1013 
[epoch 32] step 22/44: loss=-0.1013 
[epoch 32] step 24/44: loss=-0.1014 
[epoch 32] step 26/44: loss=-0.1018 
[epoch 32] step 28/44: loss=-0.1017 
[epoch 32] step 30/44: loss=-0.1020 
[epoch 32] step 32/44: loss=-0.1020 
[epoch 32] step 34/44: loss=-0.1022 
[epoch 32] step 36/44: loss=-0.1026 
[epoch 32] step 38/44: loss=-0.1024 
[epoch 32] step 40/44: loss=-0.1024 
[epoch 32] step 42/44: loss=-0.1024 
[epoch 32] step 44/44: loss=-0.1025 
[epoch 32] train_loss(avg per step)=-0.2051 lambda[min,max]=[0.445340,1.000000]
[epoch 32] val_loss=2.0103 qwk=('0.1643', '0.3500', '0.2979') averageQWK=0.2707 macroEMD=0.2335 tailR0=('0.0078', '0.1667', '0.0000') tailR0avg=0.0582
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    6   59   12    1
     0    1  107   50    4
     0    2   42   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     0    6   10    0    0
     0    8   45   13    0
     0    1  122   82    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   12   16    0    0
     0    7   99    5    0
     0    5  139   37    0
     0    0    1    0    0
[epoch 33] step 2/44: loss=-0.0947 
[epoch 33] step 4/44: loss=-0.0998 
[epoch 33] step 6/44: loss=-0.0996 
[epoch 33] step 8/44: loss=-0.1010 
[epoch 33] step 10/44: loss=-0.1007 
[epoch 33] step 12/44: loss=-0.0991 
[epoch 33] step 14/44: loss=-0.0999 
[epoch 33] step 16/44: loss=-0.1006 
[epoch 33] step 18/44: loss=-0.1008 
[epoch 33] step 20/44: loss=-0.1012 
[epoch 33] step 22/44: loss=-0.1008 
[epoch 33] step 24/44: loss=-0.1012 
[epoch 33] step 26/44: loss=-0.1019 
[epoch 33] step 28/44: loss=-0.1018 
[epoch 33] step 30/44: loss=-0.1019 
[epoch 33] step 32/44: loss=-0.1022 
[epoch 33] step 34/44: loss=-0.1023 
[epoch 33] step 36/44: loss=-0.1024 
[epoch 33] step 38/44: loss=-0.1025 
[epoch 33] step 40/44: loss=-0.1027 
[epoch 33] step 42/44: loss=-0.1029 
[epoch 33] step 44/44: loss=-0.1031 
[epoch 33] train_loss(avg per step)=-0.2062 lambda[min,max]=[0.363015,1.000000]
[epoch 33] val_loss=1.9729 qwk=('0.1859', '0.3371', '0.2927') averageQWK=0.2719 macroEMD=0.2380 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    3   61   12    2
     0    0  102   56    4
     0    1   39   23    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   12    0    0
     0    6   46   14    0
     0    1  110   94    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   12   16    0    0
     0    6  100    5    0
     0    5  140   36    0
     0    0    1    0    0
[epoch 34] step 2/44: loss=-0.1073 
[epoch 34] step 4/44: loss=-0.1084 
[epoch 34] step 6/44: loss=-0.1069 
[epoch 34] step 8/44: loss=-0.1058 
[epoch 34] step 10/44: loss=-0.1051 
[epoch 34] step 12/44: loss=-0.1048 
[epoch 34] step 14/44: loss=-0.1050 
[epoch 34] step 16/44: loss=-0.1047 
[epoch 34] step 18/44: loss=-0.1043 
[epoch 34] step 20/44: loss=-0.1038 
[epoch 34] step 22/44: loss=-0.1034 
[epoch 34] step 24/44: loss=-0.1037 
[epoch 34] step 26/44: loss=-0.1038 
[epoch 34] step 28/44: loss=-0.1039 
[epoch 34] step 30/44: loss=-0.1034 
[epoch 34] step 32/44: loss=-0.1036 
[epoch 34] step 34/44: loss=-0.1038 
[epoch 34] step 36/44: loss=-0.1040 
[epoch 34] step 38/44: loss=-0.1042 
[epoch 34] step 40/44: loss=-0.1039 
[epoch 34] step 42/44: loss=-0.1040 
[epoch 34] step 44/44: loss=-0.1041 
[epoch 34] train_loss(avg per step)=-0.2082 lambda[min,max]=[0.447932,1.000000]
[epoch 34] val_loss=2.0127 qwk=('0.1659', '0.3211', '0.2928') averageQWK=0.2599 macroEMD=0.2350 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    6   57   14    1
     0    1  104   53    4
     0    2   41   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5   11    0    0
     0    8   46   12    0
     0    1  124   80    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   10   18    0    0
     0    5  101    5    0
     0    5  138   38    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=-0.1037 
[epoch 35] step 4/44: loss=-0.1044 
[epoch 35] step 6/44: loss=-0.1049 
[epoch 35] step 8/44: loss=-0.1051 
[epoch 35] step 10/44: loss=-0.1051 
[epoch 35] step 12/44: loss=-0.1055 
[epoch 35] step 14/44: loss=-0.1043 
[epoch 35] step 16/44: loss=-0.1047 
[epoch 35] step 18/44: loss=-0.1049 
[epoch 35] step 20/44: loss=-0.1044 
[epoch 35] step 22/44: loss=-0.1041 
[epoch 35] step 24/44: loss=-0.1042 
[epoch 35] step 26/44: loss=-0.1040 
[epoch 35] step 28/44: loss=-0.1041 
[epoch 35] step 30/44: loss=-0.1039 
[epoch 35] step 32/44: loss=-0.1038 
[epoch 35] step 34/44: loss=-0.1042 
[epoch 35] step 36/44: loss=-0.1044 
[epoch 35] step 38/44: loss=-0.1042 
[epoch 35] step 40/44: loss=-0.1044 
[epoch 35] step 42/44: loss=-0.1044 
[epoch 35] step 44/44: loss=-0.1045 
[epoch 35] train_loss(avg per step)=-0.2090 lambda[min,max]=[0.431467,1.000000]
[epoch 35] val_loss=1.9677 qwk=('0.1720', '0.3538', '0.3127') averageQWK=0.2795 macroEMD=0.2351 tailR0=('0.0078', '0.0833', '0.0000') tailR0avg=0.0304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    5   58   14    1
     0    1  101   56    4
     0    2   40   21    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    5   11    0    0
     0    6   46   14    0
     0    1  111   93    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   12   16    0    0
     0    7   99    5    0
     0    5  138   38    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold0/metrics.json
Done.
