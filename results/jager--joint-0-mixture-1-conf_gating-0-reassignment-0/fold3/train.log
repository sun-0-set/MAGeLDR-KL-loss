[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.7149 
[epoch 1] step 4/44: loss=0.7173 
[epoch 1] step 6/44: loss=0.7134 
[epoch 1] step 8/44: loss=0.7079 
[epoch 1] step 10/44: loss=0.7113 
[epoch 1] step 12/44: loss=0.7120 
[epoch 1] step 14/44: loss=0.7102 
[epoch 1] step 16/44: loss=0.7114 
[epoch 1] step 18/44: loss=0.7139 
[epoch 1] step 20/44: loss=0.7169 
[epoch 1] step 22/44: loss=0.7175 
[epoch 1] step 24/44: loss=0.7176 
[epoch 1] step 26/44: loss=0.7173 
[epoch 1] step 28/44: loss=0.7157 
[epoch 1] step 30/44: loss=0.7137 
[epoch 1] step 32/44: loss=0.7125 
[epoch 1] step 34/44: loss=0.7104 
[epoch 1] step 36/44: loss=0.7098 
[epoch 1] step 38/44: loss=0.7071 
[epoch 1] step 40/44: loss=0.7042 
[epoch 1] step 42/44: loss=0.7024 
[epoch 1] step 44/44: loss=0.6999 
[epoch 1] train_loss(avg per step)=1.3998 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.3370 qwk=('-0.0559', '0.0388', '0.0912') averageQWK=0.0247 macroEMD=0.3681 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    8    0
     0    3    0   37    0
     0   14    0  114    0
     0   22    0  100    0
     0    1    0   26    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   41    7    0
     9    0   80   24    0
    12    0   96   40    0
     0    0    5    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    8   63    0    0
     0    3  148    0    0
     0    0   99    0    0
     0    0    3    0    0
[epoch 2] step 2/44: loss=0.6446 
[epoch 2] step 4/44: loss=0.6404 
[epoch 2] step 6/44: loss=0.6385 
[epoch 2] step 8/44: loss=0.6359 
[epoch 2] step 10/44: loss=0.6475 
[epoch 2] step 12/44: loss=0.6478 
[epoch 2] step 14/44: loss=0.6443 
[epoch 2] step 16/44: loss=0.6398 
[epoch 2] step 18/44: loss=0.6359 
[epoch 2] step 20/44: loss=0.6342 
[epoch 2] step 22/44: loss=0.6328 
[epoch 2] step 24/44: loss=0.6317 
[epoch 2] step 26/44: loss=0.6314 
[epoch 2] step 28/44: loss=0.6300 
[epoch 2] step 30/44: loss=0.6310 
[epoch 2] step 32/44: loss=0.6330 
[epoch 2] step 34/44: loss=0.6316 
[epoch 2] step 36/44: loss=0.6291 
[epoch 2] step 38/44: loss=0.6283 
[epoch 2] step 40/44: loss=0.6266 
[epoch 2] step 42/44: loss=0.6265 
[epoch 2] step 44/44: loss=0.6233 
[epoch 2] train_loss(avg per step)=1.2465 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.1028 qwk=('0.4210', '0.3857', '0.5483') averageQWK=0.4517 macroEMD=0.3143 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    0    0
     0    0   37    3    0
     0    0   97   31    0
     0    0   47   75    0
     0    0    3   24    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   38   10    0
     0    0   64   49    0
     0    0   36  112    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   55    3    0
     0    3  103   45    0
     0    0   21   78    0
     0    0    0    3    0
[epoch 3] step 2/44: loss=0.5786 
[epoch 3] step 4/44: loss=0.5688 
[epoch 3] step 6/44: loss=0.5695 
[epoch 3] step 8/44: loss=0.5569 
[epoch 3] step 10/44: loss=0.5480 
[epoch 3] step 12/44: loss=0.5508 
[epoch 3] step 14/44: loss=0.5489 
[epoch 3] step 16/44: loss=0.5496 
[epoch 3] step 18/44: loss=0.5473 
[epoch 3] step 20/44: loss=0.5408 
[epoch 3] step 22/44: loss=0.5350 
[epoch 3] step 24/44: loss=0.5391 
[epoch 3] step 26/44: loss=0.5359 
[epoch 3] step 28/44: loss=0.5311 
[epoch 3] step 30/44: loss=0.5287 
[epoch 3] step 32/44: loss=0.5282 
[epoch 3] step 34/44: loss=0.5252 
[epoch 3] step 36/44: loss=0.5246 
[epoch 3] step 38/44: loss=0.5244 
[epoch 3] step 40/44: loss=0.5224 
[epoch 3] step 42/44: loss=0.5219 
[epoch 3] step 44/44: loss=0.5204 
[epoch 3] train_loss(avg per step)=1.0408 lambda[min,max]=[0.492325,1.000000]
[epoch 3] val_loss=1.0638 qwk=('0.5392', '0.4070', '0.4677') averageQWK=0.4713 macroEMD=0.2644 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    7   30    3    0
     0    5   92   31    0
     0    1   42   79    0
     0    0    2   25    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   43    5    0
     0    0   76   37    0
     0    0   50   98    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   53    0    0
     0   11  131    9    0
     0    1   57   41    0
     0    0    1    2    0
[epoch 4] step 2/44: loss=0.5173 
[epoch 4] step 4/44: loss=0.4998 
[epoch 4] step 6/44: loss=0.4946 
[epoch 4] step 8/44: loss=0.4972 
[epoch 4] step 10/44: loss=0.4892 
[epoch 4] step 12/44: loss=0.4983 
[epoch 4] step 14/44: loss=0.5053 
[epoch 4] step 16/44: loss=0.5073 
[epoch 4] step 18/44: loss=0.5021 
[epoch 4] step 20/44: loss=0.5061 
[epoch 4] step 22/44: loss=0.5005 
[epoch 4] step 24/44: loss=0.4962 
[epoch 4] step 26/44: loss=0.4969 
[epoch 4] step 28/44: loss=0.4941 
[epoch 4] step 30/44: loss=0.4956 
[epoch 4] step 32/44: loss=0.4945 
[epoch 4] step 34/44: loss=0.4935 
[epoch 4] step 36/44: loss=0.4945 
[epoch 4] step 38/44: loss=0.4957 
[epoch 4] step 40/44: loss=0.4931 
[epoch 4] step 42/44: loss=0.4899 
[epoch 4] step 44/44: loss=0.4891 
[epoch 4] train_loss(avg per step)=0.9782 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=1.0556 qwk=('0.3805', '0.3956', '0.4850') averageQWK=0.4204 macroEMD=0.2655 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    0    0
     0    0   40    0    0
     0    0  114   14    0
     0    0   62   60    0
     0    0    9   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   39    9    0
     0    0   73   40    0
     0    0   45  103    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    7   64    0    0
     0    1  130   20    0
     0    0   42   57    0
     0    0    1    2    0
[epoch 5] step 2/44: loss=0.4353 
[epoch 5] step 4/44: loss=0.4402 
[epoch 5] step 6/44: loss=0.4471 
[epoch 5] step 8/44: loss=0.4487 
[epoch 5] step 10/44: loss=0.4558 
[epoch 5] step 12/44: loss=0.4566 
[epoch 5] step 14/44: loss=0.4585 
[epoch 5] step 16/44: loss=0.4551 
[epoch 5] step 18/44: loss=0.4574 
[epoch 5] step 20/44: loss=0.4571 
[epoch 5] step 22/44: loss=0.4530 
[epoch 5] step 24/44: loss=0.4586 
[epoch 5] step 26/44: loss=0.4566 
[epoch 5] step 28/44: loss=0.4567 
[epoch 5] step 30/44: loss=0.4555 
[epoch 5] step 32/44: loss=0.4577 
[epoch 5] step 34/44: loss=0.4594 
[epoch 5] step 36/44: loss=0.4601 
[epoch 5] step 38/44: loss=0.4607 
[epoch 5] step 40/44: loss=0.4578 
[epoch 5] step 42/44: loss=0.4562 
[epoch 5] step 44/44: loss=0.4576 
[epoch 5] train_loss(avg per step)=0.9153 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=1.1103 qwk=('0.5524', '0.5524', '0.5734') averageQWK=0.5594 macroEMD=0.2459 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   20   19    1    0
     0   23   89   16    0
     0    1   64   57    0
     0    0    6   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   19   28    1    0
     0   12   86   15    0
     0    2   74   72    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   48   23    0    0
     0   51   88   12    0
     0    2   51   46    0
     0    0    1    2    0
[epoch 6] step 2/44: loss=0.4300 
[epoch 6] step 4/44: loss=0.4055 
[epoch 6] step 6/44: loss=0.4129 
[epoch 6] step 8/44: loss=0.4127 
[epoch 6] step 10/44: loss=0.4075 
[epoch 6] step 12/44: loss=0.4058 
[epoch 6] step 14/44: loss=0.4146 
[epoch 6] step 16/44: loss=0.4133 
[epoch 6] step 18/44: loss=0.4141 
[epoch 6] step 20/44: loss=0.4124 
[epoch 6] step 22/44: loss=0.4155 
[epoch 6] step 24/44: loss=0.4149 
[epoch 6] step 26/44: loss=0.4125 
[epoch 6] step 28/44: loss=0.4135 
[epoch 6] step 30/44: loss=0.4093 
[epoch 6] step 32/44: loss=0.4120 
[epoch 6] step 34/44: loss=0.4160 
[epoch 6] step 36/44: loss=0.4208 
[epoch 6] step 38/44: loss=0.4269 
[epoch 6] step 40/44: loss=0.4265 
[epoch 6] step 42/44: loss=0.4260 
[epoch 6] step 44/44: loss=0.4275 
[epoch 6] train_loss(avg per step)=0.8550 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=1.0692 qwk=('0.5122', '0.4363', '0.5325') averageQWK=0.4937 macroEMD=0.2434 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    7   25    8    0
     0    3   63   62    0
     0    1   20  101    0
     0    0    0   27    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2   32   14    0
     0    1   62   50    0
     0    0   26  122    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   19   47    5    0
     0    5  100   46    0
     0    0   24   75    0
     0    0    1    2    0
[epoch 7] step 2/44: loss=0.3679 
[epoch 7] step 4/44: loss=0.3750 
[epoch 7] step 6/44: loss=0.3965 
[epoch 7] step 8/44: loss=0.4016 
[epoch 7] step 10/44: loss=0.3984 
[epoch 7] step 12/44: loss=0.3845 
[epoch 7] step 14/44: loss=0.3802 
[epoch 7] step 16/44: loss=0.3795 
[epoch 7] step 18/44: loss=0.3820 
[epoch 7] step 20/44: loss=0.3781 
[epoch 7] step 22/44: loss=0.3751 
[epoch 7] step 24/44: loss=0.3735 
[epoch 7] step 26/44: loss=0.3758 
[epoch 7] step 28/44: loss=0.3787 
[epoch 7] step 30/44: loss=0.3791 
[epoch 7] step 32/44: loss=0.3771 
[epoch 7] step 34/44: loss=0.3781 
[epoch 7] step 36/44: loss=0.3778 
[epoch 7] step 38/44: loss=0.3811 
[epoch 7] step 40/44: loss=0.3833 
[epoch 7] step 42/44: loss=0.3841 
[epoch 7] step 44/44: loss=0.3826 
[epoch 7] train_loss(avg per step)=0.7651 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.0438 qwk=('0.5207', '0.5000', '0.5757') averageQWK=0.5321 macroEMD=0.2319 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    4   32    4    0
     0    3   80   45    0
     0    0   33   89    0
     0    0    2   25    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   36    8    0
     0    1   70   42    0
     0    0   37  111    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   25   44    2    0
     0    6  107   38    0
     0    0   30   69    0
     0    0    1    2    0
[epoch 8] step 2/44: loss=0.3355 
[epoch 8] step 4/44: loss=0.3364 
[epoch 8] step 6/44: loss=0.3435 
[epoch 8] step 8/44: loss=0.3538 
[epoch 8] step 10/44: loss=0.3459 
[epoch 8] step 12/44: loss=0.3440 
[epoch 8] step 14/44: loss=0.3518 
[epoch 8] step 16/44: loss=0.3557 
[epoch 8] step 18/44: loss=0.3627 
[epoch 8] step 20/44: loss=0.3588 
[epoch 8] step 22/44: loss=0.3569 
[epoch 8] step 24/44: loss=0.3563 
[epoch 8] step 26/44: loss=0.3554 
[epoch 8] step 28/44: loss=0.3517 
[epoch 8] step 30/44: loss=0.3494 
[epoch 8] step 32/44: loss=0.3511 
[epoch 8] step 34/44: loss=0.3552 
[epoch 8] step 36/44: loss=0.3579 
[epoch 8] step 38/44: loss=0.3586 
[epoch 8] step 40/44: loss=0.3594 
[epoch 8] step 42/44: loss=0.3616 
[epoch 8] step 44/44: loss=0.3631 
[epoch 8] train_loss(avg per step)=0.7262 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.0453 qwk=('0.5119', '0.5078', '0.5341') averageQWK=0.5179 macroEMD=0.2327 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    9   29    2    0
     0    7   94   27    0
     0    0   57   65    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    9   35    4    0
     0    5   85   23    0
     0    1   63   84    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   30   40    1    0
     0   16  121   14    0
     0    1   52   46    0
     0    0    1    2    0
[epoch 9] step 2/44: loss=0.3375 
[epoch 9] step 4/44: loss=0.3498 
[epoch 9] step 6/44: loss=0.3538 
[epoch 9] step 8/44: loss=0.3385 
[epoch 9] step 10/44: loss=0.3365 
[epoch 9] step 12/44: loss=0.3166 
[epoch 9] step 14/44: loss=0.3157 
[epoch 9] step 16/44: loss=0.3218 
[epoch 9] step 18/44: loss=0.3172 
[epoch 9] step 20/44: loss=0.3165 
[epoch 9] step 22/44: loss=0.3154 
[epoch 9] step 24/44: loss=0.3134 
[epoch 9] step 26/44: loss=0.3160 
[epoch 9] step 28/44: loss=0.3118 
[epoch 9] step 30/44: loss=0.3109 
[epoch 9] step 32/44: loss=0.3113 
[epoch 9] step 34/44: loss=0.3100 
[epoch 9] step 36/44: loss=0.3078 
[epoch 9] step 38/44: loss=0.3069 
[epoch 9] step 40/44: loss=0.3028 
[epoch 9] step 42/44: loss=0.3035 
[epoch 9] step 44/44: loss=0.3025 
[epoch 9] train_loss(avg per step)=0.6050 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.0332 qwk=('0.5453', '0.4827', '0.5460') averageQWK=0.5247 macroEMD=0.2219 tailR0=('0.0741', '0.0000', '0.0000') tailR0avg=0.0247
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    5   33    2    0
     0    2   98   27    1
     0    0   48   72    2
     0    0    3   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6   37    5    0
     0    3   76   34    0
     0    0   55   93    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   25   44    2    0
     0    6  122   23    0
     0    1   41   57    0
     0    0    1    2    0
[epoch 10] step 2/44: loss=0.2896 
[epoch 10] step 4/44: loss=0.2985 
[epoch 10] step 6/44: loss=0.2739 
[epoch 10] step 8/44: loss=0.2598 
[epoch 10] step 10/44: loss=0.2610 
[epoch 10] step 12/44: loss=0.2637 
[epoch 10] step 14/44: loss=0.2667 
[epoch 10] step 16/44: loss=0.2628 
[epoch 10] step 18/44: loss=0.2606 
[epoch 10] step 20/44: loss=0.2639 
[epoch 10] step 22/44: loss=0.2638 
[epoch 10] step 24/44: loss=0.2673 
[epoch 10] step 26/44: loss=0.2654 
[epoch 10] step 28/44: loss=0.2666 
[epoch 10] step 30/44: loss=0.2681 
[epoch 10] step 32/44: loss=0.2666 
[epoch 10] step 34/44: loss=0.2632 
[epoch 10] step 36/44: loss=0.2630 
[epoch 10] step 38/44: loss=0.2644 
[epoch 10] step 40/44: loss=0.2626 
[epoch 10] step 42/44: loss=0.2585 
[epoch 10] step 44/44: loss=0.2589 
[epoch 10] train_loss(avg per step)=0.5178 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.0514 qwk=('0.5455', '0.5430', '0.5750') averageQWK=0.5545 macroEMD=0.2159 tailR0=('0.0185', '0.0000', '0.0000') tailR0avg=0.0062
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   10   24    6    0
     0    6   74   48    0
     0    0   31   91    0
     0    0    1   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   14   26    8    0
     0    8   63   42    0
     0    2   33  113    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   35   34    2    0
     0   14  112   25    0
     0    1   42   56    0
     0    0    1    2    0
[epoch 11] step 2/44: loss=0.2637 
[epoch 11] step 4/44: loss=0.2507 
[epoch 11] step 6/44: loss=0.2353 
[epoch 11] step 8/44: loss=0.2366 
[epoch 11] step 10/44: loss=0.2334 
[epoch 11] step 12/44: loss=0.2268 
[epoch 11] step 14/44: loss=0.2189 
[epoch 11] step 16/44: loss=0.2220 
[epoch 11] step 18/44: loss=0.2248 
[epoch 11] step 20/44: loss=0.2197 
[epoch 11] step 22/44: loss=0.2196 
[epoch 11] step 24/44: loss=0.2176 
[epoch 11] step 26/44: loss=0.2225 
[epoch 11] step 28/44: loss=0.2192 
[epoch 11] step 30/44: loss=0.2204 
[epoch 11] step 32/44: loss=0.2220 
[epoch 11] step 34/44: loss=0.2207 
[epoch 11] step 36/44: loss=0.2178 
[epoch 11] step 38/44: loss=0.2173 
[epoch 11] step 40/44: loss=0.2183 
[epoch 11] step 42/44: loss=0.2175 
[epoch 11] step 44/44: loss=0.2195 
[epoch 11] train_loss(avg per step)=0.4391 lambda[min,max]=[0.486746,1.000000]
[epoch 11] val_loss=1.0895 qwk=('0.5404', '0.5328', '0.5569') averageQWK=0.5434 macroEMD=0.2173 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   13   24    3    0
     0   11   89   28    0
     0    2   44   76    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   18   25    5    0
     0   13   72   28    0
     0    2   59   87    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   34   37    0    0
     0   19  117   15    0
     0    1   52   46    0
     0    0    1    2    0
[epoch 12] step 2/44: loss=0.1078 
[epoch 12] step 4/44: loss=0.1453 
[epoch 12] step 6/44: loss=0.1589 
[epoch 12] step 8/44: loss=0.1757 
[epoch 12] step 10/44: loss=0.1853 
[epoch 12] step 12/44: loss=0.1940 
[epoch 12] step 14/44: loss=0.1866 
[epoch 12] step 16/44: loss=0.1813 
[epoch 12] step 18/44: loss=0.1793 
[epoch 12] step 20/44: loss=0.1802 
[epoch 12] step 22/44: loss=0.1841 
[epoch 12] step 24/44: loss=0.1849 
[epoch 12] step 26/44: loss=0.1887 
[epoch 12] step 28/44: loss=0.1908 
[epoch 12] step 30/44: loss=0.1956 
[epoch 12] step 32/44: loss=0.1932 
[epoch 12] step 34/44: loss=0.1907 
[epoch 12] step 36/44: loss=0.1880 
[epoch 12] step 38/44: loss=0.1861 
[epoch 12] step 40/44: loss=0.1863 
[epoch 12] step 42/44: loss=0.1863 
[epoch 12] step 44/44: loss=0.1858 
[epoch 12] train_loss(avg per step)=0.3716 lambda[min,max]=[0.485198,1.000000]
[epoch 12] val_loss=1.1030 qwk=('0.5665', '0.5578', '0.5717') averageQWK=0.5653 macroEMD=0.2172 tailR0=('0.1111', '0.0000', '0.0000') tailR0avg=0.0370
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   17   20    3    0
     0   16   84   27    1
     0    2   46   69    5
     0    0    5   16    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   20   22    6    0
     0   16   57   40    0
     0    4   36  108    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   34   37    0    0
     0   21  111   19    0
     0    1   46   52    0
     0    0    1    2    0
[epoch 13] step 2/44: loss=0.1873 
[epoch 13] step 4/44: loss=0.1597 
[epoch 13] step 6/44: loss=0.1615 
[epoch 13] step 8/44: loss=0.1680 
[epoch 13] step 10/44: loss=0.1633 
[epoch 13] step 12/44: loss=0.1642 
[epoch 13] step 14/44: loss=0.1578 
[epoch 13] step 16/44: loss=0.1523 
[epoch 13] step 18/44: loss=0.1542 
[epoch 13] step 20/44: loss=0.1495 
[epoch 13] step 22/44: loss=0.1508 
[epoch 13] step 24/44: loss=0.1500 
[epoch 13] step 26/44: loss=0.1512 
[epoch 13] step 28/44: loss=0.1529 
[epoch 13] step 30/44: loss=0.1525 
[epoch 13] step 32/44: loss=0.1485 
[epoch 13] step 34/44: loss=0.1487 
[epoch 13] step 36/44: loss=0.1476 
[epoch 13] step 38/44: loss=0.1487 
[epoch 13] step 40/44: loss=0.1523 
[epoch 13] step 42/44: loss=0.1542 
[epoch 13] step 44/44: loss=0.1563 
[epoch 13] train_loss(avg per step)=0.3127 lambda[min,max]=[0.489943,1.000000]
[epoch 13] val_loss=1.1144 qwk=('0.4924', '0.5000', '0.5423') averageQWK=0.5116 macroEMD=0.2215 tailR0=('0.0926', '0.0000', '0.0000') tailR0avg=0.0309
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    5   30    5    0
     0    2   83   42    1
     0    0   45   74    3
     0    0    3   19    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   37    7    0
     0    2   64   47    0
     0    0   33  115    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   25   43    3    0
     0   13  103   35    0
     0    1   32   66    0
     0    0    1    2    0
[epoch 14] step 2/44: loss=0.1114 
[epoch 14] step 4/44: loss=0.1125 
[epoch 14] step 6/44: loss=0.1163 
[epoch 14] step 8/44: loss=0.1283 
[epoch 14] step 10/44: loss=0.1308 
[epoch 14] step 12/44: loss=0.1302 
[epoch 14] step 14/44: loss=0.1254 
[epoch 14] step 16/44: loss=0.1200 
[epoch 14] step 18/44: loss=0.1201 
[epoch 14] step 20/44: loss=0.1187 
[epoch 14] step 22/44: loss=0.1173 
[epoch 14] step 24/44: loss=0.1150 
[epoch 14] step 26/44: loss=0.1145 
[epoch 14] step 28/44: loss=0.1116 
[epoch 14] step 30/44: loss=0.1141 
[epoch 14] step 32/44: loss=0.1156 
[epoch 14] step 34/44: loss=0.1168 
[epoch 14] step 36/44: loss=0.1162 
[epoch 14] step 38/44: loss=0.1178 
[epoch 14] step 40/44: loss=0.1173 
[epoch 14] step 42/44: loss=0.1190 
[epoch 14] step 44/44: loss=0.1165 
[epoch 14] train_loss(avg per step)=0.2329 lambda[min,max]=[0.417179,1.000000]
[epoch 14] val_loss=1.1471 qwk=('0.5622', '0.5314', '0.5231') averageQWK=0.5389 macroEMD=0.2162 tailR0=('0.0741', '0.0000', '0.0000') tailR0avg=0.0247
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   11   24    5    0
     0    9   82   37    0
     0    1   37   84    0
     0    0    2   21    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   12   32    4    0
     0    8   79   26    0
     0    1   58   89    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   48    1    0
     0    7  117   27    0
     0    0   45   54    0
     0    0    1    2    0
[epoch 15] step 2/44: loss=0.1082 
[epoch 15] step 4/44: loss=0.1278 
[epoch 15] step 6/44: loss=0.1171 
[epoch 15] step 8/44: loss=0.1115 
[epoch 15] step 10/44: loss=0.1071 
[epoch 15] step 12/44: loss=0.1074 
[epoch 15] step 14/44: loss=0.0987 
[epoch 15] step 16/44: loss=0.0907 
[epoch 15] step 18/44: loss=0.0900 
[epoch 15] step 20/44: loss=0.0916 
[epoch 15] step 22/44: loss=0.0914 
[epoch 15] step 24/44: loss=0.0941 
[epoch 15] step 26/44: loss=0.0942 
[epoch 15] step 28/44: loss=0.0929 
[epoch 15] step 30/44: loss=0.0958 
[epoch 15] step 32/44: loss=0.0972 
[epoch 15] step 34/44: loss=0.0958 
[epoch 15] step 36/44: loss=0.0949 
[epoch 15] step 38/44: loss=0.0950 
[epoch 15] step 40/44: loss=0.0958 
[epoch 15] step 42/44: loss=0.0949 
[epoch 15] step 44/44: loss=0.0927 
[epoch 15] train_loss(avg per step)=0.1854 lambda[min,max]=[0.434276,1.000000]
[epoch 15] val_loss=1.1869 qwk=('0.5583', '0.5414', '0.5201') averageQWK=0.5399 macroEMD=0.2134 tailR0=('0.1551', '0.0500', '0.0000') tailR0avg=0.0684
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0   10   22    8    0
     0    5   65   58    0
     0    0   26   95    1
     0    0    0   22    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   10   31    7    0
     1    3   72   37    0
     0    1   38  108    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   49    2    0
     0    6  114   31    0
     0    0   40   59    0
     0    0    1    2    0
[epoch 16] step 2/44: loss=0.0820 
[epoch 16] step 4/44: loss=0.0809 
[epoch 16] step 6/44: loss=0.0707 
[epoch 16] step 8/44: loss=0.0673 
[epoch 16] step 10/44: loss=0.0685 
[epoch 16] step 12/44: loss=0.0688 
[epoch 16] step 14/44: loss=0.0758 
[epoch 16] step 16/44: loss=0.0753 
[epoch 16] step 18/44: loss=0.0736 
[epoch 16] step 20/44: loss=0.0783 
[epoch 16] step 22/44: loss=0.0745 
[epoch 16] step 24/44: loss=0.0733 
[epoch 16] step 26/44: loss=0.0721 
[epoch 16] step 28/44: loss=0.0735 
[epoch 16] step 30/44: loss=0.0693 
[epoch 16] step 32/44: loss=0.0672 
[epoch 16] step 34/44: loss=0.0645 
[epoch 16] step 36/44: loss=0.0654 
[epoch 16] step 38/44: loss=0.0655 
[epoch 16] step 40/44: loss=0.0649 
[epoch 16] step 42/44: loss=0.0647 
[epoch 16] step 44/44: loss=0.0638 
[epoch 16] train_loss(avg per step)=0.1277 lambda[min,max]=[0.489791,1.000000]
[epoch 16] val_loss=1.1569 qwk=('0.5203', '0.5304', '0.5499') averageQWK=0.5335 macroEMD=0.2143 tailR0=('0.2292', '0.0000', '0.0000') tailR0avg=0.0764
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    9   27    4    0
     0    8   92   26    2
     0    1   53   64    4
     0    0    7   11    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     1   11   31    5    0
     1    8   75   29    0
     0    1   53   94    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   34   34    3    0
     0   24  100   27    0
     0    4   32   63    0
     0    0    1    2    0
[epoch 17] step 2/44: loss=0.0409 
[epoch 17] step 4/44: loss=0.0325 
[epoch 17] step 6/44: loss=0.0512 
[epoch 17] step 8/44: loss=0.0450 
[epoch 17] step 10/44: loss=0.0365 
[epoch 17] step 12/44: loss=0.0354 
[epoch 17] step 14/44: loss=0.0349 
[epoch 17] step 16/44: loss=0.0330 
[epoch 17] step 18/44: loss=0.0350 
[epoch 17] step 20/44: loss=0.0369 
[epoch 17] step 22/44: loss=0.0375 
[epoch 17] step 24/44: loss=0.0351 
[epoch 17] step 26/44: loss=0.0383 
[epoch 17] step 28/44: loss=0.0354 
[epoch 17] step 30/44: loss=0.0362 
[epoch 17] step 32/44: loss=0.0382 
[epoch 17] step 34/44: loss=0.0373 
[epoch 17] step 36/44: loss=0.0369 
[epoch 17] step 38/44: loss=0.0371 
[epoch 17] step 40/44: loss=0.0354 
[epoch 17] step 42/44: loss=0.0365 
[epoch 17] step 44/44: loss=0.0373 
[epoch 17] train_loss(avg per step)=0.0746 lambda[min,max]=[0.372235,1.000000]
[epoch 17] val_loss=1.3063 qwk=('0.5085', '0.4745', '0.4731') averageQWK=0.4854 macroEMD=0.2169 tailR0=('0.1551', '0.0000', '0.0000') tailR0avg=0.0517
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    1    1    0
     0    5   27    8    0
     0    5   60   62    1
     0    0   26   93    3
     0    0    0   22    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0    3   34   11    0
     1    3   53   56    0
     0    0   25  123    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   48    7    0
     0    5   92   54    0
     0    0   27   72    0
     0    0    1    2    0
[epoch 18] step 2/44: loss=0.0343 
[epoch 18] step 4/44: loss=0.0374 
[epoch 18] step 6/44: loss=0.0358 
[epoch 18] step 8/44: loss=0.0506 
[epoch 18] step 10/44: loss=0.0512 
[epoch 18] step 12/44: loss=0.0427 
[epoch 18] step 14/44: loss=0.0414 
[epoch 18] step 16/44: loss=0.0408 
[epoch 18] step 18/44: loss=0.0401 
[epoch 18] step 20/44: loss=0.0382 
[epoch 18] step 22/44: loss=0.0364 
[epoch 18] step 24/44: loss=0.0377 
[epoch 18] step 26/44: loss=0.0362 
[epoch 18] step 28/44: loss=0.0335 
[epoch 18] step 30/44: loss=0.0297 
[epoch 18] step 32/44: loss=0.0281 
[epoch 18] step 34/44: loss=0.0280 
[epoch 18] step 36/44: loss=0.0276 
[epoch 18] step 38/44: loss=0.0269 
[epoch 18] step 40/44: loss=0.0258 
[epoch 18] step 42/44: loss=0.0243 
[epoch 18] step 44/44: loss=0.0232 
[epoch 18] train_loss(avg per step)=0.0464 lambda[min,max]=[0.364665,1.000000]
[epoch 18] val_loss=1.2173 qwk=('0.5367', '0.4930', '0.5386') averageQWK=0.5228 macroEMD=0.2138 tailR0=('0.2106', '0.1667', '0.0000') tailR0avg=0.1258
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    5   31    4    0
     0    3   85   38    2
     0    0   38   82    2
     0    0    4   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    2    0    0
     2    2   38    6    0
     2    3   69   39    0
     0    0   44  103    1
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   47    2    0
     0   12  109   30    0
     0    1   34   64    0
     0    0    1    2    0
[epoch 19] step 2/44: loss=0.0062 
[epoch 19] step 4/44: loss=-0.0028 
[epoch 19] step 6/44: loss=-0.0071 
[epoch 19] step 8/44: loss=-0.0126 
[epoch 19] step 10/44: loss=0.0002 
[epoch 19] step 12/44: loss=0.0076 
[epoch 19] step 14/44: loss=0.0061 
[epoch 19] step 16/44: loss=0.0033 
[epoch 19] step 18/44: loss=0.0019 
[epoch 19] step 20/44: loss=0.0008 
[epoch 19] step 22/44: loss=0.0028 
[epoch 19] step 24/44: loss=0.0035 
[epoch 19] step 26/44: loss=0.0055 
[epoch 19] step 28/44: loss=0.0060 
[epoch 19] step 30/44: loss=0.0050 
[epoch 19] step 32/44: loss=0.0032 
[epoch 19] step 34/44: loss=0.0013 
[epoch 19] step 36/44: loss=-0.0010 
[epoch 19] step 38/44: loss=-0.0017 
[epoch 19] step 40/44: loss=-0.0022 
[epoch 19] step 42/44: loss=-0.0035 
[epoch 19] step 44/44: loss=-0.0040 
[epoch 19] train_loss(avg per step)=-0.0080 lambda[min,max]=[0.398082,1.000000]
[epoch 19] val_loss=1.2249 qwk=('0.5447', '0.5402', '0.5289') averageQWK=0.5379 macroEMD=0.2055 tailR0=('0.1736', '0.2500', '0.0000') tailR0avg=0.1412
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     1    8   27    4    0
     0    5   97   26    0
     0    1   47   71    3
     0    0    5   16    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    0    0    0
     2    6   34    6    0
     2    4   76   31    0
     0    1   47   99    1
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   23   46    2    0
     0   10  120   21    0
     0    1   42   56    0
     0    0    1    2    0
[epoch 20] step 2/44: loss=-0.0167 
[epoch 20] step 4/44: loss=-0.0284 
[epoch 20] step 6/44: loss=-0.0277 
[epoch 20] step 8/44: loss=-0.0209 
[epoch 20] step 10/44: loss=-0.0239 
[epoch 20] step 12/44: loss=-0.0219 
[epoch 20] step 14/44: loss=-0.0212 
[epoch 20] step 16/44: loss=-0.0253 
[epoch 20] step 18/44: loss=-0.0253 
[epoch 20] step 20/44: loss=-0.0258 
[epoch 20] step 22/44: loss=-0.0250 
[epoch 20] step 24/44: loss=-0.0256 
[epoch 20] step 26/44: loss=-0.0250 
[epoch 20] step 28/44: loss=-0.0252 
[epoch 20] step 30/44: loss=-0.0241 
[epoch 20] step 32/44: loss=-0.0245 
[epoch 20] step 34/44: loss=-0.0228 
[epoch 20] step 36/44: loss=-0.0231 
[epoch 20] step 38/44: loss=-0.0242 
[epoch 20] step 40/44: loss=-0.0225 
[epoch 20] step 42/44: loss=-0.0234 
[epoch 20] step 44/44: loss=-0.0222 
[epoch 20] train_loss(avg per step)=-0.0444 lambda[min,max]=[0.422578,1.000000]
[epoch 20] val_loss=1.3401 qwk=('0.5365', '0.5092', '0.4950') averageQWK=0.5136 macroEMD=0.2146 tailR0=('0.2106', '0.1333', '0.0000') tailR0avg=0.1147
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    4   29    7    0
     0    2   68   56    2
     0    0   26   93    3
     0    0    0   19    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    3   37    8    0
     0    3   64   46    0
     0    0   28  119    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   12   57    2    0
     0    2  108   41    0
     0    0   33   66    0
     0    0    1    2    0
[epoch 21] step 2/44: loss=-0.0315 
[epoch 21] step 4/44: loss=-0.0263 
[epoch 21] step 6/44: loss=-0.0245 
[epoch 21] step 8/44: loss=-0.0218 
[epoch 21] step 10/44: loss=-0.0244 
[epoch 21] step 12/44: loss=-0.0224 
[epoch 21] step 14/44: loss=-0.0223 
[epoch 21] step 16/44: loss=-0.0270 
[epoch 21] step 18/44: loss=-0.0272 
[epoch 21] step 20/44: loss=-0.0274 
[epoch 21] step 22/44: loss=-0.0259 
[epoch 21] step 24/44: loss=-0.0253 
[epoch 21] step 26/44: loss=-0.0262 
[epoch 21] step 28/44: loss=-0.0271 
[epoch 21] step 30/44: loss=-0.0269 
[epoch 21] step 32/44: loss=-0.0270 
[epoch 21] step 34/44: loss=-0.0274 
[epoch 21] step 36/44: loss=-0.0288 
[epoch 21] step 38/44: loss=-0.0299 
[epoch 21] step 40/44: loss=-0.0309 
[epoch 21] step 42/44: loss=-0.0310 
[epoch 21] step 44/44: loss=-0.0318 
[epoch 21] train_loss(avg per step)=-0.0636 lambda[min,max]=[0.390526,1.000000]
[epoch 21] val_loss=1.2950 qwk=('0.5289', '0.5266', '0.5256') averageQWK=0.5271 macroEMD=0.2067 tailR0=('0.1366', '0.1333', '0.0000') tailR0avg=0.0900
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    6   30    4    0
     0    6   80   41    1
     0    1   35   86    0
     0    0    4   19    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    0    0
     1   11   31    5    0
     1    7   75   30    0
     0    2   55   90    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   48    3    0
     0    5  110   36    0
     0    0   35   64    0
     0    0    1    2    0
[epoch 22] step 2/44: loss=-0.0450 
[epoch 22] step 4/44: loss=-0.0487 
[epoch 22] step 6/44: loss=-0.0492 
[epoch 22] step 8/44: loss=-0.0540 
[epoch 22] step 10/44: loss=-0.0529 
[epoch 22] step 12/44: loss=-0.0522 
[epoch 22] step 14/44: loss=-0.0486 
[epoch 22] step 16/44: loss=-0.0485 
[epoch 22] step 18/44: loss=-0.0488 
[epoch 22] step 20/44: loss=-0.0502 
[epoch 22] step 22/44: loss=-0.0498 
[epoch 22] step 24/44: loss=-0.0487 
[epoch 22] step 26/44: loss=-0.0508 
[epoch 22] step 28/44: loss=-0.0499 
[epoch 22] step 30/44: loss=-0.0505 
[epoch 22] step 32/44: loss=-0.0497 
[epoch 22] step 34/44: loss=-0.0494 
[epoch 22] step 36/44: loss=-0.0495 
[epoch 22] step 38/44: loss=-0.0493 
[epoch 22] step 40/44: loss=-0.0497 
[epoch 22] step 42/44: loss=-0.0499 
[epoch 22] step 44/44: loss=-0.0499 
[epoch 22] train_loss(avg per step)=-0.0999 lambda[min,max]=[0.352541,1.000000]
[epoch 22] val_loss=1.2474 qwk=('0.5587', '0.5200', '0.5121') averageQWK=0.5303 macroEMD=0.2091 tailR0=('0.2106', '0.2167', '0.0000') tailR0avg=0.1424
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0   11   25    4    0
     2    6   81   39    0
     0    1   41   77    3
     0    0    4   15    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    0    0    0
     3    2   36    7    0
     3    3   68   38    1
     0    0   41  105    2
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   24   46    0    0
     0   12  128   11    0
     0    2   53   44    0
     0    0    1    2    0
[epoch 23] step 2/44: loss=-0.0605 
[epoch 23] step 4/44: loss=-0.0617 
[epoch 23] step 6/44: loss=-0.0606 
[epoch 23] step 8/44: loss=-0.0626 
[epoch 23] step 10/44: loss=-0.0640 
[epoch 23] step 12/44: loss=-0.0615 
[epoch 23] step 14/44: loss=-0.0625 
[epoch 23] step 16/44: loss=-0.0625 
[epoch 23] step 18/44: loss=-0.0644 
[epoch 23] step 20/44: loss=-0.0638 
[epoch 23] step 22/44: loss=-0.0633 
[epoch 23] step 24/44: loss=-0.0635 
[epoch 23] step 26/44: loss=-0.0633 
[epoch 23] step 28/44: loss=-0.0630 
[epoch 23] step 30/44: loss=-0.0633 
[epoch 23] step 32/44: loss=-0.0632 
[epoch 23] step 34/44: loss=-0.0626 
[epoch 23] step 36/44: loss=-0.0619 
[epoch 23] step 38/44: loss=-0.0621 
[epoch 23] step 40/44: loss=-0.0602 
[epoch 23] step 42/44: loss=-0.0602 
[epoch 23] step 44/44: loss=-0.0604 
[epoch 23] train_loss(avg per step)=-0.1207 lambda[min,max]=[0.359714,1.000000]
[epoch 23] val_loss=1.3093 qwk=('0.5261', '0.5083', '0.5177') averageQWK=0.5174 macroEMD=0.2095 tailR0=('0.1551', '0.3000', '0.0000') tailR0avg=0.1517
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    8   28    4    0
     1    4   92   31    0
     0    1   45   74    2
     0    0    6   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    0    0    0
     4    4   34    6    0
     4    3   77   29    0
     1    1   54   91    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   25   45    0    0
     0   13  126   12    0
     0    1   55   43    0
     0    0    1    2    0
[epoch 24] step 2/44: loss=-0.0702 
[epoch 24] step 4/44: loss=-0.0709 
[epoch 24] step 6/44: loss=-0.0696 
[epoch 24] step 8/44: loss=-0.0703 
[epoch 24] step 10/44: loss=-0.0708 
[epoch 24] step 12/44: loss=-0.0689 
[epoch 24] step 14/44: loss=-0.0669 
[epoch 24] step 16/44: loss=-0.0667 
[epoch 24] step 18/44: loss=-0.0653 
[epoch 24] step 20/44: loss=-0.0668 
[epoch 24] step 22/44: loss=-0.0681 
[epoch 24] step 24/44: loss=-0.0685 
[epoch 24] step 26/44: loss=-0.0679 
[epoch 24] step 28/44: loss=-0.0672 
[epoch 24] step 30/44: loss=-0.0674 
[epoch 24] step 32/44: loss=-0.0680 
[epoch 24] step 34/44: loss=-0.0680 
[epoch 24] step 36/44: loss=-0.0683 
[epoch 24] step 38/44: loss=-0.0681 
[epoch 24] step 40/44: loss=-0.0688 
[epoch 24] step 42/44: loss=-0.0681 
[epoch 24] step 44/44: loss=-0.0688 
[epoch 24] train_loss(avg per step)=-0.1375 lambda[min,max]=[0.336120,1.000000]
[epoch 24] val_loss=1.3541 qwk=('0.4985', '0.4730', '0.4773') averageQWK=0.4830 macroEMD=0.2081 tailR0=('0.1181', '0.0000', '0.0000') tailR0avg=0.0394
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    4   32    4    0
     0    3   84   41    0
     0    0   40   80    2
     0    0    5   19    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     1    5   36    6    0
     1    4   79   29    0
     0    1   53   94    0
     0    0    2    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   54    0    0
     0    6  131   14    0
     0    0   56   43    0
     0    0    1    2    0
[epoch 25] step 2/44: loss=-0.0853 
[epoch 25] step 4/44: loss=-0.0827 
[epoch 25] step 6/44: loss=-0.0748 
[epoch 25] step 8/44: loss=-0.0758 
[epoch 25] step 10/44: loss=-0.0740 
[epoch 25] step 12/44: loss=-0.0722 
[epoch 25] step 14/44: loss=-0.0730 
[epoch 25] step 16/44: loss=-0.0729 
[epoch 25] step 18/44: loss=-0.0750 
[epoch 25] step 20/44: loss=-0.0747 
[epoch 25] step 22/44: loss=-0.0759 
[epoch 25] step 24/44: loss=-0.0763 
[epoch 25] step 26/44: loss=-0.0756 
[epoch 25] step 28/44: loss=-0.0749 
[epoch 25] step 30/44: loss=-0.0749 
[epoch 25] step 32/44: loss=-0.0759 
[epoch 25] step 34/44: loss=-0.0756 
[epoch 25] step 36/44: loss=-0.0743 
[epoch 25] step 38/44: loss=-0.0745 
[epoch 25] step 40/44: loss=-0.0744 
[epoch 25] step 42/44: loss=-0.0744 
[epoch 25] step 44/44: loss=-0.0750 
[epoch 25] train_loss(avg per step)=-0.1500 lambda[min,max]=[0.370421,1.000000]
[epoch 25] val_loss=1.4071 qwk=('0.5363', '0.4793', '0.4958') averageQWK=0.5038 macroEMD=0.2052 tailR0=('0.0995', '0.1333', '0.5000') tailR0avg=0.2443
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    6   30    4    0
     0    6   77   45    0
     0    0   34   86    2
     0    0    3   22    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     1    3   39    5    0
     0    4   81   27    1
     0    0   58   89    1
     0    0    2    7    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    0    0    0
     0   10   61    0    0
     0    2  129   20    0
     0    0   45   54    0
     0    0    1    2    0
[epoch 26] step 2/44: loss=-0.0796 
[epoch 26] step 4/44: loss=-0.0770 
[epoch 26] step 6/44: loss=-0.0774 
[epoch 26] step 8/44: loss=-0.0820 
[epoch 26] step 10/44: loss=-0.0779 
[epoch 26] step 12/44: loss=-0.0789 
[epoch 26] step 14/44: loss=-0.0758 
[epoch 26] step 16/44: loss=-0.0767 
[epoch 26] step 18/44: loss=-0.0758 
[epoch 26] step 20/44: loss=-0.0758 
[epoch 26] step 22/44: loss=-0.0759 
[epoch 26] step 24/44: loss=-0.0765 
[epoch 26] step 26/44: loss=-0.0750 
[epoch 26] step 28/44: loss=-0.0731 
[epoch 26] step 30/44: loss=-0.0735 
[epoch 26] step 32/44: loss=-0.0743 
[epoch 26] step 34/44: loss=-0.0749 
[epoch 26] step 36/44: loss=-0.0756 
[epoch 26] step 38/44: loss=-0.0759 
[epoch 26] step 40/44: loss=-0.0762 
[epoch 26] step 42/44: loss=-0.0761 
[epoch 26] step 44/44: loss=-0.0767 
[epoch 26] train_loss(avg per step)=-0.1534 lambda[min,max]=[0.381879,1.000000]
[epoch 26] val_loss=1.3425 qwk=('0.5372', '0.5035', '0.5366') averageQWK=0.5258 macroEMD=0.2012 tailR0=('0.0995', '0.0833', '0.0000') tailR0avg=0.0610
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0   11   24    5    0
     2    5   75   45    1
     0    1   34   86    1
     0    0    2   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    0    0
     3    4   34    7    0
     2    4   71   36    0
     0    2   44  102    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   24   43    3    0
     0    7  112   32    0
     0    1   37   61    0
     0    0    1    2    0
[epoch 27] step 2/44: loss=-0.0862 
[epoch 27] step 4/44: loss=-0.0843 
[epoch 27] step 6/44: loss=-0.0819 
[epoch 27] step 8/44: loss=-0.0837 
[epoch 27] step 10/44: loss=-0.0842 
[epoch 27] step 12/44: loss=-0.0845 
[epoch 27] step 14/44: loss=-0.0865 
[epoch 27] step 16/44: loss=-0.0879 
[epoch 27] step 18/44: loss=-0.0865 
[epoch 27] step 20/44: loss=-0.0867 
[epoch 27] step 22/44: loss=-0.0865 
[epoch 27] step 24/44: loss=-0.0868 
[epoch 27] step 26/44: loss=-0.0875 
[epoch 27] step 28/44: loss=-0.0871 
[epoch 27] step 30/44: loss=-0.0853 
[epoch 27] step 32/44: loss=-0.0853 
[epoch 27] step 34/44: loss=-0.0847 
[epoch 27] step 36/44: loss=-0.0848 
[epoch 27] step 38/44: loss=-0.0852 
[epoch 27] step 40/44: loss=-0.0857 
[epoch 27] step 42/44: loss=-0.0855 
[epoch 27] step 44/44: loss=-0.0856 
[epoch 27] train_loss(avg per step)=-0.1712 lambda[min,max]=[0.367526,1.000000]
[epoch 27] val_loss=1.4170 qwk=('0.5254', '0.4373', '0.5210') averageQWK=0.4946 macroEMD=0.2056 tailR0=('0.1181', '0.1333', '0.0000') tailR0avg=0.0838
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    9   27    4    0
     0    5   80   43    0
     0    0   40   80    2
     0    0    4   20    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     2    1   40    4    1
     2    2   84   24    1
     0    0   66   81    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   51    2    0
     0    7  117   27    0
     0    0   39   60    0
     0    0    1    2    0
[epoch 28] step 2/44: loss=-0.1018 
[epoch 28] step 4/44: loss=-0.0951 
[epoch 28] step 6/44: loss=-0.0940 
[epoch 28] step 8/44: loss=-0.0933 
[epoch 28] step 10/44: loss=-0.0920 
[epoch 28] step 12/44: loss=-0.0914 
[epoch 28] step 14/44: loss=-0.0881 
[epoch 28] step 16/44: loss=-0.0864 
[epoch 28] step 18/44: loss=-0.0865 
[epoch 28] step 20/44: loss=-0.0877 
[epoch 28] step 22/44: loss=-0.0877 
[epoch 28] step 24/44: loss=-0.0889 
[epoch 28] step 26/44: loss=-0.0893 
[epoch 28] step 28/44: loss=-0.0877 
[epoch 28] step 30/44: loss=-0.0876 
[epoch 28] step 32/44: loss=-0.0871 
[epoch 28] step 34/44: loss=-0.0872 
[epoch 28] step 36/44: loss=-0.0877 
[epoch 28] step 38/44: loss=-0.0881 
[epoch 28] step 40/44: loss=-0.0884 
[epoch 28] step 42/44: loss=-0.0888 
[epoch 28] step 44/44: loss=-0.0888 
[epoch 28] train_loss(avg per step)=-0.1776 lambda[min,max]=[0.348765,1.000000]
[epoch 28] val_loss=1.3772 qwk=('0.5559', '0.4721', '0.5216') averageQWK=0.5165 macroEMD=0.2057 tailR0=('0.1736', '0.0833', '0.0000') tailR0avg=0.0856
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    7   28    5    0
     0    4   78   45    1
     0    0   34   85    3
     0    0    2   19    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1    3   33   11    0
     2    4   57   50    0
     0    0   30  117    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   19   51    1    0
     0    6  122   23    0
     0    0   44   55    0
     0    0    1    2    0
[epoch 29] step 2/44: loss=-0.0937 
[epoch 29] step 4/44: loss=-0.0911 
[epoch 29] step 6/44: loss=-0.0886 
[epoch 29] step 8/44: loss=-0.0887 
[epoch 29] step 10/44: loss=-0.0903 
[epoch 29] step 12/44: loss=-0.0910 
[epoch 29] step 14/44: loss=-0.0902 
[epoch 29] step 16/44: loss=-0.0899 
[epoch 29] step 18/44: loss=-0.0905 
[epoch 29] step 20/44: loss=-0.0905 
[epoch 29] step 22/44: loss=-0.0912 
[epoch 29] step 24/44: loss=-0.0918 
[epoch 29] step 26/44: loss=-0.0906 
[epoch 29] step 28/44: loss=-0.0902 
[epoch 29] step 30/44: loss=-0.0911 
[epoch 29] step 32/44: loss=-0.0908 
[epoch 29] step 34/44: loss=-0.0906 
[epoch 29] step 36/44: loss=-0.0903 
[epoch 29] step 38/44: loss=-0.0905 
[epoch 29] step 40/44: loss=-0.0904 
[epoch 29] step 42/44: loss=-0.0910 
[epoch 29] step 44/44: loss=-0.0910 
[epoch 29] train_loss(avg per step)=-0.1821 lambda[min,max]=[0.367737,1.000000]
[epoch 29] val_loss=1.3951 qwk=('0.5144', '0.4686', '0.5201') averageQWK=0.5011 macroEMD=0.2054 tailR0=('0.1181', '0.0833', '0.0000') tailR0avg=0.0671
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    7   29    4    0
     1    4   86   36    1
     0    0   43   78    1
     0    0    5   19    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     2    2   38    6    0
     2    4   78   29    0
     0    1   53   93    1
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   51    0    0
     0    7  130   14    0
     0    0   51   48    0
     0    0    1    2    0
[epoch 30] step 2/44: loss=-0.1062 
[epoch 30] step 4/44: loss=-0.1037 
[epoch 30] step 6/44: loss=-0.1030 
[epoch 30] step 8/44: loss=-0.1011 
[epoch 30] step 10/44: loss=-0.0984 
[epoch 30] step 12/44: loss=-0.0986 
[epoch 30] step 14/44: loss=-0.0973 
[epoch 30] step 16/44: loss=-0.0980 
[epoch 30] step 18/44: loss=-0.0974 
[epoch 30] step 20/44: loss=-0.0975 
[epoch 30] step 22/44: loss=-0.0969 
[epoch 30] step 24/44: loss=-0.0971 
[epoch 30] step 26/44: loss=-0.0965 
[epoch 30] step 28/44: loss=-0.0967 
[epoch 30] step 30/44: loss=-0.0970 
[epoch 30] step 32/44: loss=-0.0964 
[epoch 30] step 34/44: loss=-0.0963 
[epoch 30] step 36/44: loss=-0.0963 
[epoch 30] step 38/44: loss=-0.0964 
[epoch 30] step 40/44: loss=-0.0962 
[epoch 30] step 42/44: loss=-0.0956 
[epoch 30] step 44/44: loss=-0.0958 
[epoch 30] train_loss(avg per step)=-0.1915 lambda[min,max]=[0.416344,1.000000]
[epoch 30] val_loss=1.3622 qwk=('0.5168', '0.5272', '0.5194') averageQWK=0.5211 macroEMD=0.2060 tailR0=('0.1366', '0.0833', '0.0000') tailR0avg=0.0733
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1    6   29    4    0
     2    4   84   37    1
     0    0   43   75    4
     0    0    5   18    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    0    0
     2    9   31    6    0
     2    5   69   36    1
     0    2   42  103    1
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   24   45    1    0
     0    9  123   19    0
     0    2   47   50    0
     0    0    1    2    0
[epoch 31] step 2/44: loss=-0.0972 
[epoch 31] step 4/44: loss=-0.1007 
[epoch 31] step 6/44: loss=-0.1012 
[epoch 31] step 8/44: loss=-0.0999 
[epoch 31] step 10/44: loss=-0.1000 
[epoch 31] step 12/44: loss=-0.0961 
[epoch 31] step 14/44: loss=-0.0966 
[epoch 31] step 16/44: loss=-0.0969 
[epoch 31] step 18/44: loss=-0.0968 
[epoch 31] step 20/44: loss=-0.0966 
[epoch 31] step 22/44: loss=-0.0971 
[epoch 31] step 24/44: loss=-0.0963 
[epoch 31] step 26/44: loss=-0.0962 
[epoch 31] step 28/44: loss=-0.0962 
[epoch 31] step 30/44: loss=-0.0962 
[epoch 31] step 32/44: loss=-0.0965 
[epoch 31] step 34/44: loss=-0.0968 
[epoch 31] step 36/44: loss=-0.0966 
[epoch 31] step 38/44: loss=-0.0965 
[epoch 31] step 40/44: loss=-0.0967 
[epoch 31] step 42/44: loss=-0.0969 
[epoch 31] step 44/44: loss=-0.0971 
[epoch 31] train_loss(avg per step)=-0.1941 lambda[min,max]=[0.359909,1.000000]
[epoch 31] val_loss=1.4048 qwk=('0.4957', '0.4925', '0.5400') averageQWK=0.5094 macroEMD=0.2037 tailR0=('0.0810', '0.0833', '0.0000') tailR0avg=0.0548
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0   10   26    4    0
     2    4   85   37    0
     0    1   40   80    1
     0    0    8   18    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    0    0
     3    4   36    5    0
     2    4   78   28    1
     0    2   53   93    0
     0    0    2    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   22   47    1    0
     0    9  121   21    0
     0    0   45   54    0
     0    0    1    2    0
[epoch 32] step 2/44: loss=-0.1051 
[epoch 32] step 4/44: loss=-0.1018 
[epoch 32] step 6/44: loss=-0.0996 
[epoch 32] step 8/44: loss=-0.1003 
[epoch 32] step 10/44: loss=-0.1007 
[epoch 32] step 12/44: loss=-0.1014 
[epoch 32] step 14/44: loss=-0.1013 
[epoch 32] step 16/44: loss=-0.1003 
[epoch 32] step 18/44: loss=-0.1005 
[epoch 32] step 20/44: loss=-0.1004 
[epoch 32] step 22/44: loss=-0.1009 
[epoch 32] step 24/44: loss=-0.0998 
[epoch 32] step 26/44: loss=-0.0995 
[epoch 32] step 28/44: loss=-0.0991 
[epoch 32] step 30/44: loss=-0.0993 
[epoch 32] step 32/44: loss=-0.0995 
[epoch 32] step 34/44: loss=-0.1001 
[epoch 32] step 36/44: loss=-0.0990 
[epoch 32] step 38/44: loss=-0.0990 
[epoch 32] step 40/44: loss=-0.0995 
[epoch 32] step 42/44: loss=-0.0995 
[epoch 32] step 44/44: loss=-0.0986 
[epoch 32] train_loss(avg per step)=-0.1972 lambda[min,max]=[0.357147,1.000000]
[epoch 32] val_loss=1.3868 qwk=('0.4962', '0.5109', '0.5346') averageQWK=0.5139 macroEMD=0.2047 tailR0=('0.1366', '0.2167', '0.0000') tailR0avg=0.1177
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    6   30    4    0
     2    4   86   35    1
     0    0   44   74    4
     0    0    7   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    0    0    0
     3    5   33    6    1
     2    4   73   33    1
     0    1   47   99    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   22   46    2    0
     0   10  118   23    0
     0    0   43   56    0
     0    0    1    2    0
[epoch 33] step 2/44: loss=-0.1046 
[epoch 33] step 4/44: loss=-0.0990 
[epoch 33] step 6/44: loss=-0.1005 
[epoch 33] step 8/44: loss=-0.1002 
[epoch 33] step 10/44: loss=-0.1003 
[epoch 33] step 12/44: loss=-0.1010 
[epoch 33] step 14/44: loss=-0.1011 
[epoch 33] step 16/44: loss=-0.1016 
[epoch 33] step 18/44: loss=-0.1016 
[epoch 33] step 20/44: loss=-0.1020 
[epoch 33] step 22/44: loss=-0.1011 
[epoch 33] step 24/44: loss=-0.1011 
[epoch 33] step 26/44: loss=-0.1013 
[epoch 33] step 28/44: loss=-0.1011 
[epoch 33] step 30/44: loss=-0.1002 
[epoch 33] step 32/44: loss=-0.1002 
[epoch 33] step 34/44: loss=-0.1003 
[epoch 33] step 36/44: loss=-0.1001 
[epoch 33] step 38/44: loss=-0.1003 
[epoch 33] step 40/44: loss=-0.1005 
[epoch 33] step 42/44: loss=-0.1006 
[epoch 33] step 44/44: loss=-0.1009 
[epoch 33] train_loss(avg per step)=-0.2019 lambda[min,max]=[0.425117,1.000000]
[epoch 33] val_loss=1.4065 qwk=('0.5238', '0.5012', '0.5301') averageQWK=0.5184 macroEMD=0.2045 tailR0=('0.0995', '0.0833', '0.0000') tailR0avg=0.0610
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    8   28    4    0
     0    5   82   41    0
     0    0   42   79    1
     0    0    4   21    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    0    0
     3    6   33    5    1
     2    4   73   33    1
     0    2   47   98    1
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   21   49    0    0
     1    7  124   19    0
     0    0   48   51    0
     0    0    1    2    0
[epoch 34] step 2/44: loss=-0.1055 
[epoch 34] step 4/44: loss=-0.1053 
[epoch 34] step 6/44: loss=-0.1051 
[epoch 34] step 8/44: loss=-0.1048 
[epoch 34] step 10/44: loss=-0.1019 
[epoch 34] step 12/44: loss=-0.1016 
[epoch 34] step 14/44: loss=-0.1019 
[epoch 34] step 16/44: loss=-0.1025 
[epoch 34] step 18/44: loss=-0.1029 
[epoch 34] step 20/44: loss=-0.1029 
[epoch 34] step 22/44: loss=-0.1029 
[epoch 34] step 24/44: loss=-0.1026 
[epoch 34] step 26/44: loss=-0.1025 
[epoch 34] step 28/44: loss=-0.1026 
[epoch 34] step 30/44: loss=-0.1021 
[epoch 34] step 32/44: loss=-0.1012 
[epoch 34] step 34/44: loss=-0.1015 
[epoch 34] step 36/44: loss=-0.1018 
[epoch 34] step 38/44: loss=-0.1019 
[epoch 34] step 40/44: loss=-0.1014 
[epoch 34] step 42/44: loss=-0.1015 
[epoch 34] step 44/44: loss=-0.1017 
[epoch 34] train_loss(avg per step)=-0.2035 lambda[min,max]=[0.399702,1.000000]
[epoch 34] val_loss=1.4121 qwk=('0.4936', '0.5073', '0.5315') averageQWK=0.5108 macroEMD=0.2038 tailR0=('0.0995', '0.1333', '0.0000') tailR0avg=0.0776
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     0    6   30    4    0
     1    4   82   41    0
     0    0   42   77    3
     0    0    5   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    0    0
     3    6   32    6    1
     2    4   71   35    1
     0    2   43  102    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   21   47    2    0
     1    7  122   21    0
     0    0   43   56    0
     0    0    1    2    0
[epoch 35] step 2/44: loss=-0.1015 
[epoch 35] step 4/44: loss=-0.1044 
[epoch 35] step 6/44: loss=-0.1033 
[epoch 35] step 8/44: loss=-0.1043 
[epoch 35] step 10/44: loss=-0.1054 
[epoch 35] step 12/44: loss=-0.1048 
[epoch 35] step 14/44: loss=-0.1045 
[epoch 35] step 16/44: loss=-0.1046 
[epoch 35] step 18/44: loss=-0.1041 
[epoch 35] step 20/44: loss=-0.1040 
[epoch 35] step 22/44: loss=-0.1039 
[epoch 35] step 24/44: loss=-0.1040 
[epoch 35] step 26/44: loss=-0.1038 
[epoch 35] step 28/44: loss=-0.1036 
[epoch 35] step 30/44: loss=-0.1037 
[epoch 35] step 32/44: loss=-0.1028 
[epoch 35] step 34/44: loss=-0.1027 
[epoch 35] step 36/44: loss=-0.1028 
[epoch 35] step 38/44: loss=-0.1030 
[epoch 35] step 40/44: loss=-0.1029 
[epoch 35] step 42/44: loss=-0.1022 
[epoch 35] step 44/44: loss=-0.1025 
[epoch 35] train_loss(avg per step)=-0.2050 lambda[min,max]=[0.350757,1.000000]
[epoch 35] val_loss=1.4146 qwk=('0.5179', '0.5052', '0.5189') averageQWK=0.5140 macroEMD=0.2032 tailR0=('0.0995', '0.1333', '0.0000') tailR0avg=0.0776
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     0    8   28    4    0
     1    5   80   42    0
     0    0   42   79    1
     0    0    4   21    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    0    0
     3    6   33    5    1
     2    4   75   31    1
     0    2   49   96    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   21   47    2    0
     1    7  125   18    0
     0    0   47   52    0
     0    0    1    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold3/metrics.json
Done.
