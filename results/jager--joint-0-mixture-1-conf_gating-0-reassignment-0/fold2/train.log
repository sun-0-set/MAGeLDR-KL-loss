[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=0.7103 
[epoch 1] step 4/44: loss=0.7170 
[epoch 1] step 6/44: loss=0.7210 
[epoch 1] step 8/44: loss=0.7239 
[epoch 1] step 10/44: loss=0.7222 
[epoch 1] step 12/44: loss=0.7215 
[epoch 1] step 14/44: loss=0.7216 
[epoch 1] step 16/44: loss=0.7211 
[epoch 1] step 18/44: loss=0.7221 
[epoch 1] step 20/44: loss=0.7237 
[epoch 1] step 22/44: loss=0.7230 
[epoch 1] step 24/44: loss=0.7253 
[epoch 1] step 26/44: loss=0.7245 
[epoch 1] step 28/44: loss=0.7226 
[epoch 1] step 30/44: loss=0.7225 
[epoch 1] step 32/44: loss=0.7205 
[epoch 1] step 34/44: loss=0.7187 
[epoch 1] step 36/44: loss=0.7182 
[epoch 1] step 38/44: loss=0.7168 
[epoch 1] step 40/44: loss=0.7152 
[epoch 1] step 42/44: loss=0.7150 
[epoch 1] step 44/44: loss=0.7126 
[epoch 1] train_loss(avg per step)=1.4251 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=1.3717 qwk=('-0.1251', '-0.1702', '0.1215') averageQWK=-0.0579 macroEMD=0.3715 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0   19    5   74    0
     0   20   10  125    0
     0   21    8   30    0
     0    1    5    0    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   14    0    0
     5    0   76    0    1
    10    0  153    3    0
    15    0   44    2    0
     0    0    2    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    1
     0   50   46    0    8
     0   63  100    1   16
     0    9   21    1    5
     0    0    0    0    0
[epoch 2] step 2/44: loss=0.6785 
[epoch 2] step 4/44: loss=0.6657 
[epoch 2] step 6/44: loss=0.6739 
[epoch 2] step 8/44: loss=0.6665 
[epoch 2] step 10/44: loss=0.6647 
[epoch 2] step 12/44: loss=0.6647 
[epoch 2] step 14/44: loss=0.6560 
[epoch 2] step 16/44: loss=0.6555 
[epoch 2] step 18/44: loss=0.6487 
[epoch 2] step 20/44: loss=0.6487 
[epoch 2] step 22/44: loss=0.6503 
[epoch 2] step 24/44: loss=0.6471 
[epoch 2] step 26/44: loss=0.6459 
[epoch 2] step 28/44: loss=0.6453 
[epoch 2] step 30/44: loss=0.6448 
[epoch 2] step 32/44: loss=0.6428 
[epoch 2] step 34/44: loss=0.6401 
[epoch 2] step 36/44: loss=0.6390 
[epoch 2] step 38/44: loss=0.6365 
[epoch 2] step 40/44: loss=0.6329 
[epoch 2] step 42/44: loss=0.6315 
[epoch 2] step 44/44: loss=0.6298 
[epoch 2] train_loss(avg per step)=1.2595 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=1.2415 qwk=('0.1674', '0.2335', '0.2389') averageQWK=0.2133 macroEMD=0.3193 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    7    0
     0    2   59   37    0
     0    1   65   89    0
     0    0    8   51    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    4    0
     0    0   76    6    0
     0    0  136   30    0
     0    0   24   37    0
     0    0    1    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0    0   96    8    0
     0    0  146   34    0
     0    0   13   23    0
     0    0    0    0    0
[epoch 3] step 2/44: loss=0.5536 
[epoch 3] step 4/44: loss=0.5551 
[epoch 3] step 6/44: loss=0.5482 
[epoch 3] step 8/44: loss=0.5516 
[epoch 3] step 10/44: loss=0.5490 
[epoch 3] step 12/44: loss=0.5476 
[epoch 3] step 14/44: loss=0.5414 
[epoch 3] step 16/44: loss=0.5294 
[epoch 3] step 18/44: loss=0.5308 
[epoch 3] step 20/44: loss=0.5281 
[epoch 3] step 22/44: loss=0.5232 
[epoch 3] step 24/44: loss=0.5198 
[epoch 3] step 26/44: loss=0.5218 
[epoch 3] step 28/44: loss=0.5215 
[epoch 3] step 30/44: loss=0.5248 
[epoch 3] step 32/44: loss=0.5219 
[epoch 3] step 34/44: loss=0.5182 
[epoch 3] step 36/44: loss=0.5165 
[epoch 3] step 38/44: loss=0.5162 
[epoch 3] step 40/44: loss=0.5199 
[epoch 3] step 42/44: loss=0.5205 
[epoch 3] step 44/44: loss=0.5206 
[epoch 3] train_loss(avg per step)=1.0412 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=1.3274 qwk=('0.1716', '0.2050', '0.1841') averageQWK=0.1869 macroEMD=0.2984 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    2    5    0
     0    3   53   42    0
     0    1   61   93    0
     0    0    7   52    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    5    0
     0    0   59   23    0
     0    0   83   83    0
     0    0   12   49    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    3    2    0
     0    2   78   24    0
     0    1  102   77    0
     0    0    8   28    0
     0    0    0    0    0
[epoch 4] step 2/44: loss=0.5384 
[epoch 4] step 4/44: loss=0.5035 
[epoch 4] step 6/44: loss=0.5150 
[epoch 4] step 8/44: loss=0.5048 
[epoch 4] step 10/44: loss=0.5027 
[epoch 4] step 12/44: loss=0.5051 
[epoch 4] step 14/44: loss=0.4959 
[epoch 4] step 16/44: loss=0.4968 
[epoch 4] step 18/44: loss=0.4921 
[epoch 4] step 20/44: loss=0.4917 
[epoch 4] step 22/44: loss=0.4871 
[epoch 4] step 24/44: loss=0.4816 
[epoch 4] step 26/44: loss=0.4821 
[epoch 4] step 28/44: loss=0.4837 
[epoch 4] step 30/44: loss=0.4811 
[epoch 4] step 32/44: loss=0.4799 
[epoch 4] step 34/44: loss=0.4800 
[epoch 4] step 36/44: loss=0.4815 
[epoch 4] step 38/44: loss=0.4806 
[epoch 4] step 40/44: loss=0.4801 
[epoch 4] step 42/44: loss=0.4794 
[epoch 4] step 44/44: loss=0.4784 
[epoch 4] train_loss(avg per step)=0.9569 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=1.2263 qwk=('0.3465', '0.2770', '0.3092') averageQWK=0.3109 macroEMD=0.2781 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     0   34   47   17    0
     0   24   73   58    0
     0    1   17   41    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    4    0
     0   10   58   14    0
     0   15   79   72    0
     0    0   13   48    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   26   70    8    0
     0   26  119   35    0
     0    0   15   21    0
     0    0    0    0    0
[epoch 5] step 2/44: loss=0.4397 
[epoch 5] step 4/44: loss=0.4407 
[epoch 5] step 6/44: loss=0.4471 
[epoch 5] step 8/44: loss=0.4402 
[epoch 5] step 10/44: loss=0.4454 
[epoch 5] step 12/44: loss=0.4495 
[epoch 5] step 14/44: loss=0.4460 
[epoch 5] step 16/44: loss=0.4453 
[epoch 5] step 18/44: loss=0.4513 
[epoch 5] step 20/44: loss=0.4526 
[epoch 5] step 22/44: loss=0.4546 
[epoch 5] step 24/44: loss=0.4579 
[epoch 5] step 26/44: loss=0.4673 
[epoch 5] step 28/44: loss=0.4693 
[epoch 5] step 30/44: loss=0.4650 
[epoch 5] step 32/44: loss=0.4654 
[epoch 5] step 34/44: loss=0.4623 
[epoch 5] step 36/44: loss=0.4640 
[epoch 5] step 38/44: loss=0.4659 
[epoch 5] step 40/44: loss=0.4610 
[epoch 5] step 42/44: loss=0.4623 
[epoch 5] step 44/44: loss=0.4631 
[epoch 5] train_loss(avg per step)=0.9263 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=1.3140 qwk=('0.3038', '0.2665', '0.2390') averageQWK=0.2697 macroEMD=0.2843 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    2
     0   29   53   14    2
     0   15   87   41   12
     0    1   19   34    5
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    6    0
     0   17   45   20    0
     0   14   74   78    0
     0    0   12   49    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   42   31   31    0
     0   37   64   79    0
     0    0   12   24    0
     0    0    0    0    0
[epoch 6] step 2/44: loss=0.4611 
[epoch 6] step 4/44: loss=0.4308 
[epoch 6] step 6/44: loss=0.4292 
[epoch 6] step 8/44: loss=0.4274 
[epoch 6] step 10/44: loss=0.4240 
[epoch 6] step 12/44: loss=0.4268 
[epoch 6] step 14/44: loss=0.4322 
[epoch 6] step 16/44: loss=0.4280 
[epoch 6] step 18/44: loss=0.4189 
[epoch 6] step 20/44: loss=0.4229 
[epoch 6] step 22/44: loss=0.4208 
[epoch 6] step 24/44: loss=0.4176 
[epoch 6] step 26/44: loss=0.4144 
[epoch 6] step 28/44: loss=0.4126 
[epoch 6] step 30/44: loss=0.4125 
[epoch 6] step 32/44: loss=0.4103 
[epoch 6] step 34/44: loss=0.4123 
[epoch 6] step 36/44: loss=0.4085 
[epoch 6] step 38/44: loss=0.4082 
[epoch 6] step 40/44: loss=0.4080 
[epoch 6] step 42/44: loss=0.4099 
[epoch 6] step 44/44: loss=0.4091 
[epoch 6] train_loss(avg per step)=0.8181 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=1.5944 qwk=('0.1610', '0.1396', '0.2073') averageQWK=0.1693 macroEMD=0.2993 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0   13   36   42    7
     0    3   38  110    4
     0    1    3   54    1
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    8    0
     0    0   38   44    0
     0    0   47  119    0
     0    0    2   59    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   21   43   40    0
     0   10   71   99    0
     0    0    4   32    0
     0    0    0    0    0
[epoch 7] step 2/44: loss=0.4850 
[epoch 7] step 4/44: loss=0.4493 
[epoch 7] step 6/44: loss=0.4424 
[epoch 7] step 8/44: loss=0.4612 
[epoch 7] step 10/44: loss=0.4843 
[epoch 7] step 12/44: loss=0.4907 
[epoch 7] step 14/44: loss=0.4793 
[epoch 7] step 16/44: loss=0.4676 
[epoch 7] step 18/44: loss=0.4625 
[epoch 7] step 20/44: loss=0.4545 
[epoch 7] step 22/44: loss=0.4458 
[epoch 7] step 24/44: loss=0.4438 
[epoch 7] step 26/44: loss=0.4377 
[epoch 7] step 28/44: loss=0.4326 
[epoch 7] step 30/44: loss=0.4294 
[epoch 7] step 32/44: loss=0.4254 
[epoch 7] step 34/44: loss=0.4222 
[epoch 7] step 36/44: loss=0.4176 
[epoch 7] step 38/44: loss=0.4178 
[epoch 7] step 40/44: loss=0.4175 
[epoch 7] step 42/44: loss=0.4134 
[epoch 7] step 44/44: loss=0.4076 
[epoch 7] train_loss(avg per step)=0.8153 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=1.5681 qwk=('0.2232', '0.2455', '0.2302') averageQWK=0.2330 macroEMD=0.2826 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0   21   37   39    1
     0   13   49   92    1
     0    1    7   51    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    6    0
     0   16   33   33    0
     0   16   58   92    0
     0    0    7   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   30   40   34    0
     0   21   66   93    0
     0    0    7   29    0
     0    0    0    0    0
[epoch 8] step 2/44: loss=0.3474 
[epoch 8] step 4/44: loss=0.3526 
[epoch 8] step 6/44: loss=0.3469 
[epoch 8] step 8/44: loss=0.3511 
[epoch 8] step 10/44: loss=0.3475 
[epoch 8] step 12/44: loss=0.3418 
[epoch 8] step 14/44: loss=0.3412 
[epoch 8] step 16/44: loss=0.3458 
[epoch 8] step 18/44: loss=0.3447 
[epoch 8] step 20/44: loss=0.3404 
[epoch 8] step 22/44: loss=0.3428 
[epoch 8] step 24/44: loss=0.3448 
[epoch 8] step 26/44: loss=0.3499 
[epoch 8] step 28/44: loss=0.3502 
[epoch 8] step 30/44: loss=0.3465 
[epoch 8] step 32/44: loss=0.3435 
[epoch 8] step 34/44: loss=0.3411 
[epoch 8] step 36/44: loss=0.3403 
[epoch 8] step 38/44: loss=0.3409 
[epoch 8] step 40/44: loss=0.3407 
[epoch 8] step 42/44: loss=0.3410 
[epoch 8] step 44/44: loss=0.3408 
[epoch 8] train_loss(avg per step)=0.6816 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=1.4908 qwk=('0.2486', '0.2500', '0.2393') averageQWK=0.2460 macroEMD=0.2803 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0   26   37   32    3
     0   15   55   81    4
     0    1    7   50    1
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    7    0
     0   19   29   34    0
     0   16   51   99    0
     0    0    5   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   31   42   31    0
     0   25   68   87    0
     0    0    7   29    0
     0    0    0    0    0
[epoch 9] step 2/44: loss=0.2897 
[epoch 9] step 4/44: loss=0.3072 
[epoch 9] step 6/44: loss=0.2891 
[epoch 9] step 8/44: loss=0.2987 
[epoch 9] step 10/44: loss=0.2957 
[epoch 9] step 12/44: loss=0.2821 
[epoch 9] step 14/44: loss=0.2852 
[epoch 9] step 16/44: loss=0.2852 
[epoch 9] step 18/44: loss=0.2850 
[epoch 9] step 20/44: loss=0.2865 
[epoch 9] step 22/44: loss=0.2828 
[epoch 9] step 24/44: loss=0.2791 
[epoch 9] step 26/44: loss=0.2807 
[epoch 9] step 28/44: loss=0.2807 
[epoch 9] step 30/44: loss=0.2815 
[epoch 9] step 32/44: loss=0.2822 
[epoch 9] step 34/44: loss=0.2805 
[epoch 9] step 36/44: loss=0.2832 
[epoch 9] step 38/44: loss=0.2829 
[epoch 9] step 40/44: loss=0.2840 
[epoch 9] step 42/44: loss=0.2829 
[epoch 9] step 44/44: loss=0.2836 
[epoch 9] train_loss(avg per step)=0.5673 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=1.3386 qwk=('0.3302', '0.3167', '0.3166') averageQWK=0.3212 macroEMD=0.2624 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    5    0
     0   35   43   20    0
     0   24   55   76    0
     0    1   16   42    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    5    0
     0   28   39   15    0
     0   29   68   69    0
     0    1   17   43    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   33   64    7    0
     0   30  125   25    0
     0    0   20   16    0
     0    0    0    0    0
[epoch 10] step 2/44: loss=0.2811 
[epoch 10] step 4/44: loss=0.2821 
[epoch 10] step 6/44: loss=0.2851 
[epoch 10] step 8/44: loss=0.2898 
[epoch 10] step 10/44: loss=0.2818 
[epoch 10] step 12/44: loss=0.2753 
[epoch 10] step 14/44: loss=0.2797 
[epoch 10] step 16/44: loss=0.2811 
[epoch 10] step 18/44: loss=0.2816 
[epoch 10] step 20/44: loss=0.2797 
[epoch 10] step 22/44: loss=0.2780 
[epoch 10] step 24/44: loss=0.2823 
[epoch 10] step 26/44: loss=0.2820 
[epoch 10] step 28/44: loss=0.2811 
[epoch 10] step 30/44: loss=0.2828 
[epoch 10] step 32/44: loss=0.2801 
[epoch 10] step 34/44: loss=0.2777 
[epoch 10] step 36/44: loss=0.2732 
[epoch 10] step 38/44: loss=0.2700 
[epoch 10] step 40/44: loss=0.2665 
[epoch 10] step 42/44: loss=0.2631 
[epoch 10] step 44/44: loss=0.2611 
[epoch 10] train_loss(avg per step)=0.5222 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=1.2910 qwk=('0.3293', '0.3240', '0.3323') averageQWK=0.3285 macroEMD=0.2582 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     0   27   52   18    1
     0   11   82   61    1
     0    1   14   44    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    6    0
     0   21   45   16    0
     0   16   77   73    0
     0    0   12   49    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   26   71    7    0
     0   19  125   36    0
     0    0   13   23    0
     0    0    0    0    0
[epoch 11] step 2/44: loss=0.2332 
[epoch 11] step 4/44: loss=0.2222 
[epoch 11] step 6/44: loss=0.2158 
[epoch 11] step 8/44: loss=0.2164 
[epoch 11] step 10/44: loss=0.2023 
[epoch 11] step 12/44: loss=0.2014 
[epoch 11] step 14/44: loss=0.1963 
[epoch 11] step 16/44: loss=0.1943 
[epoch 11] step 18/44: loss=0.1935 
[epoch 11] step 20/44: loss=0.2001 
[epoch 11] step 22/44: loss=0.2036 
[epoch 11] step 24/44: loss=0.2036 
[epoch 11] step 26/44: loss=0.2055 
[epoch 11] step 28/44: loss=0.2089 
[epoch 11] step 30/44: loss=0.2078 
[epoch 11] step 32/44: loss=0.2084 
[epoch 11] step 34/44: loss=0.2079 
[epoch 11] step 36/44: loss=0.2092 
[epoch 11] step 38/44: loss=0.2095 
[epoch 11] step 40/44: loss=0.2103 
[epoch 11] step 42/44: loss=0.2087 
[epoch 11] step 44/44: loss=0.2066 
[epoch 11] train_loss(avg per step)=0.4132 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=1.5433 qwk=('0.2545', '0.2656', '0.2404') averageQWK=0.2535 macroEMD=0.2719 tailR0=('0.1667', '0.2500', '0.0000') tailR0avg=0.1389
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     0   26   40   27    5
     0   17   54   77    7
     0    1    9   47    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    6    1
     0   26   27   29    0
     0   23   52   89    2
     0    1    7   53    0
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   26   55   23    0
     0   25   88   67    0
     0    0   11   25    0
     0    0    0    0    0
[epoch 12] step 2/44: loss=0.1930 
[epoch 12] step 4/44: loss=0.2028 
[epoch 12] step 6/44: loss=0.2040 
[epoch 12] step 8/44: loss=0.1864 
[epoch 12] step 10/44: loss=0.2064 
[epoch 12] step 12/44: loss=0.2018 
[epoch 12] step 14/44: loss=0.2018 
[epoch 12] step 16/44: loss=0.1937 
[epoch 12] step 18/44: loss=0.1918 
[epoch 12] step 20/44: loss=0.1894 
[epoch 12] step 22/44: loss=0.1859 
[epoch 12] step 24/44: loss=0.1844 
[epoch 12] step 26/44: loss=0.1853 
[epoch 12] step 28/44: loss=0.1851 
[epoch 12] step 30/44: loss=0.1864 
[epoch 12] step 32/44: loss=0.1858 
[epoch 12] step 34/44: loss=0.1842 
[epoch 12] step 36/44: loss=0.1827 
[epoch 12] step 38/44: loss=0.1814 
[epoch 12] step 40/44: loss=0.1814 
[epoch 12] step 42/44: loss=0.1795 
[epoch 12] step 44/44: loss=0.1784 
[epoch 12] train_loss(avg per step)=0.3569 lambda[min,max]=[0.461618,1.000000]
[epoch 12] val_loss=1.4120 qwk=('0.3121', '0.2771', '0.3270') averageQWK=0.3054 macroEMD=0.2527 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     1   35   37   24    1
     0   23   64   67    1
     0    3   10   46    0
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    7    0
     0   34   14   34    0
     0   35   36   95    0
     0    1    5   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   38   58    8    0
     0   33  114   33    0
     0    0   18   18    0
     0    0    0    0    0
[epoch 13] step 2/44: loss=0.1701 
[epoch 13] step 4/44: loss=0.1514 
[epoch 13] step 6/44: loss=0.1507 
[epoch 13] step 8/44: loss=0.1567 
[epoch 13] step 10/44: loss=0.1574 
[epoch 13] step 12/44: loss=0.1507 
[epoch 13] step 14/44: loss=0.1431 
[epoch 13] step 16/44: loss=0.1379 
[epoch 13] step 18/44: loss=0.1464 
[epoch 13] step 20/44: loss=0.1446 
[epoch 13] step 22/44: loss=0.1446 
[epoch 13] step 24/44: loss=0.1452 
[epoch 13] step 26/44: loss=0.1470 
[epoch 13] step 28/44: loss=0.1484 
[epoch 13] step 30/44: loss=0.1472 
[epoch 13] step 32/44: loss=0.1455 
[epoch 13] step 34/44: loss=0.1468 
[epoch 13] step 36/44: loss=0.1467 
[epoch 13] step 38/44: loss=0.1464 
[epoch 13] step 40/44: loss=0.1469 
[epoch 13] step 42/44: loss=0.1478 
[epoch 13] step 44/44: loss=0.1446 
[epoch 13] train_loss(avg per step)=0.2891 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=1.5980 qwk=('0.3180', '0.3026', '0.2667') averageQWK=0.2957 macroEMD=0.2606 tailR0=('0.2381', '0.0000', '0.0000') tailR0avg=0.0794
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     4   31   39   20    4
     3   18   69   60    5
     0    2   10   45    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    7    0
     1   28   27   26    0
     0   28   53   85    0
     0    1    6   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   38   41   25    0
     0   38   68   74    0
     0    0    9   27    0
     0    0    0    0    0
[epoch 14] step 2/44: loss=0.1362 
[epoch 14] step 4/44: loss=0.1187 
[epoch 14] step 6/44: loss=0.1243 
[epoch 14] step 8/44: loss=0.1178 
[epoch 14] step 10/44: loss=0.1160 
[epoch 14] step 12/44: loss=0.1053 
[epoch 14] step 14/44: loss=0.1063 
[epoch 14] step 16/44: loss=0.1087 
[epoch 14] step 18/44: loss=0.1179 
[epoch 14] step 20/44: loss=0.1173 
[epoch 14] step 22/44: loss=0.1188 
[epoch 14] step 24/44: loss=0.1219 
[epoch 14] step 26/44: loss=0.1208 
[epoch 14] step 28/44: loss=0.1229 
[epoch 14] step 30/44: loss=0.1227 
[epoch 14] step 32/44: loss=0.1219 
[epoch 14] step 34/44: loss=0.1237 
[epoch 14] step 36/44: loss=0.1229 
[epoch 14] step 38/44: loss=0.1238 
[epoch 14] step 40/44: loss=0.1229 
[epoch 14] step 42/44: loss=0.1231 
[epoch 14] step 44/44: loss=0.1208 
[epoch 14] train_loss(avg per step)=0.2416 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=1.5188 qwk=('0.2693', '0.2430', '0.3016') averageQWK=0.2713 macroEMD=0.2586 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     1   29   41   25    2
     2   16   59   73    5
     0    1   13   45    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    8    0
     1   26   23   32    0
     1   27   48   89    1
     0    1    8   52    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   34   59   11    0
     0   30  113   37    0
     0    0   17   19    0
     0    0    0    0    0
[epoch 15] step 2/44: loss=0.0731 
[epoch 15] step 4/44: loss=0.0962 
[epoch 15] step 6/44: loss=0.0897 
[epoch 15] step 8/44: loss=0.0798 
[epoch 15] step 10/44: loss=0.0810 
[epoch 15] step 12/44: loss=0.0866 
[epoch 15] step 14/44: loss=0.0880 
[epoch 15] step 16/44: loss=0.0920 
[epoch 15] step 18/44: loss=0.0973 
[epoch 15] step 20/44: loss=0.0970 
[epoch 15] step 22/44: loss=0.0976 
[epoch 15] step 24/44: loss=0.0959 
[epoch 15] step 26/44: loss=0.0939 
[epoch 15] step 28/44: loss=0.0911 
[epoch 15] step 30/44: loss=0.0886 
[epoch 15] step 32/44: loss=0.0903 
[epoch 15] step 34/44: loss=0.0878 
[epoch 15] step 36/44: loss=0.0857 
[epoch 15] step 38/44: loss=0.0870 
[epoch 15] step 40/44: loss=0.0844 
[epoch 15] step 42/44: loss=0.0860 
[epoch 15] step 44/44: loss=0.0826 
[epoch 15] train_loss(avg per step)=0.1651 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=1.4884 qwk=('0.3075', '0.3205', '0.2944') averageQWK=0.3075 macroEMD=0.2522 tailR0=('0.1548', '0.2500', '0.0000') tailR0avg=0.1349
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     2   27   48   19    2
     2   18   76   51    8
     0    1   14   42    2
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    5    2
     1   37   24   20    0
     0   37   53   73    3
     0    1    9   51    0
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   46   44   14    0
     0   49   82   49    0
     0    2   13   21    0
     0    0    0    0    0
[epoch 16] step 2/44: loss=0.0901 
[epoch 16] step 4/44: loss=0.0589 
[epoch 16] step 6/44: loss=0.0602 
[epoch 16] step 8/44: loss=0.0600 
[epoch 16] step 10/44: loss=0.0645 
[epoch 16] step 12/44: loss=0.0652 
[epoch 16] step 14/44: loss=0.0675 
[epoch 16] step 16/44: loss=0.0667 
[epoch 16] step 18/44: loss=0.0633 
[epoch 16] step 20/44: loss=0.0616 
[epoch 16] step 22/44: loss=0.0589 
[epoch 16] step 24/44: loss=0.0585 
[epoch 16] step 26/44: loss=0.0628 
[epoch 16] step 28/44: loss=0.0627 
[epoch 16] step 30/44: loss=0.0623 
[epoch 16] step 32/44: loss=0.0591 
[epoch 16] step 34/44: loss=0.0602 
[epoch 16] step 36/44: loss=0.0611 
[epoch 16] step 38/44: loss=0.0616 
[epoch 16] step 40/44: loss=0.0639 
[epoch 16] step 42/44: loss=0.0637 
[epoch 16] step 44/44: loss=0.0640 
[epoch 16] train_loss(avg per step)=0.1280 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=1.7382 qwk=('0.2709', '0.2208', '0.2963') averageQWK=0.2627 macroEMD=0.2644 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     2   19   47   30    0
     0   12   55   88    0
     0    1    9   49    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    9    0
     1   17   27   37    0
     0   11   57   98    0
     0    0    6   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   29   61   14    0
     0   23  106   51    0
     0    0   14   22    0
     0    0    0    0    0
[epoch 17] step 2/44: loss=0.0352 
[epoch 17] step 4/44: loss=0.0483 
[epoch 17] step 6/44: loss=0.0555 
[epoch 17] step 8/44: loss=0.0659 
[epoch 17] step 10/44: loss=0.0569 
[epoch 17] step 12/44: loss=0.0485 
[epoch 17] step 14/44: loss=0.0450 
[epoch 17] step 16/44: loss=0.0444 
[epoch 17] step 18/44: loss=0.0427 
[epoch 17] step 20/44: loss=0.0453 
[epoch 17] step 22/44: loss=0.0433 
[epoch 17] step 24/44: loss=0.0440 
[epoch 17] step 26/44: loss=0.0428 
[epoch 17] step 28/44: loss=0.0442 
[epoch 17] step 30/44: loss=0.0463 
[epoch 17] step 32/44: loss=0.0453 
[epoch 17] step 34/44: loss=0.0437 
[epoch 17] step 36/44: loss=0.0427 
[epoch 17] step 38/44: loss=0.0416 
[epoch 17] step 40/44: loss=0.0424 
[epoch 17] step 42/44: loss=0.0425 
[epoch 17] step 44/44: loss=0.0415 
[epoch 17] train_loss(avg per step)=0.0830 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=1.7737 qwk=('0.2771', '0.2445', '0.2434') averageQWK=0.2550 macroEMD=0.2658 tailR0=('0.1548', '0.2500', '0.0000') tailR0avg=0.1349
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     3   20   48   24    3
     2   12   69   66    6
     0    1   10   47    1
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    9    0
     1   26   19   36    0
     1   21   36  106    2
     0    1    4   56    0
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   32   45   27    0
     0   31   82   67    0
     0    0   11   25    0
     0    0    0    0    0
[epoch 18] step 2/44: loss=-0.0291 
[epoch 18] step 4/44: loss=0.0043 
[epoch 18] step 6/44: loss=0.0058 
[epoch 18] step 8/44: loss=0.0218 
[epoch 18] step 10/44: loss=0.0235 
[epoch 18] step 12/44: loss=0.0168 
[epoch 18] step 14/44: loss=0.0156 
[epoch 18] step 16/44: loss=0.0140 
[epoch 18] step 18/44: loss=0.0173 
[epoch 18] step 20/44: loss=0.0152 
[epoch 18] step 22/44: loss=0.0117 
[epoch 18] step 24/44: loss=0.0114 
[epoch 18] step 26/44: loss=0.0098 
[epoch 18] step 28/44: loss=0.0088 
[epoch 18] step 30/44: loss=0.0080 
[epoch 18] step 32/44: loss=0.0094 
[epoch 18] step 34/44: loss=0.0112 
[epoch 18] step 36/44: loss=0.0101 
[epoch 18] step 38/44: loss=0.0094 
[epoch 18] step 40/44: loss=0.0106 
[epoch 18] step 42/44: loss=0.0103 
[epoch 18] step 44/44: loss=0.0103 
[epoch 18] train_loss(avg per step)=0.0206 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=1.7851 qwk=('0.2479', '0.2075', '0.2879') averageQWK=0.2478 macroEMD=0.2683 tailR0=('0.2381', '0.0000', '0.0000') tailR0avg=0.0794
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    4    1
     2   21   47   21    7
     2   13   63   64   13
     0    1    9   46    3
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    9    0
     1   15   26   40    0
     0   11   48  107    0
     0    0    3   58    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   33   56   15    0
     0   28   95   57    0
     0    0   14   22    0
     0    0    0    0    0
[epoch 19] step 2/44: loss=0.0142 
[epoch 19] step 4/44: loss=0.0133 
[epoch 19] step 6/44: loss=0.0015 
[epoch 19] step 8/44: loss=-0.0039 
[epoch 19] step 10/44: loss=-0.0021 
[epoch 19] step 12/44: loss=0.0016 
[epoch 19] step 14/44: loss=0.0046 
[epoch 19] step 16/44: loss=0.0057 
[epoch 19] step 18/44: loss=0.0058 
[epoch 19] step 20/44: loss=0.0047 
[epoch 19] step 22/44: loss=0.0037 
[epoch 19] step 24/44: loss=0.0023 
[epoch 19] step 26/44: loss=0.0031 
[epoch 19] step 28/44: loss=0.0015 
[epoch 19] step 30/44: loss=-0.0008 
[epoch 19] step 32/44: loss=-0.0009 
[epoch 19] step 34/44: loss=-0.0016 
[epoch 19] step 36/44: loss=-0.0019 
[epoch 19] step 38/44: loss=-0.0024 
[epoch 19] step 40/44: loss=-0.0022 
[epoch 19] step 42/44: loss=-0.0046 
[epoch 19] step 44/44: loss=-0.0062 
[epoch 19] train_loss(avg per step)=-0.0124 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=1.6843 qwk=('0.3188', '0.2387', '0.2915') averageQWK=0.2830 macroEMD=0.2619 tailR0=('0.2381', '0.0000', '0.0000') tailR0avg=0.0794
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    3    1
     2   28   50   15    3
     1   20   82   42   10
     0    1   16   39    3
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    8    0
     1   24   20   37    0
     0   20   45  101    0
     0    0    7   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   34   52   18    0
     0   31   90   59    0
     0    0   12   24    0
     0    0    0    0    0
[epoch 20] step 2/44: loss=-0.0165 
[epoch 20] step 4/44: loss=-0.0191 
[epoch 20] step 6/44: loss=-0.0252 
[epoch 20] step 8/44: loss=-0.0253 
[epoch 20] step 10/44: loss=-0.0239 
[epoch 20] step 12/44: loss=-0.0250 
[epoch 20] step 14/44: loss=-0.0279 
[epoch 20] step 16/44: loss=-0.0283 
[epoch 20] step 18/44: loss=-0.0284 
[epoch 20] step 20/44: loss=-0.0258 
[epoch 20] step 22/44: loss=-0.0261 
[epoch 20] step 24/44: loss=-0.0268 
[epoch 20] step 26/44: loss=-0.0261 
[epoch 20] step 28/44: loss=-0.0272 
[epoch 20] step 30/44: loss=-0.0260 
[epoch 20] step 32/44: loss=-0.0252 
[epoch 20] step 34/44: loss=-0.0247 
[epoch 20] step 36/44: loss=-0.0244 
[epoch 20] step 38/44: loss=-0.0236 
[epoch 20] step 40/44: loss=-0.0234 
[epoch 20] step 42/44: loss=-0.0229 
[epoch 20] step 44/44: loss=-0.0224 
[epoch 20] train_loss(avg per step)=-0.0448 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=1.7136 qwk=('0.3313', '0.2741', '0.2596') averageQWK=0.2884 macroEMD=0.2614 tailR0=('0.0714', '0.0357', '0.0000') tailR0avg=0.0357
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     2   28   48   19    1
     2   15   80   56    2
     0    1   12   46    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    6    0
     1   22   30   28    1
     0   19   61   86    0
     0    0   10   51    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   39   42   23    0
     0   44   76   60    0
     0    1   10   25    0
     0    0    0    0    0
[epoch 21] step 2/44: loss=-0.0392 
[epoch 21] step 4/44: loss=-0.0387 
[epoch 21] step 6/44: loss=-0.0339 
[epoch 21] step 8/44: loss=-0.0344 
[epoch 21] step 10/44: loss=-0.0344 
[epoch 21] step 12/44: loss=-0.0304 
[epoch 21] step 14/44: loss=-0.0312 
[epoch 21] step 16/44: loss=-0.0335 
[epoch 21] step 18/44: loss=-0.0351 
[epoch 21] step 20/44: loss=-0.0376 
[epoch 21] step 22/44: loss=-0.0381 
[epoch 21] step 24/44: loss=-0.0385 
[epoch 21] step 26/44: loss=-0.0396 
[epoch 21] step 28/44: loss=-0.0385 
[epoch 21] step 30/44: loss=-0.0400 
[epoch 21] step 32/44: loss=-0.0381 
[epoch 21] step 34/44: loss=-0.0389 
[epoch 21] step 36/44: loss=-0.0398 
[epoch 21] step 38/44: loss=-0.0410 
[epoch 21] step 40/44: loss=-0.0405 
[epoch 21] step 42/44: loss=-0.0402 
[epoch 21] step 44/44: loss=-0.0418 
[epoch 21] train_loss(avg per step)=-0.0837 lambda[min,max]=[0.494251,1.000000]
[epoch 21] val_loss=1.7811 qwk=('0.3015', '0.2342', '0.2944') averageQWK=0.2767 macroEMD=0.2616 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     2   26   47   22    1
     1   15   71   62    6
     0    1   11   47    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    7    1
     1   27   17   37    0
     0   28   39   98    1
     0    0    8   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   43   46   15    0
     0   44   81   55    0
     0    1   14   21    0
     0    0    0    0    0
[epoch 22] step 2/44: loss=-0.0620 
[epoch 22] step 4/44: loss=-0.0579 
[epoch 22] step 6/44: loss=-0.0562 
[epoch 22] step 8/44: loss=-0.0545 
[epoch 22] step 10/44: loss=-0.0510 
[epoch 22] step 12/44: loss=-0.0484 
[epoch 22] step 14/44: loss=-0.0503 
[epoch 22] step 16/44: loss=-0.0519 
[epoch 22] step 18/44: loss=-0.0526 
[epoch 22] step 20/44: loss=-0.0523 
[epoch 22] step 22/44: loss=-0.0547 
[epoch 22] step 24/44: loss=-0.0552 
[epoch 22] step 26/44: loss=-0.0551 
[epoch 22] step 28/44: loss=-0.0555 
[epoch 22] step 30/44: loss=-0.0551 
[epoch 22] step 32/44: loss=-0.0550 
[epoch 22] step 34/44: loss=-0.0535 
[epoch 22] step 36/44: loss=-0.0516 
[epoch 22] step 38/44: loss=-0.0524 
[epoch 22] step 40/44: loss=-0.0521 
[epoch 22] step 42/44: loss=-0.0518 
[epoch 22] step 44/44: loss=-0.0505 
[epoch 22] train_loss(avg per step)=-0.1010 lambda[min,max]=[0.477756,1.000000]
[epoch 22] val_loss=1.8502 qwk=('0.2871', '0.2387', '0.2868') averageQWK=0.2709 macroEMD=0.2665 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     2   31   33   31    1
     1   18   46   88    2
     0    1    8   50    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    5    1
     1   16   32   33    0
     0   15   67   84    0
     0    0    8   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   33   49   22    0
     0   29   90   61    0
     0    0    9   27    0
     0    0    0    0    0
[epoch 23] step 2/44: loss=-0.0170 
[epoch 23] step 4/44: loss=-0.0347 
[epoch 23] step 6/44: loss=-0.0475 
[epoch 23] step 8/44: loss=-0.0560 
[epoch 23] step 10/44: loss=-0.0571 
[epoch 23] step 12/44: loss=-0.0589 
[epoch 23] step 14/44: loss=-0.0578 
[epoch 23] step 16/44: loss=-0.0560 
[epoch 23] step 18/44: loss=-0.0582 
[epoch 23] step 20/44: loss=-0.0594 
[epoch 23] step 22/44: loss=-0.0603 
[epoch 23] step 24/44: loss=-0.0596 
[epoch 23] step 26/44: loss=-0.0593 
[epoch 23] step 28/44: loss=-0.0598 
[epoch 23] step 30/44: loss=-0.0581 
[epoch 23] step 32/44: loss=-0.0585 
[epoch 23] step 34/44: loss=-0.0580 
[epoch 23] step 36/44: loss=-0.0578 
[epoch 23] step 38/44: loss=-0.0585 
[epoch 23] step 40/44: loss=-0.0585 
[epoch 23] step 42/44: loss=-0.0588 
[epoch 23] step 44/44: loss=-0.0599 
[epoch 23] train_loss(avg per step)=-0.1198 lambda[min,max]=[0.428357,1.000000]
[epoch 23] val_loss=1.7160 qwk=('0.3306', '0.2895', '0.3225') averageQWK=0.3142 macroEMD=0.2542 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     2   28   47   21    0
     2   15   80   56    2
     0    1   11   47    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    5    1
     3   22   35   22    0
     0   22   63   80    1
     0    0   13   48    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   37   52   15    0
     0   33   99   48    0
     0    0   11   25    0
     0    0    0    0    0
[epoch 24] step 2/44: loss=-0.0905 
[epoch 24] step 4/44: loss=-0.0820 
[epoch 24] step 6/44: loss=-0.0761 
[epoch 24] step 8/44: loss=-0.0773 
[epoch 24] step 10/44: loss=-0.0730 
[epoch 24] step 12/44: loss=-0.0744 
[epoch 24] step 14/44: loss=-0.0726 
[epoch 24] step 16/44: loss=-0.0750 
[epoch 24] step 18/44: loss=-0.0748 
[epoch 24] step 20/44: loss=-0.0742 
[epoch 24] step 22/44: loss=-0.0735 
[epoch 24] step 24/44: loss=-0.0736 
[epoch 24] step 26/44: loss=-0.0737 
[epoch 24] step 28/44: loss=-0.0734 
[epoch 24] step 30/44: loss=-0.0735 
[epoch 24] step 32/44: loss=-0.0737 
[epoch 24] step 34/44: loss=-0.0744 
[epoch 24] step 36/44: loss=-0.0738 
[epoch 24] step 38/44: loss=-0.0731 
[epoch 24] step 40/44: loss=-0.0733 
[epoch 24] step 42/44: loss=-0.0742 
[epoch 24] step 44/44: loss=-0.0734 
[epoch 24] train_loss(avg per step)=-0.1468 lambda[min,max]=[0.449962,1.000000]
[epoch 24] val_loss=1.7391 qwk=('0.2934', '0.2969', '0.2605') averageQWK=0.2836 macroEMD=0.2609 tailR0=('0.0714', '0.2500', '0.0000') tailR0avg=0.1071
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     2   29   47   14    6
     2   19   74   47   13
     0    1   12   42    4
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    3    4    1
     3   27   23   29    0
     0   29   53   81    3
     0    1   10   50    0
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   44   42   18    0
     0   43   88   49    0
     0    3   13   20    0
     0    0    0    0    0
[epoch 25] step 2/44: loss=-0.0881 
[epoch 25] step 4/44: loss=-0.0842 
[epoch 25] step 6/44: loss=-0.0860 
[epoch 25] step 8/44: loss=-0.0851 
[epoch 25] step 10/44: loss=-0.0829 
[epoch 25] step 12/44: loss=-0.0835 
[epoch 25] step 14/44: loss=-0.0826 
[epoch 25] step 16/44: loss=-0.0814 
[epoch 25] step 18/44: loss=-0.0812 
[epoch 25] step 20/44: loss=-0.0805 
[epoch 25] step 22/44: loss=-0.0798 
[epoch 25] step 24/44: loss=-0.0790 
[epoch 25] step 26/44: loss=-0.0788 
[epoch 25] step 28/44: loss=-0.0790 
[epoch 25] step 30/44: loss=-0.0792 
[epoch 25] step 32/44: loss=-0.0792 
[epoch 25] step 34/44: loss=-0.0791 
[epoch 25] step 36/44: loss=-0.0792 
[epoch 25] step 38/44: loss=-0.0786 
[epoch 25] step 40/44: loss=-0.0781 
[epoch 25] step 42/44: loss=-0.0776 
[epoch 25] step 44/44: loss=-0.0767 
[epoch 25] train_loss(avg per step)=-0.1534 lambda[min,max]=[0.404253,1.000000]
[epoch 25] val_loss=1.7852 qwk=('0.2964', '0.2510', '0.2789') averageQWK=0.2754 macroEMD=0.2619 tailR0=('0.0714', '0.2857', '0.0000') tailR0avg=0.1190
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     3   23   50   22    0
     3   14   81   53    4
     0    2   13   44    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    7    1
     1   27   25   29    0
     0   27   53   84    2
     0    2   11   48    0
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   40   50   14    0
     0   39   95   46    0
     0    0   19   17    0
     0    0    0    0    0
[epoch 26] step 2/44: loss=-0.0912 
[epoch 26] step 4/44: loss=-0.0860 
[epoch 26] step 6/44: loss=-0.0877 
[epoch 26] step 8/44: loss=-0.0882 
[epoch 26] step 10/44: loss=-0.0893 
[epoch 26] step 12/44: loss=-0.0845 
[epoch 26] step 14/44: loss=-0.0851 
[epoch 26] step 16/44: loss=-0.0830 
[epoch 26] step 18/44: loss=-0.0826 
[epoch 26] step 20/44: loss=-0.0801 
[epoch 26] step 22/44: loss=-0.0811 
[epoch 26] step 24/44: loss=-0.0819 
[epoch 26] step 26/44: loss=-0.0824 
[epoch 26] step 28/44: loss=-0.0829 
[epoch 26] step 30/44: loss=-0.0832 
[epoch 26] step 32/44: loss=-0.0836 
[epoch 26] step 34/44: loss=-0.0838 
[epoch 26] step 36/44: loss=-0.0834 
[epoch 26] step 38/44: loss=-0.0833 
[epoch 26] step 40/44: loss=-0.0838 
[epoch 26] step 42/44: loss=-0.0836 
[epoch 26] step 44/44: loss=-0.0842 
[epoch 26] train_loss(avg per step)=-0.1684 lambda[min,max]=[0.462569,1.000000]
[epoch 26] val_loss=1.8432 qwk=('0.3115', '0.2704', '0.2669') averageQWK=0.2830 macroEMD=0.2603 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     5   21   50   21    1
     3    8   82   57    5
     0    1   12   46    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    6    1
     2   26   23   31    0
     0   22   57   86    1
     0    1    7   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   33   50   21    0
     0   30   90   60    0
     0    0   13   23    0
     0    0    0    0    0
[epoch 27] step 2/44: loss=-0.0826 
[epoch 27] step 4/44: loss=-0.0845 
[epoch 27] step 6/44: loss=-0.0844 
[epoch 27] step 8/44: loss=-0.0870 
[epoch 27] step 10/44: loss=-0.0862 
[epoch 27] step 12/44: loss=-0.0851 
[epoch 27] step 14/44: loss=-0.0841 
[epoch 27] step 16/44: loss=-0.0841 
[epoch 27] step 18/44: loss=-0.0837 
[epoch 27] step 20/44: loss=-0.0840 
[epoch 27] step 22/44: loss=-0.0845 
[epoch 27] step 24/44: loss=-0.0855 
[epoch 27] step 26/44: loss=-0.0860 
[epoch 27] step 28/44: loss=-0.0866 
[epoch 27] step 30/44: loss=-0.0876 
[epoch 27] step 32/44: loss=-0.0877 
[epoch 27] step 34/44: loss=-0.0878 
[epoch 27] step 36/44: loss=-0.0878 
[epoch 27] step 38/44: loss=-0.0881 
[epoch 27] step 40/44: loss=-0.0883 
[epoch 27] step 42/44: loss=-0.0883 
[epoch 27] step 44/44: loss=-0.0883 
[epoch 27] train_loss(avg per step)=-0.1765 lambda[min,max]=[0.473180,1.000000]
[epoch 27] val_loss=1.9438 qwk=('0.2990', '0.2509', '0.2920') averageQWK=0.2807 macroEMD=0.2625 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     8   15   48   26    1
     4    5   70   75    1
     0    1    9   49    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    7    1
     1   25   23   33    0
     0   21   53   91    1
     0    0    8   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   39   47   18    0
     0   35   87   58    0
     0    0   14   22    0
     0    0    0    0    0
[epoch 28] step 2/44: loss=-0.0905 
[epoch 28] step 4/44: loss=-0.0908 
[epoch 28] step 6/44: loss=-0.0868 
[epoch 28] step 8/44: loss=-0.0866 
[epoch 28] step 10/44: loss=-0.0864 
[epoch 28] step 12/44: loss=-0.0867 
[epoch 28] step 14/44: loss=-0.0879 
[epoch 28] step 16/44: loss=-0.0887 
[epoch 28] step 18/44: loss=-0.0884 
[epoch 28] step 20/44: loss=-0.0880 
[epoch 28] step 22/44: loss=-0.0888 
[epoch 28] step 24/44: loss=-0.0887 
[epoch 28] step 26/44: loss=-0.0886 
[epoch 28] step 28/44: loss=-0.0893 
[epoch 28] step 30/44: loss=-0.0894 
[epoch 28] step 32/44: loss=-0.0899 
[epoch 28] step 34/44: loss=-0.0893 
[epoch 28] step 36/44: loss=-0.0892 
[epoch 28] step 38/44: loss=-0.0894 
[epoch 28] step 40/44: loss=-0.0898 
[epoch 28] step 42/44: loss=-0.0904 
[epoch 28] step 44/44: loss=-0.0908 
[epoch 28] train_loss(avg per step)=-0.1817 lambda[min,max]=[0.429752,1.000000]
[epoch 28] val_loss=1.9191 qwk=('0.2987', '0.2327', '0.2560') averageQWK=0.2625 macroEMD=0.2612 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     5   21   45   26    1
     3   11   68   68    5
     0    1    8   50    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    7    1
     1   26   19   36    0
     0   21   50   94    1
     0    1    8   52    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   38   52   14    0
     0   38  100   42    0
     0    1   19   16    0
     0    0    0    0    0
[epoch 29] step 2/44: loss=-0.0893 
[epoch 29] step 4/44: loss=-0.0913 
[epoch 29] step 6/44: loss=-0.0908 
[epoch 29] step 8/44: loss=-0.0919 
[epoch 29] step 10/44: loss=-0.0937 
[epoch 29] step 12/44: loss=-0.0945 
[epoch 29] step 14/44: loss=-0.0957 
[epoch 29] step 16/44: loss=-0.0964 
[epoch 29] step 18/44: loss=-0.0970 
[epoch 29] step 20/44: loss=-0.0973 
[epoch 29] step 22/44: loss=-0.0968 
[epoch 29] step 24/44: loss=-0.0969 
[epoch 29] step 26/44: loss=-0.0975 
[epoch 29] step 28/44: loss=-0.0977 
[epoch 29] step 30/44: loss=-0.0973 
[epoch 29] step 32/44: loss=-0.0974 
[epoch 29] step 34/44: loss=-0.0972 
[epoch 29] step 36/44: loss=-0.0970 
[epoch 29] step 38/44: loss=-0.0966 
[epoch 29] step 40/44: loss=-0.0965 
[epoch 29] step 42/44: loss=-0.0966 
[epoch 29] step 44/44: loss=-0.0963 
[epoch 29] train_loss(avg per step)=-0.1925 lambda[min,max]=[0.492923,1.000000]
[epoch 29] val_loss=1.8538 qwk=('0.3072', '0.2451', '0.2833') averageQWK=0.2785 macroEMD=0.2620 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     5   18   53   21    1
     3    7   79   62    4
     0    1   11   47    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    6    2
     1   28   26   26    1
     0   21   61   81    3
     0    1   10   50    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   36   49   19    0
     0   34   82   64    0
     0    0   13   23    0
     0    0    0    0    0
[epoch 30] step 2/44: loss=-0.0967 
[epoch 30] step 4/44: loss=-0.0953 
[epoch 30] step 6/44: loss=-0.0973 
[epoch 30] step 8/44: loss=-0.0981 
[epoch 30] step 10/44: loss=-0.0971 
[epoch 30] step 12/44: loss=-0.0982 
[epoch 30] step 14/44: loss=-0.0972 
[epoch 30] step 16/44: loss=-0.0965 
[epoch 30] step 18/44: loss=-0.0966 
[epoch 30] step 20/44: loss=-0.0964 
[epoch 30] step 22/44: loss=-0.0969 
[epoch 30] step 24/44: loss=-0.0971 
[epoch 30] step 26/44: loss=-0.0968 
[epoch 30] step 28/44: loss=-0.0967 
[epoch 30] step 30/44: loss=-0.0971 
[epoch 30] step 32/44: loss=-0.0973 
[epoch 30] step 34/44: loss=-0.0972 
[epoch 30] step 36/44: loss=-0.0973 
[epoch 30] step 38/44: loss=-0.0976 
[epoch 30] step 40/44: loss=-0.0975 
[epoch 30] step 42/44: loss=-0.0972 
[epoch 30] step 44/44: loss=-0.0977 
[epoch 30] train_loss(avg per step)=-0.1953 lambda[min,max]=[0.349617,1.000000]
[epoch 30] val_loss=1.9695 qwk=('0.2807', '0.2298', '0.2897') averageQWK=0.2667 macroEMD=0.2656 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    1    5    0
     5   16   53   22    2
     3    7   68   68    9
     0    1    9   48    1
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    8    1
     2   22   22   36    0
     0   18   51   96    1
     0    0    6   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   40   46   18    0
     0   35   89   56    0
     0    0   15   21    0
     0    0    0    0    0
[epoch 31] step 2/44: loss=-0.0993 
[epoch 31] step 4/44: loss=-0.1003 
[epoch 31] step 6/44: loss=-0.1008 
[epoch 31] step 8/44: loss=-0.1021 
[epoch 31] step 10/44: loss=-0.1016 
[epoch 31] step 12/44: loss=-0.1015 
[epoch 31] step 14/44: loss=-0.1002 
[epoch 31] step 16/44: loss=-0.1005 
[epoch 31] step 18/44: loss=-0.1009 
[epoch 31] step 20/44: loss=-0.1011 
[epoch 31] step 22/44: loss=-0.1013 
[epoch 31] step 24/44: loss=-0.1007 
[epoch 31] step 26/44: loss=-0.1008 
[epoch 31] step 28/44: loss=-0.1005 
[epoch 31] step 30/44: loss=-0.1006 
[epoch 31] step 32/44: loss=-0.1007 
[epoch 31] step 34/44: loss=-0.1005 
[epoch 31] step 36/44: loss=-0.1007 
[epoch 31] step 38/44: loss=-0.1006 
[epoch 31] step 40/44: loss=-0.1009 
[epoch 31] step 42/44: loss=-0.1006 
[epoch 31] step 44/44: loss=-0.1006 
[epoch 31] train_loss(avg per step)=-0.2012 lambda[min,max]=[0.480059,1.000000]
[epoch 31] val_loss=1.8741 qwk=('0.2922', '0.2136', '0.2888') averageQWK=0.2649 macroEMD=0.2618 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     5   19   50   21    3
     3    9   75   61    7
     0    1   10   46    2
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    7    1
     1   24   22   35    0
     0   22   54   88    2
     0    1   10   50    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   43   46   15    0
     0   40   91   49    0
     0    1   16   19    0
     0    0    0    0    0
[epoch 32] step 2/44: loss=-0.0970 
[epoch 32] step 4/44: loss=-0.1000 
[epoch 32] step 6/44: loss=-0.1004 
[epoch 32] step 8/44: loss=-0.0993 
[epoch 32] step 10/44: loss=-0.0999 
[epoch 32] step 12/44: loss=-0.0993 
[epoch 32] step 14/44: loss=-0.0990 
[epoch 32] step 16/44: loss=-0.0989 
[epoch 32] step 18/44: loss=-0.0985 
[epoch 32] step 20/44: loss=-0.0984 
[epoch 32] step 22/44: loss=-0.0991 
[epoch 32] step 24/44: loss=-0.0993 
[epoch 32] step 26/44: loss=-0.0994 
[epoch 32] step 28/44: loss=-0.0994 
[epoch 32] step 30/44: loss=-0.0995 
[epoch 32] step 32/44: loss=-0.0998 
[epoch 32] step 34/44: loss=-0.1000 
[epoch 32] step 36/44: loss=-0.1005 
[epoch 32] step 38/44: loss=-0.1005 
[epoch 32] step 40/44: loss=-0.1008 
[epoch 32] step 42/44: loss=-0.1005 
[epoch 32] step 44/44: loss=-0.1006 
[epoch 32] train_loss(avg per step)=-0.2011 lambda[min,max]=[0.457652,1.000000]
[epoch 32] val_loss=1.9355 qwk=('0.2970', '0.2348', '0.2848') averageQWK=0.2722 macroEMD=0.2610 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     6   22   46   21    3
     3   13   69   63    7
     0    1   10   48    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    7    1
     3   23   20   36    0
     0   21   51   93    1
     0    1    6   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   42   47   15    0
     0   40   90   50    0
     0    1   16   19    0
     0    0    0    0    0
[epoch 33] step 2/44: loss=-0.0954 
[epoch 33] step 4/44: loss=-0.1005 
[epoch 33] step 6/44: loss=-0.1005 
[epoch 33] step 8/44: loss=-0.1006 
[epoch 33] step 10/44: loss=-0.1015 
[epoch 33] step 12/44: loss=-0.1021 
[epoch 33] step 14/44: loss=-0.1017 
[epoch 33] step 16/44: loss=-0.1018 
[epoch 33] step 18/44: loss=-0.1024 
[epoch 33] step 20/44: loss=-0.1030 
[epoch 33] step 22/44: loss=-0.1031 
[epoch 33] step 24/44: loss=-0.1034 
[epoch 33] step 26/44: loss=-0.1032 
[epoch 33] step 28/44: loss=-0.1031 
[epoch 33] step 30/44: loss=-0.1031 
[epoch 33] step 32/44: loss=-0.1032 
[epoch 33] step 34/44: loss=-0.1034 
[epoch 33] step 36/44: loss=-0.1036 
[epoch 33] step 38/44: loss=-0.1036 
[epoch 33] step 40/44: loss=-0.1037 
[epoch 33] step 42/44: loss=-0.1038 
[epoch 33] step 44/44: loss=-0.1037 
[epoch 33] train_loss(avg per step)=-0.2075 lambda[min,max]=[0.459526,1.000000]
[epoch 33] val_loss=1.8635 qwk=('0.2934', '0.2217', '0.2749') averageQWK=0.2633 macroEMD=0.2617 tailR0=('0.0714', '0.2500', '0.0000') tailR0avg=0.1071
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     5   19   50   21    3
     3    9   75   60    8
     0    1   10   45    3
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    5    2
     1   24   23   31    3
     0   23   56   83    4
     0    1    8   52    0
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   36   52   16    0
     0   33   98   49    0
     0    0   17   19    0
     0    0    0    0    0
[epoch 34] step 2/44: loss=-0.1086 
[epoch 34] step 4/44: loss=-0.1064 
[epoch 34] step 6/44: loss=-0.1047 
[epoch 34] step 8/44: loss=-0.1048 
[epoch 34] step 10/44: loss=-0.1051 
[epoch 34] step 12/44: loss=-0.1044 
[epoch 34] step 14/44: loss=-0.1049 
[epoch 34] step 16/44: loss=-0.1048 
[epoch 34] step 18/44: loss=-0.1045 
[epoch 34] step 20/44: loss=-0.1045 
[epoch 34] step 22/44: loss=-0.1043 
[epoch 34] step 24/44: loss=-0.1046 
[epoch 34] step 26/44: loss=-0.1046 
[epoch 34] step 28/44: loss=-0.1045 
[epoch 34] step 30/44: loss=-0.1043 
[epoch 34] step 32/44: loss=-0.1047 
[epoch 34] step 34/44: loss=-0.1045 
[epoch 34] step 36/44: loss=-0.1043 
[epoch 34] step 38/44: loss=-0.1045 
[epoch 34] step 40/44: loss=-0.1045 
[epoch 34] step 42/44: loss=-0.1043 
[epoch 34] step 44/44: loss=-0.1042 
[epoch 34] train_loss(avg per step)=-0.2085 lambda[min,max]=[0.454297,1.000000]
[epoch 34] val_loss=1.9039 qwk=('0.2915', '0.2297', '0.2944') averageQWK=0.2719 macroEMD=0.2609 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     5   20   49   21    3
     3   10   73   62    7
     0    1   10   47    1
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    7    1
     1   23   22   36    0
     0   16   60   89    1
     0    0    8   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   41   48   15    0
     0   37   93   50    0
     0    0   17   19    0
     0    0    0    0    0
[epoch 35] step 2/44: loss=-0.1054 
[epoch 35] step 4/44: loss=-0.1067 
[epoch 35] step 6/44: loss=-0.1068 
[epoch 35] step 8/44: loss=-0.1062 
[epoch 35] step 10/44: loss=-0.1060 
[epoch 35] step 12/44: loss=-0.1060 
[epoch 35] step 14/44: loss=-0.1058 
[epoch 35] step 16/44: loss=-0.1054 
[epoch 35] step 18/44: loss=-0.1047 
[epoch 35] step 20/44: loss=-0.1048 
[epoch 35] step 22/44: loss=-0.1052 
[epoch 35] step 24/44: loss=-0.1052 
[epoch 35] step 26/44: loss=-0.1053 
[epoch 35] step 28/44: loss=-0.1053 
[epoch 35] step 30/44: loss=-0.1052 
[epoch 35] step 32/44: loss=-0.1053 
[epoch 35] step 34/44: loss=-0.1050 
[epoch 35] step 36/44: loss=-0.1049 
[epoch 35] step 38/44: loss=-0.1047 
[epoch 35] step 40/44: loss=-0.1046 
[epoch 35] step 42/44: loss=-0.1047 
[epoch 35] step 44/44: loss=-0.1048 
[epoch 35] train_loss(avg per step)=-0.2095 lambda[min,max]=[0.474632,1.000000]
[epoch 35] val_loss=1.9161 qwk=('0.2917', '0.2285', '0.2845') averageQWK=0.2682 macroEMD=0.2611 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    5    0
     5   20   49   21    3
     3   10   74   61    7
     0    1   10   47    1
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    7    1
     1   25   21   35    0
     0   19   58   88    1
     0    1    8   52    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   40   46   18    0
     0   34   96   50    0
     0    0   16   20    0
     0    0    0    0    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold2/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-0-mixture-1-conf_gating-0-reassignment-0/fold2/metrics.json
Done.
