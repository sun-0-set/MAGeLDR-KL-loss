[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.8724 
[epoch 1] step 4/44: loss=7.0088 
[epoch 1] step 6/44: loss=6.9563 
[epoch 1] step 8/44: loss=7.0201 
[epoch 1] step 10/44: loss=7.0849 
[epoch 1] step 12/44: loss=7.0550 
[epoch 1] step 14/44: loss=7.0386 
[epoch 1] step 16/44: loss=7.0445 
[epoch 1] step 18/44: loss=7.0564 
[epoch 1] step 20/44: loss=6.9677 
[epoch 1] step 22/44: loss=6.9559 
[epoch 1] step 24/44: loss=6.9264 
[epoch 1] step 26/44: loss=6.9375 
[epoch 1] step 28/44: loss=6.8822 
[epoch 1] step 30/44: loss=6.8749 
[epoch 1] step 32/44: loss=6.8112 
[epoch 1] step 34/44: loss=6.7871 
[epoch 1] step 36/44: loss=6.7492 
[epoch 1] step 38/44: loss=6.7107 
[epoch 1] step 40/44: loss=6.6710 
[epoch 1] step 42/44: loss=6.6061 
[epoch 1] step 44/44: loss=6.5135 
[epoch 1] train_loss(avg per step)=13.0269 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=10.1295 qwk=('0.0294', '0.0978', '-0.0278') averageQWK=0.0331 macroEMD=0.3849 tailR0=('0.0000', '0.1667', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   12    0    3    0
     0   57    0   21    0
     0  116    0   46    0
     0   45    0   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    4    0    0
     6    0   10    0    0
    23    0   43    0    0
    36    0  169    0    0
     2    0   28    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    1   28    0    0
     0    2  109    0    0
     0   11  170    0    0
     0    0    1    0    0
[epoch 2] step 2/44: loss=4.9345 
[epoch 2] step 4/44: loss=4.7324 
[epoch 2] step 6/44: loss=4.5880 
[epoch 2] step 8/44: loss=4.4740 
[epoch 2] step 10/44: loss=4.2836 
[epoch 2] step 12/44: loss=4.2828 
[epoch 2] step 14/44: loss=4.2656 
[epoch 2] step 16/44: loss=4.1750 
[epoch 2] step 18/44: loss=4.1192 
[epoch 2] step 20/44: loss=4.0285 
[epoch 2] step 22/44: loss=3.9872 
[epoch 2] step 24/44: loss=3.9487 
[epoch 2] step 26/44: loss=3.8829 
[epoch 2] step 28/44: loss=3.8454 
[epoch 2] step 30/44: loss=3.7965 
[epoch 2] step 32/44: loss=3.7581 
[epoch 2] step 34/44: loss=3.7439 
[epoch 2] step 36/44: loss=3.7087 
[epoch 2] step 38/44: loss=3.6744 
[epoch 2] step 40/44: loss=3.6367 
[epoch 2] step 42/44: loss=3.5939 
[epoch 2] step 44/44: loss=3.5637 
[epoch 2] train_loss(avg per step)=7.1274 lambda[min,max]=[0.512688,1.000000]
[epoch 2] val_loss=4.9920 qwk=('0.0329', '0.1061', '0.1678') averageQWK=0.1023 macroEMD=0.3794 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    0   15    0    0
     0    0   71    7    0
     0    0  134   28    0
     0    0   62    2    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   12    4    0
     0    0   35   31    0
     0    0  106   99    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   26    1    0
     0    4   88   19    0
     0    1  134   46    0
     0    0    0    1    0
[epoch 3] step 2/44: loss=3.4414 
[epoch 3] step 4/44: loss=3.0202 
[epoch 3] step 6/44: loss=3.0126 
[epoch 3] step 8/44: loss=2.9898 
[epoch 3] step 10/44: loss=2.9958 
[epoch 3] step 12/44: loss=2.9232 
[epoch 3] step 14/44: loss=2.8798 
[epoch 3] step 16/44: loss=2.8397 
[epoch 3] step 18/44: loss=2.8207 
[epoch 3] step 20/44: loss=2.8127 
[epoch 3] step 22/44: loss=2.7801 
[epoch 3] step 24/44: loss=2.7565 
[epoch 3] step 26/44: loss=2.7214 
[epoch 3] step 28/44: loss=2.7086 
[epoch 3] step 30/44: loss=2.7017 
[epoch 3] step 32/44: loss=2.6769 
[epoch 3] step 34/44: loss=2.6554 
[epoch 3] step 36/44: loss=2.6445 
[epoch 3] step 38/44: loss=2.6204 
[epoch 3] step 40/44: loss=2.6214 
[epoch 3] step 42/44: loss=2.6077 
[epoch 3] step 44/44: loss=2.6136 
[epoch 3] train_loss(avg per step)=5.2273 lambda[min,max]=[0.507974,1.000000]
[epoch 3] val_loss=6.5939 qwk=('0.1335', '0.0431', '0.1615') averageQWK=0.1127 macroEMD=0.3746 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   10    4    1    0
     0   33   40    5    0
     0   26  101   35    0
     0   12   48    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   16    0    0
     0    0   62    4    0
     0    0  185   20    0
     0    0   28    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   23    6    0    0
     0   36   74    1    0
     0   49  117   15    0
     0    0    1    0    0
[epoch 4] step 2/44: loss=2.8776 
[epoch 4] step 4/44: loss=2.6091 
[epoch 4] step 6/44: loss=2.5910 
[epoch 4] step 8/44: loss=2.5763 
[epoch 4] step 10/44: loss=2.5336 
[epoch 4] step 12/44: loss=2.5182 
[epoch 4] step 14/44: loss=2.5055 
[epoch 4] step 16/44: loss=2.4574 
[epoch 4] step 18/44: loss=2.4010 
[epoch 4] step 20/44: loss=2.3995 
[epoch 4] step 22/44: loss=2.3987 
[epoch 4] step 24/44: loss=2.4064 
[epoch 4] step 26/44: loss=2.4077 
[epoch 4] step 28/44: loss=2.4193 
[epoch 4] step 30/44: loss=2.3867 
[epoch 4] step 32/44: loss=2.3869 
[epoch 4] step 34/44: loss=2.3739 
[epoch 4] step 36/44: loss=2.3621 
[epoch 4] step 38/44: loss=2.3575 
[epoch 4] step 40/44: loss=2.3486 
[epoch 4] step 42/44: loss=2.3431 
[epoch 4] step 44/44: loss=2.3432 
[epoch 4] train_loss(avg per step)=4.6865 lambda[min,max]=[0.504511,1.000000]
[epoch 4] val_loss=5.1409 qwk=('0.2106', '0.2672', '0.2494') averageQWK=0.2424 macroEMD=0.3604 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   10    4    1    0
     0   29   33   16    0
     0   17   85   60    0
     0   10   32   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5   10    1    0
     0    5   49   12    0
     0   10  122   73    0
     0    2   11   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22    7    0    0
     0   37   67    7    0
     0   33  113   35    0
     0    0    1    0    0
[epoch 5] step 2/44: loss=2.1504 
[epoch 5] step 4/44: loss=2.3574 
[epoch 5] step 6/44: loss=2.3901 
[epoch 5] step 8/44: loss=2.3435 
[epoch 5] step 10/44: loss=2.3111 
[epoch 5] step 12/44: loss=2.3015 
[epoch 5] step 14/44: loss=2.2692 
[epoch 5] step 16/44: loss=2.2310 
[epoch 5] step 18/44: loss=2.2109 
[epoch 5] step 20/44: loss=2.1923 
[epoch 5] step 22/44: loss=2.1864 
[epoch 5] step 24/44: loss=2.1731 
[epoch 5] step 26/44: loss=2.1675 
[epoch 5] step 28/44: loss=2.1496 
[epoch 5] step 30/44: loss=2.1365 
[epoch 5] step 32/44: loss=2.1296 
[epoch 5] step 34/44: loss=2.1311 
[epoch 5] step 36/44: loss=2.1291 
[epoch 5] step 38/44: loss=2.1222 
[epoch 5] step 40/44: loss=2.1237 
[epoch 5] step 42/44: loss=2.1165 
[epoch 5] step 44/44: loss=2.1054 
[epoch 5] train_loss(avg per step)=4.2109 lambda[min,max]=[0.503336,1.000000]
[epoch 5] val_loss=4.6043 qwk=('0.2122', '0.2001', '0.2928') averageQWK=0.2350 macroEMD=0.3528 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    1   14    0    0
     0    1   53   24    0
     0    0   74   88    0
     0    0   34   30    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    0   14    2    0
     0    1   46   19    0
     0    1  122   82    0
     0    0   13   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    9   20    0    0
     0    3   99    9    0
     0    2  135   44    0
     0    0    0    1    0
[epoch 6] step 2/44: loss=1.9590 
[epoch 6] step 4/44: loss=1.9873 
[epoch 6] step 6/44: loss=2.0097 
[epoch 6] step 8/44: loss=2.0252 
[epoch 6] step 10/44: loss=2.0414 
[epoch 6] step 12/44: loss=2.0503 
[epoch 6] step 14/44: loss=2.0048 
[epoch 6] step 16/44: loss=1.9937 
[epoch 6] step 18/44: loss=1.9796 
[epoch 6] step 20/44: loss=1.9556 
[epoch 6] step 22/44: loss=1.9445 
[epoch 6] step 24/44: loss=1.9353 
[epoch 6] step 26/44: loss=1.9217 
[epoch 6] step 28/44: loss=1.9151 
[epoch 6] step 30/44: loss=1.8985 
[epoch 6] step 32/44: loss=1.9088 
[epoch 6] step 34/44: loss=1.9075 
[epoch 6] step 36/44: loss=1.9061 
[epoch 6] step 38/44: loss=1.8866 
[epoch 6] step 40/44: loss=1.8865 
[epoch 6] step 42/44: loss=1.8825 
[epoch 6] step 44/44: loss=1.8780 
[epoch 6] train_loss(avg per step)=3.7560 lambda[min,max]=[0.503558,1.000000]
[epoch 6] val_loss=5.5695 qwk=('0.1056', '0.1893', '0.2329') averageQWK=0.1759 macroEMD=0.3530 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   12    0    0
     0    5   70    3    0
     0    2  127   33    0
     0    3   55    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    5   11    0    0
     0    6   50   10    0
     0   11  146   48    0
     0    2   15   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24    5    0    0
     0   34   74    3    0
     0   36  119   26    0
     0    0    1    0    0
[epoch 7] step 2/44: loss=1.9537 
[epoch 7] step 4/44: loss=1.9912 
[epoch 7] step 6/44: loss=1.9243 
[epoch 7] step 8/44: loss=1.9173 
[epoch 7] step 10/44: loss=1.8543 
[epoch 7] step 12/44: loss=1.8442 
[epoch 7] step 14/44: loss=1.8199 
[epoch 7] step 16/44: loss=1.8230 
[epoch 7] step 18/44: loss=1.8146 
[epoch 7] step 20/44: loss=1.8178 
[epoch 7] step 22/44: loss=1.8184 
[epoch 7] step 24/44: loss=1.8176 
[epoch 7] step 26/44: loss=1.8096 
[epoch 7] step 28/44: loss=1.7968 
[epoch 7] step 30/44: loss=1.7971 
[epoch 7] step 32/44: loss=1.7853 
[epoch 7] step 34/44: loss=1.7845 
[epoch 7] step 36/44: loss=1.7736 
[epoch 7] step 38/44: loss=1.7689 
[epoch 7] step 40/44: loss=1.7719 
[epoch 7] step 42/44: loss=1.7618 
[epoch 7] step 44/44: loss=1.7518 
[epoch 7] train_loss(avg per step)=3.5036 lambda[min,max]=[0.500502,1.000000]
[epoch 7] val_loss=4.4970 qwk=('0.3075', '0.2780', '0.2801') averageQWK=0.2885 macroEMD=0.3355 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    0   13    2    0
     0    1   41   36    0
     0    0   35  127    0
     0    0   18   46    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   13    3    0
     0    1   36   29    0
     0    0   75  130    0
     0    0    8   22    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   27    0    0
     0    0   98   13    0
     0    0  118   63    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=1.6057 
[epoch 8] step 4/44: loss=1.6204 
[epoch 8] step 6/44: loss=1.7621 
[epoch 8] step 8/44: loss=1.7465 
[epoch 8] step 10/44: loss=1.6707 
[epoch 8] step 12/44: loss=1.6592 
[epoch 8] step 14/44: loss=1.6404 
[epoch 8] step 16/44: loss=1.6347 
[epoch 8] step 18/44: loss=1.6134 
[epoch 8] step 20/44: loss=1.6506 
[epoch 8] step 22/44: loss=1.6194 
[epoch 8] step 24/44: loss=1.6419 
[epoch 8] step 26/44: loss=1.6334 
[epoch 8] step 28/44: loss=1.6312 
[epoch 8] step 30/44: loss=1.6329 
[epoch 8] step 32/44: loss=1.6510 
[epoch 8] step 34/44: loss=1.6286 
[epoch 8] step 36/44: loss=1.6139 
[epoch 8] step 38/44: loss=1.6187 
[epoch 8] step 40/44: loss=1.6186 
[epoch 8] step 42/44: loss=1.6155 
[epoch 8] step 44/44: loss=1.6114 
[epoch 8] train_loss(avg per step)=3.2229 lambda[min,max]=[0.500618,1.000000]
[epoch 8] val_loss=4.3869 qwk=('0.2414', '0.3239', '0.4223') averageQWK=0.3292 macroEMD=0.3309 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4    9    2    0
     0    7   44   27    0
     0    0   69   93    0
     0    1   32   31    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    8    6    2    0
     0    9   29   28    0
     0   12   80  113    0
     0    2    7   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    9   20    0    0
     0    6   78   27    0
     0    1   90   90    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=1.6420 
[epoch 9] step 4/44: loss=1.6499 
[epoch 9] step 6/44: loss=1.5697 
[epoch 9] step 8/44: loss=1.5045 
[epoch 9] step 10/44: loss=1.5225 
[epoch 9] step 12/44: loss=1.4915 
[epoch 9] step 14/44: loss=1.4957 
[epoch 9] step 16/44: loss=1.4698 
[epoch 9] step 18/44: loss=1.4545 
[epoch 9] step 20/44: loss=1.4408 
[epoch 9] step 22/44: loss=1.4349 
[epoch 9] step 24/44: loss=1.4244 
[epoch 9] step 26/44: loss=1.4290 
[epoch 9] step 28/44: loss=1.4224 
[epoch 9] step 30/44: loss=1.4144 
[epoch 9] step 32/44: loss=1.4294 
[epoch 9] step 34/44: loss=1.4446 
[epoch 9] step 36/44: loss=1.4446 
[epoch 9] step 38/44: loss=1.4368 
[epoch 9] step 40/44: loss=1.4287 
[epoch 9] step 42/44: loss=1.4319 
[epoch 9] step 44/44: loss=1.4336 
[epoch 9] train_loss(avg per step)=2.8672 lambda[min,max]=[0.500116,1.000000]
[epoch 9] val_loss=5.8642 qwk=('0.1955', '0.2567', '0.3248') averageQWK=0.2590 macroEMD=0.3275 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    9    0    0
     0   13   54   11    0
     0    7  106   49    0
     0    3   42   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    9    6    1    0
     0   11   44   11    0
     0    9  141   55    0
     0    3   13   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   12    0    0
     0   26   82    3    0
     0   14  126   41    0
     0    0    0    1    0
[epoch 10] step 2/44: loss=1.3068 
[epoch 10] step 4/44: loss=1.4244 
[epoch 10] step 6/44: loss=1.3752 
[epoch 10] step 8/44: loss=1.3938 
[epoch 10] step 10/44: loss=1.3381 
[epoch 10] step 12/44: loss=1.3330 
[epoch 10] step 14/44: loss=1.3295 
[epoch 10] step 16/44: loss=1.3095 
[epoch 10] step 18/44: loss=1.2999 
[epoch 10] step 20/44: loss=1.3050 
[epoch 10] step 22/44: loss=1.2859 
[epoch 10] step 24/44: loss=1.3029 
[epoch 10] step 26/44: loss=1.3139 
[epoch 10] step 28/44: loss=1.3006 
[epoch 10] step 30/44: loss=1.2955 
[epoch 10] step 32/44: loss=1.2981 
[epoch 10] step 34/44: loss=1.3113 
[epoch 10] step 36/44: loss=1.2979 
[epoch 10] step 38/44: loss=1.2898 
[epoch 10] step 40/44: loss=1.2913 
[epoch 10] step 42/44: loss=1.2834 
[epoch 10] step 44/44: loss=1.2742 
[epoch 10] train_loss(avg per step)=2.5485 lambda[min,max]=[0.500009,1.000000]
[epoch 10] val_loss=5.8537 qwk=('0.2391', '0.2920', '0.2335') averageQWK=0.2549 macroEMD=0.3094 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7    7    1    0
     0   10   42   26    0
     0    3   80   79    0
     0    2   33   29    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    9    5    2    0
     0   11   36   19    0
     0   10  120   75    0
     0    2    9   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   10   19    0    0
     0    5  104    2    0
     0    2  156   23    0
     0    0    1    0    0
[epoch 11] step 2/44: loss=1.1639 
[epoch 11] step 4/44: loss=1.1963 
[epoch 11] step 6/44: loss=1.2209 
[epoch 11] step 8/44: loss=1.2000 
[epoch 11] step 10/44: loss=1.2148 
[epoch 11] step 12/44: loss=1.2051 
[epoch 11] step 14/44: loss=1.1699 
[epoch 11] step 16/44: loss=1.1516 
[epoch 11] step 18/44: loss=1.1412 
[epoch 11] step 20/44: loss=1.1220 
[epoch 11] step 22/44: loss=1.1357 
[epoch 11] step 24/44: loss=1.1129 
[epoch 11] step 26/44: loss=1.1087 
[epoch 11] step 28/44: loss=1.1148 
[epoch 11] step 30/44: loss=1.1076 
[epoch 11] step 32/44: loss=1.1009 
[epoch 11] step 34/44: loss=1.0987 
[epoch 11] step 36/44: loss=1.1149 
[epoch 11] step 38/44: loss=1.1116 
[epoch 11] step 40/44: loss=1.1105 
[epoch 11] step 42/44: loss=1.1108 
[epoch 11] step 44/44: loss=1.1098 
[epoch 11] train_loss(avg per step)=2.2196 lambda[min,max]=[0.500021,1.000000]
[epoch 11] val_loss=5.6696 qwk=('0.1991', '0.3108', '0.3533') averageQWK=0.2877 macroEMD=0.3064 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    6   62   10    0
     0    0  107   55    0
     0    1   44   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    9    6    1    0
     0   10   40   16    0
     0    3  132   70    0
     0    1   13   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   11   18    0    0
     0    7   96    8    0
     0    3  124   54    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=1.0118 
[epoch 12] step 4/44: loss=1.0778 
[epoch 12] step 6/44: loss=1.0636 
[epoch 12] step 8/44: loss=1.0467 
[epoch 12] step 10/44: loss=0.9603 
[epoch 12] step 12/44: loss=0.9786 
[epoch 12] step 14/44: loss=0.9939 
[epoch 12] step 16/44: loss=0.9650 
[epoch 12] step 18/44: loss=0.9868 
[epoch 12] step 20/44: loss=1.0156 
[epoch 12] step 22/44: loss=1.0137 
[epoch 12] step 24/44: loss=1.0055 
[epoch 12] step 26/44: loss=1.0231 
[epoch 12] step 28/44: loss=1.0115 
[epoch 12] step 30/44: loss=1.0251 
[epoch 12] step 32/44: loss=1.0274 
[epoch 12] step 34/44: loss=1.0264 
[epoch 12] step 36/44: loss=1.0091 
[epoch 12] step 38/44: loss=1.0032 
[epoch 12] step 40/44: loss=1.0015 
[epoch 12] step 42/44: loss=1.0083 
[epoch 12] step 44/44: loss=1.0071 
[epoch 12] train_loss(avg per step)=2.0142 lambda[min,max]=[0.500018,1.000000]
[epoch 12] val_loss=6.2582 qwk=('0.1901', '0.2675', '0.2571') averageQWK=0.2382 macroEMD=0.3052 tailR0=('0.0000', '0.0833', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5    9    1    0
     0    6   58   14    0
     0    1  110   51    0
     0    1   42   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    3    0    0
     1    2   12    1    0
     0    4   38   24    0
     0    1  122   82    0
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   11   18    0    0
     0    4  103    4    0
     0    4  144   33    0
     0    0    0    1    0
[epoch 13] step 2/44: loss=0.7714 
[epoch 13] step 4/44: loss=0.7074 
[epoch 13] step 6/44: loss=0.7307 
[epoch 13] step 8/44: loss=0.8143 
[epoch 13] step 10/44: loss=0.8422 
[epoch 13] step 12/44: loss=0.8688 
[epoch 13] step 14/44: loss=0.8719 
[epoch 13] step 16/44: loss=0.8815 
[epoch 13] step 18/44: loss=0.8872 
[epoch 13] step 20/44: loss=0.8737 
[epoch 13] step 22/44: loss=0.8721 
[epoch 13] step 24/44: loss=0.8651 
[epoch 13] step 26/44: loss=0.8695 
[epoch 13] step 28/44: loss=0.8529 
[epoch 13] step 30/44: loss=0.8683 
[epoch 13] step 32/44: loss=0.8559 
[epoch 13] step 34/44: loss=0.8482 
[epoch 13] step 36/44: loss=0.8508 
[epoch 13] step 38/44: loss=0.8658 
[epoch 13] step 40/44: loss=0.8560 
[epoch 13] step 42/44: loss=0.8584 
[epoch 13] step 44/44: loss=0.8605 
[epoch 13] train_loss(avg per step)=1.7209 lambda[min,max]=[0.500002,1.000000]
[epoch 13] val_loss=5.7959 qwk=('0.2273', '0.3721', '0.3224') averageQWK=0.3073 macroEMD=0.3107 tailR0=('0.0000', '0.1667', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    8    1    0
     0    9   47   22    0
     0    2   75   85    0
     0    4   33   27    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     1    7    5    3    0
     0   12   28   26    0
     0   11   72  122    0
     0    2    7   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   12    0    0
     0   24   78    9    0
     0   15  118   48    0
     0    0    0    1    0
[epoch 14] step 2/44: loss=0.8348 
[epoch 14] step 4/44: loss=0.8656 
[epoch 14] step 6/44: loss=0.8221 
[epoch 14] step 8/44: loss=0.8366 
[epoch 14] step 10/44: loss=0.7941 
[epoch 14] step 12/44: loss=0.7888 
[epoch 14] step 14/44: loss=0.8068 
[epoch 14] step 16/44: loss=0.7988 
[epoch 14] step 18/44: loss=0.8237 
[epoch 14] step 20/44: loss=0.8529 
[epoch 14] step 22/44: loss=0.8581 
[epoch 14] step 24/44: loss=0.8577 
[epoch 14] step 26/44: loss=0.8572 
[epoch 14] step 28/44: loss=0.8459 
[epoch 14] step 30/44: loss=0.8392 
[epoch 14] step 32/44: loss=0.8375 
[epoch 14] step 34/44: loss=0.8344 
[epoch 14] step 36/44: loss=0.8192 
[epoch 14] step 38/44: loss=0.8222 
[epoch 14] step 40/44: loss=0.8151 
[epoch 14] step 42/44: loss=0.8068 
[epoch 14] step 44/44: loss=0.7946 
[epoch 14] train_loss(avg per step)=1.5892 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=5.4705 qwk=('0.2024', '0.2634', '0.3269') averageQWK=0.2642 macroEMD=0.3087 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    2   11    2    0
     0    1   41   36    0
     0    0   46  113    3
     0    0   32   32    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    1    0
     0    2   10    4    0
     0    4   35   27    0
     0    1   85  119    0
     0    0    9   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   27    0    0
     0    3   91   17    0
     0    0  105   76    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=0.9792 
[epoch 15] step 4/44: loss=0.7486 
[epoch 15] step 6/44: loss=0.7027 
[epoch 15] step 8/44: loss=0.6920 
[epoch 15] step 10/44: loss=0.7878 
[epoch 15] step 12/44: loss=0.8006 
[epoch 15] step 14/44: loss=0.7983 
[epoch 15] step 16/44: loss=0.7781 
[epoch 15] step 18/44: loss=0.7705 
[epoch 15] step 20/44: loss=0.7548 
[epoch 15] step 22/44: loss=0.7408 
[epoch 15] step 24/44: loss=0.7404 
[epoch 15] step 26/44: loss=0.7305 
[epoch 15] step 28/44: loss=0.7214 
[epoch 15] step 30/44: loss=0.7088 
[epoch 15] step 32/44: loss=0.7077 
[epoch 15] step 34/44: loss=0.7173 
[epoch 15] step 36/44: loss=0.7236 
[epoch 15] step 38/44: loss=0.7187 
[epoch 15] step 40/44: loss=0.7184 
[epoch 15] step 42/44: loss=0.7181 
[epoch 15] step 44/44: loss=0.7212 
[epoch 15] train_loss(avg per step)=1.4423 lambda[min,max]=[0.500001,1.000000]
[epoch 15] val_loss=6.3880 qwk=('0.1969', '0.2624', '0.2318') averageQWK=0.2304 macroEMD=0.3062 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    0   14    1    0
     0    1   51   26    0
     0    0   75   87    0
     0    0   33   30    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    3   11    2    0
     0    3   39   23    1
     0    2  100  103    0
     0    0    9   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    6   23    0    0
     0    3  101    7    0
     0    2  140   39    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=0.5241 
[epoch 16] step 4/44: loss=0.5889 
[epoch 16] step 6/44: loss=0.5620 
[epoch 16] step 8/44: loss=0.5564 
[epoch 16] step 10/44: loss=0.5479 
[epoch 16] step 12/44: loss=0.5271 
[epoch 16] step 14/44: loss=0.5506 
[epoch 16] step 16/44: loss=0.5326 
[epoch 16] step 18/44: loss=0.5338 
[epoch 16] step 20/44: loss=0.5399 
[epoch 16] step 22/44: loss=0.5357 
[epoch 16] step 24/44: loss=0.5332 
[epoch 16] step 26/44: loss=0.5484 
[epoch 16] step 28/44: loss=0.5525 
[epoch 16] step 30/44: loss=0.5522 
[epoch 16] step 32/44: loss=0.5509 
[epoch 16] step 34/44: loss=0.5530 
[epoch 16] step 36/44: loss=0.5471 
[epoch 16] step 38/44: loss=0.5423 
[epoch 16] step 40/44: loss=0.5441 
[epoch 16] step 42/44: loss=0.5383 
[epoch 16] step 44/44: loss=0.5329 
[epoch 16] train_loss(avg per step)=1.0658 lambda[min,max]=[0.500001,1.000000]
[epoch 16] val_loss=6.5382 qwk=('0.1886', '0.2817', '0.3988') averageQWK=0.2897 macroEMD=0.2919 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    2   57   19    0
     0    1   88   73    0
     0    0   39   25    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6    8    2    0
     0    7   39   20    0
     0    5  123   77    0
     0    0   13   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   16    0    0
     0   12   92    7    0
     0    6  110   65    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=0.3444 
[epoch 17] step 4/44: loss=0.3815 
[epoch 17] step 6/44: loss=0.3721 
[epoch 17] step 8/44: loss=0.3744 
[epoch 17] step 10/44: loss=0.3733 
[epoch 17] step 12/44: loss=0.3702 
[epoch 17] step 14/44: loss=0.3678 
[epoch 17] step 16/44: loss=0.3888 
[epoch 17] step 18/44: loss=0.3865 
[epoch 17] step 20/44: loss=0.3831 
[epoch 17] step 22/44: loss=0.3814 
[epoch 17] step 24/44: loss=0.3743 
[epoch 17] step 26/44: loss=0.3700 
[epoch 17] step 28/44: loss=0.3616 
[epoch 17] step 30/44: loss=0.3511 
[epoch 17] step 32/44: loss=0.3471 
[epoch 17] step 34/44: loss=0.3503 
[epoch 17] step 36/44: loss=0.3523 
[epoch 17] step 38/44: loss=0.3554 
[epoch 17] step 40/44: loss=0.3750 
[epoch 17] step 42/44: loss=0.3807 
[epoch 17] step 44/44: loss=0.3880 
[epoch 17] train_loss(avg per step)=0.7760 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=8.4425 qwk=('0.1658', '0.1806', '0.2300') averageQWK=0.1922 macroEMD=0.2997 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    2   12    1    0
     0    5   55   18    0
     0    0  103   57    2
     0    1   40   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    4   10    2    0
     0    4   47   15    0
     0    3  147   55    0
     0    0   20   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    6   23    0    0
     0    5   98    8    0
     0    3  138   40    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=0.1720 
[epoch 18] step 4/44: loss=0.2246 
[epoch 18] step 6/44: loss=0.2176 
[epoch 18] step 8/44: loss=0.2562 
[epoch 18] step 10/44: loss=0.2795 
[epoch 18] step 12/44: loss=0.2985 
[epoch 18] step 14/44: loss=0.3162 
[epoch 18] step 16/44: loss=0.3142 
[epoch 18] step 18/44: loss=0.2908 
[epoch 18] step 20/44: loss=0.2901 
[epoch 18] step 22/44: loss=0.2910 
[epoch 18] step 24/44: loss=0.2840 
[epoch 18] step 26/44: loss=0.2741 
[epoch 18] step 28/44: loss=0.2741 
[epoch 18] step 30/44: loss=0.2675 
[epoch 18] step 32/44: loss=0.2698 
[epoch 18] step 34/44: loss=0.2641 
[epoch 18] step 36/44: loss=0.2588 
[epoch 18] step 38/44: loss=0.2582 
[epoch 18] step 40/44: loss=0.2563 
[epoch 18] step 42/44: loss=0.2580 
[epoch 18] step 44/44: loss=0.2689 
[epoch 18] train_loss(avg per step)=0.5378 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=6.6297 qwk=('0.2628', '0.2828', '0.3509') averageQWK=0.2988 macroEMD=0.2861 tailR0=('0.0000', '0.0833', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    8   35   35    0
     0    1   56  104    1
     0    0   30   34    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    0    2    0
     0    6    6    4    0
     0    7   31   28    0
     0    7   80  118    0
     0    2    7   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   11   18    0    0
     0    5   98    8    0
     0    3  120   58    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=-0.0501 
[epoch 19] step 4/44: loss=-0.0017 
[epoch 19] step 6/44: loss=0.0458 
[epoch 19] step 8/44: loss=0.0616 
[epoch 19] step 10/44: loss=0.0678 
[epoch 19] step 12/44: loss=0.0873 
[epoch 19] step 14/44: loss=0.1071 
[epoch 19] step 16/44: loss=0.0997 
[epoch 19] step 18/44: loss=0.1072 
[epoch 19] step 20/44: loss=0.1155 
[epoch 19] step 22/44: loss=0.1329 
[epoch 19] step 24/44: loss=0.1220 
[epoch 19] step 26/44: loss=0.1354 
[epoch 19] step 28/44: loss=0.1358 
[epoch 19] step 30/44: loss=0.1421 
[epoch 19] step 32/44: loss=0.1444 
[epoch 19] step 34/44: loss=0.1490 
[epoch 19] step 36/44: loss=0.1429 
[epoch 19] step 38/44: loss=0.1351 
[epoch 19] step 40/44: loss=0.1403 
[epoch 19] step 42/44: loss=0.1343 
[epoch 19] step 44/44: loss=0.1239 
[epoch 19] train_loss(avg per step)=0.2478 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=8.6283 qwk=('0.2441', '0.2115', '0.2778') averageQWK=0.2445 macroEMD=0.2905 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    8    6    1    0
     0   11   42   25    0
     0    2   77   78    5
     0    2   36   23    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6    9    1    0
     0    6   51    8    1
     0    7  141   57    0
     0    1   21    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1    8   20    0    0
     0    5  102    4    0
     0    3  139   39    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=0.0043 
[epoch 20] step 4/44: loss=0.0600 
[epoch 20] step 6/44: loss=0.0800 
[epoch 20] step 8/44: loss=0.0714 
[epoch 20] step 10/44: loss=0.0718 
[epoch 20] step 12/44: loss=0.0658 
[epoch 20] step 14/44: loss=0.0646 
[epoch 20] step 16/44: loss=0.0573 
[epoch 20] step 18/44: loss=0.0773 
[epoch 20] step 20/44: loss=0.0909 
[epoch 20] step 22/44: loss=0.0893 
[epoch 20] step 24/44: loss=0.0854 
[epoch 20] step 26/44: loss=0.0810 
[epoch 20] step 28/44: loss=0.0837 
[epoch 20] step 30/44: loss=0.0790 
[epoch 20] step 32/44: loss=0.0889 
[epoch 20] step 34/44: loss=0.0912 
[epoch 20] step 36/44: loss=0.0818 
[epoch 20] step 38/44: loss=0.0801 
[epoch 20] step 40/44: loss=0.0746 
[epoch 20] step 42/44: loss=0.0696 
[epoch 20] step 44/44: loss=0.0674 
[epoch 20] train_loss(avg per step)=0.1348 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=8.5457 qwk=('0.2565', '0.1706', '0.3464') averageQWK=0.2578 macroEMD=0.2881 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    5    9    1    0
     0    6   49   23    0
     0    1   72   86    3
     0    0   34   29    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    1    0
     0    3   11    2    0
     0    6   47   13    0
     0    5  142   58    0
     0    0   20   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   16    0    0
     0   11   94    6    0
     0    6  125   50    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=-0.0518 
[epoch 21] step 4/44: loss=-0.0125 
[epoch 21] step 6/44: loss=0.0090 
[epoch 21] step 8/44: loss=0.0345 
[epoch 21] step 10/44: loss=0.0138 
[epoch 21] step 12/44: loss=0.0451 
[epoch 21] step 14/44: loss=0.0505 
[epoch 21] step 16/44: loss=0.0487 
[epoch 21] step 18/44: loss=0.0418 
[epoch 21] step 20/44: loss=0.0341 
[epoch 21] step 22/44: loss=0.0421 
[epoch 21] step 24/44: loss=0.0425 
[epoch 21] step 26/44: loss=0.0394 
[epoch 21] step 28/44: loss=0.0336 
[epoch 21] step 30/44: loss=0.0361 
[epoch 21] step 32/44: loss=0.0427 
[epoch 21] step 34/44: loss=0.0419 
[epoch 21] step 36/44: loss=0.0374 
[epoch 21] step 38/44: loss=0.0344 
[epoch 21] step 40/44: loss=0.0286 
[epoch 21] step 42/44: loss=0.0213 
[epoch 21] step 44/44: loss=0.0172 
[epoch 21] train_loss(avg per step)=0.0345 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=8.5877 qwk=('0.2321', '0.1653', '0.3686') averageQWK=0.2553 macroEMD=0.2822 tailR0=('0.0156', '0.1000', '0.0000') tailR0avg=0.0385
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    7    6    2    0
     0    7   35   36    0
     0    2   54  101    5
     0    2   31   29    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    1    1    0
     0    5    9    2    0
     0    7   48   10    1
     0    6  150   49    0
     0    1   22    6    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   17   86    8    0
     0    7  120   54    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=-0.1515 
[epoch 22] step 4/44: loss=-0.0896 
[epoch 22] step 6/44: loss=-0.1004 
[epoch 22] step 8/44: loss=-0.0981 
[epoch 22] step 10/44: loss=-0.1023 
[epoch 22] step 12/44: loss=-0.0931 
[epoch 22] step 14/44: loss=-0.1000 
[epoch 22] step 16/44: loss=-0.0987 
[epoch 22] step 18/44: loss=-0.0957 
[epoch 22] step 20/44: loss=-0.0759 
[epoch 22] step 22/44: loss=-0.0850 
[epoch 22] step 24/44: loss=-0.0881 
[epoch 22] step 26/44: loss=-0.0893 
[epoch 22] step 28/44: loss=-0.0856 
[epoch 22] step 30/44: loss=-0.0840 
[epoch 22] step 32/44: loss=-0.0856 
[epoch 22] step 34/44: loss=-0.0857 
[epoch 22] step 36/44: loss=-0.0861 
[epoch 22] step 38/44: loss=-0.0922 
[epoch 22] step 40/44: loss=-0.0950 
[epoch 22] step 42/44: loss=-0.0993 
[epoch 22] step 44/44: loss=-0.1019 
[epoch 22] train_loss(avg per step)=-0.2037 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=8.8993 qwk=('0.1976', '0.2522', '0.3049') averageQWK=0.2515 macroEMD=0.2804 tailR0=('0.0156', '0.0833', '0.0000') tailR0avg=0.0330
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    7    7    1    0
     0    6   56   16    0
     0    1   97   62    2
     0    2   42   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    1    0
     0    6    8    2    0
     0    6   35   25    0
     0    4  117   84    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1    7   21    0    0
     0    4   99    8    0
     0    3  126   52    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=-0.0806 
[epoch 23] step 4/44: loss=-0.1070 
[epoch 23] step 6/44: loss=-0.1291 
[epoch 23] step 8/44: loss=-0.1497 
[epoch 23] step 10/44: loss=-0.1566 
[epoch 23] step 12/44: loss=-0.1646 
[epoch 23] step 14/44: loss=-0.1677 
[epoch 23] step 16/44: loss=-0.1696 
[epoch 23] step 18/44: loss=-0.1695 
[epoch 23] step 20/44: loss=-0.1640 
[epoch 23] step 22/44: loss=-0.1676 
[epoch 23] step 24/44: loss=-0.1669 
[epoch 23] step 26/44: loss=-0.1650 
[epoch 23] step 28/44: loss=-0.1574 
[epoch 23] step 30/44: loss=-0.1599 
[epoch 23] step 32/44: loss=-0.1544 
[epoch 23] step 34/44: loss=-0.1546 
[epoch 23] step 36/44: loss=-0.1501 
[epoch 23] step 38/44: loss=-0.1464 
[epoch 23] step 40/44: loss=-0.1452 
[epoch 23] step 42/44: loss=-0.1417 
[epoch 23] step 44/44: loss=-0.1382 
[epoch 23] train_loss(avg per step)=-0.2764 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=9.6879 qwk=('0.2169', '0.1795', '0.2908') averageQWK=0.2291 macroEMD=0.2870 tailR0=('0.0156', '0.0167', '0.0000') tailR0avg=0.0108
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     1    5    8    1    0
     0    8   49   21    0
     1    3   82   72    4
     0    2   37   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    3   12    1    0
     0    6   46   13    1
     0    4  140   61    0
     0    0   19   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   10   19    0    0
     0    3   99    9    0
     0    3  131   47    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=-0.2077 
[epoch 24] step 4/44: loss=-0.1972 
[epoch 24] step 6/44: loss=-0.1637 
[epoch 24] step 8/44: loss=-0.1635 
[epoch 24] step 10/44: loss=-0.1626 
[epoch 24] step 12/44: loss=-0.1676 
[epoch 24] step 14/44: loss=-0.1700 
[epoch 24] step 16/44: loss=-0.1700 
[epoch 24] step 18/44: loss=-0.1754 
[epoch 24] step 20/44: loss=-0.1760 
[epoch 24] step 22/44: loss=-0.1783 
[epoch 24] step 24/44: loss=-0.1703 
[epoch 24] step 26/44: loss=-0.1669 
[epoch 24] step 28/44: loss=-0.1653 
[epoch 24] step 30/44: loss=-0.1612 
[epoch 24] step 32/44: loss=-0.1604 
[epoch 24] step 34/44: loss=-0.1571 
[epoch 24] step 36/44: loss=-0.1611 
[epoch 24] step 38/44: loss=-0.1623 
[epoch 24] step 40/44: loss=-0.1609 
[epoch 24] step 42/44: loss=-0.1631 
[epoch 24] step 44/44: loss=-0.1623 
[epoch 24] train_loss(avg per step)=-0.3246 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=10.6032 qwk=('0.2445', '0.1954', '0.3312') averageQWK=0.2570 macroEMD=0.2832 tailR0=('0.0312', '0.1000', '0.0000') tailR0avg=0.0437
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     1    7    6    1    0
     0   15   39   24    0
     1    6   70   79    6
     0    6   31   23    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    8    7    1    0
     0   10   49    6    1
     0   11  159   34    1
     0    2   22    5    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   14    0    0
     0   18   86    7    0
     0    7  132   42    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=-0.1792 
[epoch 25] step 4/44: loss=-0.1676 
[epoch 25] step 6/44: loss=-0.1763 
[epoch 25] step 8/44: loss=-0.1784 
[epoch 25] step 10/44: loss=-0.2000 
[epoch 25] step 12/44: loss=-0.1896 
[epoch 25] step 14/44: loss=-0.1918 
[epoch 25] step 16/44: loss=-0.2042 
[epoch 25] step 18/44: loss=-0.2088 
[epoch 25] step 20/44: loss=-0.2094 
[epoch 25] step 22/44: loss=-0.2072 
[epoch 25] step 24/44: loss=-0.2036 
[epoch 25] step 26/44: loss=-0.2022 
[epoch 25] step 28/44: loss=-0.2027 
[epoch 25] step 30/44: loss=-0.2011 
[epoch 25] step 32/44: loss=-0.1949 
[epoch 25] step 34/44: loss=-0.1972 
[epoch 25] step 36/44: loss=-0.1971 
[epoch 25] step 38/44: loss=-0.1968 
[epoch 25] step 40/44: loss=-0.1960 
[epoch 25] step 42/44: loss=-0.1961 
[epoch 25] step 44/44: loss=-0.1979 
[epoch 25] train_loss(avg per step)=-0.3959 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=9.2038 qwk=('0.2641', '0.2246', '0.2977') averageQWK=0.2621 macroEMD=0.2878 tailR0=('0.0391', '0.0167', '0.0000') tailR0avg=0.0186
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     1    4    9    1    0
     0    7   40   30    1
     0    0   61   90   11
     0    3   30   26    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    2    0
     0    8    6    1    1
     0    7   38   19    2
     0   10  100   88    7
     0    3   11   15    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1    6   22    0    0
     0    4  100    7    0
     0    2  129   50    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=-0.2523 
[epoch 26] step 4/44: loss=-0.2343 
[epoch 26] step 6/44: loss=-0.2382 
[epoch 26] step 8/44: loss=-0.2425 
[epoch 26] step 10/44: loss=-0.2496 
[epoch 26] step 12/44: loss=-0.2521 
[epoch 26] step 14/44: loss=-0.2441 
[epoch 26] step 16/44: loss=-0.2454 
[epoch 26] step 18/44: loss=-0.2410 
[epoch 26] step 20/44: loss=-0.2389 
[epoch 26] step 22/44: loss=-0.2418 
[epoch 26] step 24/44: loss=-0.2461 
[epoch 26] step 26/44: loss=-0.2423 
[epoch 26] step 28/44: loss=-0.2393 
[epoch 26] step 30/44: loss=-0.2352 
[epoch 26] step 32/44: loss=-0.2323 
[epoch 26] step 34/44: loss=-0.2306 
[epoch 26] step 36/44: loss=-0.2276 
[epoch 26] step 38/44: loss=-0.2259 
[epoch 26] step 40/44: loss=-0.2249 
[epoch 26] step 42/44: loss=-0.2201 
[epoch 26] step 44/44: loss=-0.2214 
[epoch 26] train_loss(avg per step)=-0.4428 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=12.1548 qwk=('0.1994', '0.2171', '0.2780') averageQWK=0.2315 macroEMD=0.2838 tailR0=('0.0234', '0.0833', '0.0000') tailR0avg=0.0356
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     1    2   11    1    0
     0    6   59   13    0
     0    0  109   47    6
     0    1   43   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    0    1    0
     0    8    7    1    0
     0   11   42   12    1
     0   14  133   58    0
     0    2   17   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   14   15    0    0
     0   14   94    3    0
     0    5  148   28    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=-0.1488 
[epoch 27] step 4/44: loss=-0.2101 
[epoch 27] step 6/44: loss=-0.2161 
[epoch 27] step 8/44: loss=-0.2328 
[epoch 27] step 10/44: loss=-0.2366 
[epoch 27] step 12/44: loss=-0.2374 
[epoch 27] step 14/44: loss=-0.2311 
[epoch 27] step 16/44: loss=-0.2247 
[epoch 27] step 18/44: loss=-0.2090 
[epoch 27] step 20/44: loss=-0.2085 
[epoch 27] step 22/44: loss=-0.2127 
[epoch 27] step 24/44: loss=-0.2180 
[epoch 27] step 26/44: loss=-0.2193 
[epoch 27] step 28/44: loss=-0.2208 
[epoch 27] step 30/44: loss=-0.2214 
[epoch 27] step 32/44: loss=-0.2248 
[epoch 27] step 34/44: loss=-0.2262 
[epoch 27] step 36/44: loss=-0.2251 
[epoch 27] step 38/44: loss=-0.2267 
[epoch 27] step 40/44: loss=-0.2239 
[epoch 27] step 42/44: loss=-0.2233 
[epoch 27] step 44/44: loss=-0.2256 
[epoch 27] train_loss(avg per step)=-0.4512 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=11.1718 qwk=('0.1859', '0.2244', '0.2819') averageQWK=0.2307 macroEMD=0.2833 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     1    2   11    1    0
     0    7   51   20    0
     0    0   97   60    5
     0    1   40   22    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6    7    3    0
     0    7   41   17    1
     0    8  122   75    0
     0    2   14   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   13   16    0    0
     0    9   96    6    0
     0    5  140   36    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=-0.2459 
[epoch 28] step 4/44: loss=-0.2573 
[epoch 28] step 6/44: loss=-0.2360 
[epoch 28] step 8/44: loss=-0.2473 
[epoch 28] step 10/44: loss=-0.2520 
[epoch 28] step 12/44: loss=-0.2536 
[epoch 28] step 14/44: loss=-0.2614 
[epoch 28] step 16/44: loss=-0.2631 
[epoch 28] step 18/44: loss=-0.2683 
[epoch 28] step 20/44: loss=-0.2661 
[epoch 28] step 22/44: loss=-0.2695 
[epoch 28] step 24/44: loss=-0.2676 
[epoch 28] step 26/44: loss=-0.2701 
[epoch 28] step 28/44: loss=-0.2709 
[epoch 28] step 30/44: loss=-0.2709 
[epoch 28] step 32/44: loss=-0.2709 
[epoch 28] step 34/44: loss=-0.2689 
[epoch 28] step 36/44: loss=-0.2686 
[epoch 28] step 38/44: loss=-0.2663 
[epoch 28] step 40/44: loss=-0.2662 
[epoch 28] step 42/44: loss=-0.2694 
[epoch 28] step 44/44: loss=-0.2653 
[epoch 28] train_loss(avg per step)=-0.5306 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=9.8289 qwk=('0.2278', '0.2455', '0.2979') averageQWK=0.2571 macroEMD=0.2822 tailR0=('0.0391', '0.0000', '0.0000') tailR0avg=0.0130
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    8   43   26    1
     0    2   75   78    7
     0    1   37   21    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    1    1    0
     0    6    8    2    0
     0    8   34   23    1
     0    8  104   93    0
     0    2   10   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    5   24    0    0
     0    3  100    8    0
     0    1  124   56    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=-0.2606 
[epoch 29] step 4/44: loss=-0.2660 
[epoch 29] step 6/44: loss=-0.2656 
[epoch 29] step 8/44: loss=-0.2692 
[epoch 29] step 10/44: loss=-0.2786 
[epoch 29] step 12/44: loss=-0.2841 
[epoch 29] step 14/44: loss=-0.2909 
[epoch 29] step 16/44: loss=-0.2916 
[epoch 29] step 18/44: loss=-0.2898 
[epoch 29] step 20/44: loss=-0.2901 
[epoch 29] step 22/44: loss=-0.2892 
[epoch 29] step 24/44: loss=-0.2908 
[epoch 29] step 26/44: loss=-0.2875 
[epoch 29] step 28/44: loss=-0.2868 
[epoch 29] step 30/44: loss=-0.2892 
[epoch 29] step 32/44: loss=-0.2891 
[epoch 29] step 34/44: loss=-0.2855 
[epoch 29] step 36/44: loss=-0.2828 
[epoch 29] step 38/44: loss=-0.2826 
[epoch 29] step 40/44: loss=-0.2812 
[epoch 29] step 42/44: loss=-0.2830 
[epoch 29] step 44/44: loss=-0.2804 
[epoch 29] train_loss(avg per step)=-0.5609 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=11.7231 qwk=('0.1758', '0.2233', '0.2975') averageQWK=0.2322 macroEMD=0.2852 tailR0=('0.0312', '0.0833', '0.0000') tailR0avg=0.0382
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    2   12    1    0
     0    5   54   18    1
     1    0   97   57    7
     0    0   42   18    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0    5   10    1    0
     0    6   46   13    1
     0    4  146   55    0
     0    1   18   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   22    0    0
     0    3  101    7    0
     0    2  127   52    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=-0.2891 
[epoch 30] step 4/44: loss=-0.2872 
[epoch 30] step 6/44: loss=-0.2601 
[epoch 30] step 8/44: loss=-0.2764 
[epoch 30] step 10/44: loss=-0.2844 
[epoch 30] step 12/44: loss=-0.2878 
[epoch 30] step 14/44: loss=-0.2937 
[epoch 30] step 16/44: loss=-0.2924 
[epoch 30] step 18/44: loss=-0.2856 
[epoch 30] step 20/44: loss=-0.2819 
[epoch 30] step 22/44: loss=-0.2823 
[epoch 30] step 24/44: loss=-0.2844 
[epoch 30] step 26/44: loss=-0.2860 
[epoch 30] step 28/44: loss=-0.2834 
[epoch 30] step 30/44: loss=-0.2835 
[epoch 30] step 32/44: loss=-0.2868 
[epoch 30] step 34/44: loss=-0.2882 
[epoch 30] step 36/44: loss=-0.2877 
[epoch 30] step 38/44: loss=-0.2858 
[epoch 30] step 40/44: loss=-0.2876 
[epoch 30] step 42/44: loss=-0.2890 
[epoch 30] step 44/44: loss=-0.2885 
[epoch 30] train_loss(avg per step)=-0.5770 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=12.3060 qwk=('0.1700', '0.2086', '0.2454') averageQWK=0.2080 macroEMD=0.2829 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    2   12    1    0
     0    5   56   17    0
     0    0   98   62    2
     0    0   43   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    2    0
     0    4    8    4    0
     0    7   39   19    1
     0    5  113   87    0
     0    1   12   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   11   18    0    0
     0    3  103    5    0
     0    3  148   30    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=-0.2567 
[epoch 31] step 4/44: loss=-0.2842 
[epoch 31] step 6/44: loss=-0.2788 
[epoch 31] step 8/44: loss=-0.2936 
[epoch 31] step 10/44: loss=-0.2849 
[epoch 31] step 12/44: loss=-0.2755 
[epoch 31] step 14/44: loss=-0.2755 
[epoch 31] step 16/44: loss=-0.2776 
[epoch 31] step 18/44: loss=-0.2824 
[epoch 31] step 20/44: loss=-0.2864 
[epoch 31] step 22/44: loss=-0.2874 
[epoch 31] step 24/44: loss=-0.2813 
[epoch 31] step 26/44: loss=-0.2834 
[epoch 31] step 28/44: loss=-0.2829 
[epoch 31] step 30/44: loss=-0.2842 
[epoch 31] step 32/44: loss=-0.2860 
[epoch 31] step 34/44: loss=-0.2866 
[epoch 31] step 36/44: loss=-0.2885 
[epoch 31] step 38/44: loss=-0.2886 
[epoch 31] step 40/44: loss=-0.2888 
[epoch 31] step 42/44: loss=-0.2911 
[epoch 31] step 44/44: loss=-0.2920 
[epoch 31] train_loss(avg per step)=-0.5840 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=11.7296 qwk=('0.1711', '0.1934', '0.3349') averageQWK=0.2331 macroEMD=0.2784 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    2   12    1    0
     0    7   55   16    0
     0    1  102   54    5
     0    2   42   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    2    0
     0    8    5    3    0
     0    9   41   15    1
     0    9  122   74    0
     0    2   16   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   14   15    0    0
     0    9   95    7    0
     0    4  130   47    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=-0.3135 
[epoch 32] step 4/44: loss=-0.3238 
[epoch 32] step 6/44: loss=-0.3255 
[epoch 32] step 8/44: loss=-0.3262 
[epoch 32] step 10/44: loss=-0.3213 
[epoch 32] step 12/44: loss=-0.3210 
[epoch 32] step 14/44: loss=-0.3116 
[epoch 32] step 16/44: loss=-0.3092 
[epoch 32] step 18/44: loss=-0.3055 
[epoch 32] step 20/44: loss=-0.2980 
[epoch 32] step 22/44: loss=-0.2982 
[epoch 32] step 24/44: loss=-0.2969 
[epoch 32] step 26/44: loss=-0.2980 
[epoch 32] step 28/44: loss=-0.2978 
[epoch 32] step 30/44: loss=-0.2972 
[epoch 32] step 32/44: loss=-0.2984 
[epoch 32] step 34/44: loss=-0.2995 
[epoch 32] step 36/44: loss=-0.2994 
[epoch 32] step 38/44: loss=-0.2992 
[epoch 32] step 40/44: loss=-0.2997 
[epoch 32] step 42/44: loss=-0.3006 
[epoch 32] step 44/44: loss=-0.2997 
[epoch 32] train_loss(avg per step)=-0.5994 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=11.6344 qwk=('0.2209', '0.2137', '0.3190') averageQWK=0.2512 macroEMD=0.2772 tailR0=('0.0078', '0.0167', '0.0000') tailR0avg=0.0082
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     1    3   10    1    0
     0    8   48   22    0
     1    1   81   73    6
     0    1   38   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    1    0
     0   10    5    1    0
     0    8   47   10    1
     0    9  151   44    1
     0    1   20    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   10   19    0    0
     0    3  101    7    0
     0    3  126   52    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=-0.2904 
[epoch 33] step 4/44: loss=-0.3082 
[epoch 33] step 6/44: loss=-0.3164 
[epoch 33] step 8/44: loss=-0.3225 
[epoch 33] step 10/44: loss=-0.3173 
[epoch 33] step 12/44: loss=-0.3114 
[epoch 33] step 14/44: loss=-0.3050 
[epoch 33] step 16/44: loss=-0.3035 
[epoch 33] step 18/44: loss=-0.3043 
[epoch 33] step 20/44: loss=-0.3075 
[epoch 33] step 22/44: loss=-0.3092 
[epoch 33] step 24/44: loss=-0.3099 
[epoch 33] step 26/44: loss=-0.3118 
[epoch 33] step 28/44: loss=-0.3071 
[epoch 33] step 30/44: loss=-0.3063 
[epoch 33] step 32/44: loss=-0.3087 
[epoch 33] step 34/44: loss=-0.3098 
[epoch 33] step 36/44: loss=-0.3114 
[epoch 33] step 38/44: loss=-0.3115 
[epoch 33] step 40/44: loss=-0.3105 
[epoch 33] step 42/44: loss=-0.3107 
[epoch 33] step 44/44: loss=-0.3113 
[epoch 33] train_loss(avg per step)=-0.6226 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=11.8880 qwk=('0.2148', '0.2007', '0.3144') averageQWK=0.2433 macroEMD=0.2783 tailR0=('0.0156', '0.0167', '0.0000') tailR0avg=0.0108
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   11    1    0
     0    8   51   18    1
     0    2   87   66    7
     0    1   38   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    1    0
     0    8    6    1    1
     0    8   46   11    1
     0    9  145   50    1
     0    1   18   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   12   17    0    0
     0    3  101    7    0
     0    4  129   48    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=-0.3267 
[epoch 34] step 4/44: loss=-0.3269 
[epoch 34] step 6/44: loss=-0.3310 
[epoch 34] step 8/44: loss=-0.3282 
[epoch 34] step 10/44: loss=-0.3284 
[epoch 34] step 12/44: loss=-0.3305 
[epoch 34] step 14/44: loss=-0.3280 
[epoch 34] step 16/44: loss=-0.3245 
[epoch 34] step 18/44: loss=-0.3243 
[epoch 34] step 20/44: loss=-0.3212 
[epoch 34] step 22/44: loss=-0.3180 
[epoch 34] step 24/44: loss=-0.3185 
[epoch 34] step 26/44: loss=-0.3196 
[epoch 34] step 28/44: loss=-0.3188 
[epoch 34] step 30/44: loss=-0.3191 
[epoch 34] step 32/44: loss=-0.3198 
[epoch 34] step 34/44: loss=-0.3204 
[epoch 34] step 36/44: loss=-0.3203 
[epoch 34] step 38/44: loss=-0.3196 
[epoch 34] step 40/44: loss=-0.3181 
[epoch 34] step 42/44: loss=-0.3166 
[epoch 34] step 44/44: loss=-0.3176 
[epoch 34] train_loss(avg per step)=-0.6352 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=11.3312 qwk=('0.2152', '0.2080', '0.2973') averageQWK=0.2402 macroEMD=0.2765 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    6   46   26    0
     0    1   74   80    7
     0    0   36   27    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    2    0
     0    5    7    4    0
     0    7   37   22    0
     0    7  107   91    0
     0    1   13   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    9   20    0    0
     0    3  101    7    0
     0    3  129   49    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=-0.3278 
[epoch 35] step 4/44: loss=-0.3229 
[epoch 35] step 6/44: loss=-0.3289 
[epoch 35] step 8/44: loss=-0.3259 
[epoch 35] step 10/44: loss=-0.3282 
[epoch 35] step 12/44: loss=-0.3269 
[epoch 35] step 14/44: loss=-0.3219 
[epoch 35] step 16/44: loss=-0.3213 
[epoch 35] step 18/44: loss=-0.3218 
[epoch 35] step 20/44: loss=-0.3221 
[epoch 35] step 22/44: loss=-0.3192 
[epoch 35] step 24/44: loss=-0.3208 
[epoch 35] step 26/44: loss=-0.3201 
[epoch 35] step 28/44: loss=-0.3211 
[epoch 35] step 30/44: loss=-0.3197 
[epoch 35] step 32/44: loss=-0.3199 
[epoch 35] step 34/44: loss=-0.3215 
[epoch 35] step 36/44: loss=-0.3223 
[epoch 35] step 38/44: loss=-0.3200 
[epoch 35] step 40/44: loss=-0.3208 
[epoch 35] step 42/44: loss=-0.3221 
[epoch 35] step 44/44: loss=-0.3214 
[epoch 35] train_loss(avg per step)=-0.6428 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=12.2241 qwk=('0.2151', '0.2033', '0.2765') averageQWK=0.2316 macroEMD=0.2755 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     1    2   11    1    0
     0    8   49   21    0
     1    1   83   70    7
     0    1   38   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    1    0
     0    8    6    2    0
     0    7   44   14    1
     0    8  140   57    0
     0    1   18   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   11   18    0    0
     0    4  100    7    0
     0    3  139   39    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-0/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-0/fold0/metrics.json
Done.
