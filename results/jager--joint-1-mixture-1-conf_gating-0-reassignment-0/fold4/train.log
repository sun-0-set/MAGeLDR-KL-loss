[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=8.2485 
[epoch 1] step 4/44: loss=7.8555 
[epoch 1] step 6/44: loss=7.7348 
[epoch 1] step 8/44: loss=7.5840 
[epoch 1] step 10/44: loss=7.6080 
[epoch 1] step 12/44: loss=7.6350 
[epoch 1] step 14/44: loss=7.6222 
[epoch 1] step 16/44: loss=7.6003 
[epoch 1] step 18/44: loss=7.5263 
[epoch 1] step 20/44: loss=7.4790 
[epoch 1] step 22/44: loss=7.4558 
[epoch 1] step 24/44: loss=7.4190 
[epoch 1] step 26/44: loss=7.3923 
[epoch 1] step 28/44: loss=7.3591 
[epoch 1] step 30/44: loss=7.3086 
[epoch 1] step 32/44: loss=7.2678 
[epoch 1] step 34/44: loss=7.2361 
[epoch 1] step 36/44: loss=7.1367 
[epoch 1] step 38/44: loss=7.0470 
[epoch 1] step 40/44: loss=6.9555 
[epoch 1] step 42/44: loss=6.8419 
[epoch 1] step 44/44: loss=6.7541 
[epoch 1] train_loss(avg per step)=13.5082 lambda[min,max]=[0.519446,1.000000]
[epoch 1] val_loss=7.5967 qwk=('0.1738', '0.2410', '0.0169') averageQWK=0.1439 macroEMD=0.3727 tailR0=('0.0000', '0.2222', '0.0000') tailR0avg=0.0741
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    6    0
     0   52    0   30    0
     0   92    0   63    0
     0   32    0   41    0
     0    1    0    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    0    3    2    0
    40    0   20   16    0
    49    0   74   41    0
    17    0   25   38    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    3   88    1    0
     0    3  163    0    0
     0    0   72    0    0
     0    0    1    0    0
[epoch 2] step 2/44: loss=4.2936 
[epoch 2] step 4/44: loss=4.3790 
[epoch 2] step 6/44: loss=4.1874 
[epoch 2] step 8/44: loss=4.0913 
[epoch 2] step 10/44: loss=3.9789 
[epoch 2] step 12/44: loss=3.9654 
[epoch 2] step 14/44: loss=3.9147 
[epoch 2] step 16/44: loss=3.8926 
[epoch 2] step 18/44: loss=3.8846 
[epoch 2] step 20/44: loss=3.8306 
[epoch 2] step 22/44: loss=3.8268 
[epoch 2] step 24/44: loss=3.7837 
[epoch 2] step 26/44: loss=3.7603 
[epoch 2] step 28/44: loss=3.7273 
[epoch 2] step 30/44: loss=3.6960 
[epoch 2] step 32/44: loss=3.6644 
[epoch 2] step 34/44: loss=3.6312 
[epoch 2] step 36/44: loss=3.6068 
[epoch 2] step 38/44: loss=3.5812 
[epoch 2] step 40/44: loss=3.5531 
[epoch 2] step 42/44: loss=3.5402 
[epoch 2] step 44/44: loss=3.5187 
[epoch 2] train_loss(avg per step)=7.0375 lambda[min,max]=[0.506724,1.000000]
[epoch 2] val_loss=5.4308 qwk=('0.0371', '0.0911', '0.1246') averageQWK=0.0843 macroEMD=0.3770 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1   12    0
     0    1    0   81    0
     0    0    0  155    0
     0    0    0   73    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    4    0
     0    0   14   62    0
     0    0   13  151    0
     0    0    0   80    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    3    1    0
     0    0   32   60    0
     0    0   37  129    0
     0    0    2   70    0
     0    0    0    1    0
[epoch 3] step 2/44: loss=3.1489 
[epoch 3] step 4/44: loss=3.0123 
[epoch 3] step 6/44: loss=3.0506 
[epoch 3] step 8/44: loss=3.0306 
[epoch 3] step 10/44: loss=2.9548 
[epoch 3] step 12/44: loss=2.9834 
[epoch 3] step 14/44: loss=2.9346 
[epoch 3] step 16/44: loss=2.9289 
[epoch 3] step 18/44: loss=2.9060 
[epoch 3] step 20/44: loss=2.9124 
[epoch 3] step 22/44: loss=2.9135 
[epoch 3] step 24/44: loss=2.8971 
[epoch 3] step 26/44: loss=2.8653 
[epoch 3] step 28/44: loss=2.8767 
[epoch 3] step 30/44: loss=2.8667 
[epoch 3] step 32/44: loss=2.8578 
[epoch 3] step 34/44: loss=2.8307 
[epoch 3] step 36/44: loss=2.8077 
[epoch 3] step 38/44: loss=2.7919 
[epoch 3] step 40/44: loss=2.7979 
[epoch 3] step 42/44: loss=2.7756 
[epoch 3] step 44/44: loss=2.7550 
[epoch 3] train_loss(avg per step)=5.5101 lambda[min,max]=[0.514943,1.000000]
[epoch 3] val_loss=4.3678 qwk=('0.4330', '0.3803', '0.4476') averageQWK=0.4203 macroEMD=0.3529 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   19   59    4    0
     0    8  116   31    0
     0    0   24   49    0
     0    1    4    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   13   43   20    0
     0   14   69   81    0
     0    1    4   75    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0   24   60    8    0
     0   18  113   35    0
     0    1   22   49    0
     0    0    0    1    0
[epoch 4] step 2/44: loss=2.5255 
[epoch 4] step 4/44: loss=2.6914 
[epoch 4] step 6/44: loss=2.6426 
[epoch 4] step 8/44: loss=2.6083 
[epoch 4] step 10/44: loss=2.5708 
[epoch 4] step 12/44: loss=2.5653 
[epoch 4] step 14/44: loss=2.5532 
[epoch 4] step 16/44: loss=2.5582 
[epoch 4] step 18/44: loss=2.5913 
[epoch 4] step 20/44: loss=2.6148 
[epoch 4] step 22/44: loss=2.6252 
[epoch 4] step 24/44: loss=2.6072 
[epoch 4] step 26/44: loss=2.6157 
[epoch 4] step 28/44: loss=2.5924 
[epoch 4] step 30/44: loss=2.5766 
[epoch 4] step 32/44: loss=2.5708 
[epoch 4] step 34/44: loss=2.5628 
[epoch 4] step 36/44: loss=2.5639 
[epoch 4] step 38/44: loss=2.5531 
[epoch 4] step 40/44: loss=2.5447 
[epoch 4] step 42/44: loss=2.5338 
[epoch 4] step 44/44: loss=2.5086 
[epoch 4] train_loss(avg per step)=5.0171 lambda[min,max]=[0.512201,1.000000]
[epoch 4] val_loss=4.2354 qwk=('0.2965', '0.3632', '0.1551') averageQWK=0.2716 macroEMD=0.3617 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   14    0    0
     0    1   81    0    0
     0    1  142   12    0
     0    0   34   39    0
     0    0    9    1    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0    8   48   20    0
     0    4   82   78    0
     0    0    4   76    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0   13   79    0    0
     0    5  161    0    0
     0    0   72    0    0
     0    0    0    1    0
[epoch 5] step 2/44: loss=2.2404 
[epoch 5] step 4/44: loss=2.3051 
[epoch 5] step 6/44: loss=2.3227 
[epoch 5] step 8/44: loss=2.3401 
[epoch 5] step 10/44: loss=2.3274 
[epoch 5] step 12/44: loss=2.3358 
[epoch 5] step 14/44: loss=2.3089 
[epoch 5] step 16/44: loss=2.2863 
[epoch 5] step 18/44: loss=2.2920 
[epoch 5] step 20/44: loss=2.2652 
[epoch 5] step 22/44: loss=2.2750 
[epoch 5] step 24/44: loss=2.2738 
[epoch 5] step 26/44: loss=2.2708 
[epoch 5] step 28/44: loss=2.2646 
[epoch 5] step 30/44: loss=2.2469 
[epoch 5] step 32/44: loss=2.2259 
[epoch 5] step 34/44: loss=2.1956 
[epoch 5] step 36/44: loss=2.2087 
[epoch 5] step 38/44: loss=2.2107 
[epoch 5] step 40/44: loss=2.1957 
[epoch 5] step 42/44: loss=2.1892 
[epoch 5] step 44/44: loss=2.1564 
[epoch 5] train_loss(avg per step)=4.3128 lambda[min,max]=[0.511984,1.000000]
[epoch 5] val_loss=5.2165 qwk=('0.3145', '0.2893', '0.3019') averageQWK=0.3019 macroEMD=0.3405 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    2    0
     0    1   64   17    0
     0    0   86   69    0
     0    0   12   61    0
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    2    0
     0    5   42   29    0
     0    0   46  118    0
     0    0    1   79    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    2   64   26    0
     0    0  105   61    0
     0    0    9   63    0
     0    0    0    1    0
[epoch 6] step 2/44: loss=1.9843 
[epoch 6] step 4/44: loss=2.2061 
[epoch 6] step 6/44: loss=2.2092 
[epoch 6] step 8/44: loss=2.1472 
[epoch 6] step 10/44: loss=2.1310 
[epoch 6] step 12/44: loss=2.1584 
[epoch 6] step 14/44: loss=2.1010 
[epoch 6] step 16/44: loss=2.0849 
[epoch 6] step 18/44: loss=2.0959 
[epoch 6] step 20/44: loss=2.1244 
[epoch 6] step 22/44: loss=2.1278 
[epoch 6] step 24/44: loss=2.1041 
[epoch 6] step 26/44: loss=2.1006 
[epoch 6] step 28/44: loss=2.0902 
[epoch 6] step 30/44: loss=2.0669 
[epoch 6] step 32/44: loss=2.0513 
[epoch 6] step 34/44: loss=2.0463 
[epoch 6] step 36/44: loss=2.0542 
[epoch 6] step 38/44: loss=2.0487 
[epoch 6] step 40/44: loss=2.0493 
[epoch 6] step 42/44: loss=2.0482 
[epoch 6] step 44/44: loss=2.0379 
[epoch 6] train_loss(avg per step)=4.0759 lambda[min,max]=[0.500646,1.000000]
[epoch 6] val_loss=5.2621 qwk=('0.2944', '0.3656', '0.1864') averageQWK=0.2822 macroEMD=0.3413 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   12    2    0
     0    2   61   19    0
     0    0   77   78    0
     0    0   12   61    0
     0    0    3    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    1   58   17    0
     0    0   90   74    0
     0    0    3   77    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    1   90    1    0
     0    0  161    5    0
     0    0   56   16    0
     0    0    0    1    0
[epoch 7] step 2/44: loss=1.9121 
[epoch 7] step 4/44: loss=1.8994 
[epoch 7] step 6/44: loss=1.9609 
[epoch 7] step 8/44: loss=1.9406 
[epoch 7] step 10/44: loss=1.9552 
[epoch 7] step 12/44: loss=1.9538 
[epoch 7] step 14/44: loss=1.9506 
[epoch 7] step 16/44: loss=1.9080 
[epoch 7] step 18/44: loss=1.9183 
[epoch 7] step 20/44: loss=1.9215 
[epoch 7] step 22/44: loss=1.8985 
[epoch 7] step 24/44: loss=1.8960 
[epoch 7] step 26/44: loss=1.9014 
[epoch 7] step 28/44: loss=1.8935 
[epoch 7] step 30/44: loss=1.8965 
[epoch 7] step 32/44: loss=1.8915 
[epoch 7] step 34/44: loss=1.8897 
[epoch 7] step 36/44: loss=1.8688 
[epoch 7] step 38/44: loss=1.8696 
[epoch 7] step 40/44: loss=1.8669 
[epoch 7] step 42/44: loss=1.8594 
[epoch 7] step 44/44: loss=1.8483 
[epoch 7] train_loss(avg per step)=3.6965 lambda[min,max]=[0.501586,1.000000]
[epoch 7] val_loss=5.2019 qwk=('0.3047', '0.3813', '0.3196') averageQWK=0.3352 macroEMD=0.3295 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    2    0
     0    1   62   19    0
     0    0   79   76    0
     0    0   11   62    0
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    2   62   12    0
     0    0  114   50    0
     0    0   13   67    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    0   79   13    0
     0    0  132   34    0
     0    0   21   51    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=1.8471 
[epoch 8] step 4/44: loss=1.7747 
[epoch 8] step 6/44: loss=1.7040 
[epoch 8] step 8/44: loss=1.7351 
[epoch 8] step 10/44: loss=1.7707 
[epoch 8] step 12/44: loss=1.7718 
[epoch 8] step 14/44: loss=1.7752 
[epoch 8] step 16/44: loss=1.7622 
[epoch 8] step 18/44: loss=1.7195 
[epoch 8] step 20/44: loss=1.7043 
[epoch 8] step 22/44: loss=1.7102 
[epoch 8] step 24/44: loss=1.7117 
[epoch 8] step 26/44: loss=1.6879 
[epoch 8] step 28/44: loss=1.6802 
[epoch 8] step 30/44: loss=1.6818 
[epoch 8] step 32/44: loss=1.6881 
[epoch 8] step 34/44: loss=1.7021 
[epoch 8] step 36/44: loss=1.7079 
[epoch 8] step 38/44: loss=1.7157 
[epoch 8] step 40/44: loss=1.7163 
[epoch 8] step 42/44: loss=1.7171 
[epoch 8] step 44/44: loss=1.7381 
[epoch 8] train_loss(avg per step)=3.4762 lambda[min,max]=[0.501264,1.000000]
[epoch 8] val_loss=4.3095 qwk=('0.4250', '0.5079', '0.3906') averageQWK=0.4412 macroEMD=0.3290 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   19   55    8    0
     0    8  102   45    0
     0    0   22   51    0
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   21   45   10    0
     0   13  112   39    0
     0    0   14   65    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   21   52   19    0
     0   24   87   55    0
     0    2   12   58    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=1.6736 
[epoch 9] step 4/44: loss=1.5647 
[epoch 9] step 6/44: loss=1.5579 
[epoch 9] step 8/44: loss=1.4964 
[epoch 9] step 10/44: loss=1.4668 
[epoch 9] step 12/44: loss=1.4942 
[epoch 9] step 14/44: loss=1.4822 
[epoch 9] step 16/44: loss=1.4543 
[epoch 9] step 18/44: loss=1.4712 
[epoch 9] step 20/44: loss=1.4681 
[epoch 9] step 22/44: loss=1.4756 
[epoch 9] step 24/44: loss=1.4861 
[epoch 9] step 26/44: loss=1.4978 
[epoch 9] step 28/44: loss=1.5117 
[epoch 9] step 30/44: loss=1.5078 
[epoch 9] step 32/44: loss=1.5197 
[epoch 9] step 34/44: loss=1.5183 
[epoch 9] step 36/44: loss=1.5363 
[epoch 9] step 38/44: loss=1.5548 
[epoch 9] step 40/44: loss=1.5551 
[epoch 9] step 42/44: loss=1.5657 
[epoch 9] step 44/44: loss=1.5513 
[epoch 9] train_loss(avg per step)=3.1026 lambda[min,max]=[0.500014,1.000000]
[epoch 9] val_loss=4.9521 qwk=('0.4423', '0.4729', '0.2782') averageQWK=0.3978 macroEMD=0.3123 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    7    1    0
     0   18   52   12    0
     0    5   95   55    0
     0    0   16   57    0
     0    0    3    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     3   14   49   10    0
     1    8   99   56    0
     0    0   10   70    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    2   89    1    0
     0    0  158    8    0
     0    0   48   24    0
     0    0    0    1    0
[epoch 10] step 2/44: loss=1.3994 
[epoch 10] step 4/44: loss=1.3784 
[epoch 10] step 6/44: loss=1.4163 
[epoch 10] step 8/44: loss=1.4391 
[epoch 10] step 10/44: loss=1.4172 
[epoch 10] step 12/44: loss=1.4213 
[epoch 10] step 14/44: loss=1.4427 
[epoch 10] step 16/44: loss=1.4798 
[epoch 10] step 18/44: loss=1.4283 
[epoch 10] step 20/44: loss=1.4319 
[epoch 10] step 22/44: loss=1.4357 
[epoch 10] step 24/44: loss=1.4377 
[epoch 10] step 26/44: loss=1.4251 
[epoch 10] step 28/44: loss=1.4319 
[epoch 10] step 30/44: loss=1.4221 
[epoch 10] step 32/44: loss=1.4185 
[epoch 10] step 34/44: loss=1.4048 
[epoch 10] step 36/44: loss=1.3984 
[epoch 10] step 38/44: loss=1.3892 
[epoch 10] step 40/44: loss=1.3891 
[epoch 10] step 42/44: loss=1.3897 
[epoch 10] step 44/44: loss=1.4148 
[epoch 10] train_loss(avg per step)=2.8295 lambda[min,max]=[0.500012,1.000000]
[epoch 10] val_loss=6.5937 qwk=('0.3018', '0.3493', '0.2905') averageQWK=0.3138 macroEMD=0.3150 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   12    2    0
     0    4   53   25    0
     0    1   64   90    0
     0    0    9   61    3
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    4   54   18    0
     0    0   83   81    0
     0    0    7   73    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    2   64   26    0
     0    0   92   74    0
     0    0    8   64    0
     0    0    0    1    0
[epoch 11] step 2/44: loss=1.6828 
[epoch 11] step 4/44: loss=1.5187 
[epoch 11] step 6/44: loss=1.4252 
[epoch 11] step 8/44: loss=1.4148 
[epoch 11] step 10/44: loss=1.4342 
[epoch 11] step 12/44: loss=1.4072 
[epoch 11] step 14/44: loss=1.4272 
[epoch 11] step 16/44: loss=1.4443 
[epoch 11] step 18/44: loss=1.4390 
[epoch 11] step 20/44: loss=1.4110 
[epoch 11] step 22/44: loss=1.3967 
[epoch 11] step 24/44: loss=1.4286 
[epoch 11] step 26/44: loss=1.4285 
[epoch 11] step 28/44: loss=1.4266 
[epoch 11] step 30/44: loss=1.4180 
[epoch 11] step 32/44: loss=1.4247 
[epoch 11] step 34/44: loss=1.4334 
[epoch 11] step 36/44: loss=1.4211 
[epoch 11] step 38/44: loss=1.4134 
[epoch 11] step 40/44: loss=1.4093 
[epoch 11] step 42/44: loss=1.3927 
[epoch 11] step 44/44: loss=1.3744 
[epoch 11] train_loss(avg per step)=2.7488 lambda[min,max]=[0.500011,1.000000]
[epoch 11] val_loss=4.9637 qwk=('0.3533', '0.4400', '0.3156') averageQWK=0.3696 macroEMD=0.3103 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   12    1    0
     0    8   69    5    0
     0    2  124   29    0
     0    0   27   45    1
     0    0    6    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   12   51   13    0
     0   10  107   47    0
     0    0   11   68    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    2   81    9    0
     0    0  146   20    0
     0    0   32   40    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=1.1629 
[epoch 12] step 4/44: loss=1.2309 
[epoch 12] step 6/44: loss=1.2549 
[epoch 12] step 8/44: loss=1.2536 
[epoch 12] step 10/44: loss=1.2344 
[epoch 12] step 12/44: loss=1.1841 
[epoch 12] step 14/44: loss=1.1840 
[epoch 12] step 16/44: loss=1.1459 
[epoch 12] step 18/44: loss=1.1462 
[epoch 12] step 20/44: loss=1.1340 
[epoch 12] step 22/44: loss=1.1260 
[epoch 12] step 24/44: loss=1.1145 
[epoch 12] step 26/44: loss=1.1269 
[epoch 12] step 28/44: loss=1.1258 
[epoch 12] step 30/44: loss=1.1161 
[epoch 12] step 32/44: loss=1.1083 
[epoch 12] step 34/44: loss=1.1095 
[epoch 12] step 36/44: loss=1.1093 
[epoch 12] step 38/44: loss=1.1187 
[epoch 12] step 40/44: loss=1.1278 
[epoch 12] step 42/44: loss=1.1290 
[epoch 12] step 44/44: loss=1.0983 
[epoch 12] train_loss(avg per step)=2.1966 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=6.4205 qwk=('0.3524', '0.3725', '0.2831') averageQWK=0.3360 macroEMD=0.3046 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   12    2    0
     0    2   65   15    0
     0    0   78   77    0
     0    0    9   64    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    3   59   14    0
     0    0  104   60    0
     0    0   13   67    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    0   83    9    0
     0    0  135   31    0
     0    0   32   40    0
     0    0    0    1    0
[epoch 13] step 2/44: loss=1.1516 
[epoch 13] step 4/44: loss=0.9576 
[epoch 13] step 6/44: loss=0.9762 
[epoch 13] step 8/44: loss=0.9886 
[epoch 13] step 10/44: loss=0.9742 
[epoch 13] step 12/44: loss=0.9887 
[epoch 13] step 14/44: loss=1.0023 
[epoch 13] step 16/44: loss=0.9831 
[epoch 13] step 18/44: loss=0.9801 
[epoch 13] step 20/44: loss=0.9922 
[epoch 13] step 22/44: loss=0.9980 
[epoch 13] step 24/44: loss=1.0005 
[epoch 13] step 26/44: loss=0.9976 
[epoch 13] step 28/44: loss=0.9911 
[epoch 13] step 30/44: loss=0.9962 
[epoch 13] step 32/44: loss=0.9865 
[epoch 13] step 34/44: loss=0.9873 
[epoch 13] step 36/44: loss=0.9798 
[epoch 13] step 38/44: loss=0.9802 
[epoch 13] step 40/44: loss=0.9708 
[epoch 13] step 42/44: loss=0.9862 
[epoch 13] step 44/44: loss=1.0480 
[epoch 13] train_loss(avg per step)=2.0960 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=5.3335 qwk=('0.4323', '0.4597', '0.3127') averageQWK=0.4016 macroEMD=0.2944 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    7    1    0
     0   20   55    7    0
     0    8  104   43    0
     0    0   26   45    2
     0    0    5    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   16   50   10    0
     0    8  121   35    0
     0    0   19   60    1
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    4   82    6    0
     0    2  149   15    0
     0    0   38   34    0
     0    0    0    1    0
[epoch 14] step 2/44: loss=0.7378 
[epoch 14] step 4/44: loss=0.7869 
[epoch 14] step 6/44: loss=0.7908 
[epoch 14] step 8/44: loss=0.8162 
[epoch 14] step 10/44: loss=0.8186 
[epoch 14] step 12/44: loss=0.8349 
[epoch 14] step 14/44: loss=0.8419 
[epoch 14] step 16/44: loss=0.8018 
[epoch 14] step 18/44: loss=0.7926 
[epoch 14] step 20/44: loss=0.7906 
[epoch 14] step 22/44: loss=0.7728 
[epoch 14] step 24/44: loss=0.7721 
[epoch 14] step 26/44: loss=0.7723 
[epoch 14] step 28/44: loss=0.7684 
[epoch 14] step 30/44: loss=0.7733 
[epoch 14] step 32/44: loss=0.7768 
[epoch 14] step 34/44: loss=0.7683 
[epoch 14] step 36/44: loss=0.7716 
[epoch 14] step 38/44: loss=0.7740 
[epoch 14] step 40/44: loss=0.7781 
[epoch 14] step 42/44: loss=0.7840 
[epoch 14] step 44/44: loss=0.8634 
[epoch 14] train_loss(avg per step)=1.7269 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=6.0568 qwk=('0.3969', '0.4104', '0.3258') averageQWK=0.3777 macroEMD=0.2943 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   12    1    0
     0    9   64    9    0
     0    2   96   57    0
     0    0   15   55    3
     0    0    3    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    6   62    8    0
     0    2  126   36    0
     0    0   20   59    1
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5   80    7    0
     0    0  149   17    0
     0    0   40   32    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=0.8109 
[epoch 15] step 4/44: loss=0.8405 
[epoch 15] step 6/44: loss=0.8241 
[epoch 15] step 8/44: loss=0.7782 
[epoch 15] step 10/44: loss=0.7720 
[epoch 15] step 12/44: loss=0.7424 
[epoch 15] step 14/44: loss=0.7072 
[epoch 15] step 16/44: loss=0.6979 
[epoch 15] step 18/44: loss=0.6981 
[epoch 15] step 20/44: loss=0.6753 
[epoch 15] step 22/44: loss=0.6855 
[epoch 15] step 24/44: loss=0.6792 
[epoch 15] step 26/44: loss=0.6761 
[epoch 15] step 28/44: loss=0.6796 
[epoch 15] step 30/44: loss=0.6729 
[epoch 15] step 32/44: loss=0.6620 
[epoch 15] step 34/44: loss=0.6655 
[epoch 15] step 36/44: loss=0.6611 
[epoch 15] step 38/44: loss=0.6607 
[epoch 15] step 40/44: loss=0.6603 
[epoch 15] step 42/44: loss=0.6603 
[epoch 15] step 44/44: loss=0.6367 
[epoch 15] train_loss(avg per step)=1.2733 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=6.3091 qwk=('0.4091', '0.4465', '0.3103') averageQWK=0.3887 macroEMD=0.2934 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   17   55    9    1
     0    8   97   50    0
     0    0   17   50    6
     0    0    5    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    1    0
     0   13   52   11    0
     0   11   87   66    0
     0    0   12   68    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    3   83    6    0
     0    2  145   19    0
     0    0   37   35    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=0.4525 
[epoch 16] step 4/44: loss=0.4935 
[epoch 16] step 6/44: loss=0.5301 
[epoch 16] step 8/44: loss=0.4829 
[epoch 16] step 10/44: loss=0.4742 
[epoch 16] step 12/44: loss=0.4683 
[epoch 16] step 14/44: loss=0.4830 
[epoch 16] step 16/44: loss=0.4735 
[epoch 16] step 18/44: loss=0.4656 
[epoch 16] step 20/44: loss=0.4697 
[epoch 16] step 22/44: loss=0.4860 
[epoch 16] step 24/44: loss=0.4782 
[epoch 16] step 26/44: loss=0.4910 
[epoch 16] step 28/44: loss=0.4915 
[epoch 16] step 30/44: loss=0.4966 
[epoch 16] step 32/44: loss=0.4924 
[epoch 16] step 34/44: loss=0.4868 
[epoch 16] step 36/44: loss=0.4839 
[epoch 16] step 38/44: loss=0.4823 
[epoch 16] step 40/44: loss=0.4813 
[epoch 16] step 42/44: loss=0.4806 
[epoch 16] step 44/44: loss=0.4783 
[epoch 16] train_loss(avg per step)=0.9565 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=6.9163 qwk=('0.3893', '0.3988', '0.2837') averageQWK=0.3572 macroEMD=0.2842 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   13   59   10    0
     0    4   99   52    0
     0    0   20   49    4
     0    0    5    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    8   56   12    0
     0    3  122   39    0
     0    0   17   63    0
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    3   85    4    0
     0    0  151   15    0
     0    0   42   30    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=0.4133 
[epoch 17] step 4/44: loss=0.3827 
[epoch 17] step 6/44: loss=0.3953 
[epoch 17] step 8/44: loss=0.4122 
[epoch 17] step 10/44: loss=0.3916 
[epoch 17] step 12/44: loss=0.4057 
[epoch 17] step 14/44: loss=0.4466 
[epoch 17] step 16/44: loss=0.4501 
[epoch 17] step 18/44: loss=0.4598 
[epoch 17] step 20/44: loss=0.4501 
[epoch 17] step 22/44: loss=0.4438 
[epoch 17] step 24/44: loss=0.4408 
[epoch 17] step 26/44: loss=0.4496 
[epoch 17] step 28/44: loss=0.4448 
[epoch 17] step 30/44: loss=0.4393 
[epoch 17] step 32/44: loss=0.4356 
[epoch 17] step 34/44: loss=0.4336 
[epoch 17] step 36/44: loss=0.4308 
[epoch 17] step 38/44: loss=0.4241 
[epoch 17] step 40/44: loss=0.4181 
[epoch 17] step 42/44: loss=0.4130 
[epoch 17] step 44/44: loss=0.3956 
[epoch 17] train_loss(avg per step)=0.7911 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=7.4440 qwk=('0.3782', '0.4549', '0.3339') averageQWK=0.3890 macroEMD=0.2874 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3   10    2    0
     0   15   53   12    2
     0    3   88   64    0
     0    0   15   47   11
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    1    0
     0   15   48   13    0
     0    9   97   58    0
     0    0   12   67    1
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    2   75   15    0
     0    1  111   54    0
     0    0   17   55    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=0.3965 
[epoch 18] step 4/44: loss=0.3811 
[epoch 18] step 6/44: loss=0.3315 
[epoch 18] step 8/44: loss=0.3072 
[epoch 18] step 10/44: loss=0.3009 
[epoch 18] step 12/44: loss=0.3136 
[epoch 18] step 14/44: loss=0.3102 
[epoch 18] step 16/44: loss=0.2942 
[epoch 18] step 18/44: loss=0.2950 
[epoch 18] step 20/44: loss=0.2993 
[epoch 18] step 22/44: loss=0.2919 
[epoch 18] step 24/44: loss=0.2988 
[epoch 18] step 26/44: loss=0.2947 
[epoch 18] step 28/44: loss=0.2871 
[epoch 18] step 30/44: loss=0.2790 
[epoch 18] step 32/44: loss=0.2733 
[epoch 18] step 34/44: loss=0.2729 
[epoch 18] step 36/44: loss=0.2671 
[epoch 18] step 38/44: loss=0.2670 
[epoch 18] step 40/44: loss=0.2729 
[epoch 18] step 42/44: loss=0.2717 
[epoch 18] step 44/44: loss=0.2580 
[epoch 18] train_loss(avg per step)=0.5161 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=7.3162 qwk=('0.4229', '0.3793', '0.3623') averageQWK=0.3882 macroEMD=0.2878 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     1   13   60    8    0
     0    2  109   41    3
     0    0   21   45    7
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    5   55   16    0
     0    1   95   68    0
     0    0    9   70    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6   78    8    0
     0    2  136   28    0
     0    0   32   40    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=0.1807 
[epoch 19] step 4/44: loss=0.1145 
[epoch 19] step 6/44: loss=0.1245 
[epoch 19] step 8/44: loss=0.1841 
[epoch 19] step 10/44: loss=0.1511 
[epoch 19] step 12/44: loss=0.1518 
[epoch 19] step 14/44: loss=0.1526 
[epoch 19] step 16/44: loss=0.1648 
[epoch 19] step 18/44: loss=0.1602 
[epoch 19] step 20/44: loss=0.1449 
[epoch 19] step 22/44: loss=0.1459 
[epoch 19] step 24/44: loss=0.1629 
[epoch 19] step 26/44: loss=0.1523 
[epoch 19] step 28/44: loss=0.1528 
[epoch 19] step 30/44: loss=0.1455 
[epoch 19] step 32/44: loss=0.1444 
[epoch 19] step 34/44: loss=0.1383 
[epoch 19] step 36/44: loss=0.1373 
[epoch 19] step 38/44: loss=0.1308 
[epoch 19] step 40/44: loss=0.1306 
[epoch 19] step 42/44: loss=0.1217 
[epoch 19] step 44/44: loss=0.1571 
[epoch 19] train_loss(avg per step)=0.3141 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=8.4409 qwk=('0.4055', '0.3948', '0.3771') averageQWK=0.3925 macroEMD=0.2789 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     1   16   51   13    1
     0    5   75   73    2
     0    0   13   51    9
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    5   56   15    0
     0    1   92   71    0
     0    0    6   73    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6   75   11    0
     0    3  127   36    0
     0    0   24   48    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=0.1078 
[epoch 20] step 4/44: loss=0.0649 
[epoch 20] step 6/44: loss=0.0370 
[epoch 20] step 8/44: loss=0.0311 
[epoch 20] step 10/44: loss=0.0626 
[epoch 20] step 12/44: loss=0.0702 
[epoch 20] step 14/44: loss=0.0827 
[epoch 20] step 16/44: loss=0.0701 
[epoch 20] step 18/44: loss=0.0715 
[epoch 20] step 20/44: loss=0.0755 
[epoch 20] step 22/44: loss=0.0706 
[epoch 20] step 24/44: loss=0.0684 
[epoch 20] step 26/44: loss=0.0690 
[epoch 20] step 28/44: loss=0.0821 
[epoch 20] step 30/44: loss=0.0767 
[epoch 20] step 32/44: loss=0.0693 
[epoch 20] step 34/44: loss=0.0618 
[epoch 20] step 36/44: loss=0.0580 
[epoch 20] step 38/44: loss=0.0592 
[epoch 20] step 40/44: loss=0.0602 
[epoch 20] step 42/44: loss=0.0643 
[epoch 20] step 44/44: loss=0.0744 
[epoch 20] train_loss(avg per step)=0.1488 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=7.0899 qwk=('0.4588', '0.4415', '0.3980') averageQWK=0.4328 macroEMD=0.2831 tailR0=('0.1000', '0.0000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    8    1    0
     1   17   58    6    0
     0    3  111   38    3
     0    0   23   36   14
     0    0    6    2    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   12   57    7    0
     0    0  136   28    0
     0    0   24   54    2
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    9   73   10    0
     0    7  125   34    0
     0    1   21   50    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=0.0712 
[epoch 21] step 4/44: loss=0.0197 
[epoch 21] step 6/44: loss=0.0350 
[epoch 21] step 8/44: loss=0.0181 
[epoch 21] step 10/44: loss=0.0179 
[epoch 21] step 12/44: loss=0.0133 
[epoch 21] step 14/44: loss=0.0133 
[epoch 21] step 16/44: loss=0.0065 
[epoch 21] step 18/44: loss=-0.0105 
[epoch 21] step 20/44: loss=-0.0137 
[epoch 21] step 22/44: loss=-0.0115 
[epoch 21] step 24/44: loss=-0.0151 
[epoch 21] step 26/44: loss=-0.0176 
[epoch 21] step 28/44: loss=-0.0121 
[epoch 21] step 30/44: loss=-0.0154 
[epoch 21] step 32/44: loss=-0.0173 
[epoch 21] step 34/44: loss=-0.0188 
[epoch 21] step 36/44: loss=-0.0202 
[epoch 21] step 38/44: loss=-0.0234 
[epoch 21] step 40/44: loss=-0.0276 
[epoch 21] step 42/44: loss=-0.0225 
[epoch 21] step 44/44: loss=-0.0299 
[epoch 21] train_loss(avg per step)=-0.0599 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=8.6124 qwk=('0.4523', '0.4577', '0.3549') averageQWK=0.4216 macroEMD=0.2741 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    8    1    0
     0   20   53    9    0
     0    5   96   51    3
     0    0   17   47    9
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   11   57    8    0
     0    2  124   38    0
     0    0   19   59    2
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    3   85    4    0
     0    4  140   22    0
     0    0   32   40    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=-0.1338 
[epoch 22] step 4/44: loss=-0.1103 
[epoch 22] step 6/44: loss=-0.1298 
[epoch 22] step 8/44: loss=-0.1412 
[epoch 22] step 10/44: loss=-0.1493 
[epoch 22] step 12/44: loss=-0.1311 
[epoch 22] step 14/44: loss=-0.1279 
[epoch 22] step 16/44: loss=-0.1317 
[epoch 22] step 18/44: loss=-0.1294 
[epoch 22] step 20/44: loss=-0.1307 
[epoch 22] step 22/44: loss=-0.1306 
[epoch 22] step 24/44: loss=-0.1127 
[epoch 22] step 26/44: loss=-0.1091 
[epoch 22] step 28/44: loss=-0.1119 
[epoch 22] step 30/44: loss=-0.1149 
[epoch 22] step 32/44: loss=-0.1056 
[epoch 22] step 34/44: loss=-0.0965 
[epoch 22] step 36/44: loss=-0.0834 
[epoch 22] step 38/44: loss=-0.0848 
[epoch 22] step 40/44: loss=-0.0871 
[epoch 22] step 42/44: loss=-0.0863 
[epoch 22] step 44/44: loss=-0.0852 
[epoch 22] train_loss(avg per step)=-0.1705 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=8.6499 qwk=('0.3777', '0.4160', '0.3748') averageQWK=0.3895 macroEMD=0.2772 tailR0=('0.0833', '0.0000', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3   10    1    0
     0    8   67    5    2
     0    2  117   30    6
     0    0   23   36   14
     0    0    7    2    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    9   58    9    0
     0    3  125   36    0
     0    0   20   59    1
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4   82    6    0
     0    1  143   22    0
     0    0   30   42    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=-0.0420 
[epoch 23] step 4/44: loss=-0.0711 
[epoch 23] step 6/44: loss=-0.0832 
[epoch 23] step 8/44: loss=-0.1040 
[epoch 23] step 10/44: loss=-0.1218 
[epoch 23] step 12/44: loss=-0.1246 
[epoch 23] step 14/44: loss=-0.1262 
[epoch 23] step 16/44: loss=-0.1330 
[epoch 23] step 18/44: loss=-0.1337 
[epoch 23] step 20/44: loss=-0.1364 
[epoch 23] step 22/44: loss=-0.1356 
[epoch 23] step 24/44: loss=-0.1333 
[epoch 23] step 26/44: loss=-0.1194 
[epoch 23] step 28/44: loss=-0.1252 
[epoch 23] step 30/44: loss=-0.1259 
[epoch 23] step 32/44: loss=-0.1217 
[epoch 23] step 34/44: loss=-0.1243 
[epoch 23] step 36/44: loss=-0.1179 
[epoch 23] step 38/44: loss=-0.1167 
[epoch 23] step 40/44: loss=-0.1227 
[epoch 23] step 42/44: loss=-0.1218 
[epoch 23] step 44/44: loss=-0.1281 
[epoch 23] train_loss(avg per step)=-0.2563 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=9.1343 qwk=('0.4275', '0.4460', '0.3701') averageQWK=0.4145 macroEMD=0.2706 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   13   59    9    1
     0    2  102   49    2
     0    0   16   48    9
     0    0    4    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    8   58   10    0
     0    1  121   42    0
     0    0   12   67    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    5   80    7    0
     0    1  141   24    0
     0    0   30   42    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=-0.2603 
[epoch 24] step 4/44: loss=-0.2034 
[epoch 24] step 6/44: loss=-0.1861 
[epoch 24] step 8/44: loss=-0.1683 
[epoch 24] step 10/44: loss=-0.1734 
[epoch 24] step 12/44: loss=-0.1718 
[epoch 24] step 14/44: loss=-0.1637 
[epoch 24] step 16/44: loss=-0.1590 
[epoch 24] step 18/44: loss=-0.1676 
[epoch 24] step 20/44: loss=-0.1682 
[epoch 24] step 22/44: loss=-0.1727 
[epoch 24] step 24/44: loss=-0.1740 
[epoch 24] step 26/44: loss=-0.1676 
[epoch 24] step 28/44: loss=-0.1655 
[epoch 24] step 30/44: loss=-0.1731 
[epoch 24] step 32/44: loss=-0.1776 
[epoch 24] step 34/44: loss=-0.1773 
[epoch 24] step 36/44: loss=-0.1792 
[epoch 24] step 38/44: loss=-0.1816 
[epoch 24] step 40/44: loss=-0.1787 
[epoch 24] step 42/44: loss=-0.1743 
[epoch 24] step 44/44: loss=-0.1791 
[epoch 24] train_loss(avg per step)=-0.3581 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=9.3934 qwk=('0.4360', '0.4355', '0.3020') averageQWK=0.3911 macroEMD=0.2735 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   14   60    7    1
     0    3  109   41    2
     0    0   19   45    9
     0    0    4    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0    9   56   11    0
     0    3  117   44    0
     0    0   15   64    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    5   84    3    0
     0    3  150   13    0
     0    0   46   26    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=-0.1880 
[epoch 25] step 4/44: loss=-0.2182 
[epoch 25] step 6/44: loss=-0.2259 
[epoch 25] step 8/44: loss=-0.2132 
[epoch 25] step 10/44: loss=-0.2234 
[epoch 25] step 12/44: loss=-0.2255 
[epoch 25] step 14/44: loss=-0.2186 
[epoch 25] step 16/44: loss=-0.2113 
[epoch 25] step 18/44: loss=-0.2055 
[epoch 25] step 20/44: loss=-0.2136 
[epoch 25] step 22/44: loss=-0.2130 
[epoch 25] step 24/44: loss=-0.2121 
[epoch 25] step 26/44: loss=-0.2127 
[epoch 25] step 28/44: loss=-0.2129 
[epoch 25] step 30/44: loss=-0.2106 
[epoch 25] step 32/44: loss=-0.2109 
[epoch 25] step 34/44: loss=-0.2121 
[epoch 25] step 36/44: loss=-0.2098 
[epoch 25] step 38/44: loss=-0.2058 
[epoch 25] step 40/44: loss=-0.2049 
[epoch 25] step 42/44: loss=-0.1957 
[epoch 25] step 44/44: loss=-0.2005 
[epoch 25] train_loss(avg per step)=-0.4009 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=9.5729 qwk=('0.3950', '0.4462', '0.3135') averageQWK=0.3849 macroEMD=0.2785 tailR0=('0.1500', '0.0000', '0.0000') tailR0avg=0.0500
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3   11    1    0
     0   11   62    6    3
     0    2  111   33    9
     0    0   20   34   19
     0    0    5    2    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   12   54   10    0
     0    7  117   40    0
     0    0   17   62    1
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    4   84    4    0
     0    3  147   16    0
     0    0   40   32    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=-0.1290 
[epoch 26] step 4/44: loss=-0.1578 
[epoch 26] step 6/44: loss=-0.1638 
[epoch 26] step 8/44: loss=-0.1815 
[epoch 26] step 10/44: loss=-0.2002 
[epoch 26] step 12/44: loss=-0.2050 
[epoch 26] step 14/44: loss=-0.2059 
[epoch 26] step 16/44: loss=-0.2140 
[epoch 26] step 18/44: loss=-0.2185 
[epoch 26] step 20/44: loss=-0.2178 
[epoch 26] step 22/44: loss=-0.2238 
[epoch 26] step 24/44: loss=-0.2261 
[epoch 26] step 26/44: loss=-0.2243 
[epoch 26] step 28/44: loss=-0.2246 
[epoch 26] step 30/44: loss=-0.2238 
[epoch 26] step 32/44: loss=-0.2285 
[epoch 26] step 34/44: loss=-0.2251 
[epoch 26] step 36/44: loss=-0.2264 
[epoch 26] step 38/44: loss=-0.2233 
[epoch 26] step 40/44: loss=-0.2258 
[epoch 26] step 42/44: loss=-0.2292 
[epoch 26] step 44/44: loss=-0.2312 
[epoch 26] train_loss(avg per step)=-0.4624 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=10.1655 qwk=('0.4045', '0.4142', '0.3583') averageQWK=0.3923 macroEMD=0.2689 tailR0=('0.1000', '0.0000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    8    1    0
     2   15   48   15    2
     0    4   90   56    5
     0    1   16   43   13
     0    0    3    5    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0    8   55   13    0
     0    4  106   54    0
     0    0   13   66    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    5   75   12    0
     0    2  119   45    0
     0    0   22   50    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=-0.2545 
[epoch 27] step 4/44: loss=-0.2409 
[epoch 27] step 6/44: loss=-0.2298 
[epoch 27] step 8/44: loss=-0.2384 
[epoch 27] step 10/44: loss=-0.2276 
[epoch 27] step 12/44: loss=-0.2344 
[epoch 27] step 14/44: loss=-0.2428 
[epoch 27] step 16/44: loss=-0.2430 
[epoch 27] step 18/44: loss=-0.2460 
[epoch 27] step 20/44: loss=-0.2539 
[epoch 27] step 22/44: loss=-0.2530 
[epoch 27] step 24/44: loss=-0.2449 
[epoch 27] step 26/44: loss=-0.2431 
[epoch 27] step 28/44: loss=-0.2465 
[epoch 27] step 30/44: loss=-0.2478 
[epoch 27] step 32/44: loss=-0.2481 
[epoch 27] step 34/44: loss=-0.2497 
[epoch 27] step 36/44: loss=-0.2482 
[epoch 27] step 38/44: loss=-0.2457 
[epoch 27] step 40/44: loss=-0.2452 
[epoch 27] step 42/44: loss=-0.2398 
[epoch 27] step 44/44: loss=-0.2398 
[epoch 27] train_loss(avg per step)=-0.4795 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=10.2394 qwk=('0.3577', '0.4354', '0.3702') averageQWK=0.3878 macroEMD=0.2705 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0    7   63   12    0
     0    0  103   49    3
     0    0   20   47    6
     0    0    5    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   11   52   13    0
     0    4  121   39    0
     0    0   15   64    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4   80    8    0
     0    1  136   29    0
     0    0   27   45    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=-0.2548 
[epoch 28] step 4/44: loss=-0.2589 
[epoch 28] step 6/44: loss=-0.2741 
[epoch 28] step 8/44: loss=-0.2548 
[epoch 28] step 10/44: loss=-0.2531 
[epoch 28] step 12/44: loss=-0.2536 
[epoch 28] step 14/44: loss=-0.2545 
[epoch 28] step 16/44: loss=-0.2459 
[epoch 28] step 18/44: loss=-0.2453 
[epoch 28] step 20/44: loss=-0.2422 
[epoch 28] step 22/44: loss=-0.2379 
[epoch 28] step 24/44: loss=-0.2380 
[epoch 28] step 26/44: loss=-0.2412 
[epoch 28] step 28/44: loss=-0.2445 
[epoch 28] step 30/44: loss=-0.2475 
[epoch 28] step 32/44: loss=-0.2483 
[epoch 28] step 34/44: loss=-0.2529 
[epoch 28] step 36/44: loss=-0.2557 
[epoch 28] step 38/44: loss=-0.2588 
[epoch 28] step 40/44: loss=-0.2586 
[epoch 28] step 42/44: loss=-0.2603 
[epoch 28] step 44/44: loss=-0.2602 
[epoch 28] train_loss(avg per step)=-0.5203 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=11.0610 qwk=('0.3453', '0.3932', '0.3621') averageQWK=0.3669 macroEMD=0.2709 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3   11    1    0
     0    7   61   14    0
     0    1   94   59    1
     0    0   18   49    6
     0    0    5    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    9   51   16    0
     0    4  101   59    0
     0    0   11   68    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    4   82    6    0
     0    2  144   20    0
     0    0   30   42    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=-0.2948 
[epoch 29] step 4/44: loss=-0.2865 
[epoch 29] step 6/44: loss=-0.2811 
[epoch 29] step 8/44: loss=-0.2755 
[epoch 29] step 10/44: loss=-0.2713 
[epoch 29] step 12/44: loss=-0.2779 
[epoch 29] step 14/44: loss=-0.2753 
[epoch 29] step 16/44: loss=-0.2769 
[epoch 29] step 18/44: loss=-0.2799 
[epoch 29] step 20/44: loss=-0.2808 
[epoch 29] step 22/44: loss=-0.2855 
[epoch 29] step 24/44: loss=-0.2845 
[epoch 29] step 26/44: loss=-0.2861 
[epoch 29] step 28/44: loss=-0.2845 
[epoch 29] step 30/44: loss=-0.2855 
[epoch 29] step 32/44: loss=-0.2868 
[epoch 29] step 34/44: loss=-0.2839 
[epoch 29] step 36/44: loss=-0.2835 
[epoch 29] step 38/44: loss=-0.2837 
[epoch 29] step 40/44: loss=-0.2830 
[epoch 29] step 42/44: loss=-0.2801 
[epoch 29] step 44/44: loss=-0.2823 
[epoch 29] train_loss(avg per step)=-0.5647 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=10.5897 qwk=('0.4437', '0.4673', '0.3716') averageQWK=0.4275 macroEMD=0.2679 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    8    1    0
     1   16   57    7    1
     0    4  101   45    5
     0    0   17   44   12
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    1    0
     0   17   48   11    0
     0   11   98   55    0
     0    0   12   67    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4   75   13    0
     0    2  123   41    0
     0    0   18   54    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=-0.2388 
[epoch 30] step 4/44: loss=-0.2589 
[epoch 30] step 6/44: loss=-0.2727 
[epoch 30] step 8/44: loss=-0.2856 
[epoch 30] step 10/44: loss=-0.2854 
[epoch 30] step 12/44: loss=-0.2905 
[epoch 30] step 14/44: loss=-0.2916 
[epoch 30] step 16/44: loss=-0.2893 
[epoch 30] step 18/44: loss=-0.2879 
[epoch 30] step 20/44: loss=-0.2830 
[epoch 30] step 22/44: loss=-0.2846 
[epoch 30] step 24/44: loss=-0.2830 
[epoch 30] step 26/44: loss=-0.2847 
[epoch 30] step 28/44: loss=-0.2870 
[epoch 30] step 30/44: loss=-0.2869 
[epoch 30] step 32/44: loss=-0.2869 
[epoch 30] step 34/44: loss=-0.2848 
[epoch 30] step 36/44: loss=-0.2823 
[epoch 30] step 38/44: loss=-0.2835 
[epoch 30] step 40/44: loss=-0.2846 
[epoch 30] step 42/44: loss=-0.2866 
[epoch 30] step 44/44: loss=-0.2892 
[epoch 30] train_loss(avg per step)=-0.5783 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=10.4382 qwk=('0.4272', '0.4138', '0.3687') averageQWK=0.4032 macroEMD=0.2689 tailR0=('0.1000', '0.0000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     1   12   63    5    1
     0    3  121   28    3
     0    0   24   33   16
     0    0    7    1    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   12   48   16    0
     0    5  104   55    0
     0    0   12   67    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5   76   11    0
     0    5  131   30    0
     0    0   25   47    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=-0.2983 
[epoch 31] step 4/44: loss=-0.2743 
[epoch 31] step 6/44: loss=-0.2822 
[epoch 31] step 8/44: loss=-0.2875 
[epoch 31] step 10/44: loss=-0.2942 
[epoch 31] step 12/44: loss=-0.2896 
[epoch 31] step 14/44: loss=-0.2857 
[epoch 31] step 16/44: loss=-0.2914 
[epoch 31] step 18/44: loss=-0.2911 
[epoch 31] step 20/44: loss=-0.2950 
[epoch 31] step 22/44: loss=-0.2974 
[epoch 31] step 24/44: loss=-0.2981 
[epoch 31] step 26/44: loss=-0.3014 
[epoch 31] step 28/44: loss=-0.3040 
[epoch 31] step 30/44: loss=-0.3018 
[epoch 31] step 32/44: loss=-0.3019 
[epoch 31] step 34/44: loss=-0.3006 
[epoch 31] step 36/44: loss=-0.3017 
[epoch 31] step 38/44: loss=-0.3018 
[epoch 31] step 40/44: loss=-0.3012 
[epoch 31] step 42/44: loss=-0.3014 
[epoch 31] step 44/44: loss=-0.2618 
[epoch 31] train_loss(avg per step)=-0.5237 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=11.6379 qwk=('0.3499', '0.3976', '0.3650') averageQWK=0.3708 macroEMD=0.2717 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0    7   67    7    1
     0    1  111   40    3
     0    0   22   42    9
     0    0    8    2    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    8   52   16    0
     0    4   97   63    0
     0    0    8   71    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    4   80    8    0
     0    2  138   26    0
     0    0   26   46    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=-0.3131 
[epoch 32] step 4/44: loss=-0.2577 
[epoch 32] step 6/44: loss=-0.2715 
[epoch 32] step 8/44: loss=-0.2852 
[epoch 32] step 10/44: loss=-0.2927 
[epoch 32] step 12/44: loss=-0.2928 
[epoch 32] step 14/44: loss=-0.2910 
[epoch 32] step 16/44: loss=-0.2931 
[epoch 32] step 18/44: loss=-0.2954 
[epoch 32] step 20/44: loss=-0.2954 
[epoch 32] step 22/44: loss=-0.2968 
[epoch 32] step 24/44: loss=-0.2975 
[epoch 32] step 26/44: loss=-0.2980 
[epoch 32] step 28/44: loss=-0.2981 
[epoch 32] step 30/44: loss=-0.2989 
[epoch 32] step 32/44: loss=-0.2997 
[epoch 32] step 34/44: loss=-0.3013 
[epoch 32] step 36/44: loss=-0.3015 
[epoch 32] step 38/44: loss=-0.3026 
[epoch 32] step 40/44: loss=-0.3024 
[epoch 32] step 42/44: loss=-0.3039 
[epoch 32] step 44/44: loss=-0.3041 
[epoch 32] train_loss(avg per step)=-0.6083 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=12.0453 qwk=('0.3915', '0.3829', '0.3467') averageQWK=0.3737 macroEMD=0.2709 tailR0=('0.1000', '0.0000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0    9   61   10    2
     0    2   98   51    4
     0    0   17   43   13
     0    0    5    3    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    7   52   17    0
     0    4   88   72    0
     0    0    7   72    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    4   76   12    0
     0    2  132   32    0
     0    0   23   49    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=-0.2645 
[epoch 33] step 4/44: loss=-0.2907 
[epoch 33] step 6/44: loss=-0.2881 
[epoch 33] step 8/44: loss=-0.2936 
[epoch 33] step 10/44: loss=-0.3016 
[epoch 33] step 12/44: loss=-0.2950 
[epoch 33] step 14/44: loss=-0.2982 
[epoch 33] step 16/44: loss=-0.3007 
[epoch 33] step 18/44: loss=-0.3029 
[epoch 33] step 20/44: loss=-0.3057 
[epoch 33] step 22/44: loss=-0.3046 
[epoch 33] step 24/44: loss=-0.3057 
[epoch 33] step 26/44: loss=-0.3069 
[epoch 33] step 28/44: loss=-0.3091 
[epoch 33] step 30/44: loss=-0.3108 
[epoch 33] step 32/44: loss=-0.3111 
[epoch 33] step 34/44: loss=-0.3115 
[epoch 33] step 36/44: loss=-0.3111 
[epoch 33] step 38/44: loss=-0.3112 
[epoch 33] step 40/44: loss=-0.3109 
[epoch 33] step 42/44: loss=-0.3115 
[epoch 33] step 44/44: loss=-0.2895 
[epoch 33] train_loss(avg per step)=-0.5790 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=10.8395 qwk=('0.4164', '0.4057', '0.3976') averageQWK=0.4066 macroEMD=0.2686 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    8    1    0
     0   11   62    8    1
     0    2  105   44    4
     0    0   18   41   14
     0    0    6    3    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    8   54   14    0
     0    3  113   48    0
     0    0   13   66    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0    5   78    9    0
     0    4  132   30    0
     0    0   25   47    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=-0.3390 
[epoch 34] step 4/44: loss=-0.3227 
[epoch 34] step 6/44: loss=-0.3166 
[epoch 34] step 8/44: loss=-0.3077 
[epoch 34] step 10/44: loss=-0.3125 
[epoch 34] step 12/44: loss=-0.3151 
[epoch 34] step 14/44: loss=-0.3170 
[epoch 34] step 16/44: loss=-0.3193 
[epoch 34] step 18/44: loss=-0.3197 
[epoch 34] step 20/44: loss=-0.3150 
[epoch 34] step 22/44: loss=-0.3170 
[epoch 34] step 24/44: loss=-0.3176 
[epoch 34] step 26/44: loss=-0.3186 
[epoch 34] step 28/44: loss=-0.3168 
[epoch 34] step 30/44: loss=-0.3147 
[epoch 34] step 32/44: loss=-0.3141 
[epoch 34] step 34/44: loss=-0.3149 
[epoch 34] step 36/44: loss=-0.3162 
[epoch 34] step 38/44: loss=-0.3171 
[epoch 34] step 40/44: loss=-0.3176 
[epoch 34] step 42/44: loss=-0.3182 
[epoch 34] step 44/44: loss=-0.3191 
[epoch 34] train_loss(avg per step)=-0.6383 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=11.0208 qwk=('0.3809', '0.4152', '0.3997') averageQWK=0.3986 macroEMD=0.2660 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0    9   65    7    1
     0    2  111   39    3
     0    0   21   41   11
     0    0    7    2    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0    9   53   14    0
     0    4  109   51    0
     0    0   13   66    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0    5   78    9    0
     0    4  134   28    0
     0    0   25   47    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=-0.3354 
[epoch 35] step 4/44: loss=-0.3353 
[epoch 35] step 6/44: loss=-0.3326 
[epoch 35] step 8/44: loss=-0.3310 
[epoch 35] step 10/44: loss=-0.3321 
[epoch 35] step 12/44: loss=-0.3300 
[epoch 35] step 14/44: loss=-0.3308 
[epoch 35] step 16/44: loss=-0.3301 
[epoch 35] step 18/44: loss=-0.3288 
[epoch 35] step 20/44: loss=-0.3300 
[epoch 35] step 22/44: loss=-0.3308 
[epoch 35] step 24/44: loss=-0.3310 
[epoch 35] step 26/44: loss=-0.3291 
[epoch 35] step 28/44: loss=-0.3280 
[epoch 35] step 30/44: loss=-0.3288 
[epoch 35] step 32/44: loss=-0.3281 
[epoch 35] step 34/44: loss=-0.3279 
[epoch 35] step 36/44: loss=-0.3279 
[epoch 35] step 38/44: loss=-0.3259 
[epoch 35] step 40/44: loss=-0.3249 
[epoch 35] step 42/44: loss=-0.3230 
[epoch 35] step 44/44: loss=-0.3237 
[epoch 35] train_loss(avg per step)=-0.6474 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=10.9804 qwk=('0.4009', '0.4153', '0.3769') averageQWK=0.3977 macroEMD=0.2654 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     1   11   61    8    1
     0    3  108   41    3
     0    0   19   43   11
     0    0    7    2    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0    9   53   14    0
     0    4  113   47    0
     0    0   14   65    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    5   78    9    0
     0    4  135   27    0
     0    0   27   45    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-0/fold4/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-0/fold4/metrics.json
Done.
