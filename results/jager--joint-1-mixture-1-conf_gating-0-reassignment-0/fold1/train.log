[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=7.9626 
[epoch 1] step 4/44: loss=7.4676 
[epoch 1] step 6/44: loss=7.2491 
[epoch 1] step 8/44: loss=7.2172 
[epoch 1] step 10/44: loss=7.2862 
[epoch 1] step 12/44: loss=7.1889 
[epoch 1] step 14/44: loss=7.1890 
[epoch 1] step 16/44: loss=7.2180 
[epoch 1] step 18/44: loss=7.2239 
[epoch 1] step 20/44: loss=7.2082 
[epoch 1] step 22/44: loss=7.2198 
[epoch 1] step 24/44: loss=7.2133 
[epoch 1] step 26/44: loss=7.1683 
[epoch 1] step 28/44: loss=7.1466 
[epoch 1] step 30/44: loss=7.1209 
[epoch 1] step 32/44: loss=7.0718 
[epoch 1] step 34/44: loss=7.0348 
[epoch 1] step 36/44: loss=6.9899 
[epoch 1] step 38/44: loss=6.9109 
[epoch 1] step 40/44: loss=6.8646 
[epoch 1] step 42/44: loss=6.7922 
[epoch 1] step 44/44: loss=6.6966 
[epoch 1] train_loss(avg per step)=13.3932 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=7.3124 qwk=('-0.0099', '0.0904', '0.0419') averageQWK=0.0408 macroEMD=0.3839 tailR0=('0.0000', '0.0385', '0.0000') tailR0avg=0.0128
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    7    0
     0   18    0   23    0
     0   51    0   71    0
     0   53    0   88    0
     0   11    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0   12    0    0
     6    0   29    4    0
    14    0   76   14    0
    18    0  114   31    0
     0    0   12    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    2   50    0    0
     0    1  157    0    0
     0    2  108    0    0
     0    0    3    0    0
[epoch 2] step 2/44: loss=4.8019 
[epoch 2] step 4/44: loss=4.8012 
[epoch 2] step 6/44: loss=4.7905 
[epoch 2] step 8/44: loss=4.6623 
[epoch 2] step 10/44: loss=4.6125 
[epoch 2] step 12/44: loss=4.5529 
[epoch 2] step 14/44: loss=4.4424 
[epoch 2] step 16/44: loss=4.3692 
[epoch 2] step 18/44: loss=4.3003 
[epoch 2] step 20/44: loss=4.1829 
[epoch 2] step 22/44: loss=4.0930 
[epoch 2] step 24/44: loss=4.0498 
[epoch 2] step 26/44: loss=3.9838 
[epoch 2] step 28/44: loss=3.9428 
[epoch 2] step 30/44: loss=3.8883 
[epoch 2] step 32/44: loss=3.8336 
[epoch 2] step 34/44: loss=3.7720 
[epoch 2] step 36/44: loss=3.7280 
[epoch 2] step 38/44: loss=3.7033 
[epoch 2] step 40/44: loss=3.6684 
[epoch 2] step 42/44: loss=3.6326 
[epoch 2] step 44/44: loss=3.5792 
[epoch 2] train_loss(avg per step)=7.1584 lambda[min,max]=[0.508702,1.000000]
[epoch 2] val_loss=4.4302 qwk=('0.4078', '0.0808', '0.1728') averageQWK=0.2205 macroEMD=0.3771 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    2   31    8    0
     0    1   48   73    0
     0    0   17  124    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    0    0
     0    0   39    0    0
     0    0  103    1    0
     0    0  149   14    0
     0    0   13    3    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    0   52    0    0
     0    0  154    4    0
     0    0   90   20    0
     0    0    1    2    0
[epoch 3] step 2/44: loss=2.5231 
[epoch 3] step 4/44: loss=2.7386 
[epoch 3] step 6/44: loss=2.7376 
[epoch 3] step 8/44: loss=2.7997 
[epoch 3] step 10/44: loss=2.8159 
[epoch 3] step 12/44: loss=2.8125 
[epoch 3] step 14/44: loss=2.8386 
[epoch 3] step 16/44: loss=2.8333 
[epoch 3] step 18/44: loss=2.8466 
[epoch 3] step 20/44: loss=2.8369 
[epoch 3] step 22/44: loss=2.8242 
[epoch 3] step 24/44: loss=2.8211 
[epoch 3] step 26/44: loss=2.8267 
[epoch 3] step 28/44: loss=2.8054 
[epoch 3] step 30/44: loss=2.8308 
[epoch 3] step 32/44: loss=2.8111 
[epoch 3] step 34/44: loss=2.7879 
[epoch 3] step 36/44: loss=2.7725 
[epoch 3] step 38/44: loss=2.7411 
[epoch 3] step 40/44: loss=2.7471 
[epoch 3] step 42/44: loss=2.7374 
[epoch 3] step 44/44: loss=2.7108 
[epoch 3] train_loss(avg per step)=5.4215 lambda[min,max]=[0.525846,1.000000]
[epoch 3] val_loss=4.1409 qwk=('0.5428', '0.4235', '0.2071') averageQWK=0.3911 macroEMD=0.3644 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    6    1    0
     0   14   24    3    0
     0   14   71   37    0
     0    0   35  106    0
     0    0    2   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    1    0
     0    3   36    0    0
     0    3   83   18    0
     0    0   67   96    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   50    0    0
     0    3  154    1    0
     0    0   86   24    0
     0    0    3    0    0
[epoch 4] step 2/44: loss=2.6852 
[epoch 4] step 4/44: loss=2.5536 
[epoch 4] step 6/44: loss=2.5116 
[epoch 4] step 8/44: loss=2.5589 
[epoch 4] step 10/44: loss=2.5318 
[epoch 4] step 12/44: loss=2.5186 
[epoch 4] step 14/44: loss=2.5154 
[epoch 4] step 16/44: loss=2.4865 
[epoch 4] step 18/44: loss=2.4650 
[epoch 4] step 20/44: loss=2.4557 
[epoch 4] step 22/44: loss=2.4691 
[epoch 4] step 24/44: loss=2.4840 
[epoch 4] step 26/44: loss=2.4798 
[epoch 4] step 28/44: loss=2.4873 
[epoch 4] step 30/44: loss=2.5136 
[epoch 4] step 32/44: loss=2.5083 
[epoch 4] step 34/44: loss=2.5070 
[epoch 4] step 36/44: loss=2.5226 
[epoch 4] step 38/44: loss=2.5118 
[epoch 4] step 40/44: loss=2.5130 
[epoch 4] step 42/44: loss=2.4903 
[epoch 4] step 44/44: loss=2.4736 
[epoch 4] train_loss(avg per step)=4.9473 lambda[min,max]=[0.510507,1.000000]
[epoch 4] val_loss=4.5318 qwk=('0.4130', '0.3510', '0.4522') averageQWK=0.4054 macroEMD=0.3478 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    4   27   10    0
     0    2   43   77    0
     0    0   11  130    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    0   20   19    0
     0    0   46   58    0
     0    0   14  149    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    0   47    5    0
     0    0  100   58    0
     0    0   16   94    0
     0    0    0    3    0
[epoch 5] step 2/44: loss=2.0643 
[epoch 5] step 4/44: loss=2.1006 
[epoch 5] step 6/44: loss=2.1038 
[epoch 5] step 8/44: loss=2.1852 
[epoch 5] step 10/44: loss=2.1616 
[epoch 5] step 12/44: loss=2.1395 
[epoch 5] step 14/44: loss=2.1433 
[epoch 5] step 16/44: loss=2.1483 
[epoch 5] step 18/44: loss=2.1268 
[epoch 5] step 20/44: loss=2.0868 
[epoch 5] step 22/44: loss=2.0854 
[epoch 5] step 24/44: loss=2.0874 
[epoch 5] step 26/44: loss=2.1067 
[epoch 5] step 28/44: loss=2.1147 
[epoch 5] step 30/44: loss=2.1235 
[epoch 5] step 32/44: loss=2.1317 
[epoch 5] step 34/44: loss=2.1098 
[epoch 5] step 36/44: loss=2.1190 
[epoch 5] step 38/44: loss=2.1164 
[epoch 5] step 40/44: loss=2.1102 
[epoch 5] step 42/44: loss=2.1034 
[epoch 5] step 44/44: loss=2.1073 
[epoch 5] train_loss(avg per step)=4.2147 lambda[min,max]=[0.512150,1.000000]
[epoch 5] val_loss=4.3565 qwk=('0.4866', '0.3987', '0.3253') averageQWK=0.4035 macroEMD=0.3377 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    3   34    4    0
     0    0   72   50    0
     0    0   26  115    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    2   23   14    0
     0    3   46   55    0
     0    0   17  146    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   50    1    0
     0    2  142   14    0
     0    0   62   48    0
     0    0    2    1    0
[epoch 6] step 2/44: loss=2.1404 
[epoch 6] step 4/44: loss=2.0227 
[epoch 6] step 6/44: loss=2.0464 
[epoch 6] step 8/44: loss=2.0161 
[epoch 6] step 10/44: loss=1.9924 
[epoch 6] step 12/44: loss=2.0071 
[epoch 6] step 14/44: loss=2.0079 
[epoch 6] step 16/44: loss=1.9971 
[epoch 6] step 18/44: loss=2.0016 
[epoch 6] step 20/44: loss=1.9950 
[epoch 6] step 22/44: loss=2.0229 
[epoch 6] step 24/44: loss=2.0014 
[epoch 6] step 26/44: loss=1.9644 
[epoch 6] step 28/44: loss=1.9619 
[epoch 6] step 30/44: loss=1.9401 
[epoch 6] step 32/44: loss=1.9349 
[epoch 6] step 34/44: loss=1.9423 
[epoch 6] step 36/44: loss=1.9428 
[epoch 6] step 38/44: loss=1.9353 
[epoch 6] step 40/44: loss=1.9455 
[epoch 6] step 42/44: loss=1.9432 
[epoch 6] step 44/44: loss=1.9295 
[epoch 6] train_loss(avg per step)=3.8591 lambda[min,max]=[0.502244,1.000000]
[epoch 6] val_loss=5.1366 qwk=('0.4572', '0.3665', '0.3455') averageQWK=0.3897 macroEMD=0.3412 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    1    0    0
     0   24   17    0    0
     0   36   74   12    0
     0    8   71   62    0
     0    0   16    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    4    0    0
     0   25   14    0    0
     0   44   56    4    0
     0   18  108   37    0
     0    0   11    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   11    1    0    0
     0   28   24    0    0
     0   47  111    0    0
     0    8   95    7    0
     0    0    3    0    0
[epoch 7] step 2/44: loss=2.6956 
[epoch 7] step 4/44: loss=2.5454 
[epoch 7] step 6/44: loss=2.2695 
[epoch 7] step 8/44: loss=2.1905 
[epoch 7] step 10/44: loss=2.2087 
[epoch 7] step 12/44: loss=2.1519 
[epoch 7] step 14/44: loss=2.1060 
[epoch 7] step 16/44: loss=2.0686 
[epoch 7] step 18/44: loss=2.0589 
[epoch 7] step 20/44: loss=2.0657 
[epoch 7] step 22/44: loss=2.0339 
[epoch 7] step 24/44: loss=2.0281 
[epoch 7] step 26/44: loss=2.0266 
[epoch 7] step 28/44: loss=2.0027 
[epoch 7] step 30/44: loss=1.9912 
[epoch 7] step 32/44: loss=1.9682 
[epoch 7] step 34/44: loss=1.9603 
[epoch 7] step 36/44: loss=1.9496 
[epoch 7] step 38/44: loss=1.9336 
[epoch 7] step 40/44: loss=1.9157 
[epoch 7] step 42/44: loss=1.9036 
[epoch 7] step 44/44: loss=1.9197 
[epoch 7] train_loss(avg per step)=3.8394 lambda[min,max]=[0.500773,1.000000]
[epoch 7] val_loss=4.1221 qwk=('0.4235', '0.4866', '0.5452') averageQWK=0.4851 macroEMD=0.3254 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    3   37    1    0
     0    1   89   32    0
     0    0   50   91    0
     0    0    7   14    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    2    0
     0    4   29    6    0
     0    2   60   42    0
     0    0   25  138    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    4    0    0
     0   18   29    5    0
     0   21   70   67    0
     0    3   12   95    0
     0    0    0    3    0
[epoch 8] step 2/44: loss=1.4396 
[epoch 8] step 4/44: loss=1.5710 
[epoch 8] step 6/44: loss=1.6120 
[epoch 8] step 8/44: loss=1.5970 
[epoch 8] step 10/44: loss=1.5974 
[epoch 8] step 12/44: loss=1.6151 
[epoch 8] step 14/44: loss=1.6372 
[epoch 8] step 16/44: loss=1.6525 
[epoch 8] step 18/44: loss=1.6562 
[epoch 8] step 20/44: loss=1.6446 
[epoch 8] step 22/44: loss=1.6390 
[epoch 8] step 24/44: loss=1.6426 
[epoch 8] step 26/44: loss=1.6456 
[epoch 8] step 28/44: loss=1.6385 
[epoch 8] step 30/44: loss=1.6553 
[epoch 8] step 32/44: loss=1.6617 
[epoch 8] step 34/44: loss=1.6687 
[epoch 8] step 36/44: loss=1.6622 
[epoch 8] step 38/44: loss=1.6462 
[epoch 8] step 40/44: loss=1.6451 
[epoch 8] step 42/44: loss=1.6442 
[epoch 8] step 44/44: loss=1.6433 
[epoch 8] train_loss(avg per step)=3.2866 lambda[min,max]=[0.500312,1.000000]
[epoch 8] val_loss=4.3368 qwk=('0.5239', '0.4801', '0.3694') averageQWK=0.4578 macroEMD=0.3168 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    0    0
     0   16   24    1    0
     0   19   73   30    0
     0    7   37   97    0
     0    0    5   16    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   11    1    1    0
     0   22   16    1    0
     0   39   48   17    0
     0   19   58   86    0
     0    1    2   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0   10   42    0    0
     0   18  123   17    0
     0    4   58   48    0
     0    0    2    1    0
[epoch 9] step 2/44: loss=1.9125 
[epoch 9] step 4/44: loss=1.7008 
[epoch 9] step 6/44: loss=1.6149 
[epoch 9] step 8/44: loss=1.6881 
[epoch 9] step 10/44: loss=1.6003 
[epoch 9] step 12/44: loss=1.5561 
[epoch 9] step 14/44: loss=1.5591 
[epoch 9] step 16/44: loss=1.5568 
[epoch 9] step 18/44: loss=1.5591 
[epoch 9] step 20/44: loss=1.5468 
[epoch 9] step 22/44: loss=1.5408 
[epoch 9] step 24/44: loss=1.5387 
[epoch 9] step 26/44: loss=1.5253 
[epoch 9] step 28/44: loss=1.5342 
[epoch 9] step 30/44: loss=1.5325 
[epoch 9] step 32/44: loss=1.5351 
[epoch 9] step 34/44: loss=1.5109 
[epoch 9] step 36/44: loss=1.5051 
[epoch 9] step 38/44: loss=1.5009 
[epoch 9] step 40/44: loss=1.5218 
[epoch 9] step 42/44: loss=1.5653 
[epoch 9] step 44/44: loss=1.5552 
[epoch 9] train_loss(avg per step)=3.1104 lambda[min,max]=[0.500016,1.000000]
[epoch 9] val_loss=4.7497 qwk=('0.3960', '0.3061', '0.4450') averageQWK=0.3824 macroEMD=0.3230 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    3    0
     0    4   26   11    0
     0    2   43   77    0
     0    0   10  131    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    5    0
     0    3   13   23    0
     0    5   32   67    0
     0    0   10  153    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    3   44    5    0
     0    5   92   61    0
     0    0   19   91    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=1.3616 
[epoch 10] step 4/44: loss=1.3850 
[epoch 10] step 6/44: loss=1.3615 
[epoch 10] step 8/44: loss=1.4173 
[epoch 10] step 10/44: loss=1.4032 
[epoch 10] step 12/44: loss=1.3799 
[epoch 10] step 14/44: loss=1.4182 
[epoch 10] step 16/44: loss=1.4311 
[epoch 10] step 18/44: loss=1.4158 
[epoch 10] step 20/44: loss=1.4022 
[epoch 10] step 22/44: loss=1.3746 
[epoch 10] step 24/44: loss=1.3444 
[epoch 10] step 26/44: loss=1.3407 
[epoch 10] step 28/44: loss=1.3337 
[epoch 10] step 30/44: loss=1.3369 
[epoch 10] step 32/44: loss=1.3306 
[epoch 10] step 34/44: loss=1.3187 
[epoch 10] step 36/44: loss=1.3194 
[epoch 10] step 38/44: loss=1.3257 
[epoch 10] step 40/44: loss=1.3197 
[epoch 10] step 42/44: loss=1.3230 
[epoch 10] step 44/44: loss=1.3139 
[epoch 10] train_loss(avg per step)=2.6278 lambda[min,max]=[0.500044,1.000000]
[epoch 10] val_loss=4.8633 qwk=('0.4684', '0.4036', '0.4650') averageQWK=0.4457 macroEMD=0.3113 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    3    0
     0   10   21   10    0
     0    8   46   68    0
     0    1   12  128    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    6   19   14    0
     0    5   41   58    0
     0    1   17  145    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    6    0    0
     0    8   37    7    0
     0   13   73   72    0
     0    4   12   94    0
     0    0    0    3    0
[epoch 11] step 2/44: loss=1.4725 
[epoch 11] step 4/44: loss=1.3506 
[epoch 11] step 6/44: loss=1.2658 
[epoch 11] step 8/44: loss=1.2827 
[epoch 11] step 10/44: loss=1.2715 
[epoch 11] step 12/44: loss=1.2460 
[epoch 11] step 14/44: loss=1.2403 
[epoch 11] step 16/44: loss=1.2482 
[epoch 11] step 18/44: loss=1.2772 
[epoch 11] step 20/44: loss=1.2837 
[epoch 11] step 22/44: loss=1.3005 
[epoch 11] step 24/44: loss=1.3113 
[epoch 11] step 26/44: loss=1.3190 
[epoch 11] step 28/44: loss=1.3085 
[epoch 11] step 30/44: loss=1.3067 
[epoch 11] step 32/44: loss=1.3026 
[epoch 11] step 34/44: loss=1.3007 
[epoch 11] step 36/44: loss=1.2962 
[epoch 11] step 38/44: loss=1.2834 
[epoch 11] step 40/44: loss=1.2737 
[epoch 11] step 42/44: loss=1.2643 
[epoch 11] step 44/44: loss=1.2290 
[epoch 11] train_loss(avg per step)=2.4580 lambda[min,max]=[0.500005,1.000000]
[epoch 11] val_loss=4.7864 qwk=('0.4700', '0.4152', '0.3944') averageQWK=0.4266 macroEMD=0.3124 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    4   32    5    0
     0    3   67   52    0
     0    0   26  115    0
     0    0    2   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    1    0
     0    3   34    2    0
     0    4   74   26    0
     0    0   62  101    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   48    2    1
     0    4  114   40    0
     0    0   38   72    0
     0    0    0    3    0
[epoch 12] step 2/44: loss=0.9946 
[epoch 12] step 4/44: loss=1.0962 
[epoch 12] step 6/44: loss=1.0840 
[epoch 12] step 8/44: loss=1.1137 
[epoch 12] step 10/44: loss=1.0896 
[epoch 12] step 12/44: loss=1.0478 
[epoch 12] step 14/44: loss=1.0212 
[epoch 12] step 16/44: loss=1.0251 
[epoch 12] step 18/44: loss=1.0406 
[epoch 12] step 20/44: loss=1.0558 
[epoch 12] step 22/44: loss=1.0482 
[epoch 12] step 24/44: loss=1.0689 
[epoch 12] step 26/44: loss=1.0968 
[epoch 12] step 28/44: loss=1.1132 
[epoch 12] step 30/44: loss=1.1388 
[epoch 12] step 32/44: loss=1.1507 
[epoch 12] step 34/44: loss=1.1601 
[epoch 12] step 36/44: loss=1.1623 
[epoch 12] step 38/44: loss=1.1690 
[epoch 12] step 40/44: loss=1.1653 
[epoch 12] step 42/44: loss=1.1650 
[epoch 12] step 44/44: loss=1.1613 
[epoch 12] train_loss(avg per step)=2.3225 lambda[min,max]=[0.500024,1.000000]
[epoch 12] val_loss=4.4071 qwk=('0.5204', '0.5039', '0.3813') averageQWK=0.4685 macroEMD=0.3018 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    0    0
     0    7   33    1    0
     0    4   83   35    0
     0    0   38  103    0
     0    0    3   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    2    0
     0    7   31    1    0
     0   13   66   25    0
     0    0   51  112    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    8   44    0    0
     0   14  135    9    0
     0    3   64   43    0
     0    0    1    2    0
[epoch 13] step 2/44: loss=1.1414 
[epoch 13] step 4/44: loss=1.0983 
[epoch 13] step 6/44: loss=1.0819 
[epoch 13] step 8/44: loss=1.0815 
[epoch 13] step 10/44: loss=1.0599 
[epoch 13] step 12/44: loss=1.0341 
[epoch 13] step 14/44: loss=1.0416 
[epoch 13] step 16/44: loss=1.0749 
[epoch 13] step 18/44: loss=1.0557 
[epoch 13] step 20/44: loss=1.0553 
[epoch 13] step 22/44: loss=1.0529 
[epoch 13] step 24/44: loss=1.0468 
[epoch 13] step 26/44: loss=1.0478 
[epoch 13] step 28/44: loss=1.0485 
[epoch 13] step 30/44: loss=1.0349 
[epoch 13] step 32/44: loss=1.0357 
[epoch 13] step 34/44: loss=1.0333 
[epoch 13] step 36/44: loss=1.0338 
[epoch 13] step 38/44: loss=1.0189 
[epoch 13] step 40/44: loss=1.0143 
[epoch 13] step 42/44: loss=1.0229 
[epoch 13] step 44/44: loss=1.0246 
[epoch 13] train_loss(avg per step)=2.0492 lambda[min,max]=[0.500005,1.000000]
[epoch 13] val_loss=5.3629 qwk=('0.4326', '0.4101', '0.3670') averageQWK=0.4032 macroEMD=0.3103 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    3    0
     0    4   30    7    0
     0    2   51   69    0
     0    0   17  123    1
     0    0    1   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    4   23   12    0
     0    7   39   58    0
     0    0   20  142    1
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   49    1    1
     0    1  131   26    0
     0    0   51   59    0
     0    0    0    3    0
[epoch 14] step 2/44: loss=0.9124 
[epoch 14] step 4/44: loss=0.9730 
[epoch 14] step 6/44: loss=1.0259 
[epoch 14] step 8/44: loss=0.9731 
[epoch 14] step 10/44: loss=0.9384 
[epoch 14] step 12/44: loss=0.9375 
[epoch 14] step 14/44: loss=0.9324 
[epoch 14] step 16/44: loss=0.9541 
[epoch 14] step 18/44: loss=0.9614 
[epoch 14] step 20/44: loss=0.9343 
[epoch 14] step 22/44: loss=0.9054 
[epoch 14] step 24/44: loss=0.9231 
[epoch 14] step 26/44: loss=0.9319 
[epoch 14] step 28/44: loss=0.9279 
[epoch 14] step 30/44: loss=0.9246 
[epoch 14] step 32/44: loss=0.9243 
[epoch 14] step 34/44: loss=0.9195 
[epoch 14] step 36/44: loss=0.9200 
[epoch 14] step 38/44: loss=0.9207 
[epoch 14] step 40/44: loss=0.9183 
[epoch 14] step 42/44: loss=0.9121 
[epoch 14] step 44/44: loss=0.9049 
[epoch 14] train_loss(avg per step)=1.8097 lambda[min,max]=[0.500001,1.000000]
[epoch 14] val_loss=5.1293 qwk=('0.4497', '0.3992', '0.4488') averageQWK=0.4326 macroEMD=0.3011 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    5   29    7    0
     0    3   53   66    0
     0    0   16  125    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    2   24   13    0
     0    4   48   52    0
     0    0   22  140    1
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    3   47    2    0
     0    8  109   41    0
     0    0   31   79    0
     0    0    0    3    0
[epoch 15] step 2/44: loss=0.7962 
[epoch 15] step 4/44: loss=0.7683 
[epoch 15] step 6/44: loss=0.7816 
[epoch 15] step 8/44: loss=0.7881 
[epoch 15] step 10/44: loss=0.8050 
[epoch 15] step 12/44: loss=0.8076 
[epoch 15] step 14/44: loss=0.8107 
[epoch 15] step 16/44: loss=0.7981 
[epoch 15] step 18/44: loss=0.8030 
[epoch 15] step 20/44: loss=0.7805 
[epoch 15] step 22/44: loss=0.8070 
[epoch 15] step 24/44: loss=0.8116 
[epoch 15] step 26/44: loss=0.7903 
[epoch 15] step 28/44: loss=0.7796 
[epoch 15] step 30/44: loss=0.7693 
[epoch 15] step 32/44: loss=0.7575 
[epoch 15] step 34/44: loss=0.7518 
[epoch 15] step 36/44: loss=0.7474 
[epoch 15] step 38/44: loss=0.7434 
[epoch 15] step 40/44: loss=0.7394 
[epoch 15] step 42/44: loss=0.7267 
[epoch 15] step 44/44: loss=0.7261 
[epoch 15] train_loss(avg per step)=1.4523 lambda[min,max]=[0.500004,1.000000]
[epoch 15] val_loss=5.1637 qwk=('0.4710', '0.4224', '0.4488') averageQWK=0.4474 macroEMD=0.2972 tailR0=('0.0952', '0.0000', '0.0000') tailR0avg=0.0317
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    3   38    0    0
     0    2   83   37    0
     0    0   43   98    0
     0    0    5   12    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    3   29    7    0
     0    3   55   46    0
     0    0   33  129    1
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    5   46    1    0
     0   10  121   27    0
     0    2   43   65    0
     0    0    0    3    0
[epoch 16] step 2/44: loss=0.6177 
[epoch 16] step 4/44: loss=0.6674 
[epoch 16] step 6/44: loss=0.6739 
[epoch 16] step 8/44: loss=0.6610 
[epoch 16] step 10/44: loss=0.6397 
[epoch 16] step 12/44: loss=0.6660 
[epoch 16] step 14/44: loss=0.6381 
[epoch 16] step 16/44: loss=0.6529 
[epoch 16] step 18/44: loss=0.6455 
[epoch 16] step 20/44: loss=0.6594 
[epoch 16] step 22/44: loss=0.6647 
[epoch 16] step 24/44: loss=0.6412 
[epoch 16] step 26/44: loss=0.6527 
[epoch 16] step 28/44: loss=0.6321 
[epoch 16] step 30/44: loss=0.6463 
[epoch 16] step 32/44: loss=0.6484 
[epoch 16] step 34/44: loss=0.6471 
[epoch 16] step 36/44: loss=0.6245 
[epoch 16] step 38/44: loss=0.6209 
[epoch 16] step 40/44: loss=0.6176 
[epoch 16] step 42/44: loss=0.6254 
[epoch 16] step 44/44: loss=0.5986 
[epoch 16] train_loss(avg per step)=1.1971 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=5.1819 qwk=('0.5279', '0.4618', '0.4534') averageQWK=0.4810 macroEMD=0.2930 tailR0=('0.1667', '0.0938', '0.0000') tailR0avg=0.0868
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0    8   27    6    0
     0    5   59   57    1
     0    0   22  113    6
     0    0    0   14    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    5   30    4    0
     0    8   56   40    0
     0    0   43  118    2
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    6   44    2    0
     0    9  114   35    0
     0    3   33   74    0
     0    0    0    3    0
[epoch 17] step 2/44: loss=0.4713 
[epoch 17] step 4/44: loss=0.5051 
[epoch 17] step 6/44: loss=0.5505 
[epoch 17] step 8/44: loss=0.5178 
[epoch 17] step 10/44: loss=0.5300 
[epoch 17] step 12/44: loss=0.5559 
[epoch 17] step 14/44: loss=0.5581 
[epoch 17] step 16/44: loss=0.5632 
[epoch 17] step 18/44: loss=0.5502 
[epoch 17] step 20/44: loss=0.5450 
[epoch 17] step 22/44: loss=0.5215 
[epoch 17] step 24/44: loss=0.5040 
[epoch 17] step 26/44: loss=0.4923 
[epoch 17] step 28/44: loss=0.4917 
[epoch 17] step 30/44: loss=0.4889 
[epoch 17] step 32/44: loss=0.4875 
[epoch 17] step 34/44: loss=0.4814 
[epoch 17] step 36/44: loss=0.4739 
[epoch 17] step 38/44: loss=0.4777 
[epoch 17] step 40/44: loss=0.4776 
[epoch 17] step 42/44: loss=0.4745 
[epoch 17] step 44/44: loss=0.4574 
[epoch 17] train_loss(avg per step)=0.9148 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=6.2190 qwk=('0.4574', '0.4242', '0.3840') averageQWK=0.4219 macroEMD=0.2986 tailR0=('0.2381', '0.1250', '0.0000') tailR0avg=0.1210
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    3    0
     0    7   25    8    1
     0    4   46   67    5
     0    0   14  115   12
     0    0    0   11   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    4   21   14    0
     0    8   41   54    1
     0    0   27  131    5
     0    0    0   12    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    1   45    5    1
     0    2   97   59    0
     0    0   26   84    0
     0    0    0    3    0
[epoch 18] step 2/44: loss=0.6823 
[epoch 18] step 4/44: loss=0.6341 
[epoch 18] step 6/44: loss=0.5659 
[epoch 18] step 8/44: loss=0.5037 
[epoch 18] step 10/44: loss=0.4887 
[epoch 18] step 12/44: loss=0.4950 
[epoch 18] step 14/44: loss=0.4520 
[epoch 18] step 16/44: loss=0.4411 
[epoch 18] step 18/44: loss=0.4361 
[epoch 18] step 20/44: loss=0.4283 
[epoch 18] step 22/44: loss=0.4268 
[epoch 18] step 24/44: loss=0.4144 
[epoch 18] step 26/44: loss=0.4109 
[epoch 18] step 28/44: loss=0.4023 
[epoch 18] step 30/44: loss=0.3905 
[epoch 18] step 32/44: loss=0.3811 
[epoch 18] step 34/44: loss=0.3681 
[epoch 18] step 36/44: loss=0.3611 
[epoch 18] step 38/44: loss=0.3603 
[epoch 18] step 40/44: loss=0.3656 
[epoch 18] step 42/44: loss=0.3570 
[epoch 18] step 44/44: loss=0.3376 
[epoch 18] train_loss(avg per step)=0.6752 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=6.0288 qwk=('0.4778', '0.4303', '0.3936') averageQWK=0.4339 macroEMD=0.2897 tailR0=('0.1429', '0.0938', '0.0000') tailR0avg=0.0789
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     1    4   30    6    0
     0    2   58   61    1
     0    0   22  117    2
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    2    0
     0    5   27    7    0
     0    7   56   41    0
     0    0   49  113    1
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    5   46    1    0
     1    6  122   29    0
     0    0   49   61    0
     0    0    0    3    0
[epoch 19] step 2/44: loss=0.1489 
[epoch 19] step 4/44: loss=0.1081 
[epoch 19] step 6/44: loss=0.1761 
[epoch 19] step 8/44: loss=0.2114 
[epoch 19] step 10/44: loss=0.2245 
[epoch 19] step 12/44: loss=0.2011 
[epoch 19] step 14/44: loss=0.1983 
[epoch 19] step 16/44: loss=0.1890 
[epoch 19] step 18/44: loss=0.1874 
[epoch 19] step 20/44: loss=0.1995 
[epoch 19] step 22/44: loss=0.2005 
[epoch 19] step 24/44: loss=0.2162 
[epoch 19] step 26/44: loss=0.2187 
[epoch 19] step 28/44: loss=0.2160 
[epoch 19] step 30/44: loss=0.2140 
[epoch 19] step 32/44: loss=0.2108 
[epoch 19] step 34/44: loss=0.2114 
[epoch 19] step 36/44: loss=0.2086 
[epoch 19] step 38/44: loss=0.2122 
[epoch 19] step 40/44: loss=0.2251 
[epoch 19] step 42/44: loss=0.2258 
[epoch 19] step 44/44: loss=0.2486 
[epoch 19] train_loss(avg per step)=0.4973 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=6.5455 qwk=('0.5122', '0.4448', '0.3000') averageQWK=0.4190 macroEMD=0.2875 tailR0=('0.2167', '0.0625', '0.0000') tailR0avg=0.0931
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    1    0
     2    3   35    1    0
     0    2   83   36    1
     0    0   40   89   12
     0    0    6    8    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    2    0
     0    8   24    7    0
     0    9   67   27    1
     0    4   45  111    3
     0    0    3   11    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    9   42    1    0
     0   11  140    7    0
     0    2   76   31    1
     0    0    2    1    0
[epoch 20] step 2/44: loss=0.1898 
[epoch 20] step 4/44: loss=0.1976 
[epoch 20] step 6/44: loss=0.1907 
[epoch 20] step 8/44: loss=0.1695 
[epoch 20] step 10/44: loss=0.1912 
[epoch 20] step 12/44: loss=0.2003 
[epoch 20] step 14/44: loss=0.2147 
[epoch 20] step 16/44: loss=0.2041 
[epoch 20] step 18/44: loss=0.1765 
[epoch 20] step 20/44: loss=0.1758 
[epoch 20] step 22/44: loss=0.1733 
[epoch 20] step 24/44: loss=0.1827 
[epoch 20] step 26/44: loss=0.1729 
[epoch 20] step 28/44: loss=0.1652 
[epoch 20] step 30/44: loss=0.1646 
[epoch 20] step 32/44: loss=0.1691 
[epoch 20] step 34/44: loss=0.1701 
[epoch 20] step 36/44: loss=0.1720 
[epoch 20] step 38/44: loss=0.1685 
[epoch 20] step 40/44: loss=0.1623 
[epoch 20] step 42/44: loss=0.1640 
[epoch 20] step 44/44: loss=0.1537 
[epoch 20] train_loss(avg per step)=0.3074 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=6.3928 qwk=('0.5233', '0.4406', '0.4187') averageQWK=0.4608 macroEMD=0.2845 tailR0=('0.2405', '0.0312', '0.0000') tailR0avg=0.0906
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    6    1    0
     2    8   28    2    1
     0   11   65   44    2
     0    4   27  101    9
     0    0    3   10    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    2    0
     0    9   21    9    0
     0   11   49   44    0
     0    5   34  124    0
     0    0    3   12    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    5   42    5    0
     1    8  112   37    0
     0    1   33   76    0
     0    0    0    3    0
[epoch 21] step 2/44: loss=0.0708 
[epoch 21] step 4/44: loss=0.0676 
[epoch 21] step 6/44: loss=0.0534 
[epoch 21] step 8/44: loss=0.0503 
[epoch 21] step 10/44: loss=0.0660 
[epoch 21] step 12/44: loss=0.0530 
[epoch 21] step 14/44: loss=0.0382 
[epoch 21] step 16/44: loss=0.0352 
[epoch 21] step 18/44: loss=0.0620 
[epoch 21] step 20/44: loss=0.0759 
[epoch 21] step 22/44: loss=0.0719 
[epoch 21] step 24/44: loss=0.0618 
[epoch 21] step 26/44: loss=0.0451 
[epoch 21] step 28/44: loss=0.0413 
[epoch 21] step 30/44: loss=0.0438 
[epoch 21] step 32/44: loss=0.0491 
[epoch 21] step 34/44: loss=0.0417 
[epoch 21] step 36/44: loss=0.0447 
[epoch 21] step 38/44: loss=0.0483 
[epoch 21] step 40/44: loss=0.0497 
[epoch 21] step 42/44: loss=0.0448 
[epoch 21] step 44/44: loss=0.0383 
[epoch 21] train_loss(avg per step)=0.0765 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=7.1984 qwk=('0.4990', '0.4067', '0.3401') averageQWK=0.4153 macroEMD=0.2884 tailR0=('0.2881', '0.0000', '0.0000') tailR0avg=0.0960
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    3   28    7    1
     0    3   57   60    2
     0    0   19  111   11
     0    0    1   10   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    5   24   10    0
     0    3   52   47    2
     0    1   34  125    3
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    4   45    2    1
     0    5  129   24    0
     0    0   59   50    1
     0    0    0    3    0
[epoch 22] step 2/44: loss=-0.0558 
[epoch 22] step 4/44: loss=-0.0265 
[epoch 22] step 6/44: loss=-0.0049 
[epoch 22] step 8/44: loss=-0.0199 
[epoch 22] step 10/44: loss=0.0023 
[epoch 22] step 12/44: loss=-0.0183 
[epoch 22] step 14/44: loss=-0.0294 
[epoch 22] step 16/44: loss=-0.0431 
[epoch 22] step 18/44: loss=-0.0444 
[epoch 22] step 20/44: loss=-0.0384 
[epoch 22] step 22/44: loss=-0.0325 
[epoch 22] step 24/44: loss=-0.0337 
[epoch 22] step 26/44: loss=-0.0355 
[epoch 22] step 28/44: loss=-0.0336 
[epoch 22] step 30/44: loss=-0.0326 
[epoch 22] step 32/44: loss=-0.0263 
[epoch 22] step 34/44: loss=-0.0096 
[epoch 22] step 36/44: loss=-0.0092 
[epoch 22] step 38/44: loss=-0.0069 
[epoch 22] step 40/44: loss=-0.0091 
[epoch 22] step 42/44: loss=-0.0071 
[epoch 22] step 44/44: loss=-0.0082 
[epoch 22] train_loss(avg per step)=-0.0164 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=7.0641 qwk=('0.5238', '0.4487', '0.3877') averageQWK=0.4534 macroEMD=0.2793 tailR0=('0.2143', '0.0312', '0.0000') tailR0avg=0.0818
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     2    4   34    1    0
     0    4   78   39    1
     0    0   35   98    8
     0    0    5    7    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    4    2    0
     0    8   19   12    0
     0   11   42   51    0
     0    5   23  132    3
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    7   40    5    0
     1    8  108   41    0
     0    3   36   71    0
     0    0    0    3    0
[epoch 23] step 2/44: loss=-0.1239 
[epoch 23] step 4/44: loss=-0.1228 
[epoch 23] step 6/44: loss=-0.1226 
[epoch 23] step 8/44: loss=-0.0846 
[epoch 23] step 10/44: loss=-0.0745 
[epoch 23] step 12/44: loss=-0.0827 
[epoch 23] step 14/44: loss=-0.0908 
[epoch 23] step 16/44: loss=-0.0798 
[epoch 23] step 18/44: loss=-0.0844 
[epoch 23] step 20/44: loss=-0.0871 
[epoch 23] step 22/44: loss=-0.0773 
[epoch 23] step 24/44: loss=-0.0737 
[epoch 23] step 26/44: loss=-0.0775 
[epoch 23] step 28/44: loss=-0.0738 
[epoch 23] step 30/44: loss=-0.0726 
[epoch 23] step 32/44: loss=-0.0814 
[epoch 23] step 34/44: loss=-0.0858 
[epoch 23] step 36/44: loss=-0.0930 
[epoch 23] step 38/44: loss=-0.0943 
[epoch 23] step 40/44: loss=-0.0990 
[epoch 23] step 42/44: loss=-0.0927 
[epoch 23] step 44/44: loss=-0.1009 
[epoch 23] train_loss(avg per step)=-0.2019 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=7.3871 qwk=('0.5260', '0.4603', '0.3590') averageQWK=0.4484 macroEMD=0.2772 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     2    6   31    2    0
     0    5   79   38    0
     0    0   35  101    5
     0    0    4   11    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    2    0
     0    6   27    6    0
     0    5   61   38    0
     0    1   40  121    1
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    4   45    2    1
     1    5  135   16    1
     0    0   56   53    1
     0    0    0    3    0
[epoch 24] step 2/44: loss=-0.1341 
[epoch 24] step 4/44: loss=-0.1297 
[epoch 24] step 6/44: loss=-0.1445 
[epoch 24] step 8/44: loss=-0.1586 
[epoch 24] step 10/44: loss=-0.1640 
[epoch 24] step 12/44: loss=-0.1530 
[epoch 24] step 14/44: loss=-0.1539 
[epoch 24] step 16/44: loss=-0.1468 
[epoch 24] step 18/44: loss=-0.1290 
[epoch 24] step 20/44: loss=-0.1258 
[epoch 24] step 22/44: loss=-0.1314 
[epoch 24] step 24/44: loss=-0.1345 
[epoch 24] step 26/44: loss=-0.1311 
[epoch 24] step 28/44: loss=-0.1412 
[epoch 24] step 30/44: loss=-0.1441 
[epoch 24] step 32/44: loss=-0.1433 
[epoch 24] step 34/44: loss=-0.1485 
[epoch 24] step 36/44: loss=-0.1431 
[epoch 24] step 38/44: loss=-0.1436 
[epoch 24] step 40/44: loss=-0.1417 
[epoch 24] step 42/44: loss=-0.1393 
[epoch 24] step 44/44: loss=-0.1465 
[epoch 24] train_loss(avg per step)=-0.2930 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=8.0460 qwk=('0.5376', '0.4434', '0.3874') averageQWK=0.4561 macroEMD=0.2789 tailR0=('0.2643', '0.0625', '0.0000') tailR0avg=0.1089
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    4   32    3    0
     1    2   71   46    2
     0    0   27   98   16
     0    0    2   10    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    2    0
     0    5   27    7    0
     0    3   59   42    0
     0    0   35  125    3
     0    0    3   11    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    6   43    2    1
     1    8  116   33    0
     0    3   39   68    0
     0    0    0    3    0
[epoch 25] step 2/44: loss=-0.0344 
[epoch 25] step 4/44: loss=-0.0984 
[epoch 25] step 6/44: loss=-0.1277 
[epoch 25] step 8/44: loss=-0.1590 
[epoch 25] step 10/44: loss=-0.1571 
[epoch 25] step 12/44: loss=-0.1638 
[epoch 25] step 14/44: loss=-0.1546 
[epoch 25] step 16/44: loss=-0.1583 
[epoch 25] step 18/44: loss=-0.1644 
[epoch 25] step 20/44: loss=-0.1701 
[epoch 25] step 22/44: loss=-0.1795 
[epoch 25] step 24/44: loss=-0.1766 
[epoch 25] step 26/44: loss=-0.1726 
[epoch 25] step 28/44: loss=-0.1737 
[epoch 25] step 30/44: loss=-0.1735 
[epoch 25] step 32/44: loss=-0.1758 
[epoch 25] step 34/44: loss=-0.1732 
[epoch 25] step 36/44: loss=-0.1746 
[epoch 25] step 38/44: loss=-0.1710 
[epoch 25] step 40/44: loss=-0.1722 
[epoch 25] step 42/44: loss=-0.1701 
[epoch 25] step 44/44: loss=-0.1573 
[epoch 25] train_loss(avg per step)=-0.3146 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=8.4026 qwk=('0.4964', '0.4170', '0.3341') averageQWK=0.4158 macroEMD=0.2796 tailR0=('0.1905', '0.0625', '0.0000') tailR0avg=0.0843
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     2    4   29    5    1
     0    6   59   56    1
     0    0   25  109    7
     0    0    1   12    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    9    2    0
     0    5   30    4    0
     0    5   71   27    1
     0    1   55  106    1
     0    0    4   10    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   48    2    1
     0    2  137   19    0
     0    0   58   52    0
     0    0    0    3    0
[epoch 26] step 2/44: loss=-0.2353 
[epoch 26] step 4/44: loss=-0.2337 
[epoch 26] step 6/44: loss=-0.2141 
[epoch 26] step 8/44: loss=-0.2102 
[epoch 26] step 10/44: loss=-0.2137 
[epoch 26] step 12/44: loss=-0.2009 
[epoch 26] step 14/44: loss=-0.1855 
[epoch 26] step 16/44: loss=-0.1803 
[epoch 26] step 18/44: loss=-0.1852 
[epoch 26] step 20/44: loss=-0.1848 
[epoch 26] step 22/44: loss=-0.1860 
[epoch 26] step 24/44: loss=-0.1892 
[epoch 26] step 26/44: loss=-0.1909 
[epoch 26] step 28/44: loss=-0.1854 
[epoch 26] step 30/44: loss=-0.1901 
[epoch 26] step 32/44: loss=-0.1870 
[epoch 26] step 34/44: loss=-0.1886 
[epoch 26] step 36/44: loss=-0.1887 
[epoch 26] step 38/44: loss=-0.1869 
[epoch 26] step 40/44: loss=-0.1911 
[epoch 26] step 42/44: loss=-0.1923 
[epoch 26] step 44/44: loss=-0.1956 
[epoch 26] train_loss(avg per step)=-0.3912 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=9.1974 qwk=('0.4804', '0.3785', '0.3506') averageQWK=0.4032 macroEMD=0.2771 tailR0=('0.1905', '0.0000', '0.0000') tailR0avg=0.0635
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     2    6   23    9    1
     0    5   40   76    1
     0    1   13  118    9
     0    0    0   13    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    5   20   14    0
     0    5   45   54    0
     0    2   23  136    2
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    5   44    2    1
     0    7  123   28    0
     0    2   51   57    0
     0    0    0    3    0
[epoch 27] step 2/44: loss=-0.2591 
[epoch 27] step 4/44: loss=-0.2209 
[epoch 27] step 6/44: loss=-0.2164 
[epoch 27] step 8/44: loss=-0.2312 
[epoch 27] step 10/44: loss=-0.2260 
[epoch 27] step 12/44: loss=-0.2216 
[epoch 27] step 14/44: loss=-0.2228 
[epoch 27] step 16/44: loss=-0.2109 
[epoch 27] step 18/44: loss=-0.2060 
[epoch 27] step 20/44: loss=-0.2093 
[epoch 27] step 22/44: loss=-0.2085 
[epoch 27] step 24/44: loss=-0.2058 
[epoch 27] step 26/44: loss=-0.2048 
[epoch 27] step 28/44: loss=-0.2065 
[epoch 27] step 30/44: loss=-0.2117 
[epoch 27] step 32/44: loss=-0.2114 
[epoch 27] step 34/44: loss=-0.2084 
[epoch 27] step 36/44: loss=-0.2111 
[epoch 27] step 38/44: loss=-0.2103 
[epoch 27] step 40/44: loss=-0.2131 
[epoch 27] step 42/44: loss=-0.2173 
[epoch 27] step 44/44: loss=-0.2206 
[epoch 27] train_loss(avg per step)=-0.4413 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=8.5465 qwk=('0.5207', '0.4364', '0.3384') averageQWK=0.4318 macroEMD=0.2789 tailR0=('0.2381', '0.0938', '0.0000') tailR0avg=0.1106
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     2    4   32    3    0
     0    3   72   44    3
     0    0   30  101   10
     0    0    3    8   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    3    0
     0    7   27    5    0
     0    5   57   39    3
     0    2   38  116    7
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   43    6    1
     1    3  114   40    0
     0    0   44   66    0
     0    0    0    3    0
[epoch 28] step 2/44: loss=-0.2534 
[epoch 28] step 4/44: loss=-0.2590 
[epoch 28] step 6/44: loss=-0.2622 
[epoch 28] step 8/44: loss=-0.2643 
[epoch 28] step 10/44: loss=-0.2528 
[epoch 28] step 12/44: loss=-0.2540 
[epoch 28] step 14/44: loss=-0.2507 
[epoch 28] step 16/44: loss=-0.2459 
[epoch 28] step 18/44: loss=-0.2484 
[epoch 28] step 20/44: loss=-0.2531 
[epoch 28] step 22/44: loss=-0.2561 
[epoch 28] step 24/44: loss=-0.2468 
[epoch 28] step 26/44: loss=-0.2463 
[epoch 28] step 28/44: loss=-0.2491 
[epoch 28] step 30/44: loss=-0.2491 
[epoch 28] step 32/44: loss=-0.2480 
[epoch 28] step 34/44: loss=-0.2505 
[epoch 28] step 36/44: loss=-0.2503 
[epoch 28] step 38/44: loss=-0.2516 
[epoch 28] step 40/44: loss=-0.2536 
[epoch 28] step 42/44: loss=-0.2551 
[epoch 28] step 44/44: loss=-0.2581 
[epoch 28] train_loss(avg per step)=-0.5162 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=9.0011 qwk=('0.5012', '0.4483', '0.3804') averageQWK=0.4433 macroEMD=0.2713 tailR0=('0.2405', '0.0000', '0.0000') tailR0avg=0.0802
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    4   31    4    0
     0    4   71   44    3
     0    0   31   98   12
     0    0    4    9    8
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    6   26    7    0
     0    6   57   40    1
     0    1   31  128    3
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   46    4    1
     0    4  115   39    0
     0    0   38   72    0
     0    0    0    3    0
[epoch 29] step 2/44: loss=-0.3090 
[epoch 29] step 4/44: loss=-0.2829 
[epoch 29] step 6/44: loss=-0.2796 
[epoch 29] step 8/44: loss=-0.2741 
[epoch 29] step 10/44: loss=-0.2689 
[epoch 29] step 12/44: loss=-0.2625 
[epoch 29] step 14/44: loss=-0.2621 
[epoch 29] step 16/44: loss=-0.2640 
[epoch 29] step 18/44: loss=-0.2661 
[epoch 29] step 20/44: loss=-0.2697 
[epoch 29] step 22/44: loss=-0.2678 
[epoch 29] step 24/44: loss=-0.2705 
[epoch 29] step 26/44: loss=-0.2731 
[epoch 29] step 28/44: loss=-0.2747 
[epoch 29] step 30/44: loss=-0.2738 
[epoch 29] step 32/44: loss=-0.2722 
[epoch 29] step 34/44: loss=-0.2713 
[epoch 29] step 36/44: loss=-0.2733 
[epoch 29] step 38/44: loss=-0.2722 
[epoch 29] step 40/44: loss=-0.2730 
[epoch 29] step 42/44: loss=-0.2729 
[epoch 29] step 44/44: loss=-0.2758 
[epoch 29] train_loss(avg per step)=-0.5517 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=9.3258 qwk=('0.5105', '0.4014', '0.3797') averageQWK=0.4306 macroEMD=0.2738 tailR0=('0.3119', '0.0938', '0.0000') tailR0avg=0.1352
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    4   29    6    0
     0    4   56   58    4
     0    0   23  107   11
     0    0    1    9   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     0    5   21   13    0
     0    7   44   51    2
     0    2   26  130    5
     0    0    2   11    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   45    5    1
     1    5  109   43    0
     0    0   34   76    0
     0    0    0    3    0
[epoch 30] step 2/44: loss=-0.3072 
[epoch 30] step 4/44: loss=-0.3119 
[epoch 30] step 6/44: loss=-0.2987 
[epoch 30] step 8/44: loss=-0.2965 
[epoch 30] step 10/44: loss=-0.2889 
[epoch 30] step 12/44: loss=-0.2907 
[epoch 30] step 14/44: loss=-0.2912 
[epoch 30] step 16/44: loss=-0.2918 
[epoch 30] step 18/44: loss=-0.2906 
[epoch 30] step 20/44: loss=-0.2870 
[epoch 30] step 22/44: loss=-0.2869 
[epoch 30] step 24/44: loss=-0.2857 
[epoch 30] step 26/44: loss=-0.2841 
[epoch 30] step 28/44: loss=-0.2855 
[epoch 30] step 30/44: loss=-0.2864 
[epoch 30] step 32/44: loss=-0.2882 
[epoch 30] step 34/44: loss=-0.2889 
[epoch 30] step 36/44: loss=-0.2883 
[epoch 30] step 38/44: loss=-0.2889 
[epoch 30] step 40/44: loss=-0.2899 
[epoch 30] step 42/44: loss=-0.2887 
[epoch 30] step 44/44: loss=-0.2897 
[epoch 30] train_loss(avg per step)=-0.5795 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=8.8857 qwk=('0.5663', '0.4683', '0.3878') averageQWK=0.4741 macroEMD=0.2666 tailR0=('0.3119', '0.0938', '0.0000') tailR0avg=0.1352
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    1    0
     2    5   31    3    0
     0    4   63   53    2
     0    0   25  102   14
     0    0    0   10   11
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    2    0
     0    7   26    6    0
     0   12   53   38    1
     0    3   37  118    5
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    4   42    5    1
     1    7  110   40    0
     0    1   34   75    0
     0    0    0    3    0
[epoch 31] step 2/44: loss=-0.2924 
[epoch 31] step 4/44: loss=-0.3013 
[epoch 31] step 6/44: loss=-0.3025 
[epoch 31] step 8/44: loss=-0.2973 
[epoch 31] step 10/44: loss=-0.2874 
[epoch 31] step 12/44: loss=-0.2830 
[epoch 31] step 14/44: loss=-0.2790 
[epoch 31] step 16/44: loss=-0.2799 
[epoch 31] step 18/44: loss=-0.2785 
[epoch 31] step 20/44: loss=-0.2818 
[epoch 31] step 22/44: loss=-0.2799 
[epoch 31] step 24/44: loss=-0.2796 
[epoch 31] step 26/44: loss=-0.2787 
[epoch 31] step 28/44: loss=-0.2791 
[epoch 31] step 30/44: loss=-0.2820 
[epoch 31] step 32/44: loss=-0.2833 
[epoch 31] step 34/44: loss=-0.2841 
[epoch 31] step 36/44: loss=-0.2857 
[epoch 31] step 38/44: loss=-0.2871 
[epoch 31] step 40/44: loss=-0.2885 
[epoch 31] step 42/44: loss=-0.2890 
[epoch 31] step 44/44: loss=-0.2900 
[epoch 31] train_loss(avg per step)=-0.5800 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=9.2203 qwk=('0.5075', '0.4562', '0.3787') averageQWK=0.4475 macroEMD=0.2697 tailR0=('0.2143', '0.0938', '0.0000') tailR0avg=0.1027
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     2    4   32    3    0
     0    1   71   46    4
     0    0   30   96   15
     0    0    3    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    5   28    6    0
     0    3   60   40    1
     0    1   35  124    3
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   47    3    1
     0    5  117   36    0
     0    0   41   69    0
     0    0    0    3    0
[epoch 32] step 2/44: loss=-0.2718 
[epoch 32] step 4/44: loss=-0.2831 
[epoch 32] step 6/44: loss=-0.2834 
[epoch 32] step 8/44: loss=-0.2852 
[epoch 32] step 10/44: loss=-0.2883 
[epoch 32] step 12/44: loss=-0.2930 
[epoch 32] step 14/44: loss=-0.2931 
[epoch 32] step 16/44: loss=-0.2900 
[epoch 32] step 18/44: loss=-0.2909 
[epoch 32] step 20/44: loss=-0.2934 
[epoch 32] step 22/44: loss=-0.2909 
[epoch 32] step 24/44: loss=-0.2895 
[epoch 32] step 26/44: loss=-0.2920 
[epoch 32] step 28/44: loss=-0.2943 
[epoch 32] step 30/44: loss=-0.2960 
[epoch 32] step 32/44: loss=-0.2971 
[epoch 32] step 34/44: loss=-0.2979 
[epoch 32] step 36/44: loss=-0.2983 
[epoch 32] step 38/44: loss=-0.2971 
[epoch 32] step 40/44: loss=-0.2976 
[epoch 32] step 42/44: loss=-0.2986 
[epoch 32] step 44/44: loss=-0.2991 
[epoch 32] train_loss(avg per step)=-0.5983 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=8.9826 qwk=('0.5359', '0.4865', '0.3597') averageQWK=0.4607 macroEMD=0.2712 tailR0=('0.2881', '0.0938', '0.0000') tailR0avg=0.1273
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    1    0
     2    5   31    3    0
     0    3   69   47    3
     0    0   29   95   17
     0    0    2    9   10
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    2    0
     0    7   25    7    0
     0    6   57   41    0
     0    1   37  122    3
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    3   45    3    1
     1    7  117   33    0
     0    1   45   64    0
     0    0    0    3    0
[epoch 33] step 2/44: loss=-0.3299 
[epoch 33] step 4/44: loss=-0.3176 
[epoch 33] step 6/44: loss=-0.3098 
[epoch 33] step 8/44: loss=-0.3041 
[epoch 33] step 10/44: loss=-0.3055 
[epoch 33] step 12/44: loss=-0.3016 
[epoch 33] step 14/44: loss=-0.2992 
[epoch 33] step 16/44: loss=-0.3004 
[epoch 33] step 18/44: loss=-0.3026 
[epoch 33] step 20/44: loss=-0.3032 
[epoch 33] step 22/44: loss=-0.3002 
[epoch 33] step 24/44: loss=-0.3030 
[epoch 33] step 26/44: loss=-0.3049 
[epoch 33] step 28/44: loss=-0.3063 
[epoch 33] step 30/44: loss=-0.3064 
[epoch 33] step 32/44: loss=-0.3077 
[epoch 33] step 34/44: loss=-0.3042 
[epoch 33] step 36/44: loss=-0.3045 
[epoch 33] step 38/44: loss=-0.3036 
[epoch 33] step 40/44: loss=-0.3032 
[epoch 33] step 42/44: loss=-0.3038 
[epoch 33] step 44/44: loss=-0.3054 
[epoch 33] train_loss(avg per step)=-0.6108 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=9.1445 qwk=('0.5291', '0.4328', '0.3897') averageQWK=0.4505 macroEMD=0.2669 tailR0=('0.2143', '0.0938', '0.0000') tailR0avg=0.1027
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     2    6   30    3    0
     0    5   68   46    3
     0    0   30   96   15
     0    0    3    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    5    3    0
     0    6   23   10    0
     0   10   46   48    0
     0    2   31  127    3
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    6   42    3    1
     0    6  119   33    0
     0    1   43   66    0
     0    0    0    3    0
[epoch 34] step 2/44: loss=-0.3224 
[epoch 34] step 4/44: loss=-0.3136 
[epoch 34] step 6/44: loss=-0.2998 
[epoch 34] step 8/44: loss=-0.3016 
[epoch 34] step 10/44: loss=-0.3062 
[epoch 34] step 12/44: loss=-0.3095 
[epoch 34] step 14/44: loss=-0.3059 
[epoch 34] step 16/44: loss=-0.3081 
[epoch 34] step 18/44: loss=-0.3115 
[epoch 34] step 20/44: loss=-0.3124 
[epoch 34] step 22/44: loss=-0.3136 
[epoch 34] step 24/44: loss=-0.3145 
[epoch 34] step 26/44: loss=-0.3160 
[epoch 34] step 28/44: loss=-0.3170 
[epoch 34] step 30/44: loss=-0.3180 
[epoch 34] step 32/44: loss=-0.3187 
[epoch 34] step 34/44: loss=-0.3186 
[epoch 34] step 36/44: loss=-0.3190 
[epoch 34] step 38/44: loss=-0.3175 
[epoch 34] step 40/44: loss=-0.3182 
[epoch 34] step 42/44: loss=-0.3177 
[epoch 34] step 44/44: loss=-0.3179 
[epoch 34] train_loss(avg per step)=-0.6358 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=9.3091 qwk=('0.5323', '0.4500', '0.3851') averageQWK=0.4558 macroEMD=0.2685 tailR0=('0.2143', '0.0938', '0.0000') tailR0avg=0.1027
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     2    6   30    3    0
     0    4   68   47    3
     0    0   28  100   13
     0    0    3    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    2    0
     0    5   26    8    0
     0    7   52   45    0
     0    1   34  125    3
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   46    3    1
     0    6  117   35    0
     0    0   41   69    0
     0    0    0    3    0
[epoch 35] step 2/44: loss=-0.3238 
[epoch 35] step 4/44: loss=-0.3104 
[epoch 35] step 6/44: loss=-0.3065 
[epoch 35] step 8/44: loss=-0.3033 
[epoch 35] step 10/44: loss=-0.3042 
[epoch 35] step 12/44: loss=-0.3082 
[epoch 35] step 14/44: loss=-0.3101 
[epoch 35] step 16/44: loss=-0.3125 
[epoch 35] step 18/44: loss=-0.3132 
[epoch 35] step 20/44: loss=-0.3144 
[epoch 35] step 22/44: loss=-0.3149 
[epoch 35] step 24/44: loss=-0.3163 
[epoch 35] step 26/44: loss=-0.3181 
[epoch 35] step 28/44: loss=-0.3175 
[epoch 35] step 30/44: loss=-0.3176 
[epoch 35] step 32/44: loss=-0.3185 
[epoch 35] step 34/44: loss=-0.3196 
[epoch 35] step 36/44: loss=-0.3197 
[epoch 35] step 38/44: loss=-0.3202 
[epoch 35] step 40/44: loss=-0.3209 
[epoch 35] step 42/44: loss=-0.3200 
[epoch 35] step 44/44: loss=-0.3191 
[epoch 35] train_loss(avg per step)=-0.6382 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=9.2896 qwk=('0.5237', '0.4521', '0.3524') averageQWK=0.4427 macroEMD=0.2696 tailR0=('0.2143', '0.0938', '0.0000') tailR0avg=0.1027
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     2    6   30    3    0
     0    4   68   47    3
     0    0   28  100   13
     0    0    3    9    9
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    2    0
     0    5   26    8    0
     0    7   53   44    0
     0    1   34  125    3
     0    0    3   10    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   46    3    1
     1    6  121   30    0
     0    0   49   61    0
     0    0    0    3    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-0/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-0/fold1/metrics.json
Done.
