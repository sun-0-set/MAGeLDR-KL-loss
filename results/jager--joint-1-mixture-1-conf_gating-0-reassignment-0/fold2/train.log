[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=7.2577 
[epoch 1] step 4/44: loss=7.1905 
[epoch 1] step 6/44: loss=7.2182 
[epoch 1] step 8/44: loss=7.3707 
[epoch 1] step 10/44: loss=7.4046 
[epoch 1] step 12/44: loss=7.3815 
[epoch 1] step 14/44: loss=7.4224 
[epoch 1] step 16/44: loss=7.4118 
[epoch 1] step 18/44: loss=7.4089 
[epoch 1] step 20/44: loss=7.4489 
[epoch 1] step 22/44: loss=7.4428 
[epoch 1] step 24/44: loss=7.4960 
[epoch 1] step 26/44: loss=7.4500 
[epoch 1] step 28/44: loss=7.3924 
[epoch 1] step 30/44: loss=7.3869 
[epoch 1] step 32/44: loss=7.3331 
[epoch 1] step 34/44: loss=7.2824 
[epoch 1] step 36/44: loss=7.2463 
[epoch 1] step 38/44: loss=7.1813 
[epoch 1] step 40/44: loss=7.1135 
[epoch 1] step 42/44: loss=7.0339 
[epoch 1] step 44/44: loss=6.9402 
[epoch 1] train_loss(avg per step)=13.8803 lambda[min,max]=[0.508652,1.000000]
[epoch 1] val_loss=10.1648 qwk=('-0.1288', '0.0026', '0.1227') averageQWK=-0.0011 macroEMD=0.3743 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    0    7    0
     0    7    0   91    0
     0   14    0  141    0
     0   19    0   40    0
     0    1    0    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    7    0
     6    0   44   32    0
    16    0   41  109    0
    13    0    6   42    0
     0    0    1    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0   31   63   10    0
     0   29  134   17    0
     0    4   25    7    0
     0    0    0    0    0
[epoch 2] step 2/44: loss=5.1102 
[epoch 2] step 4/44: loss=4.9074 
[epoch 2] step 6/44: loss=4.7838 
[epoch 2] step 8/44: loss=4.6367 
[epoch 2] step 10/44: loss=4.4890 
[epoch 2] step 12/44: loss=4.4233 
[epoch 2] step 14/44: loss=4.2983 
[epoch 2] step 16/44: loss=4.2352 
[epoch 2] step 18/44: loss=4.1628 
[epoch 2] step 20/44: loss=4.1031 
[epoch 2] step 22/44: loss=4.0473 
[epoch 2] step 24/44: loss=3.9891 
[epoch 2] step 26/44: loss=3.9403 
[epoch 2] step 28/44: loss=3.8835 
[epoch 2] step 30/44: loss=3.8437 
[epoch 2] step 32/44: loss=3.8020 
[epoch 2] step 34/44: loss=3.7539 
[epoch 2] step 36/44: loss=3.7416 
[epoch 2] step 38/44: loss=3.7056 
[epoch 2] step 40/44: loss=3.6667 
[epoch 2] step 42/44: loss=3.6391 
[epoch 2] step 44/44: loss=3.6016 
[epoch 2] train_loss(avg per step)=7.2033 lambda[min,max]=[0.516797,1.000000]
[epoch 2] val_loss=4.3045 qwk=('0.4047', '0.2338', '0.2040') averageQWK=0.2808 macroEMD=0.3731 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    4    0
     0   53   31   14    0
     0   43   65   47    0
     0    4   15   40    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    5    0
     0    0   63   19    0
     0    0   76   90    0
     0    0   10   51    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0    3   94    7    0
     0    3  147   30    0
     0    0   17   19    0
     0    0    0    0    0
[epoch 3] step 2/44: loss=2.8883 
[epoch 3] step 4/44: loss=2.8557 
[epoch 3] step 6/44: loss=2.8138 
[epoch 3] step 8/44: loss=2.8800 
[epoch 3] step 10/44: loss=2.8407 
[epoch 3] step 12/44: loss=2.8475 
[epoch 3] step 14/44: loss=2.8585 
[epoch 3] step 16/44: loss=2.7922 
[epoch 3] step 18/44: loss=2.7923 
[epoch 3] step 20/44: loss=2.7756 
[epoch 3] step 22/44: loss=2.7579 
[epoch 3] step 24/44: loss=2.7291 
[epoch 3] step 26/44: loss=2.7573 
[epoch 3] step 28/44: loss=2.7457 
[epoch 3] step 30/44: loss=2.7669 
[epoch 3] step 32/44: loss=2.7539 
[epoch 3] step 34/44: loss=2.7358 
[epoch 3] step 36/44: loss=2.7226 
[epoch 3] step 38/44: loss=2.7036 
[epoch 3] step 40/44: loss=2.7110 
[epoch 3] step 42/44: loss=2.7181 
[epoch 3] step 44/44: loss=2.7121 
[epoch 3] train_loss(avg per step)=5.4242 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=4.6556 qwk=('0.2692', '0.2437', '0.2459') averageQWK=0.2529 macroEMD=0.3610 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    4    0
     0   18   48   32    0
     0   17   60   78    0
     0    1    7   51    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    5    0
     0    0   62   20    0
     0    0   85   81    0
     0    0    7   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    1    0
     0    1   94    9    0
     0    2  135   43    0
     0    0   10   26    0
     0    0    0    0    0
[epoch 4] step 2/44: loss=2.5892 
[epoch 4] step 4/44: loss=2.4244 
[epoch 4] step 6/44: loss=2.4267 
[epoch 4] step 8/44: loss=2.3583 
[epoch 4] step 10/44: loss=2.3231 
[epoch 4] step 12/44: loss=2.3070 
[epoch 4] step 14/44: loss=2.2915 
[epoch 4] step 16/44: loss=2.2859 
[epoch 4] step 18/44: loss=2.2818 
[epoch 4] step 20/44: loss=2.2970 
[epoch 4] step 22/44: loss=2.2794 
[epoch 4] step 24/44: loss=2.2657 
[epoch 4] step 26/44: loss=2.2688 
[epoch 4] step 28/44: loss=2.2610 
[epoch 4] step 30/44: loss=2.2432 
[epoch 4] step 32/44: loss=2.2514 
[epoch 4] step 34/44: loss=2.2490 
[epoch 4] step 36/44: loss=2.2607 
[epoch 4] step 38/44: loss=2.2596 
[epoch 4] step 40/44: loss=2.2604 
[epoch 4] step 42/44: loss=2.2563 
[epoch 4] step 44/44: loss=2.2503 
[epoch 4] train_loss(avg per step)=4.5006 lambda[min,max]=[0.507904,1.000000]
[epoch 4] val_loss=4.6638 qwk=('0.3432', '0.2770', '0.2620') averageQWK=0.2941 macroEMD=0.3566 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    4    0
     0   50   18   29    1
     0   36   41   74    4
     0    2    8   49    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    4    0
     4    1   68    9    0
     1    1  118   46    0
     0    0   22   39    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   24   62   18    0
     0   22   86   72    0
     0    0   10   26    0
     0    0    0    0    0
[epoch 5] step 2/44: loss=1.9612 
[epoch 5] step 4/44: loss=2.0963 
[epoch 5] step 6/44: loss=2.1347 
[epoch 5] step 8/44: loss=2.1028 
[epoch 5] step 10/44: loss=2.1177 
[epoch 5] step 12/44: loss=2.1218 
[epoch 5] step 14/44: loss=2.1385 
[epoch 5] step 16/44: loss=2.1171 
[epoch 5] step 18/44: loss=2.1503 
[epoch 5] step 20/44: loss=2.1255 
[epoch 5] step 22/44: loss=2.1385 
[epoch 5] step 24/44: loss=2.1414 
[epoch 5] step 26/44: loss=2.1502 
[epoch 5] step 28/44: loss=2.1549 
[epoch 5] step 30/44: loss=2.1289 
[epoch 5] step 32/44: loss=2.1198 
[epoch 5] step 34/44: loss=2.1254 
[epoch 5] step 36/44: loss=2.1283 
[epoch 5] step 38/44: loss=2.1335 
[epoch 5] step 40/44: loss=2.1103 
[epoch 5] step 42/44: loss=2.1083 
[epoch 5] step 44/44: loss=2.1139 
[epoch 5] train_loss(avg per step)=4.2277 lambda[min,max]=[0.507560,1.000000]
[epoch 5] val_loss=4.8269 qwk=('0.2208', '0.1997', '0.2561') averageQWK=0.2255 macroEMD=0.3424 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     0    7   58   33    0
     0    5   76   74    0
     0    1    9   49    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    7    0
     0   12   26   44    0
     0    9   42  115    0
     0    0    0   61    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   21   80    3    0
     0   12  163    5    0
     0    0   26   10    0
     0    0    0    0    0
[epoch 6] step 2/44: loss=1.9701 
[epoch 6] step 4/44: loss=1.9326 
[epoch 6] step 6/44: loss=1.9830 
[epoch 6] step 8/44: loss=1.9683 
[epoch 6] step 10/44: loss=1.9272 
[epoch 6] step 12/44: loss=1.9444 
[epoch 6] step 14/44: loss=1.9510 
[epoch 6] step 16/44: loss=1.9520 
[epoch 6] step 18/44: loss=1.9337 
[epoch 6] step 20/44: loss=1.9419 
[epoch 6] step 22/44: loss=1.9422 
[epoch 6] step 24/44: loss=1.9432 
[epoch 6] step 26/44: loss=1.9577 
[epoch 6] step 28/44: loss=1.9457 
[epoch 6] step 30/44: loss=1.9480 
[epoch 6] step 32/44: loss=1.9443 
[epoch 6] step 34/44: loss=1.9486 
[epoch 6] step 36/44: loss=1.9306 
[epoch 6] step 38/44: loss=1.9326 
[epoch 6] step 40/44: loss=1.9267 
[epoch 6] step 42/44: loss=1.9363 
[epoch 6] step 44/44: loss=1.9220 
[epoch 6] train_loss(avg per step)=3.8440 lambda[min,max]=[0.501436,1.000000]
[epoch 6] val_loss=6.0905 qwk=('0.2324', '0.1866', '0.3565') averageQWK=0.2585 macroEMD=0.3324 tailR0=('0.0000', '0.0357', '0.0000') tailR0avg=0.0119
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    5    0
     0   37    4   57    0
     0   21   16  118    0
     0    1    1   57    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    5    8    0
     4    2   32   44    0
     1    1   45  119    0
     0    0    0   61    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   24   71    9    0
     0   15  113   52    0
     0    0    7   29    0
     0    0    0    0    0
[epoch 7] step 2/44: loss=2.0668 
[epoch 7] step 4/44: loss=1.8624 
[epoch 7] step 6/44: loss=1.9211 
[epoch 7] step 8/44: loss=1.9786 
[epoch 7] step 10/44: loss=1.9407 
[epoch 7] step 12/44: loss=1.9190 
[epoch 7] step 14/44: loss=1.8965 
[epoch 7] step 16/44: loss=1.8745 
[epoch 7] step 18/44: loss=1.8776 
[epoch 7] step 20/44: loss=1.8824 
[epoch 7] step 22/44: loss=1.8753 
[epoch 7] step 24/44: loss=1.8780 
[epoch 7] step 26/44: loss=1.8504 
[epoch 7] step 28/44: loss=1.8334 
[epoch 7] step 30/44: loss=1.8288 
[epoch 7] step 32/44: loss=1.8315 
[epoch 7] step 34/44: loss=1.8360 
[epoch 7] step 36/44: loss=1.8198 
[epoch 7] step 38/44: loss=1.8213 
[epoch 7] step 40/44: loss=1.8177 
[epoch 7] step 42/44: loss=1.8060 
[epoch 7] step 44/44: loss=1.7902 
[epoch 7] train_loss(avg per step)=3.5803 lambda[min,max]=[0.501632,1.000000]
[epoch 7] val_loss=4.7840 qwk=('0.3248', '0.3662', '0.4146') averageQWK=0.3685 macroEMD=0.3331 tailR0=('0.0000', '0.1786', '0.0000') tailR0avg=0.0595
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    4    0
     0   23   55   20    0
     0   13   92   50    0
     0    1   13   45    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     5    0    3    6    0
    24    4   34   20    0
    18    6   60   82    0
     0    0    6   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   58   40    6    0
     0   51   87   42    0
     0    1   11   24    0
     0    0    0    0    0
[epoch 8] step 2/44: loss=1.4349 
[epoch 8] step 4/44: loss=1.5379 
[epoch 8] step 6/44: loss=1.4790 
[epoch 8] step 8/44: loss=1.5166 
[epoch 8] step 10/44: loss=1.4980 
[epoch 8] step 12/44: loss=1.5259 
[epoch 8] step 14/44: loss=1.5615 
[epoch 8] step 16/44: loss=1.5707 
[epoch 8] step 18/44: loss=1.5596 
[epoch 8] step 20/44: loss=1.5551 
[epoch 8] step 22/44: loss=1.5746 
[epoch 8] step 24/44: loss=1.5846 
[epoch 8] step 26/44: loss=1.6102 
[epoch 8] step 28/44: loss=1.6215 
[epoch 8] step 30/44: loss=1.5990 
[epoch 8] step 32/44: loss=1.5815 
[epoch 8] step 34/44: loss=1.5778 
[epoch 8] step 36/44: loss=1.5818 
[epoch 8] step 38/44: loss=1.5885 
[epoch 8] step 40/44: loss=1.5927 
[epoch 8] step 42/44: loss=1.5963 
[epoch 8] step 44/44: loss=1.5871 
[epoch 8] train_loss(avg per step)=3.1741 lambda[min,max]=[0.500063,1.000000]
[epoch 8] val_loss=4.3152 qwk=('0.2780', '0.3961', '0.4117') averageQWK=0.3619 macroEMD=0.3317 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    2    1
     0   29   63    3    3
     0   18  120   11    6
     0    1   39   16    3
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    1    4    0
     0   54   18   10    0
     0   65   48   53    0
     0    8   11   42    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    3    0    0
     0   47   54    3    0
     0   39  123   18    0
     0    0   18   18    0
     0    0    0    0    0
[epoch 9] step 2/44: loss=1.5112 
[epoch 9] step 4/44: loss=1.6468 
[epoch 9] step 6/44: loss=1.5600 
[epoch 9] step 8/44: loss=1.5988 
[epoch 9] step 10/44: loss=1.5770 
[epoch 9] step 12/44: loss=1.5136 
[epoch 9] step 14/44: loss=1.5302 
[epoch 9] step 16/44: loss=1.5263 
[epoch 9] step 18/44: loss=1.5151 
[epoch 9] step 20/44: loss=1.5132 
[epoch 9] step 22/44: loss=1.5226 
[epoch 9] step 24/44: loss=1.5187 
[epoch 9] step 26/44: loss=1.5114 
[epoch 9] step 28/44: loss=1.5036 
[epoch 9] step 30/44: loss=1.4902 
[epoch 9] step 32/44: loss=1.4807 
[epoch 9] step 34/44: loss=1.4827 
[epoch 9] step 36/44: loss=1.4876 
[epoch 9] step 38/44: loss=1.4841 
[epoch 9] step 40/44: loss=1.4809 
[epoch 9] step 42/44: loss=1.4730 
[epoch 9] step 44/44: loss=1.4691 
[epoch 9] train_loss(avg per step)=2.9382 lambda[min,max]=[0.500022,1.000000]
[epoch 9] val_loss=4.8950 qwk=('0.3038', '0.3432', '0.3499') averageQWK=0.3323 macroEMD=0.3273 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    4    0
     0   33   33   32    0
     0   20   52   82    1
     0    2    7   50    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    4    0
     0   26   44   12    0
     0   20   78   68    0
     0    3   13   45    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   31   67    6    0
     0   25  122   33    0
     0    0   15   21    0
     0    0    0    0    0
[epoch 10] step 2/44: loss=1.3618 
[epoch 10] step 4/44: loss=1.3917 
[epoch 10] step 6/44: loss=1.3946 
[epoch 10] step 8/44: loss=1.3935 
[epoch 10] step 10/44: loss=1.3522 
[epoch 10] step 12/44: loss=1.3248 
[epoch 10] step 14/44: loss=1.3075 
[epoch 10] step 16/44: loss=1.2868 
[epoch 10] step 18/44: loss=1.2832 
[epoch 10] step 20/44: loss=1.3027 
[epoch 10] step 22/44: loss=1.3070 
[epoch 10] step 24/44: loss=1.3294 
[epoch 10] step 26/44: loss=1.3412 
[epoch 10] step 28/44: loss=1.3464 
[epoch 10] step 30/44: loss=1.3509 
[epoch 10] step 32/44: loss=1.3516 
[epoch 10] step 34/44: loss=1.3576 
[epoch 10] step 36/44: loss=1.3524 
[epoch 10] step 38/44: loss=1.3439 
[epoch 10] step 40/44: loss=1.3329 
[epoch 10] step 42/44: loss=1.3241 
[epoch 10] step 44/44: loss=1.3283 
[epoch 10] train_loss(avg per step)=2.6566 lambda[min,max]=[0.500073,1.000000]
[epoch 10] val_loss=5.3261 qwk=('0.2961', '0.3669', '0.3531') averageQWK=0.3387 macroEMD=0.3184 tailR0=('0.1667', '0.1429', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    2    1
     0   26   55   11    6
     0   13   95   35   12
     0    1   21   31    6
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    1    4    5    0
    12   12   42   16    0
     6   10   78   71    1
     0    1   13   46    1
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   60   29   15    0
     0   61   55   64    0
     0    2    7   27    0
     0    0    0    0    0
[epoch 11] step 2/44: loss=1.1585 
[epoch 11] step 4/44: loss=1.1467 
[epoch 11] step 6/44: loss=1.1260 
[epoch 11] step 8/44: loss=1.1226 
[epoch 11] step 10/44: loss=1.0820 
[epoch 11] step 12/44: loss=1.1278 
[epoch 11] step 14/44: loss=1.1137 
[epoch 11] step 16/44: loss=1.1012 
[epoch 11] step 18/44: loss=1.1137 
[epoch 11] step 20/44: loss=1.1207 
[epoch 11] step 22/44: loss=1.1291 
[epoch 11] step 24/44: loss=1.1378 
[epoch 11] step 26/44: loss=1.1353 
[epoch 11] step 28/44: loss=1.1383 
[epoch 11] step 30/44: loss=1.1303 
[epoch 11] step 32/44: loss=1.1343 
[epoch 11] step 34/44: loss=1.1273 
[epoch 11] step 36/44: loss=1.1349 
[epoch 11] step 38/44: loss=1.1289 
[epoch 11] step 40/44: loss=1.1280 
[epoch 11] step 42/44: loss=1.1211 
[epoch 11] step 44/44: loss=1.1058 
[epoch 11] train_loss(avg per step)=2.2115 lambda[min,max]=[0.500029,1.000000]
[epoch 11] val_loss=5.3348 qwk=('0.2681', '0.2749', '0.3308') averageQWK=0.2913 macroEMD=0.3205 tailR0=('0.2500', '0.0000', '0.0000') tailR0avg=0.0833
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    3    1
     0   35   38   13   12
     0   20   68   54   13
     0    2   13   35    9
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    1
     1   21   47    9    4
     0   15   94   46   11
     0    3   17   37    4
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   48   40   16    0
     0   37   80   63    0
     0    2    8   26    0
     0    0    0    0    0
[epoch 12] step 2/44: loss=1.0065 
[epoch 12] step 4/44: loss=1.0330 
[epoch 12] step 6/44: loss=1.0681 
[epoch 12] step 8/44: loss=1.0055 
[epoch 12] step 10/44: loss=1.0267 
[epoch 12] step 12/44: loss=1.0104 
[epoch 12] step 14/44: loss=1.0113 
[epoch 12] step 16/44: loss=0.9749 
[epoch 12] step 18/44: loss=0.9727 
[epoch 12] step 20/44: loss=0.9795 
[epoch 12] step 22/44: loss=0.9804 
[epoch 12] step 24/44: loss=0.9890 
[epoch 12] step 26/44: loss=0.9891 
[epoch 12] step 28/44: loss=0.9812 
[epoch 12] step 30/44: loss=0.9779 
[epoch 12] step 32/44: loss=0.9686 
[epoch 12] step 34/44: loss=0.9585 
[epoch 12] step 36/44: loss=0.9655 
[epoch 12] step 38/44: loss=0.9596 
[epoch 12] step 40/44: loss=0.9562 
[epoch 12] step 42/44: loss=0.9502 
[epoch 12] step 44/44: loss=0.9406 
[epoch 12] train_loss(avg per step)=1.8812 lambda[min,max]=[0.500002,1.000000]
[epoch 12] val_loss=5.7243 qwk=('0.2715', '0.2783', '0.3436') averageQWK=0.2978 macroEMD=0.3153 tailR0=('0.2500', '0.0000', '0.0000') tailR0avg=0.0833
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    5    0
     0   33   34   22    9
     0   16   63   68    8
     0    2    8   46    3
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    7    0
     1   20   33   28    0
     0   16   53   97    0
     0    3    4   53    1
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   39   56    9    0
     0   32  103   45    0
     0    1   11   24    0
     0    0    0    0    0
[epoch 13] step 2/44: loss=0.8217 
[epoch 13] step 4/44: loss=0.7252 
[epoch 13] step 6/44: loss=0.7244 
[epoch 13] step 8/44: loss=0.7613 
[epoch 13] step 10/44: loss=0.7704 
[epoch 13] step 12/44: loss=0.7603 
[epoch 13] step 14/44: loss=0.7573 
[epoch 13] step 16/44: loss=0.7334 
[epoch 13] step 18/44: loss=0.7463 
[epoch 13] step 20/44: loss=0.7524 
[epoch 13] step 22/44: loss=0.7564 
[epoch 13] step 24/44: loss=0.7554 
[epoch 13] step 26/44: loss=0.7745 
[epoch 13] step 28/44: loss=0.8030 
[epoch 13] step 30/44: loss=0.8077 
[epoch 13] step 32/44: loss=0.7963 
[epoch 13] step 34/44: loss=0.7928 
[epoch 13] step 36/44: loss=0.7836 
[epoch 13] step 38/44: loss=0.7912 
[epoch 13] step 40/44: loss=0.7926 
[epoch 13] step 42/44: loss=0.8009 
[epoch 13] step 44/44: loss=0.8019 
[epoch 13] train_loss(avg per step)=1.6038 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=6.6323 qwk=('0.2691', '0.3297', '0.3000') averageQWK=0.2996 macroEMD=0.3130 tailR0=('0.2381', '0.0000', '0.0000') tailR0avg=0.0794
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    0    5    0
    14   20   33   20   11
     5   12   58   67   13
     0    3    7   46    3
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    5    0
     5   32   17   26    2
     2   30   42   88    4
     0    3    2   54    2
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   47   39   18    0
     0   46   74   60    0
     0    2   10   24    0
     0    0    0    0    0
[epoch 14] step 2/44: loss=0.7420 
[epoch 14] step 4/44: loss=0.6467 
[epoch 14] step 6/44: loss=0.6467 
[epoch 14] step 8/44: loss=0.6632 
[epoch 14] step 10/44: loss=0.6872 
[epoch 14] step 12/44: loss=0.6530 
[epoch 14] step 14/44: loss=0.6772 
[epoch 14] step 16/44: loss=0.6813 
[epoch 14] step 18/44: loss=0.6907 
[epoch 14] step 20/44: loss=0.6695 
[epoch 14] step 22/44: loss=0.6714 
[epoch 14] step 24/44: loss=0.6744 
[epoch 14] step 26/44: loss=0.6724 
[epoch 14] step 28/44: loss=0.6775 
[epoch 14] step 30/44: loss=0.6622 
[epoch 14] step 32/44: loss=0.6553 
[epoch 14] step 34/44: loss=0.6677 
[epoch 14] step 36/44: loss=0.6550 
[epoch 14] step 38/44: loss=0.6514 
[epoch 14] step 40/44: loss=0.6515 
[epoch 14] step 42/44: loss=0.6509 
[epoch 14] step 44/44: loss=0.6426 
[epoch 14] train_loss(avg per step)=1.2852 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=7.2404 qwk=('0.2304', '0.2790', '0.2864') averageQWK=0.2653 macroEMD=0.3139 tailR0=('0.3214', '0.0357', '0.0000') tailR0avg=0.1190
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    2    2
    10    9   50   18   11
     6    5   67   55   22
     0    1   12   37    9
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    5    0
     7   14   34   24    3
     3   13   57   90    3
     0    3    6   50    2
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   35   50   19    0
     0   21  103   56    0
     0    0   12   24    0
     0    0    0    0    0
[epoch 15] step 2/44: loss=0.4561 
[epoch 15] step 4/44: loss=0.5242 
[epoch 15] step 6/44: loss=0.5123 
[epoch 15] step 8/44: loss=0.5136 
[epoch 15] step 10/44: loss=0.5650 
[epoch 15] step 12/44: loss=0.5709 
[epoch 15] step 14/44: loss=0.5744 
[epoch 15] step 16/44: loss=0.5838 
[epoch 15] step 18/44: loss=0.5807 
[epoch 15] step 20/44: loss=0.5795 
[epoch 15] step 22/44: loss=0.5730 
[epoch 15] step 24/44: loss=0.5660 
[epoch 15] step 26/44: loss=0.5651 
[epoch 15] step 28/44: loss=0.5584 
[epoch 15] step 30/44: loss=0.5607 
[epoch 15] step 32/44: loss=0.5690 
[epoch 15] step 34/44: loss=0.5607 
[epoch 15] step 36/44: loss=0.5521 
[epoch 15] step 38/44: loss=0.5545 
[epoch 15] step 40/44: loss=0.5411 
[epoch 15] step 42/44: loss=0.5419 
[epoch 15] step 44/44: loss=0.5316 
[epoch 15] train_loss(avg per step)=1.0632 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=7.7935 qwk=('0.1914', '0.3042', '0.2848') averageQWK=0.2601 macroEMD=0.3115 tailR0=('0.4762', '0.5357', '0.0000') tailR0avg=0.3373
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    1    4
    15   15   29   19   20
     9    8   52   55   31
     0    3    7   39   10
     0    0    0    2    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    4    4    1
     9   19   35   16    3
     2   17   70   62   15
     0    4   12   39    6
     0    0    0    0    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   56   22   26    0
     0   55   47   78    0
     0    2    7   27    0
     0    0    0    0    0
[epoch 16] step 2/44: loss=0.5050 
[epoch 16] step 4/44: loss=0.3832 
[epoch 16] step 6/44: loss=0.4057 
[epoch 16] step 8/44: loss=0.3613 
[epoch 16] step 10/44: loss=0.4039 
[epoch 16] step 12/44: loss=0.4334 
[epoch 16] step 14/44: loss=0.4339 
[epoch 16] step 16/44: loss=0.4310 
[epoch 16] step 18/44: loss=0.4293 
[epoch 16] step 20/44: loss=0.4166 
[epoch 16] step 22/44: loss=0.3951 
[epoch 16] step 24/44: loss=0.3809 
[epoch 16] step 26/44: loss=0.3810 
[epoch 16] step 28/44: loss=0.3770 
[epoch 16] step 30/44: loss=0.3804 
[epoch 16] step 32/44: loss=0.3660 
[epoch 16] step 34/44: loss=0.3598 
[epoch 16] step 36/44: loss=0.3587 
[epoch 16] step 38/44: loss=0.3565 
[epoch 16] step 40/44: loss=0.3649 
[epoch 16] step 42/44: loss=0.3582 
[epoch 16] step 44/44: loss=0.3539 
[epoch 16] train_loss(avg per step)=0.7077 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=8.0720 qwk=('0.3431', '0.3787', '0.2963') averageQWK=0.3394 macroEMD=0.3027 tailR0=('0.3095', '0.2500', '0.0000') tailR0avg=0.1865
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    0    4    0
    27   21   23   19    8
    12   15   53   65   10
     0    4    6   47    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     7    1    1    5    0
    17   31    9   24    1
    14   30   36   83    3
     0    5    3   50    3
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   51   31   22    0
     0   52   68   60    0
     0    1    8   27    0
     0    0    0    0    0
[epoch 17] step 2/44: loss=0.2313 
[epoch 17] step 4/44: loss=0.2034 
[epoch 17] step 6/44: loss=0.2504 
[epoch 17] step 8/44: loss=0.2757 
[epoch 17] step 10/44: loss=0.2317 
[epoch 17] step 12/44: loss=0.2319 
[epoch 17] step 14/44: loss=0.2365 
[epoch 17] step 16/44: loss=0.2185 
[epoch 17] step 18/44: loss=0.2171 
[epoch 17] step 20/44: loss=0.2310 
[epoch 17] step 22/44: loss=0.2214 
[epoch 17] step 24/44: loss=0.2260 
[epoch 17] step 26/44: loss=0.2209 
[epoch 17] step 28/44: loss=0.2245 
[epoch 17] step 30/44: loss=0.2334 
[epoch 17] step 32/44: loss=0.2305 
[epoch 17] step 34/44: loss=0.2328 
[epoch 17] step 36/44: loss=0.2278 
[epoch 17] step 38/44: loss=0.2200 
[epoch 17] step 40/44: loss=0.2269 
[epoch 17] step 42/44: loss=0.2313 
[epoch 17] step 44/44: loss=0.2329 
[epoch 17] train_loss(avg per step)=0.4659 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=8.6537 qwk=('0.2945', '0.3427', '0.3196') averageQWK=0.3189 macroEMD=0.2994 tailR0=('0.3095', '0.0000', '0.0000') tailR0avg=0.1032
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    4    1
    19   17   37   16    9
     7   12   68   55   13
     0    4    9   42    4
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    5    0
     5   34   13   30    0
     2   28   42   91    3
     0    3    2   53    3
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   42   47   15    0
     0   41   84   55    0
     0    1    8   27    0
     0    0    0    0    0
[epoch 18] step 2/44: loss=0.0402 
[epoch 18] step 4/44: loss=0.1336 
[epoch 18] step 6/44: loss=0.1251 
[epoch 18] step 8/44: loss=0.1836 
[epoch 18] step 10/44: loss=0.1647 
[epoch 18] step 12/44: loss=0.1482 
[epoch 18] step 14/44: loss=0.1440 
[epoch 18] step 16/44: loss=0.1557 
[epoch 18] step 18/44: loss=0.1616 
[epoch 18] step 20/44: loss=0.1530 
[epoch 18] step 22/44: loss=0.1471 
[epoch 18] step 24/44: loss=0.1501 
[epoch 18] step 26/44: loss=0.1434 
[epoch 18] step 28/44: loss=0.1339 
[epoch 18] step 30/44: loss=0.1339 
[epoch 18] step 32/44: loss=0.1361 
[epoch 18] step 34/44: loss=0.1279 
[epoch 18] step 36/44: loss=0.1264 
[epoch 18] step 38/44: loss=0.1206 
[epoch 18] step 40/44: loss=0.1207 
[epoch 18] step 42/44: loss=0.1201 
[epoch 18] step 44/44: loss=0.1198 
[epoch 18] train_loss(avg per step)=0.2396 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=10.5913 qwk=('0.2476', '0.2840', '0.2518') averageQWK=0.2611 macroEMD=0.3022 tailR0=('0.4048', '0.0000', '0.0000') tailR0avg=0.1349
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    0    3    2
     7   17   46   17   11
     3   14   64   52   22
     0    2   10   37   10
     0    0    0    2    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    6    0
     7   22   19   34    0
     1   23   41  101    0
     0    3    4   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   52   23   29    0
     0   56   44   80    0
     0    2    8   26    0
     0    0    0    0    0
[epoch 19] step 2/44: loss=0.0607 
[epoch 19] step 4/44: loss=0.1061 
[epoch 19] step 6/44: loss=0.0649 
[epoch 19] step 8/44: loss=0.0451 
[epoch 19] step 10/44: loss=0.0195 
[epoch 19] step 12/44: loss=0.0094 
[epoch 19] step 14/44: loss=0.0223 
[epoch 19] step 16/44: loss=0.0312 
[epoch 19] step 18/44: loss=0.0382 
[epoch 19] step 20/44: loss=0.0578 
[epoch 19] step 22/44: loss=0.0595 
[epoch 19] step 24/44: loss=0.0638 
[epoch 19] step 26/44: loss=0.0610 
[epoch 19] step 28/44: loss=0.0543 
[epoch 19] step 30/44: loss=0.0489 
[epoch 19] step 32/44: loss=0.0508 
[epoch 19] step 34/44: loss=0.0464 
[epoch 19] step 36/44: loss=0.0506 
[epoch 19] step 38/44: loss=0.0471 
[epoch 19] step 40/44: loss=0.0438 
[epoch 19] step 42/44: loss=0.0411 
[epoch 19] step 44/44: loss=0.0341 
[epoch 19] train_loss(avg per step)=0.0683 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=9.4709 qwk=('0.2478', '0.3395', '0.3093') averageQWK=0.2989 macroEMD=0.2960 tailR0=('0.2381', '0.1429', '0.0000') tailR0avg=0.1270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    4    1
    11   18   40   19   10
     4   16   67   49   19
     0    3    8   42    6
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    1    5    4    0
    11   12   38   21    0
    10   10   62   81    3
     0    2    8   49    2
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   43   44   17    0
     0   49   72   59    0
     0    1    6   29    0
     0    0    0    0    0
[epoch 20] step 2/44: loss=-0.1493 
[epoch 20] step 4/44: loss=-0.1018 
[epoch 20] step 6/44: loss=-0.0868 
[epoch 20] step 8/44: loss=-0.0704 
[epoch 20] step 10/44: loss=-0.0597 
[epoch 20] step 12/44: loss=-0.0573 
[epoch 20] step 14/44: loss=-0.0612 
[epoch 20] step 16/44: loss=-0.0667 
[epoch 20] step 18/44: loss=-0.0550 
[epoch 20] step 20/44: loss=-0.0342 
[epoch 20] step 22/44: loss=-0.0362 
[epoch 20] step 24/44: loss=-0.0439 
[epoch 20] step 26/44: loss=-0.0260 
[epoch 20] step 28/44: loss=-0.0249 
[epoch 20] step 30/44: loss=-0.0262 
[epoch 20] step 32/44: loss=-0.0298 
[epoch 20] step 34/44: loss=-0.0291 
[epoch 20] step 36/44: loss=-0.0289 
[epoch 20] step 38/44: loss=-0.0237 
[epoch 20] step 40/44: loss=-0.0213 
[epoch 20] step 42/44: loss=-0.0166 
[epoch 20] step 44/44: loss=-0.0097 
[epoch 20] train_loss(avg per step)=-0.0195 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=8.8466 qwk=('0.2785', '0.3295', '0.2349') averageQWK=0.2810 macroEMD=0.3026 tailR0=('0.3214', '0.4643', '0.0000') tailR0avg=0.2619
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    2    2
    15   14   49    9   11
     4   14   90   26   21
     0    3   16   27   13
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     6    1    2    5    0
    18    5   40   18    1
    18    7   66   72    3
     0    3   13   43    2
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   52   37   15    0
     0   64   73   43    0
     0    4   13   19    0
     0    0    0    0    0
[epoch 21] step 2/44: loss=-0.0498 
[epoch 21] step 4/44: loss=-0.0580 
[epoch 21] step 6/44: loss=-0.0758 
[epoch 21] step 8/44: loss=-0.0558 
[epoch 21] step 10/44: loss=-0.0497 
[epoch 21] step 12/44: loss=-0.0337 
[epoch 21] step 14/44: loss=-0.0463 
[epoch 21] step 16/44: loss=-0.0540 
[epoch 21] step 18/44: loss=-0.0157 
[epoch 21] step 20/44: loss=-0.0049 
[epoch 21] step 22/44: loss=-0.0212 
[epoch 21] step 24/44: loss=-0.0292 
[epoch 21] step 26/44: loss=-0.0258 
[epoch 21] step 28/44: loss=-0.0118 
[epoch 21] step 30/44: loss=-0.0044 
[epoch 21] step 32/44: loss=-0.0016 
[epoch 21] step 34/44: loss=-0.0106 
[epoch 21] step 36/44: loss=-0.0154 
[epoch 21] step 38/44: loss=-0.0167 
[epoch 21] step 40/44: loss=-0.0185 
[epoch 21] step 42/44: loss=-0.0227 
[epoch 21] step 44/44: loss=-0.0260 
[epoch 21] train_loss(avg per step)=-0.0520 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=10.0693 qwk=('0.2752', '0.2704', '0.3180') averageQWK=0.2879 macroEMD=0.2915 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    2    4    0
     9    9   60   13    7
     5    6   80   55    9
     0    1   12   43    3
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    5    0
     9   10   33   28    2
     2   13   58   89    4
     0    3    3   53    2
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   35   61    8    0
     0   38  101   41    0
     0    0   16   20    0
     0    0    0    0    0
[epoch 22] step 2/44: loss=-0.0974 
[epoch 22] step 4/44: loss=-0.1267 
[epoch 22] step 6/44: loss=-0.1443 
[epoch 22] step 8/44: loss=-0.1258 
[epoch 22] step 10/44: loss=-0.0906 
[epoch 22] step 12/44: loss=-0.1064 
[epoch 22] step 14/44: loss=-0.1232 
[epoch 22] step 16/44: loss=-0.1265 
[epoch 22] step 18/44: loss=-0.1204 
[epoch 22] step 20/44: loss=-0.1198 
[epoch 22] step 22/44: loss=-0.1230 
[epoch 22] step 24/44: loss=-0.1221 
[epoch 22] step 26/44: loss=-0.1230 
[epoch 22] step 28/44: loss=-0.1258 
[epoch 22] step 30/44: loss=-0.1284 
[epoch 22] step 32/44: loss=-0.1284 
[epoch 22] step 34/44: loss=-0.1283 
[epoch 22] step 36/44: loss=-0.1268 
[epoch 22] step 38/44: loss=-0.1314 
[epoch 22] step 40/44: loss=-0.1251 
[epoch 22] step 42/44: loss=-0.1193 
[epoch 22] step 44/44: loss=-0.1109 
[epoch 22] train_loss(avg per step)=-0.2218 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=11.3874 qwk=('0.2292', '0.3059', '0.2868') averageQWK=0.2740 macroEMD=0.2992 tailR0=('0.3929', '0.1071', '0.0000') tailR0avg=0.1667
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    3    2
    17    4   46   17   14
     9    5   65   55   21
     1    0   11   37   10
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    3    5    0
    10   17   22   32    1
     6   13   45   98    4
     0    3    3   52    3
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   41   45   18    0
     0   43   76   61    0
     0    1    8   27    0
     0    0    0    0    0
[epoch 23] step 2/44: loss=-0.1544 
[epoch 23] step 4/44: loss=-0.1568 
[epoch 23] step 6/44: loss=-0.1116 
[epoch 23] step 8/44: loss=-0.0800 
[epoch 23] step 10/44: loss=-0.1077 
[epoch 23] step 12/44: loss=-0.1306 
[epoch 23] step 14/44: loss=-0.1377 
[epoch 23] step 16/44: loss=-0.1156 
[epoch 23] step 18/44: loss=-0.1123 
[epoch 23] step 20/44: loss=-0.1218 
[epoch 23] step 22/44: loss=-0.1269 
[epoch 23] step 24/44: loss=-0.1343 
[epoch 23] step 26/44: loss=-0.1335 
[epoch 23] step 28/44: loss=-0.1345 
[epoch 23] step 30/44: loss=-0.1332 
[epoch 23] step 32/44: loss=-0.1399 
[epoch 23] step 34/44: loss=-0.1355 
[epoch 23] step 36/44: loss=-0.1406 
[epoch 23] step 38/44: loss=-0.1386 
[epoch 23] step 40/44: loss=-0.1391 
[epoch 23] step 42/44: loss=-0.1416 
[epoch 23] step 44/44: loss=-0.1484 
[epoch 23] train_loss(avg per step)=-0.2969 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=12.1426 qwk=('0.1794', '0.2719', '0.2549') averageQWK=0.2354 macroEMD=0.3044 tailR0=('0.4048', '0.1429', '0.0000') tailR0avg=0.1825
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    3    2
    11   10   36   21   20
     6    7   50   54   38
     0    2    8   34   15
     0    0    0    2    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    2    2    6    0
    13    9   24   33    3
     6   11   43   97    9
     0    3    3   52    3
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   42   35   27    0
     0   40   61   78    1
     0    2    7   27    0
     0    0    0    0    0
[epoch 24] step 2/44: loss=-0.2105 
[epoch 24] step 4/44: loss=-0.1914 
[epoch 24] step 6/44: loss=-0.1396 
[epoch 24] step 8/44: loss=-0.1653 
[epoch 24] step 10/44: loss=-0.1808 
[epoch 24] step 12/44: loss=-0.1923 
[epoch 24] step 14/44: loss=-0.1719 
[epoch 24] step 16/44: loss=-0.1676 
[epoch 24] step 18/44: loss=-0.1620 
[epoch 24] step 20/44: loss=-0.1700 
[epoch 24] step 22/44: loss=-0.1766 
[epoch 24] step 24/44: loss=-0.1725 
[epoch 24] step 26/44: loss=-0.1714 
[epoch 24] step 28/44: loss=-0.1686 
[epoch 24] step 30/44: loss=-0.1734 
[epoch 24] step 32/44: loss=-0.1745 
[epoch 24] step 34/44: loss=-0.1753 
[epoch 24] step 36/44: loss=-0.1733 
[epoch 24] step 38/44: loss=-0.1698 
[epoch 24] step 40/44: loss=-0.1668 
[epoch 24] step 42/44: loss=-0.1653 
[epoch 24] step 44/44: loss=-0.1656 
[epoch 24] train_loss(avg per step)=-0.3312 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=11.0361 qwk=('0.2268', '0.3017', '0.3076') averageQWK=0.2787 macroEMD=0.2932 tailR0=('0.4762', '0.3214', '0.0000') tailR0avg=0.2659
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    2    3
    13   19   31   17   18
     7   11   55   50   32
     0    2    9   33   15
     0    0    0    2    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    4    1
    10   25   15   29    3
     4   27   39   83   13
     0    4    2   48    7
     0    0    0    1    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   48   39   17    0
     0   53   74   53    0
     0    2    8   26    0
     0    0    0    0    0
[epoch 25] step 2/44: loss=-0.2401 
[epoch 25] step 4/44: loss=-0.2048 
[epoch 25] step 6/44: loss=-0.2065 
[epoch 25] step 8/44: loss=-0.2355 
[epoch 25] step 10/44: loss=-0.2374 
[epoch 25] step 12/44: loss=-0.2431 
[epoch 25] step 14/44: loss=-0.2514 
[epoch 25] step 16/44: loss=-0.2454 
[epoch 25] step 18/44: loss=-0.2403 
[epoch 25] step 20/44: loss=-0.2301 
[epoch 25] step 22/44: loss=-0.2282 
[epoch 25] step 24/44: loss=-0.2276 
[epoch 25] step 26/44: loss=-0.2266 
[epoch 25] step 28/44: loss=-0.2259 
[epoch 25] step 30/44: loss=-0.2232 
[epoch 25] step 32/44: loss=-0.2226 
[epoch 25] step 34/44: loss=-0.2188 
[epoch 25] step 36/44: loss=-0.2201 
[epoch 25] step 38/44: loss=-0.2193 
[epoch 25] step 40/44: loss=-0.2193 
[epoch 25] step 42/44: loss=-0.2141 
[epoch 25] step 44/44: loss=-0.2158 
[epoch 25] train_loss(avg per step)=-0.4316 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=10.9209 qwk=('0.3033', '0.2712', '0.2908') averageQWK=0.2884 macroEMD=0.2852 tailR0=('0.3929', '0.0000', '0.0000') tailR0avg=0.1310
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    1    2    2
    12   11   58   10    7
     6   10   91   30   18
     0    2   15   32   10
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    5    0
     8   13   28   33    0
     1   15   47  101    2
     0    3    5   52    1
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   44   45   15    0
     0   43   94   43    0
     0    2   13   21    0
     0    0    0    0    0
[epoch 26] step 2/44: loss=-0.2548 
[epoch 26] step 4/44: loss=-0.2493 
[epoch 26] step 6/44: loss=-0.2467 
[epoch 26] step 8/44: loss=-0.2245 
[epoch 26] step 10/44: loss=-0.2167 
[epoch 26] step 12/44: loss=-0.2123 
[epoch 26] step 14/44: loss=-0.2139 
[epoch 26] step 16/44: loss=-0.2086 
[epoch 26] step 18/44: loss=-0.2070 
[epoch 26] step 20/44: loss=-0.2077 
[epoch 26] step 22/44: loss=-0.2096 
[epoch 26] step 24/44: loss=-0.2154 
[epoch 26] step 26/44: loss=-0.2204 
[epoch 26] step 28/44: loss=-0.2226 
[epoch 26] step 30/44: loss=-0.2251 
[epoch 26] step 32/44: loss=-0.2259 
[epoch 26] step 34/44: loss=-0.2247 
[epoch 26] step 36/44: loss=-0.2267 
[epoch 26] step 38/44: loss=-0.2275 
[epoch 26] step 40/44: loss=-0.2254 
[epoch 26] step 42/44: loss=-0.2259 
[epoch 26] step 44/44: loss=-0.2289 
[epoch 26] train_loss(avg per step)=-0.4578 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=11.1187 qwk=('0.2451', '0.3669', '0.2927') averageQWK=0.3016 macroEMD=0.2880 tailR0=('0.3214', '0.0357', '0.0000') tailR0avg=0.1190
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    0    2    3
    11   33   24   16   14
     6   21   52   47   29
     0    4    8   38    9
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    5    0
    10   33   18   20    1
     5   33   47   76    5
     0    5    3   48    5
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   56   32   16    0
     0   62   73   45    0
     0    2   12   22    0
     0    0    0    0    0
[epoch 27] step 2/44: loss=-0.2103 
[epoch 27] step 4/44: loss=-0.2110 
[epoch 27] step 6/44: loss=-0.2205 
[epoch 27] step 8/44: loss=-0.2228 
[epoch 27] step 10/44: loss=-0.2236 
[epoch 27] step 12/44: loss=-0.2308 
[epoch 27] step 14/44: loss=-0.2277 
[epoch 27] step 16/44: loss=-0.2270 
[epoch 27] step 18/44: loss=-0.2316 
[epoch 27] step 20/44: loss=-0.2344 
[epoch 27] step 22/44: loss=-0.2389 
[epoch 27] step 24/44: loss=-0.2396 
[epoch 27] step 26/44: loss=-0.2399 
[epoch 27] step 28/44: loss=-0.2335 
[epoch 27] step 30/44: loss=-0.2393 
[epoch 27] step 32/44: loss=-0.2445 
[epoch 27] step 34/44: loss=-0.2473 
[epoch 27] step 36/44: loss=-0.2478 
[epoch 27] step 38/44: loss=-0.2455 
[epoch 27] step 40/44: loss=-0.2464 
[epoch 27] step 42/44: loss=-0.2482 
[epoch 27] step 44/44: loss=-0.2496 
[epoch 27] train_loss(avg per step)=-0.4993 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=12.0640 qwk=('0.2422', '0.3407', '0.2659') averageQWK=0.2829 macroEMD=0.2919 tailR0=('0.3214', '0.0714', '0.0000') tailR0avg=0.1310
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    4    1
    11    7   55   13   12
     6    5   75   46   23
     0    1   11   38    9
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    1    5    0
     9   26   19   27    1
     4   25   42   89    6
     0    4    2   52    3
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   48   36   20    0
     0   59   62   59    0
     0    2    9   25    0
     0    0    0    0    0
[epoch 28] step 2/44: loss=-0.2832 
[epoch 28] step 4/44: loss=-0.2695 
[epoch 28] step 6/44: loss=-0.2652 
[epoch 28] step 8/44: loss=-0.2644 
[epoch 28] step 10/44: loss=-0.2687 
[epoch 28] step 12/44: loss=-0.2741 
[epoch 28] step 14/44: loss=-0.2793 
[epoch 28] step 16/44: loss=-0.2724 
[epoch 28] step 18/44: loss=-0.2751 
[epoch 28] step 20/44: loss=-0.2779 
[epoch 28] step 22/44: loss=-0.2796 
[epoch 28] step 24/44: loss=-0.2749 
[epoch 28] step 26/44: loss=-0.2721 
[epoch 28] step 28/44: loss=-0.2723 
[epoch 28] step 30/44: loss=-0.2676 
[epoch 28] step 32/44: loss=-0.2687 
[epoch 28] step 34/44: loss=-0.2698 
[epoch 28] step 36/44: loss=-0.2711 
[epoch 28] step 38/44: loss=-0.2715 
[epoch 28] step 40/44: loss=-0.2706 
[epoch 28] step 42/44: loss=-0.2722 
[epoch 28] step 44/44: loss=-0.2740 
[epoch 28] train_loss(avg per step)=-0.5481 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=12.5228 qwk=('0.2276', '0.2945', '0.2850') averageQWK=0.2691 macroEMD=0.2917 tailR0=('0.3214', '0.0000', '0.0000') tailR0avg=0.1071
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    1    3    2
    13   17   34   18   16
     6   10   56   56   27
     0    1    9   38   11
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    2    5    0
     7   27   16   30    2
     3   24   41   92    6
     0    5    2   51    3
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   42   47   15    0
     0   52   82   46    0
     0    2    8   26    0
     0    0    0    0    0
[epoch 29] step 2/44: loss=-0.2832 
[epoch 29] step 4/44: loss=-0.2995 
[epoch 29] step 6/44: loss=-0.2957 
[epoch 29] step 8/44: loss=-0.2943 
[epoch 29] step 10/44: loss=-0.2886 
[epoch 29] step 12/44: loss=-0.2915 
[epoch 29] step 14/44: loss=-0.2929 
[epoch 29] step 16/44: loss=-0.2928 
[epoch 29] step 18/44: loss=-0.2958 
[epoch 29] step 20/44: loss=-0.2923 
[epoch 29] step 22/44: loss=-0.2934 
[epoch 29] step 24/44: loss=-0.2922 
[epoch 29] step 26/44: loss=-0.2940 
[epoch 29] step 28/44: loss=-0.2919 
[epoch 29] step 30/44: loss=-0.2919 
[epoch 29] step 32/44: loss=-0.2913 
[epoch 29] step 34/44: loss=-0.2906 
[epoch 29] step 36/44: loss=-0.2901 
[epoch 29] step 38/44: loss=-0.2883 
[epoch 29] step 40/44: loss=-0.2877 
[epoch 29] step 42/44: loss=-0.2857 
[epoch 29] step 44/44: loss=-0.2845 
[epoch 29] train_loss(avg per step)=-0.5689 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=12.3562 qwk=('0.2710', '0.3574', '0.3009') averageQWK=0.3097 macroEMD=0.2848 tailR0=('0.3095', '0.1429', '0.0000') tailR0avg=0.1508
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    3    2
    16   21   33   15   13
     6   15   63   53   18
     0    2   11   37    9
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    4    1    5    0
    12   24   20   25    1
     6   22   44   88    6
     0    3    5   51    2
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   51   38   15    0
     0   59   68   53    0
     0    3    7   26    0
     0    0    0    0    0
[epoch 30] step 2/44: loss=-0.3135 
[epoch 30] step 4/44: loss=-0.2926 
[epoch 30] step 6/44: loss=-0.2892 
[epoch 30] step 8/44: loss=-0.3017 
[epoch 30] step 10/44: loss=-0.3063 
[epoch 30] step 12/44: loss=-0.3102 
[epoch 30] step 14/44: loss=-0.3063 
[epoch 30] step 16/44: loss=-0.3078 
[epoch 30] step 18/44: loss=-0.3024 
[epoch 30] step 20/44: loss=-0.3047 
[epoch 30] step 22/44: loss=-0.3050 
[epoch 30] step 24/44: loss=-0.3055 
[epoch 30] step 26/44: loss=-0.3067 
[epoch 30] step 28/44: loss=-0.3072 
[epoch 30] step 30/44: loss=-0.3055 
[epoch 30] step 32/44: loss=-0.3050 
[epoch 30] step 34/44: loss=-0.3030 
[epoch 30] step 36/44: loss=-0.3034 
[epoch 30] step 38/44: loss=-0.3041 
[epoch 30] step 40/44: loss=-0.3025 
[epoch 30] step 42/44: loss=-0.3010 
[epoch 30] step 44/44: loss=-0.2970 
[epoch 30] train_loss(avg per step)=-0.5939 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=13.9788 qwk=('0.2313', '0.3240', '0.2843') averageQWK=0.2799 macroEMD=0.2950 tailR0=('0.3095', '0.0357', '0.0000') tailR0avg=0.1151
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    3    2
    16   13   35   19   15
     8    7   56   57   27
     0    1   10   38   10
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    5    0
     8   32   10   30    2
     3   24   35   94   10
     0    3    3   51    4
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   30   55   19    0
     0   27   91   62    0
     0    0    9   27    0
     0    0    0    0    0
[epoch 31] step 2/44: loss=-0.3035 
[epoch 31] step 4/44: loss=-0.3206 
[epoch 31] step 6/44: loss=-0.3226 
[epoch 31] step 8/44: loss=-0.3231 
[epoch 31] step 10/44: loss=-0.3175 
[epoch 31] step 12/44: loss=-0.3120 
[epoch 31] step 14/44: loss=-0.3132 
[epoch 31] step 16/44: loss=-0.3168 
[epoch 31] step 18/44: loss=-0.3184 
[epoch 31] step 20/44: loss=-0.3181 
[epoch 31] step 22/44: loss=-0.3186 
[epoch 31] step 24/44: loss=-0.3170 
[epoch 31] step 26/44: loss=-0.3159 
[epoch 31] step 28/44: loss=-0.3129 
[epoch 31] step 30/44: loss=-0.3117 
[epoch 31] step 32/44: loss=-0.3123 
[epoch 31] step 34/44: loss=-0.3119 
[epoch 31] step 36/44: loss=-0.3126 
[epoch 31] step 38/44: loss=-0.3135 
[epoch 31] step 40/44: loss=-0.3140 
[epoch 31] step 42/44: loss=-0.3124 
[epoch 31] step 44/44: loss=-0.3125 
[epoch 31] train_loss(avg per step)=-0.6251 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=12.9267 qwk=('0.2556', '0.3190', '0.2905') averageQWK=0.2884 macroEMD=0.2894 tailR0=('0.2381', '0.0357', '0.0000') tailR0avg=0.0913
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    0    2    3
    15   13   42   17   11
     3   10   68   48   26
     0    1   11   37   10
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    5    0
     8   28   14   31    1
     2   28   34   98    4
     0    3    4   52    2
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   48   39   17    0
     0   53   76   51    0
     0    2    9   25    0
     0    0    0    0    0
[epoch 32] step 2/44: loss=-0.2966 
[epoch 32] step 4/44: loss=-0.2974 
[epoch 32] step 6/44: loss=-0.3062 
[epoch 32] step 8/44: loss=-0.3025 
[epoch 32] step 10/44: loss=-0.2976 
[epoch 32] step 12/44: loss=-0.2863 
[epoch 32] step 14/44: loss=-0.2918 
[epoch 32] step 16/44: loss=-0.2948 
[epoch 32] step 18/44: loss=-0.2944 
[epoch 32] step 20/44: loss=-0.2944 
[epoch 32] step 22/44: loss=-0.2977 
[epoch 32] step 24/44: loss=-0.3006 
[epoch 32] step 26/44: loss=-0.3033 
[epoch 32] step 28/44: loss=-0.3045 
[epoch 32] step 30/44: loss=-0.3051 
[epoch 32] step 32/44: loss=-0.3066 
[epoch 32] step 34/44: loss=-0.3080 
[epoch 32] step 36/44: loss=-0.3097 
[epoch 32] step 38/44: loss=-0.3106 
[epoch 32] step 40/44: loss=-0.3099 
[epoch 32] step 42/44: loss=-0.3108 
[epoch 32] step 44/44: loss=-0.3096 
[epoch 32] train_loss(avg per step)=-0.6192 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=13.6681 qwk=('0.2433', '0.2890', '0.2899') averageQWK=0.2741 macroEMD=0.2925 tailR0=('0.3095', '0.0357', '0.0000') tailR0avg=0.1151
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    3    2
    16   21   26   18   17
     5   17   50   57   26
     0    1   10   36   12
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    5    1
     9   21   21   29    2
     4   19   44   92    7
     0    3    3   51    4
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   46   40   18    0
     0   53   69   58    0
     0    2    7   27    0
     0    0    0    0    0
[epoch 33] step 2/44: loss=-0.3272 
[epoch 33] step 4/44: loss=-0.3249 
[epoch 33] step 6/44: loss=-0.3208 
[epoch 33] step 8/44: loss=-0.3187 
[epoch 33] step 10/44: loss=-0.3185 
[epoch 33] step 12/44: loss=-0.3203 
[epoch 33] step 14/44: loss=-0.3214 
[epoch 33] step 16/44: loss=-0.3154 
[epoch 33] step 18/44: loss=-0.3154 
[epoch 33] step 20/44: loss=-0.3168 
[epoch 33] step 22/44: loss=-0.3168 
[epoch 33] step 24/44: loss=-0.3156 
[epoch 33] step 26/44: loss=-0.3160 
[epoch 33] step 28/44: loss=-0.3166 
[epoch 33] step 30/44: loss=-0.3166 
[epoch 33] step 32/44: loss=-0.3178 
[epoch 33] step 34/44: loss=-0.3189 
[epoch 33] step 36/44: loss=-0.3198 
[epoch 33] step 38/44: loss=-0.3178 
[epoch 33] step 40/44: loss=-0.3173 
[epoch 33] step 42/44: loss=-0.3171 
[epoch 33] step 44/44: loss=-0.3169 
[epoch 33] train_loss(avg per step)=-0.6337 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=13.1820 qwk=('0.2604', '0.3299', '0.2826') averageQWK=0.2909 macroEMD=0.2880 tailR0=('0.3095', '0.0357', '0.0000') tailR0avg=0.1151
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    3    2
    13   18   38   16   13
     3   17   58   57   20
     0    1   11   37   10
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    5    0
     9   23   23   26    1
     1   21   47   90    7
     0    3    5   52    1
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   35   52   17    0
     0   37   87   56    0
     0    1    9   26    0
     0    0    0    0    0
[epoch 34] step 2/44: loss=-0.3403 
[epoch 34] step 4/44: loss=-0.3226 
[epoch 34] step 6/44: loss=-0.3255 
[epoch 34] step 8/44: loss=-0.3232 
[epoch 34] step 10/44: loss=-0.3230 
[epoch 34] step 12/44: loss=-0.3249 
[epoch 34] step 14/44: loss=-0.3263 
[epoch 34] step 16/44: loss=-0.3257 
[epoch 34] step 18/44: loss=-0.3251 
[epoch 34] step 20/44: loss=-0.3259 
[epoch 34] step 22/44: loss=-0.3253 
[epoch 34] step 24/44: loss=-0.3256 
[epoch 34] step 26/44: loss=-0.3257 
[epoch 34] step 28/44: loss=-0.3255 
[epoch 34] step 30/44: loss=-0.3232 
[epoch 34] step 32/44: loss=-0.3242 
[epoch 34] step 34/44: loss=-0.3213 
[epoch 34] step 36/44: loss=-0.3216 
[epoch 34] step 38/44: loss=-0.3221 
[epoch 34] step 40/44: loss=-0.3214 
[epoch 34] step 42/44: loss=-0.3219 
[epoch 34] step 44/44: loss=-0.3224 
[epoch 34] train_loss(avg per step)=-0.6448 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=13.3802 qwk=('0.2726', '0.3321', '0.2927') averageQWK=0.2992 macroEMD=0.2876 tailR0=('0.3095', '0.0357', '0.0000') tailR0avg=0.1151
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    3    2
    17   13   41   15   12
     7   11   66   51   20
     0    1   11   36   11
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    5    0
    10   23   21   27    1
     2   21   44   92    7
     0    3    4   52    2
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   41   46   17    0
     0   41   85   54    0
     0    1   10   25    0
     0    0    0    0    0
[epoch 35] step 2/44: loss=-0.3313 
[epoch 35] step 4/44: loss=-0.3358 
[epoch 35] step 6/44: loss=-0.3342 
[epoch 35] step 8/44: loss=-0.3360 
[epoch 35] step 10/44: loss=-0.3300 
[epoch 35] step 12/44: loss=-0.3279 
[epoch 35] step 14/44: loss=-0.3258 
[epoch 35] step 16/44: loss=-0.3260 
[epoch 35] step 18/44: loss=-0.3245 
[epoch 35] step 20/44: loss=-0.3260 
[epoch 35] step 22/44: loss=-0.3276 
[epoch 35] step 24/44: loss=-0.3279 
[epoch 35] step 26/44: loss=-0.3284 
[epoch 35] step 28/44: loss=-0.3281 
[epoch 35] step 30/44: loss=-0.3278 
[epoch 35] step 32/44: loss=-0.3276 
[epoch 35] step 34/44: loss=-0.3269 
[epoch 35] step 36/44: loss=-0.3272 
[epoch 35] step 38/44: loss=-0.3276 
[epoch 35] step 40/44: loss=-0.3262 
[epoch 35] step 42/44: loss=-0.3266 
[epoch 35] step 44/44: loss=-0.3258 
[epoch 35] train_loss(avg per step)=-0.6516 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=13.4793 qwk=('0.2759', '0.3387', '0.2829') averageQWK=0.2991 macroEMD=0.2871 tailR0=('0.3095', '0.0357', '0.0000') tailR0avg=0.1151
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    3    2
    18   17   35   16   12
     8   12   59   57   19
     0    1   11   38    9
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    2    5    0
    10   27   18   26    1
     3   25   44   89    5
     0    3    5   52    1
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1    2    0
     0   38   49   17    0
     0   40   85   55    0
     0    1   10   25    0
     0    0    0    0    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-0/fold2/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-0/fold2/metrics.json
Done.
