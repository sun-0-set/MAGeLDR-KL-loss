[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=19.9390 
[epoch 1] step 4/44: loss=19.4326 
[epoch 1] step 6/44: loss=19.1320 
[epoch 1] step 8/44: loss=19.4236 
[epoch 1] step 10/44: loss=19.3373 
[epoch 1] step 12/44: loss=19.4195 
[epoch 1] step 14/44: loss=19.4799 
[epoch 1] step 16/44: loss=19.4097 
[epoch 1] step 18/44: loss=19.4318 
[epoch 1] step 20/44: loss=19.4497 
[epoch 1] step 22/44: loss=19.4465 
[epoch 1] step 24/44: loss=19.6385 
[epoch 1] step 26/44: loss=19.6034 
[epoch 1] step 28/44: loss=19.4855 
[epoch 1] step 30/44: loss=19.4356 
[epoch 1] step 32/44: loss=19.3892 
[epoch 1] step 34/44: loss=19.3322 
[epoch 1] step 36/44: loss=19.2630 
[epoch 1] step 38/44: loss=19.2023 
[epoch 1] step 40/44: loss=19.1896 
[epoch 1] step 42/44: loss=19.1016 
[epoch 1] step 44/44: loss=19.0206 
[epoch 1] train_loss(avg per step)=38.0412 lambda[min,max]=[0.533866,1.000000]
[epoch 1] val_loss=31.7937 qwk=('-0.1777', '-0.1391', '0.0866') averageQWK=-0.0767 macroEMD=0.3876 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    0    2    0
     0   65    0   33    0
     0  107    0   48    0
     0   55    0    4    0
     0    6    0    0    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   14    0    0
     4    0   77    1    0
     8    0  158    0    0
    11    0   49    1    0
     0    0    2    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    0    0
     0   23   81    0    0
     0   19  161    0    0
     0    4   32    0    0
     0    0    0    0    0
[epoch 2] step 2/44: loss=18.5387 
[epoch 2] step 4/44: loss=18.0279 
[epoch 2] step 6/44: loss=17.9360 
[epoch 2] step 8/44: loss=17.5302 
[epoch 2] step 10/44: loss=17.2191 
[epoch 2] step 12/44: loss=16.9591 
[epoch 2] step 14/44: loss=16.8286 
[epoch 2] step 16/44: loss=16.8780 
[epoch 2] step 18/44: loss=16.8839 
[epoch 2] step 20/44: loss=16.8216 
[epoch 2] step 22/44: loss=16.5325 
[epoch 2] step 24/44: loss=16.3892 
[epoch 2] step 26/44: loss=16.1473 
[epoch 2] step 28/44: loss=15.9666 
[epoch 2] step 30/44: loss=15.7879 
[epoch 2] step 32/44: loss=15.6263 
[epoch 2] step 34/44: loss=15.4545 
[epoch 2] step 36/44: loss=15.3529 
[epoch 2] step 38/44: loss=15.2607 
[epoch 2] step 40/44: loss=15.1223 
[epoch 2] step 42/44: loss=15.0189 
[epoch 2] step 44/44: loss=14.9005 
[epoch 2] train_loss(avg per step)=29.8011 lambda[min,max]=[0.527475,1.000000]
[epoch 2] val_loss=14.0337 qwk=('0.1851', '0.2607', '0.1703') averageQWK=0.2054 macroEMD=0.3852 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    0    4    0
    72    8    0   14    4
   110    2    0   41    2
    21    1    0   35    2
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    2    0
     0    0   78    4    0
     0    0  136   30    0
     0    0   26   35    0
     0    0    1    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     1   29   74    0    0
     0   22  158    0    0
     0    3   33    0    0
     0    0    0    0    0
[epoch 3] step 2/44: loss=12.4820 
[epoch 3] step 4/44: loss=13.0546 
[epoch 3] step 6/44: loss=13.3649 
[epoch 3] step 8/44: loss=13.2025 
[epoch 3] step 10/44: loss=13.0933 
[epoch 3] step 12/44: loss=12.9694 
[epoch 3] step 14/44: loss=13.0253 
[epoch 3] step 16/44: loss=12.8699 
[epoch 3] step 18/44: loss=12.8374 
[epoch 3] step 20/44: loss=12.7975 
[epoch 3] step 22/44: loss=12.8691 
[epoch 3] step 24/44: loss=12.8291 
[epoch 3] step 26/44: loss=12.7847 
[epoch 3] step 28/44: loss=12.8068 
[epoch 3] step 30/44: loss=12.8149 
[epoch 3] step 32/44: loss=12.8025 
[epoch 3] step 34/44: loss=12.7804 
[epoch 3] step 36/44: loss=12.7303 
[epoch 3] step 38/44: loss=12.6897 
[epoch 3] step 40/44: loss=12.6486 
[epoch 3] step 42/44: loss=12.6154 
[epoch 3] step 44/44: loss=12.5815 
[epoch 3] train_loss(avg per step)=25.1631 lambda[min,max]=[0.534353,1.000000]
[epoch 3] val_loss=12.4143 qwk=('0.2880', '0.1538', '0.1905') averageQWK=0.2108 macroEMD=0.3834 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    5    2    0
     0    0   90    8    0
     0    0  133   22    0
     0    0   25   34    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    1    1
     0    6   68    2    6
     0    8  138   11    9
     0    0   31   30    0
     0    0    1    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    3    2    0
     0    3   83   18    0
     0    2  115   63    0
     0    0   11   25    0
     0    0    0    0    0
[epoch 4] step 2/44: loss=11.6493 
[epoch 4] step 4/44: loss=11.6500 
[epoch 4] step 6/44: loss=11.6034 
[epoch 4] step 8/44: loss=11.4060 
[epoch 4] step 10/44: loss=11.3410 
[epoch 4] step 12/44: loss=11.4514 
[epoch 4] step 14/44: loss=11.6572 
[epoch 4] step 16/44: loss=11.8124 
[epoch 4] step 18/44: loss=11.7124 
[epoch 4] step 20/44: loss=11.7141 
[epoch 4] step 22/44: loss=11.7047 
[epoch 4] step 24/44: loss=11.7213 
[epoch 4] step 26/44: loss=11.7035 
[epoch 4] step 28/44: loss=11.6586 
[epoch 4] step 30/44: loss=11.5553 
[epoch 4] step 32/44: loss=11.5648 
[epoch 4] step 34/44: loss=11.4580 
[epoch 4] step 36/44: loss=11.4417 
[epoch 4] step 38/44: loss=11.4300 
[epoch 4] step 40/44: loss=11.4325 
[epoch 4] step 42/44: loss=11.4397 
[epoch 4] step 44/44: loss=11.4125 
[epoch 4] train_loss(avg per step)=22.8249 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=12.6190 qwk=('0.1873', '0.2788', '0.1699') averageQWK=0.2120 macroEMD=0.3813 tailR0=('0.5476', '0.0000', '0.0000') tailR0avg=0.1825
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    0    0    4
    54    5    1    2   36
    54   15    0    9   77
     8    1    0   20   30
     0    0    0    2    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    6    0
     0   23   27   32    0
     0   19   45  102    0
     0    1    2   58    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0    9   92    3    0
     0    3  167   10    0
     0    0   29    7    0
     0    0    0    0    0
[epoch 5] step 2/44: loss=10.2784 
[epoch 5] step 4/44: loss=10.1265 
[epoch 5] step 6/44: loss=10.3404 
[epoch 5] step 8/44: loss=10.4530 
[epoch 5] step 10/44: loss=10.7935 
[epoch 5] step 12/44: loss=10.7883 
[epoch 5] step 14/44: loss=10.7826 
[epoch 5] step 16/44: loss=10.5377 
[epoch 5] step 18/44: loss=10.4377 
[epoch 5] step 20/44: loss=10.3135 
[epoch 5] step 22/44: loss=10.2795 
[epoch 5] step 24/44: loss=10.2137 
[epoch 5] step 26/44: loss=10.2834 
[epoch 5] step 28/44: loss=10.2615 
[epoch 5] step 30/44: loss=10.3317 
[epoch 5] step 32/44: loss=10.2829 
[epoch 5] step 34/44: loss=10.1506 
[epoch 5] step 36/44: loss=10.0483 
[epoch 5] step 38/44: loss=9.9568 
[epoch 5] step 40/44: loss=9.9843 
[epoch 5] step 42/44: loss=10.0539 
[epoch 5] step 44/44: loss=10.0060 
[epoch 5] train_loss(avg per step)=20.0121 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=8.6106 qwk=('0.2767', '0.2723', '0.3201') averageQWK=0.2897 macroEMD=0.3804 tailR0=('0.2976', '0.0000', '0.0000') tailR0avg=0.0992
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    0    3    1
    54    4    8   28    4
    55    3   24   64    9
     5    1    6   45    2
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    3    0
     0    1   62   19    0
     0    0   91   75    0
     0    0    9   52    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    2    0
     0   68    6   30    0
     0   69   11  100    0
     0    2    1   33    0
     0    0    0    0    0
[epoch 6] step 2/44: loss=8.8905 
[epoch 6] step 4/44: loss=8.3377 
[epoch 6] step 6/44: loss=8.1519 
[epoch 6] step 8/44: loss=8.2388 
[epoch 6] step 10/44: loss=8.4319 
[epoch 6] step 12/44: loss=8.7472 
[epoch 6] step 14/44: loss=9.1148 
[epoch 6] step 16/44: loss=9.2713 
[epoch 6] step 18/44: loss=9.3786 
[epoch 6] step 20/44: loss=9.3239 
[epoch 6] step 22/44: loss=9.1828 
[epoch 6] step 24/44: loss=9.0361 
[epoch 6] step 26/44: loss=8.9814 
[epoch 6] step 28/44: loss=8.9858 
[epoch 6] step 30/44: loss=9.1673 
[epoch 6] step 32/44: loss=9.3305 
[epoch 6] step 34/44: loss=9.4595 
[epoch 6] step 36/44: loss=9.4513 
[epoch 6] step 38/44: loss=9.3622 
[epoch 6] step 40/44: loss=9.2697 
[epoch 6] step 42/44: loss=9.2450 
[epoch 6] step 44/44: loss=9.2574 
[epoch 6] train_loss(avg per step)=18.5148 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=9.4241 qwk=('0.2383', '0.1470', '0.2577') averageQWK=0.2143 macroEMD=0.3793 tailR0=('0.2143', '0.0000', '0.0000') tailR0avg=0.0714
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    0    4    0
    40    0    9   46    3
    39    0   21   92    3
     4    0    3   51    1
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1   10    0
     0   14   14   54    0
     0    8   33  125    0
     0    1    0   60    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    2    2    0
     0   27   51   26    0
     0   13   92   75    0
     0    1    6   29    0
     0    0    0    0    0
[epoch 7] step 2/44: loss=8.5584 
[epoch 7] step 4/44: loss=8.2052 
[epoch 7] step 6/44: loss=8.0782 
[epoch 7] step 8/44: loss=8.1867 
[epoch 7] step 10/44: loss=8.3313 
[epoch 7] step 12/44: loss=8.4159 
[epoch 7] step 14/44: loss=8.7000 
[epoch 7] step 16/44: loss=8.7882 
[epoch 7] step 18/44: loss=8.8180 
[epoch 7] step 20/44: loss=8.7267 
[epoch 7] step 22/44: loss=8.6413 
[epoch 7] step 24/44: loss=8.5817 
[epoch 7] step 26/44: loss=8.5795 
[epoch 7] step 28/44: loss=8.5882 
[epoch 7] step 30/44: loss=8.5871 
[epoch 7] step 32/44: loss=8.5670 
[epoch 7] step 34/44: loss=8.5518 
[epoch 7] step 36/44: loss=8.5270 
[epoch 7] step 38/44: loss=8.4842 
[epoch 7] step 40/44: loss=8.4384 
[epoch 7] step 42/44: loss=8.4331 
[epoch 7] step 44/44: loss=8.4623 
[epoch 7] train_loss(avg per step)=16.9246 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=12.9623 qwk=('0.1832', '0.0628', '0.2881') averageQWK=0.1781 macroEMD=0.3732 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    11    4   41   28   14
     3    5   49   69   29
     0    0    8   46    5
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0   13    0
     0    4   13   65    0
     0    2   24  140    0
     0    0    0   61    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   18   81    5    0
     0   12  149   19    0
     0    1   17   18    0
     0    0    0    0    0
[epoch 8] step 2/44: loss=8.7644 
[epoch 8] step 4/44: loss=8.4571 
[epoch 8] step 6/44: loss=8.4689 
[epoch 8] step 8/44: loss=8.1627 
[epoch 8] step 10/44: loss=8.2650 
[epoch 8] step 12/44: loss=8.2457 
[epoch 8] step 14/44: loss=8.2394 
[epoch 8] step 16/44: loss=8.2086 
[epoch 8] step 18/44: loss=8.1389 
[epoch 8] step 20/44: loss=7.9984 
[epoch 8] step 22/44: loss=8.0158 
[epoch 8] step 24/44: loss=8.0840 
[epoch 8] step 26/44: loss=8.0999 
[epoch 8] step 28/44: loss=8.1864 
[epoch 8] step 30/44: loss=8.3181 
[epoch 8] step 32/44: loss=8.3201 
[epoch 8] step 34/44: loss=8.2637 
[epoch 8] step 36/44: loss=8.2022 
[epoch 8] step 38/44: loss=8.1631 
[epoch 8] step 40/44: loss=8.1928 
[epoch 8] step 42/44: loss=8.2016 
[epoch 8] step 44/44: loss=8.2100 
[epoch 8] train_loss(avg per step)=16.4201 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=8.9402 qwk=('0.1744', '0.3695', '0.2547') averageQWK=0.2662 macroEMD=0.3731 tailR0=('0.3333', '0.0000', '0.0000') tailR0avg=0.1111
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    0    0    5
     3   39   19    5   32
     1   29   45   12   68
     0    1    9   25   24
     0    0    0    2    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    1    5    0
     0   36   25   20    1
     0   40   43   83    0
     0    1    5   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    2    0
     0   62    0   42    0
     0   63    9  108    0
     0    3    1   32    0
     0    0    0    0    0
[epoch 9] step 2/44: loss=8.1113 
[epoch 9] step 4/44: loss=7.8384 
[epoch 9] step 6/44: loss=7.8858 
[epoch 9] step 8/44: loss=8.0952 
[epoch 9] step 10/44: loss=8.2271 
[epoch 9] step 12/44: loss=8.1653 
[epoch 9] step 14/44: loss=8.0345 
[epoch 9] step 16/44: loss=7.9697 
[epoch 9] step 18/44: loss=7.8800 
[epoch 9] step 20/44: loss=7.8517 
[epoch 9] step 22/44: loss=7.8768 
[epoch 9] step 24/44: loss=7.9220 
[epoch 9] step 26/44: loss=8.0564 
[epoch 9] step 28/44: loss=8.1057 
[epoch 9] step 30/44: loss=8.1392 
[epoch 9] step 32/44: loss=8.1217 
[epoch 9] step 34/44: loss=8.1052 
[epoch 9] step 36/44: loss=8.0386 
[epoch 9] step 38/44: loss=8.0173 
[epoch 9] step 40/44: loss=8.0131 
[epoch 9] step 42/44: loss=8.0125 
[epoch 9] step 44/44: loss=8.0445 
[epoch 9] train_loss(avg per step)=16.0890 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=11.5058 qwk=('0.2619', '0.2841', '0.3520') averageQWK=0.2993 macroEMD=0.3710 tailR0=('0.1429', '0.1786', '0.0000') tailR0avg=0.1071
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    28    6   16   42    6
    12    3   38   91   11
     0    0    6   51    2
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     5    1    1    7    0
    24    1   14   43    0
    17    2   35  112    0
     1    0    0   60    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    0    0
     0   31   67    6    0
     0   16  143   21    0
     0    0   18   18    0
     0    0    0    0    0
[epoch 10] step 2/44: loss=8.3661 
[epoch 10] step 4/44: loss=8.5081 
[epoch 10] step 6/44: loss=8.6320 
[epoch 10] step 8/44: loss=8.2524 
[epoch 10] step 10/44: loss=7.9792 
[epoch 10] step 12/44: loss=8.0658 
[epoch 10] step 14/44: loss=7.9578 
[epoch 10] step 16/44: loss=8.0720 
[epoch 10] step 18/44: loss=8.1743 
[epoch 10] step 20/44: loss=8.1646 
[epoch 10] step 22/44: loss=8.1166 
[epoch 10] step 24/44: loss=8.0194 
[epoch 10] step 26/44: loss=7.9888 
[epoch 10] step 28/44: loss=7.9410 
[epoch 10] step 30/44: loss=7.9385 
[epoch 10] step 32/44: loss=7.8944 
[epoch 10] step 34/44: loss=7.8954 
[epoch 10] step 36/44: loss=7.9546 
[epoch 10] step 38/44: loss=7.9140 
[epoch 10] step 40/44: loss=7.9232 
[epoch 10] step 42/44: loss=7.9696 
[epoch 10] step 44/44: loss=8.0293 
[epoch 10] train_loss(avg per step)=16.0586 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=9.2462 qwk=('0.3227', '0.2186', '0.3063') averageQWK=0.2825 macroEMD=0.3719 tailR0=('0.3929', '0.0357', '0.0000') tailR0avg=0.1429
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    3    1    1
    15    0   76    4    3
     8    1  133   11    2
     0    0   37   16    6
     0    0    2    1    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    5    6    0
     4   12   40   24    2
     4   10   64   87    1
     0    2   14   45    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     0   50   30   24    0
     0   35   75   70    0
     0    3    8   25    0
     0    0    0    0    0
[epoch 11] step 2/44: loss=8.5754 
[epoch 11] step 4/44: loss=7.8109 
[epoch 11] step 6/44: loss=7.7810 
[epoch 11] step 8/44: loss=7.6970 
[epoch 11] step 10/44: loss=7.6723 
[epoch 11] step 12/44: loss=7.8222 
[epoch 11] step 14/44: loss=8.0409 
[epoch 11] step 16/44: loss=8.2580 
[epoch 11] step 18/44: loss=8.2206 
[epoch 11] step 20/44: loss=8.0804 
[epoch 11] step 22/44: loss=7.9146 
[epoch 11] step 24/44: loss=7.8014 
[epoch 11] step 26/44: loss=7.7162 
[epoch 11] step 28/44: loss=7.7628 
[epoch 11] step 30/44: loss=7.8606 
[epoch 11] step 32/44: loss=7.9298 
[epoch 11] step 34/44: loss=7.9403 
[epoch 11] step 36/44: loss=7.9257 
[epoch 11] step 38/44: loss=7.9204 
[epoch 11] step 40/44: loss=7.9310 
[epoch 11] step 42/44: loss=7.9386 
[epoch 11] step 44/44: loss=7.9353 
[epoch 11] train_loss(avg per step)=15.8705 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=8.6682 qwk=('0.4139', '0.3896', '0.3155') averageQWK=0.3730 macroEMD=0.3709 tailR0=('0.0833', '0.0714', '0.0000') tailR0avg=0.0516
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    3    0
     1   47   39   10    1
     0   42   82   31    0
     0    3   21   34    1
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    5    4    3    0
     4   30   41    6    1
     2   34   91   39    0
     1    2   19   39    0
     0    0    1    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     0   52   30   22    0
     0   44   67   69    0
     0    2    9   25    0
     0    0    0    0    0
[epoch 12] step 2/44: loss=7.2655 
[epoch 12] step 4/44: loss=7.1678 
[epoch 12] step 6/44: loss=7.3347 
[epoch 12] step 8/44: loss=7.5510 
[epoch 12] step 10/44: loss=7.7856 
[epoch 12] step 12/44: loss=7.8512 
[epoch 12] step 14/44: loss=7.8926 
[epoch 12] step 16/44: loss=7.8801 
[epoch 12] step 18/44: loss=7.9213 
[epoch 12] step 20/44: loss=7.9694 
[epoch 12] step 22/44: loss=8.0057 
[epoch 12] step 24/44: loss=7.8929 
[epoch 12] step 26/44: loss=7.8057 
[epoch 12] step 28/44: loss=7.8532 
[epoch 12] step 30/44: loss=7.9223 
[epoch 12] step 32/44: loss=7.9357 
[epoch 12] step 34/44: loss=8.0344 
[epoch 12] step 36/44: loss=8.0383 
[epoch 12] step 38/44: loss=8.0442 
[epoch 12] step 40/44: loss=8.0268 
[epoch 12] step 42/44: loss=8.0003 
[epoch 12] step 44/44: loss=7.9137 
[epoch 12] train_loss(avg per step)=15.8275 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=10.6508 qwk=('0.4484', '0.3831', '0.4200') averageQWK=0.4172 macroEMD=0.3675 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    2    2    0
    11   57   24    4    2
     5   56   77   15    2
     0    5   26   28    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    1    3    0
     0   67    4   11    0
     0  100   29   37    0
     0   10   14   37    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    2    0    0
     0   63   36    5    0
     0   59   96   25    0
     0    1   17   18    0
     0    0    0    0    0
[epoch 13] step 2/44: loss=7.6697 
[epoch 13] step 4/44: loss=7.9110 
[epoch 13] step 6/44: loss=7.9278 
[epoch 13] step 8/44: loss=8.1885 
[epoch 13] step 10/44: loss=8.0165 
[epoch 13] step 12/44: loss=7.9555 
[epoch 13] step 14/44: loss=7.7762 
[epoch 13] step 16/44: loss=7.6839 
[epoch 13] step 18/44: loss=7.8059 
[epoch 13] step 20/44: loss=7.8825 
[epoch 13] step 22/44: loss=7.8841 
[epoch 13] step 24/44: loss=7.8632 
[epoch 13] step 26/44: loss=7.7898 
[epoch 13] step 28/44: loss=7.7663 
[epoch 13] step 30/44: loss=7.7770 
[epoch 13] step 32/44: loss=7.8480 
[epoch 13] step 34/44: loss=7.9875 
[epoch 13] step 36/44: loss=8.0974 
[epoch 13] step 38/44: loss=8.1350 
[epoch 13] step 40/44: loss=8.0835 
[epoch 13] step 42/44: loss=8.0083 
[epoch 13] step 44/44: loss=7.9590 
[epoch 13] train_loss(avg per step)=15.9180 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=8.7864 qwk=('0.3466', '0.2660', '0.2905') averageQWK=0.3010 macroEMD=0.3701 tailR0=('0.4643', '0.1071', '0.0000') tailR0avg=0.1905
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    0    4    0
    21   22   26   20    9
     9   18   53   66    9
     0    1   10   41    7
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    0    8    0
    10   24    1   46    1
     4   28   11  123    0
     0    1    0   60    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   46   30   28    0
     0   41   52   87    0
     0    1    6   29    0
     0    0    0    0    0
[epoch 14] step 2/44: loss=6.3671 
[epoch 14] step 4/44: loss=7.1411 
[epoch 14] step 6/44: loss=7.2578 
[epoch 14] step 8/44: loss=7.7848 
[epoch 14] step 10/44: loss=8.0972 
[epoch 14] step 12/44: loss=8.2661 
[epoch 14] step 14/44: loss=8.3138 
[epoch 14] step 16/44: loss=8.1891 
[epoch 14] step 18/44: loss=8.0341 
[epoch 14] step 20/44: loss=8.0165 
[epoch 14] step 22/44: loss=7.9652 
[epoch 14] step 24/44: loss=8.0003 
[epoch 14] step 26/44: loss=7.9869 
[epoch 14] step 28/44: loss=7.9869 
[epoch 14] step 30/44: loss=8.0071 
[epoch 14] step 32/44: loss=8.0167 
[epoch 14] step 34/44: loss=7.9515 
[epoch 14] step 36/44: loss=7.9209 
[epoch 14] step 38/44: loss=7.9066 
[epoch 14] step 40/44: loss=7.8817 
[epoch 14] step 42/44: loss=7.8834 
[epoch 14] step 44/44: loss=7.8627 
[epoch 14] train_loss(avg per step)=15.7254 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=10.4815 qwk=('0.4118', '0.3398', '0.3181') averageQWK=0.3566 macroEMD=0.3665 tailR0=('0.1429', '0.0000', '0.0000') tailR0avg=0.0476
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    1    3    0
    22   20   42   12    2
     7   24   86   38    0
     0    2   19   37    1
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    6    0
     0   54    5   23    0
     0   77   20   69    0
     0    6    3   52    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   59   29   16    0
     0   61   56   63    0
     0    2   12   22    0
     0    0    0    0    0
[epoch 15] step 2/44: loss=8.3416 
[epoch 15] step 4/44: loss=7.7507 
[epoch 15] step 6/44: loss=7.5012 
[epoch 15] step 8/44: loss=7.7031 
[epoch 15] step 10/44: loss=7.8233 
[epoch 15] step 12/44: loss=7.8576 
[epoch 15] step 14/44: loss=8.0226 
[epoch 15] step 16/44: loss=7.9981 
[epoch 15] step 18/44: loss=7.9579 
[epoch 15] step 20/44: loss=7.9181 
[epoch 15] step 22/44: loss=7.8591 
[epoch 15] step 24/44: loss=7.8200 
[epoch 15] step 26/44: loss=7.8166 
[epoch 15] step 28/44: loss=7.8219 
[epoch 15] step 30/44: loss=7.9029 
[epoch 15] step 32/44: loss=7.9248 
[epoch 15] step 34/44: loss=8.0016 
[epoch 15] step 36/44: loss=8.0343 
[epoch 15] step 38/44: loss=8.0624 
[epoch 15] step 40/44: loss=8.0032 
[epoch 15] step 42/44: loss=7.9402 
[epoch 15] step 44/44: loss=7.8912 
[epoch 15] train_loss(avg per step)=15.7825 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=9.5274 qwk=('0.3639', '0.2947', '0.3523') averageQWK=0.3370 macroEMD=0.3699 tailR0=('0.3095', '0.1071', '0.0000') tailR0avg=0.1389
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    2    3    0
    30    0   46   17    5
    14    0   87   50    4
     0    0   15   40    4
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    1    5    1
     8   29   11   32    2
     2   33   32   95    4
     0    4    2   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   39   53   12    0
     0   23  101   56    0
     0    0   12   24    0
     0    0    0    0    0
[epoch 16] step 2/44: loss=6.8906 
[epoch 16] step 4/44: loss=7.5596 
[epoch 16] step 6/44: loss=7.5087 
[epoch 16] step 8/44: loss=7.6348 
[epoch 16] step 10/44: loss=7.7605 
[epoch 16] step 12/44: loss=7.8430 
[epoch 16] step 14/44: loss=7.9004 
[epoch 16] step 16/44: loss=7.9440 
[epoch 16] step 18/44: loss=7.8662 
[epoch 16] step 20/44: loss=7.8248 
[epoch 16] step 22/44: loss=7.7807 
[epoch 16] step 24/44: loss=7.7961 
[epoch 16] step 26/44: loss=7.8048 
[epoch 16] step 28/44: loss=7.8734 
[epoch 16] step 30/44: loss=7.9050 
[epoch 16] step 32/44: loss=7.8771 
[epoch 16] step 34/44: loss=7.8171 
[epoch 16] step 36/44: loss=7.7805 
[epoch 16] step 38/44: loss=7.8554 
[epoch 16] step 40/44: loss=7.8361 
[epoch 16] step 42/44: loss=7.8103 
[epoch 16] step 44/44: loss=7.8287 
[epoch 16] train_loss(avg per step)=15.6574 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=10.3604 qwk=('0.3855', '0.3663', '0.3368') averageQWK=0.3628 macroEMD=0.3673 tailR0=('0.3095', '0.0357', '0.0000') tailR0avg=0.1151
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    1    3    0
    14   29   37   13    5
     4   25   81   42    3
     0    2   18   37    2
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    0    6    0
     3   50    7   22    0
     0   64   13   88    1
     0    6    0   55    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   52   34   18    0
     0   52   66   62    0
     0    1    7   28    0
     0    0    0    0    0
[epoch 17] step 2/44: loss=7.1777 
[epoch 17] step 4/44: loss=7.4524 
[epoch 17] step 6/44: loss=7.8469 
[epoch 17] step 8/44: loss=8.0265 
[epoch 17] step 10/44: loss=8.3063 
[epoch 17] step 12/44: loss=8.3294 
[epoch 17] step 14/44: loss=8.2255 
[epoch 17] step 16/44: loss=8.1464 
[epoch 17] step 18/44: loss=8.0113 
[epoch 17] step 20/44: loss=7.8809 
[epoch 17] step 22/44: loss=7.7551 
[epoch 17] step 24/44: loss=7.7379 
[epoch 17] step 26/44: loss=7.7911 
[epoch 17] step 28/44: loss=7.8361 
[epoch 17] step 30/44: loss=7.9142 
[epoch 17] step 32/44: loss=7.9829 
[epoch 17] step 34/44: loss=8.0173 
[epoch 17] step 36/44: loss=8.0289 
[epoch 17] step 38/44: loss=7.9939 
[epoch 17] step 40/44: loss=7.9518 
[epoch 17] step 42/44: loss=7.8998 
[epoch 17] step 44/44: loss=7.9084 
[epoch 17] train_loss(avg per step)=15.8168 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=9.3237 qwk=('0.3564', '0.3553', '0.3508') averageQWK=0.3541 macroEMD=0.3693 tailR0=('0.2143', '0.1429', '0.0000') tailR0avg=0.1190
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    1    3    0
    38    8   30   21    1
    25   14   66   50    0
     2    0   18   38    1
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    4    0    6    0
    19   31    8   23    1
    10   58   19   78    1
     0    6    1   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   54   40   10    0
     0   53   82   45    0
     0    1   14   21    0
     0    0    0    0    0
[epoch 18] step 2/44: loss=7.4467 
[epoch 18] step 4/44: loss=7.2128 
[epoch 18] step 6/44: loss=7.3636 
[epoch 18] step 8/44: loss=7.6643 
[epoch 18] step 10/44: loss=7.9459 
[epoch 18] step 12/44: loss=8.1289 
[epoch 18] step 14/44: loss=8.2784 
[epoch 18] step 16/44: loss=8.1987 
[epoch 18] step 18/44: loss=8.1477 
[epoch 18] step 20/44: loss=8.1008 
[epoch 18] step 22/44: loss=7.9930 
[epoch 18] step 24/44: loss=7.9057 
[epoch 18] step 26/44: loss=7.8929 
[epoch 18] step 28/44: loss=7.8484 
[epoch 18] step 30/44: loss=7.8544 
[epoch 18] step 32/44: loss=7.8491 
[epoch 18] step 34/44: loss=7.8828 
[epoch 18] step 36/44: loss=7.8819 
[epoch 18] step 38/44: loss=7.9343 
[epoch 18] step 40/44: loss=7.9389 
[epoch 18] step 42/44: loss=7.9696 
[epoch 18] step 44/44: loss=7.9401 
[epoch 18] train_loss(avg per step)=15.8801 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=10.1366 qwk=('0.3262', '0.3321', '0.2262') averageQWK=0.2948 macroEMD=0.3680 tailR0=('0.2381', '0.2143', '0.0000') tailR0avg=0.1508
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    0    5    0
     5   38   27   23    5
     0   33   56   61    5
     0    1   12   43    3
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     6    1    0    7    0
    15   25   13   29    0
    11   30   32   92    1
     0    4    4   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   44   26   34    0
     0   41   54   85    0
     0    1   12   23    0
     0    0    0    0    0
[epoch 19] step 2/44: loss=6.9286 
[epoch 19] step 4/44: loss=7.2182 
[epoch 19] step 6/44: loss=7.4138 
[epoch 19] step 8/44: loss=7.5073 
[epoch 19] step 10/44: loss=7.8068 
[epoch 19] step 12/44: loss=7.9721 
[epoch 19] step 14/44: loss=8.0065 
[epoch 19] step 16/44: loss=7.9808 
[epoch 19] step 18/44: loss=7.8574 
[epoch 19] step 20/44: loss=7.8401 
[epoch 19] step 22/44: loss=7.8304 
[epoch 19] step 24/44: loss=7.8879 
[epoch 19] step 26/44: loss=8.0116 
[epoch 19] step 28/44: loss=7.9529 
[epoch 19] step 30/44: loss=7.9000 
[epoch 19] step 32/44: loss=7.8538 
[epoch 19] step 34/44: loss=7.7764 
[epoch 19] step 36/44: loss=7.7799 
[epoch 19] step 38/44: loss=7.7987 
[epoch 19] step 40/44: loss=7.8365 
[epoch 19] step 42/44: loss=7.8462 
[epoch 19] step 44/44: loss=7.8668 
[epoch 19] train_loss(avg per step)=15.7335 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=10.6371 qwk=('0.3369', '0.3556', '0.2627') averageQWK=0.3184 macroEMD=0.3645 tailR0=('0.3095', '0.0357', '0.0000') tailR0avg=0.1151
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    1    3    0
    14   32   30   11   11
     3   31   62   38   21
     0    3   12   34   10
     0    0    0    4    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    1    4    1
     1   49   16   16    0
     1   70   31   63    1
     0    7    4   50    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    1    0
     0   64   15   25    0
     0   76   35   69    0
     0    4   10   22    0
     0    0    0    0    0
[epoch 20] step 2/44: loss=7.6618 
[epoch 20] step 4/44: loss=7.9214 
[epoch 20] step 6/44: loss=8.1291 
[epoch 20] step 8/44: loss=8.2386 
[epoch 20] step 10/44: loss=8.3212 
[epoch 20] step 12/44: loss=8.2094 
[epoch 20] step 14/44: loss=8.1786 
[epoch 20] step 16/44: loss=8.0774 
[epoch 20] step 18/44: loss=7.9037 
[epoch 20] step 20/44: loss=7.8077 
[epoch 20] step 22/44: loss=7.6897 
[epoch 20] step 24/44: loss=7.5943 
[epoch 20] step 26/44: loss=7.6157 
[epoch 20] step 28/44: loss=7.6745 
[epoch 20] step 30/44: loss=7.7421 
[epoch 20] step 32/44: loss=7.8835 
[epoch 20] step 34/44: loss=7.9093 
[epoch 20] step 36/44: loss=7.9283 
[epoch 20] step 38/44: loss=7.9514 
[epoch 20] step 40/44: loss=7.9538 
[epoch 20] step 42/44: loss=7.9156 
[epoch 20] step 44/44: loss=7.9325 
[epoch 20] train_loss(avg per step)=15.8651 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=9.6355 qwk=('0.4017', '0.3465', '0.2434') averageQWK=0.3305 macroEMD=0.3671 tailR0=('0.4643', '0.1071', '0.0000') tailR0avg=0.1905
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    1    3    0
    20   15   45   13    5
     8   10   81   49    7
     0    0   14   42    3
     0    0    0    3    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    5    1    4    1
     8   27   23   23    1
     4   26   47   87    2
     0    3    6   52    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   40   26   38    0
     0   27   58   95    0
     0    1    7   28    0
     0    0    0    0    0
[epoch 21] step 2/44: loss=6.9273 
[epoch 21] step 4/44: loss=6.9719 
[epoch 21] step 6/44: loss=6.9137 
[epoch 21] step 8/44: loss=6.9703 
[epoch 21] step 10/44: loss=7.2365 
[epoch 21] step 12/44: loss=7.3979 
[epoch 21] step 14/44: loss=7.5957 
[epoch 21] step 16/44: loss=7.7164 
[epoch 21] step 18/44: loss=7.7823 
[epoch 21] step 20/44: loss=7.8237 
[epoch 21] step 22/44: loss=7.7435 
[epoch 21] step 24/44: loss=7.7633 
[epoch 21] step 26/44: loss=7.7870 
[epoch 21] step 28/44: loss=7.7860 
[epoch 21] step 30/44: loss=7.7562 
[epoch 21] step 32/44: loss=7.7601 
[epoch 21] step 34/44: loss=7.7700 
[epoch 21] step 36/44: loss=7.7652 
[epoch 21] step 38/44: loss=7.7526 
[epoch 21] step 40/44: loss=7.7574 
[epoch 21] step 42/44: loss=7.7362 
[epoch 21] step 44/44: loss=7.7827 
[epoch 21] train_loss(avg per step)=15.5654 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=13.1370 qwk=('0.3661', '0.3786', '0.3087') averageQWK=0.3511 macroEMD=0.3629 tailR0=('0.1429', '0.1071', '0.0000') tailR0avg=0.0833
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    14   30   31   21    2
     5   23   70   56    1
     0    1   14   43    1
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    3    3    5    0
    10   26   27   19    0
     7   24   66   69    0
     0    2    8   51    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   40   49   15    0
     0   33   96   51    0
     0    1   13   22    0
     0    0    0    0    0
[epoch 22] step 2/44: loss=8.6771 
[epoch 22] step 4/44: loss=8.6637 
[epoch 22] step 6/44: loss=8.4402 
[epoch 22] step 8/44: loss=8.3065 
[epoch 22] step 10/44: loss=8.1021 
[epoch 22] step 12/44: loss=7.9459 
[epoch 22] step 14/44: loss=7.8385 
[epoch 22] step 16/44: loss=7.8684 
[epoch 22] step 18/44: loss=7.8324 
[epoch 22] step 20/44: loss=7.8395 
[epoch 22] step 22/44: loss=7.7781 
[epoch 22] step 24/44: loss=7.7375 
[epoch 22] step 26/44: loss=7.7744 
[epoch 22] step 28/44: loss=7.7558 
[epoch 22] step 30/44: loss=7.8675 
[epoch 22] step 32/44: loss=7.9814 
[epoch 22] step 34/44: loss=8.0563 
[epoch 22] step 36/44: loss=8.1242 
[epoch 22] step 38/44: loss=8.0961 
[epoch 22] step 40/44: loss=8.0588 
[epoch 22] step 42/44: loss=8.0051 
[epoch 22] step 44/44: loss=7.9581 
[epoch 22] train_loss(avg per step)=15.9162 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=10.2594 qwk=('0.2743', '0.2714', '0.1926') averageQWK=0.2461 macroEMD=0.3696 tailR0=('0.1429', '0.0357', '0.0000') tailR0avg=0.0595
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    11   21   37   22    7
     4   22   64   61    4
     1    0   13   42    3
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    8    0
     5   32   12   31    2
     1   36   30   98    1
     0    3    5   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   33   38   33    0
     0   30   72   78    0
     0    0   15   21    0
     0    0    0    0    0
[epoch 23] step 2/44: loss=7.6649 
[epoch 23] step 4/44: loss=7.4878 
[epoch 23] step 6/44: loss=7.3180 
[epoch 23] step 8/44: loss=7.3505 
[epoch 23] step 10/44: loss=7.4432 
[epoch 23] step 12/44: loss=7.7441 
[epoch 23] step 14/44: loss=7.7817 
[epoch 23] step 16/44: loss=7.8191 
[epoch 23] step 18/44: loss=7.7255 
[epoch 23] step 20/44: loss=7.6723 
[epoch 23] step 22/44: loss=7.6898 
[epoch 23] step 24/44: loss=7.7198 
[epoch 23] step 26/44: loss=7.7511 
[epoch 23] step 28/44: loss=7.8279 
[epoch 23] step 30/44: loss=7.8579 
[epoch 23] step 32/44: loss=7.9183 
[epoch 23] step 34/44: loss=7.9576 
[epoch 23] step 36/44: loss=7.9364 
[epoch 23] step 38/44: loss=7.9344 
[epoch 23] step 40/44: loss=7.8969 
[epoch 23] step 42/44: loss=7.8736 
[epoch 23] step 44/44: loss=7.8686 
[epoch 23] train_loss(avg per step)=15.7371 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=10.9943 qwk=('0.3042', '0.3511', '0.2502') averageQWK=0.3018 macroEMD=0.3673 tailR0=('0.1429', '0.1429', '0.0000') tailR0avg=0.0952
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    13   27   28   26    4
     5   24   59   63    4
     0    2   13   41    3
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    4    0    6    0
    11   31   14   25    1
     5   34   33   93    1
     0    5    3   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   37   45   22    0
     0   33   83   64    0
     0    1   13   22    0
     0    0    0    0    0
[epoch 24] step 2/44: loss=8.7202 
[epoch 24] step 4/44: loss=7.9573 
[epoch 24] step 6/44: loss=7.7556 
[epoch 24] step 8/44: loss=7.8958 
[epoch 24] step 10/44: loss=7.8647 
[epoch 24] step 12/44: loss=7.8840 
[epoch 24] step 14/44: loss=7.9854 
[epoch 24] step 16/44: loss=8.0210 
[epoch 24] step 18/44: loss=8.0468 
[epoch 24] step 20/44: loss=7.9532 
[epoch 24] step 22/44: loss=7.8813 
[epoch 24] step 24/44: loss=7.9365 
[epoch 24] step 26/44: loss=7.9166 
[epoch 24] step 28/44: loss=7.8742 
[epoch 24] step 30/44: loss=7.8399 
[epoch 24] step 32/44: loss=7.8583 
[epoch 24] step 34/44: loss=7.8960 
[epoch 24] step 36/44: loss=7.8812 
[epoch 24] step 38/44: loss=7.9121 
[epoch 24] step 40/44: loss=7.9182 
[epoch 24] step 42/44: loss=7.9098 
[epoch 24] step 44/44: loss=7.8995 
[epoch 24] train_loss(avg per step)=15.7990 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=10.5088 qwk=('0.3430', '0.3654', '0.3362') averageQWK=0.3482 macroEMD=0.3653 tailR0=('0.1429', '0.1786', '0.0000') tailR0avg=0.1071
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    0    4    0
    12   31   33   15    7
     4   25   81   41    4
     0    1   17   39    2
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     5    2    2    5    0
    10   31   16   23    2
     6   24   40   95    1
     0    4    3   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   49   44   11    0
     0   47   87   46    0
     0    1   14   21    0
     0    0    0    0    0
[epoch 25] step 2/44: loss=7.7135 
[epoch 25] step 4/44: loss=8.0401 
[epoch 25] step 6/44: loss=7.8438 
[epoch 25] step 8/44: loss=7.6625 
[epoch 25] step 10/44: loss=7.5076 
[epoch 25] step 12/44: loss=7.5728 
[epoch 25] step 14/44: loss=7.7413 
[epoch 25] step 16/44: loss=7.6595 
[epoch 25] step 18/44: loss=7.7200 
[epoch 25] step 20/44: loss=7.7398 
[epoch 25] step 22/44: loss=7.8686 
[epoch 25] step 24/44: loss=7.9679 
[epoch 25] step 26/44: loss=7.9416 
[epoch 25] step 28/44: loss=7.9792 
[epoch 25] step 30/44: loss=7.9940 
[epoch 25] step 32/44: loss=7.9733 
[epoch 25] step 34/44: loss=7.9005 
[epoch 25] step 36/44: loss=7.8158 
[epoch 25] step 38/44: loss=7.7913 
[epoch 25] step 40/44: loss=7.7188 
[epoch 25] step 42/44: loss=7.6890 
[epoch 25] step 44/44: loss=7.6840 
[epoch 25] train_loss(avg per step)=15.3679 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=11.6228 qwk=('0.3113', '0.3150', '0.2492') averageQWK=0.2918 macroEMD=0.3651 tailR0=('0.1429', '0.2143', '0.0000') tailR0avg=0.1190
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    21   14   35   26    2
    10   14   62   68    1
     1    0   14   44    0
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     6    0    1    7    0
    18   13   17   34    0
    10   12   42  102    0
     0    3    4   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   44   30   30    0
     0   41   62   77    0
     0    1    9   26    0
     0    0    0    0    0
[epoch 26] step 2/44: loss=7.7531 
[epoch 26] step 4/44: loss=8.3159 
[epoch 26] step 6/44: loss=8.1912 
[epoch 26] step 8/44: loss=8.3069 
[epoch 26] step 10/44: loss=8.4323 
[epoch 26] step 12/44: loss=8.4734 
[epoch 26] step 14/44: loss=8.4388 
[epoch 26] step 16/44: loss=8.4198 
[epoch 26] step 18/44: loss=8.3442 
[epoch 26] step 20/44: loss=8.2651 
[epoch 26] step 22/44: loss=8.1873 
[epoch 26] step 24/44: loss=8.0661 
[epoch 26] step 26/44: loss=8.0252 
[epoch 26] step 28/44: loss=8.0247 
[epoch 26] step 30/44: loss=8.0493 
[epoch 26] step 32/44: loss=8.0750 
[epoch 26] step 34/44: loss=8.0585 
[epoch 26] step 36/44: loss=8.0435 
[epoch 26] step 38/44: loss=8.0621 
[epoch 26] step 40/44: loss=8.0175 
[epoch 26] step 42/44: loss=8.0442 
[epoch 26] step 44/44: loss=8.0630 
[epoch 26] train_loss(avg per step)=16.1261 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=10.0032 qwk=('0.3508', '0.3620', '0.3189') averageQWK=0.3439 macroEMD=0.3665 tailR0=('0.2143', '0.1429', '0.0000') tailR0avg=0.1190
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    0    4    0
    18   20   41   14    5
     9   20   76   48    2
     1    0   17   39    2
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    3    2    5    0
    15   23   19   25    0
     5   31   41   88    1
     0    4    5   52    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   43   47   14    0
     0   32   92   56    0
     0    1   13   22    0
     0    0    0    0    0
[epoch 27] step 2/44: loss=7.7814 
[epoch 27] step 4/44: loss=7.6577 
[epoch 27] step 6/44: loss=7.6202 
[epoch 27] step 8/44: loss=7.4631 
[epoch 27] step 10/44: loss=7.4415 
[epoch 27] step 12/44: loss=7.4278 
[epoch 27] step 14/44: loss=7.4849 
[epoch 27] step 16/44: loss=7.6220 
[epoch 27] step 18/44: loss=7.6666 
[epoch 27] step 20/44: loss=7.6953 
[epoch 27] step 22/44: loss=7.6783 
[epoch 27] step 24/44: loss=7.6784 
[epoch 27] step 26/44: loss=7.6611 
[epoch 27] step 28/44: loss=7.7102 
[epoch 27] step 30/44: loss=7.7366 
[epoch 27] step 32/44: loss=7.7955 
[epoch 27] step 34/44: loss=7.7764 
[epoch 27] step 36/44: loss=7.7522 
[epoch 27] step 38/44: loss=7.7272 
[epoch 27] step 40/44: loss=7.7328 
[epoch 27] step 42/44: loss=7.7512 
[epoch 27] step 44/44: loss=7.7689 
[epoch 27] train_loss(avg per step)=15.5379 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=12.9201 qwk=('0.3269', '0.3031', '0.2887') averageQWK=0.3062 macroEMD=0.3643 tailR0=('0.1429', '0.1429', '0.0000') tailR0avg=0.0952
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    21   14   39   20    4
     9    9   66   70    1
     1    0   15   40    3
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    1    3    6    0
    10   18   23   31    0
     6   16   45   99    0
     0    2    7   52    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   46   40   18    0
     0   40   87   53    0
     0    2   13   21    0
     0    0    0    0    0
[epoch 28] step 2/44: loss=8.5039 
[epoch 28] step 4/44: loss=8.7669 
[epoch 28] step 6/44: loss=8.5265 
[epoch 28] step 8/44: loss=8.3486 
[epoch 28] step 10/44: loss=8.4438 
[epoch 28] step 12/44: loss=8.3429 
[epoch 28] step 14/44: loss=8.2535 
[epoch 28] step 16/44: loss=8.1648 
[epoch 28] step 18/44: loss=8.1057 
[epoch 28] step 20/44: loss=8.1350 
[epoch 28] step 22/44: loss=8.0515 
[epoch 28] step 24/44: loss=8.0481 
[epoch 28] step 26/44: loss=7.9804 
[epoch 28] step 28/44: loss=7.9372 
[epoch 28] step 30/44: loss=7.9289 
[epoch 28] step 32/44: loss=7.9450 
[epoch 28] step 34/44: loss=7.9157 
[epoch 28] step 36/44: loss=7.9265 
[epoch 28] step 38/44: loss=7.9040 
[epoch 28] step 40/44: loss=7.8926 
[epoch 28] step 42/44: loss=7.9554 
[epoch 28] step 44/44: loss=8.0068 
[epoch 28] train_loss(avg per step)=16.0136 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=12.1128 qwk=('0.3024', '0.3119', '0.2983') averageQWK=0.3042 macroEMD=0.3651 tailR0=('0.1429', '0.0714', '0.0000') tailR0avg=0.0714
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    10   25   40   18    5
     6   23   73   52    1
     1    0   16   40    2
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    3    5    0
     5   30   18   29    0
     4   29   41   92    0
     0    4    5   52    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   47   43   14    0
     0   46   82   52    0
     0    2   14   20    0
     0    0    0    0    0
[epoch 29] step 2/44: loss=8.1658 
[epoch 29] step 4/44: loss=8.6067 
[epoch 29] step 6/44: loss=8.3146 
[epoch 29] step 8/44: loss=8.1665 
[epoch 29] step 10/44: loss=8.0009 
[epoch 29] step 12/44: loss=7.8851 
[epoch 29] step 14/44: loss=7.7606 
[epoch 29] step 16/44: loss=7.7260 
[epoch 29] step 18/44: loss=7.7665 
[epoch 29] step 20/44: loss=7.8105 
[epoch 29] step 22/44: loss=7.7863 
[epoch 29] step 24/44: loss=7.7497 
[epoch 29] step 26/44: loss=7.7256 
[epoch 29] step 28/44: loss=7.7818 
[epoch 29] step 30/44: loss=7.7952 
[epoch 29] step 32/44: loss=7.8442 
[epoch 29] step 34/44: loss=7.8950 
[epoch 29] step 36/44: loss=7.9363 
[epoch 29] step 38/44: loss=7.9627 
[epoch 29] step 40/44: loss=7.9738 
[epoch 29] step 42/44: loss=7.9686 
[epoch 29] step 44/44: loss=7.9104 
[epoch 29] train_loss(avg per step)=15.8209 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=10.5320 qwk=('0.3192', '0.3178', '0.2341') averageQWK=0.2904 macroEMD=0.3683 tailR0=('0.2262', '0.1429', '0.0000') tailR0avg=0.1230
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    16   14   46   17    5
     7   11   84   51    2
     1    0   15   41    2
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    2    2    6    0
     6   28   16   31    1
     3   23   41   99    0
     0    4    1   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   35   41   28    0
     0   28   81   71    0
     0    1   11   24    0
     0    0    0    0    0
[epoch 30] step 2/44: loss=7.3201 
[epoch 30] step 4/44: loss=7.6901 
[epoch 30] step 6/44: loss=7.7000 
[epoch 30] step 8/44: loss=7.5301 
[epoch 30] step 10/44: loss=7.4388 
[epoch 30] step 12/44: loss=7.3665 
[epoch 30] step 14/44: loss=7.4377 
[epoch 30] step 16/44: loss=7.3639 
[epoch 30] step 18/44: loss=7.4243 
[epoch 30] step 20/44: loss=7.5184 
[epoch 30] step 22/44: loss=7.6523 
[epoch 30] step 24/44: loss=7.7087 
[epoch 30] step 26/44: loss=7.7994 
[epoch 30] step 28/44: loss=7.8038 
[epoch 30] step 30/44: loss=7.8641 
[epoch 30] step 32/44: loss=7.8583 
[epoch 30] step 34/44: loss=7.8137 
[epoch 30] step 36/44: loss=7.8431 
[epoch 30] step 38/44: loss=7.8356 
[epoch 30] step 40/44: loss=7.8120 
[epoch 30] step 42/44: loss=7.8133 
[epoch 30] step 44/44: loss=7.8116 
[epoch 30] train_loss(avg per step)=15.6232 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=11.1227 qwk=('0.3717', '0.2942', '0.2134') averageQWK=0.2931 macroEMD=0.3660 tailR0=('0.2143', '0.0714', '0.0000') tailR0avg=0.0952
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    0    4    0
    17   20   42   15    4
     5   23   73   54    0
     1    0   15   41    2
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    0    8    0
     4   38    7   33    0
     2   40   21  103    0
     0    5    0   56    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   43   25   36    0
     0   38   59   83    0
     0    2    9   25    0
     0    0    0    0    0
[epoch 31] step 2/44: loss=8.2388 
[epoch 31] step 4/44: loss=8.1365 
[epoch 31] step 6/44: loss=8.2137 
[epoch 31] step 8/44: loss=8.0562 
[epoch 31] step 10/44: loss=7.9772 
[epoch 31] step 12/44: loss=8.0016 
[epoch 31] step 14/44: loss=7.9187 
[epoch 31] step 16/44: loss=7.9007 
[epoch 31] step 18/44: loss=7.9633 
[epoch 31] step 20/44: loss=7.9280 
[epoch 31] step 22/44: loss=8.0001 
[epoch 31] step 24/44: loss=7.9086 
[epoch 31] step 26/44: loss=7.9349 
[epoch 31] step 28/44: loss=7.9358 
[epoch 31] step 30/44: loss=7.9314 
[epoch 31] step 32/44: loss=7.9244 
[epoch 31] step 34/44: loss=7.9598 
[epoch 31] step 36/44: loss=7.9744 
[epoch 31] step 38/44: loss=7.9610 
[epoch 31] step 40/44: loss=7.9368 
[epoch 31] step 42/44: loss=7.9509 
[epoch 31] step 44/44: loss=7.8910 
[epoch 31] train_loss(avg per step)=15.7820 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=10.6427 qwk=('0.3965', '0.3120', '0.3144') averageQWK=0.3409 macroEMD=0.3664 tailR0=('0.2143', '0.0714', '0.0000') tailR0avg=0.0952
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    1    3    0
    20   15   48   13    2
    10   12   88   44    1
     1    0   17   39    2
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    2    6    0
     5   34   14   28    1
     3   32   35   96    0
     0    5    2   54    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   50   37   17    0
     0   42   79   59    0
     0    1   14   21    0
     0    0    0    0    0
[epoch 32] step 2/44: loss=7.3035 
[epoch 32] step 4/44: loss=7.4441 
[epoch 32] step 6/44: loss=7.5410 
[epoch 32] step 8/44: loss=7.5487 
[epoch 32] step 10/44: loss=7.5193 
[epoch 32] step 12/44: loss=7.5391 
[epoch 32] step 14/44: loss=7.5973 
[epoch 32] step 16/44: loss=7.6224 
[epoch 32] step 18/44: loss=7.7132 
[epoch 32] step 20/44: loss=7.6874 
[epoch 32] step 22/44: loss=7.6937 
[epoch 32] step 24/44: loss=7.6614 
[epoch 32] step 26/44: loss=7.6776 
[epoch 32] step 28/44: loss=7.7029 
[epoch 32] step 30/44: loss=7.6991 
[epoch 32] step 32/44: loss=7.7430 
[epoch 32] step 34/44: loss=7.8138 
[epoch 32] step 36/44: loss=7.7998 
[epoch 32] step 38/44: loss=7.7867 
[epoch 32] step 40/44: loss=7.8458 
[epoch 32] step 42/44: loss=7.8432 
[epoch 32] step 44/44: loss=7.8643 
[epoch 32] train_loss(avg per step)=15.7285 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=12.2166 qwk=('0.3466', '0.3199', '0.2939') averageQWK=0.3201 macroEMD=0.3645 tailR0=('0.1429', '0.1071', '0.0000') tailR0avg=0.0833
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    17   18   43   17    3
     8   14   78   55    0
     1    0   14   43    1
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    3    6    0
     9   22   25   26    0
     5   18   55   88    0
     0    3    7   51    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    1    0
     0   42   46   16    0
     0   34   87   59    0
     0    1   14   21    0
     0    0    0    0    0
[epoch 33] step 2/44: loss=7.7540 
[epoch 33] step 4/44: loss=8.1596 
[epoch 33] step 6/44: loss=8.1640 
[epoch 33] step 8/44: loss=8.1248 
[epoch 33] step 10/44: loss=8.1962 
[epoch 33] step 12/44: loss=8.1510 
[epoch 33] step 14/44: loss=8.1128 
[epoch 33] step 16/44: loss=8.1114 
[epoch 33] step 18/44: loss=8.0527 
[epoch 33] step 20/44: loss=8.0342 
[epoch 33] step 22/44: loss=7.9332 
[epoch 33] step 24/44: loss=7.8957 
[epoch 33] step 26/44: loss=7.9010 
[epoch 33] step 28/44: loss=7.9207 
[epoch 33] step 30/44: loss=7.9597 
[epoch 33] step 32/44: loss=7.9554 
[epoch 33] step 34/44: loss=7.9517 
[epoch 33] step 36/44: loss=7.9453 
[epoch 33] step 38/44: loss=7.9403 
[epoch 33] step 40/44: loss=7.8744 
[epoch 33] step 42/44: loss=7.8605 
[epoch 33] step 44/44: loss=7.8338 
[epoch 33] train_loss(avg per step)=15.6675 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=10.8623 qwk=('0.3440', '0.3317', '0.2985') averageQWK=0.3247 macroEMD=0.3658 tailR0=('0.1429', '0.1429', '0.0000') tailR0avg=0.0952
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    0    5    0
    17   21   41   16    3
    11   20   74   50    0
     1    0   15   41    2
     0    0    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    2    2    6    0
    10   28   17   27    0
     4   33   41   88    0
     0    5    4   52    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   53   30   21    0
     0   52   59   69    0
     0    1   12   23    0
     0    0    0    0    0
[epoch 34] step 2/44: loss=8.0127 
[epoch 34] step 4/44: loss=7.9962 
[epoch 34] step 6/44: loss=7.9896 
[epoch 34] step 8/44: loss=7.7333 
[epoch 34] step 10/44: loss=7.7347 
[epoch 34] step 12/44: loss=7.6633 
[epoch 34] step 14/44: loss=7.7195 
[epoch 34] step 16/44: loss=7.7453 
[epoch 34] step 18/44: loss=7.8608 
[epoch 34] step 20/44: loss=7.8897 
[epoch 34] step 22/44: loss=7.8892 
[epoch 34] step 24/44: loss=7.8974 
[epoch 34] step 26/44: loss=7.9187 
[epoch 34] step 28/44: loss=7.9367 
[epoch 34] step 30/44: loss=7.9052 
[epoch 34] step 32/44: loss=7.9121 
[epoch 34] step 34/44: loss=7.8793 
[epoch 34] step 36/44: loss=7.9225 
[epoch 34] step 38/44: loss=7.9094 
[epoch 34] step 40/44: loss=7.9334 
[epoch 34] step 42/44: loss=7.9024 
[epoch 34] step 44/44: loss=7.9225 
[epoch 34] train_loss(avg per step)=15.8450 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=10.8241 qwk=('0.3852', '0.3362', '0.3206') averageQWK=0.3473 macroEMD=0.3653 tailR0=('0.2976', '0.1429', '0.0000') tailR0avg=0.1468
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    0    4    0
    18   22   41   14    3
    11   20   78   45    1
     1    0   15   41    2
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    3    2    5    0
    12   25   18   26    1
     4   33   42   86    1
     0    5    5   51    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   53   34   17    0
     0   48   71   61    0
     0    1   13   22    0
     0    0    0    0    0
[epoch 35] step 2/44: loss=8.0604 
[epoch 35] step 4/44: loss=8.0333 
[epoch 35] step 6/44: loss=8.0993 
[epoch 35] step 8/44: loss=8.1166 
[epoch 35] step 10/44: loss=7.9765 
[epoch 35] step 12/44: loss=7.8216 
[epoch 35] step 14/44: loss=7.8937 
[epoch 35] step 16/44: loss=7.9301 
[epoch 35] step 18/44: loss=7.9099 
[epoch 35] step 20/44: loss=7.9504 
[epoch 35] step 22/44: loss=7.9739 
[epoch 35] step 24/44: loss=7.9501 
[epoch 35] step 26/44: loss=7.9627 
[epoch 35] step 28/44: loss=7.9853 
[epoch 35] step 30/44: loss=7.9672 
[epoch 35] step 32/44: loss=7.9614 
[epoch 35] step 34/44: loss=7.9697 
[epoch 35] step 36/44: loss=7.9828 
[epoch 35] step 38/44: loss=7.9432 
[epoch 35] step 40/44: loss=7.9462 
[epoch 35] step 42/44: loss=7.9814 
[epoch 35] step 44/44: loss=7.9304 
[epoch 35] train_loss(avg per step)=15.8608 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=11.1098 qwk=('0.3768', '0.3454', '0.3277') averageQWK=0.3499 macroEMD=0.3654 tailR0=('0.2976', '0.1429', '0.0000') tailR0avg=0.1468
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    0    4    0
    19   18   43   15    3
    11   17   76   51    0
     1    0   15   41    2
     0    0    0    5    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    2    2    6    0
    11   28   17   26    0
     4   27   40   94    1
     0    5    3   53    0
     0    0    0    2    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    1    0
     0   51   37   16    0
     0   43   77   60    0
     0    1   13   22    0
     0    0    0    0    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-1/fold2/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-1/fold2/metrics.json
Done.
