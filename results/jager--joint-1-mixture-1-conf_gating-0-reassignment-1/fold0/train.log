[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=19.5936 
[epoch 1] step 4/44: loss=19.5454 
[epoch 1] step 6/44: loss=19.4777 
[epoch 1] step 8/44: loss=19.3924 
[epoch 1] step 10/44: loss=19.3834 
[epoch 1] step 12/44: loss=19.3304 
[epoch 1] step 14/44: loss=19.2808 
[epoch 1] step 16/44: loss=19.2846 
[epoch 1] step 18/44: loss=19.3055 
[epoch 1] step 20/44: loss=19.2303 
[epoch 1] step 22/44: loss=19.2516 
[epoch 1] step 24/44: loss=19.2130 
[epoch 1] step 26/44: loss=19.1660 
[epoch 1] step 28/44: loss=19.0598 
[epoch 1] step 30/44: loss=19.0461 
[epoch 1] step 32/44: loss=18.9697 
[epoch 1] step 34/44: loss=18.9158 
[epoch 1] step 36/44: loss=18.8264 
[epoch 1] step 38/44: loss=18.7582 
[epoch 1] step 40/44: loss=18.7321 
[epoch 1] step 42/44: loss=18.7416 
[epoch 1] step 44/44: loss=18.6735 
[epoch 1] train_loss(avg per step)=37.3470 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=32.8501 qwk=('-0.0077', '0.1022', '-0.0578') averageQWK=0.0122 macroEMD=0.3964 tailR0=('0.0000', '0.1667', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   15    0    0    0
     0   75    0    3    0
     0  162    0    0    0
     0   64    0    0    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    4    0    0
     7    0    9    0    0
    33    0   33    0    0
    50    0  155    0    0
     2    0   28    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   27    0    0
     0    2  109    0    0
     0   22  159    0    0
     0    0    1    0    0
[epoch 2] step 2/44: loss=18.8496 
[epoch 2] step 4/44: loss=18.5158 
[epoch 2] step 6/44: loss=17.8556 
[epoch 2] step 8/44: loss=17.6709 
[epoch 2] step 10/44: loss=17.3172 
[epoch 2] step 12/44: loss=17.1359 
[epoch 2] step 14/44: loss=16.8205 
[epoch 2] step 16/44: loss=16.6010 
[epoch 2] step 18/44: loss=16.4341 
[epoch 2] step 20/44: loss=16.2961 
[epoch 2] step 22/44: loss=16.2037 
[epoch 2] step 24/44: loss=16.0573 
[epoch 2] step 26/44: loss=15.8878 
[epoch 2] step 28/44: loss=15.7445 
[epoch 2] step 30/44: loss=15.5758 
[epoch 2] step 32/44: loss=15.4637 
[epoch 2] step 34/44: loss=15.3906 
[epoch 2] step 36/44: loss=15.2948 
[epoch 2] step 38/44: loss=15.2267 
[epoch 2] step 40/44: loss=15.1122 
[epoch 2] step 42/44: loss=14.9933 
[epoch 2] step 44/44: loss=14.9557 
[epoch 2] train_loss(avg per step)=29.9114 lambda[min,max]=[0.500000,1.000000]
[epoch 2] val_loss=15.3672 qwk=('0.1815', '0.0866', '0.0416') averageQWK=0.1033 macroEMD=0.3927 tailR0=('0.2500', '0.0000', '0.0000') tailR0avg=0.0833
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    0    0    0
     8    0    7    0    0
    14    7   52    5    0
    11    5  121   24    1
     2    2   57    3    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   14    2    0
     0    0   40   26    0
     0    0  118   87    0
     0    0   20   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   27    0    0
     1    2  108    0    0
     0    0  181    0    0
     0    0    1    0    0
[epoch 3] step 2/44: loss=13.9193 
[epoch 3] step 4/44: loss=13.7466 
[epoch 3] step 6/44: loss=13.7496 
[epoch 3] step 8/44: loss=13.5721 
[epoch 3] step 10/44: loss=13.5931 
[epoch 3] step 12/44: loss=13.2841 
[epoch 3] step 14/44: loss=13.1307 
[epoch 3] step 16/44: loss=13.0117 
[epoch 3] step 18/44: loss=13.0272 
[epoch 3] step 20/44: loss=13.0221 
[epoch 3] step 22/44: loss=13.0475 
[epoch 3] step 24/44: loss=12.9902 
[epoch 3] step 26/44: loss=12.8344 
[epoch 3] step 28/44: loss=12.7974 
[epoch 3] step 30/44: loss=12.7648 
[epoch 3] step 32/44: loss=12.6420 
[epoch 3] step 34/44: loss=12.5520 
[epoch 3] step 36/44: loss=12.5510 
[epoch 3] step 38/44: loss=12.5780 
[epoch 3] step 40/44: loss=12.5574 
[epoch 3] step 42/44: loss=12.5180 
[epoch 3] step 44/44: loss=12.5447 
[epoch 3] train_loss(avg per step)=25.0895 lambda[min,max]=[0.540153,1.000000]
[epoch 3] val_loss=24.6290 qwk=('0.0360', '0.0979', '0.0388') averageQWK=0.0575 macroEMD=0.3886 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    0   15    0    0
     0    0   75    3    0
     0    0  133   29    0
     0    0   62    2    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    1   15    0    0
     0    0   58    8    0
     0    3  149   53    0
     0    0   26    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    0   29    0    0
     0    0  111    0    0
     0    0  173    8    0
     0    0    1    0    0
[epoch 4] step 2/44: loss=12.6899 
[epoch 4] step 4/44: loss=12.8781 
[epoch 4] step 6/44: loss=12.7140 
[epoch 4] step 8/44: loss=12.4857 
[epoch 4] step 10/44: loss=12.3320 
[epoch 4] step 12/44: loss=12.0452 
[epoch 4] step 14/44: loss=11.9473 
[epoch 4] step 16/44: loss=11.9349 
[epoch 4] step 18/44: loss=11.8619 
[epoch 4] step 20/44: loss=11.8772 
[epoch 4] step 22/44: loss=11.9026 
[epoch 4] step 24/44: loss=11.8115 
[epoch 4] step 26/44: loss=11.8313 
[epoch 4] step 28/44: loss=11.7622 
[epoch 4] step 30/44: loss=11.6895 
[epoch 4] step 32/44: loss=11.7173 
[epoch 4] step 34/44: loss=11.7790 
[epoch 4] step 36/44: loss=11.7936 
[epoch 4] step 38/44: loss=11.7983 
[epoch 4] step 40/44: loss=11.8158 
[epoch 4] step 42/44: loss=11.8193 
[epoch 4] step 44/44: loss=11.8086 
[epoch 4] train_loss(avg per step)=23.6171 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=7.1443 qwk=('0.0285', '0.1153', '0.1790') averageQWK=0.1076 macroEMD=0.3929 tailR0=('0.0312', '0.0000', '0.0000') tailR0avg=0.0104
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   13    1    1    0
     0   66    1    8    3
     0  110   11   39    2
     0   53    4    3    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    3   12    1    0
     0   10   47    9    0
     0   28  127   50    0
     0    3   20    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   28    0    1    0
     0   59    0   52    0
     0   87    0   94    0
     0    0    0    1    0
[epoch 5] step 2/44: loss=9.9789 
[epoch 5] step 4/44: loss=10.6634 
[epoch 5] step 6/44: loss=11.2552 
[epoch 5] step 8/44: loss=11.2447 
[epoch 5] step 10/44: loss=11.1906 
[epoch 5] step 12/44: loss=11.0139 
[epoch 5] step 14/44: loss=11.0941 
[epoch 5] step 16/44: loss=11.1157 
[epoch 5] step 18/44: loss=11.0721 
[epoch 5] step 20/44: loss=11.0124 
[epoch 5] step 22/44: loss=11.1098 
[epoch 5] step 24/44: loss=11.1759 
[epoch 5] step 26/44: loss=11.1619 
[epoch 5] step 28/44: loss=11.0785 
[epoch 5] step 30/44: loss=11.0485 
[epoch 5] step 32/44: loss=11.0725 
[epoch 5] step 34/44: loss=10.9994 
[epoch 5] step 36/44: loss=10.9459 
[epoch 5] step 38/44: loss=10.8883 
[epoch 5] step 40/44: loss=10.8369 
[epoch 5] step 42/44: loss=10.7775 
[epoch 5] step 44/44: loss=10.7493 
[epoch 5] train_loss(avg per step)=21.4986 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=18.7656 qwk=('0.0156', '0.0763', '0.0659') averageQWK=0.0526 macroEMD=0.3874 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    0   15    0    0
     0    0   78    0    0
     0    0  149   13    0
     0    0   63    1    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    1   15    0    0
     0    5   61    0    0
     0    8  192    5    0
     0    0   30    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    5   24    0    0
     0    2  109    0    0
     0    2  178    1    0
     0    0    1    0    0
[epoch 6] step 2/44: loss=10.1866 
[epoch 6] step 4/44: loss=10.2657 
[epoch 6] step 6/44: loss=10.1316 
[epoch 6] step 8/44: loss=9.8189 
[epoch 6] step 10/44: loss=9.7667 
[epoch 6] step 12/44: loss=9.5829 
[epoch 6] step 14/44: loss=9.4997 
[epoch 6] step 16/44: loss=9.4460 
[epoch 6] step 18/44: loss=9.4524 
[epoch 6] step 20/44: loss=9.5173 
[epoch 6] step 22/44: loss=9.6042 
[epoch 6] step 24/44: loss=9.5983 
[epoch 6] step 26/44: loss=9.6371 
[epoch 6] step 28/44: loss=9.6391 
[epoch 6] step 30/44: loss=9.6303 
[epoch 6] step 32/44: loss=9.5407 
[epoch 6] step 34/44: loss=9.4096 
[epoch 6] step 36/44: loss=9.3701 
[epoch 6] step 38/44: loss=9.3680 
[epoch 6] step 40/44: loss=9.4016 
[epoch 6] step 42/44: loss=9.3919 
[epoch 6] step 44/44: loss=9.3675 
[epoch 6] train_loss(avg per step)=18.7351 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=11.2679 qwk=('0.3038', '0.2602', '0.2107') averageQWK=0.2582 macroEMD=0.3822 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    8    2    5    0
     0   19    9   50    0
     0   14    8  140    0
     0    7    4   53    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    2    0
     0    1    6    9    0
     0    0    7   59    0
     0    1   10  194    0
     0    0    1   29    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   10   19    0    0
     0    6   99    6    0
     0    8  144   29    0
     0    0    1    0    0
[epoch 7] step 2/44: loss=8.5440 
[epoch 7] step 4/44: loss=8.1436 
[epoch 7] step 6/44: loss=8.0553 
[epoch 7] step 8/44: loss=8.1212 
[epoch 7] step 10/44: loss=8.2907 
[epoch 7] step 12/44: loss=8.5454 
[epoch 7] step 14/44: loss=8.9074 
[epoch 7] step 16/44: loss=8.9107 
[epoch 7] step 18/44: loss=8.8020 
[epoch 7] step 20/44: loss=8.6493 
[epoch 7] step 22/44: loss=8.5265 
[epoch 7] step 24/44: loss=8.4497 
[epoch 7] step 26/44: loss=8.5670 
[epoch 7] step 28/44: loss=8.6912 
[epoch 7] step 30/44: loss=8.7489 
[epoch 7] step 32/44: loss=8.7340 
[epoch 7] step 34/44: loss=8.6809 
[epoch 7] step 36/44: loss=8.6408 
[epoch 7] step 38/44: loss=8.5895 
[epoch 7] step 40/44: loss=8.6132 
[epoch 7] step 42/44: loss=8.6582 
[epoch 7] step 44/44: loss=8.6838 
[epoch 7] train_loss(avg per step)=17.3676 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=16.6964 qwk=('0.2158', '0.0207', '0.1214') averageQWK=0.1193 macroEMD=0.3834 tailR0=('0.1250', '0.0000', '0.0000') tailR0avg=0.0417
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     0    0   11    4    0
     0    0   39   39    0
     0    0   48  114    0
     0    0   24   40    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   16    0    0
     0    0   62    4    0
     0    0  185   20    0
     0    0   29    1    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    1   28    0    0
     0    0  105    6    0
     0    0  153   28    0
     0    0    1    0    0
[epoch 8] step 2/44: loss=8.4267 
[epoch 8] step 4/44: loss=7.9405 
[epoch 8] step 6/44: loss=7.8130 
[epoch 8] step 8/44: loss=7.7840 
[epoch 8] step 10/44: loss=7.9034 
[epoch 8] step 12/44: loss=8.1889 
[epoch 8] step 14/44: loss=8.2454 
[epoch 8] step 16/44: loss=8.4450 
[epoch 8] step 18/44: loss=8.6165 
[epoch 8] step 20/44: loss=8.6591 
[epoch 8] step 22/44: loss=8.6575 
[epoch 8] step 24/44: loss=8.6331 
[epoch 8] step 26/44: loss=8.5537 
[epoch 8] step 28/44: loss=8.4931 
[epoch 8] step 30/44: loss=8.4479 
[epoch 8] step 32/44: loss=8.4243 
[epoch 8] step 34/44: loss=8.3959 
[epoch 8] step 36/44: loss=8.4246 
[epoch 8] step 38/44: loss=8.4675 
[epoch 8] step 40/44: loss=8.4959 
[epoch 8] step 42/44: loss=8.4831 
[epoch 8] step 44/44: loss=8.4427 
[epoch 8] train_loss(avg per step)=16.8853 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=13.1013 qwk=('0.0650', '0.3118', '0.2991') averageQWK=0.2253 macroEMD=0.3791 tailR0=('0.0000', '0.0833', '0.0000') tailR0avg=0.0278
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    0   14    1    0
     0    0   67   11    0
     0    0  120   42    0
     0    0   52   12    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    4    1    0
     0    0   13    3    0
     0    0   34   32    0
     0    0   60  145    0
     0    0    6   24    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   26    1    0
     0    1   89   21    0
     0    0  104   77    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=7.9818 
[epoch 9] step 4/44: loss=8.3646 
[epoch 9] step 6/44: loss=8.4385 
[epoch 9] step 8/44: loss=8.1483 
[epoch 9] step 10/44: loss=7.9884 
[epoch 9] step 12/44: loss=7.8967 
[epoch 9] step 14/44: loss=7.8445 
[epoch 9] step 16/44: loss=7.8194 
[epoch 9] step 18/44: loss=7.9826 
[epoch 9] step 20/44: loss=8.1645 
[epoch 9] step 22/44: loss=8.2364 
[epoch 9] step 24/44: loss=8.2947 
[epoch 9] step 26/44: loss=8.2900 
[epoch 9] step 28/44: loss=8.2043 
[epoch 9] step 30/44: loss=8.0975 
[epoch 9] step 32/44: loss=8.0648 
[epoch 9] step 34/44: loss=8.0168 
[epoch 9] step 36/44: loss=8.0105 
[epoch 9] step 38/44: loss=8.0857 
[epoch 9] step 40/44: loss=8.1537 
[epoch 9] step 42/44: loss=8.1800 
[epoch 9] step 44/44: loss=8.2060 
[epoch 9] train_loss(avg per step)=16.4119 lambda[min,max]=[0.537973,1.000000]
[epoch 9] val_loss=14.1922 qwk=('0.1300', '0.2547', '0.1589') averageQWK=0.1812 macroEMD=0.3758 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    0   13    2    0
     0    0   61   17    0
     0    0   97   65    0
     0    0   42   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    1   12    3    0
     0    2   34   30    0
     0    1   96  108    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   27    0    0
     0    1  106    4    0
     0    0  150   31    0
     0    0    1    0    0
[epoch 10] step 2/44: loss=8.4307 
[epoch 10] step 4/44: loss=8.2166 
[epoch 10] step 6/44: loss=7.7519 
[epoch 10] step 8/44: loss=7.6017 
[epoch 10] step 10/44: loss=7.5576 
[epoch 10] step 12/44: loss=7.7982 
[epoch 10] step 14/44: loss=7.7982 
[epoch 10] step 16/44: loss=7.8564 
[epoch 10] step 18/44: loss=7.8462 
[epoch 10] step 20/44: loss=7.8860 
[epoch 10] step 22/44: loss=7.9596 
[epoch 10] step 24/44: loss=8.0549 
[epoch 10] step 26/44: loss=8.0472 
[epoch 10] step 28/44: loss=7.9676 
[epoch 10] step 30/44: loss=7.9168 
[epoch 10] step 32/44: loss=7.8515 
[epoch 10] step 34/44: loss=7.9062 
[epoch 10] step 36/44: loss=7.9300 
[epoch 10] step 38/44: loss=7.9246 
[epoch 10] step 40/44: loss=7.9313 
[epoch 10] step 42/44: loss=7.9423 
[epoch 10] step 44/44: loss=8.0384 
[epoch 10] train_loss(avg per step)=16.0769 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=19.8129 qwk=('0.1498', '0.2636', '0.2214') averageQWK=0.2116 macroEMD=0.3721 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    0   14    1    0
     0    0   64   14    0
     0    0  103   59    0
     0    0   39   25    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   13    3    0
     0    0   39   27    0
     0    0   80  125    0
     0    0    9   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    1   28    0    0
     0    1  106    4    0
     0    0  137   44    0
     0    0    0    1    0
[epoch 11] step 2/44: loss=9.4482 
[epoch 11] step 4/44: loss=9.3370 
[epoch 11] step 6/44: loss=8.6153 
[epoch 11] step 8/44: loss=7.9488 
[epoch 11] step 10/44: loss=7.7837 
[epoch 11] step 12/44: loss=7.4803 
[epoch 11] step 14/44: loss=7.5374 
[epoch 11] step 16/44: loss=7.8738 
[epoch 11] step 18/44: loss=8.1400 
[epoch 11] step 20/44: loss=8.2558 
[epoch 11] step 22/44: loss=8.3432 
[epoch 11] step 24/44: loss=8.2336 
[epoch 11] step 26/44: loss=8.1310 
[epoch 11] step 28/44: loss=8.0210 
[epoch 11] step 30/44: loss=7.9403 
[epoch 11] step 32/44: loss=7.9205 
[epoch 11] step 34/44: loss=7.9390 
[epoch 11] step 36/44: loss=8.0268 
[epoch 11] step 38/44: loss=8.0761 
[epoch 11] step 40/44: loss=8.0781 
[epoch 11] step 42/44: loss=8.0542 
[epoch 11] step 44/44: loss=7.9978 
[epoch 11] train_loss(avg per step)=15.9957 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=11.1884 qwk=('0.2463', '0.3406', '0.4091') averageQWK=0.3320 macroEMD=0.3730 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   11    1    0
     0    6   47   25    0
     0    1   73   88    0
     0    0   33   31    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    3   10    3    0
     0    7   30   29    0
     0    2   83  120    0
     0    0    9   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   12    0    0
     0   12   72   27    0
     0    7   94   80    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=7.4315 
[epoch 12] step 4/44: loss=8.3500 
[epoch 12] step 6/44: loss=8.2037 
[epoch 12] step 8/44: loss=8.0941 
[epoch 12] step 10/44: loss=8.0625 
[epoch 12] step 12/44: loss=7.9167 
[epoch 12] step 14/44: loss=7.8894 
[epoch 12] step 16/44: loss=7.9588 
[epoch 12] step 18/44: loss=8.0230 
[epoch 12] step 20/44: loss=8.0579 
[epoch 12] step 22/44: loss=8.0790 
[epoch 12] step 24/44: loss=7.9998 
[epoch 12] step 26/44: loss=7.9121 
[epoch 12] step 28/44: loss=7.8663 
[epoch 12] step 30/44: loss=7.8267 
[epoch 12] step 32/44: loss=7.8472 
[epoch 12] step 34/44: loss=7.8963 
[epoch 12] step 36/44: loss=7.9799 
[epoch 12] step 38/44: loss=8.0252 
[epoch 12] step 40/44: loss=8.0859 
[epoch 12] step 42/44: loss=8.0624 
[epoch 12] step 44/44: loss=8.0701 
[epoch 12] train_loss(avg per step)=16.1401 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=10.3767 qwk=('0.2111', '0.3465', '0.2767') averageQWK=0.2781 macroEMD=0.3775 tailR0=('0.0469', '0.1667', '0.0000') tailR0avg=0.0712
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   11    0    0
     0    7   61    8    2
     2    0  123   29    8
     0    0   43   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    2    0    0
     0    2   11    3    0
     1    2   37   26    0
     0    0   93  112    0
     0    0    8   22    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0   15   93    3    0
     0    7  145   29    0
     0    0    1    0    0
[epoch 13] step 2/44: loss=6.2682 
[epoch 13] step 4/44: loss=6.2887 
[epoch 13] step 6/44: loss=6.3515 
[epoch 13] step 8/44: loss=6.8064 
[epoch 13] step 10/44: loss=7.0687 
[epoch 13] step 12/44: loss=7.3398 
[epoch 13] step 14/44: loss=7.4142 
[epoch 13] step 16/44: loss=7.3002 
[epoch 13] step 18/44: loss=7.2867 
[epoch 13] step 20/44: loss=7.3330 
[epoch 13] step 22/44: loss=7.4625 
[epoch 13] step 24/44: loss=7.6628 
[epoch 13] step 26/44: loss=7.7846 
[epoch 13] step 28/44: loss=7.8231 
[epoch 13] step 30/44: loss=7.8042 
[epoch 13] step 32/44: loss=7.7571 
[epoch 13] step 34/44: loss=7.7211 
[epoch 13] step 36/44: loss=7.6813 
[epoch 13] step 38/44: loss=7.6922 
[epoch 13] step 40/44: loss=7.7262 
[epoch 13] step 42/44: loss=7.7787 
[epoch 13] step 44/44: loss=7.8718 
[epoch 13] train_loss(avg per step)=15.7435 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=15.4252 qwk=('0.3580', '0.4062', '0.2926') averageQWK=0.3523 macroEMD=0.3718 tailR0=('0.0000', '0.1667', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4    5    6    0
     0    5   18   55    0
     0    2   10  150    0
     0    1    5   58    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    3    1    0
     0    1    8    7    0
     0    1   25   40    0
     0    0   22  183    0
     0    0    2   28    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    5   24    0    0
     0    1  103    7    0
     0    0  128   53    0
     0    0    0    1    0
[epoch 14] step 2/44: loss=8.7595 
[epoch 14] step 4/44: loss=8.2348 
[epoch 14] step 6/44: loss=7.7747 
[epoch 14] step 8/44: loss=7.5681 
[epoch 14] step 10/44: loss=7.6159 
[epoch 14] step 12/44: loss=7.6489 
[epoch 14] step 14/44: loss=7.6051 
[epoch 14] step 16/44: loss=7.8009 
[epoch 14] step 18/44: loss=7.9455 
[epoch 14] step 20/44: loss=8.0490 
[epoch 14] step 22/44: loss=7.9962 
[epoch 14] step 24/44: loss=7.9307 
[epoch 14] step 26/44: loss=7.8855 
[epoch 14] step 28/44: loss=7.8967 
[epoch 14] step 30/44: loss=7.9495 
[epoch 14] step 32/44: loss=8.0130 
[epoch 14] step 34/44: loss=8.0205 
[epoch 14] step 36/44: loss=8.0362 
[epoch 14] step 38/44: loss=8.0438 
[epoch 14] step 40/44: loss=8.0541 
[epoch 14] step 42/44: loss=8.0676 
[epoch 14] step 44/44: loss=8.0603 
[epoch 14] train_loss(avg per step)=16.1206 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=12.3418 qwk=('0.1629', '0.2641', '0.2644') averageQWK=0.2305 macroEMD=0.3773 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0   16   54    8    0
     0   15  108   38    1
     0    5   40   18    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    3   11    2    0
     0    7   41   18    0
     0    1  132   72    0
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   19   10    0    0
     0   29   74    8    0
     0   27  114   40    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=7.4084 
[epoch 15] step 4/44: loss=7.2301 
[epoch 15] step 6/44: loss=7.2687 
[epoch 15] step 8/44: loss=7.4203 
[epoch 15] step 10/44: loss=7.5770 
[epoch 15] step 12/44: loss=7.5533 
[epoch 15] step 14/44: loss=7.5362 
[epoch 15] step 16/44: loss=7.6416 
[epoch 15] step 18/44: loss=7.7210 
[epoch 15] step 20/44: loss=7.8094 
[epoch 15] step 22/44: loss=7.8601 
[epoch 15] step 24/44: loss=7.8321 
[epoch 15] step 26/44: loss=7.7641 
[epoch 15] step 28/44: loss=7.7711 
[epoch 15] step 30/44: loss=7.8049 
[epoch 15] step 32/44: loss=7.8243 
[epoch 15] step 34/44: loss=7.8474 
[epoch 15] step 36/44: loss=7.8578 
[epoch 15] step 38/44: loss=7.8678 
[epoch 15] step 40/44: loss=7.8743 
[epoch 15] step 42/44: loss=7.8628 
[epoch 15] step 44/44: loss=7.8174 
[epoch 15] train_loss(avg per step)=15.6349 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=15.0403 qwk=('0.1870', '0.2549', '0.4202') averageQWK=0.2874 macroEMD=0.3748 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   12    0    0
     0    4   65    9    0
     0    1  113   46    2
     0    0   44   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    2   12    2    0
     0    4   44   18    0
     0    0  120   85    0
     0    0   13   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   14   15    0    0
     0   13   80   18    0
     0    6   96   79    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=8.1354 
[epoch 16] step 4/44: loss=8.2393 
[epoch 16] step 6/44: loss=8.3995 
[epoch 16] step 8/44: loss=8.3295 
[epoch 16] step 10/44: loss=8.2073 
[epoch 16] step 12/44: loss=7.9473 
[epoch 16] step 14/44: loss=7.8811 
[epoch 16] step 16/44: loss=7.8280 
[epoch 16] step 18/44: loss=7.7357 
[epoch 16] step 20/44: loss=7.8326 
[epoch 16] step 22/44: loss=7.8432 
[epoch 16] step 24/44: loss=7.7994 
[epoch 16] step 26/44: loss=7.8796 
[epoch 16] step 28/44: loss=7.9188 
[epoch 16] step 30/44: loss=7.9552 
[epoch 16] step 32/44: loss=8.0231 
[epoch 16] step 34/44: loss=8.0723 
[epoch 16] step 36/44: loss=8.1271 
[epoch 16] step 38/44: loss=8.1319 
[epoch 16] step 40/44: loss=8.1050 
[epoch 16] step 42/44: loss=8.0147 
[epoch 16] step 44/44: loss=7.9603 
[epoch 16] train_loss(avg per step)=15.9205 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=10.9844 qwk=('0.3392', '0.4010', '0.4629') averageQWK=0.4011 macroEMD=0.3737 tailR0=('0.0391', '0.0000', '0.0000') tailR0avg=0.0130
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3    9    3    0
     0    3   42   30    3
     0    0   40  115    7
     0    0   18   41    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2    8    6    0
     0    7   24   35    0
     0    0   43  162    0
     0    0    5   25    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    9   16    4    0
     0    8   34   69    0
     0    1   29  151    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=8.3007 
[epoch 17] step 4/44: loss=7.9726 
[epoch 17] step 6/44: loss=7.8950 
[epoch 17] step 8/44: loss=7.8853 
[epoch 17] step 10/44: loss=8.0226 
[epoch 17] step 12/44: loss=8.2935 
[epoch 17] step 14/44: loss=8.4440 
[epoch 17] step 16/44: loss=8.5037 
[epoch 17] step 18/44: loss=8.3784 
[epoch 17] step 20/44: loss=8.2935 
[epoch 17] step 22/44: loss=8.1778 
[epoch 17] step 24/44: loss=8.1320 
[epoch 17] step 26/44: loss=8.0374 
[epoch 17] step 28/44: loss=8.0373 
[epoch 17] step 30/44: loss=8.0516 
[epoch 17] step 32/44: loss=8.1364 
[epoch 17] step 34/44: loss=8.1844 
[epoch 17] step 36/44: loss=8.1916 
[epoch 17] step 38/44: loss=8.1533 
[epoch 17] step 40/44: loss=8.0978 
[epoch 17] step 42/44: loss=8.0712 
[epoch 17] step 44/44: loss=8.0480 
[epoch 17] train_loss(avg per step)=16.0959 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=14.6453 qwk=('0.1502', '0.2730', '0.2294') averageQWK=0.2175 macroEMD=0.3764 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    1   14    0    0
     1    2   63   11    1
     0    0  116   43    3
     0    0   45   18    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    4   10    2    0
     0    7   40   19    0
     0    0  121   84    0
     0    0   13   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   22    0    0
     0    2  106    3    0
     0    0  151   30    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=8.0712 
[epoch 18] step 4/44: loss=7.7751 
[epoch 18] step 6/44: loss=8.1280 
[epoch 18] step 8/44: loss=8.2691 
[epoch 18] step 10/44: loss=8.1778 
[epoch 18] step 12/44: loss=8.1454 
[epoch 18] step 14/44: loss=8.0929 
[epoch 18] step 16/44: loss=8.0532 
[epoch 18] step 18/44: loss=8.0687 
[epoch 18] step 20/44: loss=8.0865 
[epoch 18] step 22/44: loss=8.0182 
[epoch 18] step 24/44: loss=7.9969 
[epoch 18] step 26/44: loss=7.8775 
[epoch 18] step 28/44: loss=7.8050 
[epoch 18] step 30/44: loss=7.7899 
[epoch 18] step 32/44: loss=7.8273 
[epoch 18] step 34/44: loss=7.8572 
[epoch 18] step 36/44: loss=7.8837 
[epoch 18] step 38/44: loss=7.9118 
[epoch 18] step 40/44: loss=7.9379 
[epoch 18] step 42/44: loss=7.9628 
[epoch 18] step 44/44: loss=7.9201 
[epoch 18] train_loss(avg per step)=15.8402 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=12.4259 qwk=('0.3072', '0.3584', '0.3667') averageQWK=0.3441 macroEMD=0.3743 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   11    1    0
     0    4   51   22    1
     0    2   60   99    1
     0    0   27   35    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    2   11    3    0
     0    6   31   29    0
     0    1   64  140    0
     0    0    8   22    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    9   20    0    0
     0    8   88   15    0
     0    3  110   68    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=8.1946 
[epoch 19] step 4/44: loss=8.1158 
[epoch 19] step 6/44: loss=7.9824 
[epoch 19] step 8/44: loss=7.7487 
[epoch 19] step 10/44: loss=7.6319 
[epoch 19] step 12/44: loss=7.5715 
[epoch 19] step 14/44: loss=7.6183 
[epoch 19] step 16/44: loss=7.7020 
[epoch 19] step 18/44: loss=7.9147 
[epoch 19] step 20/44: loss=8.0876 
[epoch 19] step 22/44: loss=8.1389 
[epoch 19] step 24/44: loss=8.1714 
[epoch 19] step 26/44: loss=8.1584 
[epoch 19] step 28/44: loss=8.0533 
[epoch 19] step 30/44: loss=7.9846 
[epoch 19] step 32/44: loss=7.9412 
[epoch 19] step 34/44: loss=7.8628 
[epoch 19] step 36/44: loss=7.8480 
[epoch 19] step 38/44: loss=7.8365 
[epoch 19] step 40/44: loss=7.8473 
[epoch 19] step 42/44: loss=7.8752 
[epoch 19] step 44/44: loss=7.8840 
[epoch 19] train_loss(avg per step)=15.7679 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=17.1834 qwk=('0.2834', '0.2521', '0.3303') averageQWK=0.2886 macroEMD=0.3726 tailR0=('0.0547', '0.0000', '0.0000') tailR0avg=0.0182
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    2   50   23    3
     0    1   60   92    9
     0    0   29   28    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    1   12    3    0
     0    1   40   24    1
     0    0   99  105    1
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    6   23    0    0
     0    3   92   16    0
     0    0  114   67    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=9.5696 
[epoch 20] step 4/44: loss=9.3304 
[epoch 20] step 6/44: loss=9.0229 
[epoch 20] step 8/44: loss=8.7844 
[epoch 20] step 10/44: loss=8.5689 
[epoch 20] step 12/44: loss=8.3768 
[epoch 20] step 14/44: loss=8.4324 
[epoch 20] step 16/44: loss=8.4394 
[epoch 20] step 18/44: loss=8.2794 
[epoch 20] step 20/44: loss=8.1472 
[epoch 20] step 22/44: loss=8.0106 
[epoch 20] step 24/44: loss=7.8807 
[epoch 20] step 26/44: loss=7.8110 
[epoch 20] step 28/44: loss=7.7101 
[epoch 20] step 30/44: loss=7.6821 
[epoch 20] step 32/44: loss=7.7306 
[epoch 20] step 34/44: loss=7.8569 
[epoch 20] step 36/44: loss=7.9581 
[epoch 20] step 38/44: loss=8.0544 
[epoch 20] step 40/44: loss=8.0822 
[epoch 20] step 42/44: loss=8.0974 
[epoch 20] step 44/44: loss=8.0448 
[epoch 20] train_loss(avg per step)=16.0897 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=10.8792 qwk=('0.2467', '0.3173', '0.3456') averageQWK=0.3032 macroEMD=0.3756 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     1    5    8    1    0
     0   11   44   21    2
     2    9   61   84    6
     0    4   28   29    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    5    9    2    0
     0    9   31   26    0
     0    2  100  103    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   11    1    0
     0   26   57   28    0
     0   19   80   82    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=7.1696 
[epoch 21] step 4/44: loss=7.2406 
[epoch 21] step 6/44: loss=7.4182 
[epoch 21] step 8/44: loss=7.5104 
[epoch 21] step 10/44: loss=7.6174 
[epoch 21] step 12/44: loss=7.6829 
[epoch 21] step 14/44: loss=7.6863 
[epoch 21] step 16/44: loss=7.7660 
[epoch 21] step 18/44: loss=7.8092 
[epoch 21] step 20/44: loss=7.7109 
[epoch 21] step 22/44: loss=7.6409 
[epoch 21] step 24/44: loss=7.6003 
[epoch 21] step 26/44: loss=7.5984 
[epoch 21] step 28/44: loss=7.6353 
[epoch 21] step 30/44: loss=7.7027 
[epoch 21] step 32/44: loss=7.7504 
[epoch 21] step 34/44: loss=7.8380 
[epoch 21] step 36/44: loss=7.8617 
[epoch 21] step 38/44: loss=7.8548 
[epoch 21] step 40/44: loss=7.8464 
[epoch 21] step 42/44: loss=7.8338 
[epoch 21] step 44/44: loss=7.8055 
[epoch 21] train_loss(avg per step)=15.6109 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=11.8544 qwk=('0.2349', '0.2145', '0.3046') averageQWK=0.2513 macroEMD=0.3779 tailR0=('0.0391', '0.0000', '0.0000') tailR0avg=0.0130
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    4   52   20    2
     3    1   77   76    5
     0    0   32   27    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    1   13    2    0
     0    2   44   20    0
     0    0  125   80    0
     0    0   14   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    7   22    0    0
     0    3  102    6    0
     0    1  133   47    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=7.6264 
[epoch 22] step 4/44: loss=7.6457 
[epoch 22] step 6/44: loss=7.7468 
[epoch 22] step 8/44: loss=7.9093 
[epoch 22] step 10/44: loss=8.0685 
[epoch 22] step 12/44: loss=7.9928 
[epoch 22] step 14/44: loss=7.9924 
[epoch 22] step 16/44: loss=8.0372 
[epoch 22] step 18/44: loss=8.0440 
[epoch 22] step 20/44: loss=8.0518 
[epoch 22] step 22/44: loss=7.9444 
[epoch 22] step 24/44: loss=7.8723 
[epoch 22] step 26/44: loss=7.8351 
[epoch 22] step 28/44: loss=7.7826 
[epoch 22] step 30/44: loss=7.7971 
[epoch 22] step 32/44: loss=7.8059 
[epoch 22] step 34/44: loss=7.8185 
[epoch 22] step 36/44: loss=7.8180 
[epoch 22] step 38/44: loss=7.8931 
[epoch 22] step 40/44: loss=7.9215 
[epoch 22] step 42/44: loss=7.9366 
[epoch 22] step 44/44: loss=7.9222 
[epoch 22] train_loss(avg per step)=15.8444 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=12.8283 qwk=('0.1914', '0.3401', '0.3623') averageQWK=0.2979 macroEMD=0.3735 tailR0=('0.0312', '0.0000', '0.0000') tailR0avg=0.0104
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   11    0    0
     0    8   52   16    2
     0    4   96   57    5
     0    4   37   19    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    6    3    0
     0   10   32   24    0
     1    7   82  114    1
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   16    0    0
     0   17   82   12    0
     0   11  103   67    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=7.6490 
[epoch 23] step 4/44: loss=8.2050 
[epoch 23] step 6/44: loss=8.0688 
[epoch 23] step 8/44: loss=8.0417 
[epoch 23] step 10/44: loss=8.0416 
[epoch 23] step 12/44: loss=7.9710 
[epoch 23] step 14/44: loss=7.8973 
[epoch 23] step 16/44: loss=7.9419 
[epoch 23] step 18/44: loss=7.9734 
[epoch 23] step 20/44: loss=8.0778 
[epoch 23] step 22/44: loss=8.1652 
[epoch 23] step 24/44: loss=8.1928 
[epoch 23] step 26/44: loss=8.1123 
[epoch 23] step 28/44: loss=8.0905 
[epoch 23] step 30/44: loss=8.0369 
[epoch 23] step 32/44: loss=8.0116 
[epoch 23] step 34/44: loss=7.9429 
[epoch 23] step 36/44: loss=7.8831 
[epoch 23] step 38/44: loss=7.8820 
[epoch 23] step 40/44: loss=7.9215 
[epoch 23] step 42/44: loss=7.9479 
[epoch 23] step 44/44: loss=7.9615 
[epoch 23] train_loss(avg per step)=15.9230 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=15.4166 qwk=('0.1543', '0.1805', '0.2262') averageQWK=0.1870 macroEMD=0.3788 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   11    1    0
     0    6   59   11    2
     0    3  109   46    4
     0    1   46   15    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    1   13    2    0
     0    5   46   15    0
     0    0  146   59    0
     0    0   19   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    8   21    0    0
     0    5  101    5    0
     0    4  144   33    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=8.5710 
[epoch 24] step 4/44: loss=8.0946 
[epoch 24] step 6/44: loss=8.1553 
[epoch 24] step 8/44: loss=8.0769 
[epoch 24] step 10/44: loss=7.9437 
[epoch 24] step 12/44: loss=7.9234 
[epoch 24] step 14/44: loss=7.7945 
[epoch 24] step 16/44: loss=7.7411 
[epoch 24] step 18/44: loss=7.7300 
[epoch 24] step 20/44: loss=7.8460 
[epoch 24] step 22/44: loss=7.9250 
[epoch 24] step 24/44: loss=7.8873 
[epoch 24] step 26/44: loss=7.8579 
[epoch 24] step 28/44: loss=7.8101 
[epoch 24] step 30/44: loss=7.8086 
[epoch 24] step 32/44: loss=7.8354 
[epoch 24] step 34/44: loss=7.8450 
[epoch 24] step 36/44: loss=7.8645 
[epoch 24] step 38/44: loss=7.8556 
[epoch 24] step 40/44: loss=7.8401 
[epoch 24] step 42/44: loss=7.8780 
[epoch 24] step 44/44: loss=7.9110 
[epoch 24] train_loss(avg per step)=15.8220 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=13.5536 qwk=('0.1963', '0.1934', '0.2284') averageQWK=0.2060 macroEMD=0.3768 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    6   51   19    2
     0    5   83   69    5
     0    4   33   24    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    1   13    2    0
     0    4   44   18    0
     0    0  131   74    0
     0    0   17   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   13   16    0    0
     0   23   83    5    0
     0   23  122   36    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=7.8336 
[epoch 25] step 4/44: loss=7.8032 
[epoch 25] step 6/44: loss=7.7161 
[epoch 25] step 8/44: loss=7.7863 
[epoch 25] step 10/44: loss=7.6855 
[epoch 25] step 12/44: loss=7.5766 
[epoch 25] step 14/44: loss=7.5908 
[epoch 25] step 16/44: loss=7.7137 
[epoch 25] step 18/44: loss=7.7730 
[epoch 25] step 20/44: loss=7.7256 
[epoch 25] step 22/44: loss=7.8181 
[epoch 25] step 24/44: loss=7.8565 
[epoch 25] step 26/44: loss=7.9130 
[epoch 25] step 28/44: loss=7.9622 
[epoch 25] step 30/44: loss=7.9506 
[epoch 25] step 32/44: loss=7.9215 
[epoch 25] step 34/44: loss=7.9165 
[epoch 25] step 36/44: loss=7.9217 
[epoch 25] step 38/44: loss=7.9155 
[epoch 25] step 40/44: loss=7.8763 
[epoch 25] step 42/44: loss=7.8534 
[epoch 25] step 44/44: loss=7.8198 
[epoch 25] train_loss(avg per step)=15.6396 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=11.9954 qwk=('0.1679', '0.2438', '0.3044') averageQWK=0.2387 macroEMD=0.3787 tailR0=('0.0469', '0.0000', '0.0000') tailR0avg=0.0156
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   11    0    0
     1    8   59    8    2
     2    5  116   33    6
     0    3   45   10    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    5    9    2    0
     0    8   40   18    0
     0    2  130   73    0
     0    0   17   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   10   19    0    0
     0    6   98    7    0
     0    6  127   48    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=7.8735 
[epoch 26] step 4/44: loss=7.5036 
[epoch 26] step 6/44: loss=7.6265 
[epoch 26] step 8/44: loss=7.8060 
[epoch 26] step 10/44: loss=7.9812 
[epoch 26] step 12/44: loss=8.1372 
[epoch 26] step 14/44: loss=8.1862 
[epoch 26] step 16/44: loss=8.0924 
[epoch 26] step 18/44: loss=8.1020 
[epoch 26] step 20/44: loss=8.0861 
[epoch 26] step 22/44: loss=8.0545 
[epoch 26] step 24/44: loss=8.0101 
[epoch 26] step 26/44: loss=7.9432 
[epoch 26] step 28/44: loss=7.9288 
[epoch 26] step 30/44: loss=7.9464 
[epoch 26] step 32/44: loss=7.9638 
[epoch 26] step 34/44: loss=7.9981 
[epoch 26] step 36/44: loss=8.0057 
[epoch 26] step 38/44: loss=8.0751 
[epoch 26] step 40/44: loss=8.0827 
[epoch 26] step 42/44: loss=8.0366 
[epoch 26] step 44/44: loss=8.0225 
[epoch 26] train_loss(avg per step)=16.0450 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=11.2632 qwk=('0.2008', '0.2889', '0.2843') averageQWK=0.2580 macroEMD=0.3792 tailR0=('0.0469', '0.0000', '0.0000') tailR0avg=0.0156
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    7   55   14    2
     2    4  100   47    9
     0    1   40   17    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    3   10    3    0
     0    7   36   23    0
     0    1  101  102    1
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   22    0    0
     0    4  100    7    0
     0    1  133   47    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=7.0539 
[epoch 27] step 4/44: loss=6.9437 
[epoch 27] step 6/44: loss=6.8883 
[epoch 27] step 8/44: loss=6.8701 
[epoch 27] step 10/44: loss=6.9752 
[epoch 27] step 12/44: loss=7.3553 
[epoch 27] step 14/44: loss=7.6480 
[epoch 27] step 16/44: loss=7.7528 
[epoch 27] step 18/44: loss=7.7794 
[epoch 27] step 20/44: loss=7.7902 
[epoch 27] step 22/44: loss=7.7861 
[epoch 27] step 24/44: loss=7.7889 
[epoch 27] step 26/44: loss=7.7745 
[epoch 27] step 28/44: loss=7.7771 
[epoch 27] step 30/44: loss=7.7667 
[epoch 27] step 32/44: loss=7.7899 
[epoch 27] step 34/44: loss=7.8241 
[epoch 27] step 36/44: loss=7.8445 
[epoch 27] step 38/44: loss=7.8776 
[epoch 27] step 40/44: loss=7.8901 
[epoch 27] step 42/44: loss=7.9055 
[epoch 27] step 44/44: loss=7.9531 
[epoch 27] train_loss(avg per step)=15.9063 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=12.1563 qwk=('0.2488', '0.3403', '0.3026') averageQWK=0.2972 macroEMD=0.3766 tailR0=('0.0547', '0.0167', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    8   50   18    2
     1    4   80   70    7
     0    1   35   21    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   10    2    0
     0    8   37   21    0
     0    6   91  107    1
     0    0   11   18    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    6   23    0    0
     0    7   98    6    0
     0    2  130   49    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=7.7333 
[epoch 28] step 4/44: loss=8.1767 
[epoch 28] step 6/44: loss=7.9535 
[epoch 28] step 8/44: loss=7.8465 
[epoch 28] step 10/44: loss=7.7615 
[epoch 28] step 12/44: loss=7.7246 
[epoch 28] step 14/44: loss=7.7640 
[epoch 28] step 16/44: loss=7.8321 
[epoch 28] step 18/44: loss=7.8553 
[epoch 28] step 20/44: loss=7.8191 
[epoch 28] step 22/44: loss=7.8266 
[epoch 28] step 24/44: loss=7.8525 
[epoch 28] step 26/44: loss=7.8307 
[epoch 28] step 28/44: loss=7.7982 
[epoch 28] step 30/44: loss=7.8223 
[epoch 28] step 32/44: loss=7.7539 
[epoch 28] step 34/44: loss=7.8070 
[epoch 28] step 36/44: loss=7.7922 
[epoch 28] step 38/44: loss=7.8314 
[epoch 28] step 40/44: loss=7.8461 
[epoch 28] step 42/44: loss=7.8723 
[epoch 28] step 44/44: loss=7.8809 
[epoch 28] train_loss(avg per step)=15.7619 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=13.8025 qwk=('0.2486', '0.2620', '0.3137') averageQWK=0.2748 macroEMD=0.3773 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0   10   48   19    1
     0    3   77   79    3
     0    1   35   26    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    2   12    2    0
     0    7   41   18    0
     0    1  124   80    0
     0    0   15   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    9   20    0    0
     0    5  100    6    0
     0    1  136   44    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=7.4255 
[epoch 29] step 4/44: loss=7.6467 
[epoch 29] step 6/44: loss=7.8031 
[epoch 29] step 8/44: loss=7.9049 
[epoch 29] step 10/44: loss=7.8398 
[epoch 29] step 12/44: loss=7.8931 
[epoch 29] step 14/44: loss=7.9126 
[epoch 29] step 16/44: loss=7.8203 
[epoch 29] step 18/44: loss=7.8231 
[epoch 29] step 20/44: loss=7.7861 
[epoch 29] step 22/44: loss=7.7477 
[epoch 29] step 24/44: loss=7.7586 
[epoch 29] step 26/44: loss=7.7880 
[epoch 29] step 28/44: loss=7.8413 
[epoch 29] step 30/44: loss=7.9238 
[epoch 29] step 32/44: loss=7.9366 
[epoch 29] step 34/44: loss=7.9633 
[epoch 29] step 36/44: loss=7.9818 
[epoch 29] step 38/44: loss=7.9204 
[epoch 29] step 40/44: loss=7.8614 
[epoch 29] step 42/44: loss=7.8374 
[epoch 29] step 44/44: loss=7.8013 
[epoch 29] train_loss(avg per step)=15.6026 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=12.7228 qwk=('0.1954', '0.2659', '0.2861') averageQWK=0.2491 macroEMD=0.3784 tailR0=('0.0391', '0.0000', '0.0000') tailR0avg=0.0130
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   11    0    0
     0    7   55   14    2
     0    3  106   47    6
     0    1   43   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6    8    2    0
     0    9   38   19    0
     0   13  110   81    1
     0    0   14   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    8   21    0    0
     0    4  101    6    0
     0    1  140   40    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=7.5573 
[epoch 30] step 4/44: loss=7.9426 
[epoch 30] step 6/44: loss=7.9428 
[epoch 30] step 8/44: loss=7.9972 
[epoch 30] step 10/44: loss=8.0877 
[epoch 30] step 12/44: loss=8.1458 
[epoch 30] step 14/44: loss=8.0359 
[epoch 30] step 16/44: loss=7.9853 
[epoch 30] step 18/44: loss=7.9042 
[epoch 30] step 20/44: loss=7.8857 
[epoch 30] step 22/44: loss=7.8710 
[epoch 30] step 24/44: loss=7.9182 
[epoch 30] step 26/44: loss=7.9173 
[epoch 30] step 28/44: loss=7.9182 
[epoch 30] step 30/44: loss=7.9142 
[epoch 30] step 32/44: loss=7.9147 
[epoch 30] step 34/44: loss=8.0002 
[epoch 30] step 36/44: loss=8.0043 
[epoch 30] step 38/44: loss=8.0144 
[epoch 30] step 40/44: loss=7.9931 
[epoch 30] step 42/44: loss=7.9956 
[epoch 30] step 44/44: loss=7.9905 
[epoch 30] train_loss(avg per step)=15.9810 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=13.2107 qwk=('0.1771', '0.2764', '0.2934') averageQWK=0.2489 macroEMD=0.3781 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    7   55   14    2
     0    3  102   51    6
     0    1   44   16    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    4   10    2    0
     0    8   37   21    0
     0    6  110   88    1
     0    0   14   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   10   19    0    0
     0    8   97    6    0
     0    5  134   42    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=8.2366 
[epoch 31] step 4/44: loss=7.9826 
[epoch 31] step 6/44: loss=8.0659 
[epoch 31] step 8/44: loss=8.2159 
[epoch 31] step 10/44: loss=8.0102 
[epoch 31] step 12/44: loss=8.0218 
[epoch 31] step 14/44: loss=7.9792 
[epoch 31] step 16/44: loss=8.0317 
[epoch 31] step 18/44: loss=8.0140 
[epoch 31] step 20/44: loss=8.0382 
[epoch 31] step 22/44: loss=8.0375 
[epoch 31] step 24/44: loss=8.0572 
[epoch 31] step 26/44: loss=7.9953 
[epoch 31] step 28/44: loss=7.9931 
[epoch 31] step 30/44: loss=7.9592 
[epoch 31] step 32/44: loss=7.9298 
[epoch 31] step 34/44: loss=7.9281 
[epoch 31] step 36/44: loss=7.9390 
[epoch 31] step 38/44: loss=7.9231 
[epoch 31] step 40/44: loss=7.9042 
[epoch 31] step 42/44: loss=7.9053 
[epoch 31] step 44/44: loss=7.8950 
[epoch 31] train_loss(avg per step)=15.7900 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=12.7741 qwk=('0.1882', '0.3653', '0.3436') averageQWK=0.2991 macroEMD=0.3762 tailR0=('0.0391', '0.0000', '0.0000') tailR0avg=0.0130
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    7   55   14    2
     0    2  103   51    6
     0    1   44   14    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    3   11    2    0
     0    8   35   23    0
     0    4   82  118    1
     0    0    9   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    9   20    0    0
     0    7   97    7    0
     0    3  123   55    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=6.9307 
[epoch 32] step 4/44: loss=7.6281 
[epoch 32] step 6/44: loss=7.8842 
[epoch 32] step 8/44: loss=8.0664 
[epoch 32] step 10/44: loss=8.0426 
[epoch 32] step 12/44: loss=8.1480 
[epoch 32] step 14/44: loss=8.2295 
[epoch 32] step 16/44: loss=8.2771 
[epoch 32] step 18/44: loss=8.1408 
[epoch 32] step 20/44: loss=8.1265 
[epoch 32] step 22/44: loss=8.1155 
[epoch 32] step 24/44: loss=8.1363 
[epoch 32] step 26/44: loss=8.1670 
[epoch 32] step 28/44: loss=8.1287 
[epoch 32] step 30/44: loss=8.1417 
[epoch 32] step 32/44: loss=8.0941 
[epoch 32] step 34/44: loss=8.1300 
[epoch 32] step 36/44: loss=8.1336 
[epoch 32] step 38/44: loss=8.1222 
[epoch 32] step 40/44: loss=8.0936 
[epoch 32] step 42/44: loss=8.0484 
[epoch 32] step 44/44: loss=8.0600 
[epoch 32] train_loss(avg per step)=16.1201 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=11.4413 qwk=('0.2051', '0.3306', '0.3784') averageQWK=0.3047 macroEMD=0.3784 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    7   53   16    2
     3    3   89   60    7
     0    1   37   23    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5    9    2    0
     0    9   34   23    0
     0    6   94  105    0
     0    0   11   19    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    9   20    0    0
     0    7   93   11    0
     0    1  116   64    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=8.3148 
[epoch 33] step 4/44: loss=7.8064 
[epoch 33] step 6/44: loss=7.9146 
[epoch 33] step 8/44: loss=7.8467 
[epoch 33] step 10/44: loss=7.8850 
[epoch 33] step 12/44: loss=7.8657 
[epoch 33] step 14/44: loss=7.8233 
[epoch 33] step 16/44: loss=7.8905 
[epoch 33] step 18/44: loss=7.8476 
[epoch 33] step 20/44: loss=7.8389 
[epoch 33] step 22/44: loss=7.8152 
[epoch 33] step 24/44: loss=7.8725 
[epoch 33] step 26/44: loss=7.8426 
[epoch 33] step 28/44: loss=7.7947 
[epoch 33] step 30/44: loss=7.8133 
[epoch 33] step 32/44: loss=7.8015 
[epoch 33] step 34/44: loss=7.7943 
[epoch 33] step 36/44: loss=7.8580 
[epoch 33] step 38/44: loss=7.8833 
[epoch 33] step 40/44: loss=7.9194 
[epoch 33] step 42/44: loss=7.9249 
[epoch 33] step 44/44: loss=7.9707 
[epoch 33] train_loss(avg per step)=15.9413 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=12.3715 qwk=('0.1936', '0.3047', '0.3339') averageQWK=0.2774 macroEMD=0.3781 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    9   51   16    2
     2    4   92   57    7
     0    1   40   20    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    7    2    0
     0    8   38   20    0
     0    9  100   96    0
     0    0   14   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    9   20    0    0
     0    7   98    6    0
     0    2  129   50    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=7.6452 
[epoch 34] step 4/44: loss=7.8460 
[epoch 34] step 6/44: loss=8.2635 
[epoch 34] step 8/44: loss=8.2621 
[epoch 34] step 10/44: loss=8.1895 
[epoch 34] step 12/44: loss=8.1622 
[epoch 34] step 14/44: loss=8.0249 
[epoch 34] step 16/44: loss=8.0081 
[epoch 34] step 18/44: loss=8.0372 
[epoch 34] step 20/44: loss=8.0547 
[epoch 34] step 22/44: loss=7.9693 
[epoch 34] step 24/44: loss=7.9590 
[epoch 34] step 26/44: loss=7.9048 
[epoch 34] step 28/44: loss=7.8721 
[epoch 34] step 30/44: loss=7.9097 
[epoch 34] step 32/44: loss=7.9130 
[epoch 34] step 34/44: loss=7.9264 
[epoch 34] step 36/44: loss=7.9737 
[epoch 34] step 38/44: loss=7.9802 
[epoch 34] step 40/44: loss=7.9876 
[epoch 34] step 42/44: loss=7.9842 
[epoch 34] step 44/44: loss=7.9882 
[epoch 34] train_loss(avg per step)=15.9764 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=12.3865 qwk=('0.1932', '0.2995', '0.3197') averageQWK=0.2708 macroEMD=0.3785 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    7   53   16    2
     1    4   93   57    7
     0    1   40   20    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2   12    2    0
     0    8   37   21    0
     0    4   96  105    0
     0    0   12   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    9   20    0    0
     0    7   97    7    0
     0    3  129   49    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=8.8691 
[epoch 35] step 4/44: loss=8.3926 
[epoch 35] step 6/44: loss=8.0281 
[epoch 35] step 8/44: loss=8.1041 
[epoch 35] step 10/44: loss=8.0005 
[epoch 35] step 12/44: loss=8.0038 
[epoch 35] step 14/44: loss=8.0011 
[epoch 35] step 16/44: loss=7.9802 
[epoch 35] step 18/44: loss=7.9699 
[epoch 35] step 20/44: loss=8.0003 
[epoch 35] step 22/44: loss=7.9758 
[epoch 35] step 24/44: loss=7.9627 
[epoch 35] step 26/44: loss=7.9585 
[epoch 35] step 28/44: loss=7.9002 
[epoch 35] step 30/44: loss=7.8831 
[epoch 35] step 32/44: loss=7.8769 
[epoch 35] step 34/44: loss=7.9044 
[epoch 35] step 36/44: loss=7.8876 
[epoch 35] step 38/44: loss=7.8572 
[epoch 35] step 40/44: loss=7.8541 
[epoch 35] step 42/44: loss=7.8841 
[epoch 35] step 44/44: loss=7.9034 
[epoch 35] train_loss(avg per step)=15.8068 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=12.1486 qwk=('0.2118', '0.2739', '0.3023') averageQWK=0.2627 macroEMD=0.3787 tailR0=('0.0234', '0.0000', '0.0000') tailR0avg=0.0078
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    4   10    1    0
     0    8   51   17    2
     1    4   90   61    6
     0    1   37   23    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    3   11    2    0
     0    8   38   20    0
     0    6  109   90    0
     0    0   14   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0    8   21    0    0
     0    7   98    6    0
     0    3  132   46    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-1/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-1/fold0/metrics.json
Done.
