[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=20.7788 
[epoch 1] step 4/44: loss=19.9471 
[epoch 1] step 6/44: loss=19.5771 
[epoch 1] step 8/44: loss=19.4205 
[epoch 1] step 10/44: loss=19.4950 
[epoch 1] step 12/44: loss=19.3459 
[epoch 1] step 14/44: loss=19.3803 
[epoch 1] step 16/44: loss=19.4659 
[epoch 1] step 18/44: loss=19.4891 
[epoch 1] step 20/44: loss=19.5060 
[epoch 1] step 22/44: loss=19.5668 
[epoch 1] step 24/44: loss=19.4941 
[epoch 1] step 26/44: loss=19.3833 
[epoch 1] step 28/44: loss=19.3298 
[epoch 1] step 30/44: loss=19.2462 
[epoch 1] step 32/44: loss=19.1938 
[epoch 1] step 34/44: loss=19.1802 
[epoch 1] step 36/44: loss=19.0885 
[epoch 1] step 38/44: loss=18.9507 
[epoch 1] step 40/44: loss=18.9184 
[epoch 1] step 42/44: loss=18.8761 
[epoch 1] step 44/44: loss=18.5719 
[epoch 1] train_loss(avg per step)=37.1437 lambda[min,max]=[0.500000,1.000000]
[epoch 1] val_loss=32.6955 qwk=('-0.0016', '0.0244', '0.0374') averageQWK=0.0201 macroEMD=0.4009 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    0    0    0
     0   41    0    0    0
     0  121    0    1    0
     0  141    0    0    0
     0   21    0    0    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    0    0
     6    0   33    0    0
    20    0   84    0    0
    18    0  145    0    0
     1    0   15    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    3   49    0    0
     0    4  154    0    0
     0    2  108    0    0
     0    1    2    0    0
[epoch 2] step 2/44: loss=17.5546 
[epoch 2] step 4/44: loss=18.4775 
[epoch 2] step 6/44: loss=18.1238 
[epoch 2] step 8/44: loss=17.8116 
[epoch 2] step 10/44: loss=17.7153 
[epoch 2] step 12/44: loss=17.3933 
[epoch 2] step 14/44: loss=17.0722 
[epoch 2] step 16/44: loss=16.7981 
[epoch 2] step 18/44: loss=16.6719 
[epoch 2] step 20/44: loss=16.4277 
[epoch 2] step 22/44: loss=16.2374 
[epoch 2] step 24/44: loss=16.0535 
[epoch 2] step 26/44: loss=15.8445 
[epoch 2] step 28/44: loss=15.6682 
[epoch 2] step 30/44: loss=15.4762 
[epoch 2] step 32/44: loss=15.3092 
[epoch 2] step 34/44: loss=15.1579 
[epoch 2] step 36/44: loss=15.0057 
[epoch 2] step 38/44: loss=14.8590 
[epoch 2] step 40/44: loss=14.7543 
[epoch 2] step 42/44: loss=14.6583 
[epoch 2] step 44/44: loss=14.6444 
[epoch 2] train_loss(avg per step)=29.2888 lambda[min,max]=[0.542191,1.000000]
[epoch 2] val_loss=17.7952 qwk=('0.0935', '0.3119', '0.3045') averageQWK=0.2366 macroEMD=0.3905 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    9    0
     2    1    1   37    0
     1    2    0  119    0
     0    0    0  141    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    1    0
     0    0   32    7    0
     0    0   82   22    0
     0    0   75   88    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     1    0   50    1    0
     0    0  126   32    0
     0    0   61   49    0
     0    0    1    2    0
[epoch 3] step 2/44: loss=12.1417 
[epoch 3] step 4/44: loss=12.7642 
[epoch 3] step 6/44: loss=12.5452 
[epoch 3] step 8/44: loss=12.6575 
[epoch 3] step 10/44: loss=12.6917 
[epoch 3] step 12/44: loss=12.7999 
[epoch 3] step 14/44: loss=12.8959 
[epoch 3] step 16/44: loss=12.9700 
[epoch 3] step 18/44: loss=12.9191 
[epoch 3] step 20/44: loss=12.8170 
[epoch 3] step 22/44: loss=12.7440 
[epoch 3] step 24/44: loss=12.7102 
[epoch 3] step 26/44: loss=12.6918 
[epoch 3] step 28/44: loss=12.6780 
[epoch 3] step 30/44: loss=12.6511 
[epoch 3] step 32/44: loss=12.5983 
[epoch 3] step 34/44: loss=12.5683 
[epoch 3] step 36/44: loss=12.5950 
[epoch 3] step 38/44: loss=12.5522 
[epoch 3] step 40/44: loss=12.5328 
[epoch 3] step 42/44: loss=12.4907 
[epoch 3] step 44/44: loss=12.4115 
[epoch 3] train_loss(avg per step)=24.8230 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=16.6448 qwk=('0.0124', '0.4771', '0.2075') averageQWK=0.2323 macroEMD=0.3904 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    0   41    0    0
     0    0  122    0    0
     0    0  138    3    0
     0    0   21    0    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    4    2    0
     0   17   11   11    0
     0   38   19   47    0
     0   13   12  138    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    0   52    0    0
     0    0  157    1    0
     0    0   88   22    0
     0    0    1    2    0
[epoch 4] step 2/44: loss=12.0178 
[epoch 4] step 4/44: loss=12.1750 
[epoch 4] step 6/44: loss=12.3143 
[epoch 4] step 8/44: loss=12.5452 
[epoch 4] step 10/44: loss=12.4346 
[epoch 4] step 12/44: loss=12.3432 
[epoch 4] step 14/44: loss=12.3625 
[epoch 4] step 16/44: loss=12.2973 
[epoch 4] step 18/44: loss=12.2175 
[epoch 4] step 20/44: loss=12.1568 
[epoch 4] step 22/44: loss=12.0409 
[epoch 4] step 24/44: loss=12.0211 
[epoch 4] step 26/44: loss=12.0474 
[epoch 4] step 28/44: loss=12.0828 
[epoch 4] step 30/44: loss=12.0607 
[epoch 4] step 32/44: loss=11.9981 
[epoch 4] step 34/44: loss=11.9422 
[epoch 4] step 36/44: loss=11.9565 
[epoch 4] step 38/44: loss=11.9252 
[epoch 4] step 40/44: loss=11.9145 
[epoch 4] step 42/44: loss=11.8724 
[epoch 4] step 44/44: loss=11.8543 
[epoch 4] train_loss(avg per step)=23.7086 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=11.4334 qwk=('0.1374', '0.3597', '0.3763') averageQWK=0.2911 macroEMD=0.3910 tailR0=('0.0238', '0.0000', '0.1667') tailR0avg=0.0635
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    0    0    0
     0   41    0    0    0
     0  120    0    2    0
     2  102    6   30    1
     2   13    1    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    4    0
     0    0   25   14    0
     0    1   54   49    0
     0    0   22  141    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    1    5    2    0
    12    0   12   28    0
     9    0   32  117    0
     0    0    1  109    0
     0    0    0    3    0
[epoch 5] step 2/44: loss=10.5094 
[epoch 5] step 4/44: loss=10.6098 
[epoch 5] step 6/44: loss=11.0001 
[epoch 5] step 8/44: loss=11.0837 
[epoch 5] step 10/44: loss=10.8473 
[epoch 5] step 12/44: loss=10.8259 
[epoch 5] step 14/44: loss=10.7279 
[epoch 5] step 16/44: loss=10.5687 
[epoch 5] step 18/44: loss=10.6338 
[epoch 5] step 20/44: loss=10.7086 
[epoch 5] step 22/44: loss=10.7340 
[epoch 5] step 24/44: loss=10.9016 
[epoch 5] step 26/44: loss=10.8836 
[epoch 5] step 28/44: loss=10.8120 
[epoch 5] step 30/44: loss=10.6674 
[epoch 5] step 32/44: loss=10.5868 
[epoch 5] step 34/44: loss=10.5405 
[epoch 5] step 36/44: loss=10.4876 
[epoch 5] step 38/44: loss=10.4603 
[epoch 5] step 40/44: loss=10.4373 
[epoch 5] step 42/44: loss=10.3830 
[epoch 5] step 44/44: loss=10.2720 
[epoch 5] train_loss(avg per step)=20.5440 lambda[min,max]=[0.500000,1.000000]
[epoch 5] val_loss=7.0821 qwk=('0.5336', '0.3029', '0.5474') averageQWK=0.4613 macroEMD=0.3857 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    1    0
     0   35    0    6    0
     0   62    1   59    0
     0   22    0  119    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    1    0
     1    0   32    6    0
     3    0   70   31    0
     4    0   54  105    0
     1    0    1   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   12    0    0    0
     0   34    8   10    0
     1   55   42   60    0
     0    6   13   91    0
     0    0    0    3    0
[epoch 6] step 2/44: loss=8.8815 
[epoch 6] step 4/44: loss=8.4285 
[epoch 6] step 6/44: loss=9.1072 
[epoch 6] step 8/44: loss=9.4555 
[epoch 6] step 10/44: loss=9.6340 
[epoch 6] step 12/44: loss=9.6746 
[epoch 6] step 14/44: loss=9.6830 
[epoch 6] step 16/44: loss=9.5329 
[epoch 6] step 18/44: loss=9.3924 
[epoch 6] step 20/44: loss=9.3127 
[epoch 6] step 22/44: loss=9.3144 
[epoch 6] step 24/44: loss=9.3666 
[epoch 6] step 26/44: loss=9.3680 
[epoch 6] step 28/44: loss=9.3898 
[epoch 6] step 30/44: loss=9.4044 
[epoch 6] step 32/44: loss=9.3713 
[epoch 6] step 34/44: loss=9.3223 
[epoch 6] step 36/44: loss=9.2251 
[epoch 6] step 38/44: loss=9.1253 
[epoch 6] step 40/44: loss=9.0646 
[epoch 6] step 42/44: loss=9.0928 
[epoch 6] step 44/44: loss=9.2182 
[epoch 6] train_loss(avg per step)=18.4363 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=18.0366 qwk=('0.2388', '0.4365', '0.4091') averageQWK=0.3615 macroEMD=0.3752 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    8   33    0    0
     0    5  116    1    0
     0    0  108   33    0
     0    0   18    3    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    1    0
     0    4   34    1    0
     0    8   71   25    0
     0    0   63  100    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   12    0    0    0
     0   44    5    3    0
     0  109   19   30    0
     0   28   24   58    0
     0    1    0    2    0
[epoch 7] step 2/44: loss=11.3617 
[epoch 7] step 4/44: loss=10.7084 
[epoch 7] step 6/44: loss=10.3654 
[epoch 7] step 8/44: loss=10.2525 
[epoch 7] step 10/44: loss=9.7809 
[epoch 7] step 12/44: loss=9.5794 
[epoch 7] step 14/44: loss=9.4490 
[epoch 7] step 16/44: loss=9.4274 
[epoch 7] step 18/44: loss=9.2871 
[epoch 7] step 20/44: loss=9.2997 
[epoch 7] step 22/44: loss=9.1687 
[epoch 7] step 24/44: loss=8.9667 
[epoch 7] step 26/44: loss=8.7913 
[epoch 7] step 28/44: loss=8.7081 
[epoch 7] step 30/44: loss=8.7637 
[epoch 7] step 32/44: loss=8.8311 
[epoch 7] step 34/44: loss=8.8569 
[epoch 7] step 36/44: loss=8.8086 
[epoch 7] step 38/44: loss=8.7747 
[epoch 7] step 40/44: loss=8.7791 
[epoch 7] step 42/44: loss=8.7614 
[epoch 7] step 44/44: loss=8.8101 
[epoch 7] train_loss(avg per step)=17.6202 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=12.4413 qwk=('0.2555', '0.2218', '0.1712') averageQWK=0.2162 macroEMD=0.3810 tailR0=('0.0476', '0.0000', '0.0000') tailR0avg=0.0159
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    2    0
     0    0   27    6    8
     0    0   45   64   13
     0    0   12  123    6
     0    0    0   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    7    0
     0    3    9   27    0
     0   11   17   76    0
     0    1   10  152    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    7    0
     0    0   21   31    0
     0    0   34  124    0
     0    0    4  106    0
     0    0    0    3    0
[epoch 8] step 2/44: loss=8.2254 
[epoch 8] step 4/44: loss=8.3764 
[epoch 8] step 6/44: loss=8.1397 
[epoch 8] step 8/44: loss=8.1938 
[epoch 8] step 10/44: loss=8.1790 
[epoch 8] step 12/44: loss=8.2420 
[epoch 8] step 14/44: loss=8.3324 
[epoch 8] step 16/44: loss=8.3032 
[epoch 8] step 18/44: loss=8.2289 
[epoch 8] step 20/44: loss=8.0785 
[epoch 8] step 22/44: loss=8.1741 
[epoch 8] step 24/44: loss=8.2882 
[epoch 8] step 26/44: loss=8.3595 
[epoch 8] step 28/44: loss=8.3508 
[epoch 8] step 30/44: loss=8.3419 
[epoch 8] step 32/44: loss=8.2972 
[epoch 8] step 34/44: loss=8.2724 
[epoch 8] step 36/44: loss=8.2476 
[epoch 8] step 38/44: loss=8.2067 
[epoch 8] step 40/44: loss=8.2243 
[epoch 8] step 42/44: loss=8.2778 
[epoch 8] step 44/44: loss=8.3270 
[epoch 8] train_loss(avg per step)=16.6540 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=12.8015 qwk=('0.1135', '0.4854', '0.5215') averageQWK=0.3735 macroEMD=0.3753 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    0    0
     0    0   41    0    0
     0    0  119    3    0
     0    0  119   22    0
     0    0   18    3    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    3    2    0
     0   13   18    8    0
     0   21   39   44    0
     0   10   25  128    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   11    1    0    0
     0   33   15    4    0
     0   46   81   31    0
     0   10   34   66    0
     0    0    1    2    0
[epoch 9] step 2/44: loss=9.3501 
[epoch 9] step 4/44: loss=8.9717 
[epoch 9] step 6/44: loss=8.1897 
[epoch 9] step 8/44: loss=7.9681 
[epoch 9] step 10/44: loss=8.1619 
[epoch 9] step 12/44: loss=8.3451 
[epoch 9] step 14/44: loss=8.3394 
[epoch 9] step 16/44: loss=8.4126 
[epoch 9] step 18/44: loss=8.4373 
[epoch 9] step 20/44: loss=8.3570 
[epoch 9] step 22/44: loss=8.2585 
[epoch 9] step 24/44: loss=8.1300 
[epoch 9] step 26/44: loss=8.1205 
[epoch 9] step 28/44: loss=8.0884 
[epoch 9] step 30/44: loss=8.0380 
[epoch 9] step 32/44: loss=8.0785 
[epoch 9] step 34/44: loss=8.1319 
[epoch 9] step 36/44: loss=8.2262 
[epoch 9] step 38/44: loss=8.2242 
[epoch 9] step 40/44: loss=8.2216 
[epoch 9] step 42/44: loss=8.1597 
[epoch 9] step 44/44: loss=8.0620 
[epoch 9] train_loss(avg per step)=16.1240 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=7.8628 qwk=('0.4824', '0.5374', '0.4998') averageQWK=0.5065 macroEMD=0.3778 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    0    0    0
     0   39    2    0    0
     0   82    1   39    0
     0   41    2   98    0
     0    2    0   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    3    1    0
     0   14   18    7    0
     0   23   39   42    0
     0    9   20  134    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   12    0    0    0
     0   38    1   13    0
     0   62    0   96    0
     0   10    1   99    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=7.9508 
[epoch 10] step 4/44: loss=7.8369 
[epoch 10] step 6/44: loss=7.5061 
[epoch 10] step 8/44: loss=7.5502 
[epoch 10] step 10/44: loss=7.8140 
[epoch 10] step 12/44: loss=8.1108 
[epoch 10] step 14/44: loss=8.3034 
[epoch 10] step 16/44: loss=8.3205 
[epoch 10] step 18/44: loss=8.2727 
[epoch 10] step 20/44: loss=8.2253 
[epoch 10] step 22/44: loss=8.0825 
[epoch 10] step 24/44: loss=7.9724 
[epoch 10] step 26/44: loss=7.9364 
[epoch 10] step 28/44: loss=8.0006 
[epoch 10] step 30/44: loss=8.0389 
[epoch 10] step 32/44: loss=8.1368 
[epoch 10] step 34/44: loss=8.2427 
[epoch 10] step 36/44: loss=8.2907 
[epoch 10] step 38/44: loss=8.2593 
[epoch 10] step 40/44: loss=8.2033 
[epoch 10] step 42/44: loss=8.1627 
[epoch 10] step 44/44: loss=8.0673 
[epoch 10] train_loss(avg per step)=16.1347 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=7.0047 qwk=('0.4711', '0.3941', '0.5030') averageQWK=0.4560 macroEMD=0.3806 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    5   33    3    0
     0    1   80   41    0
     1    0   31  109    0
     0    0    2   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    5    0
     0   12    8   19    0
     0   19   28   57    0
     0    7   10  146    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   12    0    0    0
     0   37    1   14    0
     0   64    5   89    0
     0    9    2   99    0
     0    0    0    3    0
[epoch 11] step 2/44: loss=6.1616 
[epoch 11] step 4/44: loss=6.5666 
[epoch 11] step 6/44: loss=7.0005 
[epoch 11] step 8/44: loss=7.3951 
[epoch 11] step 10/44: loss=7.8088 
[epoch 11] step 12/44: loss=7.9188 
[epoch 11] step 14/44: loss=7.9440 
[epoch 11] step 16/44: loss=7.8405 
[epoch 11] step 18/44: loss=7.7705 
[epoch 11] step 20/44: loss=7.7072 
[epoch 11] step 22/44: loss=7.6949 
[epoch 11] step 24/44: loss=7.8188 
[epoch 11] step 26/44: loss=7.9785 
[epoch 11] step 28/44: loss=8.1048 
[epoch 11] step 30/44: loss=8.1638 
[epoch 11] step 32/44: loss=8.0983 
[epoch 11] step 34/44: loss=8.0174 
[epoch 11] step 36/44: loss=7.9062 
[epoch 11] step 38/44: loss=7.8719 
[epoch 11] step 40/44: loss=7.8629 
[epoch 11] step 42/44: loss=7.9340 
[epoch 11] step 44/44: loss=8.0272 
[epoch 11] train_loss(avg per step)=16.0545 lambda[min,max]=[0.500000,1.000000]
[epoch 11] val_loss=15.7407 qwk=('0.3323', '0.4363', '0.5367') averageQWK=0.4351 macroEMD=0.3715 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    2   39    0    0
     0    0  111   11    0
     0    0   76   65    0
     0    0   13    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    0   33    6    0
     0    0   63   41    0
     0    0   32  131    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    2    0    0
     0   18   29    5    0
     0   17  101   40    0
     0    5   26   79    0
     0    0    1    2    0
[epoch 12] step 2/44: loss=9.3056 
[epoch 12] step 4/44: loss=9.1607 
[epoch 12] step 6/44: loss=8.6558 
[epoch 12] step 8/44: loss=8.2366 
[epoch 12] step 10/44: loss=7.9595 
[epoch 12] step 12/44: loss=7.7342 
[epoch 12] step 14/44: loss=7.6930 
[epoch 12] step 16/44: loss=7.7509 
[epoch 12] step 18/44: loss=7.8760 
[epoch 12] step 20/44: loss=8.0237 
[epoch 12] step 22/44: loss=8.0165 
[epoch 12] step 24/44: loss=8.0213 
[epoch 12] step 26/44: loss=8.0263 
[epoch 12] step 28/44: loss=8.0157 
[epoch 12] step 30/44: loss=8.0057 
[epoch 12] step 32/44: loss=8.0002 
[epoch 12] step 34/44: loss=7.9443 
[epoch 12] step 36/44: loss=7.9511 
[epoch 12] step 38/44: loss=7.9490 
[epoch 12] step 40/44: loss=7.8897 
[epoch 12] step 42/44: loss=7.8340 
[epoch 12] step 44/44: loss=7.9659 
[epoch 12] train_loss(avg per step)=15.9318 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=15.8630 qwk=('0.4583', '0.4227', '0.3755') averageQWK=0.4188 macroEMD=0.3715 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    1    0
     0    0   38    3    0
     0    0   76   46    0
     0    0   25  116    0
     0    0    2   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    0   35    4    0
     0    0   66   38    0
     0    0   41  122    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    0   44    8    0
     0    1  105   52    0
     0    0   31   79    0
     0    0    1    2    0
[epoch 13] step 2/44: loss=9.0665 
[epoch 13] step 4/44: loss=8.9629 
[epoch 13] step 6/44: loss=8.7297 
[epoch 13] step 8/44: loss=8.3282 
[epoch 13] step 10/44: loss=8.0872 
[epoch 13] step 12/44: loss=7.8933 
[epoch 13] step 14/44: loss=7.8848 
[epoch 13] step 16/44: loss=7.8454 
[epoch 13] step 18/44: loss=7.8840 
[epoch 13] step 20/44: loss=7.9381 
[epoch 13] step 22/44: loss=7.9260 
[epoch 13] step 24/44: loss=7.9303 
[epoch 13] step 26/44: loss=7.9181 
[epoch 13] step 28/44: loss=7.9027 
[epoch 13] step 30/44: loss=7.9006 
[epoch 13] step 32/44: loss=7.8794 
[epoch 13] step 34/44: loss=7.9048 
[epoch 13] step 36/44: loss=7.9515 
[epoch 13] step 38/44: loss=7.9681 
[epoch 13] step 40/44: loss=7.9797 
[epoch 13] step 42/44: loss=7.9721 
[epoch 13] step 44/44: loss=7.8790 
[epoch 13] train_loss(avg per step)=15.7580 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=16.4711 qwk=('0.3588', '0.3543', '0.3669') averageQWK=0.3600 macroEMD=0.3755 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    2    0
     0    0   33    8    0
     0    0   66   56    0
     0    0   32  109    0
     0    0    2   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   10    3    0
     0    0   27   12    0
     0    0   52   52    0
     0    0   27  136    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    0   49    3    0
     0    0  126   32    0
     0    0   46   64    0
     0    0    1    2    0
[epoch 14] step 2/44: loss=9.6354 
[epoch 14] step 4/44: loss=9.0288 
[epoch 14] step 6/44: loss=8.8068 
[epoch 14] step 8/44: loss=8.3821 
[epoch 14] step 10/44: loss=8.0004 
[epoch 14] step 12/44: loss=7.6794 
[epoch 14] step 14/44: loss=7.6847 
[epoch 14] step 16/44: loss=7.6367 
[epoch 14] step 18/44: loss=7.6233 
[epoch 14] step 20/44: loss=7.6475 
[epoch 14] step 22/44: loss=7.7872 
[epoch 14] step 24/44: loss=7.9119 
[epoch 14] step 26/44: loss=8.0291 
[epoch 14] step 28/44: loss=8.0707 
[epoch 14] step 30/44: loss=8.0271 
[epoch 14] step 32/44: loss=7.9249 
[epoch 14] step 34/44: loss=7.8914 
[epoch 14] step 36/44: loss=7.8501 
[epoch 14] step 38/44: loss=7.8582 
[epoch 14] step 40/44: loss=7.8922 
[epoch 14] step 42/44: loss=7.9161 
[epoch 14] step 44/44: loss=7.8615 
[epoch 14] train_loss(avg per step)=15.7230 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=14.7536 qwk=('0.5430', '0.4028', '0.4708') averageQWK=0.4722 macroEMD=0.3696 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    4    0    0
     0   21   15    5    0
     0   28   53   41    0
     0    9   23  109    0
     0    0    2   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    1    0
     0    1   36    2    0
     0    2   77   25    0
     0    0   63  100    0
     0    0    3   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    5    0    0
     0   17   30    5    0
     0   20   97   41    0
     0    6   31   73    0
     0    0    1    2    0
[epoch 15] step 2/44: loss=8.2030 
[epoch 15] step 4/44: loss=8.4114 
[epoch 15] step 6/44: loss=8.2985 
[epoch 15] step 8/44: loss=8.0727 
[epoch 15] step 10/44: loss=7.7579 
[epoch 15] step 12/44: loss=7.6952 
[epoch 15] step 14/44: loss=7.4846 
[epoch 15] step 16/44: loss=7.4290 
[epoch 15] step 18/44: loss=7.4556 
[epoch 15] step 20/44: loss=7.5730 
[epoch 15] step 22/44: loss=7.6285 
[epoch 15] step 24/44: loss=7.7300 
[epoch 15] step 26/44: loss=7.8350 
[epoch 15] step 28/44: loss=7.8781 
[epoch 15] step 30/44: loss=7.8839 
[epoch 15] step 32/44: loss=7.8843 
[epoch 15] step 34/44: loss=7.8836 
[epoch 15] step 36/44: loss=7.8393 
[epoch 15] step 38/44: loss=7.7675 
[epoch 15] step 40/44: loss=7.7773 
[epoch 15] step 42/44: loss=7.7905 
[epoch 15] step 44/44: loss=7.7583 
[epoch 15] train_loss(avg per step)=15.5165 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=18.0746 qwk=('0.3760', '0.3886', '0.4263') averageQWK=0.3970 macroEMD=0.3725 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    9    1    0
     0    0   38    3    0
     0    0   77   44    1
     0    0   44   97    0
     0    0    4   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    1    0
     0    0   28   11    0
     0    0   52   52    0
     0    0   27  136    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    0   49    3    0
     0    0   98   60    0
     0    0   25   85    0
     0    0    0    3    0
[epoch 16] step 2/44: loss=9.7726 
[epoch 16] step 4/44: loss=9.6150 
[epoch 16] step 6/44: loss=9.4138 
[epoch 16] step 8/44: loss=9.0177 
[epoch 16] step 10/44: loss=8.6439 
[epoch 16] step 12/44: loss=8.3064 
[epoch 16] step 14/44: loss=8.0939 
[epoch 16] step 16/44: loss=7.9643 
[epoch 16] step 18/44: loss=7.9549 
[epoch 16] step 20/44: loss=7.9672 
[epoch 16] step 22/44: loss=8.0290 
[epoch 16] step 24/44: loss=8.0511 
[epoch 16] step 26/44: loss=7.9831 
[epoch 16] step 28/44: loss=8.0204 
[epoch 16] step 30/44: loss=8.0145 
[epoch 16] step 32/44: loss=8.0268 
[epoch 16] step 34/44: loss=7.9858 
[epoch 16] step 36/44: loss=8.0234 
[epoch 16] step 38/44: loss=8.0347 
[epoch 16] step 40/44: loss=8.0242 
[epoch 16] step 42/44: loss=8.0090 
[epoch 16] step 44/44: loss=8.1143 
[epoch 16] train_loss(avg per step)=16.2285 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=13.2675 qwk=('0.4586', '0.3663', '0.4117') averageQWK=0.4122 macroEMD=0.3717 tailR0=('0.0738', '0.0385', '0.0000') tailR0avg=0.0374
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     0    8   24    9    0
     0    5   62   55    0
     0    0   23  118    0
     0    0    1   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    8    4    0
     0    5   17   17    0
     0    9   36   59    0
     0    0   18  145    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    0   48    4    0
     0    2  112   44    0
     0    0   30   80    0
     0    0    1    2    0
[epoch 17] step 2/44: loss=8.7355 
[epoch 17] step 4/44: loss=8.1685 
[epoch 17] step 6/44: loss=8.3069 
[epoch 17] step 8/44: loss=8.3069 
[epoch 17] step 10/44: loss=8.2775 
[epoch 17] step 12/44: loss=7.9784 
[epoch 17] step 14/44: loss=7.6662 
[epoch 17] step 16/44: loss=7.5719 
[epoch 17] step 18/44: loss=7.5223 
[epoch 17] step 20/44: loss=7.4351 
[epoch 17] step 22/44: loss=7.5136 
[epoch 17] step 24/44: loss=7.5585 
[epoch 17] step 26/44: loss=7.7143 
[epoch 17] step 28/44: loss=7.8366 
[epoch 17] step 30/44: loss=7.9214 
[epoch 17] step 32/44: loss=7.9360 
[epoch 17] step 34/44: loss=7.9844 
[epoch 17] step 36/44: loss=7.9640 
[epoch 17] step 38/44: loss=7.9159 
[epoch 17] step 40/44: loss=7.8766 
[epoch 17] step 42/44: loss=7.8353 
[epoch 17] step 44/44: loss=7.7377 
[epoch 17] train_loss(avg per step)=15.4753 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=12.9462 qwk=('0.4780', '0.4215', '0.4112') averageQWK=0.4369 macroEMD=0.3710 tailR0=('0.0000', '0.0385', '0.0000') tailR0avg=0.0128
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    7   32    2    0
     0    2   83   37    0
     0    0   43   98    0
     0    0    2   19    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    8    3    0
     0    4   24   11    0
     0    7   45   52    0
     0    0   25  138    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    1   48    3    0
     0    5  114   39    0
     0    1   37   72    0
     0    0    1    2    0
[epoch 18] step 2/44: loss=7.3620 
[epoch 18] step 4/44: loss=8.0130 
[epoch 18] step 6/44: loss=8.2336 
[epoch 18] step 8/44: loss=8.2990 
[epoch 18] step 10/44: loss=8.4765 
[epoch 18] step 12/44: loss=8.3082 
[epoch 18] step 14/44: loss=8.2482 
[epoch 18] step 16/44: loss=8.0882 
[epoch 18] step 18/44: loss=7.9933 
[epoch 18] step 20/44: loss=8.0306 
[epoch 18] step 22/44: loss=7.9785 
[epoch 18] step 24/44: loss=7.9519 
[epoch 18] step 26/44: loss=7.9086 
[epoch 18] step 28/44: loss=7.8988 
[epoch 18] step 30/44: loss=7.9542 
[epoch 18] step 32/44: loss=7.9789 
[epoch 18] step 34/44: loss=8.0357 
[epoch 18] step 36/44: loss=8.0841 
[epoch 18] step 38/44: loss=8.0897 
[epoch 18] step 40/44: loss=8.0409 
[epoch 18] step 42/44: loss=8.0475 
[epoch 18] step 44/44: loss=7.9916 
[epoch 18] train_loss(avg per step)=15.9831 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=12.6787 qwk=('0.4373', '0.4658', '0.4274') averageQWK=0.4435 macroEMD=0.3749 tailR0=('0.0476', '0.0385', '0.0000') tailR0avg=0.0287
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    7   32    2    0
     1    4   82   34    1
     0    0   51   84    6
     0    0    7   12    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1   10    1    0
     0    2   32    5    0
     0    4   63   37    0
     0    0   42  121    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    1   46    5    0
     0    5  111   42    0
     0    1   31   78    0
     0    0    0    3    0
[epoch 19] step 2/44: loss=7.3911 
[epoch 19] step 4/44: loss=7.7454 
[epoch 19] step 6/44: loss=7.6920 
[epoch 19] step 8/44: loss=7.6094 
[epoch 19] step 10/44: loss=7.5913 
[epoch 19] step 12/44: loss=7.6849 
[epoch 19] step 14/44: loss=7.7823 
[epoch 19] step 16/44: loss=7.6897 
[epoch 19] step 18/44: loss=7.7184 
[epoch 19] step 20/44: loss=7.6923 
[epoch 19] step 22/44: loss=7.7145 
[epoch 19] step 24/44: loss=7.7263 
[epoch 19] step 26/44: loss=7.8059 
[epoch 19] step 28/44: loss=7.8224 
[epoch 19] step 30/44: loss=7.8068 
[epoch 19] step 32/44: loss=7.8068 
[epoch 19] step 34/44: loss=7.8287 
[epoch 19] step 36/44: loss=7.8074 
[epoch 19] step 38/44: loss=7.7942 
[epoch 19] step 40/44: loss=7.7800 
[epoch 19] step 42/44: loss=7.7774 
[epoch 19] step 44/44: loss=7.8690 
[epoch 19] train_loss(avg per step)=15.7380 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=12.3136 qwk=('0.4758', '0.4745', '0.4710') averageQWK=0.4738 macroEMD=0.3702 tailR0=('0.1452', '0.0385', '0.0000') tailR0avg=0.0612
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    9    0    0
     0    9   30    2    0
     0   10   75   36    1
     0    3   46   88    4
     0    0    4   13    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    7    1    0
     0    7   25    7    0
     0   16   47   41    0
     0    5   35  123    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   14   35    3    0
     0   20   98   40    0
     0    5   29   76    0
     0    0    1    2    0
[epoch 20] step 2/44: loss=7.4397 
[epoch 20] step 4/44: loss=7.9447 
[epoch 20] step 6/44: loss=8.2091 
[epoch 20] step 8/44: loss=8.1176 
[epoch 20] step 10/44: loss=8.1440 
[epoch 20] step 12/44: loss=8.1143 
[epoch 20] step 14/44: loss=7.9819 
[epoch 20] step 16/44: loss=7.8638 
[epoch 20] step 18/44: loss=7.8798 
[epoch 20] step 20/44: loss=7.7713 
[epoch 20] step 22/44: loss=7.7657 
[epoch 20] step 24/44: loss=7.7812 
[epoch 20] step 26/44: loss=7.7753 
[epoch 20] step 28/44: loss=7.7967 
[epoch 20] step 30/44: loss=7.8893 
[epoch 20] step 32/44: loss=7.9484 
[epoch 20] step 34/44: loss=7.9316 
[epoch 20] step 36/44: loss=7.9094 
[epoch 20] step 38/44: loss=7.8419 
[epoch 20] step 40/44: loss=7.8402 
[epoch 20] step 42/44: loss=7.8032 
[epoch 20] step 44/44: loss=7.6717 
[epoch 20] train_loss(avg per step)=15.3433 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=13.4296 qwk=('0.4378', '0.4317', '0.3901') averageQWK=0.4198 macroEMD=0.3746 tailR0=('0.1214', '0.0697', '0.0000') tailR0avg=0.0637
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     0    4   30    7    0
     0    0   64   57    1
     0    0   30  105    6
     0    0    1   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0   10    2    0
     0    1   31    7    0
     0    3   58   43    0
     0    0   36  127    0
     0    0    0   15    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    3   48    1    0
     0    6  128   24    0
     0    0   53   57    0
     0    0    2    1    0
[epoch 21] step 2/44: loss=8.3964 
[epoch 21] step 4/44: loss=8.8940 
[epoch 21] step 6/44: loss=8.7453 
[epoch 21] step 8/44: loss=8.5380 
[epoch 21] step 10/44: loss=8.3883 
[epoch 21] step 12/44: loss=8.3048 
[epoch 21] step 14/44: loss=8.2006 
[epoch 21] step 16/44: loss=8.1794 
[epoch 21] step 18/44: loss=8.1004 
[epoch 21] step 20/44: loss=8.1374 
[epoch 21] step 22/44: loss=8.1459 
[epoch 21] step 24/44: loss=8.1239 
[epoch 21] step 26/44: loss=8.1523 
[epoch 21] step 28/44: loss=8.1076 
[epoch 21] step 30/44: loss=8.1409 
[epoch 21] step 32/44: loss=8.1417 
[epoch 21] step 34/44: loss=8.1128 
[epoch 21] step 36/44: loss=8.0946 
[epoch 21] step 38/44: loss=8.0607 
[epoch 21] step 40/44: loss=8.0118 
[epoch 21] step 42/44: loss=8.0120 
[epoch 21] step 44/44: loss=8.0857 
[epoch 21] train_loss(avg per step)=16.1714 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=13.2845 qwk=('0.4723', '0.4354', '0.4083') averageQWK=0.4387 macroEMD=0.3712 tailR0=('0.1929', '0.0385', '0.0000') tailR0avg=0.0771
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     1    6   29    5    0
     1    3   63   53    2
     0    0   34  102    5
     0    0    1   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    9    2    0
     1    3   24   11    0
     0    7   47   50    0
     0    0   27  136    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   48    3    0
     0    4  117   37    0
     0    0   36   74    0
     0    0    1    2    0
[epoch 22] step 2/44: loss=9.1875 
[epoch 22] step 4/44: loss=8.8678 
[epoch 22] step 6/44: loss=8.6261 
[epoch 22] step 8/44: loss=8.5061 
[epoch 22] step 10/44: loss=8.3124 
[epoch 22] step 12/44: loss=8.0354 
[epoch 22] step 14/44: loss=7.9590 
[epoch 22] step 16/44: loss=7.7737 
[epoch 22] step 18/44: loss=7.7054 
[epoch 22] step 20/44: loss=7.7267 
[epoch 22] step 22/44: loss=7.7844 
[epoch 22] step 24/44: loss=7.9243 
[epoch 22] step 26/44: loss=7.9449 
[epoch 22] step 28/44: loss=7.9666 
[epoch 22] step 30/44: loss=7.9808 
[epoch 22] step 32/44: loss=8.0333 
[epoch 22] step 34/44: loss=8.0116 
[epoch 22] step 36/44: loss=8.0169 
[epoch 22] step 38/44: loss=7.9800 
[epoch 22] step 40/44: loss=7.9084 
[epoch 22] step 42/44: loss=7.8529 
[epoch 22] step 44/44: loss=7.9031 
[epoch 22] train_loss(avg per step)=15.8062 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=11.5444 qwk=('0.4558', '0.4754', '0.4559') averageQWK=0.4624 macroEMD=0.3740 tailR0=('0.3095', '0.1322', '0.0000') tailR0avg=0.1472
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    6   35    0    0
     0    5   89   14   14
     0    0   60   53   28
     0    0    7    1   13
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    7    2    0
     0    6   25    8    0
     0   12   46   46    0
     0    1   36  126    0
     0    0    0   13    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    7   41    4    0
     0    7  101   50    0
     0    2   27   81    0
     0    0    1    2    0
[epoch 23] step 2/44: loss=7.3114 
[epoch 23] step 4/44: loss=8.0013 
[epoch 23] step 6/44: loss=8.3229 
[epoch 23] step 8/44: loss=8.3811 
[epoch 23] step 10/44: loss=8.2215 
[epoch 23] step 12/44: loss=8.1618 
[epoch 23] step 14/44: loss=8.0865 
[epoch 23] step 16/44: loss=7.9422 
[epoch 23] step 18/44: loss=7.8160 
[epoch 23] step 20/44: loss=7.8346 
[epoch 23] step 22/44: loss=7.8058 
[epoch 23] step 24/44: loss=7.8011 
[epoch 23] step 26/44: loss=7.8776 
[epoch 23] step 28/44: loss=7.9384 
[epoch 23] step 30/44: loss=7.9848 
[epoch 23] step 32/44: loss=7.9801 
[epoch 23] step 34/44: loss=7.9596 
[epoch 23] step 36/44: loss=7.9527 
[epoch 23] step 38/44: loss=7.9215 
[epoch 23] step 40/44: loss=7.9225 
[epoch 23] step 42/44: loss=7.8946 
[epoch 23] step 44/44: loss=8.0191 
[epoch 23] train_loss(avg per step)=16.0381 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=10.7859 qwk=('0.5309', '0.5056', '0.4937') averageQWK=0.5100 macroEMD=0.3709 tailR0=('0.0952', '0.1154', '0.0000') tailR0avg=0.0702
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    0    0
     0   12   26    3    0
     0    8   75   38    1
     0    0   43   93    5
     0    0    3   14    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    5    3    2    0
     4    5   17   13    0
     1   16   31   56    0
     0    3   18  142    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    5    0    0
     0   17   30    5    0
     0   21   80   57    0
     0    3   28   79    0
     0    0    0    3    0
[epoch 24] step 2/44: loss=7.4698 
[epoch 24] step 4/44: loss=7.5806 
[epoch 24] step 6/44: loss=7.9737 
[epoch 24] step 8/44: loss=7.6978 
[epoch 24] step 10/44: loss=7.8346 
[epoch 24] step 12/44: loss=7.8132 
[epoch 24] step 14/44: loss=7.7722 
[epoch 24] step 16/44: loss=7.7396 
[epoch 24] step 18/44: loss=7.7356 
[epoch 24] step 20/44: loss=7.7323 
[epoch 24] step 22/44: loss=7.7736 
[epoch 24] step 24/44: loss=7.7829 
[epoch 24] step 26/44: loss=7.8019 
[epoch 24] step 28/44: loss=7.8484 
[epoch 24] step 30/44: loss=7.8322 
[epoch 24] step 32/44: loss=7.8124 
[epoch 24] step 34/44: loss=7.8431 
[epoch 24] step 36/44: loss=7.8620 
[epoch 24] step 38/44: loss=7.8752 
[epoch 24] step 40/44: loss=7.8791 
[epoch 24] step 42/44: loss=7.9072 
[epoch 24] step 44/44: loss=7.9430 
[epoch 24] train_loss(avg per step)=15.8859 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=10.9774 qwk=('0.4508', '0.4569', '0.4284') averageQWK=0.4454 macroEMD=0.3747 tailR0=('0.0714', '0.0312', '0.0000') tailR0avg=0.0342
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    7   32    2    0
     0    6   74   42    0
     1    0   50   89    1
     0    0    3   15    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    2    0
     0    5   28    6    0
     0   10   62   32    0
     0    1   45  117    0
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    5   46    1    0
     0    6  124   28    0
     0    2   43   65    0
     0    0    1    2    0
[epoch 25] step 2/44: loss=6.9022 
[epoch 25] step 4/44: loss=6.9438 
[epoch 25] step 6/44: loss=6.8205 
[epoch 25] step 8/44: loss=7.0089 
[epoch 25] step 10/44: loss=7.0658 
[epoch 25] step 12/44: loss=7.1200 
[epoch 25] step 14/44: loss=7.1897 
[epoch 25] step 16/44: loss=7.2870 
[epoch 25] step 18/44: loss=7.3797 
[epoch 25] step 20/44: loss=7.4312 
[epoch 25] step 22/44: loss=7.5519 
[epoch 25] step 24/44: loss=7.6439 
[epoch 25] step 26/44: loss=7.6404 
[epoch 25] step 28/44: loss=7.6442 
[epoch 25] step 30/44: loss=7.6825 
[epoch 25] step 32/44: loss=7.6706 
[epoch 25] step 34/44: loss=7.6717 
[epoch 25] step 36/44: loss=7.6754 
[epoch 25] step 38/44: loss=7.6864 
[epoch 25] step 40/44: loss=7.6903 
[epoch 25] step 42/44: loss=7.7537 
[epoch 25] step 44/44: loss=7.7068 
[epoch 25] train_loss(avg per step)=15.4137 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=10.7556 qwk=('0.5015', '0.4654', '0.4881') averageQWK=0.4850 macroEMD=0.3710 tailR0=('0.1667', '0.0312', '0.0000') tailR0avg=0.0660
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    0    0
     0   10   29    2    0
     1    5   74   40    2
     0    1   51   78   11
     0    0    2   12    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    3    2    0
     0   14   10   15    0
     0   18   26   60    0
     0    8   12  143    0
     0    0    0   15    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   11   38    3    0
     0   15   83   60    0
     0    2   24   84    0
     0    0    0    3    0
[epoch 26] step 2/44: loss=7.7195 
[epoch 26] step 4/44: loss=7.8432 
[epoch 26] step 6/44: loss=7.7295 
[epoch 26] step 8/44: loss=7.8058 
[epoch 26] step 10/44: loss=7.8344 
[epoch 26] step 12/44: loss=7.8338 
[epoch 26] step 14/44: loss=7.9034 
[epoch 26] step 16/44: loss=7.9415 
[epoch 26] step 18/44: loss=7.8594 
[epoch 26] step 20/44: loss=7.8444 
[epoch 26] step 22/44: loss=7.8208 
[epoch 26] step 24/44: loss=7.7682 
[epoch 26] step 26/44: loss=7.7714 
[epoch 26] step 28/44: loss=7.8265 
[epoch 26] step 30/44: loss=7.8895 
[epoch 26] step 32/44: loss=7.8735 
[epoch 26] step 34/44: loss=7.8851 
[epoch 26] step 36/44: loss=7.8965 
[epoch 26] step 38/44: loss=7.9011 
[epoch 26] step 40/44: loss=7.9487 
[epoch 26] step 42/44: loss=7.9611 
[epoch 26] step 44/44: loss=8.0562 
[epoch 26] train_loss(avg per step)=16.1125 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=10.3397 qwk=('0.4709', '0.4397', '0.4502') averageQWK=0.4536 macroEMD=0.3746 tailR0=('0.1452', '0.1010', '0.0000') tailR0avg=0.0821
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    9    0    0
     0    6   31    4    0
     1    2   72   46    1
     0    0   44   92    5
     0    0    2   15    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    9    2    0
     2    4   26    7    0
     0    8   62   34    0
     0    3   43  116    1
     0    0    2   12    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    9   40    3    0
     0   13  109   36    0
     0    2   37   71    0
     0    0    1    2    0
[epoch 27] step 2/44: loss=7.5103 
[epoch 27] step 4/44: loss=7.3795 
[epoch 27] step 6/44: loss=7.2175 
[epoch 27] step 8/44: loss=7.1699 
[epoch 27] step 10/44: loss=7.2261 
[epoch 27] step 12/44: loss=7.3670 
[epoch 27] step 14/44: loss=7.4601 
[epoch 27] step 16/44: loss=7.6596 
[epoch 27] step 18/44: loss=7.7026 
[epoch 27] step 20/44: loss=7.8293 
[epoch 27] step 22/44: loss=7.8335 
[epoch 27] step 24/44: loss=7.8370 
[epoch 27] step 26/44: loss=7.8945 
[epoch 27] step 28/44: loss=7.8813 
[epoch 27] step 30/44: loss=7.8267 
[epoch 27] step 32/44: loss=7.7967 
[epoch 27] step 34/44: loss=7.7672 
[epoch 27] step 36/44: loss=7.7066 
[epoch 27] step 38/44: loss=7.6953 
[epoch 27] step 40/44: loss=7.7212 
[epoch 27] step 42/44: loss=7.7967 
[epoch 27] step 44/44: loss=7.7659 
[epoch 27] train_loss(avg per step)=15.5317 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=13.0333 qwk=('0.4950', '0.4398', '0.4591') averageQWK=0.4646 macroEMD=0.3705 tailR0=('0.1667', '0.0697', '0.0000') tailR0avg=0.0788
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0   10   28    3    0
     0    5   77   38    2
     0    0   53   77   11
     0    0    2   12    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    9    2    0
     0    6   23   10    0
     0   11   44   49    0
     0    3   25  135    0
     0    0    0   15    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    7   42    3    0
     1    7   92   58    0
     0    2   26   82    0
     0    0    0    3    0
[epoch 28] step 2/44: loss=8.9101 
[epoch 28] step 4/44: loss=8.6324 
[epoch 28] step 6/44: loss=8.6287 
[epoch 28] step 8/44: loss=8.4062 
[epoch 28] step 10/44: loss=8.3435 
[epoch 28] step 12/44: loss=8.1465 
[epoch 28] step 14/44: loss=8.0406 
[epoch 28] step 16/44: loss=8.0909 
[epoch 28] step 18/44: loss=8.0508 
[epoch 28] step 20/44: loss=7.9984 
[epoch 28] step 22/44: loss=8.0495 
[epoch 28] step 24/44: loss=7.9741 
[epoch 28] step 26/44: loss=7.9321 
[epoch 28] step 28/44: loss=7.9593 
[epoch 28] step 30/44: loss=7.9410 
[epoch 28] step 32/44: loss=7.9136 
[epoch 28] step 34/44: loss=7.8837 
[epoch 28] step 36/44: loss=7.8971 
[epoch 28] step 38/44: loss=7.8599 
[epoch 28] step 40/44: loss=7.8727 
[epoch 28] step 42/44: loss=7.9032 
[epoch 28] step 44/44: loss=7.9256 
[epoch 28] train_loss(avg per step)=15.8512 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=12.3222 qwk=('0.4694', '0.4670', '0.4935') averageQWK=0.4766 macroEMD=0.3715 tailR0=('0.0952', '0.0697', '0.0000') tailR0avg=0.0550
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    8   27    6    0
     1    5   63   52    1
     0    1   32   99    9
     0    0    1   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    6    2    0
     0    7   21   11    0
     0   15   38   51    0
     0    3   23  137    0
     0    0    0   15    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   12   38    2    0
     0   13  106   39    0
     0    2   33   75    0
     0    0    1    2    0
[epoch 29] step 2/44: loss=8.3486 
[epoch 29] step 4/44: loss=8.2867 
[epoch 29] step 6/44: loss=8.1927 
[epoch 29] step 8/44: loss=8.2711 
[epoch 29] step 10/44: loss=8.1078 
[epoch 29] step 12/44: loss=8.0088 
[epoch 29] step 14/44: loss=7.9887 
[epoch 29] step 16/44: loss=7.8460 
[epoch 29] step 18/44: loss=7.8523 
[epoch 29] step 20/44: loss=7.9066 
[epoch 29] step 22/44: loss=7.8997 
[epoch 29] step 24/44: loss=7.8267 
[epoch 29] step 26/44: loss=7.8986 
[epoch 29] step 28/44: loss=7.9304 
[epoch 29] step 30/44: loss=7.9537 
[epoch 29] step 32/44: loss=7.9457 
[epoch 29] step 34/44: loss=7.9506 
[epoch 29] step 36/44: loss=7.9426 
[epoch 29] step 38/44: loss=7.9476 
[epoch 29] step 40/44: loss=7.9711 
[epoch 29] step 42/44: loss=7.9352 
[epoch 29] step 44/44: loss=7.8514 
[epoch 29] train_loss(avg per step)=15.7028 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=10.5556 qwk=('0.5027', '0.4382', '0.4543') averageQWK=0.4651 macroEMD=0.3737 tailR0=('0.1452', '0.0697', '0.0000') tailR0avg=0.0716
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    8    0    0
     0   10   27    4    0
     1    6   65   49    1
     0    0   43   91    7
     0    0    1   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0   10    2    0
     2    4   25    8    0
     0    8   52   44    0
     0    1   33  129    0
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    8    0    0
     0    5   44    3    0
     0    7  110   41    0
     0    2   33   75    0
     0    0    0    3    0
[epoch 30] step 2/44: loss=7.6959 
[epoch 30] step 4/44: loss=7.7083 
[epoch 30] step 6/44: loss=7.5202 
[epoch 30] step 8/44: loss=7.6732 
[epoch 30] step 10/44: loss=7.5245 
[epoch 30] step 12/44: loss=7.6524 
[epoch 30] step 14/44: loss=7.7463 
[epoch 30] step 16/44: loss=7.7636 
[epoch 30] step 18/44: loss=7.7776 
[epoch 30] step 20/44: loss=7.7566 
[epoch 30] step 22/44: loss=7.7571 
[epoch 30] step 24/44: loss=7.7164 
[epoch 30] step 26/44: loss=7.7496 
[epoch 30] step 28/44: loss=7.7796 
[epoch 30] step 30/44: loss=7.7957 
[epoch 30] step 32/44: loss=7.8051 
[epoch 30] step 34/44: loss=7.8053 
[epoch 30] step 36/44: loss=7.8574 
[epoch 30] step 38/44: loss=7.8333 
[epoch 30] step 40/44: loss=7.8495 
[epoch 30] step 42/44: loss=7.8654 
[epoch 30] step 44/44: loss=7.8835 
[epoch 30] train_loss(avg per step)=15.7670 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=11.1301 qwk=('0.5185', '0.4535', '0.4765') averageQWK=0.4829 macroEMD=0.3721 tailR0=('0.1929', '0.0697', '0.0000') tailR0avg=0.0875
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    8    0    0
     1   10   27    3    0
     2    4   71   44    1
     0    0   46   86    9
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    6    2    0
     0    8   20   11    0
     0   15   40   49    0
     0    6   23  134    0
     0    0    0   15    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    6   44    2    0
     0    8  113   37    0
     0    1   35   74    0
     0    0    1    2    0
[epoch 31] step 2/44: loss=8.3652 
[epoch 31] step 4/44: loss=8.1966 
[epoch 31] step 6/44: loss=8.1618 
[epoch 31] step 8/44: loss=8.0942 
[epoch 31] step 10/44: loss=8.0553 
[epoch 31] step 12/44: loss=7.9440 
[epoch 31] step 14/44: loss=7.9218 
[epoch 31] step 16/44: loss=7.8737 
[epoch 31] step 18/44: loss=7.8200 
[epoch 31] step 20/44: loss=7.7872 
[epoch 31] step 22/44: loss=7.7185 
[epoch 31] step 24/44: loss=7.7073 
[epoch 31] step 26/44: loss=7.6759 
[epoch 31] step 28/44: loss=7.7478 
[epoch 31] step 30/44: loss=7.8000 
[epoch 31] step 32/44: loss=7.8148 
[epoch 31] step 34/44: loss=7.8342 
[epoch 31] step 36/44: loss=7.8438 
[epoch 31] step 38/44: loss=7.8755 
[epoch 31] step 40/44: loss=7.9113 
[epoch 31] step 42/44: loss=7.9258 
[epoch 31] step 44/44: loss=7.8540 
[epoch 31] train_loss(avg per step)=15.7080 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=11.6349 qwk=('0.5005', '0.4582', '0.4800') averageQWK=0.4796 macroEMD=0.3714 tailR0=('0.1452', '0.0697', '0.0000') tailR0avg=0.0716
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    8    0    0
     1    7   29    4    0
     2    3   68   47    2
     0    0   40   91   10
     0    0    1   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    9    2    0
     1    5   23   10    0
     0    9   50   45    0
     0    1   28  134    0
     0    0    0   15    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0   13   35    4    0
     0   14   88   56    0
     0    3   26   81    0
     0    0    0    3    0
[epoch 32] step 2/44: loss=8.5153 
[epoch 32] step 4/44: loss=8.6520 
[epoch 32] step 6/44: loss=8.3663 
[epoch 32] step 8/44: loss=8.2677 
[epoch 32] step 10/44: loss=8.2170 
[epoch 32] step 12/44: loss=8.0706 
[epoch 32] step 14/44: loss=7.9930 
[epoch 32] step 16/44: loss=7.9608 
[epoch 32] step 18/44: loss=7.9291 
[epoch 32] step 20/44: loss=7.8769 
[epoch 32] step 22/44: loss=7.8284 
[epoch 32] step 24/44: loss=7.8463 
[epoch 32] step 26/44: loss=7.8793 
[epoch 32] step 28/44: loss=7.9597 
[epoch 32] step 30/44: loss=7.9796 
[epoch 32] step 32/44: loss=7.9778 
[epoch 32] step 34/44: loss=7.9469 
[epoch 32] step 36/44: loss=7.9134 
[epoch 32] step 38/44: loss=7.8982 
[epoch 32] step 40/44: loss=7.9049 
[epoch 32] step 42/44: loss=7.9051 
[epoch 32] step 44/44: loss=7.9391 
[epoch 32] train_loss(avg per step)=15.8781 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=11.6419 qwk=('0.4904', '0.4212', '0.4764') averageQWK=0.4627 macroEMD=0.3730 tailR0=('0.1429', '0.0697', '0.0000') tailR0avg=0.0709
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    9   29    3    0
     0    5   73   42    2
     0    0   48   83   10
     0    0    2   13    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    8    2    0
     0    6   23   10    0
     0   13   51   40    0
     0    4   34  125    0
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    9   41    2    0
     0   11  112   35    0
     0    2   36   72    0
     0    0    1    2    0
[epoch 33] step 2/44: loss=8.2070 
[epoch 33] step 4/44: loss=8.3238 
[epoch 33] step 6/44: loss=8.1186 
[epoch 33] step 8/44: loss=8.0668 
[epoch 33] step 10/44: loss=8.0416 
[epoch 33] step 12/44: loss=8.1319 
[epoch 33] step 14/44: loss=7.9849 
[epoch 33] step 16/44: loss=7.9681 
[epoch 33] step 18/44: loss=8.0111 
[epoch 33] step 20/44: loss=8.0202 
[epoch 33] step 22/44: loss=7.9463 
[epoch 33] step 24/44: loss=7.9519 
[epoch 33] step 26/44: loss=7.9014 
[epoch 33] step 28/44: loss=7.8683 
[epoch 33] step 30/44: loss=7.8328 
[epoch 33] step 32/44: loss=7.8341 
[epoch 33] step 34/44: loss=7.8084 
[epoch 33] step 36/44: loss=7.7927 
[epoch 33] step 38/44: loss=7.8175 
[epoch 33] step 40/44: loss=7.8167 
[epoch 33] step 42/44: loss=7.8590 
[epoch 33] step 44/44: loss=7.8038 
[epoch 33] train_loss(avg per step)=15.6075 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=11.2877 qwk=('0.4827', '0.4136', '0.4749') averageQWK=0.4571 macroEMD=0.3726 tailR0=('0.1190', '0.0697', '0.0000') tailR0avg=0.0629
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     1    7   28    5    0
     1    5   66   49    1
     0    0   42   88   11
     0    0    1   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    8    2    0
     0    5   21   13    0
     1   13   37   53    0
     0    3   25  135    0
     0    0    0   15    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    8   41    3    0
     0   10   99   49    0
     0    2   30   78    0
     0    0    0    3    0
[epoch 34] step 2/44: loss=8.4027 
[epoch 34] step 4/44: loss=8.1176 
[epoch 34] step 6/44: loss=8.1043 
[epoch 34] step 8/44: loss=8.1354 
[epoch 34] step 10/44: loss=8.0687 
[epoch 34] step 12/44: loss=8.0980 
[epoch 34] step 14/44: loss=8.0832 
[epoch 34] step 16/44: loss=8.1225 
[epoch 34] step 18/44: loss=8.0736 
[epoch 34] step 20/44: loss=8.0131 
[epoch 34] step 22/44: loss=7.9797 
[epoch 34] step 24/44: loss=8.0192 
[epoch 34] step 26/44: loss=8.0654 
[epoch 34] step 28/44: loss=8.0842 
[epoch 34] step 30/44: loss=8.1375 
[epoch 34] step 32/44: loss=8.1689 
[epoch 34] step 34/44: loss=8.1890 
[epoch 34] step 36/44: loss=8.1673 
[epoch 34] step 38/44: loss=8.1563 
[epoch 34] step 40/44: loss=8.1306 
[epoch 34] step 42/44: loss=8.1159 
[epoch 34] step 44/44: loss=8.1242 
[epoch 34] train_loss(avg per step)=16.2483 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=10.2449 qwk=('0.4852', '0.4165', '0.4749') averageQWK=0.4589 macroEMD=0.3736 tailR0=('0.1429', '0.0697', '0.0000') tailR0avg=0.0709
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     1    7   28    5    0
     1    5   68   46    2
     0    0   43   86   12
     0    0    1   14    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    8    2    0
     0    5   21   13    0
     2   13   36   53    0
     0    2   26  135    0
     0    0    0   15    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    9   40    3    0
     0   13   95   50    0
     0    2   30   78    0
     0    0    0    3    0
[epoch 35] step 2/44: loss=8.8581 
[epoch 35] step 4/44: loss=8.0838 
[epoch 35] step 6/44: loss=8.0398 
[epoch 35] step 8/44: loss=7.9207 
[epoch 35] step 10/44: loss=7.8036 
[epoch 35] step 12/44: loss=7.8740 
[epoch 35] step 14/44: loss=7.8316 
[epoch 35] step 16/44: loss=7.7421 
[epoch 35] step 18/44: loss=7.7181 
[epoch 35] step 20/44: loss=7.7006 
[epoch 35] step 22/44: loss=7.7285 
[epoch 35] step 24/44: loss=7.7376 
[epoch 35] step 26/44: loss=7.6994 
[epoch 35] step 28/44: loss=7.7284 
[epoch 35] step 30/44: loss=7.7096 
[epoch 35] step 32/44: loss=7.7281 
[epoch 35] step 34/44: loss=7.7648 
[epoch 35] step 36/44: loss=7.7304 
[epoch 35] step 38/44: loss=7.7074 
[epoch 35] step 40/44: loss=7.7454 
[epoch 35] step 42/44: loss=7.7705 
[epoch 35] step 44/44: loss=7.7924 
[epoch 35] train_loss(avg per step)=15.5848 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=10.7151 qwk=('0.4854', '0.4034', '0.4708') averageQWK=0.4532 macroEMD=0.3730 tailR0=('0.1190', '0.0697', '0.0000') tailR0avg=0.0629
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     1    7   28    5    0
     1    5   70   45    1
     0    0   44   86   11
     0    0    1   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    8    2    0
     0    5   21   13    0
     1   13   33   57    0
     0    4   23  136    0
     0    0    0   15    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    7    0    0
     0    7   42    3    0
     0   10   97   51    0
     0    2   29   79    0
     0    0    0    3    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-1/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-1/fold1/metrics.json
Done.
