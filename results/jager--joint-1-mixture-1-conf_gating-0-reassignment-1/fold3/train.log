[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=20.1128 
[epoch 1] step 4/44: loss=19.8911 
[epoch 1] step 6/44: loss=19.5398 
[epoch 1] step 8/44: loss=19.2007 
[epoch 1] step 10/44: loss=19.1172 
[epoch 1] step 12/44: loss=19.0662 
[epoch 1] step 14/44: loss=18.9411 
[epoch 1] step 16/44: loss=18.9627 
[epoch 1] step 18/44: loss=19.0993 
[epoch 1] step 20/44: loss=19.2071 
[epoch 1] step 22/44: loss=19.2144 
[epoch 1] step 24/44: loss=19.1688 
[epoch 1] step 26/44: loss=19.1965 
[epoch 1] step 28/44: loss=19.0918 
[epoch 1] step 30/44: loss=19.0321 
[epoch 1] step 32/44: loss=18.9976 
[epoch 1] step 34/44: loss=18.9098 
[epoch 1] step 36/44: loss=18.8853 
[epoch 1] step 38/44: loss=18.7778 
[epoch 1] step 40/44: loss=18.7427 
[epoch 1] step 42/44: loss=18.6725 
[epoch 1] step 44/44: loss=18.6067 
[epoch 1] train_loss(avg per step)=37.2134 lambda[min,max]=[0.524598,1.000000]
[epoch 1] val_loss=26.2865 qwk=('-0.0090', '-0.1057', '0.0453') averageQWK=-0.0231 macroEMD=0.4048 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    0    0
     0   37    0    3    0
     0  121    0    7    0
     0  117    0    5    0
     0   26    0    1    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
    13    0   35    0    0
    48    0   65    0    0
    78    0   70    0    0
     5    0    5    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    6   65    0    0
     0    8  143    0    0
     0    3   96    0    0
     0    0    3    0    0
[epoch 2] step 2/44: loss=18.7145 
[epoch 2] step 4/44: loss=18.7927 
[epoch 2] step 6/44: loss=19.0547 
[epoch 2] step 8/44: loss=18.7445 
[epoch 2] step 10/44: loss=18.2907 
[epoch 2] step 12/44: loss=17.8735 
[epoch 2] step 14/44: loss=17.6609 
[epoch 2] step 16/44: loss=17.3636 
[epoch 2] step 18/44: loss=17.0654 
[epoch 2] step 20/44: loss=16.8144 
[epoch 2] step 22/44: loss=16.6498 
[epoch 2] step 24/44: loss=16.4200 
[epoch 2] step 26/44: loss=16.1867 
[epoch 2] step 28/44: loss=16.0368 
[epoch 2] step 30/44: loss=15.8727 
[epoch 2] step 32/44: loss=15.7665 
[epoch 2] step 34/44: loss=15.5926 
[epoch 2] step 36/44: loss=15.4762 
[epoch 2] step 38/44: loss=15.3673 
[epoch 2] step 40/44: loss=15.2750 
[epoch 2] step 42/44: loss=15.1419 
[epoch 2] step 44/44: loss=15.0342 
[epoch 2] train_loss(avg per step)=30.0684 lambda[min,max]=[0.524050,1.000000]
[epoch 2] val_loss=14.1288 qwk=('0.2377', '0.2074', '0.0409') averageQWK=0.1620 macroEMD=0.3929 tailR0=('0.2801', '0.0000', '0.0000') tailR0avg=0.0934
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    4    1    0    0
    26    4    9    0    1
    56   10   50    0   12
    18   20   76    4    4
     1    4   13    4    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   22   24    2
     0    0   27   81    5
     0    0   19  124    5
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   69    0    0
     0    0  150    1    0
     0    0   97    2    0
     0    0    3    0    0
[epoch 3] step 2/44: loss=12.3053 
[epoch 3] step 4/44: loss=12.7544 
[epoch 3] step 6/44: loss=12.9125 
[epoch 3] step 8/44: loss=12.8135 
[epoch 3] step 10/44: loss=12.8049 
[epoch 3] step 12/44: loss=12.8718 
[epoch 3] step 14/44: loss=12.8059 
[epoch 3] step 16/44: loss=12.6567 
[epoch 3] step 18/44: loss=12.4799 
[epoch 3] step 20/44: loss=12.3976 
[epoch 3] step 22/44: loss=12.3636 
[epoch 3] step 24/44: loss=12.4046 
[epoch 3] step 26/44: loss=12.4544 
[epoch 3] step 28/44: loss=12.3774 
[epoch 3] step 30/44: loss=12.3416 
[epoch 3] step 32/44: loss=12.3195 
[epoch 3] step 34/44: loss=12.2952 
[epoch 3] step 36/44: loss=12.2907 
[epoch 3] step 38/44: loss=12.2625 
[epoch 3] step 40/44: loss=12.3504 
[epoch 3] step 42/44: loss=12.4581 
[epoch 3] step 44/44: loss=12.4989 
[epoch 3] train_loss(avg per step)=24.9978 lambda[min,max]=[0.500000,1.000000]
[epoch 3] val_loss=22.4207 qwk=('0.2556', '0.2717', '0.0233') averageQWK=0.1835 macroEMD=0.3895 tailR0=('0.0625', '0.0000', '0.0000') tailR0avg=0.0208
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    7    0    0    0
    12   27    0    1    0
    23   89    0   16    0
     4   71    0   47    0
     0   13    0   14    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   47    1    0
     0    0  105    8    0
     0    0  105   43    0
     0    0    2    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   69    0    0
     0    0  151    0    0
     0    0   99    0    0
     0    0    3    0    0
[epoch 4] step 2/44: loss=11.2795 
[epoch 4] step 4/44: loss=11.6075 
[epoch 4] step 6/44: loss=11.5372 
[epoch 4] step 8/44: loss=11.5608 
[epoch 4] step 10/44: loss=11.4622 
[epoch 4] step 12/44: loss=11.6334 
[epoch 4] step 14/44: loss=11.7242 
[epoch 4] step 16/44: loss=11.7085 
[epoch 4] step 18/44: loss=11.7589 
[epoch 4] step 20/44: loss=11.7838 
[epoch 4] step 22/44: loss=11.6868 
[epoch 4] step 24/44: loss=11.6068 
[epoch 4] step 26/44: loss=11.5383 
[epoch 4] step 28/44: loss=11.5750 
[epoch 4] step 30/44: loss=11.6052 
[epoch 4] step 32/44: loss=11.6158 
[epoch 4] step 34/44: loss=11.6794 
[epoch 4] step 36/44: loss=11.7031 
[epoch 4] step 38/44: loss=11.7578 
[epoch 4] step 40/44: loss=11.7143 
[epoch 4] step 42/44: loss=11.6881 
[epoch 4] step 44/44: loss=11.6899 
[epoch 4] train_loss(avg per step)=23.3798 lambda[min,max]=[0.500000,1.000000]
[epoch 4] val_loss=23.4190 qwk=('0.4210', '0.2879', '0.2628') averageQWK=0.3239 macroEMD=0.3830 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    0    0
     0    0   38    2    0
     0    0   95   33    0
     0    0   48   74    0
     0    0    3   24    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   25   23    0
     0    0   26   87    0
     0    0    9  139    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    0   43   28    0
     0    0   35  116    0
     0    0    3   96    0
     0    0    0    3    0
[epoch 5] step 2/44: loss=13.1713 
[epoch 5] step 4/44: loss=12.7777 
[epoch 5] step 6/44: loss=12.2293 
[epoch 5] step 8/44: loss=11.9116 
[epoch 5] step 10/44: loss=11.4878 
[epoch 5] step 12/44: loss=11.2305 
[epoch 5] step 14/44: loss=11.1202 
[epoch 5] step 16/44: loss=11.1414 
[epoch 5] step 18/44: loss=11.3436 
[epoch 5] step 20/44: loss=11.4513 
[epoch 5] step 22/44: loss=11.4016 
[epoch 5] step 24/44: loss=11.2837 
[epoch 5] step 26/44: loss=11.1691 
[epoch 5] step 28/44: loss=11.0089 
[epoch 5] step 30/44: loss=10.8843 
[epoch 5] step 32/44: loss=10.7951 
[epoch 5] step 34/44: loss=10.7884 
[epoch 5] step 36/44: loss=10.8162 
[epoch 5] step 38/44: loss=10.8414 
[epoch 5] step 40/44: loss=10.8168 
[epoch 5] step 42/44: loss=10.7754 
[epoch 5] step 44/44: loss=10.7183 
[epoch 5] train_loss(avg per step)=21.4365 lambda[min,max]=[0.550817,1.000000]
[epoch 5] val_loss=16.1973 qwk=('0.2206', '0.3297', '0.1803') averageQWK=0.2435 macroEMD=0.3847 tailR0=('0.1250', '0.0000', '0.0000') tailR0avg=0.0417
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    6    0    0    0
    22   18    0    0    0
    86   17    0   24    1
    49    5    0   67    1
     9    0    0   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    5   16   27    0
     0    0   25   88    0
     0    1    7  140    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   15   56    0    0
     0    9  142    0    0
     0    0   99    0    0
     0    0    3    0    0
[epoch 6] step 2/44: loss=10.1447 
[epoch 6] step 4/44: loss=9.6514 
[epoch 6] step 6/44: loss=9.7312 
[epoch 6] step 8/44: loss=9.4938 
[epoch 6] step 10/44: loss=9.3501 
[epoch 6] step 12/44: loss=9.4859 
[epoch 6] step 14/44: loss=9.6182 
[epoch 6] step 16/44: loss=9.5780 
[epoch 6] step 18/44: loss=9.5418 
[epoch 6] step 20/44: loss=9.5656 
[epoch 6] step 22/44: loss=9.5312 
[epoch 6] step 24/44: loss=9.4992 
[epoch 6] step 26/44: loss=9.4477 
[epoch 6] step 28/44: loss=9.4399 
[epoch 6] step 30/44: loss=9.4596 
[epoch 6] step 32/44: loss=9.4633 
[epoch 6] step 34/44: loss=9.4759 
[epoch 6] step 36/44: loss=9.4224 
[epoch 6] step 38/44: loss=9.3636 
[epoch 6] step 40/44: loss=9.2896 
[epoch 6] step 42/44: loss=9.2584 
[epoch 6] step 44/44: loss=9.1507 
[epoch 6] train_loss(avg per step)=18.3013 lambda[min,max]=[0.500000,1.000000]
[epoch 6] val_loss=7.2244 qwk=('0.3751', '0.4556', '0.6010') averageQWK=0.4772 macroEMD=0.3843 tailR0=('0.0741', '0.0000', '0.0000') tailR0avg=0.0247
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    0    0
     1   37    2    0    0
     0   94   25    8    1
     1   44   35   38    4
     1    4    5   13    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     1   26   16    5    0
     5   27   60   21    0
     5    8   51   84    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   58   11    2    0
     0   70   41   40    0
     0    5   20   74    0
     0    0    1    2    0
[epoch 7] step 2/44: loss=6.9735 
[epoch 7] step 4/44: loss=7.8672 
[epoch 7] step 6/44: loss=8.6190 
[epoch 7] step 8/44: loss=8.8973 
[epoch 7] step 10/44: loss=9.0632 
[epoch 7] step 12/44: loss=9.0944 
[epoch 7] step 14/44: loss=8.9063 
[epoch 7] step 16/44: loss=8.8556 
[epoch 7] step 18/44: loss=8.7368 
[epoch 7] step 20/44: loss=8.6629 
[epoch 7] step 22/44: loss=8.5947 
[epoch 7] step 24/44: loss=8.5982 
[epoch 7] step 26/44: loss=8.6280 
[epoch 7] step 28/44: loss=8.6137 
[epoch 7] step 30/44: loss=8.6214 
[epoch 7] step 32/44: loss=8.6848 
[epoch 7] step 34/44: loss=8.6795 
[epoch 7] step 36/44: loss=8.6509 
[epoch 7] step 38/44: loss=8.6280 
[epoch 7] step 40/44: loss=8.6187 
[epoch 7] step 42/44: loss=8.6073 
[epoch 7] step 44/44: loss=8.5500 
[epoch 7] train_loss(avg per step)=17.1000 lambda[min,max]=[0.500000,1.000000]
[epoch 7] val_loss=13.9325 qwk=('0.2540', '0.3457', '0.3584') averageQWK=0.3194 macroEMD=0.3773 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    0    0
     0    1   39    0    0
     0    0  126    2    0
     0    0   95   27    0
     0    0   16   11    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    0   47    1    0
     0    0  107    6    0
     0    0   96   52    0
     0    0    2    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   10   61    0    0
     0    1  149    1    0
     0    0   71   28    0
     0    0    2    1    0
[epoch 8] step 2/44: loss=9.2787 
[epoch 8] step 4/44: loss=8.9578 
[epoch 8] step 6/44: loss=8.6742 
[epoch 8] step 8/44: loss=8.3918 
[epoch 8] step 10/44: loss=8.2564 
[epoch 8] step 12/44: loss=8.1463 
[epoch 8] step 14/44: loss=8.1929 
[epoch 8] step 16/44: loss=8.3359 
[epoch 8] step 18/44: loss=8.4177 
[epoch 8] step 20/44: loss=8.5464 
[epoch 8] step 22/44: loss=8.6344 
[epoch 8] step 24/44: loss=8.5932 
[epoch 8] step 26/44: loss=8.5136 
[epoch 8] step 28/44: loss=8.4219 
[epoch 8] step 30/44: loss=8.3481 
[epoch 8] step 32/44: loss=8.3256 
[epoch 8] step 34/44: loss=8.2972 
[epoch 8] step 36/44: loss=8.2893 
[epoch 8] step 38/44: loss=8.3111 
[epoch 8] step 40/44: loss=8.3219 
[epoch 8] step 42/44: loss=8.3532 
[epoch 8] step 44/44: loss=8.3291 
[epoch 8] train_loss(avg per step)=16.6582 lambda[min,max]=[0.500000,1.000000]
[epoch 8] val_loss=7.7109 qwk=('0.3445', '0.4807', '0.5970') averageQWK=0.4741 macroEMD=0.3767 tailR0=('0.1366', '0.0000', '0.0000') tailR0avg=0.0455
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    5    0    0
     2    0   38    0    0
     2    0  121    5    0
     2    0   84   33    3
     0    0   14    9    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   10   36    2    0
     0    3   95   15    0
     0    1   77   70    0
     0    0    2    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   42   25    4    0
     0   37   74   40    0
     0    2   21   76    0
     0    0    1    2    0
[epoch 9] step 2/44: loss=7.0976 
[epoch 9] step 4/44: loss=7.1512 
[epoch 9] step 6/44: loss=7.3685 
[epoch 9] step 8/44: loss=7.5337 
[epoch 9] step 10/44: loss=7.5164 
[epoch 9] step 12/44: loss=7.4823 
[epoch 9] step 14/44: loss=7.5339 
[epoch 9] step 16/44: loss=7.6212 
[epoch 9] step 18/44: loss=7.6918 
[epoch 9] step 20/44: loss=7.8506 
[epoch 9] step 22/44: loss=7.9382 
[epoch 9] step 24/44: loss=8.0074 
[epoch 9] step 26/44: loss=7.9785 
[epoch 9] step 28/44: loss=7.9598 
[epoch 9] step 30/44: loss=7.9321 
[epoch 9] step 32/44: loss=7.9251 
[epoch 9] step 34/44: loss=7.9219 
[epoch 9] step 36/44: loss=7.9234 
[epoch 9] step 38/44: loss=7.9239 
[epoch 9] step 40/44: loss=7.9288 
[epoch 9] step 42/44: loss=7.8904 
[epoch 9] step 44/44: loss=7.8548 
[epoch 9] train_loss(avg per step)=15.7095 lambda[min,max]=[0.500000,1.000000]
[epoch 9] val_loss=10.0952 qwk=('0.4596', '0.4849', '0.5744') averageQWK=0.5063 macroEMD=0.3721 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     2    2   29    7    0
     4    0   77   47    0
     0    0   33   89    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   13   21   14    0
     0    9   46   58    0
     0    1   26  121    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   46   22    3    0
     0   53   58   40    0
     0    5   22   72    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=7.4855 
[epoch 10] step 4/44: loss=8.1098 
[epoch 10] step 6/44: loss=8.4994 
[epoch 10] step 8/44: loss=8.5377 
[epoch 10] step 10/44: loss=8.3589 
[epoch 10] step 12/44: loss=8.1272 
[epoch 10] step 14/44: loss=8.0225 
[epoch 10] step 16/44: loss=7.9378 
[epoch 10] step 18/44: loss=7.9535 
[epoch 10] step 20/44: loss=7.9488 
[epoch 10] step 22/44: loss=7.8739 
[epoch 10] step 24/44: loss=7.8078 
[epoch 10] step 26/44: loss=7.8315 
[epoch 10] step 28/44: loss=7.9019 
[epoch 10] step 30/44: loss=8.0415 
[epoch 10] step 32/44: loss=8.1230 
[epoch 10] step 34/44: loss=8.1205 
[epoch 10] step 36/44: loss=8.1004 
[epoch 10] step 38/44: loss=8.0847 
[epoch 10] step 40/44: loss=8.0771 
[epoch 10] step 42/44: loss=8.0439 
[epoch 10] step 44/44: loss=7.9979 
[epoch 10] train_loss(avg per step)=15.9958 lambda[min,max]=[0.500000,1.000000]
[epoch 10] val_loss=13.9747 qwk=('0.3891', '0.4149', '0.5407') averageQWK=0.4482 macroEMD=0.3712 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    0    0
     0    1   37    2    0
     0    0  109   19    0
     0    0   61   61    0
     0    0    6   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    2   40    6    0
     0    0   98   15    0
     0    0   77   71    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   21   49    1    0
     0   10  118   23    0
     0    0   41   58    0
     0    0    1    2    0
[epoch 11] step 2/44: loss=9.0769 
[epoch 11] step 4/44: loss=8.9367 
[epoch 11] step 6/44: loss=8.7286 
[epoch 11] step 8/44: loss=8.4083 
[epoch 11] step 10/44: loss=8.1719 
[epoch 11] step 12/44: loss=8.0376 
[epoch 11] step 14/44: loss=8.0452 
[epoch 11] step 16/44: loss=8.1550 
[epoch 11] step 18/44: loss=8.3382 
[epoch 11] step 20/44: loss=8.3536 
[epoch 11] step 22/44: loss=8.2837 
[epoch 11] step 24/44: loss=8.2276 
[epoch 11] step 26/44: loss=8.2237 
[epoch 11] step 28/44: loss=8.2122 
[epoch 11] step 30/44: loss=8.2014 
[epoch 11] step 32/44: loss=8.0923 
[epoch 11] step 34/44: loss=8.0297 
[epoch 11] step 36/44: loss=8.0108 
[epoch 11] step 38/44: loss=8.0998 
[epoch 11] step 40/44: loss=8.1470 
[epoch 11] step 42/44: loss=8.1606 
[epoch 11] step 44/44: loss=8.1425 
[epoch 11] train_loss(avg per step)=16.2851 lambda[min,max]=[0.520501,1.000000]
[epoch 11] val_loss=9.7443 qwk=('0.5144', '0.4498', '0.5341') averageQWK=0.4994 macroEMD=0.3678 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0   17   18    5    0
     1   21   68   38    0
     0    5   32   85    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   13   18   17    0
     1    8   28   76    0
     0    2   14  132    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   50    5    0
     0    6   96   49    0
     0    0   21   78    0
     0    0    0    3    0
[epoch 12] step 2/44: loss=8.1634 
[epoch 12] step 4/44: loss=7.7863 
[epoch 12] step 6/44: loss=7.8936 
[epoch 12] step 8/44: loss=7.8100 
[epoch 12] step 10/44: loss=7.9076 
[epoch 12] step 12/44: loss=7.9300 
[epoch 12] step 14/44: loss=7.9166 
[epoch 12] step 16/44: loss=7.8773 
[epoch 12] step 18/44: loss=7.8498 
[epoch 12] step 20/44: loss=7.7847 
[epoch 12] step 22/44: loss=7.7995 
[epoch 12] step 24/44: loss=7.8367 
[epoch 12] step 26/44: loss=7.8908 
[epoch 12] step 28/44: loss=7.8413 
[epoch 12] step 30/44: loss=7.8392 
[epoch 12] step 32/44: loss=7.8345 
[epoch 12] step 34/44: loss=7.8318 
[epoch 12] step 36/44: loss=7.8626 
[epoch 12] step 38/44: loss=7.8819 
[epoch 12] step 40/44: loss=7.8664 
[epoch 12] step 42/44: loss=7.8831 
[epoch 12] step 44/44: loss=7.8893 
[epoch 12] train_loss(avg per step)=15.7785 lambda[min,max]=[0.500000,1.000000]
[epoch 12] val_loss=11.5148 qwk=('0.4965', '0.4954', '0.5489') averageQWK=0.5136 macroEMD=0.3684 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    0    0    0
     0   20    6   14    0
     0   25   24   78    1
     0    4   10  108    0
     0    0    1   26    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   11   29    8    0
     0    6   51   56    0
     0    2   33  113    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   30   36    5    0
     0   12   74   65    0
     0    1   21   77    0
     0    0    0    3    0
[epoch 13] step 2/44: loss=8.2196 
[epoch 13] step 4/44: loss=8.1702 
[epoch 13] step 6/44: loss=8.1783 
[epoch 13] step 8/44: loss=8.0013 
[epoch 13] step 10/44: loss=7.8390 
[epoch 13] step 12/44: loss=7.7738 
[epoch 13] step 14/44: loss=7.7278 
[epoch 13] step 16/44: loss=7.6328 
[epoch 13] step 18/44: loss=7.7258 
[epoch 13] step 20/44: loss=7.8379 
[epoch 13] step 22/44: loss=7.8808 
[epoch 13] step 24/44: loss=7.7765 
[epoch 13] step 26/44: loss=7.7255 
[epoch 13] step 28/44: loss=7.7723 
[epoch 13] step 30/44: loss=7.8565 
[epoch 13] step 32/44: loss=7.8890 
[epoch 13] step 34/44: loss=7.8387 
[epoch 13] step 36/44: loss=7.8295 
[epoch 13] step 38/44: loss=7.7758 
[epoch 13] step 40/44: loss=7.7826 
[epoch 13] step 42/44: loss=7.8167 
[epoch 13] step 44/44: loss=7.8771 
[epoch 13] train_loss(avg per step)=15.7542 lambda[min,max]=[0.500000,1.000000]
[epoch 13] val_loss=12.8689 qwk=('0.4585', '0.3870', '0.4318') averageQWK=0.4258 macroEMD=0.3723 tailR0=('0.0741', '0.0000', '0.0000') tailR0avg=0.0247
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    0    0
     0    1   37    2    0
     0    1   92   34    1
     0    0   46   73    3
     0    0    6   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    0   45    3    0
     0    0   92   21    0
     0    0   77   71    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   11   60    0    0
     0    1  136   14    0
     0    0   56   43    0
     0    0    2    1    0
[epoch 14] step 2/44: loss=7.5551 
[epoch 14] step 4/44: loss=7.0912 
[epoch 14] step 6/44: loss=6.6431 
[epoch 14] step 8/44: loss=6.7330 
[epoch 14] step 10/44: loss=6.9150 
[epoch 14] step 12/44: loss=7.1455 
[epoch 14] step 14/44: loss=7.3719 
[epoch 14] step 16/44: loss=7.6387 
[epoch 14] step 18/44: loss=7.8467 
[epoch 14] step 20/44: loss=7.8780 
[epoch 14] step 22/44: loss=7.7728 
[epoch 14] step 24/44: loss=7.6658 
[epoch 14] step 26/44: loss=7.5838 
[epoch 14] step 28/44: loss=7.5703 
[epoch 14] step 30/44: loss=7.5969 
[epoch 14] step 32/44: loss=7.6790 
[epoch 14] step 34/44: loss=7.7232 
[epoch 14] step 36/44: loss=7.7896 
[epoch 14] step 38/44: loss=7.8187 
[epoch 14] step 40/44: loss=7.7762 
[epoch 14] step 42/44: loss=7.7331 
[epoch 14] step 44/44: loss=7.6956 
[epoch 14] train_loss(avg per step)=15.3912 lambda[min,max]=[0.500000,1.000000]
[epoch 14] val_loss=15.0690 qwk=('0.4569', '0.3815', '0.4778') averageQWK=0.4387 macroEMD=0.3697 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    4   32    4    0
     0    5   95   28    0
     0    0   49   73    0
     0    0    7   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    0   45    3    0
     0    1   98   14    0
     0    0   81   67    0
     0    0    2    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   10   60    1    0
     0    2  121   28    0
     0    0   39   60    0
     0    0    2    1    0
[epoch 15] step 2/44: loss=7.6717 
[epoch 15] step 4/44: loss=8.3582 
[epoch 15] step 6/44: loss=8.9028 
[epoch 15] step 8/44: loss=8.6704 
[epoch 15] step 10/44: loss=8.4274 
[epoch 15] step 12/44: loss=8.2024 
[epoch 15] step 14/44: loss=8.0535 
[epoch 15] step 16/44: loss=7.9472 
[epoch 15] step 18/44: loss=7.9982 
[epoch 15] step 20/44: loss=8.0481 
[epoch 15] step 22/44: loss=8.0300 
[epoch 15] step 24/44: loss=7.9472 
[epoch 15] step 26/44: loss=7.9204 
[epoch 15] step 28/44: loss=7.9209 
[epoch 15] step 30/44: loss=7.9094 
[epoch 15] step 32/44: loss=7.9748 
[epoch 15] step 34/44: loss=7.9599 
[epoch 15] step 36/44: loss=7.8711 
[epoch 15] step 38/44: loss=7.8379 
[epoch 15] step 40/44: loss=7.8375 
[epoch 15] step 42/44: loss=7.8294 
[epoch 15] step 44/44: loss=7.8698 
[epoch 15] train_loss(avg per step)=15.7396 lambda[min,max]=[0.500000,1.000000]
[epoch 15] val_loss=13.4142 qwk=('0.4272', '0.4853', '0.5484') averageQWK=0.4870 macroEMD=0.3670 tailR0=('0.0625', '0.0833', '0.0000') tailR0avg=0.0486
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    4    0    0
     1    1   30    8    0
     1    2   85   40    0
     0    0   41   81    0
     0    0    5   22    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     3    3   33    9    0
     2    2   65   44    0
     0    0   43  105    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   42   22    7    0
     0   37   64   50    0
     0    4   21   74    0
     0    0    0    3    0
[epoch 16] step 2/44: loss=7.7726 
[epoch 16] step 4/44: loss=8.1559 
[epoch 16] step 6/44: loss=8.1806 
[epoch 16] step 8/44: loss=8.1282 
[epoch 16] step 10/44: loss=7.9144 
[epoch 16] step 12/44: loss=7.8694 
[epoch 16] step 14/44: loss=8.0222 
[epoch 16] step 16/44: loss=8.1396 
[epoch 16] step 18/44: loss=8.3610 
[epoch 16] step 20/44: loss=8.2867 
[epoch 16] step 22/44: loss=8.2142 
[epoch 16] step 24/44: loss=8.2267 
[epoch 16] step 26/44: loss=8.0848 
[epoch 16] step 28/44: loss=8.0776 
[epoch 16] step 30/44: loss=8.1000 
[epoch 16] step 32/44: loss=8.1012 
[epoch 16] step 34/44: loss=8.1142 
[epoch 16] step 36/44: loss=8.0929 
[epoch 16] step 38/44: loss=8.0741 
[epoch 16] step 40/44: loss=8.0617 
[epoch 16] step 42/44: loss=8.0901 
[epoch 16] step 44/44: loss=8.0969 
[epoch 16] train_loss(avg per step)=16.1937 lambda[min,max]=[0.500000,1.000000]
[epoch 16] val_loss=11.4563 qwk=('0.4678', '0.4672', '0.4972') averageQWK=0.4774 macroEMD=0.3700 tailR0=('0.0995', '0.0000', '0.0000') tailR0avg=0.0332
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     1    3   30    6    0
     1    4   89   33    1
     0    0   44   76    2
     0    0    6   19    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    5   35    8    0
     0    5   75   33    0
     0    1   51   96    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   48    3    0
     0   14  100   37    0
     0    1   33   65    0
     0    0    2    1    0
[epoch 17] step 2/44: loss=6.9418 
[epoch 17] step 4/44: loss=7.4703 
[epoch 17] step 6/44: loss=7.4826 
[epoch 17] step 8/44: loss=7.4703 
[epoch 17] step 10/44: loss=7.5217 
[epoch 17] step 12/44: loss=7.5463 
[epoch 17] step 14/44: loss=7.4733 
[epoch 17] step 16/44: loss=7.4676 
[epoch 17] step 18/44: loss=7.4401 
[epoch 17] step 20/44: loss=7.5275 
[epoch 17] step 22/44: loss=7.6899 
[epoch 17] step 24/44: loss=7.8085 
[epoch 17] step 26/44: loss=7.8705 
[epoch 17] step 28/44: loss=7.8979 
[epoch 17] step 30/44: loss=7.8660 
[epoch 17] step 32/44: loss=7.8266 
[epoch 17] step 34/44: loss=7.8081 
[epoch 17] step 36/44: loss=7.7769 
[epoch 17] step 38/44: loss=7.7004 
[epoch 17] step 40/44: loss=7.6389 
[epoch 17] step 42/44: loss=7.6326 
[epoch 17] step 44/44: loss=7.6425 
[epoch 17] train_loss(avg per step)=15.2850 lambda[min,max]=[0.500000,1.000000]
[epoch 17] val_loss=12.5924 qwk=('0.5064', '0.4853', '0.4641') averageQWK=0.4853 macroEMD=0.3646 tailR0=('0.0625', '0.0000', '0.0000') tailR0avg=0.0208
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1   13   16   10    0
     0   14   46   68    0
     0    2   20  100    0
     0    0    1   26    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   18   15   15    0
     0   23   24   66    0
     0    5   16  127    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   30   24   17    0
     0   22   55   74    0
     0    2   12   85    0
     0    0    0    3    0
[epoch 18] step 2/44: loss=8.8366 
[epoch 18] step 4/44: loss=8.6816 
[epoch 18] step 6/44: loss=8.8498 
[epoch 18] step 8/44: loss=8.6824 
[epoch 18] step 10/44: loss=8.4259 
[epoch 18] step 12/44: loss=8.3895 
[epoch 18] step 14/44: loss=8.2087 
[epoch 18] step 16/44: loss=8.0419 
[epoch 18] step 18/44: loss=7.8768 
[epoch 18] step 20/44: loss=7.8162 
[epoch 18] step 22/44: loss=7.8138 
[epoch 18] step 24/44: loss=7.8434 
[epoch 18] step 26/44: loss=7.9111 
[epoch 18] step 28/44: loss=8.0185 
[epoch 18] step 30/44: loss=8.0812 
[epoch 18] step 32/44: loss=8.0758 
[epoch 18] step 34/44: loss=7.9758 
[epoch 18] step 36/44: loss=7.9394 
[epoch 18] step 38/44: loss=7.9398 
[epoch 18] step 40/44: loss=7.9695 
[epoch 18] step 42/44: loss=7.9677 
[epoch 18] step 44/44: loss=7.9926 
[epoch 18] train_loss(avg per step)=15.9853 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=10.2276 qwk=('0.5006', '0.4529', '0.4960') averageQWK=0.4831 macroEMD=0.3652 tailR0=('0.0810', '0.0833', '0.0000') tailR0avg=0.0548
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     2   12   16   10    0
     1   17   56   54    0
     0    4   29   89    0
     0    0    2   24    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     1   16   13   18    0
     1   20   28   64    0
     0    7   14  127    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   34   24   13    0
     0   30   51   70    0
     0    4    9   86    0
     0    0    0    3    0
[epoch 19] step 2/44: loss=7.9401 
[epoch 19] step 4/44: loss=8.4818 
[epoch 19] step 6/44: loss=8.2363 
[epoch 19] step 8/44: loss=8.1369 
[epoch 19] step 10/44: loss=8.0376 
[epoch 19] step 12/44: loss=7.8896 
[epoch 19] step 14/44: loss=7.7838 
[epoch 19] step 16/44: loss=7.6696 
[epoch 19] step 18/44: loss=7.5823 
[epoch 19] step 20/44: loss=7.5365 
[epoch 19] step 22/44: loss=7.6711 
[epoch 19] step 24/44: loss=7.7236 
[epoch 19] step 26/44: loss=7.7793 
[epoch 19] step 28/44: loss=7.8139 
[epoch 19] step 30/44: loss=7.8960 
[epoch 19] step 32/44: loss=7.9045 
[epoch 19] step 34/44: loss=7.8676 
[epoch 19] step 36/44: loss=7.8692 
[epoch 19] step 38/44: loss=7.8769 
[epoch 19] step 40/44: loss=7.8890 
[epoch 19] step 42/44: loss=7.8802 
[epoch 19] step 44/44: loss=7.8468 
[epoch 19] train_loss(avg per step)=15.6937 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=10.4253 qwk=('0.4780', '0.4770', '0.5057') averageQWK=0.4869 macroEMD=0.3680 tailR0=('0.1181', '0.0000', '0.0000') tailR0avg=0.0394
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1   10   18   11    0
     1   13   60   50    4
     0    2   30   86    4
     0    0    2   22    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   14   20   14    0
     0   17   44   52    0
     0    4   25  119    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   36   25   10    0
     0   37   55   59    0
     0    5   14   80    0
     0    0    0    3    0
[epoch 20] step 2/44: loss=8.0645 
[epoch 20] step 4/44: loss=7.7562 
[epoch 20] step 6/44: loss=7.7942 
[epoch 20] step 8/44: loss=7.9929 
[epoch 20] step 10/44: loss=8.0946 
[epoch 20] step 12/44: loss=8.2829 
[epoch 20] step 14/44: loss=8.1524 
[epoch 20] step 16/44: loss=8.0610 
[epoch 20] step 18/44: loss=7.9892 
[epoch 20] step 20/44: loss=7.8972 
[epoch 20] step 22/44: loss=7.8317 
[epoch 20] step 24/44: loss=7.8359 
[epoch 20] step 26/44: loss=7.8029 
[epoch 20] step 28/44: loss=7.8255 
[epoch 20] step 30/44: loss=7.8625 
[epoch 20] step 32/44: loss=7.9223 
[epoch 20] step 34/44: loss=7.9517 
[epoch 20] step 36/44: loss=7.9555 
[epoch 20] step 38/44: loss=7.9909 
[epoch 20] step 40/44: loss=7.9362 
[epoch 20] step 42/44: loss=7.9340 
[epoch 20] step 44/44: loss=7.9530 
[epoch 20] train_loss(avg per step)=15.9061 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=11.7539 qwk=('0.4468', '0.4721', '0.4631') averageQWK=0.4607 macroEMD=0.3700 tailR0=('0.0625', '0.0000', '0.0000') tailR0avg=0.0208
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     1    7   23    9    0
     1    7   75   45    0
     0    1   42   79    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     1    7   29   11    0
     1    6   52   54    0
     0    0   35  113    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   20   42    9    0
     0   11   83   57    0
     0    3   22   74    0
     0    0    0    3    0
[epoch 21] step 2/44: loss=7.8268 
[epoch 21] step 4/44: loss=7.4946 
[epoch 21] step 6/44: loss=7.3610 
[epoch 21] step 8/44: loss=7.2832 
[epoch 21] step 10/44: loss=7.2719 
[epoch 21] step 12/44: loss=7.2746 
[epoch 21] step 14/44: loss=7.3976 
[epoch 21] step 16/44: loss=7.4892 
[epoch 21] step 18/44: loss=7.6806 
[epoch 21] step 20/44: loss=7.7875 
[epoch 21] step 22/44: loss=7.8065 
[epoch 21] step 24/44: loss=7.7665 
[epoch 21] step 26/44: loss=7.6790 
[epoch 21] step 28/44: loss=7.6817 
[epoch 21] step 30/44: loss=7.6758 
[epoch 21] step 32/44: loss=7.7255 
[epoch 21] step 34/44: loss=7.7756 
[epoch 21] step 36/44: loss=7.8390 
[epoch 21] step 38/44: loss=7.8838 
[epoch 21] step 40/44: loss=7.9089 
[epoch 21] step 42/44: loss=7.8406 
[epoch 21] step 44/44: loss=7.8722 
[epoch 21] train_loss(avg per step)=15.7443 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=9.7862 qwk=('0.4810', '0.4964', '0.4755') averageQWK=0.4843 macroEMD=0.3709 tailR0=('0.1181', '0.0000', '0.0000') tailR0avg=0.0394
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1   11   19    9    0
     1   13   75   34    5
     0    1   45   75    1
     0    0    3   21    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     1   12   24   11    0
     1   11   64   37    0
     0    2   41  105    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   32    8    0
     0   33   72   46    0
     0    4   24   71    0
     0    1    0    2    0
[epoch 22] step 2/44: loss=7.1652 
[epoch 22] step 4/44: loss=7.1474 
[epoch 22] step 6/44: loss=7.3314 
[epoch 22] step 8/44: loss=7.4325 
[epoch 22] step 10/44: loss=7.4927 
[epoch 22] step 12/44: loss=7.6449 
[epoch 22] step 14/44: loss=7.7441 
[epoch 22] step 16/44: loss=7.8559 
[epoch 22] step 18/44: loss=7.9129 
[epoch 22] step 20/44: loss=7.9500 
[epoch 22] step 22/44: loss=8.0027 
[epoch 22] step 24/44: loss=7.9456 
[epoch 22] step 26/44: loss=7.8739 
[epoch 22] step 28/44: loss=7.7435 
[epoch 22] step 30/44: loss=7.6804 
[epoch 22] step 32/44: loss=7.6743 
[epoch 22] step 34/44: loss=7.6898 
[epoch 22] step 36/44: loss=7.7336 
[epoch 22] step 38/44: loss=7.7775 
[epoch 22] step 40/44: loss=7.7970 
[epoch 22] step 42/44: loss=7.8129 
[epoch 22] step 44/44: loss=7.8641 
[epoch 22] train_loss(avg per step)=15.7281 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=10.2972 qwk=('0.4638', '0.4287', '0.4089') averageQWK=0.4338 macroEMD=0.3706 tailR0=('0.1181', '0.0000', '0.0000') tailR0avg=0.0394
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     1    6   22   11    0
     1    5   68   49    5
     0    0   30   87    5
     0    0    2   22    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     1    9   21   17    0
     1    8   33   71    0
     0    2   17  129    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   21   31   19    0
     0   12   58   81    0
     0    1   15   83    0
     0    0    0    3    0
[epoch 23] step 2/44: loss=8.3685 
[epoch 23] step 4/44: loss=8.0928 
[epoch 23] step 6/44: loss=7.5251 
[epoch 23] step 8/44: loss=7.2950 
[epoch 23] step 10/44: loss=7.3561 
[epoch 23] step 12/44: loss=7.3986 
[epoch 23] step 14/44: loss=7.4756 
[epoch 23] step 16/44: loss=7.5612 
[epoch 23] step 18/44: loss=7.8766 
[epoch 23] step 20/44: loss=8.0285 
[epoch 23] step 22/44: loss=7.9884 
[epoch 23] step 24/44: loss=7.9487 
[epoch 23] step 26/44: loss=7.9098 
[epoch 23] step 28/44: loss=7.8335 
[epoch 23] step 30/44: loss=7.8369 
[epoch 23] step 32/44: loss=7.7597 
[epoch 23] step 34/44: loss=7.7400 
[epoch 23] step 36/44: loss=7.7522 
[epoch 23] step 38/44: loss=7.7223 
[epoch 23] step 40/44: loss=7.7423 
[epoch 23] step 42/44: loss=7.7302 
[epoch 23] step 44/44: loss=7.6916 
[epoch 23] train_loss(avg per step)=15.3832 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=11.1714 qwk=('0.4615', '0.4777', '0.4620') averageQWK=0.4671 macroEMD=0.3661 tailR0=('0.0995', '0.0000', '0.0000') tailR0avg=0.0332
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1    9   20   10    0
     1   12   70   43    2
     0    0   42   79    1
     0    0    5   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     1   12   22   13    0
     1   11   45   56    0
     0    3   26  119    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   28   30   13    0
     0   20   73   58    0
     0    4   19   76    0
     0    0    0    3    0
[epoch 24] step 2/44: loss=8.1475 
[epoch 24] step 4/44: loss=8.5159 
[epoch 24] step 6/44: loss=8.2615 
[epoch 24] step 8/44: loss=8.1614 
[epoch 24] step 10/44: loss=8.1818 
[epoch 24] step 12/44: loss=8.2338 
[epoch 24] step 14/44: loss=8.0776 
[epoch 24] step 16/44: loss=8.0313 
[epoch 24] step 18/44: loss=7.9139 
[epoch 24] step 20/44: loss=7.8578 
[epoch 24] step 22/44: loss=7.9120 
[epoch 24] step 24/44: loss=7.9345 
[epoch 24] step 26/44: loss=8.0591 
[epoch 24] step 28/44: loss=8.0553 
[epoch 24] step 30/44: loss=8.0173 
[epoch 24] step 32/44: loss=8.0132 
[epoch 24] step 34/44: loss=7.9975 
[epoch 24] step 36/44: loss=7.9541 
[epoch 24] step 38/44: loss=7.9376 
[epoch 24] step 40/44: loss=7.9426 
[epoch 24] step 42/44: loss=7.9347 
[epoch 24] step 44/44: loss=7.9514 
[epoch 24] train_loss(avg per step)=15.9028 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=11.3661 qwk=('0.4698', '0.4718', '0.4648') averageQWK=0.4688 macroEMD=0.3680 tailR0=('0.0556', '0.0000', '0.0000') tailR0avg=0.0185
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    1    0
     1   13   14   12    0
     1   15   41   68    3
     0    3   17  100    2
     0    0    1   23    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     2   16   17   13    0
     1   20   42   50    0
     1    5   29  113    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   31   14    0
     0   18   60   73    0
     0    2   14   83    0
     0    0    0    3    0
[epoch 25] step 2/44: loss=8.1631 
[epoch 25] step 4/44: loss=7.8932 
[epoch 25] step 6/44: loss=7.9637 
[epoch 25] step 8/44: loss=7.9274 
[epoch 25] step 10/44: loss=7.8581 
[epoch 25] step 12/44: loss=7.6967 
[epoch 25] step 14/44: loss=7.6790 
[epoch 25] step 16/44: loss=7.7395 
[epoch 25] step 18/44: loss=7.7771 
[epoch 25] step 20/44: loss=7.7964 
[epoch 25] step 22/44: loss=7.8500 
[epoch 25] step 24/44: loss=7.9177 
[epoch 25] step 26/44: loss=7.9483 
[epoch 25] step 28/44: loss=7.9167 
[epoch 25] step 30/44: loss=7.9457 
[epoch 25] step 32/44: loss=7.9899 
[epoch 25] step 34/44: loss=8.0111 
[epoch 25] step 36/44: loss=7.9467 
[epoch 25] step 38/44: loss=7.8513 
[epoch 25] step 40/44: loss=7.8109 
[epoch 25] step 42/44: loss=7.8080 
[epoch 25] step 44/44: loss=7.7608 
[epoch 25] train_loss(avg per step)=15.5216 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=10.8166 qwk=('0.4794', '0.4455', '0.4442') averageQWK=0.4564 macroEMD=0.3686 tailR0=('0.0625', '0.0000', '0.0000') tailR0avg=0.0208
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1   10   18   11    0
     1   16   53   56    2
     0    2   23   97    0
     0    0    2   25    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     1   17   15   15    0
     2   22   30   59    0
     1    7   20  120    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   37   16    0
     0    6   78   67    0
     0    0   17   82    0
     0    0    0    3    0
[epoch 26] step 2/44: loss=7.5910 
[epoch 26] step 4/44: loss=7.9407 
[epoch 26] step 6/44: loss=8.0024 
[epoch 26] step 8/44: loss=8.2491 
[epoch 26] step 10/44: loss=8.2698 
[epoch 26] step 12/44: loss=8.2677 
[epoch 26] step 14/44: loss=8.1774 
[epoch 26] step 16/44: loss=8.1321 
[epoch 26] step 18/44: loss=8.0104 
[epoch 26] step 20/44: loss=8.0410 
[epoch 26] step 22/44: loss=8.0852 
[epoch 26] step 24/44: loss=8.0804 
[epoch 26] step 26/44: loss=8.0318 
[epoch 26] step 28/44: loss=7.9835 
[epoch 26] step 30/44: loss=7.9909 
[epoch 26] step 32/44: loss=7.9181 
[epoch 26] step 34/44: loss=7.9246 
[epoch 26] step 36/44: loss=7.9567 
[epoch 26] step 38/44: loss=7.9925 
[epoch 26] step 40/44: loss=7.9706 
[epoch 26] step 42/44: loss=7.9740 
[epoch 26] step 44/44: loss=7.9374 
[epoch 26] train_loss(avg per step)=15.8749 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=9.0572 qwk=('0.4919', '0.4521', '0.4667') averageQWK=0.4702 macroEMD=0.3706 tailR0=('0.1181', '0.0833', '0.0000') tailR0avg=0.0671
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     2   13   13   12    0
     2   18   48   56    4
     1    3   18   98    2
     0    0    2   22    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     4   10   22   12    0
     7    9   41   56    0
     3    3   19  123    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   25   15    0
     0   25   63   63    0
     0    3   17   79    0
     0    0    0    3    0
[epoch 27] step 2/44: loss=7.5840 
[epoch 27] step 4/44: loss=7.5134 
[epoch 27] step 6/44: loss=7.7757 
[epoch 27] step 8/44: loss=7.6414 
[epoch 27] step 10/44: loss=7.6675 
[epoch 27] step 12/44: loss=7.5858 
[epoch 27] step 14/44: loss=7.6244 
[epoch 27] step 16/44: loss=7.7036 
[epoch 27] step 18/44: loss=7.7044 
[epoch 27] step 20/44: loss=7.7824 
[epoch 27] step 22/44: loss=7.7989 
[epoch 27] step 24/44: loss=7.9036 
[epoch 27] step 26/44: loss=7.9340 
[epoch 27] step 28/44: loss=7.9244 
[epoch 27] step 30/44: loss=7.8702 
[epoch 27] step 32/44: loss=7.8938 
[epoch 27] step 34/44: loss=7.8997 
[epoch 27] step 36/44: loss=7.8866 
[epoch 27] step 38/44: loss=7.8435 
[epoch 27] step 40/44: loss=7.8631 
[epoch 27] step 42/44: loss=7.8624 
[epoch 27] step 44/44: loss=7.8418 
[epoch 27] train_loss(avg per step)=15.6835 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=10.7729 qwk=('0.4981', '0.4870', '0.4502') averageQWK=0.4784 macroEMD=0.3679 tailR0=('0.1181', '0.0833', '0.0000') tailR0avg=0.0671
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1   13   16   10    0
     1   17   52   54    4
     0    3   23   94    2
     0    0    2   22    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     1   12   22   13    0
     2   12   47   52    0
     0    3   27  118    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   33   22   16    0
     0   25   56   70    0
     0    5   14   80    0
     0    0    0    3    0
[epoch 28] step 2/44: loss=8.3437 
[epoch 28] step 4/44: loss=8.3519 
[epoch 28] step 6/44: loss=8.3909 
[epoch 28] step 8/44: loss=8.0502 
[epoch 28] step 10/44: loss=7.9559 
[epoch 28] step 12/44: loss=8.0424 
[epoch 28] step 14/44: loss=7.9218 
[epoch 28] step 16/44: loss=7.9135 
[epoch 28] step 18/44: loss=7.9624 
[epoch 28] step 20/44: loss=7.9025 
[epoch 28] step 22/44: loss=7.8994 
[epoch 28] step 24/44: loss=7.9240 
[epoch 28] step 26/44: loss=7.9087 
[epoch 28] step 28/44: loss=7.9147 
[epoch 28] step 30/44: loss=7.9507 
[epoch 28] step 32/44: loss=7.9672 
[epoch 28] step 34/44: loss=7.9426 
[epoch 28] step 36/44: loss=7.9164 
[epoch 28] step 38/44: loss=7.9198 
[epoch 28] step 40/44: loss=7.9025 
[epoch 28] step 42/44: loss=7.9030 
[epoch 28] step 44/44: loss=7.9301 
[epoch 28] train_loss(avg per step)=15.8602 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=10.6925 qwk=('0.4708', '0.4607', '0.4466') averageQWK=0.4594 macroEMD=0.3709 tailR0=('0.0625', '0.0833', '0.0000') tailR0avg=0.0486
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1   10   16   13    0
     1   13   53   59    2
     0    1   22   99    0
     0    0    2   25    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     2    8   27   11    0
     3   11   50   49    0
     0    5   29  114    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   18   42   11    0
     0   11   88   52    0
     0    3   22   74    0
     0    0    0    3    0
[epoch 29] step 2/44: loss=7.9987 
[epoch 29] step 4/44: loss=7.7597 
[epoch 29] step 6/44: loss=7.8633 
[epoch 29] step 8/44: loss=7.7637 
[epoch 29] step 10/44: loss=7.6197 
[epoch 29] step 12/44: loss=7.6906 
[epoch 29] step 14/44: loss=7.9319 
[epoch 29] step 16/44: loss=8.0652 
[epoch 29] step 18/44: loss=8.0944 
[epoch 29] step 20/44: loss=8.0427 
[epoch 29] step 22/44: loss=7.9393 
[epoch 29] step 24/44: loss=7.8676 
[epoch 29] step 26/44: loss=7.7898 
[epoch 29] step 28/44: loss=7.7548 
[epoch 29] step 30/44: loss=7.7246 
[epoch 29] step 32/44: loss=7.7351 
[epoch 29] step 34/44: loss=7.8018 
[epoch 29] step 36/44: loss=7.8040 
[epoch 29] step 38/44: loss=7.8130 
[epoch 29] step 40/44: loss=7.8340 
[epoch 29] step 42/44: loss=7.8114 
[epoch 29] step 44/44: loss=7.8036 
[epoch 29] train_loss(avg per step)=15.6073 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=11.1939 qwk=('0.4952', '0.4784', '0.4655') averageQWK=0.4797 macroEMD=0.3695 tailR0=('0.0810', '0.0000', '0.0000') tailR0avg=0.0270
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     1   11   20    8    0
     1   22   54   49    2
     0    3   27   92    0
     0    1    2   23    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     1   14   23   10    0
     1   15   48   49    0
     0    5   35  108    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22   41    8    0
     0   16   84   51    0
     0    4   24   71    0
     0    0    0    3    0
[epoch 30] step 2/44: loss=8.3775 
[epoch 30] step 4/44: loss=8.5775 
[epoch 30] step 6/44: loss=8.4007 
[epoch 30] step 8/44: loss=8.2921 
[epoch 30] step 10/44: loss=8.1422 
[epoch 30] step 12/44: loss=8.1825 
[epoch 30] step 14/44: loss=8.1549 
[epoch 30] step 16/44: loss=8.1365 
[epoch 30] step 18/44: loss=8.1644 
[epoch 30] step 20/44: loss=8.1561 
[epoch 30] step 22/44: loss=8.0957 
[epoch 30] step 24/44: loss=8.0465 
[epoch 30] step 26/44: loss=7.9343 
[epoch 30] step 28/44: loss=7.8453 
[epoch 30] step 30/44: loss=7.8129 
[epoch 30] step 32/44: loss=7.8044 
[epoch 30] step 34/44: loss=7.7706 
[epoch 30] step 36/44: loss=7.8269 
[epoch 30] step 38/44: loss=7.8737 
[epoch 30] step 40/44: loss=7.9006 
[epoch 30] step 42/44: loss=7.9129 
[epoch 30] step 44/44: loss=7.9947 
[epoch 30] train_loss(avg per step)=15.9894 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=10.8273 qwk=('0.4913', '0.4670', '0.4446') averageQWK=0.4676 macroEMD=0.3717 tailR0=('0.1366', '0.0000', '0.0000') tailR0avg=0.0455
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     1    8   23    8    0
     1   15   56   50    6
     0    1   26   90    5
     0    1    2   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     2    9   27   10    0
     1    9   55   48    0
     0    3   37  107    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   25   33   13    0
     0   19   76   56    0
     0    4   21   74    0
     0    0    0    3    0
[epoch 31] step 2/44: loss=8.1917 
[epoch 31] step 4/44: loss=8.2778 
[epoch 31] step 6/44: loss=7.9338 
[epoch 31] step 8/44: loss=7.7167 
[epoch 31] step 10/44: loss=7.7048 
[epoch 31] step 12/44: loss=7.5841 
[epoch 31] step 14/44: loss=7.5754 
[epoch 31] step 16/44: loss=7.5422 
[epoch 31] step 18/44: loss=7.5549 
[epoch 31] step 20/44: loss=7.5749 
[epoch 31] step 22/44: loss=7.6252 
[epoch 31] step 24/44: loss=7.6688 
[epoch 31] step 26/44: loss=7.7248 
[epoch 31] step 28/44: loss=7.7196 
[epoch 31] step 30/44: loss=7.7690 
[epoch 31] step 32/44: loss=7.7851 
[epoch 31] step 34/44: loss=7.7979 
[epoch 31] step 36/44: loss=7.7838 
[epoch 31] step 38/44: loss=7.7640 
[epoch 31] step 40/44: loss=7.7799 
[epoch 31] step 42/44: loss=7.7708 
[epoch 31] step 44/44: loss=7.7855 
[epoch 31] train_loss(avg per step)=15.5709 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=11.0631 qwk=('0.4938', '0.4811', '0.4536') averageQWK=0.4762 macroEMD=0.3711 tailR0=('0.1366', '0.0833', '0.0000') tailR0avg=0.0733
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     1    8   23    8    0
     1   16   59   47    5
     0    2   33   83    4
     0    0    2   21    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     2    8   29    9    0
     1    6   57   49    0
     0    1   41  105    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   21   39   11    0
     0   16   84   51    0
     0    3   23   73    0
     0    0    0    3    0
[epoch 32] step 2/44: loss=8.0376 
[epoch 32] step 4/44: loss=8.2875 
[epoch 32] step 6/44: loss=8.0649 
[epoch 32] step 8/44: loss=8.0250 
[epoch 32] step 10/44: loss=8.0658 
[epoch 32] step 12/44: loss=8.0013 
[epoch 32] step 14/44: loss=7.9130 
[epoch 32] step 16/44: loss=7.8706 
[epoch 32] step 18/44: loss=7.8370 
[epoch 32] step 20/44: loss=7.7847 
[epoch 32] step 22/44: loss=7.7664 
[epoch 32] step 24/44: loss=7.7783 
[epoch 32] step 26/44: loss=7.7750 
[epoch 32] step 28/44: loss=7.7698 
[epoch 32] step 30/44: loss=7.7603 
[epoch 32] step 32/44: loss=7.7875 
[epoch 32] step 34/44: loss=7.8226 
[epoch 32] step 36/44: loss=7.8023 
[epoch 32] step 38/44: loss=7.7980 
[epoch 32] step 40/44: loss=7.8559 
[epoch 32] step 42/44: loss=7.8554 
[epoch 32] step 44/44: loss=7.8793 
[epoch 32] train_loss(avg per step)=15.7585 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=10.5935 qwk=('0.4979', '0.4712', '0.4729') averageQWK=0.4807 macroEMD=0.3703 tailR0=('0.0810', '0.1667', '0.0000') tailR0avg=0.0826
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     1   10   16   13    0
     2   16   53   55    2
     0    2   19   98    3
     0    0    1   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     3    9   25   11    0
     4    7   51   51    0
     2    2   31  112    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   32   25   14    0
     0   29   60   62    0
     0    4   15   80    0
     0    0    0    3    0
[epoch 33] step 2/44: loss=8.4570 
[epoch 33] step 4/44: loss=8.0221 
[epoch 33] step 6/44: loss=7.9797 
[epoch 33] step 8/44: loss=7.9510 
[epoch 33] step 10/44: loss=7.9521 
[epoch 33] step 12/44: loss=7.9722 
[epoch 33] step 14/44: loss=8.0478 
[epoch 33] step 16/44: loss=8.0453 
[epoch 33] step 18/44: loss=7.9842 
[epoch 33] step 20/44: loss=7.9707 
[epoch 33] step 22/44: loss=7.9424 
[epoch 33] step 24/44: loss=7.9808 
[epoch 33] step 26/44: loss=7.9525 
[epoch 33] step 28/44: loss=7.9130 
[epoch 33] step 30/44: loss=7.8944 
[epoch 33] step 32/44: loss=7.8994 
[epoch 33] step 34/44: loss=7.9384 
[epoch 33] step 36/44: loss=7.9457 
[epoch 33] step 38/44: loss=7.9102 
[epoch 33] step 40/44: loss=7.9517 
[epoch 33] step 42/44: loss=7.9639 
[epoch 33] step 44/44: loss=7.9628 
[epoch 33] train_loss(avg per step)=15.9256 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=10.4655 qwk=('0.4996', '0.4707', '0.4866') averageQWK=0.4856 macroEMD=0.3719 tailR0=('0.0625', '0.0833', '0.0000') tailR0avg=0.0486
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     1    9   21    9    0
     1   16   59   50    2
     0    2   27   91    2
     0    0    2   25    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     3    8   26   11    0
     2   10   51   50    0
     0    2   37  108    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   28   36    7    0
     0   18   87   46    0
     0    5   24   70    0
     0    0    1    2    0
[epoch 34] step 2/44: loss=7.6827 
[epoch 34] step 4/44: loss=7.5356 
[epoch 34] step 6/44: loss=7.4508 
[epoch 34] step 8/44: loss=7.5027 
[epoch 34] step 10/44: loss=7.4805 
[epoch 34] step 12/44: loss=7.4802 
[epoch 34] step 14/44: loss=7.5721 
[epoch 34] step 16/44: loss=7.5675 
[epoch 34] step 18/44: loss=7.7014 
[epoch 34] step 20/44: loss=7.7681 
[epoch 34] step 22/44: loss=7.7599 
[epoch 34] step 24/44: loss=7.8028 
[epoch 34] step 26/44: loss=7.8443 
[epoch 34] step 28/44: loss=7.8976 
[epoch 34] step 30/44: loss=7.9146 
[epoch 34] step 32/44: loss=7.9221 
[epoch 34] step 34/44: loss=7.9163 
[epoch 34] step 36/44: loss=7.9112 
[epoch 34] step 38/44: loss=7.8683 
[epoch 34] step 40/44: loss=7.8681 
[epoch 34] step 42/44: loss=7.8736 
[epoch 34] step 44/44: loss=7.9379 
[epoch 34] train_loss(avg per step)=15.8757 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=10.7994 qwk=('0.5083', '0.4828', '0.4538') averageQWK=0.4816 macroEMD=0.3717 tailR0=('0.0995', '0.0833', '0.0000') tailR0avg=0.0610
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     1    9   21    9    0
     1   14   60   51    2
     0    2   27   90    3
     0    0    2   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     2    8   28   10    0
     1    9   53   50    0
     0    1   37  109    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   33   12    0
     0   19   77   55    0
     0    4   22   73    0
     0    0    0    3    0
[epoch 35] step 2/44: loss=8.2649 
[epoch 35] step 4/44: loss=8.2219 
[epoch 35] step 6/44: loss=8.0447 
[epoch 35] step 8/44: loss=7.8882 
[epoch 35] step 10/44: loss=7.8418 
[epoch 35] step 12/44: loss=7.7860 
[epoch 35] step 14/44: loss=7.8154 
[epoch 35] step 16/44: loss=7.7952 
[epoch 35] step 18/44: loss=7.7838 
[epoch 35] step 20/44: loss=7.7628 
[epoch 35] step 22/44: loss=7.8011 
[epoch 35] step 24/44: loss=7.8201 
[epoch 35] step 26/44: loss=7.7758 
[epoch 35] step 28/44: loss=7.8121 
[epoch 35] step 30/44: loss=7.8202 
[epoch 35] step 32/44: loss=7.8161 
[epoch 35] step 34/44: loss=7.8182 
[epoch 35] step 36/44: loss=7.8483 
[epoch 35] step 38/44: loss=7.8160 
[epoch 35] step 40/44: loss=7.8299 
[epoch 35] step 42/44: loss=7.8409 
[epoch 35] step 44/44: loss=7.8357 
[epoch 35] train_loss(avg per step)=15.6713 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=10.5014 qwk=('0.5129', '0.4680', '0.4449') averageQWK=0.4753 macroEMD=0.3713 tailR0=('0.0995', '0.0833', '0.0000') tailR0avg=0.0610
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    6    1    0    0
     1    9   21    9    0
     1   15   59   51    2
     0    2   25   93    2
     0    0    2   23    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1   11   24   12    0
     2    9   48   54    0
     0    3   30  114    1
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   26   31   14    0
     0   16   79   56    0
     0    4   21   74    0
     0    0    0    3    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-1/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-1-conf_gating-0-reassignment-1/fold3/metrics.json
Done.
