[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=5.9277 
[epoch 1] step 4/44: loss=6.1687 
[epoch 1] step 6/44: loss=6.2563 
[epoch 1] step 8/44: loss=6.2427 
[epoch 1] step 10/44: loss=6.2636 
[epoch 1] step 12/44: loss=6.1901 
[epoch 1] step 14/44: loss=6.1217 
[epoch 1] step 16/44: loss=6.0655 
[epoch 1] step 18/44: loss=6.0471 
[epoch 1] step 20/44: loss=6.0978 
[epoch 1] step 22/44: loss=6.0802 
[epoch 1] step 24/44: loss=6.0699 
[epoch 1] step 26/44: loss=6.1103 
[epoch 1] step 28/44: loss=6.1127 
[epoch 1] step 30/44: loss=6.1108 
[epoch 1] step 32/44: loss=6.1037 
[epoch 1] step 34/44: loss=6.0928 
[epoch 1] step 36/44: loss=6.0358 
[epoch 1] step 38/44: loss=6.0001 
[epoch 1] step 40/44: loss=5.9242 
[epoch 1] step 42/44: loss=5.8453 
[epoch 1] step 44/44: loss=5.8034 
[epoch 1] train_loss(avg per step)=11.6069 lambda[min,max]=[0.526956,1.000000]
[epoch 1] val_loss=5.7300 qwk=('0.2381', '0.2427', '0.0313') averageQWK=0.1707 macroEMD=0.3726 tailR0=('0.0000', '0.2857', '0.0000') tailR0avg=0.0952
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    0    3    0
     0   41    0   11    0
     0   58    0   56    0
     0   60    0   79    0
     0    3    0    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     4    0    2    1    0
    27    0   22    6    0
    30    0   41   43    0
    27    0   54   62    0
     1    0    2    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    3   62    0    0
     0    0  143    0    0
     0    0  110    0    0
     0    0    3    0    0
[epoch 2] step 2/44: loss=3.6777 
[epoch 2] step 4/44: loss=3.7607 
[epoch 2] step 6/44: loss=3.6235 
[epoch 2] step 8/44: loss=3.5639 
[epoch 2] step 10/44: loss=3.4084 
[epoch 2] step 12/44: loss=3.3986 
[epoch 2] step 14/44: loss=3.3620 
[epoch 2] step 16/44: loss=3.2249 
[epoch 2] step 18/44: loss=3.1923 
[epoch 2] step 20/44: loss=3.0914 
[epoch 2] step 22/44: loss=3.0453 
[epoch 2] step 24/44: loss=2.9896 
[epoch 2] step 26/44: loss=2.9294 
[epoch 2] step 28/44: loss=2.9023 
[epoch 2] step 30/44: loss=2.8571 
[epoch 2] step 32/44: loss=2.8157 
[epoch 2] step 34/44: loss=2.7801 
[epoch 2] step 36/44: loss=2.7391 
[epoch 2] step 38/44: loss=2.7024 
[epoch 2] step 40/44: loss=2.6607 
[epoch 2] step 42/44: loss=2.6466 
[epoch 2] step 44/44: loss=2.6375 
[epoch 2] train_loss(avg per step)=5.2751 lambda[min,max]=[0.506257,1.000000]
[epoch 2] val_loss=2.8061 qwk=('0.4990', '0.3862', '0.1204') averageQWK=0.3352 macroEMD=0.3736 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    0    0
     0   13   38    1    0
     0    6   94   14    0
     0    1   59   79    0
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    0    0
     0    0   54    1    0
     0    0   88   26    0
     0    0   66   77    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   65    0    0
     0    0  138    5    0
     0    0   96   14    0
     0    0    2    1    0
[epoch 3] step 2/44: loss=1.8727 
[epoch 3] step 4/44: loss=1.9133 
[epoch 3] step 6/44: loss=1.9185 
[epoch 3] step 8/44: loss=1.9235 
[epoch 3] step 10/44: loss=1.8776 
[epoch 3] step 12/44: loss=1.8867 
[epoch 3] step 14/44: loss=1.8992 
[epoch 3] step 16/44: loss=1.8797 
[epoch 3] step 18/44: loss=1.8678 
[epoch 3] step 20/44: loss=1.8706 
[epoch 3] step 22/44: loss=1.8391 
[epoch 3] step 24/44: loss=1.8279 
[epoch 3] step 26/44: loss=1.8298 
[epoch 3] step 28/44: loss=1.8371 
[epoch 3] step 30/44: loss=1.8258 
[epoch 3] step 32/44: loss=1.8178 
[epoch 3] step 34/44: loss=1.8109 
[epoch 3] step 36/44: loss=1.7836 
[epoch 3] step 38/44: loss=1.7704 
[epoch 3] step 40/44: loss=1.7632 
[epoch 3] step 42/44: loss=1.7647 
[epoch 3] step 44/44: loss=1.7417 
[epoch 3] train_loss(avg per step)=3.4834 lambda[min,max]=[0.505338,1.000000]
[epoch 3] val_loss=2.7386 qwk=('0.3783', '0.4448', '0.4247') averageQWK=0.4160 macroEMD=0.3480 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    1    0
     0    1   33   18    0
     0    0   35   79    0
     0    0    6  133    0
     0    0    1    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    0    0
     0    1   47    7    0
     0    0   39   75    0
     0    0   13  130    0
     0    0    0    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    3   55    7    0
     0    0   51   92    0
     0    0   10  100    0
     0    0    0    3    0
[epoch 4] step 2/44: loss=1.7839 
[epoch 4] step 4/44: loss=1.7758 
[epoch 4] step 6/44: loss=1.7453 
[epoch 4] step 8/44: loss=1.7275 
[epoch 4] step 10/44: loss=1.6700 
[epoch 4] step 12/44: loss=1.6096 
[epoch 4] step 14/44: loss=1.5699 
[epoch 4] step 16/44: loss=1.5454 
[epoch 4] step 18/44: loss=1.5590 
[epoch 4] step 20/44: loss=1.5673 
[epoch 4] step 22/44: loss=1.5744 
[epoch 4] step 24/44: loss=1.5768 
[epoch 4] step 26/44: loss=1.5513 
[epoch 4] step 28/44: loss=1.5505 
[epoch 4] step 30/44: loss=1.5265 
[epoch 4] step 32/44: loss=1.5218 
[epoch 4] step 34/44: loss=1.5128 
[epoch 4] step 36/44: loss=1.4896 
[epoch 4] step 38/44: loss=1.4713 
[epoch 4] step 40/44: loss=1.4486 
[epoch 4] step 42/44: loss=1.4373 
[epoch 4] step 44/44: loss=1.4315 
[epoch 4] train_loss(avg per step)=2.8629 lambda[min,max]=[0.504334,1.000000]
[epoch 4] val_loss=2.5169 qwk=('0.5440', '0.4597', '0.2795') averageQWK=0.4277 macroEMD=0.3376 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    7    0    0
     0    7   41    4    0
     0    4   87   23    0
     0    0   35  104    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     0    8   47    0    0
     0    1   91   22    0
     0    0   62   81    0
     0    0    3    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0   15   50    0    0
     0    4  139    0    0
     0    0   95   15    0
     0    0    3    0    0
[epoch 5] step 2/44: loss=1.3909 
[epoch 5] step 4/44: loss=1.1894 
[epoch 5] step 6/44: loss=1.2072 
[epoch 5] step 8/44: loss=1.1877 
[epoch 5] step 10/44: loss=1.2046 
[epoch 5] step 12/44: loss=1.2146 
[epoch 5] step 14/44: loss=1.2176 
[epoch 5] step 16/44: loss=1.2125 
[epoch 5] step 18/44: loss=1.1987 
[epoch 5] step 20/44: loss=1.1877 
[epoch 5] step 22/44: loss=1.1725 
[epoch 5] step 24/44: loss=1.1661 
[epoch 5] step 26/44: loss=1.1459 
[epoch 5] step 28/44: loss=1.1355 
[epoch 5] step 30/44: loss=1.1469 
[epoch 5] step 32/44: loss=1.1642 
[epoch 5] step 34/44: loss=1.1601 
[epoch 5] step 36/44: loss=1.1697 
[epoch 5] step 38/44: loss=1.1752 
[epoch 5] step 40/44: loss=1.1774 
[epoch 5] step 42/44: loss=1.1761 
[epoch 5] step 44/44: loss=1.1855 
[epoch 5] train_loss(avg per step)=2.3710 lambda[min,max]=[0.506973,1.000000]
[epoch 5] val_loss=2.7774 qwk=('0.4421', '0.3874', '0.4688') averageQWK=0.4328 macroEMD=0.3315 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    1    0
     0    0   44    8    0
     0    0   54   60    0
     0    0   13  126    0
     0    0    1    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    1    0
     0   12   23   20    0
     0    4   20   90    0
     0    0   12  131    0
     0    0    0    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    1   63    1    0
     0    0   86   57    0
     0    0   22   88    0
     0    0    0    3    0
[epoch 6] step 2/44: loss=1.0784 
[epoch 6] step 4/44: loss=1.1073 
[epoch 6] step 6/44: loss=1.0855 
[epoch 6] step 8/44: loss=1.1769 
[epoch 6] step 10/44: loss=1.1523 
[epoch 6] step 12/44: loss=1.1368 
[epoch 6] step 14/44: loss=1.1424 
[epoch 6] step 16/44: loss=1.1259 
[epoch 6] step 18/44: loss=1.1079 
[epoch 6] step 20/44: loss=1.0887 
[epoch 6] step 22/44: loss=1.0683 
[epoch 6] step 24/44: loss=1.0604 
[epoch 6] step 26/44: loss=1.0575 
[epoch 6] step 28/44: loss=1.0441 
[epoch 6] step 30/44: loss=1.0469 
[epoch 6] step 32/44: loss=1.0455 
[epoch 6] step 34/44: loss=1.0453 
[epoch 6] step 36/44: loss=1.0348 
[epoch 6] step 38/44: loss=1.0336 
[epoch 6] step 40/44: loss=1.0289 
[epoch 6] step 42/44: loss=1.0217 
[epoch 6] step 44/44: loss=1.0112 
[epoch 6] train_loss(avg per step)=2.0224 lambda[min,max]=[0.506270,1.000000]
[epoch 6] val_loss=2.2820 qwk=('0.5214', '0.5156', '0.5540') averageQWK=0.5303 macroEMD=0.3154 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    0    0
     0    4   46    2    0
     0    2   93   19    0
     0    0   42   97    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     0   10   40    5    0
     0    3   45   66    0
     0    0   21  122    0
     0    0    0    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0   15   49    1    0
     0    8  100   35    0
     0    0   31   79    0
     0    0    0    3    0
[epoch 7] step 2/44: loss=1.0330 
[epoch 7] step 4/44: loss=0.8445 
[epoch 7] step 6/44: loss=0.8656 
[epoch 7] step 8/44: loss=0.8568 
[epoch 7] step 10/44: loss=0.8859 
[epoch 7] step 12/44: loss=0.8642 
[epoch 7] step 14/44: loss=0.8505 
[epoch 7] step 16/44: loss=0.8225 
[epoch 7] step 18/44: loss=0.8477 
[epoch 7] step 20/44: loss=0.8469 
[epoch 7] step 22/44: loss=0.8522 
[epoch 7] step 24/44: loss=0.8429 
[epoch 7] step 26/44: loss=0.8355 
[epoch 7] step 28/44: loss=0.8297 
[epoch 7] step 30/44: loss=0.8193 
[epoch 7] step 32/44: loss=0.8246 
[epoch 7] step 34/44: loss=0.8232 
[epoch 7] step 36/44: loss=0.8214 
[epoch 7] step 38/44: loss=0.8182 
[epoch 7] step 40/44: loss=0.8100 
[epoch 7] step 42/44: loss=0.8129 
[epoch 7] step 44/44: loss=0.8174 
[epoch 7] train_loss(avg per step)=1.6348 lambda[min,max]=[0.501367,1.000000]
[epoch 7] val_loss=2.2817 qwk=('0.4942', '0.4907', '0.5859') averageQWK=0.5236 macroEMD=0.3121 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    6    0    0
     0    9   41    2    0
     0    6   95   13    0
     0    0   62   77    0
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     0   12   42    1    0
     0    5   90   19    0
     0    0   67   76    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0   32   32    1    0
     0   24   81   38    0
     0    3   29   78    0
     0    0    0    3    0
[epoch 8] step 2/44: loss=0.6999 
[epoch 8] step 4/44: loss=0.6325 
[epoch 8] step 6/44: loss=0.6469 
[epoch 8] step 8/44: loss=0.6521 
[epoch 8] step 10/44: loss=0.6952 
[epoch 8] step 12/44: loss=0.7124 
[epoch 8] step 14/44: loss=0.7161 
[epoch 8] step 16/44: loss=0.7015 
[epoch 8] step 18/44: loss=0.7074 
[epoch 8] step 20/44: loss=0.7080 
[epoch 8] step 22/44: loss=0.7118 
[epoch 8] step 24/44: loss=0.7157 
[epoch 8] step 26/44: loss=0.7313 
[epoch 8] step 28/44: loss=0.7394 
[epoch 8] step 30/44: loss=0.7431 
[epoch 8] step 32/44: loss=0.7374 
[epoch 8] step 34/44: loss=0.7352 
[epoch 8] step 36/44: loss=0.7320 
[epoch 8] step 38/44: loss=0.7352 
[epoch 8] step 40/44: loss=0.7184 
[epoch 8] step 42/44: loss=0.7163 
[epoch 8] step 44/44: loss=0.7081 
[epoch 8] train_loss(avg per step)=1.4162 lambda[min,max]=[0.501939,1.000000]
[epoch 8] val_loss=2.2346 qwk=('0.5478', '0.5376', '0.6059') averageQWK=0.5638 macroEMD=0.3048 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    4    0    0
     0    8   42    2    0
     0    8   91   15    0
     0    0   49   90    0
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     2   16   37    0    0
     0    9   84   21    0
     0    3   55   85    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   30   35    0    0
     0   27   89   27    0
     0    2   36   72    0
     0    0    0    3    0
[epoch 9] step 2/44: loss=0.7477 
[epoch 9] step 4/44: loss=0.6509 
[epoch 9] step 6/44: loss=0.5970 
[epoch 9] step 8/44: loss=0.5945 
[epoch 9] step 10/44: loss=0.5739 
[epoch 9] step 12/44: loss=0.5705 
[epoch 9] step 14/44: loss=0.5610 
[epoch 9] step 16/44: loss=0.5625 
[epoch 9] step 18/44: loss=0.5550 
[epoch 9] step 20/44: loss=0.5385 
[epoch 9] step 22/44: loss=0.5374 
[epoch 9] step 24/44: loss=0.5352 
[epoch 9] step 26/44: loss=0.5181 
[epoch 9] step 28/44: loss=0.5025 
[epoch 9] step 30/44: loss=0.5075 
[epoch 9] step 32/44: loss=0.5058 
[epoch 9] step 34/44: loss=0.5149 
[epoch 9] step 36/44: loss=0.5153 
[epoch 9] step 38/44: loss=0.5219 
[epoch 9] step 40/44: loss=0.5169 
[epoch 9] step 42/44: loss=0.5173 
[epoch 9] step 44/44: loss=0.5218 
[epoch 9] train_loss(avg per step)=1.0436 lambda[min,max]=[0.500569,1.000000]
[epoch 9] val_loss=2.4908 qwk=('0.4966', '0.4983', '0.5167') averageQWK=0.5039 macroEMD=0.2990 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     0   12   39    1    0
     0   15   87   12    0
     0    1   64   74    0
     0    1    3    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   13   39    3    0
     0    4   76   34    0
     0    2   50   91    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   11   53    1    0
     0    5  116   22    0
     0    0   37   73    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=0.6114 
[epoch 10] step 4/44: loss=0.5745 
[epoch 10] step 6/44: loss=0.5767 
[epoch 10] step 8/44: loss=0.5579 
[epoch 10] step 10/44: loss=0.5148 
[epoch 10] step 12/44: loss=0.5024 
[epoch 10] step 14/44: loss=0.4903 
[epoch 10] step 16/44: loss=0.4890 
[epoch 10] step 18/44: loss=0.4807 
[epoch 10] step 20/44: loss=0.4992 
[epoch 10] step 22/44: loss=0.5075 
[epoch 10] step 24/44: loss=0.5013 
[epoch 10] step 26/44: loss=0.4851 
[epoch 10] step 28/44: loss=0.4755 
[epoch 10] step 30/44: loss=0.4619 
[epoch 10] step 32/44: loss=0.4488 
[epoch 10] step 34/44: loss=0.4411 
[epoch 10] step 36/44: loss=0.4421 
[epoch 10] step 38/44: loss=0.4318 
[epoch 10] step 40/44: loss=0.4308 
[epoch 10] step 42/44: loss=0.4296 
[epoch 10] step 44/44: loss=0.4261 
[epoch 10] train_loss(avg per step)=0.8522 lambda[min,max]=[0.500428,1.000000]
[epoch 10] val_loss=2.5320 qwk=('0.4857', '0.5600', '0.5432') averageQWK=0.5296 macroEMD=0.2968 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    6    0    0
     0    8   43    1    0
     0    4   97   13    0
     0    0   63   76    0
     0    1    3    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   14   39    2    0
     0    6   62   46    0
     0    2   27  114    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0   13   51    1    0
     0    6  100   37    0
     0    0   31   79    0
     0    0    0    3    0
[epoch 11] step 2/44: loss=0.2743 
[epoch 11] step 4/44: loss=0.2663 
[epoch 11] step 6/44: loss=0.2658 
[epoch 11] step 8/44: loss=0.2658 
[epoch 11] step 10/44: loss=0.2605 
[epoch 11] step 12/44: loss=0.2442 
[epoch 11] step 14/44: loss=0.2400 
[epoch 11] step 16/44: loss=0.2385 
[epoch 11] step 18/44: loss=0.2361 
[epoch 11] step 20/44: loss=0.2357 
[epoch 11] step 22/44: loss=0.2515 
[epoch 11] step 24/44: loss=0.2444 
[epoch 11] step 26/44: loss=0.2417 
[epoch 11] step 28/44: loss=0.2496 
[epoch 11] step 30/44: loss=0.2493 
[epoch 11] step 32/44: loss=0.2604 
[epoch 11] step 34/44: loss=0.2702 
[epoch 11] step 36/44: loss=0.2784 
[epoch 11] step 38/44: loss=0.2835 
[epoch 11] step 40/44: loss=0.2760 
[epoch 11] step 42/44: loss=0.2789 
[epoch 11] step 44/44: loss=0.2775 
[epoch 11] train_loss(avg per step)=0.5551 lambda[min,max]=[0.500149,1.000000]
[epoch 11] val_loss=2.7248 qwk=('0.4697', '0.5157', '0.5353') averageQWK=0.5069 macroEMD=0.2889 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    9    0    0
     0    2   48    2    0
     0    0   93   21    0
     0    0   50   89    0
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     0    8   41    6    0
     0    1   57   56    0
     0    0   20  123    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   12   52    1    0
     0    6   99   38    0
     0    0   26   84    0
     0    0    0    3    0
[epoch 12] step 2/44: loss=0.2352 
[epoch 12] step 4/44: loss=0.2593 
[epoch 12] step 6/44: loss=0.2339 
[epoch 12] step 8/44: loss=0.2358 
[epoch 12] step 10/44: loss=0.2171 
[epoch 12] step 12/44: loss=0.2019 
[epoch 12] step 14/44: loss=0.1931 
[epoch 12] step 16/44: loss=0.1944 
[epoch 12] step 18/44: loss=0.1859 
[epoch 12] step 20/44: loss=0.1857 
[epoch 12] step 22/44: loss=0.1808 
[epoch 12] step 24/44: loss=0.1730 
[epoch 12] step 26/44: loss=0.1750 
[epoch 12] step 28/44: loss=0.1678 
[epoch 12] step 30/44: loss=0.1603 
[epoch 12] step 32/44: loss=0.1588 
[epoch 12] step 34/44: loss=0.1560 
[epoch 12] step 36/44: loss=0.1525 
[epoch 12] step 38/44: loss=0.1511 
[epoch 12] step 40/44: loss=0.1497 
[epoch 12] step 42/44: loss=0.1421 
[epoch 12] step 44/44: loss=0.1548 
[epoch 12] train_loss(avg per step)=0.3095 lambda[min,max]=[0.500404,1.000000]
[epoch 12] val_loss=2.9383 qwk=('0.5300', '0.5319', '0.5280') averageQWK=0.5300 macroEMD=0.2835 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    0    0
     0    4   45    3    0
     0    0   73   41    0
     0    0   27  112    0
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     0    8   43    4    0
     0    1   65   48    0
     0    0   25  118    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0   12   52    1    0
     0    5  107   31    0
     0    0   34   76    0
     0    0    0    3    0
[epoch 13] step 2/44: loss=0.0084 
[epoch 13] step 4/44: loss=0.0691 
[epoch 13] step 6/44: loss=0.0629 
[epoch 13] step 8/44: loss=0.0541 
[epoch 13] step 10/44: loss=0.0295 
[epoch 13] step 12/44: loss=0.0376 
[epoch 13] step 14/44: loss=0.0298 
[epoch 13] step 16/44: loss=0.0158 
[epoch 13] step 18/44: loss=0.0197 
[epoch 13] step 20/44: loss=0.0084 
[epoch 13] step 22/44: loss=0.0097 
[epoch 13] step 24/44: loss=0.0173 
[epoch 13] step 26/44: loss=0.0246 
[epoch 13] step 28/44: loss=0.0340 
[epoch 13] step 30/44: loss=0.0355 
[epoch 13] step 32/44: loss=0.0342 
[epoch 13] step 34/44: loss=0.0355 
[epoch 13] step 36/44: loss=0.0320 
[epoch 13] step 38/44: loss=0.0236 
[epoch 13] step 40/44: loss=0.0226 
[epoch 13] step 42/44: loss=0.0240 
[epoch 13] step 44/44: loss=0.0324 
[epoch 13] train_loss(avg per step)=0.0648 lambda[min,max]=[0.500211,1.000000]
[epoch 13] val_loss=3.1419 qwk=('0.5308', '0.4376', '0.5298') averageQWK=0.4994 macroEMD=0.2886 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    6    0    0
     0    8   37    7    0
     0    3   68   43    0
     0    0   24  114    1
     0    1    1    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    0    0
     0    5   41    9    0
     0    2   54   58    0
     0    0   24  119    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   15   47    3    0
     0    7   84   52    0
     0    0   20   90    0
     0    0    0    3    0
[epoch 14] step 2/44: loss=-0.0338 
[epoch 14] step 4/44: loss=-0.0043 
[epoch 14] step 6/44: loss=0.0139 
[epoch 14] step 8/44: loss=-0.0127 
[epoch 14] step 10/44: loss=-0.0031 
[epoch 14] step 12/44: loss=-0.0135 
[epoch 14] step 14/44: loss=-0.0240 
[epoch 14] step 16/44: loss=-0.0384 
[epoch 14] step 18/44: loss=-0.0462 
[epoch 14] step 20/44: loss=-0.0364 
[epoch 14] step 22/44: loss=-0.0251 
[epoch 14] step 24/44: loss=-0.0230 
[epoch 14] step 26/44: loss=-0.0241 
[epoch 14] step 28/44: loss=-0.0248 
[epoch 14] step 30/44: loss=-0.0174 
[epoch 14] step 32/44: loss=-0.0178 
[epoch 14] step 34/44: loss=-0.0180 
[epoch 14] step 36/44: loss=-0.0135 
[epoch 14] step 38/44: loss=-0.0152 
[epoch 14] step 40/44: loss=-0.0168 
[epoch 14] step 42/44: loss=-0.0140 
[epoch 14] step 44/44: loss=-0.0179 
[epoch 14] train_loss(avg per step)=-0.0358 lambda[min,max]=[0.500139,1.000000]
[epoch 14] val_loss=2.8592 qwk=('0.5970', '0.5373', '0.5820') averageQWK=0.5721 macroEMD=0.2760 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   11    2    0    0
     1   18   32    1    0
     0   14   83   16    1
     0    4   40   89    6
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     3   13   39    0    0
     0    9   83   21    1
     0    4   51   86    2
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0   30   34    1    0
     0   24   79   40    0
     0    2   27   81    0
     0    0    0    3    0
[epoch 15] step 2/44: loss=-0.0193 
[epoch 15] step 4/44: loss=-0.0794 
[epoch 15] step 6/44: loss=-0.0704 
[epoch 15] step 8/44: loss=-0.0899 
[epoch 15] step 10/44: loss=-0.1055 
[epoch 15] step 12/44: loss=-0.0925 
[epoch 15] step 14/44: loss=-0.0923 
[epoch 15] step 16/44: loss=-0.0819 
[epoch 15] step 18/44: loss=-0.0933 
[epoch 15] step 20/44: loss=-0.1023 
[epoch 15] step 22/44: loss=-0.1076 
[epoch 15] step 24/44: loss=-0.1116 
[epoch 15] step 26/44: loss=-0.1137 
[epoch 15] step 28/44: loss=-0.1126 
[epoch 15] step 30/44: loss=-0.1205 
[epoch 15] step 32/44: loss=-0.1260 
[epoch 15] step 34/44: loss=-0.1306 
[epoch 15] step 36/44: loss=-0.1321 
[epoch 15] step 38/44: loss=-0.1388 
[epoch 15] step 40/44: loss=-0.1395 
[epoch 15] step 42/44: loss=-0.1402 
[epoch 15] step 44/44: loss=-0.1361 
[epoch 15] train_loss(avg per step)=-0.2721 lambda[min,max]=[0.500065,1.000000]
[epoch 15] val_loss=3.0026 qwk=('0.5200', '0.4996', '0.5455') averageQWK=0.5217 macroEMD=0.2835 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    7    0    0
     0    8   42    2    0
     0    2   87   25    0
     0    0   44   94    1
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   12   38    5    0
     0    8   53   53    0
     0    3   25  113    2
     0    1    0    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0   20   43    2    0
     0   12   85   46    0
     0    2   22   86    0
     0    0    0    3    0
[epoch 16] step 2/44: loss=-0.2261 
[epoch 16] step 4/44: loss=-0.2162 
[epoch 16] step 6/44: loss=-0.2218 
[epoch 16] step 8/44: loss=-0.2500 
[epoch 16] step 10/44: loss=-0.2525 
[epoch 16] step 12/44: loss=-0.2178 
[epoch 16] step 14/44: loss=-0.2036 
[epoch 16] step 16/44: loss=-0.2122 
[epoch 16] step 18/44: loss=-0.2065 
[epoch 16] step 20/44: loss=-0.1980 
[epoch 16] step 22/44: loss=-0.1976 
[epoch 16] step 24/44: loss=-0.1997 
[epoch 16] step 26/44: loss=-0.1944 
[epoch 16] step 28/44: loss=-0.1939 
[epoch 16] step 30/44: loss=-0.1920 
[epoch 16] step 32/44: loss=-0.1927 
[epoch 16] step 34/44: loss=-0.1955 
[epoch 16] step 36/44: loss=-0.1981 
[epoch 16] step 38/44: loss=-0.1960 
[epoch 16] step 40/44: loss=-0.1954 
[epoch 16] step 42/44: loss=-0.1979 
[epoch 16] step 44/44: loss=-0.2002 
[epoch 16] train_loss(avg per step)=-0.4004 lambda[min,max]=[0.500030,1.000000]
[epoch 16] val_loss=3.4898 qwk=('0.5924', '0.5338', '0.4870') averageQWK=0.5377 macroEMD=0.2797 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    4    0    0
     0   16   34    2    0
     0   10   75   29    0
     0    0   36  102    1
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   12   41    2    0
     0    6   71   37    0
     0    1   41  101    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    9   54    2    0
     2    2   95   44    0
     0    0   28   82    0
     0    0    0    3    0
[epoch 17] step 2/44: loss=-0.2969 
[epoch 17] step 4/44: loss=-0.2792 
[epoch 17] step 6/44: loss=-0.2737 
[epoch 17] step 8/44: loss=-0.2763 
[epoch 17] step 10/44: loss=-0.2700 
[epoch 17] step 12/44: loss=-0.2819 
[epoch 17] step 14/44: loss=-0.2911 
[epoch 17] step 16/44: loss=-0.2901 
[epoch 17] step 18/44: loss=-0.2942 
[epoch 17] step 20/44: loss=-0.3017 
[epoch 17] step 22/44: loss=-0.3016 
[epoch 17] step 24/44: loss=-0.3002 
[epoch 17] step 26/44: loss=-0.3007 
[epoch 17] step 28/44: loss=-0.2898 
[epoch 17] step 30/44: loss=-0.2816 
[epoch 17] step 32/44: loss=-0.2780 
[epoch 17] step 34/44: loss=-0.2751 
[epoch 17] step 36/44: loss=-0.2749 
[epoch 17] step 38/44: loss=-0.2776 
[epoch 17] step 40/44: loss=-0.2819 
[epoch 17] step 42/44: loss=-0.2813 
[epoch 17] step 44/44: loss=-0.2828 
[epoch 17] train_loss(avg per step)=-0.5655 lambda[min,max]=[0.500010,1.000000]
[epoch 17] val_loss=3.6926 qwk=('0.5517', '0.5196', '0.5344') averageQWK=0.5352 macroEMD=0.2740 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     1    8   41    2    0
     0    2   85   27    0
     0    0   41   96    2
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     0    9   45    1    0
     0    4   72   38    0
     0    0   43   98    2
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   11   53    1    0
     0    3  102   38    0
     0    0   26   84    0
     0    0    0    3    0
[epoch 18] step 2/44: loss=-0.3488 
[epoch 18] step 4/44: loss=-0.3602 
[epoch 18] step 6/44: loss=-0.3528 
[epoch 18] step 8/44: loss=-0.3239 
[epoch 18] step 10/44: loss=-0.3185 
[epoch 18] step 12/44: loss=-0.3299 
[epoch 18] step 14/44: loss=-0.3320 
[epoch 18] step 16/44: loss=-0.3307 
[epoch 18] step 18/44: loss=-0.3329 
[epoch 18] step 20/44: loss=-0.3298 
[epoch 18] step 22/44: loss=-0.3337 
[epoch 18] step 24/44: loss=-0.3342 
[epoch 18] step 26/44: loss=-0.3213 
[epoch 18] step 28/44: loss=-0.3194 
[epoch 18] step 30/44: loss=-0.3220 
[epoch 18] step 32/44: loss=-0.3214 
[epoch 18] step 34/44: loss=-0.3235 
[epoch 18] step 36/44: loss=-0.3259 
[epoch 18] step 38/44: loss=-0.3282 
[epoch 18] step 40/44: loss=-0.3277 
[epoch 18] step 42/44: loss=-0.3288 
[epoch 18] step 44/44: loss=-0.3309 
[epoch 18] train_loss(avg per step)=-0.6618 lambda[min,max]=[0.500004,1.000000]
[epoch 18] val_loss=3.7488 qwk=('0.5560', '0.5067', '0.5235') averageQWK=0.5288 macroEMD=0.2759 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     0   13   38    1    0
     0    3   96   15    0
     0    0   54   84    1
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    5    0    0
     1    8   45    1    0
     0    4   73   36    1
     0    1   44   94    4
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   20   42    3    0
     0   12   85   46    0
     0    1   26   83    0
     0    0    0    3    0
[epoch 19] step 2/44: loss=-0.3414 
[epoch 19] step 4/44: loss=-0.3741 
[epoch 19] step 6/44: loss=-0.3700 
[epoch 19] step 8/44: loss=-0.3871 
[epoch 19] step 10/44: loss=-0.3746 
[epoch 19] step 12/44: loss=-0.3749 
[epoch 19] step 14/44: loss=-0.3875 
[epoch 19] step 16/44: loss=-0.3892 
[epoch 19] step 18/44: loss=-0.3824 
[epoch 19] step 20/44: loss=-0.3760 
[epoch 19] step 22/44: loss=-0.3765 
[epoch 19] step 24/44: loss=-0.3731 
[epoch 19] step 26/44: loss=-0.3750 
[epoch 19] step 28/44: loss=-0.3731 
[epoch 19] step 30/44: loss=-0.3680 
[epoch 19] step 32/44: loss=-0.3695 
[epoch 19] step 34/44: loss=-0.3727 
[epoch 19] step 36/44: loss=-0.3727 
[epoch 19] step 38/44: loss=-0.3755 
[epoch 19] step 40/44: loss=-0.3736 
[epoch 19] step 42/44: loss=-0.3767 
[epoch 19] step 44/44: loss=-0.3802 
[epoch 19] train_loss(avg per step)=-0.7605 lambda[min,max]=[0.500005,1.000000]
[epoch 19] val_loss=4.8869 qwk=('0.4371', '0.4823', '0.5027') averageQWK=0.4740 macroEMD=0.2741 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    8    0    0
     1    2   48    1    0
     0    0  103   11    0
     0    0   69   70    0
     0    0    4    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     0    5   47    3    0
     0    2   69   43    0
     0    0   37  106    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   13   51    1    0
     0    6  108   29    0
     0    0   39   71    0
     0    0    0    3    0
[epoch 20] step 2/44: loss=-0.4521 
[epoch 20] step 4/44: loss=-0.4587 
[epoch 20] step 6/44: loss=-0.4395 
[epoch 20] step 8/44: loss=-0.4305 
[epoch 20] step 10/44: loss=-0.4345 
[epoch 20] step 12/44: loss=-0.4311 
[epoch 20] step 14/44: loss=-0.4212 
[epoch 20] step 16/44: loss=-0.4141 
[epoch 20] step 18/44: loss=-0.4193 
[epoch 20] step 20/44: loss=-0.4163 
[epoch 20] step 22/44: loss=-0.4222 
[epoch 20] step 24/44: loss=-0.4174 
[epoch 20] step 26/44: loss=-0.4098 
[epoch 20] step 28/44: loss=-0.4004 
[epoch 20] step 30/44: loss=-0.3977 
[epoch 20] step 32/44: loss=-0.3954 
[epoch 20] step 34/44: loss=-0.3994 
[epoch 20] step 36/44: loss=-0.4021 
[epoch 20] step 38/44: loss=-0.4034 
[epoch 20] step 40/44: loss=-0.4051 
[epoch 20] step 42/44: loss=-0.4061 
[epoch 20] step 44/44: loss=-0.4099 
[epoch 20] train_loss(avg per step)=-0.8197 lambda[min,max]=[0.500005,1.000000]
[epoch 20] val_loss=4.1203 qwk=('0.5129', '0.5384', '0.5341') averageQWK=0.5284 macroEMD=0.2694 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     1    7   43    1    0
     0    2  102   10    0
     0    0   61   78    0
     0    1    3    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   12   41    2    0
     0    5   69   40    0
     0    2   35  106    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0   20   45    0    0
     0   11  110   22    0
     0    1   41   68    0
     0    0    1    2    0
[epoch 21] step 2/44: loss=-0.4783 
[epoch 21] step 4/44: loss=-0.4704 
[epoch 21] step 6/44: loss=-0.4754 
[epoch 21] step 8/44: loss=-0.4665 
[epoch 21] step 10/44: loss=-0.4583 
[epoch 21] step 12/44: loss=-0.4588 
[epoch 21] step 14/44: loss=-0.4538 
[epoch 21] step 16/44: loss=-0.4591 
[epoch 21] step 18/44: loss=-0.4582 
[epoch 21] step 20/44: loss=-0.4569 
[epoch 21] step 22/44: loss=-0.4624 
[epoch 21] step 24/44: loss=-0.4620 
[epoch 21] step 26/44: loss=-0.4634 
[epoch 21] step 28/44: loss=-0.4641 
[epoch 21] step 30/44: loss=-0.4597 
[epoch 21] step 32/44: loss=-0.4602 
[epoch 21] step 34/44: loss=-0.4603 
[epoch 21] step 36/44: loss=-0.4608 
[epoch 21] step 38/44: loss=-0.4614 
[epoch 21] step 40/44: loss=-0.4572 
[epoch 21] step 42/44: loss=-0.4579 
[epoch 21] step 44/44: loss=-0.4563 
[epoch 21] train_loss(avg per step)=-0.9125 lambda[min,max]=[0.500001,1.000000]
[epoch 21] val_loss=4.8311 qwk=('0.5593', '0.5229', '0.5155') averageQWK=0.5326 macroEMD=0.2623 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    3    0    0
     1   17   33    1    0
     0   12   92   10    0
     0    0   64   75    0
     0    1    3    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     1   13   38    3    0
     0   12   55   47    0
     0    4   29  110    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   13   52    0    0
     0    6  109   28    0
     0    0   36   74    0
     0    0    1    2    0
[epoch 22] step 2/44: loss=-0.5004 
[epoch 22] step 4/44: loss=-0.4951 
[epoch 22] step 6/44: loss=-0.4716 
[epoch 22] step 8/44: loss=-0.4810 
[epoch 22] step 10/44: loss=-0.4932 
[epoch 22] step 12/44: loss=-0.4720 
[epoch 22] step 14/44: loss=-0.4646 
[epoch 22] step 16/44: loss=-0.4616 
[epoch 22] step 18/44: loss=-0.4647 
[epoch 22] step 20/44: loss=-0.4662 
[epoch 22] step 22/44: loss=-0.4633 
[epoch 22] step 24/44: loss=-0.4665 
[epoch 22] step 26/44: loss=-0.4698 
[epoch 22] step 28/44: loss=-0.4726 
[epoch 22] step 30/44: loss=-0.4712 
[epoch 22] step 32/44: loss=-0.4729 
[epoch 22] step 34/44: loss=-0.4754 
[epoch 22] step 36/44: loss=-0.4734 
[epoch 22] step 38/44: loss=-0.4745 
[epoch 22] step 40/44: loss=-0.4757 
[epoch 22] step 42/44: loss=-0.4762 
[epoch 22] step 44/44: loss=-0.4737 
[epoch 22] train_loss(avg per step)=-0.9474 lambda[min,max]=[0.500001,1.000000]
[epoch 22] val_loss=4.3041 qwk=('0.5908', '0.5401', '0.5371') averageQWK=0.5560 macroEMD=0.2623 tailR0=('0.0769', '0.0000', '0.0000') tailR0avg=0.0256
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    8    3    0    0
     1   14   36    1    0
     0   11   87   16    0
     0    1   50   88    0
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    3    0    0
     0   15   40    0    0
     0   12   62   40    0
     0    4   39  100    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   20   45    0    0
     0   10   99   34    0
     0    0   35   75    0
     0    0    1    2    0
[epoch 23] step 2/44: loss=-0.5378 
[epoch 23] step 4/44: loss=-0.5378 
[epoch 23] step 6/44: loss=-0.5374 
[epoch 23] step 8/44: loss=-0.5318 
[epoch 23] step 10/44: loss=-0.5280 
[epoch 23] step 12/44: loss=-0.5233 
[epoch 23] step 14/44: loss=-0.5205 
[epoch 23] step 16/44: loss=-0.5206 
[epoch 23] step 18/44: loss=-0.5175 
[epoch 23] step 20/44: loss=-0.5148 
[epoch 23] step 22/44: loss=-0.5152 
[epoch 23] step 24/44: loss=-0.5156 
[epoch 23] step 26/44: loss=-0.5130 
[epoch 23] step 28/44: loss=-0.5139 
[epoch 23] step 30/44: loss=-0.5126 
[epoch 23] step 32/44: loss=-0.5112 
[epoch 23] step 34/44: loss=-0.5073 
[epoch 23] step 36/44: loss=-0.5031 
[epoch 23] step 38/44: loss=-0.5032 
[epoch 23] step 40/44: loss=-0.5029 
[epoch 23] step 42/44: loss=-0.5046 
[epoch 23] step 44/44: loss=-0.5063 
[epoch 23] train_loss(avg per step)=-1.0126 lambda[min,max]=[0.500001,1.000000]
[epoch 23] val_loss=5.0332 qwk=('0.4954', '0.5134', '0.4950') averageQWK=0.5012 macroEMD=0.2667 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     1    7   43    1    0
     0    4   99   11    0
     0    0   66   72    1
     0    0    5    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   10   45    0    0
     0    7   75   32    0
     0    3   46   94    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   13   52    0    0
     0    8  109   26    0
     0    0   41   69    0
     0    0    1    2    0
[epoch 24] step 2/44: loss=-0.5505 
[epoch 24] step 4/44: loss=-0.5136 
[epoch 24] step 6/44: loss=-0.5120 
[epoch 24] step 8/44: loss=-0.5085 
[epoch 24] step 10/44: loss=-0.5130 
[epoch 24] step 12/44: loss=-0.5152 
[epoch 24] step 14/44: loss=-0.5193 
[epoch 24] step 16/44: loss=-0.5181 
[epoch 24] step 18/44: loss=-0.5170 
[epoch 24] step 20/44: loss=-0.5173 
[epoch 24] step 22/44: loss=-0.5161 
[epoch 24] step 24/44: loss=-0.5150 
[epoch 24] step 26/44: loss=-0.5149 
[epoch 24] step 28/44: loss=-0.5165 
[epoch 24] step 30/44: loss=-0.5162 
[epoch 24] step 32/44: loss=-0.5126 
[epoch 24] step 34/44: loss=-0.5139 
[epoch 24] step 36/44: loss=-0.5145 
[epoch 24] step 38/44: loss=-0.5156 
[epoch 24] step 40/44: loss=-0.5168 
[epoch 24] step 42/44: loss=-0.5181 
[epoch 24] step 44/44: loss=-0.5170 
[epoch 24] train_loss(avg per step)=-1.0339 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=5.1482 qwk=('0.5040', '0.5224', '0.5264') averageQWK=0.5176 macroEMD=0.2610 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     0   12   39    1    0
     0    9   95   10    0
     0    0   67   72    0
     0    1    3    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   11   43    1    0
     0    7   74   33    0
     0    3   42   97    1
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   15   50    0    0
     0    5  113   25    0
     0    0   40   70    0
     0    0    0    3    0
[epoch 25] step 2/44: loss=-0.4999 
[epoch 25] step 4/44: loss=-0.5336 
[epoch 25] step 6/44: loss=-0.5423 
[epoch 25] step 8/44: loss=-0.5394 
[epoch 25] step 10/44: loss=-0.5487 
[epoch 25] step 12/44: loss=-0.5400 
[epoch 25] step 14/44: loss=-0.5357 
[epoch 25] step 16/44: loss=-0.5419 
[epoch 25] step 18/44: loss=-0.5408 
[epoch 25] step 20/44: loss=-0.5401 
[epoch 25] step 22/44: loss=-0.5387 
[epoch 25] step 24/44: loss=-0.5399 
[epoch 25] step 26/44: loss=-0.5407 
[epoch 25] step 28/44: loss=-0.5386 
[epoch 25] step 30/44: loss=-0.5395 
[epoch 25] step 32/44: loss=-0.5408 
[epoch 25] step 34/44: loss=-0.5415 
[epoch 25] step 36/44: loss=-0.5425 
[epoch 25] step 38/44: loss=-0.5429 
[epoch 25] step 40/44: loss=-0.5446 
[epoch 25] step 42/44: loss=-0.5440 
[epoch 25] step 44/44: loss=-0.5445 
[epoch 25] train_loss(avg per step)=-1.0891 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=5.1912 qwk=('0.5299', '0.5456', '0.5261') averageQWK=0.5339 macroEMD=0.2574 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     0   12   39    1    0
     0    6   92   16    0
     0    0   59   80    0
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   15   39    1    0
     0    7   67   40    0
     0    2   39  101    1
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   18   47    0    0
     0   10  110   23    0
     0    0   43   67    0
     0    0    0    3    0
[epoch 26] step 2/44: loss=-0.5572 
[epoch 26] step 4/44: loss=-0.5578 
[epoch 26] step 6/44: loss=-0.5590 
[epoch 26] step 8/44: loss=-0.5618 
[epoch 26] step 10/44: loss=-0.5617 
[epoch 26] step 12/44: loss=-0.5635 
[epoch 26] step 14/44: loss=-0.5590 
[epoch 26] step 16/44: loss=-0.5555 
[epoch 26] step 18/44: loss=-0.5521 
[epoch 26] step 20/44: loss=-0.5505 
[epoch 26] step 22/44: loss=-0.5493 
[epoch 26] step 24/44: loss=-0.5490 
[epoch 26] step 26/44: loss=-0.5483 
[epoch 26] step 28/44: loss=-0.5485 
[epoch 26] step 30/44: loss=-0.5470 
[epoch 26] step 32/44: loss=-0.5483 
[epoch 26] step 34/44: loss=-0.5478 
[epoch 26] step 36/44: loss=-0.5494 
[epoch 26] step 38/44: loss=-0.5496 
[epoch 26] step 40/44: loss=-0.5500 
[epoch 26] step 42/44: loss=-0.5475 
[epoch 26] step 44/44: loss=-0.5471 
[epoch 26] train_loss(avg per step)=-1.0942 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=5.5933 qwk=('0.5845', '0.5217', '0.5226') averageQWK=0.5429 macroEMD=0.2561 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    3    0    0
     0   16   34    2    0
     0   12   75   27    0
     0    3   36  100    0
     0    1    1    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   13   37    5    0
     0    6   58   50    0
     0    2   28  112    1
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   14   50    1    0
     0    6   96   41    0
     0    0   30   80    0
     0    0    0    3    0
[epoch 27] step 2/44: loss=-0.5759 
[epoch 27] step 4/44: loss=-0.5588 
[epoch 27] step 6/44: loss=-0.5571 
[epoch 27] step 8/44: loss=-0.5555 
[epoch 27] step 10/44: loss=-0.5552 
[epoch 27] step 12/44: loss=-0.5544 
[epoch 27] step 14/44: loss=-0.5570 
[epoch 27] step 16/44: loss=-0.5591 
[epoch 27] step 18/44: loss=-0.5613 
[epoch 27] step 20/44: loss=-0.5618 
[epoch 27] step 22/44: loss=-0.5586 
[epoch 27] step 24/44: loss=-0.5588 
[epoch 27] step 26/44: loss=-0.5598 
[epoch 27] step 28/44: loss=-0.5585 
[epoch 27] step 30/44: loss=-0.5592 
[epoch 27] step 32/44: loss=-0.5579 
[epoch 27] step 34/44: loss=-0.5572 
[epoch 27] step 36/44: loss=-0.5567 
[epoch 27] step 38/44: loss=-0.5554 
[epoch 27] step 40/44: loss=-0.5550 
[epoch 27] step 42/44: loss=-0.5553 
[epoch 27] step 44/44: loss=-0.5562 
[epoch 27] train_loss(avg per step)=-1.1124 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=6.2876 qwk=('0.5606', '0.5306', '0.5244') averageQWK=0.5385 macroEMD=0.2586 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     1    9   41    1    0
     0    4   94   16    0
     0    0   48   91    0
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0    8   46    1    0
     0    4   64   46    0
     0    0   36  107    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   13   51    1    0
     0    4   98   41    0
     0    0   29   81    0
     0    0    0    3    0
[epoch 28] step 2/44: loss=-0.5763 
[epoch 28] step 4/44: loss=-0.5703 
[epoch 28] step 6/44: loss=-0.5643 
[epoch 28] step 8/44: loss=-0.5579 
[epoch 28] step 10/44: loss=-0.5602 
[epoch 28] step 12/44: loss=-0.5583 
[epoch 28] step 14/44: loss=-0.5580 
[epoch 28] step 16/44: loss=-0.5572 
[epoch 28] step 18/44: loss=-0.5579 
[epoch 28] step 20/44: loss=-0.5584 
[epoch 28] step 22/44: loss=-0.5574 
[epoch 28] step 24/44: loss=-0.5578 
[epoch 28] step 26/44: loss=-0.5587 
[epoch 28] step 28/44: loss=-0.5583 
[epoch 28] step 30/44: loss=-0.5599 
[epoch 28] step 32/44: loss=-0.5601 
[epoch 28] step 34/44: loss=-0.5604 
[epoch 28] step 36/44: loss=-0.5599 
[epoch 28] step 38/44: loss=-0.5594 
[epoch 28] step 40/44: loss=-0.5592 
[epoch 28] step 42/44: loss=-0.5600 
[epoch 28] step 44/44: loss=-0.5609 
[epoch 28] train_loss(avg per step)=-1.1218 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=5.9159 qwk=('0.5842', '0.5313', '0.5214') averageQWK=0.5456 macroEMD=0.2547 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    4    0    0
     1   14   36    1    0
     0    8   93   13    0
     0    0   51   88    0
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   13   40    2    0
     0    5   62   47    0
     0    2   34  107    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   13   52    0    0
     0    5  107   31    0
     0    0   36   74    0
     0    0    0    3    0
[epoch 29] step 2/44: loss=-0.5761 
[epoch 29] step 4/44: loss=-0.5633 
[epoch 29] step 6/44: loss=-0.5647 
[epoch 29] step 8/44: loss=-0.5661 
[epoch 29] step 10/44: loss=-0.5693 
[epoch 29] step 12/44: loss=-0.5683 
[epoch 29] step 14/44: loss=-0.5706 
[epoch 29] step 16/44: loss=-0.5697 
[epoch 29] step 18/44: loss=-0.5709 
[epoch 29] step 20/44: loss=-0.5708 
[epoch 29] step 22/44: loss=-0.5718 
[epoch 29] step 24/44: loss=-0.5712 
[epoch 29] step 26/44: loss=-0.5704 
[epoch 29] step 28/44: loss=-0.5721 
[epoch 29] step 30/44: loss=-0.5709 
[epoch 29] step 32/44: loss=-0.5717 
[epoch 29] step 34/44: loss=-0.5726 
[epoch 29] step 36/44: loss=-0.5711 
[epoch 29] step 38/44: loss=-0.5702 
[epoch 29] step 40/44: loss=-0.5707 
[epoch 29] step 42/44: loss=-0.5703 
[epoch 29] step 44/44: loss=-0.5715 
[epoch 29] train_loss(avg per step)=-1.1429 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=6.3894 qwk=('0.5180', '0.5158', '0.5307') averageQWK=0.5215 macroEMD=0.2565 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    6    0    0
     1   10   40    1    0
     0    4   97   13    0
     0    0   61   78    0
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   11   40    4    0
     0    5   57   52    0
     0    2   28  113    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   16   49    0    0
     0    8  101   34    0
     0    0   35   75    0
     0    0    0    3    0
[epoch 30] step 2/44: loss=-0.5767 
[epoch 30] step 4/44: loss=-0.5786 
[epoch 30] step 6/44: loss=-0.5828 
[epoch 30] step 8/44: loss=-0.5795 
[epoch 30] step 10/44: loss=-0.5795 
[epoch 30] step 12/44: loss=-0.5763 
[epoch 30] step 14/44: loss=-0.5777 
[epoch 30] step 16/44: loss=-0.5780 
[epoch 30] step 18/44: loss=-0.5786 
[epoch 30] step 20/44: loss=-0.5794 
[epoch 30] step 22/44: loss=-0.5800 
[epoch 30] step 24/44: loss=-0.5797 
[epoch 30] step 26/44: loss=-0.5796 
[epoch 30] step 28/44: loss=-0.5795 
[epoch 30] step 30/44: loss=-0.5797 
[epoch 30] step 32/44: loss=-0.5802 
[epoch 30] step 34/44: loss=-0.5806 
[epoch 30] step 36/44: loss=-0.5800 
[epoch 30] step 38/44: loss=-0.5796 
[epoch 30] step 40/44: loss=-0.5797 
[epoch 30] step 42/44: loss=-0.5803 
[epoch 30] step 44/44: loss=-0.5809 
[epoch 30] train_loss(avg per step)=-1.1617 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=5.8301 qwk=('0.6151', '0.5402', '0.5172') averageQWK=0.5575 macroEMD=0.2504 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    3    0    0
     1   15   35    1    0
     0    7   86   21    0
     0    0   43   96    0
     0    1    1    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   11   42    2    0
     0    5   63   46    0
     0    1   32  110    0
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   19   45    1    0
     0   10   98   35    0
     0    1   36   73    0
     0    0    0    3    0
[epoch 31] step 2/44: loss=-0.5766 
[epoch 31] step 4/44: loss=-0.5727 
[epoch 31] step 6/44: loss=-0.5769 
[epoch 31] step 8/44: loss=-0.5742 
[epoch 31] step 10/44: loss=-0.5772 
[epoch 31] step 12/44: loss=-0.5801 
[epoch 31] step 14/44: loss=-0.5804 
[epoch 31] step 16/44: loss=-0.5808 
[epoch 31] step 18/44: loss=-0.5816 
[epoch 31] step 20/44: loss=-0.5814 
[epoch 31] step 22/44: loss=-0.5797 
[epoch 31] step 24/44: loss=-0.5791 
[epoch 31] step 26/44: loss=-0.5787 
[epoch 31] step 28/44: loss=-0.5797 
[epoch 31] step 30/44: loss=-0.5794 
[epoch 31] step 32/44: loss=-0.5805 
[epoch 31] step 34/44: loss=-0.5797 
[epoch 31] step 36/44: loss=-0.5804 
[epoch 31] step 38/44: loss=-0.5806 
[epoch 31] step 40/44: loss=-0.5805 
[epoch 31] step 42/44: loss=-0.5802 
[epoch 31] step 44/44: loss=-0.5812 
[epoch 31] train_loss(avg per step)=-1.1623 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=6.3757 qwk=('0.5691', '0.5061', '0.5107') averageQWK=0.5286 macroEMD=0.2575 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     1    8   42    1    0
     0    3   91   20    0
     0    0   48   91    0
     0    0    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    0    0
     0    8   46    1    0
     0    4   67   43    0
     0    0   39  103    1
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   15   49    1    0
     0    9   97   37    0
     0    0   35   75    0
     0    0    0    3    0
[epoch 32] step 2/44: loss=-0.5821 
[epoch 32] step 4/44: loss=-0.5766 
[epoch 32] step 6/44: loss=-0.5822 
[epoch 32] step 8/44: loss=-0.5865 
[epoch 32] step 10/44: loss=-0.5882 
[epoch 32] step 12/44: loss=-0.5882 
[epoch 32] step 14/44: loss=-0.5893 
[epoch 32] step 16/44: loss=-0.5899 
[epoch 32] step 18/44: loss=-0.5899 
[epoch 32] step 20/44: loss=-0.5902 
[epoch 32] step 22/44: loss=-0.5890 
[epoch 32] step 24/44: loss=-0.5878 
[epoch 32] step 26/44: loss=-0.5882 
[epoch 32] step 28/44: loss=-0.5884 
[epoch 32] step 30/44: loss=-0.5858 
[epoch 32] step 32/44: loss=-0.5861 
[epoch 32] step 34/44: loss=-0.5857 
[epoch 32] step 36/44: loss=-0.5856 
[epoch 32] step 38/44: loss=-0.5860 
[epoch 32] step 40/44: loss=-0.5865 
[epoch 32] step 42/44: loss=-0.5869 
[epoch 32] step 44/44: loss=-0.5862 
[epoch 32] train_loss(avg per step)=-1.1723 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=6.8909 qwk=('0.5327', '0.5371', '0.5112') averageQWK=0.5270 macroEMD=0.2542 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    4    0    0
     1   10   40    1    0
     0    4   97   13    0
     0    0   60   79    0
     0    1    3    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   11   43    1    0
     0    5   73   36    0
     0    1   42   98    2
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   14   51    0    0
     0    9  100   34    0
     0    0   37   73    0
     0    0    0    3    0
[epoch 33] step 2/44: loss=-0.6004 
[epoch 33] step 4/44: loss=-0.5963 
[epoch 33] step 6/44: loss=-0.5943 
[epoch 33] step 8/44: loss=-0.5874 
[epoch 33] step 10/44: loss=-0.5881 
[epoch 33] step 12/44: loss=-0.5895 
[epoch 33] step 14/44: loss=-0.5906 
[epoch 33] step 16/44: loss=-0.5912 
[epoch 33] step 18/44: loss=-0.5900 
[epoch 33] step 20/44: loss=-0.5909 
[epoch 33] step 22/44: loss=-0.5913 
[epoch 33] step 24/44: loss=-0.5915 
[epoch 33] step 26/44: loss=-0.5901 
[epoch 33] step 28/44: loss=-0.5890 
[epoch 33] step 30/44: loss=-0.5889 
[epoch 33] step 32/44: loss=-0.5891 
[epoch 33] step 34/44: loss=-0.5891 
[epoch 33] step 36/44: loss=-0.5892 
[epoch 33] step 38/44: loss=-0.5897 
[epoch 33] step 40/44: loss=-0.5894 
[epoch 33] step 42/44: loss=-0.5895 
[epoch 33] step 44/44: loss=-0.5897 
[epoch 33] train_loss(avg per step)=-1.1795 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=7.0539 qwk=('0.5186', '0.5273', '0.5101') averageQWK=0.5187 macroEMD=0.2545 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     1    9   41    1    0
     0    4   97   13    0
     0    0   60   78    1
     0    1    3    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   11   43    1    0
     0    6   69   39    0
     0    3   37  101    2
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   13   52    0    0
     0    9  102   32    0
     0    0   37   73    0
     0    0    0    3    0
[epoch 34] step 2/44: loss=-0.5995 
[epoch 34] step 4/44: loss=-0.5988 
[epoch 34] step 6/44: loss=-0.5969 
[epoch 34] step 8/44: loss=-0.5954 
[epoch 34] step 10/44: loss=-0.5953 
[epoch 34] step 12/44: loss=-0.5958 
[epoch 34] step 14/44: loss=-0.5942 
[epoch 34] step 16/44: loss=-0.5941 
[epoch 34] step 18/44: loss=-0.5948 
[epoch 34] step 20/44: loss=-0.5955 
[epoch 34] step 22/44: loss=-0.5959 
[epoch 34] step 24/44: loss=-0.5953 
[epoch 34] step 26/44: loss=-0.5954 
[epoch 34] step 28/44: loss=-0.5954 
[epoch 34] step 30/44: loss=-0.5954 
[epoch 34] step 32/44: loss=-0.5951 
[epoch 34] step 34/44: loss=-0.5941 
[epoch 34] step 36/44: loss=-0.5941 
[epoch 34] step 38/44: loss=-0.5937 
[epoch 34] step 40/44: loss=-0.5940 
[epoch 34] step 42/44: loss=-0.5941 
[epoch 34] step 44/44: loss=-0.5942 
[epoch 34] train_loss(avg per step)=-1.1885 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=6.8667 qwk=('0.5552', '0.5331', '0.5177') averageQWK=0.5353 macroEMD=0.2528 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     1    9   41    1    0
     0    4   96   14    0
     0    0   51   87    1
     0    1    2    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   11   43    1    0
     0    6   69   39    0
     0    1   41   99    2
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   14   51    0    0
     0    9   99   35    0
     0    0   35   75    0
     0    0    0    3    0
[epoch 35] step 2/44: loss=-0.6000 
[epoch 35] step 4/44: loss=-0.5996 
[epoch 35] step 6/44: loss=-0.5984 
[epoch 35] step 8/44: loss=-0.5966 
[epoch 35] step 10/44: loss=-0.5950 
[epoch 35] step 12/44: loss=-0.5945 
[epoch 35] step 14/44: loss=-0.5939 
[epoch 35] step 16/44: loss=-0.5931 
[epoch 35] step 18/44: loss=-0.5936 
[epoch 35] step 20/44: loss=-0.5930 
[epoch 35] step 22/44: loss=-0.5932 
[epoch 35] step 24/44: loss=-0.5929 
[epoch 35] step 26/44: loss=-0.5929 
[epoch 35] step 28/44: loss=-0.5935 
[epoch 35] step 30/44: loss=-0.5938 
[epoch 35] step 32/44: loss=-0.5942 
[epoch 35] step 34/44: loss=-0.5945 
[epoch 35] step 36/44: loss=-0.5939 
[epoch 35] step 38/44: loss=-0.5940 
[epoch 35] step 40/44: loss=-0.5939 
[epoch 35] step 42/44: loss=-0.5941 
[epoch 35] step 44/44: loss=-0.5945 
[epoch 35] train_loss(avg per step)=-1.1889 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=7.0435 qwk=('0.5512', '0.5377', '0.5087') averageQWK=0.5325 macroEMD=0.2538 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    5    0    0
     1    8   42    1    0
     0    4   97   13    0
     0    0   55   83    1
     0    0    3    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    0    0
     0   11   43    1    0
     0    6   65   43    0
     0    1   37  103    2
     0    0    1    7    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0   12   53    0    0
     0    8  102   33    0
     0    0   36   74    0
     0    0    0    3    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-0-conf_gating-0-reassignment-0/fold5/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-0-conf_gating-0-reassignment-0/fold5/metrics.json
Done.
