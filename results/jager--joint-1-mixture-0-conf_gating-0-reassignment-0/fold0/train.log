[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=5.8254 
[epoch 1] step 4/44: loss=5.9734 
[epoch 1] step 6/44: loss=5.9359 
[epoch 1] step 8/44: loss=6.0028 
[epoch 1] step 10/44: loss=6.0763 
[epoch 1] step 12/44: loss=6.0490 
[epoch 1] step 14/44: loss=6.0324 
[epoch 1] step 16/44: loss=6.0407 
[epoch 1] step 18/44: loss=6.0583 
[epoch 1] step 20/44: loss=5.9676 
[epoch 1] step 22/44: loss=5.9588 
[epoch 1] step 24/44: loss=5.9284 
[epoch 1] step 26/44: loss=5.9450 
[epoch 1] step 28/44: loss=5.8976 
[epoch 1] step 30/44: loss=5.8891 
[epoch 1] step 32/44: loss=5.8276 
[epoch 1] step 34/44: loss=5.8113 
[epoch 1] step 36/44: loss=5.7831 
[epoch 1] step 38/44: loss=5.7515 
[epoch 1] step 40/44: loss=5.7138 
[epoch 1] step 42/44: loss=5.6428 
[epoch 1] step 44/44: loss=5.5583 
[epoch 1] train_loss(avg per step)=11.1166 lambda[min,max]=[0.531109,1.000000]
[epoch 1] val_loss=8.9793 qwk=('0.0437', '0.0987', '-0.0236') averageQWK=0.0396 macroEMD=0.3855 tailR0=('0.0000', '0.1667', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   12    0    3    0
     0   58    0   20    0
     0  114    0   48    0
     0   43    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    0    4    0    0
     7    0    9    0    0
    26    0   40    0    0
    43    0  162    0    0
     2    0   28    0    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    1   28    0    0
     0    1  110    0    0
     0    9  172    0    0
     0    0    1    0    0
[epoch 2] step 2/44: loss=3.9838 
[epoch 2] step 4/44: loss=3.8000 
[epoch 2] step 6/44: loss=3.6663 
[epoch 2] step 8/44: loss=3.5395 
[epoch 2] step 10/44: loss=3.3586 
[epoch 2] step 12/44: loss=3.3533 
[epoch 2] step 14/44: loss=3.3419 
[epoch 2] step 16/44: loss=3.2547 
[epoch 2] step 18/44: loss=3.1967 
[epoch 2] step 20/44: loss=3.1053 
[epoch 2] step 22/44: loss=3.0626 
[epoch 2] step 24/44: loss=3.0264 
[epoch 2] step 26/44: loss=2.9619 
[epoch 2] step 28/44: loss=2.9271 
[epoch 2] step 30/44: loss=2.8806 
[epoch 2] step 32/44: loss=2.8482 
[epoch 2] step 34/44: loss=2.8367 
[epoch 2] step 36/44: loss=2.8071 
[epoch 2] step 38/44: loss=2.7772 
[epoch 2] step 40/44: loss=2.7409 
[epoch 2] step 42/44: loss=2.6996 
[epoch 2] step 44/44: loss=2.6691 
[epoch 2] train_loss(avg per step)=5.3382 lambda[min,max]=[0.505457,1.000000]
[epoch 2] val_loss=3.6303 qwk=('0.0565', '0.0721', '0.1698') averageQWK=0.0995 macroEMD=0.3798 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    2   12    1    0
     0    6   62   10    0
     0    2  122   38    0
     0    2   58    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   13    3    0
     0    0   46   20    0
     0    0  135   70    0
     0    0   20   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   26    1    0
     0    6   83   22    0
     0    1  132   48    0
     0    0    0    1    0
[epoch 3] step 2/44: loss=2.5110 
[epoch 3] step 4/44: loss=2.1501 
[epoch 3] step 6/44: loss=2.1282 
[epoch 3] step 8/44: loss=2.1001 
[epoch 3] step 10/44: loss=2.1040 
[epoch 3] step 12/44: loss=2.0315 
[epoch 3] step 14/44: loss=2.0017 
[epoch 3] step 16/44: loss=1.9668 
[epoch 3] step 18/44: loss=1.9463 
[epoch 3] step 20/44: loss=1.9299 
[epoch 3] step 22/44: loss=1.8937 
[epoch 3] step 24/44: loss=1.8736 
[epoch 3] step 26/44: loss=1.8437 
[epoch 3] step 28/44: loss=1.8312 
[epoch 3] step 30/44: loss=1.8238 
[epoch 3] step 32/44: loss=1.7984 
[epoch 3] step 34/44: loss=1.7775 
[epoch 3] step 36/44: loss=1.7632 
[epoch 3] step 38/44: loss=1.7397 
[epoch 3] step 40/44: loss=1.7362 
[epoch 3] step 42/44: loss=1.7230 
[epoch 3] step 44/44: loss=1.7227 
[epoch 3] train_loss(avg per step)=3.4453 lambda[min,max]=[0.500179,1.000000]
[epoch 3] val_loss=4.7945 qwk=('0.1023', '0.0453', '0.2168') averageQWK=0.1214 macroEMD=0.3717 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    8    1    0
     0    9   63    6    0
     0    7  118   37    0
     0    4   56    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   16    0    0
     0    0   60    6    0
     0    0  183   22    0
     0    0   27    3    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   19   10    0    0
     0   25   84    2    0
     0   23  141   17    0
     0    0    1    0    0
[epoch 4] step 2/44: loss=1.9604 
[epoch 4] step 4/44: loss=1.7354 
[epoch 4] step 6/44: loss=1.6932 
[epoch 4] step 8/44: loss=1.6568 
[epoch 4] step 10/44: loss=1.6563 
[epoch 4] step 12/44: loss=1.6422 
[epoch 4] step 14/44: loss=1.6280 
[epoch 4] step 16/44: loss=1.5883 
[epoch 4] step 18/44: loss=1.5397 
[epoch 4] step 20/44: loss=1.5443 
[epoch 4] step 22/44: loss=1.5506 
[epoch 4] step 24/44: loss=1.5551 
[epoch 4] step 26/44: loss=1.5519 
[epoch 4] step 28/44: loss=1.5605 
[epoch 4] step 30/44: loss=1.5253 
[epoch 4] step 32/44: loss=1.5208 
[epoch 4] step 34/44: loss=1.5097 
[epoch 4] step 36/44: loss=1.4991 
[epoch 4] step 38/44: loss=1.4898 
[epoch 4] step 40/44: loss=1.4833 
[epoch 4] step 42/44: loss=1.4772 
[epoch 4] step 44/44: loss=1.4759 
[epoch 4] train_loss(avg per step)=2.9517 lambda[min,max]=[0.500854,1.000000]
[epoch 4] val_loss=3.5777 qwk=('0.1354', '0.2043', '0.2842') averageQWK=0.2080 macroEMD=0.3575 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0    5    9    1    0
     0   13   60    5    0
     0    2  126   34    0
     0    2   58    4    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    3   10    3    0
     0    3   45   18    0
     0    5  118   82    0
     0    1   14   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   22    7    0    0
     0   37   62   12    0
     0   31  103   47    0
     0    0    0    1    0
[epoch 5] step 2/44: loss=1.1630 
[epoch 5] step 4/44: loss=1.4309 
[epoch 5] step 6/44: loss=1.4328 
[epoch 5] step 8/44: loss=1.3911 
[epoch 5] step 10/44: loss=1.3983 
[epoch 5] step 12/44: loss=1.3827 
[epoch 5] step 14/44: loss=1.3578 
[epoch 5] step 16/44: loss=1.3274 
[epoch 5] step 18/44: loss=1.3094 
[epoch 5] step 20/44: loss=1.2949 
[epoch 5] step 22/44: loss=1.2941 
[epoch 5] step 24/44: loss=1.2853 
[epoch 5] step 26/44: loss=1.2770 
[epoch 5] step 28/44: loss=1.2519 
[epoch 5] step 30/44: loss=1.2425 
[epoch 5] step 32/44: loss=1.2288 
[epoch 5] step 34/44: loss=1.2199 
[epoch 5] step 36/44: loss=1.2165 
[epoch 5] step 38/44: loss=1.2030 
[epoch 5] step 40/44: loss=1.2062 
[epoch 5] step 42/44: loss=1.2055 
[epoch 5] step 44/44: loss=1.1994 
[epoch 5] train_loss(avg per step)=2.3987 lambda[min,max]=[0.503107,1.000000]
[epoch 5] val_loss=3.4409 qwk=('0.1304', '0.1706', '0.1517') averageQWK=0.1509 macroEMD=0.3488 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    1   14    0    0
     0    1   62   15    0
     0    0  103   59    0
     0    0   47   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   16    0    0
     0    1   50   15    0
     0    0  139   66    0
     0    0   16   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    3   26    0    0
     0    3  107    1    0
     0    0  158   23    0
     0    0    1    0    0
[epoch 6] step 2/44: loss=1.1840 
[epoch 6] step 4/44: loss=1.1878 
[epoch 6] step 6/44: loss=1.1175 
[epoch 6] step 8/44: loss=1.1124 
[epoch 6] step 10/44: loss=1.1194 
[epoch 6] step 12/44: loss=1.1158 
[epoch 6] step 14/44: loss=1.0791 
[epoch 6] step 16/44: loss=1.0546 
[epoch 6] step 18/44: loss=1.0616 
[epoch 6] step 20/44: loss=1.0548 
[epoch 6] step 22/44: loss=1.0378 
[epoch 6] step 24/44: loss=1.0543 
[epoch 6] step 26/44: loss=1.0524 
[epoch 6] step 28/44: loss=1.0502 
[epoch 6] step 30/44: loss=1.0434 
[epoch 6] step 32/44: loss=1.0508 
[epoch 6] step 34/44: loss=1.0456 
[epoch 6] step 36/44: loss=1.0458 
[epoch 6] step 38/44: loss=1.0298 
[epoch 6] step 40/44: loss=1.0271 
[epoch 6] step 42/44: loss=1.0250 
[epoch 6] step 44/44: loss=1.0120 
[epoch 6] train_loss(avg per step)=2.0239 lambda[min,max]=[0.503239,1.000000]
[epoch 6] val_loss=3.9760 qwk=('0.1293', '0.2629', '0.2451') averageQWK=0.2124 macroEMD=0.3391 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   12    0    0
     0    5   65    8    0
     0    0  123   39    0
     0    2   51   11    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   10    3    3    0
     0   14   37   15    0
     0   16  116   73    0
     0    2   13   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   12    0    0
     0   22   85    4    0
     0   20  131   30    0
     0    0    1    0    0
[epoch 7] step 2/44: loss=0.9905 
[epoch 7] step 4/44: loss=0.9827 
[epoch 7] step 6/44: loss=0.9324 
[epoch 7] step 8/44: loss=0.9175 
[epoch 7] step 10/44: loss=0.8721 
[epoch 7] step 12/44: loss=0.8892 
[epoch 7] step 14/44: loss=0.8691 
[epoch 7] step 16/44: loss=0.8878 
[epoch 7] step 18/44: loss=0.8899 
[epoch 7] step 20/44: loss=0.8918 
[epoch 7] step 22/44: loss=0.8960 
[epoch 7] step 24/44: loss=0.8999 
[epoch 7] step 26/44: loss=0.9015 
[epoch 7] step 28/44: loss=0.9021 
[epoch 7] step 30/44: loss=0.9111 
[epoch 7] step 32/44: loss=0.9053 
[epoch 7] step 34/44: loss=0.9081 
[epoch 7] step 36/44: loss=0.8948 
[epoch 7] step 38/44: loss=0.8952 
[epoch 7] step 40/44: loss=0.8889 
[epoch 7] step 42/44: loss=0.8794 
[epoch 7] step 44/44: loss=0.8687 
[epoch 7] train_loss(avg per step)=1.7374 lambda[min,max]=[0.503676,1.000000]
[epoch 7] val_loss=2.9472 qwk=('0.2138', '0.1798', '0.2910') averageQWK=0.2282 macroEMD=0.3229 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    1   13    1    0
     0    1   45   32    0
     0    0   56  106    0
     0    0   31   33    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    5    0    0
     0    0   14    2    0
     0    0   51   15    0
     0    0  130   75    0
     0    0   14   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    5   24    0    0
     0    1   95   15    0
     0    0  121   60    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=0.7557 
[epoch 8] step 4/44: loss=0.7537 
[epoch 8] step 6/44: loss=0.8389 
[epoch 8] step 8/44: loss=0.8090 
[epoch 8] step 10/44: loss=0.7539 
[epoch 8] step 12/44: loss=0.7462 
[epoch 8] step 14/44: loss=0.7192 
[epoch 8] step 16/44: loss=0.7200 
[epoch 8] step 18/44: loss=0.7091 
[epoch 8] step 20/44: loss=0.7390 
[epoch 8] step 22/44: loss=0.7380 
[epoch 8] step 24/44: loss=0.7397 
[epoch 8] step 26/44: loss=0.7296 
[epoch 8] step 28/44: loss=0.7281 
[epoch 8] step 30/44: loss=0.7171 
[epoch 8] step 32/44: loss=0.7187 
[epoch 8] step 34/44: loss=0.7018 
[epoch 8] step 36/44: loss=0.6920 
[epoch 8] step 38/44: loss=0.6978 
[epoch 8] step 40/44: loss=0.6991 
[epoch 8] step 42/44: loss=0.6972 
[epoch 8] step 44/44: loss=0.6974 
[epoch 8] train_loss(avg per step)=1.3948 lambda[min,max]=[0.503423,1.000000]
[epoch 8] val_loss=3.2649 qwk=('0.1836', '0.2885', '0.3554') averageQWK=0.2758 macroEMD=0.3150 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    6   58   14    0
     0    1  102   59    0
     0    1   40   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6    9    1    0
     0    6   38   22    0
     0    3  120   82    0
     0    1   12   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   11   18    0    0
     0    6   85   20    0
     0    3  108   70    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=0.6284 
[epoch 9] step 4/44: loss=0.5828 
[epoch 9] step 6/44: loss=0.5689 
[epoch 9] step 8/44: loss=0.5428 
[epoch 9] step 10/44: loss=0.5427 
[epoch 9] step 12/44: loss=0.5458 
[epoch 9] step 14/44: loss=0.5561 
[epoch 9] step 16/44: loss=0.5518 
[epoch 9] step 18/44: loss=0.5460 
[epoch 9] step 20/44: loss=0.5702 
[epoch 9] step 22/44: loss=0.5552 
[epoch 9] step 24/44: loss=0.5526 
[epoch 9] step 26/44: loss=0.5532 
[epoch 9] step 28/44: loss=0.5471 
[epoch 9] step 30/44: loss=0.5400 
[epoch 9] step 32/44: loss=0.5369 
[epoch 9] step 34/44: loss=0.5384 
[epoch 9] step 36/44: loss=0.5361 
[epoch 9] step 38/44: loss=0.5258 
[epoch 9] step 40/44: loss=0.5210 
[epoch 9] step 42/44: loss=0.5257 
[epoch 9] step 44/44: loss=0.5230 
[epoch 9] train_loss(avg per step)=1.0460 lambda[min,max]=[0.500736,1.000000]
[epoch 9] val_loss=3.4015 qwk=('0.2263', '0.2326', '0.2826') averageQWK=0.2471 macroEMD=0.3100 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    2   11    2    0
     0    1   58   19    0
     0    0   75   86    1
     0    0   34   29    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    2   13    1    0
     0    3   49   14    0
     0    1  137   67    0
     0    0   14   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   22    0    0
     0    5  102    4    0
     0    2  134   45    0
     0    0    0    1    0
[epoch 10] step 2/44: loss=0.4501 
[epoch 10] step 4/44: loss=0.5394 
[epoch 10] step 6/44: loss=0.4939 
[epoch 10] step 8/44: loss=0.5191 
[epoch 10] step 10/44: loss=0.4833 
[epoch 10] step 12/44: loss=0.5030 
[epoch 10] step 14/44: loss=0.4860 
[epoch 10] step 16/44: loss=0.4659 
[epoch 10] step 18/44: loss=0.4617 
[epoch 10] step 20/44: loss=0.4600 
[epoch 10] step 22/44: loss=0.4477 
[epoch 10] step 24/44: loss=0.4470 
[epoch 10] step 26/44: loss=0.4467 
[epoch 10] step 28/44: loss=0.4512 
[epoch 10] step 30/44: loss=0.4514 
[epoch 10] step 32/44: loss=0.4480 
[epoch 10] step 34/44: loss=0.4511 
[epoch 10] step 36/44: loss=0.4443 
[epoch 10] step 38/44: loss=0.4334 
[epoch 10] step 40/44: loss=0.4375 
[epoch 10] step 42/44: loss=0.4301 
[epoch 10] step 44/44: loss=0.4191 
[epoch 10] train_loss(avg per step)=0.8383 lambda[min,max]=[0.500276,1.000000]
[epoch 10] val_loss=3.8483 qwk=('0.2248', '0.2706', '0.2262') averageQWK=0.2405 macroEMD=0.3030 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    3   11    1    0
     0    5   50   23    0
     0    1   83   77    1
     0    1   33   30    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    4   11    1    0
     0    7   36   23    0
     0    2  120   83    0
     0    1   11   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   22    0    0
     0    4  103    4    0
     0    2  144   35    0
     0    0    1    0    0
[epoch 11] step 2/44: loss=0.2261 
[epoch 11] step 4/44: loss=0.2610 
[epoch 11] step 6/44: loss=0.2654 
[epoch 11] step 8/44: loss=0.2724 
[epoch 11] step 10/44: loss=0.2761 
[epoch 11] step 12/44: loss=0.2999 
[epoch 11] step 14/44: loss=0.2879 
[epoch 11] step 16/44: loss=0.2794 
[epoch 11] step 18/44: loss=0.2715 
[epoch 11] step 20/44: loss=0.2694 
[epoch 11] step 22/44: loss=0.2799 
[epoch 11] step 24/44: loss=0.2719 
[epoch 11] step 26/44: loss=0.2753 
[epoch 11] step 28/44: loss=0.2885 
[epoch 11] step 30/44: loss=0.2863 
[epoch 11] step 32/44: loss=0.2832 
[epoch 11] step 34/44: loss=0.2825 
[epoch 11] step 36/44: loss=0.2848 
[epoch 11] step 38/44: loss=0.2805 
[epoch 11] step 40/44: loss=0.2796 
[epoch 11] step 42/44: loss=0.2773 
[epoch 11] step 44/44: loss=0.2830 
[epoch 11] train_loss(avg per step)=0.5661 lambda[min,max]=[0.500072,1.000000]
[epoch 11] val_loss=3.4858 qwk=('0.2208', '0.2920', '0.4406') averageQWK=0.3178 macroEMD=0.2957 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    8    1    0
     0    8   55   15    0
     0    2  101   58    1
     0    2   38   23    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    9    6    1    0
     0   10   39   17    0
     0    6  126   73    0
     0    1   11   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   16   13    0    0
     0   10   78   23    0
     0    3   94   84    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=0.2696 
[epoch 12] step 4/44: loss=0.3128 
[epoch 12] step 6/44: loss=0.2687 
[epoch 12] step 8/44: loss=0.2314 
[epoch 12] step 10/44: loss=0.1929 
[epoch 12] step 12/44: loss=0.1878 
[epoch 12] step 14/44: loss=0.1978 
[epoch 12] step 16/44: loss=0.1734 
[epoch 12] step 18/44: loss=0.1820 
[epoch 12] step 20/44: loss=0.1907 
[epoch 12] step 22/44: loss=0.1865 
[epoch 12] step 24/44: loss=0.1730 
[epoch 12] step 26/44: loss=0.1767 
[epoch 12] step 28/44: loss=0.1774 
[epoch 12] step 30/44: loss=0.1846 
[epoch 12] step 32/44: loss=0.1846 
[epoch 12] step 34/44: loss=0.1861 
[epoch 12] step 36/44: loss=0.1865 
[epoch 12] step 38/44: loss=0.1824 
[epoch 12] step 40/44: loss=0.1929 
[epoch 12] step 42/44: loss=0.2067 
[epoch 12] step 44/44: loss=0.2078 
[epoch 12] train_loss(avg per step)=0.4155 lambda[min,max]=[0.500471,1.000000]
[epoch 12] val_loss=4.3926 qwk=('0.2136', '0.2498', '0.2538') averageQWK=0.2391 macroEMD=0.3038 tailR0=('0.1250', '0.1667', '0.0000') tailR0avg=0.0972
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0    5    9    1    0
     0   11   49   18    0
     0    3   95   63    1
     0    3   37   24    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    2    0    0
     0    8    6    2    0
     0    9   36   21    0
     0    8  135   62    0
     0    1   14   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   10   19    0    0
     0    6   99    6    0
     0    3  144   34    0
     0    0    0    1    0
[epoch 13] step 2/44: loss=0.1272 
[epoch 13] step 4/44: loss=0.0764 
[epoch 13] step 6/44: loss=0.0907 
[epoch 13] step 8/44: loss=0.1346 
[epoch 13] step 10/44: loss=0.1431 
[epoch 13] step 12/44: loss=0.1482 
[epoch 13] step 14/44: loss=0.1460 
[epoch 13] step 16/44: loss=0.1596 
[epoch 13] step 18/44: loss=0.1589 
[epoch 13] step 20/44: loss=0.1409 
[epoch 13] step 22/44: loss=0.1380 
[epoch 13] step 24/44: loss=0.1295 
[epoch 13] step 26/44: loss=0.1260 
[epoch 13] step 28/44: loss=0.1135 
[epoch 13] step 30/44: loss=0.1121 
[epoch 13] step 32/44: loss=0.0992 
[epoch 13] step 34/44: loss=0.0888 
[epoch 13] step 36/44: loss=0.0872 
[epoch 13] step 38/44: loss=0.0951 
[epoch 13] step 40/44: loss=0.0901 
[epoch 13] step 42/44: loss=0.0890 
[epoch 13] step 44/44: loss=0.0855 
[epoch 13] train_loss(avg per step)=0.1711 lambda[min,max]=[0.500544,1.000000]
[epoch 13] val_loss=3.5451 qwk=('0.2772', '0.3685', '0.3432') averageQWK=0.3296 macroEMD=0.2968 tailR0=('0.1328', '0.1667', '0.0000') tailR0avg=0.0998
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     0    5    8    2    0
     0    9   38   30    1
     0    2   56  102    2
     0    2   25   36    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    1    3    0    0
     1    6    6    3    0
     2    7   29   28    0
     0    5   74  126    0
     0    1    8   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   11   17    0    0
     0   15   89    7    0
     0    5  128   48    0
     0    0    0    1    0
[epoch 14] step 2/44: loss=-0.0197 
[epoch 14] step 4/44: loss=0.0165 
[epoch 14] step 6/44: loss=0.0172 
[epoch 14] step 8/44: loss=0.0301 
[epoch 14] step 10/44: loss=0.0145 
[epoch 14] step 12/44: loss=0.0055 
[epoch 14] step 14/44: loss=0.0114 
[epoch 14] step 16/44: loss=0.0106 
[epoch 14] step 18/44: loss=0.0210 
[epoch 14] step 20/44: loss=0.0233 
[epoch 14] step 22/44: loss=0.0281 
[epoch 14] step 24/44: loss=0.0232 
[epoch 14] step 26/44: loss=0.0222 
[epoch 14] step 28/44: loss=0.0173 
[epoch 14] step 30/44: loss=0.0124 
[epoch 14] step 32/44: loss=0.0022 
[epoch 14] step 34/44: loss=-0.0022 
[epoch 14] step 36/44: loss=-0.0083 
[epoch 14] step 38/44: loss=-0.0085 
[epoch 14] step 40/44: loss=-0.0106 
[epoch 14] step 42/44: loss=-0.0106 
[epoch 14] step 44/44: loss=-0.0096 
[epoch 14] train_loss(avg per step)=-0.0191 lambda[min,max]=[0.500183,1.000000]
[epoch 14] val_loss=3.6930 qwk=('0.2394', '0.2607', '0.3889') averageQWK=0.2963 macroEMD=0.2967 tailR0=('0.1328', '0.0167', '0.0000') tailR0avg=0.0498
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     0    3    9    3    0
     1    5   32   39    1
     0    1   44  116    1
     0    1   26   36    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    6    7    3    0
     0    7   35   23    1
     0    3  109   91    2
     0    1   10   18    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   13   15    0    0
     0   19   77   15    0
     0    6  110   65    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=0.0839 
[epoch 15] step 4/44: loss=-0.0312 
[epoch 15] step 6/44: loss=-0.0478 
[epoch 15] step 8/44: loss=-0.0545 
[epoch 15] step 10/44: loss=-0.0532 
[epoch 15] step 12/44: loss=-0.0518 
[epoch 15] step 14/44: loss=-0.0378 
[epoch 15] step 16/44: loss=-0.0470 
[epoch 15] step 18/44: loss=-0.0546 
[epoch 15] step 20/44: loss=-0.0567 
[epoch 15] step 22/44: loss=-0.0609 
[epoch 15] step 24/44: loss=-0.0717 
[epoch 15] step 26/44: loss=-0.0821 
[epoch 15] step 28/44: loss=-0.0825 
[epoch 15] step 30/44: loss=-0.0902 
[epoch 15] step 32/44: loss=-0.0938 
[epoch 15] step 34/44: loss=-0.0931 
[epoch 15] step 36/44: loss=-0.0953 
[epoch 15] step 38/44: loss=-0.0961 
[epoch 15] step 40/44: loss=-0.0976 
[epoch 15] step 42/44: loss=-0.0995 
[epoch 15] step 44/44: loss=-0.1001 
[epoch 15] train_loss(avg per step)=-0.2001 lambda[min,max]=[0.500038,1.000000]
[epoch 15] val_loss=4.9678 qwk=('0.1421', '0.2073', '0.3011') averageQWK=0.2168 macroEMD=0.2924 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4   10    1    0
     0    5   64    7    2
     0    2  119   39    2
     0    2   45   16    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    6    8    2    0
     0    8   44   14    0
     0    1  155   49    0
     0    0   18   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   10   19    0    0
     0    8   97    6    0
     0    3  133   45    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=-0.1075 
[epoch 16] step 4/44: loss=-0.0802 
[epoch 16] step 6/44: loss=-0.1195 
[epoch 16] step 8/44: loss=-0.1235 
[epoch 16] step 10/44: loss=-0.1310 
[epoch 16] step 12/44: loss=-0.1351 
[epoch 16] step 14/44: loss=-0.1182 
[epoch 16] step 16/44: loss=-0.1297 
[epoch 16] step 18/44: loss=-0.1342 
[epoch 16] step 20/44: loss=-0.1400 
[epoch 16] step 22/44: loss=-0.1374 
[epoch 16] step 24/44: loss=-0.1373 
[epoch 16] step 26/44: loss=-0.1314 
[epoch 16] step 28/44: loss=-0.1369 
[epoch 16] step 30/44: loss=-0.1372 
[epoch 16] step 32/44: loss=-0.1358 
[epoch 16] step 34/44: loss=-0.1399 
[epoch 16] step 36/44: loss=-0.1446 
[epoch 16] step 38/44: loss=-0.1430 
[epoch 16] step 40/44: loss=-0.1425 
[epoch 16] step 42/44: loss=-0.1441 
[epoch 16] step 44/44: loss=-0.1413 
[epoch 16] train_loss(avg per step)=-0.2826 lambda[min,max]=[0.500059,1.000000]
[epoch 16] val_loss=3.4675 qwk=('0.1863', '0.2394', '0.3603') averageQWK=0.2620 macroEMD=0.2965 tailR0=('0.0391', '0.0167', '0.0000') tailR0avg=0.0186
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    2    7    6    0
     0    3   36   34    5
     0    1   43  112    6
     0    1   26   32    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    3    9    4    0
     0    5   33   28    0
     0    1   99  104    1
     0    1   10   18    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   22    0    0
     0    8   87   16    0
     0    2  105   74    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=-0.2161 
[epoch 17] step 4/44: loss=-0.2078 
[epoch 17] step 6/44: loss=-0.2056 
[epoch 17] step 8/44: loss=-0.2090 
[epoch 17] step 10/44: loss=-0.1983 
[epoch 17] step 12/44: loss=-0.2045 
[epoch 17] step 14/44: loss=-0.2119 
[epoch 17] step 16/44: loss=-0.2061 
[epoch 17] step 18/44: loss=-0.2143 
[epoch 17] step 20/44: loss=-0.2094 
[epoch 17] step 22/44: loss=-0.2122 
[epoch 17] step 24/44: loss=-0.2244 
[epoch 17] step 26/44: loss=-0.2295 
[epoch 17] step 28/44: loss=-0.2370 
[epoch 17] step 30/44: loss=-0.2415 
[epoch 17] step 32/44: loss=-0.2444 
[epoch 17] step 34/44: loss=-0.2414 
[epoch 17] step 36/44: loss=-0.2373 
[epoch 17] step 38/44: loss=-0.2363 
[epoch 17] step 40/44: loss=-0.2279 
[epoch 17] step 42/44: loss=-0.2294 
[epoch 17] step 44/44: loss=-0.2291 
[epoch 17] train_loss(avg per step)=-0.4581 lambda[min,max]=[0.500030,1.000000]
[epoch 17] val_loss=4.1169 qwk=('0.2162', '0.2988', '0.3052') averageQWK=0.2734 macroEMD=0.2910 tailR0=('0.1250', '0.0000', '0.0000') tailR0avg=0.0417
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     0    2   12    1    0
     0    3   45   30    0
     0    1   67   92    2
     0    1   31   32    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    3   10    3    0
     0    5   34   27    0
     0    2   91  112    0
     0    0    9   21    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    7   22    0    0
     0    5   97    9    0
     0    2  124   55    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=-0.3130 
[epoch 18] step 4/44: loss=-0.2893 
[epoch 18] step 6/44: loss=-0.2765 
[epoch 18] step 8/44: loss=-0.2557 
[epoch 18] step 10/44: loss=-0.2447 
[epoch 18] step 12/44: loss=-0.2594 
[epoch 18] step 14/44: loss=-0.2558 
[epoch 18] step 16/44: loss=-0.2538 
[epoch 18] step 18/44: loss=-0.2697 
[epoch 18] step 20/44: loss=-0.2717 
[epoch 18] step 22/44: loss=-0.2572 
[epoch 18] step 24/44: loss=-0.2615 
[epoch 18] step 26/44: loss=-0.2676 
[epoch 18] step 28/44: loss=-0.2689 
[epoch 18] step 30/44: loss=-0.2683 
[epoch 18] step 32/44: loss=-0.2685 
[epoch 18] step 34/44: loss=-0.2666 
[epoch 18] step 36/44: loss=-0.2696 
[epoch 18] step 38/44: loss=-0.2711 
[epoch 18] step 40/44: loss=-0.2701 
[epoch 18] step 42/44: loss=-0.2686 
[epoch 18] step 44/44: loss=-0.2607 
[epoch 18] train_loss(avg per step)=-0.5213 lambda[min,max]=[0.500003,1.000000]
[epoch 18] val_loss=4.3763 qwk=('0.2094', '0.3506', '0.2978') averageQWK=0.2859 macroEMD=0.2860 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    3   11    1    0
     0    5   53   18    2
     0    2   82   77    1
     0    2   32   29    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    4    8    4    0
     0    6   31   29    0
     0    1   74  130    0
     0    0    7   23    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   11   18    0    0
     0    9   96    6    0
     0    2  139   40    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=-0.3347 
[epoch 19] step 4/44: loss=-0.3593 
[epoch 19] step 6/44: loss=-0.3520 
[epoch 19] step 8/44: loss=-0.3422 
[epoch 19] step 10/44: loss=-0.3272 
[epoch 19] step 12/44: loss=-0.3205 
[epoch 19] step 14/44: loss=-0.3129 
[epoch 19] step 16/44: loss=-0.3204 
[epoch 19] step 18/44: loss=-0.3208 
[epoch 19] step 20/44: loss=-0.3214 
[epoch 19] step 22/44: loss=-0.3231 
[epoch 19] step 24/44: loss=-0.3288 
[epoch 19] step 26/44: loss=-0.3289 
[epoch 19] step 28/44: loss=-0.3295 
[epoch 19] step 30/44: loss=-0.3248 
[epoch 19] step 32/44: loss=-0.3232 
[epoch 19] step 34/44: loss=-0.3220 
[epoch 19] step 36/44: loss=-0.3229 
[epoch 19] step 38/44: loss=-0.3280 
[epoch 19] step 40/44: loss=-0.3246 
[epoch 19] step 42/44: loss=-0.3275 
[epoch 19] step 44/44: loss=-0.3317 
[epoch 19] train_loss(avg per step)=-0.6634 lambda[min,max]=[0.500009,1.000000]
[epoch 19] val_loss=5.3247 qwk=('0.2346', '0.1768', '0.3550') averageQWK=0.2554 macroEMD=0.2880 tailR0=('0.0078', '0.0167', '0.0000') tailR0avg=0.0082
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6    7    2    0
     0    9   39   28    2
     0    3   68   90    1
     0    2   30   31    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    7    8    1    0
     0    8   47   10    1
     0    5  157   38    5
     0    1   24    4    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1   10   18    0    0
     0   11   91    9    0
     0    3  121   57    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=-0.4294 
[epoch 20] step 4/44: loss=-0.4330 
[epoch 20] step 6/44: loss=-0.4192 
[epoch 20] step 8/44: loss=-0.4106 
[epoch 20] step 10/44: loss=-0.4161 
[epoch 20] step 12/44: loss=-0.4142 
[epoch 20] step 14/44: loss=-0.4166 
[epoch 20] step 16/44: loss=-0.4178 
[epoch 20] step 18/44: loss=-0.4160 
[epoch 20] step 20/44: loss=-0.4107 
[epoch 20] step 22/44: loss=-0.4068 
[epoch 20] step 24/44: loss=-0.4054 
[epoch 20] step 26/44: loss=-0.4059 
[epoch 20] step 28/44: loss=-0.4024 
[epoch 20] step 30/44: loss=-0.3986 
[epoch 20] step 32/44: loss=-0.3949 
[epoch 20] step 34/44: loss=-0.3954 
[epoch 20] step 36/44: loss=-0.3935 
[epoch 20] step 38/44: loss=-0.3911 
[epoch 20] step 40/44: loss=-0.3882 
[epoch 20] step 42/44: loss=-0.3883 
[epoch 20] step 44/44: loss=-0.3894 
[epoch 20] train_loss(avg per step)=-0.7789 lambda[min,max]=[0.500008,1.000000]
[epoch 20] val_loss=5.3989 qwk=('0.2003', '0.2162', '0.3036') averageQWK=0.2400 macroEMD=0.2858 tailR0=('0.1328', '0.0000', '0.0000') tailR0avg=0.0443
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0    7    6    2    0
     0   14   40   22    2
     0    6   83   72    1
     0    4   36   23    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    7    2    0
     0    9   42   14    1
     0    7  134   61    3
     0    1   20    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   12   17    0    0
     0   15   91    5    0
     0    5  135   41    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=-0.4311 
[epoch 21] step 4/44: loss=-0.3657 
[epoch 21] step 6/44: loss=-0.3795 
[epoch 21] step 8/44: loss=-0.4006 
[epoch 21] step 10/44: loss=-0.4169 
[epoch 21] step 12/44: loss=-0.4187 
[epoch 21] step 14/44: loss=-0.4191 
[epoch 21] step 16/44: loss=-0.4254 
[epoch 21] step 18/44: loss=-0.4215 
[epoch 21] step 20/44: loss=-0.4171 
[epoch 21] step 22/44: loss=-0.4206 
[epoch 21] step 24/44: loss=-0.4189 
[epoch 21] step 26/44: loss=-0.4214 
[epoch 21] step 28/44: loss=-0.4237 
[epoch 21] step 30/44: loss=-0.4254 
[epoch 21] step 32/44: loss=-0.4288 
[epoch 21] step 34/44: loss=-0.4272 
[epoch 21] step 36/44: loss=-0.4273 
[epoch 21] step 38/44: loss=-0.4285 
[epoch 21] step 40/44: loss=-0.4295 
[epoch 21] step 42/44: loss=-0.4304 
[epoch 21] step 44/44: loss=-0.4274 
[epoch 21] train_loss(avg per step)=-0.8548 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=5.6945 qwk=('0.1953', '0.1759', '0.3514') averageQWK=0.2409 macroEMD=0.2812 tailR0=('0.0078', '0.0167', '0.0000') tailR0avg=0.0082
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4    9    2    0
     0    5   50   22    1
     0    1   74   86    1
     0    3   33   27    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    3   11    2    0
     0    5   45   15    1
     0    2  136   66    1
     0    0   19   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   14   15    0    0
     0   12   93    6    0
     0    3  130   48    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=-0.4797 
[epoch 22] step 4/44: loss=-0.4497 
[epoch 22] step 6/44: loss=-0.4137 
[epoch 22] step 8/44: loss=-0.4249 
[epoch 22] step 10/44: loss=-0.4236 
[epoch 22] step 12/44: loss=-0.4380 
[epoch 22] step 14/44: loss=-0.4412 
[epoch 22] step 16/44: loss=-0.4432 
[epoch 22] step 18/44: loss=-0.4436 
[epoch 22] step 20/44: loss=-0.4435 
[epoch 22] step 22/44: loss=-0.4437 
[epoch 22] step 24/44: loss=-0.4471 
[epoch 22] step 26/44: loss=-0.4488 
[epoch 22] step 28/44: loss=-0.4504 
[epoch 22] step 30/44: loss=-0.4533 
[epoch 22] step 32/44: loss=-0.4534 
[epoch 22] step 34/44: loss=-0.4529 
[epoch 22] step 36/44: loss=-0.4532 
[epoch 22] step 38/44: loss=-0.4547 
[epoch 22] step 40/44: loss=-0.4534 
[epoch 22] step 42/44: loss=-0.4529 
[epoch 22] step 44/44: loss=-0.4546 
[epoch 22] train_loss(avg per step)=-0.9092 lambda[min,max]=[0.500002,1.000000]
[epoch 22] val_loss=4.7798 qwk=('0.1948', '0.3181', '0.3580') averageQWK=0.2903 macroEMD=0.2811 tailR0=('0.0078', '0.0167', '0.0000') tailR0avg=0.0082
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    7    4    4    0
     0   10   32   35    1
     0    4   51  104    3
     0    4   29   30    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6    7    3    0
     0    6   37   22    1
     0    5   91  107    2
     0    1   11   17    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   13   16    0    0
     0   12   89   10    0
     0    5  117   59    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=-0.4640 
[epoch 23] step 4/44: loss=-0.4433 
[epoch 23] step 6/44: loss=-0.4489 
[epoch 23] step 8/44: loss=-0.4507 
[epoch 23] step 10/44: loss=-0.4645 
[epoch 23] step 12/44: loss=-0.4685 
[epoch 23] step 14/44: loss=-0.4740 
[epoch 23] step 16/44: loss=-0.4781 
[epoch 23] step 18/44: loss=-0.4861 
[epoch 23] step 20/44: loss=-0.4857 
[epoch 23] step 22/44: loss=-0.4850 
[epoch 23] step 24/44: loss=-0.4817 
[epoch 23] step 26/44: loss=-0.4825 
[epoch 23] step 28/44: loss=-0.4852 
[epoch 23] step 30/44: loss=-0.4845 
[epoch 23] step 32/44: loss=-0.4853 
[epoch 23] step 34/44: loss=-0.4857 
[epoch 23] step 36/44: loss=-0.4861 
[epoch 23] step 38/44: loss=-0.4834 
[epoch 23] step 40/44: loss=-0.4816 
[epoch 23] step 42/44: loss=-0.4828 
[epoch 23] step 44/44: loss=-0.4825 
[epoch 23] train_loss(avg per step)=-0.9650 lambda[min,max]=[0.500001,1.000000]
[epoch 23] val_loss=5.7710 qwk=('0.2326', '0.2062', '0.3275') averageQWK=0.2554 macroEMD=0.2773 tailR0=('0.0000', '0.0167', '0.0000') tailR0avg=0.0056
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7    5    3    0
     0   11   38   28    1
     0    5   63   93    1
     0    4   27   33    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    5    9    2    0
     0    5   45   15    1
     0    4  132   63    6
     0    1   17   11    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   13   16    0    0
     0    8   97    6    0
     0    3  133   45    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=-0.4856 
[epoch 24] step 4/44: loss=-0.5028 
[epoch 24] step 6/44: loss=-0.5011 
[epoch 24] step 8/44: loss=-0.5045 
[epoch 24] step 10/44: loss=-0.5099 
[epoch 24] step 12/44: loss=-0.5153 
[epoch 24] step 14/44: loss=-0.5139 
[epoch 24] step 16/44: loss=-0.5134 
[epoch 24] step 18/44: loss=-0.5120 
[epoch 24] step 20/44: loss=-0.5095 
[epoch 24] step 22/44: loss=-0.5063 
[epoch 24] step 24/44: loss=-0.5039 
[epoch 24] step 26/44: loss=-0.5065 
[epoch 24] step 28/44: loss=-0.5082 
[epoch 24] step 30/44: loss=-0.5057 
[epoch 24] step 32/44: loss=-0.5075 
[epoch 24] step 34/44: loss=-0.5071 
[epoch 24] step 36/44: loss=-0.5062 
[epoch 24] step 38/44: loss=-0.5080 
[epoch 24] step 40/44: loss=-0.5073 
[epoch 24] step 42/44: loss=-0.5070 
[epoch 24] step 44/44: loss=-0.5078 
[epoch 24] train_loss(avg per step)=-1.0156 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=5.9913 qwk=('0.2026', '0.2566', '0.3449') averageQWK=0.2680 macroEMD=0.2772 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    6    7    2    0
     0    7   45   26    0
     0    3   69   90    0
     0    4   31   29    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    6    7    3    0
     0    5   41   19    1
     0    3  117   83    2
     0    1   11   18    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   12   17    0    0
     0   10   93    8    0
     0    6  117   58    0
     0    0    0    1    0
[epoch 25] step 2/44: loss=-0.5195 
[epoch 25] step 4/44: loss=-0.5303 
[epoch 25] step 6/44: loss=-0.5323 
[epoch 25] step 8/44: loss=-0.5236 
[epoch 25] step 10/44: loss=-0.5209 
[epoch 25] step 12/44: loss=-0.5180 
[epoch 25] step 14/44: loss=-0.5150 
[epoch 25] step 16/44: loss=-0.5147 
[epoch 25] step 18/44: loss=-0.5047 
[epoch 25] step 20/44: loss=-0.5059 
[epoch 25] step 22/44: loss=-0.5051 
[epoch 25] step 24/44: loss=-0.5042 
[epoch 25] step 26/44: loss=-0.5051 
[epoch 25] step 28/44: loss=-0.5063 
[epoch 25] step 30/44: loss=-0.5063 
[epoch 25] step 32/44: loss=-0.5079 
[epoch 25] step 34/44: loss=-0.5089 
[epoch 25] step 36/44: loss=-0.5100 
[epoch 25] step 38/44: loss=-0.5102 
[epoch 25] step 40/44: loss=-0.5107 
[epoch 25] step 42/44: loss=-0.5116 
[epoch 25] step 44/44: loss=-0.5124 
[epoch 25] train_loss(avg per step)=-1.0249 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=6.3689 qwk=('0.1897', '0.2870', '0.3224') averageQWK=0.2663 macroEMD=0.2762 tailR0=('0.0078', '0.0167', '0.0000') tailR0avg=0.0082
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    6    8    1    0
     0    6   52   18    2
     0    3   86   70    3
     0    4   34   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    6    3    0
     0   11   29   25    1
     0   11   90   98    6
     0    2   10   17    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     2    9   18    0    0
     0    8   98    5    0
     0    3  134   44    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=-0.5430 
[epoch 26] step 4/44: loss=-0.5276 
[epoch 26] step 6/44: loss=-0.5348 
[epoch 26] step 8/44: loss=-0.5402 
[epoch 26] step 10/44: loss=-0.5415 
[epoch 26] step 12/44: loss=-0.5441 
[epoch 26] step 14/44: loss=-0.5401 
[epoch 26] step 16/44: loss=-0.5403 
[epoch 26] step 18/44: loss=-0.5385 
[epoch 26] step 20/44: loss=-0.5404 
[epoch 26] step 22/44: loss=-0.5411 
[epoch 26] step 24/44: loss=-0.5447 
[epoch 26] step 26/44: loss=-0.5433 
[epoch 26] step 28/44: loss=-0.5436 
[epoch 26] step 30/44: loss=-0.5443 
[epoch 26] step 32/44: loss=-0.5451 
[epoch 26] step 34/44: loss=-0.5461 
[epoch 26] step 36/44: loss=-0.5432 
[epoch 26] step 38/44: loss=-0.5435 
[epoch 26] step 40/44: loss=-0.5436 
[epoch 26] step 42/44: loss=-0.5392 
[epoch 26] step 44/44: loss=-0.5398 
[epoch 26] train_loss(avg per step)=-1.0796 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=6.6904 qwk=('0.2125', '0.2543', '0.3285') averageQWK=0.2651 macroEMD=0.2711 tailR0=('0.1328', '0.0000', '0.0000') tailR0avg=0.0443
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0    5    8    2    0
     0    7   49   20    2
     0    1   85   73    3
     0    3   34   26    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7    6    3    0
     0   12   32   22    0
     0    9  111   85    0
     0    2   13   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     2    7   20    0    0
     0    6  100    5    0
     0    2  130   49    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=-0.5238 
[epoch 27] step 4/44: loss=-0.5403 
[epoch 27] step 6/44: loss=-0.5419 
[epoch 27] step 8/44: loss=-0.5343 
[epoch 27] step 10/44: loss=-0.5367 
[epoch 27] step 12/44: loss=-0.5395 
[epoch 27] step 14/44: loss=-0.5420 
[epoch 27] step 16/44: loss=-0.5332 
[epoch 27] step 18/44: loss=-0.5203 
[epoch 27] step 20/44: loss=-0.5170 
[epoch 27] step 22/44: loss=-0.5187 
[epoch 27] step 24/44: loss=-0.5225 
[epoch 27] step 26/44: loss=-0.5261 
[epoch 27] step 28/44: loss=-0.5301 
[epoch 27] step 30/44: loss=-0.5304 
[epoch 27] step 32/44: loss=-0.5318 
[epoch 27] step 34/44: loss=-0.5332 
[epoch 27] step 36/44: loss=-0.5325 
[epoch 27] step 38/44: loss=-0.5340 
[epoch 27] step 40/44: loss=-0.5341 
[epoch 27] step 42/44: loss=-0.5357 
[epoch 27] step 44/44: loss=-0.5358 
[epoch 27] train_loss(avg per step)=-1.0716 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=7.7883 qwk=('0.1992', '0.2175', '0.2920') averageQWK=0.2362 macroEMD=0.2712 tailR0=('0.1328', '0.0833', '0.0000') tailR0avg=0.0720
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     0    6    8    1    0
     0    8   50   18    2
     0    4   89   67    2
     0    4   34   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0    4   10    2    0
     0    8   41   16    1
     0    6  127   70    2
     0    2   15   13    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1   10   18    0    0
     0   12   95    4    0
     0    4  140   37    0
     0    0    0    1    0
[epoch 28] step 2/44: loss=-0.5767 
[epoch 28] step 4/44: loss=-0.5696 
[epoch 28] step 6/44: loss=-0.5623 
[epoch 28] step 8/44: loss=-0.5542 
[epoch 28] step 10/44: loss=-0.5476 
[epoch 28] step 12/44: loss=-0.5541 
[epoch 28] step 14/44: loss=-0.5581 
[epoch 28] step 16/44: loss=-0.5568 
[epoch 28] step 18/44: loss=-0.5581 
[epoch 28] step 20/44: loss=-0.5583 
[epoch 28] step 22/44: loss=-0.5582 
[epoch 28] step 24/44: loss=-0.5594 
[epoch 28] step 26/44: loss=-0.5611 
[epoch 28] step 28/44: loss=-0.5615 
[epoch 28] step 30/44: loss=-0.5613 
[epoch 28] step 32/44: loss=-0.5590 
[epoch 28] step 34/44: loss=-0.5578 
[epoch 28] step 36/44: loss=-0.5562 
[epoch 28] step 38/44: loss=-0.5570 
[epoch 28] step 40/44: loss=-0.5552 
[epoch 28] step 42/44: loss=-0.5545 
[epoch 28] step 44/44: loss=-0.5536 
[epoch 28] train_loss(avg per step)=-1.1072 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=6.6805 qwk=('0.1812', '0.2336', '0.3194') averageQWK=0.2447 macroEMD=0.2777 tailR0=('0.0156', '0.0000', '0.0000') tailR0avg=0.0052
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4   10    1    0
     0    7   48   21    2
     0    3   84   70    5
     0    3   35   24    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    5    9    2    0
     0    6   38   21    1
     0    6  115   83    1
     0    1   12   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1    6   22    0    0
     0    4   97   10    0
     0    2  121   58    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=-0.5689 
[epoch 29] step 4/44: loss=-0.5554 
[epoch 29] step 6/44: loss=-0.5649 
[epoch 29] step 8/44: loss=-0.5577 
[epoch 29] step 10/44: loss=-0.5593 
[epoch 29] step 12/44: loss=-0.5622 
[epoch 29] step 14/44: loss=-0.5624 
[epoch 29] step 16/44: loss=-0.5651 
[epoch 29] step 18/44: loss=-0.5658 
[epoch 29] step 20/44: loss=-0.5659 
[epoch 29] step 22/44: loss=-0.5658 
[epoch 29] step 24/44: loss=-0.5645 
[epoch 29] step 26/44: loss=-0.5646 
[epoch 29] step 28/44: loss=-0.5649 
[epoch 29] step 30/44: loss=-0.5661 
[epoch 29] step 32/44: loss=-0.5659 
[epoch 29] step 34/44: loss=-0.5652 
[epoch 29] step 36/44: loss=-0.5593 
[epoch 29] step 38/44: loss=-0.5592 
[epoch 29] step 40/44: loss=-0.5582 
[epoch 29] step 42/44: loss=-0.5587 
[epoch 29] step 44/44: loss=-0.5591 
[epoch 29] train_loss(avg per step)=-1.1183 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=7.9341 qwk=('0.2236', '0.2362', '0.3361') averageQWK=0.2653 macroEMD=0.2703 tailR0=('0.1328', '0.0167', '0.0000') tailR0avg=0.0498
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    2    1    0    0
     0    5    9    1    0
     0    8   51   17    2
     0    4   90   66    2
     0    3   33   27    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    7    7    2    0
     0   11   44   10    1
     0    9  131   63    2
     0    1   18   10    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1   10   18    0    0
     0    8   96    7    0
     0    3  127   51    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=-0.5855 
[epoch 30] step 4/44: loss=-0.5803 
[epoch 30] step 6/44: loss=-0.5699 
[epoch 30] step 8/44: loss=-0.5698 
[epoch 30] step 10/44: loss=-0.5738 
[epoch 30] step 12/44: loss=-0.5736 
[epoch 30] step 14/44: loss=-0.5719 
[epoch 30] step 16/44: loss=-0.5723 
[epoch 30] step 18/44: loss=-0.5722 
[epoch 30] step 20/44: loss=-0.5713 
[epoch 30] step 22/44: loss=-0.5699 
[epoch 30] step 24/44: loss=-0.5704 
[epoch 30] step 26/44: loss=-0.5720 
[epoch 30] step 28/44: loss=-0.5714 
[epoch 30] step 30/44: loss=-0.5700 
[epoch 30] step 32/44: loss=-0.5707 
[epoch 30] step 34/44: loss=-0.5719 
[epoch 30] step 36/44: loss=-0.5714 
[epoch 30] step 38/44: loss=-0.5707 
[epoch 30] step 40/44: loss=-0.5706 
[epoch 30] step 42/44: loss=-0.5707 
[epoch 30] step 44/44: loss=-0.5708 
[epoch 30] train_loss(avg per step)=-1.1417 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=7.1235 qwk=('0.1961', '0.2417', '0.3340') averageQWK=0.2573 macroEMD=0.2719 tailR0=('0.0078', '0.0167', '0.0000') tailR0avg=0.0082
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    6    7    2    0
     0    7   49   21    1
     0    4   80   77    1
     0    4   32   27    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    7    7    2    0
     0    9   39   17    1
     0    8  122   72    3
     0    1   14   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     1    7   21    0    0
     0    6   98    7    0
     0    2  123   56    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=-0.5900 
[epoch 31] step 4/44: loss=-0.5742 
[epoch 31] step 6/44: loss=-0.5737 
[epoch 31] step 8/44: loss=-0.5772 
[epoch 31] step 10/44: loss=-0.5748 
[epoch 31] step 12/44: loss=-0.5725 
[epoch 31] step 14/44: loss=-0.5746 
[epoch 31] step 16/44: loss=-0.5732 
[epoch 31] step 18/44: loss=-0.5739 
[epoch 31] step 20/44: loss=-0.5743 
[epoch 31] step 22/44: loss=-0.5730 
[epoch 31] step 24/44: loss=-0.5729 
[epoch 31] step 26/44: loss=-0.5742 
[epoch 31] step 28/44: loss=-0.5749 
[epoch 31] step 30/44: loss=-0.5733 
[epoch 31] step 32/44: loss=-0.5744 
[epoch 31] step 34/44: loss=-0.5713 
[epoch 31] step 36/44: loss=-0.5700 
[epoch 31] step 38/44: loss=-0.5710 
[epoch 31] step 40/44: loss=-0.5716 
[epoch 31] step 42/44: loss=-0.5720 
[epoch 31] step 44/44: loss=-0.5731 
[epoch 31] train_loss(avg per step)=-1.1461 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=7.7267 qwk=('0.1959', '0.2506', '0.3370') averageQWK=0.2612 macroEMD=0.2716 tailR0=('0.1328', '0.0000', '0.0000') tailR0avg=0.0443
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     0    4   10    1    0
     0    7   53   17    1
     0    5   84   72    1
     0    4   34   25    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    6    8    2    0
     0   12   33   21    0
     0    8  108   89    0
     0    2   12   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   11   18    0    0
     0    8   99    4    0
     0    3  128   50    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=-0.5880 
[epoch 32] step 4/44: loss=-0.5883 
[epoch 32] step 6/44: loss=-0.5830 
[epoch 32] step 8/44: loss=-0.5847 
[epoch 32] step 10/44: loss=-0.5870 
[epoch 32] step 12/44: loss=-0.5866 
[epoch 32] step 14/44: loss=-0.5858 
[epoch 32] step 16/44: loss=-0.5853 
[epoch 32] step 18/44: loss=-0.5838 
[epoch 32] step 20/44: loss=-0.5820 
[epoch 32] step 22/44: loss=-0.5819 
[epoch 32] step 24/44: loss=-0.5815 
[epoch 32] step 26/44: loss=-0.5826 
[epoch 32] step 28/44: loss=-0.5812 
[epoch 32] step 30/44: loss=-0.5820 
[epoch 32] step 32/44: loss=-0.5820 
[epoch 32] step 34/44: loss=-0.5824 
[epoch 32] step 36/44: loss=-0.5823 
[epoch 32] step 38/44: loss=-0.5827 
[epoch 32] step 40/44: loss=-0.5823 
[epoch 32] step 42/44: loss=-0.5827 
[epoch 32] step 44/44: loss=-0.5812 
[epoch 32] train_loss(avg per step)=-1.1623 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=7.2170 qwk=('0.2084', '0.2061', '0.3317') averageQWK=0.2487 macroEMD=0.2740 tailR0=('0.1328', '0.0000', '0.0000') tailR0avg=0.0443
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     0    6    6    3    0
     0    8   39   29    2
     0    4   62   95    1
     0    4   28   31    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    6    8    2    0
     0    6   41   18    1
     0    4  128   69    4
     0    1   15   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     2    7   20    0    0
     0    5  100    6    0
     0    2  128   51    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=-0.5836 
[epoch 33] step 4/44: loss=-0.5849 
[epoch 33] step 6/44: loss=-0.5864 
[epoch 33] step 8/44: loss=-0.5888 
[epoch 33] step 10/44: loss=-0.5887 
[epoch 33] step 12/44: loss=-0.5870 
[epoch 33] step 14/44: loss=-0.5877 
[epoch 33] step 16/44: loss=-0.5849 
[epoch 33] step 18/44: loss=-0.5854 
[epoch 33] step 20/44: loss=-0.5860 
[epoch 33] step 22/44: loss=-0.5855 
[epoch 33] step 24/44: loss=-0.5860 
[epoch 33] step 26/44: loss=-0.5865 
[epoch 33] step 28/44: loss=-0.5855 
[epoch 33] step 30/44: loss=-0.5851 
[epoch 33] step 32/44: loss=-0.5860 
[epoch 33] step 34/44: loss=-0.5864 
[epoch 33] step 36/44: loss=-0.5862 
[epoch 33] step 38/44: loss=-0.5867 
[epoch 33] step 40/44: loss=-0.5868 
[epoch 33] step 42/44: loss=-0.5863 
[epoch 33] step 44/44: loss=-0.5860 
[epoch 33] train_loss(avg per step)=-1.1720 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=7.2364 qwk=('0.1989', '0.2640', '0.3492') averageQWK=0.2707 macroEMD=0.2704 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    7    6    2    0
     0    6   44   28    0
     0    3   70   89    0
     0    4   31   29    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    6    8    2    0
     0    8   37   21    0
     0    4  108   93    0
     0    1   12   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    9   20    0    0
     0    6   97    8    0
     0    2  119   60    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=-0.5936 
[epoch 34] step 4/44: loss=-0.5853 
[epoch 34] step 6/44: loss=-0.5786 
[epoch 34] step 8/44: loss=-0.5813 
[epoch 34] step 10/44: loss=-0.5823 
[epoch 34] step 12/44: loss=-0.5844 
[epoch 34] step 14/44: loss=-0.5843 
[epoch 34] step 16/44: loss=-0.5849 
[epoch 34] step 18/44: loss=-0.5860 
[epoch 34] step 20/44: loss=-0.5861 
[epoch 34] step 22/44: loss=-0.5859 
[epoch 34] step 24/44: loss=-0.5856 
[epoch 34] step 26/44: loss=-0.5862 
[epoch 34] step 28/44: loss=-0.5852 
[epoch 34] step 30/44: loss=-0.5846 
[epoch 34] step 32/44: loss=-0.5852 
[epoch 34] step 34/44: loss=-0.5858 
[epoch 34] step 36/44: loss=-0.5864 
[epoch 34] step 38/44: loss=-0.5866 
[epoch 34] step 40/44: loss=-0.5864 
[epoch 34] step 42/44: loss=-0.5861 
[epoch 34] step 44/44: loss=-0.5864 
[epoch 34] train_loss(avg per step)=-1.1729 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=8.3212 qwk=('0.1950', '0.2312', '0.3020') averageQWK=0.2427 macroEMD=0.2717 tailR0=('0.1328', '0.0000', '0.0000') tailR0avg=0.0443
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    2    0    0
     0    4   10    1    0
     0    6   47   23    2
     0    3   78   80    1
     0    3   33   27    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    6    8    2    0
     0    7   40   19    0
     0    4  129   72    0
     0    1   12   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    9   20    0    0
     0    8   98    5    0
     0    2  134   45    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=-0.5997 
[epoch 35] step 4/44: loss=-0.5972 
[epoch 35] step 6/44: loss=-0.5931 
[epoch 35] step 8/44: loss=-0.5926 
[epoch 35] step 10/44: loss=-0.5923 
[epoch 35] step 12/44: loss=-0.5931 
[epoch 35] step 14/44: loss=-0.5933 
[epoch 35] step 16/44: loss=-0.5921 
[epoch 35] step 18/44: loss=-0.5925 
[epoch 35] step 20/44: loss=-0.5907 
[epoch 35] step 22/44: loss=-0.5905 
[epoch 35] step 24/44: loss=-0.5907 
[epoch 35] step 26/44: loss=-0.5894 
[epoch 35] step 28/44: loss=-0.5890 
[epoch 35] step 30/44: loss=-0.5894 
[epoch 35] step 32/44: loss=-0.5892 
[epoch 35] step 34/44: loss=-0.5895 
[epoch 35] step 36/44: loss=-0.5901 
[epoch 35] step 38/44: loss=-0.5900 
[epoch 35] step 40/44: loss=-0.5903 
[epoch 35] step 42/44: loss=-0.5904 
[epoch 35] step 44/44: loss=-0.5904 
[epoch 35] train_loss(avg per step)=-1.1807 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=8.2632 qwk=('0.1976', '0.2435', '0.3203') averageQWK=0.2538 macroEMD=0.2696 tailR0=('0.0078', '0.0000', '0.0000') tailR0avg=0.0026
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    4   10    1    0
     0    6   49   23    0
     0    2   83   76    1
     0    3   33   27    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    4    0    0
     0    6    8    2    0
     0    7   39   20    0
     0    4  120   81    0
     0    1   12   17    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0   10   19    0    0
     0    9   97    5    0
     0    2  132   47    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-0-conf_gating-0-reassignment-0/fold0/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-0-conf_gating-0-reassignment-0/fold0/metrics.json
Done.
