[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=7.1611 
[epoch 1] step 4/44: loss=6.7904 
[epoch 1] step 6/44: loss=6.6987 
[epoch 1] step 8/44: loss=6.5473 
[epoch 1] step 10/44: loss=6.5757 
[epoch 1] step 12/44: loss=6.6055 
[epoch 1] step 14/44: loss=6.5992 
[epoch 1] step 16/44: loss=6.5720 
[epoch 1] step 18/44: loss=6.5004 
[epoch 1] step 20/44: loss=6.4586 
[epoch 1] step 22/44: loss=6.4416 
[epoch 1] step 24/44: loss=6.4033 
[epoch 1] step 26/44: loss=6.3777 
[epoch 1] step 28/44: loss=6.3427 
[epoch 1] step 30/44: loss=6.2940 
[epoch 1] step 32/44: loss=6.2565 
[epoch 1] step 34/44: loss=6.2165 
[epoch 1] step 36/44: loss=6.1144 
[epoch 1] step 38/44: loss=6.0201 
[epoch 1] step 40/44: loss=5.9235 
[epoch 1] step 42/44: loss=5.8146 
[epoch 1] step 44/44: loss=5.7389 
[epoch 1] train_loss(avg per step)=11.4777 lambda[min,max]=[0.504040,1.000000]
[epoch 1] val_loss=5.7570 qwk=('0.2057', '0.2413', '0.0073') averageQWK=0.1514 macroEMD=0.3703 tailR0=('0.0000', '0.1667', '0.0000') tailR0avg=0.0556
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    9    0    6    0
     0   47    0   35    0
     0   67    0   88    0
     0   26    0   47    0
     0    0    0   10    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    0    4    2    0
    32    0   27   17    0
    33    0   95   36    0
    14    0   27   39    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    2   89    1    0
     0    3  163    0    0
     0    0   72    0    0
     0    0    1    0    0
[epoch 2] step 2/44: loss=3.1771 
[epoch 2] step 4/44: loss=3.2471 
[epoch 2] step 6/44: loss=3.0956 
[epoch 2] step 8/44: loss=3.0163 
[epoch 2] step 10/44: loss=2.9125 
[epoch 2] step 12/44: loss=2.9194 
[epoch 2] step 14/44: loss=2.8739 
[epoch 2] step 16/44: loss=2.8559 
[epoch 2] step 18/44: loss=2.8455 
[epoch 2] step 20/44: loss=2.7996 
[epoch 2] step 22/44: loss=2.7956 
[epoch 2] step 24/44: loss=2.7576 
[epoch 2] step 26/44: loss=2.7395 
[epoch 2] step 28/44: loss=2.7076 
[epoch 2] step 30/44: loss=2.6826 
[epoch 2] step 32/44: loss=2.6596 
[epoch 2] step 34/44: loss=2.6377 
[epoch 2] step 36/44: loss=2.6146 
[epoch 2] step 38/44: loss=2.5897 
[epoch 2] step 40/44: loss=2.5673 
[epoch 2] step 42/44: loss=2.5559 
[epoch 2] step 44/44: loss=2.5313 
[epoch 2] train_loss(avg per step)=5.0626 lambda[min,max]=[0.502399,1.000000]
[epoch 2] val_loss=3.6044 qwk=('0.0501', '0.2379', '0.1010') averageQWK=0.1297 macroEMD=0.3752 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    1   12    0
     0    5    1   76    0
     0    3    1  151    0
     0    0    0   73    0
     0    1    0    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    0   43   33    0
     0    0   52  112    0
     0    0    3   77    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    3    1    0
     0    0   27   65    0
     0    0   27  139    0
     0    0    3   69    0
     0    0    0    1    0
[epoch 3] step 2/44: loss=2.1122 
[epoch 3] step 4/44: loss=2.0401 
[epoch 3] step 6/44: loss=2.0905 
[epoch 3] step 8/44: loss=2.0895 
[epoch 3] step 10/44: loss=2.0376 
[epoch 3] step 12/44: loss=2.0249 
[epoch 3] step 14/44: loss=1.9804 
[epoch 3] step 16/44: loss=1.9719 
[epoch 3] step 18/44: loss=1.9865 
[epoch 3] step 20/44: loss=1.9884 
[epoch 3] step 22/44: loss=1.9819 
[epoch 3] step 24/44: loss=1.9730 
[epoch 3] step 26/44: loss=1.9440 
[epoch 3] step 28/44: loss=1.9569 
[epoch 3] step 30/44: loss=1.9515 
[epoch 3] step 32/44: loss=1.9504 
[epoch 3] step 34/44: loss=1.9254 
[epoch 3] step 36/44: loss=1.9109 
[epoch 3] step 38/44: loss=1.8919 
[epoch 3] step 40/44: loss=1.8953 
[epoch 3] step 42/44: loss=1.8729 
[epoch 3] step 44/44: loss=1.8433 
[epoch 3] train_loss(avg per step)=3.6865 lambda[min,max]=[0.501000,1.000000]
[epoch 3] val_loss=3.2975 qwk=('0.3906', '0.2354', '0.3359') averageQWK=0.3207 macroEMD=0.3535 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3   10    2    0
     0   16   54   12    0
     0    7   87   61    0
     0    0   12   61    0
     0    1    2    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    0   44   32    0
     0    0   53  111    0
     0    0    5   75    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    3   73   16    0
     0    0  116   50    0
     0    0   15   57    0
     0    0    0    1    0
[epoch 4] step 2/44: loss=1.4061 
[epoch 4] step 4/44: loss=1.6022 
[epoch 4] step 6/44: loss=1.5830 
[epoch 4] step 8/44: loss=1.5865 
[epoch 4] step 10/44: loss=1.6065 
[epoch 4] step 12/44: loss=1.6650 
[epoch 4] step 14/44: loss=1.6627 
[epoch 4] step 16/44: loss=1.6533 
[epoch 4] step 18/44: loss=1.6883 
[epoch 4] step 20/44: loss=1.7011 
[epoch 4] step 22/44: loss=1.7062 
[epoch 4] step 24/44: loss=1.6900 
[epoch 4] step 26/44: loss=1.6901 
[epoch 4] step 28/44: loss=1.6652 
[epoch 4] step 30/44: loss=1.6479 
[epoch 4] step 32/44: loss=1.6403 
[epoch 4] step 34/44: loss=1.6344 
[epoch 4] step 36/44: loss=1.6320 
[epoch 4] step 38/44: loss=1.6238 
[epoch 4] step 40/44: loss=1.6196 
[epoch 4] step 42/44: loss=1.6083 
[epoch 4] step 44/44: loss=1.5817 
[epoch 4] train_loss(avg per step)=3.1634 lambda[min,max]=[0.501745,1.000000]
[epoch 4] val_loss=2.8950 qwk=('0.3274', '0.3037', '0.4564') averageQWK=0.3625 macroEMD=0.3562 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3   11    1    0
     0    9   73    0    0
     0    4  141   10    0
     0    0   37   36    0
     0    0    9    1    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    4    4    0
     0   11   37   28    0
     0    3   67   94    0
     0    0    3   77    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   20   71    1    0
     0   14  139   13    0
     0    0   40   32    0
     0    0    0    1    0
[epoch 5] step 2/44: loss=1.2551 
[epoch 5] step 4/44: loss=1.3546 
[epoch 5] step 6/44: loss=1.3500 
[epoch 5] step 8/44: loss=1.3817 
[epoch 5] step 10/44: loss=1.3719 
[epoch 5] step 12/44: loss=1.3794 
[epoch 5] step 14/44: loss=1.3620 
[epoch 5] step 16/44: loss=1.3487 
[epoch 5] step 18/44: loss=1.3494 
[epoch 5] step 20/44: loss=1.3148 
[epoch 5] step 22/44: loss=1.3225 
[epoch 5] step 24/44: loss=1.3270 
[epoch 5] step 26/44: loss=1.3218 
[epoch 5] step 28/44: loss=1.3196 
[epoch 5] step 30/44: loss=1.3077 
[epoch 5] step 32/44: loss=1.2921 
[epoch 5] step 34/44: loss=1.2692 
[epoch 5] step 36/44: loss=1.2741 
[epoch 5] step 38/44: loss=1.2748 
[epoch 5] step 40/44: loss=1.2599 
[epoch 5] step 42/44: loss=1.2485 
[epoch 5] step 44/44: loss=1.2127 
[epoch 5] train_loss(avg per step)=2.4255 lambda[min,max]=[0.506337,1.000000]
[epoch 5] val_loss=3.6993 qwk=('0.3603', '0.2568', '0.2560') averageQWK=0.2911 macroEMD=0.3407 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3   10    2    0
     0    7   56   19    0
     0    0   71   84    0
     0    0    7   66    0
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    1   44   31    0
     0    0   47  117    0
     0    0    1   79    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    2   57   33    0
     0    0   80   86    0
     0    0    6   66    0
     0    0    0    1    0
[epoch 6] step 2/44: loss=1.0078 
[epoch 6] step 4/44: loss=1.0212 
[epoch 6] step 6/44: loss=1.0665 
[epoch 6] step 8/44: loss=1.1214 
[epoch 6] step 10/44: loss=1.1070 
[epoch 6] step 12/44: loss=1.1157 
[epoch 6] step 14/44: loss=1.0874 
[epoch 6] step 16/44: loss=1.0873 
[epoch 6] step 18/44: loss=1.0817 
[epoch 6] step 20/44: loss=1.1035 
[epoch 6] step 22/44: loss=1.1020 
[epoch 6] step 24/44: loss=1.0878 
[epoch 6] step 26/44: loss=1.0780 
[epoch 6] step 28/44: loss=1.0729 
[epoch 6] step 30/44: loss=1.0715 
[epoch 6] step 32/44: loss=1.0673 
[epoch 6] step 34/44: loss=1.0581 
[epoch 6] step 36/44: loss=1.0681 
[epoch 6] step 38/44: loss=1.0690 
[epoch 6] step 40/44: loss=1.0657 
[epoch 6] step 42/44: loss=1.0678 
[epoch 6] step 44/44: loss=1.0488 
[epoch 6] train_loss(avg per step)=2.0975 lambda[min,max]=[0.502411,1.000000]
[epoch 6] val_loss=3.5529 qwk=('0.3244', '0.3171', '0.3263') averageQWK=0.3226 macroEMD=0.3397 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    3    0
     0    6   55   21    0
     0    0   60   95    0
     0    0    7   66    0
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    1   53   22    0
     0    0   60  104    0
     0    0    2   78    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    1   85    6    0
     0    0  144   22    0
     0    0   31   41    0
     0    0    0    1    0
[epoch 7] step 2/44: loss=0.9429 
[epoch 7] step 4/44: loss=0.8943 
[epoch 7] step 6/44: loss=0.9794 
[epoch 7] step 8/44: loss=0.9587 
[epoch 7] step 10/44: loss=0.9659 
[epoch 7] step 12/44: loss=0.9835 
[epoch 7] step 14/44: loss=0.9861 
[epoch 7] step 16/44: loss=0.9549 
[epoch 7] step 18/44: loss=0.9474 
[epoch 7] step 20/44: loss=0.9594 
[epoch 7] step 22/44: loss=0.9558 
[epoch 7] step 24/44: loss=0.9544 
[epoch 7] step 26/44: loss=0.9723 
[epoch 7] step 28/44: loss=0.9834 
[epoch 7] step 30/44: loss=0.9909 
[epoch 7] step 32/44: loss=0.9885 
[epoch 7] step 34/44: loss=0.9939 
[epoch 7] step 36/44: loss=0.9776 
[epoch 7] step 38/44: loss=0.9773 
[epoch 7] step 40/44: loss=0.9766 
[epoch 7] step 42/44: loss=0.9683 
[epoch 7] step 44/44: loss=0.9510 
[epoch 7] train_loss(avg per step)=1.9020 lambda[min,max]=[0.506891,1.000000]
[epoch 7] val_loss=4.0616 qwk=('0.2883', '0.3575', '0.3168') averageQWK=0.3209 macroEMD=0.3261 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    2    0
     0    1   56   25    0
     0    0   56   99    0
     0    0    5   68    0
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    0   61   15    0
     0    0   91   73    0
     0    0    7   73    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    0   83    9    0
     0    0  137   29    0
     0    0   27   45    0
     0    0    0    1    0
[epoch 8] step 2/44: loss=1.0290 
[epoch 8] step 4/44: loss=0.9447 
[epoch 8] step 6/44: loss=0.8590 
[epoch 8] step 8/44: loss=0.8514 
[epoch 8] step 10/44: loss=0.9067 
[epoch 8] step 12/44: loss=0.9059 
[epoch 8] step 14/44: loss=0.9103 
[epoch 8] step 16/44: loss=0.9046 
[epoch 8] step 18/44: loss=0.8708 
[epoch 8] step 20/44: loss=0.8608 
[epoch 8] step 22/44: loss=0.8765 
[epoch 8] step 24/44: loss=0.9001 
[epoch 8] step 26/44: loss=0.8786 
[epoch 8] step 28/44: loss=0.8690 
[epoch 8] step 30/44: loss=0.8713 
[epoch 8] step 32/44: loss=0.8750 
[epoch 8] step 34/44: loss=0.8749 
[epoch 8] step 36/44: loss=0.8731 
[epoch 8] step 38/44: loss=0.8705 
[epoch 8] step 40/44: loss=0.8664 
[epoch 8] step 42/44: loss=0.8630 
[epoch 8] step 44/44: loss=0.8713 
[epoch 8] train_loss(avg per step)=1.7427 lambda[min,max]=[0.506095,1.000000]
[epoch 8] val_loss=2.8431 qwk=('0.4063', '0.4355', '0.3790') averageQWK=0.4069 macroEMD=0.3213 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3   11    1    0
     0    8   65    9    0
     0    1  104   50    0
     0    0   14   59    0
     0    0    3    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    1   69    6    0
     0    0  131   33    0
     0    0   15   62    3
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    0    0    0
     0   19   57   16    0
     0   19   99   48    0
     0    5   12   55    0
     0    0    0    1    0
[epoch 9] step 2/44: loss=0.7727 
[epoch 9] step 4/44: loss=0.7484 
[epoch 9] step 6/44: loss=0.7345 
[epoch 9] step 8/44: loss=0.7107 
[epoch 9] step 10/44: loss=0.6657 
[epoch 9] step 12/44: loss=0.6778 
[epoch 9] step 14/44: loss=0.6685 
[epoch 9] step 16/44: loss=0.6359 
[epoch 9] step 18/44: loss=0.6460 
[epoch 9] step 20/44: loss=0.6423 
[epoch 9] step 22/44: loss=0.6504 
[epoch 9] step 24/44: loss=0.6517 
[epoch 9] step 26/44: loss=0.6589 
[epoch 9] step 28/44: loss=0.6661 
[epoch 9] step 30/44: loss=0.6684 
[epoch 9] step 32/44: loss=0.6771 
[epoch 9] step 34/44: loss=0.6794 
[epoch 9] step 36/44: loss=0.6912 
[epoch 9] step 38/44: loss=0.7110 
[epoch 9] step 40/44: loss=0.7087 
[epoch 9] step 42/44: loss=0.7123 
[epoch 9] step 44/44: loss=0.6953 
[epoch 9] train_loss(avg per step)=1.3905 lambda[min,max]=[0.502215,1.000000]
[epoch 9] val_loss=2.8842 qwk=('0.4066', '0.4044', '0.2429') averageQWK=0.3513 macroEMD=0.3137 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   14   58   10    0
     0    2  105   48    0
     0    0   18   55    0
     0    0    5    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     2    5   57   12    0
     0    7  111   46    0
     0    0   13   67    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    4   87    1    0
     0    0  158    8    0
     0    0   54   18    0
     0    0    0    1    0
[epoch 10] step 2/44: loss=0.6417 
[epoch 10] step 4/44: loss=0.6080 
[epoch 10] step 6/44: loss=0.6245 
[epoch 10] step 8/44: loss=0.6089 
[epoch 10] step 10/44: loss=0.6155 
[epoch 10] step 12/44: loss=0.6129 
[epoch 10] step 14/44: loss=0.6288 
[epoch 10] step 16/44: loss=0.6687 
[epoch 10] step 18/44: loss=0.6305 
[epoch 10] step 20/44: loss=0.6341 
[epoch 10] step 22/44: loss=0.6365 
[epoch 10] step 24/44: loss=0.6495 
[epoch 10] step 26/44: loss=0.6349 
[epoch 10] step 28/44: loss=0.6335 
[epoch 10] step 30/44: loss=0.6201 
[epoch 10] step 32/44: loss=0.6127 
[epoch 10] step 34/44: loss=0.6065 
[epoch 10] step 36/44: loss=0.6083 
[epoch 10] step 38/44: loss=0.6012 
[epoch 10] step 40/44: loss=0.6039 
[epoch 10] step 42/44: loss=0.6160 
[epoch 10] step 44/44: loss=0.6321 
[epoch 10] train_loss(avg per step)=1.2643 lambda[min,max]=[0.500804,1.000000]
[epoch 10] val_loss=3.2241 qwk=('0.4012', '0.4230', '0.3381') averageQWK=0.3874 macroEMD=0.3087 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3   11    1    0
     0   12   59   11    0
     0    3   94   58    0
     0    0   15   56    2
     0    0    3    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   15   44   17    0
     0   10   92   62    0
     0    0    8   71    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    5   73   14    0
     0    2  126   38    0
     0    0   20   52    0
     0    0    0    1    0
[epoch 11] step 2/44: loss=0.4863 
[epoch 11] step 4/44: loss=0.4739 
[epoch 11] step 6/44: loss=0.4665 
[epoch 11] step 8/44: loss=0.4619 
[epoch 11] step 10/44: loss=0.4861 
[epoch 11] step 12/44: loss=0.5071 
[epoch 11] step 14/44: loss=0.5270 
[epoch 11] step 16/44: loss=0.5087 
[epoch 11] step 18/44: loss=0.5016 
[epoch 11] step 20/44: loss=0.4861 
[epoch 11] step 22/44: loss=0.4724 
[epoch 11] step 24/44: loss=0.4840 
[epoch 11] step 26/44: loss=0.4823 
[epoch 11] step 28/44: loss=0.4896 
[epoch 11] step 30/44: loss=0.4864 
[epoch 11] step 32/44: loss=0.4897 
[epoch 11] step 34/44: loss=0.4910 
[epoch 11] step 36/44: loss=0.4924 
[epoch 11] step 38/44: loss=0.4894 
[epoch 11] step 40/44: loss=0.4877 
[epoch 11] step 42/44: loss=0.4804 
[epoch 11] step 44/44: loss=0.4664 
[epoch 11] train_loss(avg per step)=0.9329 lambda[min,max]=[0.501418,1.000000]
[epoch 11] val_loss=3.5273 qwk=('0.3984', '0.3925', '0.3426') averageQWK=0.3778 macroEMD=0.3070 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   12    1    0
     0    9   61   12    0
     0    2   93   60    0
     0    0   11   61    1
     0    0    2    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   17   38   21    0
     0   13   68   83    0
     0    1    3   76    0
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    4   74   14    0
     0    0  122   44    0
     0    0   18   54    0
     0    0    0    1    0
[epoch 12] step 2/44: loss=0.3341 
[epoch 12] step 4/44: loss=0.3791 
[epoch 12] step 6/44: loss=0.3972 
[epoch 12] step 8/44: loss=0.3810 
[epoch 12] step 10/44: loss=0.3591 
[epoch 12] step 12/44: loss=0.3503 
[epoch 12] step 14/44: loss=0.3459 
[epoch 12] step 16/44: loss=0.3421 
[epoch 12] step 18/44: loss=0.3353 
[epoch 12] step 20/44: loss=0.3425 
[epoch 12] step 22/44: loss=0.3338 
[epoch 12] step 24/44: loss=0.3280 
[epoch 12] step 26/44: loss=0.3424 
[epoch 12] step 28/44: loss=0.3428 
[epoch 12] step 30/44: loss=0.3338 
[epoch 12] step 32/44: loss=0.3285 
[epoch 12] step 34/44: loss=0.3290 
[epoch 12] step 36/44: loss=0.3265 
[epoch 12] step 38/44: loss=0.3301 
[epoch 12] step 40/44: loss=0.3343 
[epoch 12] step 42/44: loss=0.3293 
[epoch 12] step 44/44: loss=0.3201 
[epoch 12] train_loss(avg per step)=0.6403 lambda[min,max]=[0.500359,1.000000]
[epoch 12] val_loss=4.3308 qwk=('0.3722', '0.3612', '0.3416') averageQWK=0.3584 macroEMD=0.3080 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   12    1    0
     0    4   62   16    0
     0    1   68   86    0
     0    0    6   65    2
     0    0    1    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    3   55   18    0
     0    0   79   85    0
     0    0    5   74    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    5   68   19    0
     0    0  102   64    0
     0    0   12   60    0
     0    0    0    1    0
[epoch 13] step 2/44: loss=0.2207 
[epoch 13] step 4/44: loss=0.1054 
[epoch 13] step 6/44: loss=0.1315 
[epoch 13] step 8/44: loss=0.1250 
[epoch 13] step 10/44: loss=0.1119 
[epoch 13] step 12/44: loss=0.1270 
[epoch 13] step 14/44: loss=0.1388 
[epoch 13] step 16/44: loss=0.1430 
[epoch 13] step 18/44: loss=0.1600 
[epoch 13] step 20/44: loss=0.1731 
[epoch 13] step 22/44: loss=0.1837 
[epoch 13] step 24/44: loss=0.1935 
[epoch 13] step 26/44: loss=0.1936 
[epoch 13] step 28/44: loss=0.1946 
[epoch 13] step 30/44: loss=0.2122 
[epoch 13] step 32/44: loss=0.2063 
[epoch 13] step 34/44: loss=0.2090 
[epoch 13] step 36/44: loss=0.2083 
[epoch 13] step 38/44: loss=0.2100 
[epoch 13] step 40/44: loss=0.2112 
[epoch 13] step 42/44: loss=0.2188 
[epoch 13] step 44/44: loss=0.2338 
[epoch 13] train_loss(avg per step)=0.4676 lambda[min,max]=[0.500068,1.000000]
[epoch 13] val_loss=3.3682 qwk=('0.4599', '0.4325', '0.3064') averageQWK=0.3996 macroEMD=0.2989 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    6    1    0
     0   23   46   13    0
     0   10   82   62    1
     0    0   13   58    2
     0    0    3    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0   11   57    8    0
     0    8  101   55    0
     0    1   14   62    3
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    5   79    8    0
     0    1  145   20    0
     0    0   37   35    0
     0    0    0    1    0
[epoch 14] step 2/44: loss=0.1213 
[epoch 14] step 4/44: loss=0.1163 
[epoch 14] step 6/44: loss=0.1007 
[epoch 14] step 8/44: loss=0.1129 
[epoch 14] step 10/44: loss=0.1032 
[epoch 14] step 12/44: loss=0.1106 
[epoch 14] step 14/44: loss=0.1030 
[epoch 14] step 16/44: loss=0.0968 
[epoch 14] step 18/44: loss=0.0935 
[epoch 14] step 20/44: loss=0.0895 
[epoch 14] step 22/44: loss=0.0766 
[epoch 14] step 24/44: loss=0.0687 
[epoch 14] step 26/44: loss=0.0663 
[epoch 14] step 28/44: loss=0.0663 
[epoch 14] step 30/44: loss=0.0651 
[epoch 14] step 32/44: loss=0.0750 
[epoch 14] step 34/44: loss=0.0727 
[epoch 14] step 36/44: loss=0.0782 
[epoch 14] step 38/44: loss=0.0822 
[epoch 14] step 40/44: loss=0.0809 
[epoch 14] step 42/44: loss=0.0838 
[epoch 14] step 44/44: loss=0.1025 
[epoch 14] train_loss(avg per step)=0.2051 lambda[min,max]=[0.500123,1.000000]
[epoch 14] val_loss=3.3964 qwk=('0.4335', '0.3969', '0.3661') averageQWK=0.3988 macroEMD=0.2950 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    8    1    0
     0   16   55   11    0
     0    5   91   58    1
     0    0   12   56    5
     0    0    5    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    3   65    8    0
     0    1  115   48    0
     0    0   16   61    3
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6   79    7    0
     0    6  141   19    0
     0    0   33   39    0
     0    0    0    1    0
[epoch 15] step 2/44: loss=0.1325 
[epoch 15] step 4/44: loss=0.1467 
[epoch 15] step 6/44: loss=0.1305 
[epoch 15] step 8/44: loss=0.0893 
[epoch 15] step 10/44: loss=0.0710 
[epoch 15] step 12/44: loss=0.0600 
[epoch 15] step 14/44: loss=0.0452 
[epoch 15] step 16/44: loss=0.0408 
[epoch 15] step 18/44: loss=0.0472 
[epoch 15] step 20/44: loss=0.0305 
[epoch 15] step 22/44: loss=0.0332 
[epoch 15] step 24/44: loss=0.0273 
[epoch 15] step 26/44: loss=0.0270 
[epoch 15] step 28/44: loss=0.0312 
[epoch 15] step 30/44: loss=0.0265 
[epoch 15] step 32/44: loss=0.0214 
[epoch 15] step 34/44: loss=0.0170 
[epoch 15] step 36/44: loss=0.0121 
[epoch 15] step 38/44: loss=0.0062 
[epoch 15] step 40/44: loss=0.0023 
[epoch 15] step 42/44: loss=0.0035 
[epoch 15] step 44/44: loss=-0.0119 
[epoch 15] train_loss(avg per step)=-0.0239 lambda[min,max]=[0.500199,1.000000]
[epoch 15] val_loss=3.8388 qwk=('0.4350', '0.4068', '0.3443') averageQWK=0.3954 macroEMD=0.2916 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   16   57    9    0
     0    5  101   48    1
     0    0   16   54    3
     0    0    3    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    1    0
     0    7   61    8    0
     0    2  113   49    0
     0    0   19   59    2
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    6   74   12    0
     0    1  130   35    0
     0    0   23   49    0
     0    0    0    1    0
[epoch 16] step 2/44: loss=-0.2141 
[epoch 16] step 4/44: loss=-0.1569 
[epoch 16] step 6/44: loss=-0.1443 
[epoch 16] step 8/44: loss=-0.1480 
[epoch 16] step 10/44: loss=-0.1385 
[epoch 16] step 12/44: loss=-0.1388 
[epoch 16] step 14/44: loss=-0.1357 
[epoch 16] step 16/44: loss=-0.1211 
[epoch 16] step 18/44: loss=-0.1135 
[epoch 16] step 20/44: loss=-0.1160 
[epoch 16] step 22/44: loss=-0.1131 
[epoch 16] step 24/44: loss=-0.1183 
[epoch 16] step 26/44: loss=-0.1146 
[epoch 16] step 28/44: loss=-0.1123 
[epoch 16] step 30/44: loss=-0.1091 
[epoch 16] step 32/44: loss=-0.1131 
[epoch 16] step 34/44: loss=-0.1155 
[epoch 16] step 36/44: loss=-0.1151 
[epoch 16] step 38/44: loss=-0.1151 
[epoch 16] step 40/44: loss=-0.1166 
[epoch 16] step 42/44: loss=-0.1203 
[epoch 16] step 44/44: loss=-0.1206 
[epoch 16] train_loss(avg per step)=-0.2411 lambda[min,max]=[0.500017,1.000000]
[epoch 16] val_loss=4.5864 qwk=('0.4233', '0.3496', '0.3666') averageQWK=0.3798 macroEMD=0.2924 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    8    1    0
     0   16   50   16    0
     0    5   79   70    1
     0    0    8   63    2
     0    0    3    7    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    7    2    0
     0    6   52   18    0
     0    2   81   81    0
     0    0    7   71    2
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    6   74   12    0
     0    3  124   39    0
     0    0   20   52    0
     0    0    0    1    0
[epoch 17] step 2/44: loss=-0.1223 
[epoch 17] step 4/44: loss=-0.1409 
[epoch 17] step 6/44: loss=-0.1614 
[epoch 17] step 8/44: loss=-0.1544 
[epoch 17] step 10/44: loss=-0.1724 
[epoch 17] step 12/44: loss=-0.1734 
[epoch 17] step 14/44: loss=-0.1509 
[epoch 17] step 16/44: loss=-0.1452 
[epoch 17] step 18/44: loss=-0.1458 
[epoch 17] step 20/44: loss=-0.1587 
[epoch 17] step 22/44: loss=-0.1648 
[epoch 17] step 24/44: loss=-0.1701 
[epoch 17] step 26/44: loss=-0.1673 
[epoch 17] step 28/44: loss=-0.1743 
[epoch 17] step 30/44: loss=-0.1802 
[epoch 17] step 32/44: loss=-0.1891 
[epoch 17] step 34/44: loss=-0.1910 
[epoch 17] step 36/44: loss=-0.1926 
[epoch 17] step 38/44: loss=-0.1982 
[epoch 17] step 40/44: loss=-0.2029 
[epoch 17] step 42/44: loss=-0.2102 
[epoch 17] step 44/44: loss=-0.2207 
[epoch 17] train_loss(avg per step)=-0.4415 lambda[min,max]=[0.500005,1.000000]
[epoch 17] val_loss=4.6974 qwk=('0.4314', '0.3613', '0.3529') averageQWK=0.3819 macroEMD=0.2839 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   11    0    0
     0   13   62    6    1
     0    2  106   45    2
     0    0   19   45    9
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    3   62   11    0
     0    1  109   54    0
     0    0   17   62    1
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    6   76   10    0
     0    2  130   34    0
     0    0   26   46    0
     0    0    0    1    0
[epoch 18] step 2/44: loss=-0.3168 
[epoch 18] step 4/44: loss=-0.2962 
[epoch 18] step 6/44: loss=-0.2890 
[epoch 18] step 8/44: loss=-0.2794 
[epoch 18] step 10/44: loss=-0.2776 
[epoch 18] step 12/44: loss=-0.2799 
[epoch 18] step 14/44: loss=-0.2831 
[epoch 18] step 16/44: loss=-0.2833 
[epoch 18] step 18/44: loss=-0.2852 
[epoch 18] step 20/44: loss=-0.2818 
[epoch 18] step 22/44: loss=-0.2879 
[epoch 18] step 24/44: loss=-0.2849 
[epoch 18] step 26/44: loss=-0.2803 
[epoch 18] step 28/44: loss=-0.2730 
[epoch 18] step 30/44: loss=-0.2756 
[epoch 18] step 32/44: loss=-0.2738 
[epoch 18] step 34/44: loss=-0.2673 
[epoch 18] step 36/44: loss=-0.2631 
[epoch 18] step 38/44: loss=-0.2578 
[epoch 18] step 40/44: loss=-0.2542 
[epoch 18] step 42/44: loss=-0.2524 
[epoch 18] step 44/44: loss=-0.2538 
[epoch 18] train_loss(avg per step)=-0.5076 lambda[min,max]=[0.500003,1.000000]
[epoch 18] val_loss=4.9864 qwk=('0.3656', '0.3376', '0.3455') averageQWK=0.3496 macroEMD=0.2865 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   12    1    0
     0    7   65    9    1
     0    0  113   41    1
     0    0   20   46    7
     0    0    5    4    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    4   53   19    0
     0    0   88   76    0
     0    0   10   69    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    7   74   11    0
     0    6  130   30    0
     0    1   24   47    0
     0    0    0    1    0
[epoch 19] step 2/44: loss=-0.3673 
[epoch 19] step 4/44: loss=-0.3572 
[epoch 19] step 6/44: loss=-0.3147 
[epoch 19] step 8/44: loss=-0.2943 
[epoch 19] step 10/44: loss=-0.3167 
[epoch 19] step 12/44: loss=-0.3061 
[epoch 19] step 14/44: loss=-0.3029 
[epoch 19] step 16/44: loss=-0.2988 
[epoch 19] step 18/44: loss=-0.2876 
[epoch 19] step 20/44: loss=-0.2812 
[epoch 19] step 22/44: loss=-0.2820 
[epoch 19] step 24/44: loss=-0.2822 
[epoch 19] step 26/44: loss=-0.2828 
[epoch 19] step 28/44: loss=-0.2857 
[epoch 19] step 30/44: loss=-0.2857 
[epoch 19] step 32/44: loss=-0.2860 
[epoch 19] step 34/44: loss=-0.2897 
[epoch 19] step 36/44: loss=-0.2905 
[epoch 19] step 38/44: loss=-0.2935 
[epoch 19] step 40/44: loss=-0.2892 
[epoch 19] step 42/44: loss=-0.2915 
[epoch 19] step 44/44: loss=-0.2845 
[epoch 19] train_loss(avg per step)=-0.5691 lambda[min,max]=[0.500002,1.000000]
[epoch 19] val_loss=4.9342 qwk=('0.4442', '0.3598', '0.3292') averageQWK=0.3777 macroEMD=0.2922 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    8    1    0
     0   13   58   10    1
     0    3   89   58    5
     0    0   11   53    9
     0    0    2    7    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    2   62   12    0
     0    1   99   64    0
     0    0   15   64    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    3   73   16    0
     0    1  115   50    0
     0    0   16   56    0
     0    0    0    1    0
[epoch 20] step 2/44: loss=-0.3279 
[epoch 20] step 4/44: loss=-0.3030 
[epoch 20] step 6/44: loss=-0.3249 
[epoch 20] step 8/44: loss=-0.3316 
[epoch 20] step 10/44: loss=-0.3310 
[epoch 20] step 12/44: loss=-0.3238 
[epoch 20] step 14/44: loss=-0.3168 
[epoch 20] step 16/44: loss=-0.3236 
[epoch 20] step 18/44: loss=-0.3285 
[epoch 20] step 20/44: loss=-0.3213 
[epoch 20] step 22/44: loss=-0.3287 
[epoch 20] step 24/44: loss=-0.3337 
[epoch 20] step 26/44: loss=-0.3314 
[epoch 20] step 28/44: loss=-0.3284 
[epoch 20] step 30/44: loss=-0.3364 
[epoch 20] step 32/44: loss=-0.3407 
[epoch 20] step 34/44: loss=-0.3460 
[epoch 20] step 36/44: loss=-0.3500 
[epoch 20] step 38/44: loss=-0.3529 
[epoch 20] step 40/44: loss=-0.3537 
[epoch 20] step 42/44: loss=-0.3546 
[epoch 20] step 44/44: loss=-0.3398 
[epoch 20] train_loss(avg per step)=-0.6795 lambda[min,max]=[0.500009,1.000000]
[epoch 20] val_loss=4.3417 qwk=('0.4552', '0.3687', '0.3681') averageQWK=0.3973 macroEMD=0.2802 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    6    1    0
     0   21   51   10    0
     0   11   86   56    2
     0    0   13   57    3
     0    0    5    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    4   64    8    0
     0    1  129   34    0
     0    0   24   53    3
     0    0    2    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0   11   66   15    0
     0   17  112   37    0
     0    2   16   54    0
     0    0    0    1    0
[epoch 21] step 2/44: loss=-0.3752 
[epoch 21] step 4/44: loss=-0.3818 
[epoch 21] step 6/44: loss=-0.4070 
[epoch 21] step 8/44: loss=-0.4081 
[epoch 21] step 10/44: loss=-0.4157 
[epoch 21] step 12/44: loss=-0.4224 
[epoch 21] step 14/44: loss=-0.4207 
[epoch 21] step 16/44: loss=-0.4182 
[epoch 21] step 18/44: loss=-0.4196 
[epoch 21] step 20/44: loss=-0.4211 
[epoch 21] step 22/44: loss=-0.4167 
[epoch 21] step 24/44: loss=-0.4170 
[epoch 21] step 26/44: loss=-0.4158 
[epoch 21] step 28/44: loss=-0.4122 
[epoch 21] step 30/44: loss=-0.4150 
[epoch 21] step 32/44: loss=-0.4148 
[epoch 21] step 34/44: loss=-0.4166 
[epoch 21] step 36/44: loss=-0.4201 
[epoch 21] step 38/44: loss=-0.4193 
[epoch 21] step 40/44: loss=-0.4204 
[epoch 21] step 42/44: loss=-0.4209 
[epoch 21] step 44/44: loss=-0.4252 
[epoch 21] train_loss(avg per step)=-0.8504 lambda[min,max]=[0.500001,1.000000]
[epoch 21] val_loss=5.0161 qwk=('0.4374', '0.3811', '0.3227') averageQWK=0.3804 macroEMD=0.2748 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    6    1    0
     0   16   56   10    0
     0    4   96   53    2
     0    0   18   53    2
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    4   64    8    0
     0    2  109   53    0
     0    0   18   61    1
     0    0    1    5    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    9   76    7    0
     0   13  135   18    0
     0    2   34   36    0
     0    0    0    1    0
[epoch 22] step 2/44: loss=-0.3852 
[epoch 22] step 4/44: loss=-0.4263 
[epoch 22] step 6/44: loss=-0.4554 
[epoch 22] step 8/44: loss=-0.4666 
[epoch 22] step 10/44: loss=-0.4761 
[epoch 22] step 12/44: loss=-0.4747 
[epoch 22] step 14/44: loss=-0.4713 
[epoch 22] step 16/44: loss=-0.4720 
[epoch 22] step 18/44: loss=-0.4753 
[epoch 22] step 20/44: loss=-0.4762 
[epoch 22] step 22/44: loss=-0.4787 
[epoch 22] step 24/44: loss=-0.4779 
[epoch 22] step 26/44: loss=-0.4762 
[epoch 22] step 28/44: loss=-0.4776 
[epoch 22] step 30/44: loss=-0.4799 
[epoch 22] step 32/44: loss=-0.4747 
[epoch 22] step 34/44: loss=-0.4745 
[epoch 22] step 36/44: loss=-0.4722 
[epoch 22] step 38/44: loss=-0.4728 
[epoch 22] step 40/44: loss=-0.4733 
[epoch 22] step 42/44: loss=-0.4710 
[epoch 22] step 44/44: loss=-0.4672 
[epoch 22] train_loss(avg per step)=-0.9343 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=5.9085 qwk=('0.3892', '0.3759', '0.3376') averageQWK=0.3676 macroEMD=0.2791 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3   11    1    0
     0   11   60   11    0
     0    4   91   57    3
     0    0   15   51    7
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    8   50   18    0
     0    6   81   77    0
     0    0    5   73    2
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    6   69   17    0
     0    5  115   46    0
     0    1   17   54    0
     0    0    0    1    0
[epoch 23] step 2/44: loss=-0.4198 
[epoch 23] step 4/44: loss=-0.4780 
[epoch 23] step 6/44: loss=-0.4745 
[epoch 23] step 8/44: loss=-0.4557 
[epoch 23] step 10/44: loss=-0.4666 
[epoch 23] step 12/44: loss=-0.4644 
[epoch 23] step 14/44: loss=-0.4697 
[epoch 23] step 16/44: loss=-0.4727 
[epoch 23] step 18/44: loss=-0.4686 
[epoch 23] step 20/44: loss=-0.4738 
[epoch 23] step 22/44: loss=-0.4768 
[epoch 23] step 24/44: loss=-0.4743 
[epoch 23] step 26/44: loss=-0.4703 
[epoch 23] step 28/44: loss=-0.4708 
[epoch 23] step 30/44: loss=-0.4701 
[epoch 23] step 32/44: loss=-0.4712 
[epoch 23] step 34/44: loss=-0.4717 
[epoch 23] step 36/44: loss=-0.4712 
[epoch 23] step 38/44: loss=-0.4679 
[epoch 23] step 40/44: loss=-0.4679 
[epoch 23] step 42/44: loss=-0.4699 
[epoch 23] step 44/44: loss=-0.4664 
[epoch 23] train_loss(avg per step)=-0.9328 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=5.4822 qwk=('0.4274', '0.3592', '0.3471') averageQWK=0.3779 macroEMD=0.2711 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    8    6    1    0
     0   17   55   10    0
     0    8   97   48    2
     0    0   21   51    1
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    5   60   11    0
     0    2  110   52    0
     0    1   15   63    1
     0    0    2    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    7   79    6    0
     0    6  143   17    0
     0    1   36   35    0
     0    0    0    1    0
[epoch 24] step 2/44: loss=-0.4437 
[epoch 24] step 4/44: loss=-0.4445 
[epoch 24] step 6/44: loss=-0.4574 
[epoch 24] step 8/44: loss=-0.4699 
[epoch 24] step 10/44: loss=-0.4821 
[epoch 24] step 12/44: loss=-0.4817 
[epoch 24] step 14/44: loss=-0.4750 
[epoch 24] step 16/44: loss=-0.4787 
[epoch 24] step 18/44: loss=-0.4836 
[epoch 24] step 20/44: loss=-0.4812 
[epoch 24] step 22/44: loss=-0.4829 
[epoch 24] step 24/44: loss=-0.4828 
[epoch 24] step 26/44: loss=-0.4826 
[epoch 24] step 28/44: loss=-0.4837 
[epoch 24] step 30/44: loss=-0.4847 
[epoch 24] step 32/44: loss=-0.4859 
[epoch 24] step 34/44: loss=-0.4836 
[epoch 24] step 36/44: loss=-0.4876 
[epoch 24] step 38/44: loss=-0.4857 
[epoch 24] step 40/44: loss=-0.4856 
[epoch 24] step 42/44: loss=-0.4820 
[epoch 24] step 44/44: loss=-0.4857 
[epoch 24] train_loss(avg per step)=-0.9715 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=5.9154 qwk=('0.4382', '0.3920', '0.3542') averageQWK=0.3948 macroEMD=0.2739 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    7    1    0
     0   16   55   10    1
     0    4   97   50    4
     0    0   18   46    9
     0    0    3    6    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    5   58   13    0
     0    2  107   55    0
     0    0   12   65    3
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    6   73   13    0
     0    4  124   38    0
     0    1   19   51    1
     0    0    0    1    0
[epoch 25] step 2/44: loss=-0.5260 
[epoch 25] step 4/44: loss=-0.5256 
[epoch 25] step 6/44: loss=-0.5111 
[epoch 25] step 8/44: loss=-0.5049 
[epoch 25] step 10/44: loss=-0.5132 
[epoch 25] step 12/44: loss=-0.5143 
[epoch 25] step 14/44: loss=-0.5099 
[epoch 25] step 16/44: loss=-0.5073 
[epoch 25] step 18/44: loss=-0.5024 
[epoch 25] step 20/44: loss=-0.5056 
[epoch 25] step 22/44: loss=-0.5058 
[epoch 25] step 24/44: loss=-0.5093 
[epoch 25] step 26/44: loss=-0.5069 
[epoch 25] step 28/44: loss=-0.5092 
[epoch 25] step 30/44: loss=-0.5113 
[epoch 25] step 32/44: loss=-0.5131 
[epoch 25] step 34/44: loss=-0.5123 
[epoch 25] step 36/44: loss=-0.5115 
[epoch 25] step 38/44: loss=-0.5103 
[epoch 25] step 40/44: loss=-0.5111 
[epoch 25] step 42/44: loss=-0.5107 
[epoch 25] step 44/44: loss=-0.5136 
[epoch 25] train_loss(avg per step)=-1.0272 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=6.3547 qwk=('0.4068', '0.4079', '0.3502') averageQWK=0.3883 macroEMD=0.2744 tailR0=('0.0500', '0.0000', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3   11    1    0
     0    8   64    9    1
     0    3   89   56    7
     0    0   11   53    9
     0    0    2    7    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    6   61    9    0
     0    2   92   70    0
     0    0   11   67    2
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    6   74   12    0
     0    4  128   34    0
     0    1   23   48    0
     0    0    0    1    0
[epoch 26] step 2/44: loss=-0.4822 
[epoch 26] step 4/44: loss=-0.5030 
[epoch 26] step 6/44: loss=-0.5218 
[epoch 26] step 8/44: loss=-0.5229 
[epoch 26] step 10/44: loss=-0.5214 
[epoch 26] step 12/44: loss=-0.5208 
[epoch 26] step 14/44: loss=-0.5239 
[epoch 26] step 16/44: loss=-0.5254 
[epoch 26] step 18/44: loss=-0.5267 
[epoch 26] step 20/44: loss=-0.5253 
[epoch 26] step 22/44: loss=-0.5252 
[epoch 26] step 24/44: loss=-0.5249 
[epoch 26] step 26/44: loss=-0.5238 
[epoch 26] step 28/44: loss=-0.5226 
[epoch 26] step 30/44: loss=-0.5223 
[epoch 26] step 32/44: loss=-0.5236 
[epoch 26] step 34/44: loss=-0.5258 
[epoch 26] step 36/44: loss=-0.5267 
[epoch 26] step 38/44: loss=-0.5262 
[epoch 26] step 40/44: loss=-0.5265 
[epoch 26] step 42/44: loss=-0.5268 
[epoch 26] step 44/44: loss=-0.5286 
[epoch 26] train_loss(avg per step)=-1.0572 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=6.3618 qwk=('0.4358', '0.3933', '0.3277') averageQWK=0.3856 macroEMD=0.2682 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   12   59   11    0
     0    3   89   61    2
     0    0    9   59    5
     0    0    2    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    3   65    8    0
     0    2  115   47    0
     0    0   18   61    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    6   74   12    0
     0    4  137   25    0
     0    1   30   41    0
     0    0    0    1    0
[epoch 27] step 2/44: loss=-0.5360 
[epoch 27] step 4/44: loss=-0.5073 
[epoch 27] step 6/44: loss=-0.5224 
[epoch 27] step 8/44: loss=-0.5277 
[epoch 27] step 10/44: loss=-0.5333 
[epoch 27] step 12/44: loss=-0.5348 
[epoch 27] step 14/44: loss=-0.5389 
[epoch 27] step 16/44: loss=-0.5380 
[epoch 27] step 18/44: loss=-0.5366 
[epoch 27] step 20/44: loss=-0.5385 
[epoch 27] step 22/44: loss=-0.5411 
[epoch 27] step 24/44: loss=-0.5403 
[epoch 27] step 26/44: loss=-0.5409 
[epoch 27] step 28/44: loss=-0.5398 
[epoch 27] step 30/44: loss=-0.5400 
[epoch 27] step 32/44: loss=-0.5401 
[epoch 27] step 34/44: loss=-0.5385 
[epoch 27] step 36/44: loss=-0.5370 
[epoch 27] step 38/44: loss=-0.5383 
[epoch 27] step 40/44: loss=-0.5390 
[epoch 27] step 42/44: loss=-0.5409 
[epoch 27] step 44/44: loss=-0.5417 
[epoch 27] train_loss(avg per step)=-1.0834 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=6.6178 qwk=('0.3507', '0.4081', '0.3952') averageQWK=0.3846 macroEMD=0.2767 tailR0=('0.1000', '0.0000', '0.0000') tailR0avg=0.0333
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   12    1    0
     0    6   68    7    1
     0    2  112   32    9
     0    0   24   39   10
     0    0    5    3    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    3   63   10    0
     0    1  108   55    0
     0    0   11   66    3
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    1    0    0
     0    9   70   13    0
     0    9  115   42    0
     0    1   16   54    1
     0    0    0    1    0
[epoch 28] step 2/44: loss=-0.5257 
[epoch 28] step 4/44: loss=-0.5400 
[epoch 28] step 6/44: loss=-0.5483 
[epoch 28] step 8/44: loss=-0.5512 
[epoch 28] step 10/44: loss=-0.5472 
[epoch 28] step 12/44: loss=-0.5480 
[epoch 28] step 14/44: loss=-0.5519 
[epoch 28] step 16/44: loss=-0.5508 
[epoch 28] step 18/44: loss=-0.5511 
[epoch 28] step 20/44: loss=-0.5489 
[epoch 28] step 22/44: loss=-0.5477 
[epoch 28] step 24/44: loss=-0.5483 
[epoch 28] step 26/44: loss=-0.5508 
[epoch 28] step 28/44: loss=-0.5504 
[epoch 28] step 30/44: loss=-0.5509 
[epoch 28] step 32/44: loss=-0.5527 
[epoch 28] step 34/44: loss=-0.5529 
[epoch 28] step 36/44: loss=-0.5541 
[epoch 28] step 38/44: loss=-0.5547 
[epoch 28] step 40/44: loss=-0.5527 
[epoch 28] step 42/44: loss=-0.5521 
[epoch 28] step 44/44: loss=-0.5535 
[epoch 28] train_loss(avg per step)=-1.1069 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=6.7911 qwk=('0.4379', '0.4091', '0.3247') averageQWK=0.3906 macroEMD=0.2687 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    8    1    0
     0   15   59    8    0
     0    4  108   42    1
     0    0   20   49    4
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    3   64    9    0
     0    1  107   56    0
     0    0   13   62    5
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    6   72   14    0
     0    4  129   33    0
     0    1   23   48    0
     0    0    0    1    0
[epoch 29] step 2/44: loss=-0.5549 
[epoch 29] step 4/44: loss=-0.5479 
[epoch 29] step 6/44: loss=-0.5475 
[epoch 29] step 8/44: loss=-0.5499 
[epoch 29] step 10/44: loss=-0.5518 
[epoch 29] step 12/44: loss=-0.5523 
[epoch 29] step 14/44: loss=-0.5529 
[epoch 29] step 16/44: loss=-0.5533 
[epoch 29] step 18/44: loss=-0.5556 
[epoch 29] step 20/44: loss=-0.5580 
[epoch 29] step 22/44: loss=-0.5593 
[epoch 29] step 24/44: loss=-0.5613 
[epoch 29] step 26/44: loss=-0.5615 
[epoch 29] step 28/44: loss=-0.5617 
[epoch 29] step 30/44: loss=-0.5613 
[epoch 29] step 32/44: loss=-0.5614 
[epoch 29] step 34/44: loss=-0.5613 
[epoch 29] step 36/44: loss=-0.5621 
[epoch 29] step 38/44: loss=-0.5616 
[epoch 29] step 40/44: loss=-0.5627 
[epoch 29] step 42/44: loss=-0.5594 
[epoch 29] step 44/44: loss=-0.5599 
[epoch 29] train_loss(avg per step)=-1.1197 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=7.1586 qwk=('0.4302', '0.4036', '0.3374') averageQWK=0.3904 macroEMD=0.2661 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   13   58   11    0
     0    3   96   55    1
     0    0   15   55    3
     0    0    2    8    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    6   61    9    0
     0    3  110   51    0
     0    0   16   63    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    4    0    0
     0    5   74   13    0
     0    2  126   38    0
     0    1   19   52    0
     0    0    0    1    0
[epoch 30] step 2/44: loss=-0.5639 
[epoch 30] step 4/44: loss=-0.5749 
[epoch 30] step 6/44: loss=-0.5702 
[epoch 30] step 8/44: loss=-0.5734 
[epoch 30] step 10/44: loss=-0.5673 
[epoch 30] step 12/44: loss=-0.5701 
[epoch 30] step 14/44: loss=-0.5727 
[epoch 30] step 16/44: loss=-0.5714 
[epoch 30] step 18/44: loss=-0.5704 
[epoch 30] step 20/44: loss=-0.5687 
[epoch 30] step 22/44: loss=-0.5695 
[epoch 30] step 24/44: loss=-0.5692 
[epoch 30] step 26/44: loss=-0.5710 
[epoch 30] step 28/44: loss=-0.5716 
[epoch 30] step 30/44: loss=-0.5726 
[epoch 30] step 32/44: loss=-0.5718 
[epoch 30] step 34/44: loss=-0.5717 
[epoch 30] step 36/44: loss=-0.5714 
[epoch 30] step 38/44: loss=-0.5722 
[epoch 30] step 40/44: loss=-0.5726 
[epoch 30] step 42/44: loss=-0.5737 
[epoch 30] step 44/44: loss=-0.5737 
[epoch 30] train_loss(avg per step)=-1.1474 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=7.3735 qwk=('0.4182', '0.4037', '0.3521') averageQWK=0.3913 macroEMD=0.2689 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    8    1    0
     0   14   57   10    1
     0    4  100   45    6
     0    0   14   52    7
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    9   55   12    0
     0    5   88   71    0
     0    0    9   70    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    2    0    0
     0    6   69   17    0
     0    6  114   46    0
     0    1   14   57    0
     0    0    0    1    0
[epoch 31] step 2/44: loss=-0.5881 
[epoch 31] step 4/44: loss=-0.5723 
[epoch 31] step 6/44: loss=-0.5710 
[epoch 31] step 8/44: loss=-0.5715 
[epoch 31] step 10/44: loss=-0.5715 
[epoch 31] step 12/44: loss=-0.5692 
[epoch 31] step 14/44: loss=-0.5711 
[epoch 31] step 16/44: loss=-0.5723 
[epoch 31] step 18/44: loss=-0.5732 
[epoch 31] step 20/44: loss=-0.5741 
[epoch 31] step 22/44: loss=-0.5752 
[epoch 31] step 24/44: loss=-0.5767 
[epoch 31] step 26/44: loss=-0.5772 
[epoch 31] step 28/44: loss=-0.5781 
[epoch 31] step 30/44: loss=-0.5774 
[epoch 31] step 32/44: loss=-0.5768 
[epoch 31] step 34/44: loss=-0.5765 
[epoch 31] step 36/44: loss=-0.5771 
[epoch 31] step 38/44: loss=-0.5778 
[epoch 31] step 40/44: loss=-0.5774 
[epoch 31] step 42/44: loss=-0.5778 
[epoch 31] step 44/44: loss=-0.5779 
[epoch 31] train_loss(avg per step)=-1.1558 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=7.5413 qwk=('0.3838', '0.4087', '0.3455') averageQWK=0.3793 macroEMD=0.2689 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   11   63    7    1
     0    3  108   38    6
     0    0   20   46    7
     0    0    5    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0   10   56   10    0
     0    5   99   60    0
     0    1   12   66    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    6   71   15    0
     0    4  121   41    0
     0    1   17   54    0
     0    0    0    1    0
[epoch 32] step 2/44: loss=-0.5622 
[epoch 32] step 4/44: loss=-0.5615 
[epoch 32] step 6/44: loss=-0.5678 
[epoch 32] step 8/44: loss=-0.5721 
[epoch 32] step 10/44: loss=-0.5756 
[epoch 32] step 12/44: loss=-0.5788 
[epoch 32] step 14/44: loss=-0.5800 
[epoch 32] step 16/44: loss=-0.5815 
[epoch 32] step 18/44: loss=-0.5824 
[epoch 32] step 20/44: loss=-0.5838 
[epoch 32] step 22/44: loss=-0.5849 
[epoch 32] step 24/44: loss=-0.5850 
[epoch 32] step 26/44: loss=-0.5845 
[epoch 32] step 28/44: loss=-0.5837 
[epoch 32] step 30/44: loss=-0.5836 
[epoch 32] step 32/44: loss=-0.5835 
[epoch 32] step 34/44: loss=-0.5842 
[epoch 32] step 36/44: loss=-0.5839 
[epoch 32] step 38/44: loss=-0.5845 
[epoch 32] step 40/44: loss=-0.5843 
[epoch 32] step 42/44: loss=-0.5848 
[epoch 32] step 44/44: loss=-0.5836 
[epoch 32] train_loss(avg per step)=-1.1672 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=7.7619 qwk=('0.4008', '0.4057', '0.3450') averageQWK=0.3838 macroEMD=0.2670 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4   10    1    0
     0   13   60    9    0
     0    3  103   47    2
     0    0   18   51    4
     0    0    5    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    8   57   11    0
     0    4  104   56    0
     0    0   13   66    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    6   71   15    0
     0    5  114   47    0
     0    1   16   55    0
     0    0    0    1    0
[epoch 33] step 2/44: loss=-0.5909 
[epoch 33] step 4/44: loss=-0.5905 
[epoch 33] step 6/44: loss=-0.5886 
[epoch 33] step 8/44: loss=-0.5881 
[epoch 33] step 10/44: loss=-0.5901 
[epoch 33] step 12/44: loss=-0.5892 
[epoch 33] step 14/44: loss=-0.5844 
[epoch 33] step 16/44: loss=-0.5850 
[epoch 33] step 18/44: loss=-0.5855 
[epoch 33] step 20/44: loss=-0.5847 
[epoch 33] step 22/44: loss=-0.5850 
[epoch 33] step 24/44: loss=-0.5857 
[epoch 33] step 26/44: loss=-0.5863 
[epoch 33] step 28/44: loss=-0.5864 
[epoch 33] step 30/44: loss=-0.5869 
[epoch 33] step 32/44: loss=-0.5874 
[epoch 33] step 34/44: loss=-0.5874 
[epoch 33] step 36/44: loss=-0.5870 
[epoch 33] step 38/44: loss=-0.5876 
[epoch 33] step 40/44: loss=-0.5881 
[epoch 33] step 42/44: loss=-0.5883 
[epoch 33] step 44/44: loss=-0.5888 
[epoch 33] train_loss(avg per step)=-1.1777 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=7.6385 qwk=('0.4399', '0.4500', '0.3399') averageQWK=0.4099 macroEMD=0.2630 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    7    1    0
     0   16   55   11    0
     0    4  100   49    2
     0    0   16   52    5
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    1    0
     0   12   55    9    0
     0    7   99   58    0
     0    1   10   68    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    5   73   14    0
     0    4  118   44    0
     0    1   18   53    0
     0    0    0    1    0
[epoch 34] step 2/44: loss=-0.5846 
[epoch 34] step 4/44: loss=-0.5872 
[epoch 34] step 6/44: loss=-0.5872 
[epoch 34] step 8/44: loss=-0.5867 
[epoch 34] step 10/44: loss=-0.5841 
[epoch 34] step 12/44: loss=-0.5847 
[epoch 34] step 14/44: loss=-0.5845 
[epoch 34] step 16/44: loss=-0.5859 
[epoch 34] step 18/44: loss=-0.5869 
[epoch 34] step 20/44: loss=-0.5881 
[epoch 34] step 22/44: loss=-0.5891 
[epoch 34] step 24/44: loss=-0.5895 
[epoch 34] step 26/44: loss=-0.5901 
[epoch 34] step 28/44: loss=-0.5906 
[epoch 34] step 30/44: loss=-0.5912 
[epoch 34] step 32/44: loss=-0.5915 
[epoch 34] step 34/44: loss=-0.5913 
[epoch 34] step 36/44: loss=-0.5913 
[epoch 34] step 38/44: loss=-0.5915 
[epoch 34] step 40/44: loss=-0.5918 
[epoch 34] step 42/44: loss=-0.5912 
[epoch 34] step 44/44: loss=-0.5908 
[epoch 34] train_loss(avg per step)=-1.1815 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=8.7580 qwk=('0.3857', '0.3974', '0.3404') averageQWK=0.3745 macroEMD=0.2681 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   12    1    0
     0   11   61    9    1
     0    2  101   50    2
     0    0   15   53    5
     0    0    4    6    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    4   62   10    0
     0    1  102   61    0
     0    0   12   67    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    6   69   17    0
     0    2  109   55    0
     0    1   14   57    0
     0    0    0    1    0
[epoch 35] step 2/44: loss=-0.5920 
[epoch 35] step 4/44: loss=-0.5909 
[epoch 35] step 6/44: loss=-0.5915 
[epoch 35] step 8/44: loss=-0.5856 
[epoch 35] step 10/44: loss=-0.5876 
[epoch 35] step 12/44: loss=-0.5892 
[epoch 35] step 14/44: loss=-0.5902 
[epoch 35] step 16/44: loss=-0.5911 
[epoch 35] step 18/44: loss=-0.5905 
[epoch 35] step 20/44: loss=-0.5914 
[epoch 35] step 22/44: loss=-0.5911 
[epoch 35] step 24/44: loss=-0.5918 
[epoch 35] step 26/44: loss=-0.5923 
[epoch 35] step 28/44: loss=-0.5928 
[epoch 35] step 30/44: loss=-0.5932 
[epoch 35] step 32/44: loss=-0.5931 
[epoch 35] step 34/44: loss=-0.5929 
[epoch 35] step 36/44: loss=-0.5930 
[epoch 35] step 38/44: loss=-0.5929 
[epoch 35] step 40/44: loss=-0.5932 
[epoch 35] step 42/44: loss=-0.5916 
[epoch 35] step 44/44: loss=-0.5920 
[epoch 35] train_loss(avg per step)=-1.1841 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=8.0869 qwk=('0.4133', '0.4037', '0.3547') averageQWK=0.3906 macroEMD=0.2653 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    9    1    0
     0   14   59    8    1
     0    3  101   49    2
     0    0   16   52    5
     0    0    5    5    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    8    1    0
     0    6   60   10    0
     0    1  104   59    0
     0    0   13   66    1
     0    0    0    6    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    3    0    0
     0    6   72   14    0
     0    4  117   45    0
     0    1   16   55    0
     0    0    0    1    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-0-conf_gating-0-reassignment-0/fold4/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-0-conf_gating-0-reassignment-0/fold4/metrics.json
Done.
