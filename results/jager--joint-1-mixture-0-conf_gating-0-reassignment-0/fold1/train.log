[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.8632 
[epoch 1] step 4/44: loss=6.4251 
[epoch 1] step 6/44: loss=6.2171 
[epoch 1] step 8/44: loss=6.2089 
[epoch 1] step 10/44: loss=6.2890 
[epoch 1] step 12/44: loss=6.1975 
[epoch 1] step 14/44: loss=6.1951 
[epoch 1] step 16/44: loss=6.2183 
[epoch 1] step 18/44: loss=6.2240 
[epoch 1] step 20/44: loss=6.2036 
[epoch 1] step 22/44: loss=6.2107 
[epoch 1] step 24/44: loss=6.2108 
[epoch 1] step 26/44: loss=6.1726 
[epoch 1] step 28/44: loss=6.1571 
[epoch 1] step 30/44: loss=6.1365 
[epoch 1] step 32/44: loss=6.0914 
[epoch 1] step 34/44: loss=6.0514 
[epoch 1] step 36/44: loss=6.0116 
[epoch 1] step 38/44: loss=5.9436 
[epoch 1] step 40/44: loss=5.8944 
[epoch 1] step 42/44: loss=5.8274 
[epoch 1] step 44/44: loss=5.7482 
[epoch 1] train_loss(avg per step)=11.4963 lambda[min,max]=[0.541167,1.000000]
[epoch 1] val_loss=5.9118 qwk=('0.0011', '0.0670', '0.0246') averageQWK=0.0309 macroEMD=0.3829 tailR0=('0.0000', '0.0385', '0.0000') tailR0avg=0.0128
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    0    7    0
     0   17    0   24    0
     0   46    0   76    0
     0   48    0   93    0
     0   10    0   11    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0   11    1    0
     6    0   26    7    0
    17    0   69   18    0
    21    0  104   38    0
     0    0   12    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   50    0    0
     0    2  156    0    0
     0    2  108    0    0
     0    0    3    0    0
[epoch 2] step 2/44: loss=3.9232 
[epoch 2] step 4/44: loss=3.9004 
[epoch 2] step 6/44: loss=3.8723 
[epoch 2] step 8/44: loss=3.7201 
[epoch 2] step 10/44: loss=3.6422 
[epoch 2] step 12/44: loss=3.5864 
[epoch 2] step 14/44: loss=3.5046 
[epoch 2] step 16/44: loss=3.4126 
[epoch 2] step 18/44: loss=3.3509 
[epoch 2] step 20/44: loss=3.2430 
[epoch 2] step 22/44: loss=3.1674 
[epoch 2] step 24/44: loss=3.1270 
[epoch 2] step 26/44: loss=3.0658 
[epoch 2] step 28/44: loss=3.0296 
[epoch 2] step 30/44: loss=2.9821 
[epoch 2] step 32/44: loss=2.9347 
[epoch 2] step 34/44: loss=2.8813 
[epoch 2] step 36/44: loss=2.8405 
[epoch 2] step 38/44: loss=2.8103 
[epoch 2] step 40/44: loss=2.7733 
[epoch 2] step 42/44: loss=2.7375 
[epoch 2] step 44/44: loss=2.6915 
[epoch 2] train_loss(avg per step)=5.3830 lambda[min,max]=[0.500520,1.000000]
[epoch 2] val_loss=2.9987 qwk=('0.4693', '0.1057', '0.0680') averageQWK=0.2143 macroEMD=0.3745 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    0   38    3    0
     0    0   70   52    0
     0    0   26  115    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   13    0    0
     0    0   39    0    0
     0    0  103    1    0
     0    0  145   18    0
     0    0   12    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    0   52    0    0
     0    0  157    1    0
     0    0  101    9    0
     0    0    3    0    0
[epoch 3] step 2/44: loss=1.6354 
[epoch 3] step 4/44: loss=1.8550 
[epoch 3] step 6/44: loss=1.9060 
[epoch 3] step 8/44: loss=1.9893 
[epoch 3] step 10/44: loss=2.0013 
[epoch 3] step 12/44: loss=1.9895 
[epoch 3] step 14/44: loss=2.0007 
[epoch 3] step 16/44: loss=1.9857 
[epoch 3] step 18/44: loss=1.9907 
[epoch 3] step 20/44: loss=1.9812 
[epoch 3] step 22/44: loss=1.9665 
[epoch 3] step 24/44: loss=1.9549 
[epoch 3] step 26/44: loss=1.9532 
[epoch 3] step 28/44: loss=1.9300 
[epoch 3] step 30/44: loss=1.9517 
[epoch 3] step 32/44: loss=1.9382 
[epoch 3] step 34/44: loss=1.9036 
[epoch 3] step 36/44: loss=1.8859 
[epoch 3] step 38/44: loss=1.8520 
[epoch 3] step 40/44: loss=1.8533 
[epoch 3] step 42/44: loss=1.8496 
[epoch 3] step 44/44: loss=1.8328 
[epoch 3] train_loss(avg per step)=3.6656 lambda[min,max]=[0.500869,1.000000]
[epoch 3] val_loss=2.9839 qwk=('0.5035', '0.3239', '0.1200') averageQWK=0.3158 macroEMD=0.3654 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    0    0
     0   10   30    1    0
     0    5   89   28    0
     0    1   48   92    0
     0    0    4   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   12    0    0
     0    1   38    0    0
     0    1   93   10    0
     0    0  102   61    0
     0    0    5   11    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   50    0    0
     0    0  158    0    0
     0    0   99   11    0
     0    0    3    0    0
[epoch 4] step 2/44: loss=1.9029 
[epoch 4] step 4/44: loss=1.7394 
[epoch 4] step 6/44: loss=1.6551 
[epoch 4] step 8/44: loss=1.6775 
[epoch 4] step 10/44: loss=1.6450 
[epoch 4] step 12/44: loss=1.6242 
[epoch 4] step 14/44: loss=1.6215 
[epoch 4] step 16/44: loss=1.5841 
[epoch 4] step 18/44: loss=1.5555 
[epoch 4] step 20/44: loss=1.5571 
[epoch 4] step 22/44: loss=1.5484 
[epoch 4] step 24/44: loss=1.5644 
[epoch 4] step 26/44: loss=1.5607 
[epoch 4] step 28/44: loss=1.5617 
[epoch 4] step 30/44: loss=1.5807 
[epoch 4] step 32/44: loss=1.5832 
[epoch 4] step 34/44: loss=1.5879 
[epoch 4] step 36/44: loss=1.6015 
[epoch 4] step 38/44: loss=1.5993 
[epoch 4] step 40/44: loss=1.6028 
[epoch 4] step 42/44: loss=1.5827 
[epoch 4] step 44/44: loss=1.5641 
[epoch 4] train_loss(avg per step)=3.1283 lambda[min,max]=[0.501781,1.000000]
[epoch 4] val_loss=3.4798 qwk=('0.1029', '0.1684', '0.3936') averageQWK=0.2217 macroEMD=0.3509 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    9    0
     0    4    3   34    0
     0    1    1  120    0
     0    0    0  141    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    7    0
     0    0    9   30    0
     0    0   22   82    0
     0    0    5  158    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    0    0
     0    0   41   11    0
     0    0   76   82    0
     0    0    8  102    0
     0    0    0    3    0
[epoch 5] step 2/44: loss=1.5139 
[epoch 5] step 4/44: loss=1.4441 
[epoch 5] step 6/44: loss=1.3953 
[epoch 5] step 8/44: loss=1.4655 
[epoch 5] step 10/44: loss=1.4805 
[epoch 5] step 12/44: loss=1.4808 
[epoch 5] step 14/44: loss=1.4543 
[epoch 5] step 16/44: loss=1.4497 
[epoch 5] step 18/44: loss=1.4091 
[epoch 5] step 20/44: loss=1.3670 
[epoch 5] step 22/44: loss=1.3621 
[epoch 5] step 24/44: loss=1.3657 
[epoch 5] step 26/44: loss=1.3780 
[epoch 5] step 28/44: loss=1.3776 
[epoch 5] step 30/44: loss=1.3745 
[epoch 5] step 32/44: loss=1.3780 
[epoch 5] step 34/44: loss=1.3565 
[epoch 5] step 36/44: loss=1.3594 
[epoch 5] step 38/44: loss=1.3479 
[epoch 5] step 40/44: loss=1.3451 
[epoch 5] step 42/44: loss=1.3344 
[epoch 5] step 44/44: loss=1.3333 
[epoch 5] train_loss(avg per step)=2.6665 lambda[min,max]=[0.509867,1.000000]
[epoch 5] val_loss=2.5880 qwk=('0.3867', '0.4128', '0.4380') averageQWK=0.4125 macroEMD=0.3436 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    5   23   13    0
     0    0   38   84    0
     0    0    9  132    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0   12    1    0
     0    0   28   11    0
     0    0   57   47    0
     0    0   23  140    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   49    2    0
     0    4  128   26    0
     0    0   38   72    0
     0    0    0    3    0
[epoch 6] step 2/44: loss=1.3636 
[epoch 6] step 4/44: loss=1.2884 
[epoch 6] step 6/44: loss=1.3095 
[epoch 6] step 8/44: loss=1.2527 
[epoch 6] step 10/44: loss=1.2487 
[epoch 6] step 12/44: loss=1.2768 
[epoch 6] step 14/44: loss=1.2658 
[epoch 6] step 16/44: loss=1.2462 
[epoch 6] step 18/44: loss=1.2204 
[epoch 6] step 20/44: loss=1.2215 
[epoch 6] step 22/44: loss=1.2359 
[epoch 6] step 24/44: loss=1.2193 
[epoch 6] step 26/44: loss=1.1848 
[epoch 6] step 28/44: loss=1.1778 
[epoch 6] step 30/44: loss=1.1610 
[epoch 6] step 32/44: loss=1.1605 
[epoch 6] step 34/44: loss=1.1653 
[epoch 6] step 36/44: loss=1.1647 
[epoch 6] step 38/44: loss=1.1604 
[epoch 6] step 40/44: loss=1.1585 
[epoch 6] step 42/44: loss=1.1559 
[epoch 6] step 44/44: loss=1.1401 
[epoch 6] train_loss(avg per step)=2.2803 lambda[min,max]=[0.503545,1.000000]
[epoch 6] val_loss=2.6309 qwk=('0.5204', '0.3848', '0.4085') averageQWK=0.4379 macroEMD=0.3338 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    7    0    0
     0   13   21    7    0
     0    8   52   62    0
     0    0   20  121    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    4    0
     0   10    9   20    0
     0   13   30   61    0
     0    5   10  148    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    5   42    5    0
     0    8  116   34    0
     0    0   40   70    0
     0    0    0    3    0
[epoch 7] step 2/44: loss=0.9374 
[epoch 7] step 4/44: loss=0.9261 
[epoch 7] step 6/44: loss=0.9453 
[epoch 7] step 8/44: loss=0.9263 
[epoch 7] step 10/44: loss=0.9332 
[epoch 7] step 12/44: loss=0.9038 
[epoch 7] step 14/44: loss=0.8981 
[epoch 7] step 16/44: loss=0.9068 
[epoch 7] step 18/44: loss=0.9076 
[epoch 7] step 20/44: loss=0.9430 
[epoch 7] step 22/44: loss=0.9351 
[epoch 7] step 24/44: loss=0.9549 
[epoch 7] step 26/44: loss=0.9742 
[epoch 7] step 28/44: loss=0.9659 
[epoch 7] step 30/44: loss=0.9654 
[epoch 7] step 32/44: loss=0.9542 
[epoch 7] step 34/44: loss=0.9631 
[epoch 7] step 36/44: loss=0.9598 
[epoch 7] step 38/44: loss=0.9510 
[epoch 7] step 40/44: loss=0.9453 
[epoch 7] step 42/44: loss=0.9438 
[epoch 7] step 44/44: loss=0.9466 
[epoch 7] train_loss(avg per step)=1.8933 lambda[min,max]=[0.509560,1.000000]
[epoch 7] val_loss=2.7805 qwk=('0.5019', '0.4013', '0.3466') averageQWK=0.4166 macroEMD=0.3268 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    5   33    3    0
     0    2   77   43    0
     0    0   32  109    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    5    0
     0    9   11   19    0
     0   12   30   62    0
     0    2   11  150    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    4   31   17    0
     0    7   52   99    0
     0    1    8  101    0
     0    0    0    3    0
[epoch 8] step 2/44: loss=0.5975 
[epoch 8] step 4/44: loss=0.7626 
[epoch 8] step 6/44: loss=0.7979 
[epoch 8] step 8/44: loss=0.8003 
[epoch 8] step 10/44: loss=0.7892 
[epoch 8] step 12/44: loss=0.8089 
[epoch 8] step 14/44: loss=0.8332 
[epoch 8] step 16/44: loss=0.8431 
[epoch 8] step 18/44: loss=0.8438 
[epoch 8] step 20/44: loss=0.8460 
[epoch 8] step 22/44: loss=0.8405 
[epoch 8] step 24/44: loss=0.8422 
[epoch 8] step 26/44: loss=0.8601 
[epoch 8] step 28/44: loss=0.8566 
[epoch 8] step 30/44: loss=0.8597 
[epoch 8] step 32/44: loss=0.8587 
[epoch 8] step 34/44: loss=0.8692 
[epoch 8] step 36/44: loss=0.8654 
[epoch 8] step 38/44: loss=0.8579 
[epoch 8] step 40/44: loss=0.8517 
[epoch 8] step 42/44: loss=0.8485 
[epoch 8] step 44/44: loss=0.8566 
[epoch 8] train_loss(avg per step)=1.7132 lambda[min,max]=[0.504577,1.000000]
[epoch 8] val_loss=2.8284 qwk=('0.5298', '0.4864', '0.3005') averageQWK=0.4389 macroEMD=0.3133 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    0    0
     0   15   25    1    0
     0   12   87   23    0
     0    1   50   90    0
     0    0    4   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0   10    2    1    0
     0   28   11    0    0
     0   46   45   13    0
     0   19   68   76    0
     0    0    4   12    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0    8   44    0    0
     0   16  137    5    0
     0    3   76   31    0
     0    0    2    1    0
[epoch 9] step 2/44: loss=1.1556 
[epoch 9] step 4/44: loss=0.9822 
[epoch 9] step 6/44: loss=0.8703 
[epoch 9] step 8/44: loss=0.9099 
[epoch 9] step 10/44: loss=0.8485 
[epoch 9] step 12/44: loss=0.8161 
[epoch 9] step 14/44: loss=0.8120 
[epoch 9] step 16/44: loss=0.8328 
[epoch 9] step 18/44: loss=0.8352 
[epoch 9] step 20/44: loss=0.8187 
[epoch 9] step 22/44: loss=0.8101 
[epoch 9] step 24/44: loss=0.8025 
[epoch 9] step 26/44: loss=0.7949 
[epoch 9] step 28/44: loss=0.7987 
[epoch 9] step 30/44: loss=0.7864 
[epoch 9] step 32/44: loss=0.7756 
[epoch 9] step 34/44: loss=0.7587 
[epoch 9] step 36/44: loss=0.7521 
[epoch 9] step 38/44: loss=0.7447 
[epoch 9] step 40/44: loss=0.7518 
[epoch 9] step 42/44: loss=0.7604 
[epoch 9] step 44/44: loss=0.7590 
[epoch 9] train_loss(avg per step)=1.5180 lambda[min,max]=[0.502944,1.000000]
[epoch 9] val_loss=2.8073 qwk=('0.4542', '0.3247', '0.3940') averageQWK=0.3910 macroEMD=0.3193 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    7   24   10    0
     0    2   53   67    0
     0    0   16  123    2
     0    0    0   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    4    6    0
     0    6   11   22    0
     0    7   34   63    0
     0    1   12  150    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    3   42    6    1
     0    8   98   52    0
     0    0   31   79    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=0.5101 
[epoch 10] step 4/44: loss=0.5501 
[epoch 10] step 6/44: loss=0.5784 
[epoch 10] step 8/44: loss=0.6477 
[epoch 10] step 10/44: loss=0.6267 
[epoch 10] step 12/44: loss=0.6025 
[epoch 10] step 14/44: loss=0.6210 
[epoch 10] step 16/44: loss=0.6273 
[epoch 10] step 18/44: loss=0.6174 
[epoch 10] step 20/44: loss=0.6063 
[epoch 10] step 22/44: loss=0.5835 
[epoch 10] step 24/44: loss=0.5664 
[epoch 10] step 26/44: loss=0.5563 
[epoch 10] step 28/44: loss=0.5454 
[epoch 10] step 30/44: loss=0.5419 
[epoch 10] step 32/44: loss=0.5357 
[epoch 10] step 34/44: loss=0.5301 
[epoch 10] step 36/44: loss=0.5305 
[epoch 10] step 38/44: loss=0.5325 
[epoch 10] step 40/44: loss=0.5331 
[epoch 10] step 42/44: loss=0.5306 
[epoch 10] step 44/44: loss=0.5273 
[epoch 10] train_loss(avg per step)=1.0546 lambda[min,max]=[0.501740,1.000000]
[epoch 10] val_loss=2.8054 qwk=('0.3975', '0.3015', '0.4351') averageQWK=0.3780 macroEMD=0.3135 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    3    0
     0    7   23   11    0
     0    4   38   80    0
     0    0   13  127    1
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    6    6    0
     0    4   14   21    0
     0    6   32   66    0
     0    0   12  150    1
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    4   43    5    0
     0    7   97   54    0
     0    0   25   85    0
     0    0    0    3    0
[epoch 11] step 2/44: loss=0.5777 
[epoch 11] step 4/44: loss=0.5330 
[epoch 11] step 6/44: loss=0.5191 
[epoch 11] step 8/44: loss=0.5317 
[epoch 11] step 10/44: loss=0.5282 
[epoch 11] step 12/44: loss=0.5274 
[epoch 11] step 14/44: loss=0.5257 
[epoch 11] step 16/44: loss=0.5207 
[epoch 11] step 18/44: loss=0.5297 
[epoch 11] step 20/44: loss=0.5185 
[epoch 11] step 22/44: loss=0.5137 
[epoch 11] step 24/44: loss=0.5265 
[epoch 11] step 26/44: loss=0.5402 
[epoch 11] step 28/44: loss=0.5351 
[epoch 11] step 30/44: loss=0.5341 
[epoch 11] step 32/44: loss=0.5324 
[epoch 11] step 34/44: loss=0.5356 
[epoch 11] step 36/44: loss=0.5284 
[epoch 11] step 38/44: loss=0.5270 
[epoch 11] step 40/44: loss=0.5205 
[epoch 11] step 42/44: loss=0.5134 
[epoch 11] step 44/44: loss=0.4868 
[epoch 11] train_loss(avg per step)=0.9736 lambda[min,max]=[0.500753,1.000000]
[epoch 11] val_loss=2.6811 qwk=('0.4538', '0.4554', '0.4382') averageQWK=0.4491 macroEMD=0.3049 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    3   33    5    0
     0    0   67   55    0
     0    0   26  115    0
     0    0    1   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    3   32    4    0
     0    4   65   35    0
     0    0   38  125    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    1   49    2    0
     0    1  122   35    0
     0    0   35   75    0
     0    0    0    3    0
[epoch 12] step 2/44: loss=0.2918 
[epoch 12] step 4/44: loss=0.3374 
[epoch 12] step 6/44: loss=0.3217 
[epoch 12] step 8/44: loss=0.3479 
[epoch 12] step 10/44: loss=0.3637 
[epoch 12] step 12/44: loss=0.3322 
[epoch 12] step 14/44: loss=0.3176 
[epoch 12] step 16/44: loss=0.3123 
[epoch 12] step 18/44: loss=0.3194 
[epoch 12] step 20/44: loss=0.3221 
[epoch 12] step 22/44: loss=0.3204 
[epoch 12] step 24/44: loss=0.3199 
[epoch 12] step 26/44: loss=0.3279 
[epoch 12] step 28/44: loss=0.3365 
[epoch 12] step 30/44: loss=0.3327 
[epoch 12] step 32/44: loss=0.3405 
[epoch 12] step 34/44: loss=0.3435 
[epoch 12] step 36/44: loss=0.3399 
[epoch 12] step 38/44: loss=0.3448 
[epoch 12] step 40/44: loss=0.3391 
[epoch 12] step 42/44: loss=0.3359 
[epoch 12] step 44/44: loss=0.3230 
[epoch 12] train_loss(avg per step)=0.6460 lambda[min,max]=[0.500314,1.000000]
[epoch 12] val_loss=2.6881 qwk=('0.4788', '0.4771', '0.3627') averageQWK=0.4395 macroEMD=0.3007 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    0    0
     0    7   30    4    0
     0    4   82   36    0
     0    0   40  100    1
     0    0    3   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    6   27    6    0
     0   11   54   39    0
     0    0   37  126    0
     0    0    0   16    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    6   45    1    0
     0   12  127   19    0
     0    1   58   51    0
     0    0    2    1    0
[epoch 13] step 2/44: loss=0.2039 
[epoch 13] step 4/44: loss=0.2163 
[epoch 13] step 6/44: loss=0.2468 
[epoch 13] step 8/44: loss=0.2784 
[epoch 13] step 10/44: loss=0.2801 
[epoch 13] step 12/44: loss=0.2691 
[epoch 13] step 14/44: loss=0.2663 
[epoch 13] step 16/44: loss=0.2917 
[epoch 13] step 18/44: loss=0.2585 
[epoch 13] step 20/44: loss=0.2460 
[epoch 13] step 22/44: loss=0.2436 
[epoch 13] step 24/44: loss=0.2344 
[epoch 13] step 26/44: loss=0.2401 
[epoch 13] step 28/44: loss=0.2362 
[epoch 13] step 30/44: loss=0.2285 
[epoch 13] step 32/44: loss=0.2264 
[epoch 13] step 34/44: loss=0.2268 
[epoch 13] step 36/44: loss=0.2188 
[epoch 13] step 38/44: loss=0.2135 
[epoch 13] step 40/44: loss=0.2126 
[epoch 13] step 42/44: loss=0.2104 
[epoch 13] step 44/44: loss=0.2089 
[epoch 13] train_loss(avg per step)=0.4178 lambda[min,max]=[0.500145,1.000000]
[epoch 13] val_loss=3.0051 qwk=('0.4379', '0.4048', '0.3440') averageQWK=0.3956 macroEMD=0.3054 tailR0=('0.0714', '0.0000', '0.0000') tailR0avg=0.0238
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0    4   30    7    0
     0    1   64   55    2
     0    0   29  107    5
     0    0    0   18    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    9    3    0
     0    4   26    9    0
     0    7   52   45    0
     0    0   32  131    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    0   49    2    1
     0    1  129   28    0
     0    0   52   58    0
     0    0    0    3    0
[epoch 14] step 2/44: loss=0.2154 
[epoch 14] step 4/44: loss=0.2475 
[epoch 14] step 6/44: loss=0.1919 
[epoch 14] step 8/44: loss=0.1697 
[epoch 14] step 10/44: loss=0.1760 
[epoch 14] step 12/44: loss=0.1650 
[epoch 14] step 14/44: loss=0.1559 
[epoch 14] step 16/44: loss=0.1567 
[epoch 14] step 18/44: loss=0.1493 
[epoch 14] step 20/44: loss=0.1356 
[epoch 14] step 22/44: loss=0.1147 
[epoch 14] step 24/44: loss=0.1126 
[epoch 14] step 26/44: loss=0.1164 
[epoch 14] step 28/44: loss=0.1161 
[epoch 14] step 30/44: loss=0.1075 
[epoch 14] step 32/44: loss=0.1075 
[epoch 14] step 34/44: loss=0.1083 
[epoch 14] step 36/44: loss=0.1108 
[epoch 14] step 38/44: loss=0.1078 
[epoch 14] step 40/44: loss=0.1040 
[epoch 14] step 42/44: loss=0.0992 
[epoch 14] step 44/44: loss=0.0874 
[epoch 14] train_loss(avg per step)=0.1749 lambda[min,max]=[0.500040,1.000000]
[epoch 14] val_loss=3.0645 qwk=('0.4557', '0.4312', '0.4572') averageQWK=0.4480 macroEMD=0.2899 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    7    2    0
     0   13   21    7    0
     0   12   45   65    0
     0    1   25  115    0
     0    0    0   21    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    8    3    0
     0    5   28    6    0
     0   11   57   36    0
     0    0   43  120    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    1    0
     0    9   39    4    0
     0   17   88   53    0
     0    3   22   85    0
     0    0    0    3    0
[epoch 15] step 2/44: loss=0.0599 
[epoch 15] step 4/44: loss=0.0840 
[epoch 15] step 6/44: loss=0.0790 
[epoch 15] step 8/44: loss=0.0906 
[epoch 15] step 10/44: loss=0.0796 
[epoch 15] step 12/44: loss=0.0772 
[epoch 15] step 14/44: loss=0.0797 
[epoch 15] step 16/44: loss=0.0623 
[epoch 15] step 18/44: loss=0.0544 
[epoch 15] step 20/44: loss=0.0314 
[epoch 15] step 22/44: loss=0.0398 
[epoch 15] step 24/44: loss=0.0403 
[epoch 15] step 26/44: loss=0.0281 
[epoch 15] step 28/44: loss=0.0274 
[epoch 15] step 30/44: loss=0.0239 
[epoch 15] step 32/44: loss=0.0233 
[epoch 15] step 34/44: loss=0.0214 
[epoch 15] step 36/44: loss=0.0179 
[epoch 15] step 38/44: loss=0.0141 
[epoch 15] step 40/44: loss=0.0138 
[epoch 15] step 42/44: loss=0.0061 
[epoch 15] step 44/44: loss=0.0038 
[epoch 15] train_loss(avg per step)=0.0076 lambda[min,max]=[0.500030,1.000000]
[epoch 15] val_loss=3.0721 qwk=('0.4945', '0.3957', '0.4845') averageQWK=0.4583 macroEMD=0.2964 tailR0=('0.2167', '0.0625', '0.0000') tailR0avg=0.0931
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     0    7   29    5    0
     0    2   59   59    2
     0    0   27  104   10
     0    0    0   14    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    4    0
     0    7   17   15    0
     0    9   34   60    1
     0    0   19  141    3
     0    0    0   14    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0   12   38    2    0
     0   14   99   45    0
     0    2   27   81    0
     0    0    0    3    0
[epoch 16] step 2/44: loss=0.0143 
[epoch 16] step 4/44: loss=0.0180 
[epoch 16] step 6/44: loss=0.0569 
[epoch 16] step 8/44: loss=0.0583 
[epoch 16] step 10/44: loss=0.0317 
[epoch 16] step 12/44: loss=0.0198 
[epoch 16] step 14/44: loss=0.0088 
[epoch 16] step 16/44: loss=0.0004 
[epoch 16] step 18/44: loss=-0.0167 
[epoch 16] step 20/44: loss=-0.0228 
[epoch 16] step 22/44: loss=-0.0224 
[epoch 16] step 24/44: loss=-0.0415 
[epoch 16] step 26/44: loss=-0.0390 
[epoch 16] step 28/44: loss=-0.0478 
[epoch 16] step 30/44: loss=-0.0399 
[epoch 16] step 32/44: loss=-0.0351 
[epoch 16] step 34/44: loss=-0.0335 
[epoch 16] step 36/44: loss=-0.0448 
[epoch 16] step 38/44: loss=-0.0458 
[epoch 16] step 40/44: loss=-0.0432 
[epoch 16] step 42/44: loss=-0.0466 
[epoch 16] step 44/44: loss=-0.0493 
[epoch 16] train_loss(avg per step)=-0.0986 lambda[min,max]=[0.500032,1.000000]
[epoch 16] val_loss=3.1557 qwk=('0.5182', '0.4822', '0.3975') averageQWK=0.4660 macroEMD=0.2850 tailR0=('0.0238', '0.0000', '0.0000') tailR0avg=0.0079
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    1    0
     0   18   20    3    0
     0   21   65   36    0
     0    3   41   97    0
     0    0    4   16    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    2    0
     0   13   20    6    0
     0   21   53   30    0
     0    3   50  110    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    9    0    0
     0   16   35    1    0
     0   27  115   16    0
     0    5   56   49    0
     0    0    1    2    0
[epoch 17] step 2/44: loss=0.0254 
[epoch 17] step 4/44: loss=0.0392 
[epoch 17] step 6/44: loss=-0.0154 
[epoch 17] step 8/44: loss=-0.0442 
[epoch 17] step 10/44: loss=-0.0370 
[epoch 17] step 12/44: loss=-0.0369 
[epoch 17] step 14/44: loss=-0.0434 
[epoch 17] step 16/44: loss=-0.0373 
[epoch 17] step 18/44: loss=-0.0440 
[epoch 17] step 20/44: loss=-0.0510 
[epoch 17] step 22/44: loss=-0.0601 
[epoch 17] step 24/44: loss=-0.0743 
[epoch 17] step 26/44: loss=-0.0778 
[epoch 17] step 28/44: loss=-0.0855 
[epoch 17] step 30/44: loss=-0.0921 
[epoch 17] step 32/44: loss=-0.0960 
[epoch 17] step 34/44: loss=-0.1044 
[epoch 17] step 36/44: loss=-0.1097 
[epoch 17] step 38/44: loss=-0.1109 
[epoch 17] step 40/44: loss=-0.1131 
[epoch 17] step 42/44: loss=-0.1154 
[epoch 17] step 44/44: loss=-0.1159 
[epoch 17] train_loss(avg per step)=-0.2318 lambda[min,max]=[0.500006,1.000000]
[epoch 17] val_loss=3.5772 qwk=('0.4778', '0.4290', '0.4025') averageQWK=0.4364 macroEMD=0.2862 tailR0=('0.0238', '0.0000', '0.0000') tailR0avg=0.0079
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    6   33    2    0
     0    2   84   36    0
     0    0   47   93    1
     0    0    1   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   10    2    0
     0    4   31    4    0
     0    7   63   33    1
     0    0   45  118    0
     0    0    2   14    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    7   44    1    0
     0   10  130   18    0
     0    0   54   56    0
     0    0    1    2    0
[epoch 18] step 2/44: loss=-0.2198 
[epoch 18] step 4/44: loss=-0.2388 
[epoch 18] step 6/44: loss=-0.2204 
[epoch 18] step 8/44: loss=-0.2037 
[epoch 18] step 10/44: loss=-0.1969 
[epoch 18] step 12/44: loss=-0.1788 
[epoch 18] step 14/44: loss=-0.1855 
[epoch 18] step 16/44: loss=-0.1772 
[epoch 18] step 18/44: loss=-0.1792 
[epoch 18] step 20/44: loss=-0.1854 
[epoch 18] step 22/44: loss=-0.1828 
[epoch 18] step 24/44: loss=-0.1864 
[epoch 18] step 26/44: loss=-0.1887 
[epoch 18] step 28/44: loss=-0.1968 
[epoch 18] step 30/44: loss=-0.1987 
[epoch 18] step 32/44: loss=-0.2037 
[epoch 18] step 34/44: loss=-0.2115 
[epoch 18] step 36/44: loss=-0.2156 
[epoch 18] step 38/44: loss=-0.2166 
[epoch 18] step 40/44: loss=-0.2153 
[epoch 18] step 42/44: loss=-0.2190 
[epoch 18] step 44/44: loss=-0.2276 
[epoch 18] train_loss(avg per step)=-0.4552 lambda[min,max]=[0.500003,1.000000]
[epoch 18] val_loss=3.5730 qwk=('0.4729', '0.4638', '0.4450') averageQWK=0.4606 macroEMD=0.2835 tailR0=('0.0952', '0.0625', '0.1667') tailR0avg=0.1081
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    2    0
     0    9   24    8    0
     0    3   57   61    1
     0    0   26  109    6
     0    0    0   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    2    0
     0   11   20    8    0
     0   15   51   38    0
     0    5   41  115    2
     0    0    2   12    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0   12   37    3    0
     0   14  113   31    0
     0    3   40   67    0
     0    0    0    2    1
[epoch 19] step 2/44: loss=-0.3009 
[epoch 19] step 4/44: loss=-0.3206 
[epoch 19] step 6/44: loss=-0.2936 
[epoch 19] step 8/44: loss=-0.2884 
[epoch 19] step 10/44: loss=-0.2773 
[epoch 19] step 12/44: loss=-0.2867 
[epoch 19] step 14/44: loss=-0.2902 
[epoch 19] step 16/44: loss=-0.2919 
[epoch 19] step 18/44: loss=-0.2977 
[epoch 19] step 20/44: loss=-0.2923 
[epoch 19] step 22/44: loss=-0.2942 
[epoch 19] step 24/44: loss=-0.2898 
[epoch 19] step 26/44: loss=-0.2902 
[epoch 19] step 28/44: loss=-0.2931 
[epoch 19] step 30/44: loss=-0.2944 
[epoch 19] step 32/44: loss=-0.3003 
[epoch 19] step 34/44: loss=-0.3034 
[epoch 19] step 36/44: loss=-0.3044 
[epoch 19] step 38/44: loss=-0.3047 
[epoch 19] step 40/44: loss=-0.3054 
[epoch 19] step 42/44: loss=-0.3046 
[epoch 19] step 44/44: loss=-0.3065 
[epoch 19] train_loss(avg per step)=-0.6130 lambda[min,max]=[0.500003,1.000000]
[epoch 19] val_loss=3.7128 qwk=('0.4853', '0.4041', '0.4079') averageQWK=0.4324 macroEMD=0.2820 tailR0=('0.1929', '0.0312', '0.1667') tailR0avg=0.1303
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     0   10   23    8    0
     0    2   60   58    2
     0    0   26  110    5
     0    0    0   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    4    4    0
     0    8   18   13    0
     0    9   45   49    1
     0    5   23  134    1
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    8   41    3    0
     0   11  113   33    1
     0    1   45   64    0
     0    0    0    2    1
[epoch 20] step 2/44: loss=-0.3787 
[epoch 20] step 4/44: loss=-0.3822 
[epoch 20] step 6/44: loss=-0.3668 
[epoch 20] step 8/44: loss=-0.3570 
[epoch 20] step 10/44: loss=-0.3629 
[epoch 20] step 12/44: loss=-0.3566 
[epoch 20] step 14/44: loss=-0.3525 
[epoch 20] step 16/44: loss=-0.3501 
[epoch 20] step 18/44: loss=-0.3596 
[epoch 20] step 20/44: loss=-0.3583 
[epoch 20] step 22/44: loss=-0.3574 
[epoch 20] step 24/44: loss=-0.3517 
[epoch 20] step 26/44: loss=-0.3555 
[epoch 20] step 28/44: loss=-0.3593 
[epoch 20] step 30/44: loss=-0.3547 
[epoch 20] step 32/44: loss=-0.3525 
[epoch 20] step 34/44: loss=-0.3552 
[epoch 20] step 36/44: loss=-0.3561 
[epoch 20] step 38/44: loss=-0.3575 
[epoch 20] step 40/44: loss=-0.3565 
[epoch 20] step 42/44: loss=-0.3535 
[epoch 20] step 44/44: loss=-0.3560 
[epoch 20] train_loss(avg per step)=-0.7121 lambda[min,max]=[0.500000,1.000000]
[epoch 20] val_loss=4.0565 qwk=('0.4993', '0.4498', '0.4058') averageQWK=0.4516 macroEMD=0.2756 tailR0=('0.0738', '0.0000', '0.1667') tailR0avg=0.0802
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    1    7    1    0
     1    8   27    5    0
     0    6   71   44    1
     0    0   35  106    0
     0    0    1   19    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    2    0
     0   12   17   10    0
     0   16   43   44    1
     0    8   26  129    0
     0    0    1   15    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0   10   41    1    0
     1   13  130   14    0
     0    1   59   49    1
     0    0    0    2    1
[epoch 21] step 2/44: loss=-0.4080 
[epoch 21] step 4/44: loss=-0.4178 
[epoch 21] step 6/44: loss=-0.4157 
[epoch 21] step 8/44: loss=-0.4091 
[epoch 21] step 10/44: loss=-0.4008 
[epoch 21] step 12/44: loss=-0.3957 
[epoch 21] step 14/44: loss=-0.3994 
[epoch 21] step 16/44: loss=-0.3999 
[epoch 21] step 18/44: loss=-0.3979 
[epoch 21] step 20/44: loss=-0.3943 
[epoch 21] step 22/44: loss=-0.3968 
[epoch 21] step 24/44: loss=-0.3968 
[epoch 21] step 26/44: loss=-0.4002 
[epoch 21] step 28/44: loss=-0.4024 
[epoch 21] step 30/44: loss=-0.3998 
[epoch 21] step 32/44: loss=-0.3985 
[epoch 21] step 34/44: loss=-0.4010 
[epoch 21] step 36/44: loss=-0.3998 
[epoch 21] step 38/44: loss=-0.3990 
[epoch 21] step 40/44: loss=-0.3898 
[epoch 21] step 42/44: loss=-0.3930 
[epoch 21] step 44/44: loss=-0.3975 
[epoch 21] train_loss(avg per step)=-0.7950 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=4.0770 qwk=('0.4863', '0.4323', '0.4111') averageQWK=0.4432 macroEMD=0.2813 tailR0=('0.0238', '0.0312', '0.1667') tailR0avg=0.0739
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    8   30    3    0
     0    3   67   50    2
     0    0   33  103    5
     0    0    0   20    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    6   24    9    0
     0    9   57   37    1
     0    2   38  123    0
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    5   45    1    1
     0    9  127   22    0
     0    0   49   60    1
     0    0    0    2    1
[epoch 22] step 2/44: loss=-0.3483 
[epoch 22] step 4/44: loss=-0.4059 
[epoch 22] step 6/44: loss=-0.4149 
[epoch 22] step 8/44: loss=-0.4289 
[epoch 22] step 10/44: loss=-0.4343 
[epoch 22] step 12/44: loss=-0.4348 
[epoch 22] step 14/44: loss=-0.4318 
[epoch 22] step 16/44: loss=-0.4316 
[epoch 22] step 18/44: loss=-0.4341 
[epoch 22] step 20/44: loss=-0.4333 
[epoch 22] step 22/44: loss=-0.4293 
[epoch 22] step 24/44: loss=-0.4312 
[epoch 22] step 26/44: loss=-0.4315 
[epoch 22] step 28/44: loss=-0.4331 
[epoch 22] step 30/44: loss=-0.4330 
[epoch 22] step 32/44: loss=-0.4351 
[epoch 22] step 34/44: loss=-0.4299 
[epoch 22] step 36/44: loss=-0.4304 
[epoch 22] step 38/44: loss=-0.4303 
[epoch 22] step 40/44: loss=-0.4328 
[epoch 22] step 42/44: loss=-0.4332 
[epoch 22] step 44/44: loss=-0.4360 
[epoch 22] train_loss(avg per step)=-0.8720 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=4.2559 qwk=('0.4873', '0.3894', '0.4084') averageQWK=0.4284 macroEMD=0.2799 tailR0=('0.1190', '0.0938', '0.0000') tailR0avg=0.0709
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    8   26    7    0
     0    3   69   48    2
     0    0   32  102    7
     0    0    0   16    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    5    0
     0    8   19   12    0
     0   10   48   45    1
     0    2   40  115    6
     0    0    1   12    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    5   44    3    0
     0    7  123   28    0
     0    0   46   64    0
     0    0    0    3    0
[epoch 23] step 2/44: loss=-0.4605 
[epoch 23] step 4/44: loss=-0.4819 
[epoch 23] step 6/44: loss=-0.4619 
[epoch 23] step 8/44: loss=-0.4570 
[epoch 23] step 10/44: loss=-0.4560 
[epoch 23] step 12/44: loss=-0.4541 
[epoch 23] step 14/44: loss=-0.4529 
[epoch 23] step 16/44: loss=-0.4539 
[epoch 23] step 18/44: loss=-0.4577 
[epoch 23] step 20/44: loss=-0.4582 
[epoch 23] step 22/44: loss=-0.4568 
[epoch 23] step 24/44: loss=-0.4507 
[epoch 23] step 26/44: loss=-0.4507 
[epoch 23] step 28/44: loss=-0.4519 
[epoch 23] step 30/44: loss=-0.4527 
[epoch 23] step 32/44: loss=-0.4575 
[epoch 23] step 34/44: loss=-0.4562 
[epoch 23] step 36/44: loss=-0.4569 
[epoch 23] step 38/44: loss=-0.4539 
[epoch 23] step 40/44: loss=-0.4544 
[epoch 23] step 42/44: loss=-0.4536 
[epoch 23] step 44/44: loss=-0.4532 
[epoch 23] train_loss(avg per step)=-0.9064 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=4.4881 qwk=('0.4784', '0.4376', '0.4004') averageQWK=0.4388 macroEMD=0.2817 tailR0=('0.1429', '0.1562', '0.0000') tailR0avg=0.0997
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    8   25    8    0
     0    6   64   50    2
     0    0   33  100    8
     0    0    0   15    6
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    7    2    0
     0   10   21    8    0
     0   11   51   39    3
     0    6   39  110    8
     0    0    2    9    5
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    3   44    5    0
     0    5  100   51    2
     0    0   31   79    0
     0    0    0    3    0
[epoch 24] step 2/44: loss=-0.5199 
[epoch 24] step 4/44: loss=-0.4749 
[epoch 24] step 6/44: loss=-0.4548 
[epoch 24] step 8/44: loss=-0.4461 
[epoch 24] step 10/44: loss=-0.4445 
[epoch 24] step 12/44: loss=-0.4446 
[epoch 24] step 14/44: loss=-0.4478 
[epoch 24] step 16/44: loss=-0.4561 
[epoch 24] step 18/44: loss=-0.4578 
[epoch 24] step 20/44: loss=-0.4625 
[epoch 24] step 22/44: loss=-0.4658 
[epoch 24] step 24/44: loss=-0.4657 
[epoch 24] step 26/44: loss=-0.4650 
[epoch 24] step 28/44: loss=-0.4673 
[epoch 24] step 30/44: loss=-0.4718 
[epoch 24] step 32/44: loss=-0.4738 
[epoch 24] step 34/44: loss=-0.4767 
[epoch 24] step 36/44: loss=-0.4769 
[epoch 24] step 38/44: loss=-0.4777 
[epoch 24] step 40/44: loss=-0.4755 
[epoch 24] step 42/44: loss=-0.4739 
[epoch 24] step 44/44: loss=-0.4769 
[epoch 24] train_loss(avg per step)=-0.9539 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=4.4549 qwk=('0.5299', '0.5015', '0.4694') averageQWK=0.5003 macroEMD=0.2676 tailR0=('0.1190', '0.1250', '0.1667') tailR0avg=0.1369
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0   10   29    2    0
     0    6   82   33    1
     0    0   41   95    5
     0    0    3   13    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    5    2    0
     0   13   19    7    0
     0   13   56   34    1
     0    6   37  117    3
     0    0    1   11    4
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0   11   40    1    0
     1   13  124   20    0
     0    2   43   65    0
     0    0    0    2    1
[epoch 25] step 2/44: loss=-0.4103 
[epoch 25] step 4/44: loss=-0.4460 
[epoch 25] step 6/44: loss=-0.4671 
[epoch 25] step 8/44: loss=-0.4836 
[epoch 25] step 10/44: loss=-0.4851 
[epoch 25] step 12/44: loss=-0.4890 
[epoch 25] step 14/44: loss=-0.4921 
[epoch 25] step 16/44: loss=-0.4957 
[epoch 25] step 18/44: loss=-0.5009 
[epoch 25] step 20/44: loss=-0.4972 
[epoch 25] step 22/44: loss=-0.4989 
[epoch 25] step 24/44: loss=-0.4966 
[epoch 25] step 26/44: loss=-0.4958 
[epoch 25] step 28/44: loss=-0.4942 
[epoch 25] step 30/44: loss=-0.4944 
[epoch 25] step 32/44: loss=-0.4947 
[epoch 25] step 34/44: loss=-0.4963 
[epoch 25] step 36/44: loss=-0.4979 
[epoch 25] step 38/44: loss=-0.4963 
[epoch 25] step 40/44: loss=-0.4975 
[epoch 25] step 42/44: loss=-0.4983 
[epoch 25] step 44/44: loss=-0.4819 
[epoch 25] train_loss(avg per step)=-0.9638 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=4.7032 qwk=('0.5042', '0.4441', '0.4225') averageQWK=0.4570 macroEMD=0.2734 tailR0=('0.0952', '0.0938', '0.0000') tailR0avg=0.0630
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0    8   27    6    0
     0    5   76   40    1
     0    0   35  103    3
     0    0    1   16    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    2    0
     0   10   21    8    0
     0   12   63   27    2
     0    5   50  102    6
     0    0    2   11    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    8   43    1    0
     0    9  127   22    0
     0    0   52   58    0
     0    0    0    3    0
[epoch 26] step 2/44: loss=-0.5170 
[epoch 26] step 4/44: loss=-0.5379 
[epoch 26] step 6/44: loss=-0.5221 
[epoch 26] step 8/44: loss=-0.5187 
[epoch 26] step 10/44: loss=-0.5170 
[epoch 26] step 12/44: loss=-0.5174 
[epoch 26] step 14/44: loss=-0.5122 
[epoch 26] step 16/44: loss=-0.5108 
[epoch 26] step 18/44: loss=-0.5104 
[epoch 26] step 20/44: loss=-0.5107 
[epoch 26] step 22/44: loss=-0.5107 
[epoch 26] step 24/44: loss=-0.5140 
[epoch 26] step 26/44: loss=-0.5157 
[epoch 26] step 28/44: loss=-0.5128 
[epoch 26] step 30/44: loss=-0.5133 
[epoch 26] step 32/44: loss=-0.5111 
[epoch 26] step 34/44: loss=-0.5124 
[epoch 26] step 36/44: loss=-0.5138 
[epoch 26] step 38/44: loss=-0.5149 
[epoch 26] step 40/44: loss=-0.5155 
[epoch 26] step 42/44: loss=-0.5157 
[epoch 26] step 44/44: loss=-0.5177 
[epoch 26] train_loss(avg per step)=-1.0353 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=5.1380 qwk=('0.4335', '0.3542', '0.3934') averageQWK=0.3937 macroEMD=0.2800 tailR0=('0.1690', '0.0312', '0.0000') tailR0avg=0.0668
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    0    7    2    0
     0    7   26    8    0
     0    1   55   63    3
     0    0   28  112    1
     0    0    1   15    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    5    0
     0    8   18   13    0
     0   10   43   50    1
     0    3   35  125    0
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    5   44    2    1
     0    9  126   23    0
     0    0   51   59    0
     0    0    0    3    0
[epoch 27] step 2/44: loss=-0.5630 
[epoch 27] step 4/44: loss=-0.5330 
[epoch 27] step 6/44: loss=-0.5390 
[epoch 27] step 8/44: loss=-0.5439 
[epoch 27] step 10/44: loss=-0.5417 
[epoch 27] step 12/44: loss=-0.5467 
[epoch 27] step 14/44: loss=-0.5491 
[epoch 27] step 16/44: loss=-0.5464 
[epoch 27] step 18/44: loss=-0.5442 
[epoch 27] step 20/44: loss=-0.5463 
[epoch 27] step 22/44: loss=-0.5450 
[epoch 27] step 24/44: loss=-0.5435 
[epoch 27] step 26/44: loss=-0.5418 
[epoch 27] step 28/44: loss=-0.5419 
[epoch 27] step 30/44: loss=-0.5425 
[epoch 27] step 32/44: loss=-0.5428 
[epoch 27] step 34/44: loss=-0.5418 
[epoch 27] step 36/44: loss=-0.5423 
[epoch 27] step 38/44: loss=-0.5401 
[epoch 27] step 40/44: loss=-0.5407 
[epoch 27] step 42/44: loss=-0.5425 
[epoch 27] step 44/44: loss=-0.5441 
[epoch 27] train_loss(avg per step)=-1.0881 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=5.3321 qwk=('0.4682', '0.4393', '0.4572') averageQWK=0.4549 macroEMD=0.2697 tailR0=('0.0238', '0.0312', '0.1667') tailR0avg=0.0739
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    8   29    4    0
     0    4   75   42    1
     0    0   36  104    1
     0    0    3   17    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    6    2    0
     0   10   19   10    0
     0   13   54   36    1
     0    6   34  123    0
     0    0    2   13    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0   10   41    1    0
     0   12  122   24    0
     0    1   47   62    0
     0    0    0    2    1
[epoch 28] step 2/44: loss=-0.5574 
[epoch 28] step 4/44: loss=-0.5589 
[epoch 28] step 6/44: loss=-0.5482 
[epoch 28] step 8/44: loss=-0.5418 
[epoch 28] step 10/44: loss=-0.5437 
[epoch 28] step 12/44: loss=-0.5466 
[epoch 28] step 14/44: loss=-0.5460 
[epoch 28] step 16/44: loss=-0.5476 
[epoch 28] step 18/44: loss=-0.5491 
[epoch 28] step 20/44: loss=-0.5496 
[epoch 28] step 22/44: loss=-0.5516 
[epoch 28] step 24/44: loss=-0.5488 
[epoch 28] step 26/44: loss=-0.5499 
[epoch 28] step 28/44: loss=-0.5499 
[epoch 28] step 30/44: loss=-0.5478 
[epoch 28] step 32/44: loss=-0.5473 
[epoch 28] step 34/44: loss=-0.5475 
[epoch 28] step 36/44: loss=-0.5488 
[epoch 28] step 38/44: loss=-0.5499 
[epoch 28] step 40/44: loss=-0.5485 
[epoch 28] step 42/44: loss=-0.5491 
[epoch 28] step 44/44: loss=-0.5496 
[epoch 28] train_loss(avg per step)=-1.0993 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=6.1051 qwk=('0.4667', '0.4164', '0.3874') averageQWK=0.4235 macroEMD=0.2678 tailR0=('0.0238', '0.0312', '0.1667') tailR0avg=0.0739
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    7    1    0
     0    8   28    5    0
     0    1   67   53    1
     0    0   32  109    0
     0    0    2   18    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    8    2    0
     0    7   20   12    0
     0   10   51   42    1
     0    2   34  127    0
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    6   45    1    0
     0    7  135   16    0
     0    0   62   47    1
     0    0    1    1    1
[epoch 29] step 2/44: loss=-0.5533 
[epoch 29] step 4/44: loss=-0.5535 
[epoch 29] step 6/44: loss=-0.5529 
[epoch 29] step 8/44: loss=-0.5583 
[epoch 29] step 10/44: loss=-0.5637 
[epoch 29] step 12/44: loss=-0.5662 
[epoch 29] step 14/44: loss=-0.5638 
[epoch 29] step 16/44: loss=-0.5638 
[epoch 29] step 18/44: loss=-0.5643 
[epoch 29] step 20/44: loss=-0.5647 
[epoch 29] step 22/44: loss=-0.5643 
[epoch 29] step 24/44: loss=-0.5652 
[epoch 29] step 26/44: loss=-0.5664 
[epoch 29] step 28/44: loss=-0.5664 
[epoch 29] step 30/44: loss=-0.5659 
[epoch 29] step 32/44: loss=-0.5657 
[epoch 29] step 34/44: loss=-0.5657 
[epoch 29] step 36/44: loss=-0.5641 
[epoch 29] step 38/44: loss=-0.5636 
[epoch 29] step 40/44: loss=-0.5631 
[epoch 29] step 42/44: loss=-0.5606 
[epoch 29] step 44/44: loss=-0.5619 
[epoch 29] train_loss(avg per step)=-1.1238 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=6.0221 qwk=('0.4692', '0.3809', '0.4400') averageQWK=0.4300 macroEMD=0.2695 tailR0=('0.0476', '0.0312', '0.1667') tailR0avg=0.0818
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    8   27    6    0
     0    4   65   52    1
     0    0   31  107    3
     0    0    1   18    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    2    6    0
     0   10   14   15    0
     0   12   35   56    1
     0    4   19  140    0
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    7   44    1    0
     0    9  130   19    0
     0    0   53   56    1
     0    0    0    2    1
[epoch 30] step 2/44: loss=-0.5808 
[epoch 30] step 4/44: loss=-0.5763 
[epoch 30] step 6/44: loss=-0.5651 
[epoch 30] step 8/44: loss=-0.5695 
[epoch 30] step 10/44: loss=-0.5631 
[epoch 30] step 12/44: loss=-0.5658 
[epoch 30] step 14/44: loss=-0.5664 
[epoch 30] step 16/44: loss=-0.5656 
[epoch 30] step 18/44: loss=-0.5635 
[epoch 30] step 20/44: loss=-0.5646 
[epoch 30] step 22/44: loss=-0.5650 
[epoch 30] step 24/44: loss=-0.5652 
[epoch 30] step 26/44: loss=-0.5648 
[epoch 30] step 28/44: loss=-0.5651 
[epoch 30] step 30/44: loss=-0.5649 
[epoch 30] step 32/44: loss=-0.5659 
[epoch 30] step 34/44: loss=-0.5650 
[epoch 30] step 36/44: loss=-0.5662 
[epoch 30] step 38/44: loss=-0.5670 
[epoch 30] step 40/44: loss=-0.5674 
[epoch 30] step 42/44: loss=-0.5672 
[epoch 30] step 44/44: loss=-0.5678 
[epoch 30] train_loss(avg per step)=-1.1356 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=6.1701 qwk=('0.4759', '0.3816', '0.3481') averageQWK=0.4019 macroEMD=0.2696 tailR0=('0.0476', '0.0312', '0.1667') tailR0avg=0.0818
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    8   29    4    0
     0    4   73   43    2
     0    0   35  105    1
     0    0    2   17    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    4    0
     0    7   20   12    0
     0   10   46   47    1
     0    3   35  125    0
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   48    1    1
     0    4  138   16    0
     0    0   59   50    1
     0    0    1    1    1
[epoch 31] step 2/44: loss=-0.5844 
[epoch 31] step 4/44: loss=-0.5796 
[epoch 31] step 6/44: loss=-0.5821 
[epoch 31] step 8/44: loss=-0.5837 
[epoch 31] step 10/44: loss=-0.5836 
[epoch 31] step 12/44: loss=-0.5776 
[epoch 31] step 14/44: loss=-0.5774 
[epoch 31] step 16/44: loss=-0.5750 
[epoch 31] step 18/44: loss=-0.5734 
[epoch 31] step 20/44: loss=-0.5742 
[epoch 31] step 22/44: loss=-0.5716 
[epoch 31] step 24/44: loss=-0.5715 
[epoch 31] step 26/44: loss=-0.5717 
[epoch 31] step 28/44: loss=-0.5719 
[epoch 31] step 30/44: loss=-0.5699 
[epoch 31] step 32/44: loss=-0.5702 
[epoch 31] step 34/44: loss=-0.5708 
[epoch 31] step 36/44: loss=-0.5719 
[epoch 31] step 38/44: loss=-0.5728 
[epoch 31] step 40/44: loss=-0.5727 
[epoch 31] step 42/44: loss=-0.5732 
[epoch 31] step 44/44: loss=-0.5734 
[epoch 31] train_loss(avg per step)=-1.1468 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=6.1406 qwk=('0.4681', '0.3879', '0.3817') averageQWK=0.4125 macroEMD=0.2691 tailR0=('0.0952', '0.0312', '0.0000') tailR0avg=0.0422
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    8   26    7    0
     0    2   64   54    2
     0    0   32  105    4
     0    0    0   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    4    0
     0    9   18   12    0
     0   10   42   51    1
     0    5   28  130    0
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    2   48    1    1
     0    7  127   24    0
     0    0   49   61    0
     0    0    0    3    0
[epoch 32] step 2/44: loss=-0.5536 
[epoch 32] step 4/44: loss=-0.5685 
[epoch 32] step 6/44: loss=-0.5705 
[epoch 32] step 8/44: loss=-0.5695 
[epoch 32] step 10/44: loss=-0.5703 
[epoch 32] step 12/44: loss=-0.5715 
[epoch 32] step 14/44: loss=-0.5740 
[epoch 32] step 16/44: loss=-0.5736 
[epoch 32] step 18/44: loss=-0.5746 
[epoch 32] step 20/44: loss=-0.5750 
[epoch 32] step 22/44: loss=-0.5746 
[epoch 32] step 24/44: loss=-0.5732 
[epoch 32] step 26/44: loss=-0.5748 
[epoch 32] step 28/44: loss=-0.5759 
[epoch 32] step 30/44: loss=-0.5772 
[epoch 32] step 32/44: loss=-0.5768 
[epoch 32] step 34/44: loss=-0.5753 
[epoch 32] step 36/44: loss=-0.5753 
[epoch 32] step 38/44: loss=-0.5762 
[epoch 32] step 40/44: loss=-0.5765 
[epoch 32] step 42/44: loss=-0.5773 
[epoch 32] step 44/44: loss=-0.5759 
[epoch 32] train_loss(avg per step)=-1.1518 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=6.0919 qwk=('0.4816', '0.3834', '0.3920') averageQWK=0.4190 macroEMD=0.2684 tailR0=('0.0952', '0.0312', '0.0000') tailR0avg=0.0422
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    9   25    7    0
     0    6   60   55    1
     0    0   30  108    3
     0    0    0   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    4    5    0
     0   10   17   12    0
     0   11   41   51    1
     0    4   30  129    0
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    4   46    1    1
     0    7  129   22    0
     0    1   50   59    0
     0    0    0    3    0
[epoch 33] step 2/44: loss=-0.5750 
[epoch 33] step 4/44: loss=-0.5814 
[epoch 33] step 6/44: loss=-0.5813 
[epoch 33] step 8/44: loss=-0.5829 
[epoch 33] step 10/44: loss=-0.5844 
[epoch 33] step 12/44: loss=-0.5791 
[epoch 33] step 14/44: loss=-0.5799 
[epoch 33] step 16/44: loss=-0.5815 
[epoch 33] step 18/44: loss=-0.5808 
[epoch 33] step 20/44: loss=-0.5797 
[epoch 33] step 22/44: loss=-0.5799 
[epoch 33] step 24/44: loss=-0.5807 
[epoch 33] step 26/44: loss=-0.5811 
[epoch 33] step 28/44: loss=-0.5818 
[epoch 33] step 30/44: loss=-0.5826 
[epoch 33] step 32/44: loss=-0.5832 
[epoch 33] step 34/44: loss=-0.5821 
[epoch 33] step 36/44: loss=-0.5818 
[epoch 33] step 38/44: loss=-0.5819 
[epoch 33] step 40/44: loss=-0.5820 
[epoch 33] step 42/44: loss=-0.5820 
[epoch 33] step 44/44: loss=-0.5829 
[epoch 33] train_loss(avg per step)=-1.1658 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=6.2058 qwk=('0.4896', '0.4343', '0.3718') averageQWK=0.4319 macroEMD=0.2659 tailR0=('0.0714', '0.0312', '0.0000') tailR0avg=0.0342
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    8   28    5    0
     0    3   77   40    2
     0    0   35  104    2
     0    0    1   17    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    6    3    0
     0   11   19    9    0
     0   11   51   41    1
     0    5   34  124    0
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1   11    0    0
     0    3   47    1    1
     0    8  130   20    0
     0    1   51   58    0
     0    0    0    3    0
[epoch 34] step 2/44: loss=-0.5864 
[epoch 34] step 4/44: loss=-0.5857 
[epoch 34] step 6/44: loss=-0.5817 
[epoch 34] step 8/44: loss=-0.5808 
[epoch 34] step 10/44: loss=-0.5822 
[epoch 34] step 12/44: loss=-0.5819 
[epoch 34] step 14/44: loss=-0.5819 
[epoch 34] step 16/44: loss=-0.5823 
[epoch 34] step 18/44: loss=-0.5829 
[epoch 34] step 20/44: loss=-0.5835 
[epoch 34] step 22/44: loss=-0.5849 
[epoch 34] step 24/44: loss=-0.5852 
[epoch 34] step 26/44: loss=-0.5862 
[epoch 34] step 28/44: loss=-0.5864 
[epoch 34] step 30/44: loss=-0.5866 
[epoch 34] step 32/44: loss=-0.5869 
[epoch 34] step 34/44: loss=-0.5867 
[epoch 34] step 36/44: loss=-0.5863 
[epoch 34] step 38/44: loss=-0.5867 
[epoch 34] step 40/44: loss=-0.5871 
[epoch 34] step 42/44: loss=-0.5870 
[epoch 34] step 44/44: loss=-0.5853 
[epoch 34] train_loss(avg per step)=-1.1707 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=6.2216 qwk=('0.4816', '0.4078', '0.4300') averageQWK=0.4398 macroEMD=0.2663 tailR0=('0.0952', '0.0312', '0.0000') tailR0avg=0.0422
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    8   26    7    0
     0    7   64   50    1
     0    0   32  106    3
     0    0    0   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    4    0
     0    8   20   11    0
     0    9   45   49    1
     0    2   31  130    0
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    7   44    1    0
     0    8  127   23    0
     0    1   49   60    0
     0    0    0    3    0
[epoch 35] step 2/44: loss=-0.5937 
[epoch 35] step 4/44: loss=-0.5917 
[epoch 35] step 6/44: loss=-0.5820 
[epoch 35] step 8/44: loss=-0.5829 
[epoch 35] step 10/44: loss=-0.5846 
[epoch 35] step 12/44: loss=-0.5817 
[epoch 35] step 14/44: loss=-0.5825 
[epoch 35] step 16/44: loss=-0.5824 
[epoch 35] step 18/44: loss=-0.5835 
[epoch 35] step 20/44: loss=-0.5838 
[epoch 35] step 22/44: loss=-0.5853 
[epoch 35] step 24/44: loss=-0.5859 
[epoch 35] step 26/44: loss=-0.5860 
[epoch 35] step 28/44: loss=-0.5865 
[epoch 35] step 30/44: loss=-0.5857 
[epoch 35] step 32/44: loss=-0.5855 
[epoch 35] step 34/44: loss=-0.5858 
[epoch 35] step 36/44: loss=-0.5859 
[epoch 35] step 38/44: loss=-0.5858 
[epoch 35] step 40/44: loss=-0.5865 
[epoch 35] step 42/44: loss=-0.5857 
[epoch 35] step 44/44: loss=-0.5862 
[epoch 35] train_loss(avg per step)=-1.1724 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=6.2661 qwk=('0.5023', '0.4135', '0.4020') averageQWK=0.4393 macroEMD=0.2663 tailR0=('0.0952', '0.0312', '0.0000') tailR0avg=0.0422
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    8    1    0
     0    8   28    5    0
     0    7   67   47    1
     0    0   32  106    3
     0    0    0   17    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    5    4    0
     0    8   20   11    0
     0    9   49   45    1
     0    2   32  129    0
     0    0    1   14    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2   10    0    0
     0    3   48    1    0
     0    8  128   22    0
     0    1   51   57    1
     0    0    0    3    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-0-conf_gating-0-reassignment-0/fold1/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-0-conf_gating-0-reassignment-0/fold1/metrics.json
Done.
