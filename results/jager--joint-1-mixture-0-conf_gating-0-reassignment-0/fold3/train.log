[tok] class=PreTrainedTokenizerFast fast=True src=tokenizer.json
[info] minority classes per head (from TRAIN): [[1, 5], [1, 5], [1, 5]]
>> Grad checkpointing: False
[epoch 1] step 2/44: loss=6.2062 
[epoch 1] step 4/44: loss=6.3926 
[epoch 1] step 6/44: loss=6.1891 
[epoch 1] step 8/44: loss=6.0058 
[epoch 1] step 10/44: loss=6.1441 
[epoch 1] step 12/44: loss=6.1575 
[epoch 1] step 14/44: loss=6.1024 
[epoch 1] step 16/44: loss=6.1124 
[epoch 1] step 18/44: loss=6.1800 
[epoch 1] step 20/44: loss=6.2183 
[epoch 1] step 22/44: loss=6.2217 
[epoch 1] step 24/44: loss=6.2143 
[epoch 1] step 26/44: loss=6.2203 
[epoch 1] step 28/44: loss=6.1744 
[epoch 1] step 30/44: loss=6.1161 
[epoch 1] step 32/44: loss=6.0932 
[epoch 1] step 34/44: loss=6.0436 
[epoch 1] step 36/44: loss=6.0092 
[epoch 1] step 38/44: loss=5.9362 
[epoch 1] step 40/44: loss=5.8752 
[epoch 1] step 42/44: loss=5.7934 
[epoch 1] step 44/44: loss=5.7120 
[epoch 1] train_loss(avg per step)=11.4241 lambda[min,max]=[0.526261,1.000000]
[epoch 1] val_loss=8.1567 qwk=('-0.1289', '-0.0324', '0.0560') averageQWK=-0.0351 macroEMD=0.3912 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    7    0
     0   18    0   22    0
     0   57    0   71    0
     0   72    0   50    0
     0   14    0   13    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     8    0   30   10    0
    34    0   49   30    0
    41    0   69   38    0
     3    0    3    4    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    4   67    0    0
     0    1  150    0    0
     0    0   98    1    0
     0    0    3    0    0
[epoch 2] step 2/44: loss=4.2482 
[epoch 2] step 4/44: loss=3.7744 
[epoch 2] step 6/44: loss=3.7328 
[epoch 2] step 8/44: loss=3.4840 
[epoch 2] step 10/44: loss=3.5588 
[epoch 2] step 12/44: loss=3.5037 
[epoch 2] step 14/44: loss=3.4072 
[epoch 2] step 16/44: loss=3.2731 
[epoch 2] step 18/44: loss=3.1554 
[epoch 2] step 20/44: loss=3.0714 
[epoch 2] step 22/44: loss=2.9983 
[epoch 2] step 24/44: loss=2.9601 
[epoch 2] step 26/44: loss=2.9138 
[epoch 2] step 28/44: loss=2.8681 
[epoch 2] step 30/44: loss=2.8352 
[epoch 2] step 32/44: loss=2.8120 
[epoch 2] step 34/44: loss=2.7745 
[epoch 2] step 36/44: loss=2.7349 
[epoch 2] step 38/44: loss=2.7058 
[epoch 2] step 40/44: loss=2.6734 
[epoch 2] step 42/44: loss=2.6539 
[epoch 2] step 44/44: loss=2.6342 
[epoch 2] train_loss(avg per step)=5.2685 lambda[min,max]=[0.504457,1.000000]
[epoch 2] val_loss=2.8441 qwk=('0.4880', '0.4206', '0.4801') averageQWK=0.4629 macroEMD=0.3735 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    7    1    0    0
     0   20   18    2    0
     0   41   50   37    0
     0   14   32   76    0
     0    1    3   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    6    0    0
     0    0   41    7    0
     0    0   63   50    0
     0    0   33  115    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    5   63    3    0
     0    0  106   45    0
     0    0   25   74    0
     0    0    0    3    0
[epoch 3] step 2/44: loss=2.1395 
[epoch 3] step 4/44: loss=2.0456 
[epoch 3] step 6/44: loss=2.0821 
[epoch 3] step 8/44: loss=1.9620 
[epoch 3] step 10/44: loss=1.9169 
[epoch 3] step 12/44: loss=1.9120 
[epoch 3] step 14/44: loss=1.9468 
[epoch 3] step 16/44: loss=1.9421 
[epoch 3] step 18/44: loss=1.9102 
[epoch 3] step 20/44: loss=1.8945 
[epoch 3] step 22/44: loss=1.8644 
[epoch 3] step 24/44: loss=1.9066 
[epoch 3] step 26/44: loss=1.8872 
[epoch 3] step 28/44: loss=1.8642 
[epoch 3] step 30/44: loss=1.8493 
[epoch 3] step 32/44: loss=1.8365 
[epoch 3] step 34/44: loss=1.8217 
[epoch 3] step 36/44: loss=1.8003 
[epoch 3] step 38/44: loss=1.7842 
[epoch 3] step 40/44: loss=1.7686 
[epoch 3] step 42/44: loss=1.7495 
[epoch 3] step 44/44: loss=1.7265 
[epoch 3] train_loss(avg per step)=3.4530 lambda[min,max]=[0.505699,1.000000]
[epoch 3] val_loss=2.7423 qwk=('0.3368', '0.4712', '0.3226') averageQWK=0.3769 macroEMD=0.3489 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    2    6    0    0
     0    2   38    0    0
     0    0  118   10    0
     0    0   85   37    0
     0    0   10   17    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   29    3   16    0
     0   33    8   72    0
     0   15    3  130    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    2   69    0    0
     0    0  144    7    0
     0    0   65   34    0
     0    0    1    2    0
[epoch 4] step 2/44: loss=1.6734 
[epoch 4] step 4/44: loss=1.6561 
[epoch 4] step 6/44: loss=1.5974 
[epoch 4] step 8/44: loss=1.5660 
[epoch 4] step 10/44: loss=1.5005 
[epoch 4] step 12/44: loss=1.5440 
[epoch 4] step 14/44: loss=1.5097 
[epoch 4] step 16/44: loss=1.5085 
[epoch 4] step 18/44: loss=1.5015 
[epoch 4] step 20/44: loss=1.5093 
[epoch 4] step 22/44: loss=1.5039 
[epoch 4] step 24/44: loss=1.5072 
[epoch 4] step 26/44: loss=1.4943 
[epoch 4] step 28/44: loss=1.4969 
[epoch 4] step 30/44: loss=1.4842 
[epoch 4] step 32/44: loss=1.4809 
[epoch 4] step 34/44: loss=1.4729 
[epoch 4] step 36/44: loss=1.4640 
[epoch 4] step 38/44: loss=1.4638 
[epoch 4] step 40/44: loss=1.4527 
[epoch 4] step 42/44: loss=1.4411 
[epoch 4] step 44/44: loss=1.4276 
[epoch 4] train_loss(avg per step)=2.8553 lambda[min,max]=[0.501573,1.000000]
[epoch 4] val_loss=2.8485 qwk=('0.2607', '0.4302', '0.1849') averageQWK=0.2920 macroEMD=0.3445 tailR0=('0.0185', '0.0000', '0.0000') tailR0avg=0.0062
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    0    0
     0    1   39    0    0
     0    0  124    4    0
     0    0   95   27    0
     0    0   17    9    1
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    2   37    9    0
     0    0   70   43    0
     0    0   41  107    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    0    1    0    0
     0    0   71    0    0
     0    0  150    1    0
     0    0   78   21    0
     0    0    3    0    0
[epoch 5] step 2/44: loss=1.2383 
[epoch 5] step 4/44: loss=1.3991 
[epoch 5] step 6/44: loss=1.3993 
[epoch 5] step 8/44: loss=1.3190 
[epoch 5] step 10/44: loss=1.3064 
[epoch 5] step 12/44: loss=1.2895 
[epoch 5] step 14/44: loss=1.2677 
[epoch 5] step 16/44: loss=1.2479 
[epoch 5] step 18/44: loss=1.2621 
[epoch 5] step 20/44: loss=1.2330 
[epoch 5] step 22/44: loss=1.2442 
[epoch 5] step 24/44: loss=1.2558 
[epoch 5] step 26/44: loss=1.2463 
[epoch 5] step 28/44: loss=1.2407 
[epoch 5] step 30/44: loss=1.2512 
[epoch 5] step 32/44: loss=1.2745 
[epoch 5] step 34/44: loss=1.2796 
[epoch 5] step 36/44: loss=1.2800 
[epoch 5] step 38/44: loss=1.2758 
[epoch 5] step 40/44: loss=1.2615 
[epoch 5] step 42/44: loss=1.2621 
[epoch 5] step 44/44: loss=1.2568 
[epoch 5] train_loss(avg per step)=2.5136 lambda[min,max]=[0.501566,1.000000]
[epoch 5] val_loss=2.4318 qwk=('0.2991', '0.5354', '0.6004') averageQWK=0.4783 macroEMD=0.3274 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    2   38    0    0
     0    0  123    5    0
     0    0   88   34    0
     0    0   18    9    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   28   15    5    0
     0   36   51   26    0
     0    9   50   89    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   33   35    3    0
     0   15   97   39    0
     0    0   27   72    0
     0    0    1    2    0
[epoch 6] step 2/44: loss=1.0209 
[epoch 6] step 4/44: loss=0.9653 
[epoch 6] step 6/44: loss=1.0091 
[epoch 6] step 8/44: loss=0.9767 
[epoch 6] step 10/44: loss=0.9664 
[epoch 6] step 12/44: loss=0.9534 
[epoch 6] step 14/44: loss=0.9956 
[epoch 6] step 16/44: loss=1.0101 
[epoch 6] step 18/44: loss=1.0013 
[epoch 6] step 20/44: loss=0.9933 
[epoch 6] step 22/44: loss=0.9874 
[epoch 6] step 24/44: loss=0.9920 
[epoch 6] step 26/44: loss=0.9892 
[epoch 6] step 28/44: loss=0.9962 
[epoch 6] step 30/44: loss=0.9906 
[epoch 6] step 32/44: loss=0.9884 
[epoch 6] step 34/44: loss=0.9871 
[epoch 6] step 36/44: loss=0.9899 
[epoch 6] step 38/44: loss=0.9943 
[epoch 6] step 40/44: loss=0.9972 
[epoch 6] step 42/44: loss=0.9981 
[epoch 6] step 44/44: loss=1.0032 
[epoch 6] train_loss(avg per step)=2.0065 lambda[min,max]=[0.503937,1.000000]
[epoch 6] val_loss=3.0232 qwk=('0.5250', '0.4954', '0.4114') averageQWK=0.4773 macroEMD=0.3309 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   18   22    0    0
     0   23   90   15    0
     0    1   68   53    0
     0    0    7   20    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   29   15    4    0
     0   30   66   17    0
     0   15   59   74    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   69    2    0    0
     0  111   28   12    0
     0   29   31   39    0
     0    0    2    1    0
[epoch 7] step 2/44: loss=1.0660 
[epoch 7] step 4/44: loss=0.9808 
[epoch 7] step 6/44: loss=0.9604 
[epoch 7] step 8/44: loss=0.9705 
[epoch 7] step 10/44: loss=0.9398 
[epoch 7] step 12/44: loss=0.9151 
[epoch 7] step 14/44: loss=0.9305 
[epoch 7] step 16/44: loss=0.9108 
[epoch 7] step 18/44: loss=0.9085 
[epoch 7] step 20/44: loss=0.8819 
[epoch 7] step 22/44: loss=0.8792 
[epoch 7] step 24/44: loss=0.8712 
[epoch 7] step 26/44: loss=0.8601 
[epoch 7] step 28/44: loss=0.8577 
[epoch 7] step 30/44: loss=0.8633 
[epoch 7] step 32/44: loss=0.8630 
[epoch 7] step 34/44: loss=0.8587 
[epoch 7] step 36/44: loss=0.8570 
[epoch 7] step 38/44: loss=0.8603 
[epoch 7] step 40/44: loss=0.8616 
[epoch 7] step 42/44: loss=0.8656 
[epoch 7] step 44/44: loss=0.8552 
[epoch 7] train_loss(avg per step)=1.7105 lambda[min,max]=[0.509422,1.000000]
[epoch 7] val_loss=2.6561 qwk=('0.5382', '0.3635', '0.4504') averageQWK=0.4507 macroEMD=0.3097 tailR0=('0.0000', '0.0500', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   11   24    5    0
     0    8   82   38    0
     0    0   35   87    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     1    7   40    0    0
     0    3  108    2    0
     0    0  113   35    0
     0    0    6    3    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   16   55    0    0
     0    4  136   11    0
     0    0   59   40    0
     0    0    2    1    0
[epoch 8] step 2/44: loss=0.7745 
[epoch 8] step 4/44: loss=0.7792 
[epoch 8] step 6/44: loss=0.7773 
[epoch 8] step 8/44: loss=0.7792 
[epoch 8] step 10/44: loss=0.7493 
[epoch 8] step 12/44: loss=0.7512 
[epoch 8] step 14/44: loss=0.7566 
[epoch 8] step 16/44: loss=0.7552 
[epoch 8] step 18/44: loss=0.7472 
[epoch 8] step 20/44: loss=0.7279 
[epoch 8] step 22/44: loss=0.7252 
[epoch 8] step 24/44: loss=0.7192 
[epoch 8] step 26/44: loss=0.7315 
[epoch 8] step 28/44: loss=0.7258 
[epoch 8] step 30/44: loss=0.7190 
[epoch 8] step 32/44: loss=0.7224 
[epoch 8] step 34/44: loss=0.7147 
[epoch 8] step 36/44: loss=0.7150 
[epoch 8] step 38/44: loss=0.7127 
[epoch 8] step 40/44: loss=0.7067 
[epoch 8] step 42/44: loss=0.7123 
[epoch 8] step 44/44: loss=0.7116 
[epoch 8] train_loss(avg per step)=1.4231 lambda[min,max]=[0.502993,1.000000]
[epoch 8] val_loss=2.6942 qwk=('0.5688', '0.5210', '0.4987') averageQWK=0.5295 macroEMD=0.2980 tailR0=('0.0926', '0.3333', '0.0000') tailR0avg=0.1420
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   10   27    3    0
     0    5   87   35    1
     0    0   40   76    6
     0    0    3   19    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    0    0
     4   23   11    9    1
     0   29   41   39    4
     0    9   35  102    2
     0    0    1    4    5
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   13   52    5    0
     0    3   95   53    0
     0    0   24   75    0
     0    0    1    2    0
[epoch 9] step 2/44: loss=0.5493 
[epoch 9] step 4/44: loss=0.6647 
[epoch 9] step 6/44: loss=0.6741 
[epoch 9] step 8/44: loss=0.6509 
[epoch 9] step 10/44: loss=0.6474 
[epoch 9] step 12/44: loss=0.6041 
[epoch 9] step 14/44: loss=0.5938 
[epoch 9] step 16/44: loss=0.5921 
[epoch 9] step 18/44: loss=0.5727 
[epoch 9] step 20/44: loss=0.5685 
[epoch 9] step 22/44: loss=0.6004 
[epoch 9] step 24/44: loss=0.6150 
[epoch 9] step 26/44: loss=0.6288 
[epoch 9] step 28/44: loss=0.6338 
[epoch 9] step 30/44: loss=0.6338 
[epoch 9] step 32/44: loss=0.6276 
[epoch 9] step 34/44: loss=0.6208 
[epoch 9] step 36/44: loss=0.6104 
[epoch 9] step 38/44: loss=0.6058 
[epoch 9] step 40/44: loss=0.5983 
[epoch 9] step 42/44: loss=0.5992 
[epoch 9] step 44/44: loss=0.5951 
[epoch 9] train_loss(avg per step)=1.1901 lambda[min,max]=[0.502787,1.000000]
[epoch 9] val_loss=2.5742 qwk=('0.4946', '0.4395', '0.4942') averageQWK=0.4761 macroEMD=0.2899 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    6   27    7    0
     0    2   78   48    0
     0    0   35   87    0
     0    0    2   25    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0    6   32   10    0
     0    2   61   50    0
     0    0   41  107    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   27   13    0
     0   17   62   72    0
     0    1   17   81    0
     0    0    0    3    0
[epoch 10] step 2/44: loss=0.7271 
[epoch 10] step 4/44: loss=0.6515 
[epoch 10] step 6/44: loss=0.5187 
[epoch 10] step 8/44: loss=0.5128 
[epoch 10] step 10/44: loss=0.4967 
[epoch 10] step 12/44: loss=0.4889 
[epoch 10] step 14/44: loss=0.4881 
[epoch 10] step 16/44: loss=0.4979 
[epoch 10] step 18/44: loss=0.4755 
[epoch 10] step 20/44: loss=0.5018 
[epoch 10] step 22/44: loss=0.5307 
[epoch 10] step 24/44: loss=0.5386 
[epoch 10] step 26/44: loss=0.5342 
[epoch 10] step 28/44: loss=0.5484 
[epoch 10] step 30/44: loss=0.5751 
[epoch 10] step 32/44: loss=0.5733 
[epoch 10] step 34/44: loss=0.5591 
[epoch 10] step 36/44: loss=0.5537 
[epoch 10] step 38/44: loss=0.5632 
[epoch 10] step 40/44: loss=0.5520 
[epoch 10] step 42/44: loss=0.5425 
[epoch 10] step 44/44: loss=0.5333 
[epoch 10] train_loss(avg per step)=1.0666 lambda[min,max]=[0.500263,1.000000]
[epoch 10] val_loss=2.3816 qwk=('0.4715', '0.4912', '0.5181') averageQWK=0.4936 macroEMD=0.2904 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    5    0    0
     1    3   33    3    0
     0    0   98   30    0
     0    0   48   74    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    0    0    0
     0   11   27   10    0
     0    7   56   50    0
     0    1   37  110    0
     0    0    1    9    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   29   42    0    0
     0    8  127   16    0
     0    0   58   41    0
     0    0    2    1    0
[epoch 11] step 2/44: loss=0.5179 
[epoch 11] step 4/44: loss=0.4435 
[epoch 11] step 6/44: loss=0.4467 
[epoch 11] step 8/44: loss=0.4248 
[epoch 11] step 10/44: loss=0.3966 
[epoch 11] step 12/44: loss=0.3819 
[epoch 11] step 14/44: loss=0.3537 
[epoch 11] step 16/44: loss=0.3501 
[epoch 11] step 18/44: loss=0.3495 
[epoch 11] step 20/44: loss=0.3340 
[epoch 11] step 22/44: loss=0.3422 
[epoch 11] step 24/44: loss=0.3404 
[epoch 11] step 26/44: loss=0.3493 
[epoch 11] step 28/44: loss=0.3401 
[epoch 11] step 30/44: loss=0.3396 
[epoch 11] step 32/44: loss=0.3419 
[epoch 11] step 34/44: loss=0.3373 
[epoch 11] step 36/44: loss=0.3300 
[epoch 11] step 38/44: loss=0.3212 
[epoch 11] step 40/44: loss=0.3240 
[epoch 11] step 42/44: loss=0.3191 
[epoch 11] step 44/44: loss=0.3180 
[epoch 11] train_loss(avg per step)=0.6360 lambda[min,max]=[0.500312,1.000000]
[epoch 11] val_loss=2.5711 qwk=('0.4794', '0.4725', '0.4922') averageQWK=0.4814 macroEMD=0.2801 tailR0=('0.0000', '0.0000', '0.0000') tailR0avg=0.0000
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    4   32    4    0
     0    3   90   35    0
     0    0   45   77    0
     0    0    4   23    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    7   29   12    0
     0    4   56   53    0
     0    0   32  116    0
     0    0    0   10    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   17   53    1    0
     0    4  127   20    0
     0    0   47   52    0
     0    0    2    1    0
[epoch 12] step 2/44: loss=0.0121 
[epoch 12] step 4/44: loss=0.1305 
[epoch 12] step 6/44: loss=0.1882 
[epoch 12] step 8/44: loss=0.2216 
[epoch 12] step 10/44: loss=0.2150 
[epoch 12] step 12/44: loss=0.2534 
[epoch 12] step 14/44: loss=0.2272 
[epoch 12] step 16/44: loss=0.2223 
[epoch 12] step 18/44: loss=0.2236 
[epoch 12] step 20/44: loss=0.2217 
[epoch 12] step 22/44: loss=0.2259 
[epoch 12] step 24/44: loss=0.2258 
[epoch 12] step 26/44: loss=0.2310 
[epoch 12] step 28/44: loss=0.2317 
[epoch 12] step 30/44: loss=0.2412 
[epoch 12] step 32/44: loss=0.2344 
[epoch 12] step 34/44: loss=0.2282 
[epoch 12] step 36/44: loss=0.2205 
[epoch 12] step 38/44: loss=0.2081 
[epoch 12] step 40/44: loss=0.2099 
[epoch 12] step 42/44: loss=0.2037 
[epoch 12] step 44/44: loss=0.1956 
[epoch 12] train_loss(avg per step)=0.3912 lambda[min,max]=[0.500187,1.000000]
[epoch 12] val_loss=2.8153 qwk=('0.4773', '0.4840', '0.5121') averageQWK=0.4912 macroEMD=0.2760 tailR0=('0.0556', '0.1000', '0.0000') tailR0avg=0.0519
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    1    1    0
     0   10   16   14    0
     0    7   41   80    0
     0    0   12  110    0
     0    0    0   24    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   15   16   17    0
     0    8   37   66    2
     0    1   16  131    0
     0    0    0    8    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   28   35    8    0
     0   10   88   53    0
     0    1   26   72    0
     0    0    1    2    0
[epoch 13] step 2/44: loss=0.1959 
[epoch 13] step 4/44: loss=0.1210 
[epoch 13] step 6/44: loss=0.1048 
[epoch 13] step 8/44: loss=0.1012 
[epoch 13] step 10/44: loss=0.0890 
[epoch 13] step 12/44: loss=0.0751 
[epoch 13] step 14/44: loss=0.0654 
[epoch 13] step 16/44: loss=0.0551 
[epoch 13] step 18/44: loss=0.0634 
[epoch 13] step 20/44: loss=0.0525 
[epoch 13] step 22/44: loss=0.0525 
[epoch 13] step 24/44: loss=0.0427 
[epoch 13] step 26/44: loss=0.0498 
[epoch 13] step 28/44: loss=0.0573 
[epoch 13] step 30/44: loss=0.0533 
[epoch 13] step 32/44: loss=0.0464 
[epoch 13] step 34/44: loss=0.0499 
[epoch 13] step 36/44: loss=0.0500 
[epoch 13] step 38/44: loss=0.0529 
[epoch 13] step 40/44: loss=0.0580 
[epoch 13] step 42/44: loss=0.0661 
[epoch 13] step 44/44: loss=0.0732 
[epoch 13] train_loss(avg per step)=0.1463 lambda[min,max]=[0.500086,1.000000]
[epoch 13] val_loss=2.8447 qwk=('0.5017', '0.5112', '0.5342') averageQWK=0.5157 macroEMD=0.2721 tailR0=('0.0625', '0.1333', '0.0000') tailR0avg=0.0653
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     4    6   27    3    0
     1    5  105   17    0
     0    0   58   64    0
     0    0    9   18    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    0    0    0
     1   20   22    5    0
     0   21   71   21    0
     0    3   71   73    1
     0    0    3    6    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   42   29    0    0
     0   39  101   11    0
     0    1   59   39    0
     0    0    2    1    0
[epoch 14] step 2/44: loss=-0.0414 
[epoch 14] step 4/44: loss=-0.0479 
[epoch 14] step 6/44: loss=-0.0466 
[epoch 14] step 8/44: loss=0.0040 
[epoch 14] step 10/44: loss=0.0084 
[epoch 14] step 12/44: loss=-0.0009 
[epoch 14] step 14/44: loss=-0.0008 
[epoch 14] step 16/44: loss=-0.0034 
[epoch 14] step 18/44: loss=-0.0052 
[epoch 14] step 20/44: loss=-0.0057 
[epoch 14] step 22/44: loss=-0.0215 
[epoch 14] step 24/44: loss=-0.0228 
[epoch 14] step 26/44: loss=-0.0162 
[epoch 14] step 28/44: loss=-0.0250 
[epoch 14] step 30/44: loss=-0.0261 
[epoch 14] step 32/44: loss=-0.0221 
[epoch 14] step 34/44: loss=-0.0250 
[epoch 14] step 36/44: loss=-0.0271 
[epoch 14] step 38/44: loss=-0.0177 
[epoch 14] step 40/44: loss=-0.0158 
[epoch 14] step 42/44: loss=-0.0028 
[epoch 14] step 44/44: loss=-0.0046 
[epoch 14] train_loss(avg per step)=-0.0092 lambda[min,max]=[0.500025,1.000000]
[epoch 14] val_loss=2.7855 qwk=('0.5142', '0.4726', '0.5415') averageQWK=0.5094 macroEMD=0.2684 tailR0=('0.0370', '0.1333', '0.0000') tailR0avg=0.0568
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   11   20    9    0
     0    5   64   59    0
     0    0   32   90    0
     0    0    0   25    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     2   10   23   13    0
     1    8   49   55    0
     0    0   32  116    0
     0    0    2    7    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   24   44    2    0
     0    7  115   29    0
     0    0   42   57    0
     0    0    1    2    0
[epoch 15] step 2/44: loss=-0.1369 
[epoch 15] step 4/44: loss=-0.0730 
[epoch 15] step 6/44: loss=-0.0841 
[epoch 15] step 8/44: loss=-0.0504 
[epoch 15] step 10/44: loss=-0.0653 
[epoch 15] step 12/44: loss=-0.0838 
[epoch 15] step 14/44: loss=-0.0997 
[epoch 15] step 16/44: loss=-0.1077 
[epoch 15] step 18/44: loss=-0.1087 
[epoch 15] step 20/44: loss=-0.1162 
[epoch 15] step 22/44: loss=-0.1164 
[epoch 15] step 24/44: loss=-0.1091 
[epoch 15] step 26/44: loss=-0.1100 
[epoch 15] step 28/44: loss=-0.1112 
[epoch 15] step 30/44: loss=-0.1116 
[epoch 15] step 32/44: loss=-0.1078 
[epoch 15] step 34/44: loss=-0.1131 
[epoch 15] step 36/44: loss=-0.1148 
[epoch 15] step 38/44: loss=-0.1161 
[epoch 15] step 40/44: loss=-0.1139 
[epoch 15] step 42/44: loss=-0.1166 
[epoch 15] step 44/44: loss=-0.1221 
[epoch 15] train_loss(avg per step)=-0.2442 lambda[min,max]=[0.500049,1.000000]
[epoch 15] val_loss=2.8720 qwk=('0.4830', '0.4955', '0.5463') averageQWK=0.5083 macroEMD=0.2645 tailR0=('0.0556', '0.1333', '0.0000') tailR0avg=0.0630
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     2    5   23   10    0
     1    5   59   63    0
     0    0   27   94    1
     0    0    1   23    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     2    9   30    7    0
     0    6   61   44    2
     0    0   45  102    1
     0    0    1    8    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   21   49    0    0
     0    6  123   22    0
     0    0   45   54    0
     0    0    1    2    0
[epoch 16] step 2/44: loss=-0.1720 
[epoch 16] step 4/44: loss=-0.1246 
[epoch 16] step 6/44: loss=-0.1530 
[epoch 16] step 8/44: loss=-0.1640 
[epoch 16] step 10/44: loss=-0.1730 
[epoch 16] step 12/44: loss=-0.1754 
[epoch 16] step 14/44: loss=-0.1553 
[epoch 16] step 16/44: loss=-0.1703 
[epoch 16] step 18/44: loss=-0.1755 
[epoch 16] step 20/44: loss=-0.1575 
[epoch 16] step 22/44: loss=-0.1685 
[epoch 16] step 24/44: loss=-0.1719 
[epoch 16] step 26/44: loss=-0.1676 
[epoch 16] step 28/44: loss=-0.1642 
[epoch 16] step 30/44: loss=-0.1733 
[epoch 16] step 32/44: loss=-0.1762 
[epoch 16] step 34/44: loss=-0.1800 
[epoch 16] step 36/44: loss=-0.1791 
[epoch 16] step 38/44: loss=-0.1743 
[epoch 16] step 40/44: loss=-0.1762 
[epoch 16] step 42/44: loss=-0.1758 
[epoch 16] step 44/44: loss=-0.1751 
[epoch 16] train_loss(avg per step)=-0.3502 lambda[min,max]=[0.500019,1.000000]
[epoch 16] val_loss=2.8586 qwk=('0.5421', '0.5546', '0.5258') averageQWK=0.5408 macroEMD=0.2542 tailR0=('0.0995', '0.2167', '0.0000') tailR0avg=0.1054
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     1   11   25    3    0
     1   10   82   35    0
     0    0   45   77    0
     0    0    5   20    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    4    0    0    0
     2   15   22    9    0
     1   11   57   44    0
     0    2   38  108    0
     0    0    0    9    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   32   38    0    0
     0   28  109   14    0
     0    0   56   43    0
     0    0    2    1    0
[epoch 17] step 2/44: loss=-0.2861 
[epoch 17] step 4/44: loss=-0.3035 
[epoch 17] step 6/44: loss=-0.2465 
[epoch 17] step 8/44: loss=-0.2540 
[epoch 17] step 10/44: loss=-0.2529 
[epoch 17] step 12/44: loss=-0.2689 
[epoch 17] step 14/44: loss=-0.2667 
[epoch 17] step 16/44: loss=-0.2658 
[epoch 17] step 18/44: loss=-0.2773 
[epoch 17] step 20/44: loss=-0.2629 
[epoch 17] step 22/44: loss=-0.2623 
[epoch 17] step 24/44: loss=-0.2642 
[epoch 17] step 26/44: loss=-0.2578 
[epoch 17] step 28/44: loss=-0.2669 
[epoch 17] step 30/44: loss=-0.2650 
[epoch 17] step 32/44: loss=-0.2654 
[epoch 17] step 34/44: loss=-0.2690 
[epoch 17] step 36/44: loss=-0.2722 
[epoch 17] step 38/44: loss=-0.2726 
[epoch 17] step 40/44: loss=-0.2774 
[epoch 17] step 42/44: loss=-0.2800 
[epoch 17] step 44/44: loss=-0.2838 
[epoch 17] train_loss(avg per step)=-0.5676 lambda[min,max]=[0.500004,1.000000]
[epoch 17] val_loss=3.1023 qwk=('0.5229', '0.5112', '0.5686') averageQWK=0.5342 macroEMD=0.2561 tailR0=('0.1366', '0.2333', '0.0000') tailR0avg=0.1233
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     2    5   27    6    0
     1    6   78   43    0
     0    0   37   85    0
     0    0    3   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     1   13   26    8    0
     2   10   60   38    3
     0    1   42  103    2
     0    0    2    5    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     2   35   32    2    0
     0   27   85   39    0
     0    2   32   65    0
     0    0    1    2    0
[epoch 18] step 2/44: loss=-0.3169 
[epoch 18] step 4/44: loss=-0.3516 
[epoch 18] step 6/44: loss=-0.3435 
[epoch 18] step 8/44: loss=-0.3214 
[epoch 18] step 10/44: loss=-0.3182 
[epoch 18] step 12/44: loss=-0.3259 
[epoch 18] step 14/44: loss=-0.3282 
[epoch 18] step 16/44: loss=-0.3354 
[epoch 18] step 18/44: loss=-0.3338 
[epoch 18] step 20/44: loss=-0.3311 
[epoch 18] step 22/44: loss=-0.3356 
[epoch 18] step 24/44: loss=-0.3284 
[epoch 18] step 26/44: loss=-0.3270 
[epoch 18] step 28/44: loss=-0.3332 
[epoch 18] step 30/44: loss=-0.3358 
[epoch 18] step 32/44: loss=-0.3281 
[epoch 18] step 34/44: loss=-0.3167 
[epoch 18] step 36/44: loss=-0.3141 
[epoch 18] step 38/44: loss=-0.3146 
[epoch 18] step 40/44: loss=-0.3133 
[epoch 18] step 42/44: loss=-0.3156 
[epoch 18] step 44/44: loss=-0.3160 
[epoch 18] train_loss(avg per step)=-0.6321 lambda[min,max]=[0.500000,1.000000]
[epoch 18] val_loss=3.6435 qwk=('0.4674', '0.4663', '0.5332') averageQWK=0.4890 macroEMD=0.2580 tailR0=('0.0000', '0.0500', '0.0000') tailR0avg=0.0167
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     1    7   23    9    0
     0    7   66   55    0
     0    0   34   88    0
     0    0    2   25    0
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0    6   36    6    0
     0    3   85   25    0
     0    0   60   88    0
     0    0    3    6    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   32   39    0    0
     0   28  103   20    0
     0    2   47   50    0
     0    0    1    2    0
[epoch 19] step 2/44: loss=-0.3662 
[epoch 19] step 4/44: loss=-0.3404 
[epoch 19] step 6/44: loss=-0.3118 
[epoch 19] step 8/44: loss=-0.3312 
[epoch 19] step 10/44: loss=-0.3284 
[epoch 19] step 12/44: loss=-0.3265 
[epoch 19] step 14/44: loss=-0.3373 
[epoch 19] step 16/44: loss=-0.3469 
[epoch 19] step 18/44: loss=-0.3485 
[epoch 19] step 20/44: loss=-0.3523 
[epoch 19] step 22/44: loss=-0.3408 
[epoch 19] step 24/44: loss=-0.3464 
[epoch 19] step 26/44: loss=-0.3456 
[epoch 19] step 28/44: loss=-0.3425 
[epoch 19] step 30/44: loss=-0.3353 
[epoch 19] step 32/44: loss=-0.3402 
[epoch 19] step 34/44: loss=-0.3350 
[epoch 19] step 36/44: loss=-0.3357 
[epoch 19] step 38/44: loss=-0.3357 
[epoch 19] step 40/44: loss=-0.3386 
[epoch 19] step 42/44: loss=-0.3434 
[epoch 19] step 44/44: loss=-0.3431 
[epoch 19] train_loss(avg per step)=-0.6862 lambda[min,max]=[0.500000,1.000000]
[epoch 19] val_loss=3.5099 qwk=('0.4512', '0.4878', '0.5802') averageQWK=0.5064 macroEMD=0.2611 tailR0=('0.1296', '0.1500', '0.0000') tailR0avg=0.0932
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     1    6   30    3    0
     1    5  106   16    0
     0    0   71   47    4
     0    0   11    9    7
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   12   31    4    1
     2    7   85   16    3
     0    1   61   83    3
     0    0    3    4    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   28   43    0    0
     0   12  115   24    0
     0    0   41   58    0
     0    0    1    2    0
[epoch 20] step 2/44: loss=-0.3240 
[epoch 20] step 4/44: loss=-0.3211 
[epoch 20] step 6/44: loss=-0.3388 
[epoch 20] step 8/44: loss=-0.3583 
[epoch 20] step 10/44: loss=-0.3766 
[epoch 20] step 12/44: loss=-0.3744 
[epoch 20] step 14/44: loss=-0.3852 
[epoch 20] step 16/44: loss=-0.3939 
[epoch 20] step 18/44: loss=-0.3967 
[epoch 20] step 20/44: loss=-0.4034 
[epoch 20] step 22/44: loss=-0.4026 
[epoch 20] step 24/44: loss=-0.4061 
[epoch 20] step 26/44: loss=-0.4029 
[epoch 20] step 28/44: loss=-0.4049 
[epoch 20] step 30/44: loss=-0.4050 
[epoch 20] step 32/44: loss=-0.4085 
[epoch 20] step 34/44: loss=-0.4076 
[epoch 20] step 36/44: loss=-0.4054 
[epoch 20] step 38/44: loss=-0.4090 
[epoch 20] step 40/44: loss=-0.4104 
[epoch 20] step 42/44: loss=-0.4122 
[epoch 20] step 44/44: loss=-0.4122 
[epoch 20] train_loss(avg per step)=-0.8243 lambda[min,max]=[0.500001,1.000000]
[epoch 20] val_loss=3.4746 qwk=('0.4993', '0.4563', '0.5780') averageQWK=0.5112 macroEMD=0.2545 tailR0=('0.0741', '0.1000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    8   24    8    0
     0    3   79   46    0
     0    0   37   85    0
     0    0    3   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0   10   30    8    0
     1    4   67   39    2
     0    0   45  102    1
     0    0    3    5    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   42   29    0    0
     0   34   94   23    0
     0    3   41   55    0
     0    0    1    2    0
[epoch 21] step 2/44: loss=-0.4715 
[epoch 21] step 4/44: loss=-0.4317 
[epoch 21] step 6/44: loss=-0.4277 
[epoch 21] step 8/44: loss=-0.4303 
[epoch 21] step 10/44: loss=-0.4304 
[epoch 21] step 12/44: loss=-0.4419 
[epoch 21] step 14/44: loss=-0.4436 
[epoch 21] step 16/44: loss=-0.4490 
[epoch 21] step 18/44: loss=-0.4470 
[epoch 21] step 20/44: loss=-0.4457 
[epoch 21] step 22/44: loss=-0.4380 
[epoch 21] step 24/44: loss=-0.4373 
[epoch 21] step 26/44: loss=-0.4340 
[epoch 21] step 28/44: loss=-0.4342 
[epoch 21] step 30/44: loss=-0.4377 
[epoch 21] step 32/44: loss=-0.4363 
[epoch 21] step 34/44: loss=-0.4338 
[epoch 21] step 36/44: loss=-0.4346 
[epoch 21] step 38/44: loss=-0.4369 
[epoch 21] step 40/44: loss=-0.4397 
[epoch 21] step 42/44: loss=-0.4374 
[epoch 21] step 44/44: loss=-0.4395 
[epoch 21] train_loss(avg per step)=-0.8791 lambda[min,max]=[0.500000,1.000000]
[epoch 21] val_loss=3.4235 qwk=('0.5154', '0.4654', '0.5519') averageQWK=0.5109 macroEMD=0.2527 tailR0=('0.0741', '0.1000', '0.0000') tailR0avg=0.0580
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   10   23    7    0
     1    8   77   42    0
     0    0   42   80    0
     0    0    3   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   14   24   10    0
     1    9   59   42    2
     0    2   45  100    1
     0    0    2    6    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   38   33    0    0
     0   30  102   19    0
     0    1   52   46    0
     0    0    1    2    0
[epoch 22] step 2/44: loss=-0.4998 
[epoch 22] step 4/44: loss=-0.5090 
[epoch 22] step 6/44: loss=-0.4825 
[epoch 22] step 8/44: loss=-0.4761 
[epoch 22] step 10/44: loss=-0.4697 
[epoch 22] step 12/44: loss=-0.4699 
[epoch 22] step 14/44: loss=-0.4688 
[epoch 22] step 16/44: loss=-0.4709 
[epoch 22] step 18/44: loss=-0.4735 
[epoch 22] step 20/44: loss=-0.4764 
[epoch 22] step 22/44: loss=-0.4776 
[epoch 22] step 24/44: loss=-0.4756 
[epoch 22] step 26/44: loss=-0.4725 
[epoch 22] step 28/44: loss=-0.4670 
[epoch 22] step 30/44: loss=-0.4668 
[epoch 22] step 32/44: loss=-0.4670 
[epoch 22] step 34/44: loss=-0.4647 
[epoch 22] step 36/44: loss=-0.4664 
[epoch 22] step 38/44: loss=-0.4683 
[epoch 22] step 40/44: loss=-0.4694 
[epoch 22] step 42/44: loss=-0.4683 
[epoch 22] step 44/44: loss=-0.4675 
[epoch 22] train_loss(avg per step)=-0.9350 lambda[min,max]=[0.500000,1.000000]
[epoch 22] val_loss=3.9453 qwk=('0.4767', '0.5045', '0.5592') averageQWK=0.5135 macroEMD=0.2477 tailR0=('0.2245', '0.1667', '0.0000') tailR0avg=0.1304
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     3    2    3    0    0
     4    6   27    3    0
     4    6   89   29    0
     0    0   60   62    0
     0    0    9   16    2
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    3    1    0    0
     1   17   20   10    0
     2   11   59   41    0
     0    2   44  102    0
     0    0    2    8    0
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   37   33    0    0
     0   29  107   15    0
     0    2   50   47    0
     0    0    1    2    0
[epoch 23] step 2/44: loss=-0.4919 
[epoch 23] step 4/44: loss=-0.4743 
[epoch 23] step 6/44: loss=-0.4779 
[epoch 23] step 8/44: loss=-0.4800 
[epoch 23] step 10/44: loss=-0.4920 
[epoch 23] step 12/44: loss=-0.4872 
[epoch 23] step 14/44: loss=-0.4637 
[epoch 23] step 16/44: loss=-0.4490 
[epoch 23] step 18/44: loss=-0.4562 
[epoch 23] step 20/44: loss=-0.4561 
[epoch 23] step 22/44: loss=-0.4582 
[epoch 23] step 24/44: loss=-0.4582 
[epoch 23] step 26/44: loss=-0.4613 
[epoch 23] step 28/44: loss=-0.4639 
[epoch 23] step 30/44: loss=-0.4623 
[epoch 23] step 32/44: loss=-0.4593 
[epoch 23] step 34/44: loss=-0.4575 
[epoch 23] step 36/44: loss=-0.4571 
[epoch 23] step 38/44: loss=-0.4588 
[epoch 23] step 40/44: loss=-0.4551 
[epoch 23] step 42/44: loss=-0.4544 
[epoch 23] step 44/44: loss=-0.4524 
[epoch 23] train_loss(avg per step)=-0.9048 lambda[min,max]=[0.500000,1.000000]
[epoch 23] val_loss=3.9987 qwk=('0.5425', '0.4065', '0.5403') averageQWK=0.4964 macroEMD=0.2541 tailR0=('0.1366', '0.3000', '0.0000') tailR0avg=0.1455
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    3    0    0
     2    6   26    6    0
     1    4   79   44    0
     0    0   34   87    1
     0    0    2   21    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     1    7   35    2    3
     0    4   91   13    5
     0    0   77   57   14
     0    0    4    0    6
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   33   33    5    0
     0   24   94   33    0
     0    1   35   63    0
     0    0    1    2    0
[epoch 24] step 2/44: loss=-0.4572 
[epoch 24] step 4/44: loss=-0.4671 
[epoch 24] step 6/44: loss=-0.4545 
[epoch 24] step 8/44: loss=-0.4598 
[epoch 24] step 10/44: loss=-0.4622 
[epoch 24] step 12/44: loss=-0.4673 
[epoch 24] step 14/44: loss=-0.4667 
[epoch 24] step 16/44: loss=-0.4704 
[epoch 24] step 18/44: loss=-0.4691 
[epoch 24] step 20/44: loss=-0.4681 
[epoch 24] step 22/44: loss=-0.4629 
[epoch 24] step 24/44: loss=-0.4659 
[epoch 24] step 26/44: loss=-0.4671 
[epoch 24] step 28/44: loss=-0.4698 
[epoch 24] step 30/44: loss=-0.4641 
[epoch 24] step 32/44: loss=-0.4657 
[epoch 24] step 34/44: loss=-0.4662 
[epoch 24] step 36/44: loss=-0.4688 
[epoch 24] step 38/44: loss=-0.4707 
[epoch 24] step 40/44: loss=-0.4738 
[epoch 24] step 42/44: loss=-0.4753 
[epoch 24] step 44/44: loss=-0.4778 
[epoch 24] train_loss(avg per step)=-0.9556 lambda[min,max]=[0.500000,1.000000]
[epoch 24] val_loss=3.8902 qwk=('0.5203', '0.5328', '0.5369') averageQWK=0.5300 macroEMD=0.2454 tailR0=('0.1366', '0.1000', '0.0000') tailR0avg=0.0789
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     3    6   26    5    0
     2    7   85   34    0
     0    0   48   73    1
     0    0    5   18    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   20   18   10    0
     1   20   44   48    0
     0    3   30  115    0
     0    0    1    7    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     3   34   34    0    0
     0   33   97   21    0
     0    3   48   48    0
     0    0    1    2    0
[epoch 25] step 2/44: loss=-0.5143 
[epoch 25] step 4/44: loss=-0.5219 
[epoch 25] step 6/44: loss=-0.5244 
[epoch 25] step 8/44: loss=-0.5315 
[epoch 25] step 10/44: loss=-0.5257 
[epoch 25] step 12/44: loss=-0.5283 
[epoch 25] step 14/44: loss=-0.5300 
[epoch 25] step 16/44: loss=-0.5252 
[epoch 25] step 18/44: loss=-0.5265 
[epoch 25] step 20/44: loss=-0.5262 
[epoch 25] step 22/44: loss=-0.5265 
[epoch 25] step 24/44: loss=-0.5253 
[epoch 25] step 26/44: loss=-0.5263 
[epoch 25] step 28/44: loss=-0.5271 
[epoch 25] step 30/44: loss=-0.5273 
[epoch 25] step 32/44: loss=-0.5247 
[epoch 25] step 34/44: loss=-0.5229 
[epoch 25] step 36/44: loss=-0.5241 
[epoch 25] step 38/44: loss=-0.5250 
[epoch 25] step 40/44: loss=-0.5247 
[epoch 25] step 42/44: loss=-0.5244 
[epoch 25] step 44/44: loss=-0.5241 
[epoch 25] train_loss(avg per step)=-1.0482 lambda[min,max]=[0.500000,1.000000]
[epoch 25] val_loss=4.2807 qwk=('0.5388', '0.4386', '0.5139') averageQWK=0.4971 macroEMD=0.2479 tailR0=('0.0926', '0.0500', '0.0000') tailR0avg=0.0475
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    9   24    7    0
     0   10   71   47    0
     0    0   31   89    2
     0    0    3   19    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0    8   33    7    0
     1    5   76   29    2
     0    0   54   94    0
     0    0    3    6    1
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   24   46    1    0
     0   12  115   24    0
     0    0   49   50    0
     0    0    1    2    0
[epoch 26] step 2/44: loss=-0.5628 
[epoch 26] step 4/44: loss=-0.5666 
[epoch 26] step 6/44: loss=-0.5662 
[epoch 26] step 8/44: loss=-0.5626 
[epoch 26] step 10/44: loss=-0.5600 
[epoch 26] step 12/44: loss=-0.5556 
[epoch 26] step 14/44: loss=-0.5554 
[epoch 26] step 16/44: loss=-0.5456 
[epoch 26] step 18/44: loss=-0.5440 
[epoch 26] step 20/44: loss=-0.5409 
[epoch 26] step 22/44: loss=-0.5352 
[epoch 26] step 24/44: loss=-0.5375 
[epoch 26] step 26/44: loss=-0.5374 
[epoch 26] step 28/44: loss=-0.5374 
[epoch 26] step 30/44: loss=-0.5376 
[epoch 26] step 32/44: loss=-0.5386 
[epoch 26] step 34/44: loss=-0.5370 
[epoch 26] step 36/44: loss=-0.5362 
[epoch 26] step 38/44: loss=-0.5354 
[epoch 26] step 40/44: loss=-0.5336 
[epoch 26] step 42/44: loss=-0.5316 
[epoch 26] step 44/44: loss=-0.5330 
[epoch 26] train_loss(avg per step)=-1.0660 lambda[min,max]=[0.500000,1.000000]
[epoch 26] val_loss=4.4084 qwk=('0.5130', '0.5200', '0.5824') averageQWK=0.5385 macroEMD=0.2427 tailR0=('0.0556', '0.1000', '0.0000') tailR0avg=0.0519
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    9   25    6    0
     1    5   85   37    0
     0    0   40   82    0
     0    0    4   20    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    1    0    0
     0   18   25    5    0
     1    9   83   18    2
     0    1   63   83    1
     0    0    3    5    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   33   37    0    0
     0   19  108   24    0
     0    1   42   56    0
     0    0    1    2    0
[epoch 27] step 2/44: loss=-0.5715 
[epoch 27] step 4/44: loss=-0.5483 
[epoch 27] step 6/44: loss=-0.5479 
[epoch 27] step 8/44: loss=-0.5564 
[epoch 27] step 10/44: loss=-0.5501 
[epoch 27] step 12/44: loss=-0.5523 
[epoch 27] step 14/44: loss=-0.5531 
[epoch 27] step 16/44: loss=-0.5531 
[epoch 27] step 18/44: loss=-0.5473 
[epoch 27] step 20/44: loss=-0.5482 
[epoch 27] step 22/44: loss=-0.5510 
[epoch 27] step 24/44: loss=-0.5514 
[epoch 27] step 26/44: loss=-0.5506 
[epoch 27] step 28/44: loss=-0.5465 
[epoch 27] step 30/44: loss=-0.5447 
[epoch 27] step 32/44: loss=-0.5434 
[epoch 27] step 34/44: loss=-0.5403 
[epoch 27] step 36/44: loss=-0.5413 
[epoch 27] step 38/44: loss=-0.5411 
[epoch 27] step 40/44: loss=-0.5421 
[epoch 27] step 42/44: loss=-0.5419 
[epoch 27] step 44/44: loss=-0.5414 
[epoch 27] train_loss(avg per step)=-1.0828 lambda[min,max]=[0.500000,1.000000]
[epoch 27] val_loss=4.5032 qwk=('0.5279', '0.4874', '0.5472') averageQWK=0.5208 macroEMD=0.2430 tailR0=('0.1551', '0.2667', '0.0000') tailR0avg=0.1406
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    5    2    0    0
     3    7   25    5    0
     2    6   85   35    0
     0    0   48   74    0
     0    0    5   17    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     2    2    2    0    0
     2    7   30    9    0
     2    4   70   36    1
     0    0   47  101    0
     0    0    2    6    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   35   35    1    0
     0   29   98   24    0
     0    2   43   54    0
     0    0    1    2    0
[epoch 28] step 2/44: loss=-0.5741 
[epoch 28] step 4/44: loss=-0.5687 
[epoch 28] step 6/44: loss=-0.5686 
[epoch 28] step 8/44: loss=-0.5682 
[epoch 28] step 10/44: loss=-0.5645 
[epoch 28] step 12/44: loss=-0.5581 
[epoch 28] step 14/44: loss=-0.5582 
[epoch 28] step 16/44: loss=-0.5574 
[epoch 28] step 18/44: loss=-0.5598 
[epoch 28] step 20/44: loss=-0.5590 
[epoch 28] step 22/44: loss=-0.5581 
[epoch 28] step 24/44: loss=-0.5585 
[epoch 28] step 26/44: loss=-0.5568 
[epoch 28] step 28/44: loss=-0.5535 
[epoch 28] step 30/44: loss=-0.5512 
[epoch 28] step 32/44: loss=-0.5493 
[epoch 28] step 34/44: loss=-0.5506 
[epoch 28] step 36/44: loss=-0.5515 
[epoch 28] step 38/44: loss=-0.5529 
[epoch 28] step 40/44: loss=-0.5527 
[epoch 28] step 42/44: loss=-0.5534 
[epoch 28] step 44/44: loss=-0.5534 
[epoch 28] train_loss(avg per step)=-1.1068 lambda[min,max]=[0.500000,1.000000]
[epoch 28] val_loss=4.6278 qwk=('0.5172', '0.5228', '0.5585') averageQWK=0.5328 macroEMD=0.2413 tailR0=('0.0556', '0.2333', '0.0000') tailR0avg=0.0963
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     1    8   24    7    0
     1    9   65   53    0
     0    0   30   91    1
     0    0    3   21    3
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     1   13   27    7    0
     2    7   68   34    2
     0    1   46  101    0
     0    0    2    5    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     1   30   40    0    0
     0   22  107   22    0
     0    0   47   52    0
     0    0    1    2    0
[epoch 29] step 2/44: loss=-0.5640 
[epoch 29] step 4/44: loss=-0.5391 
[epoch 29] step 6/44: loss=-0.5488 
[epoch 29] step 8/44: loss=-0.5549 
[epoch 29] step 10/44: loss=-0.5592 
[epoch 29] step 12/44: loss=-0.5560 
[epoch 29] step 14/44: loss=-0.5557 
[epoch 29] step 16/44: loss=-0.5554 
[epoch 29] step 18/44: loss=-0.5557 
[epoch 29] step 20/44: loss=-0.5574 
[epoch 29] step 22/44: loss=-0.5590 
[epoch 29] step 24/44: loss=-0.5583 
[epoch 29] step 26/44: loss=-0.5571 
[epoch 29] step 28/44: loss=-0.5568 
[epoch 29] step 30/44: loss=-0.5579 
[epoch 29] step 32/44: loss=-0.5596 
[epoch 29] step 34/44: loss=-0.5608 
[epoch 29] step 36/44: loss=-0.5591 
[epoch 29] step 38/44: loss=-0.5590 
[epoch 29] step 40/44: loss=-0.5590 
[epoch 29] step 42/44: loss=-0.5599 
[epoch 29] step 44/44: loss=-0.5613 
[epoch 29] train_loss(avg per step)=-1.1226 lambda[min,max]=[0.500000,1.000000]
[epoch 29] val_loss=4.8856 qwk=('0.5203', '0.4777', '0.5310') averageQWK=0.5096 macroEMD=0.2393 tailR0=('0.0741', '0.1833', '0.0000') tailR0avg=0.0858
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    9   24    7    0
     1    5   83   39    0
     0    0   38   84    0
     0    0    3   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     1    9   31    7    0
     2    5   71   34    1
     0    0   52   95    1
     0    0    3    5    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   27   44    0    0
     0   17  112   22    0
     0    0   50   49    0
     0    0    1    2    0
[epoch 30] step 2/44: loss=-0.5868 
[epoch 30] step 4/44: loss=-0.5726 
[epoch 30] step 6/44: loss=-0.5742 
[epoch 30] step 8/44: loss=-0.5740 
[epoch 30] step 10/44: loss=-0.5700 
[epoch 30] step 12/44: loss=-0.5698 
[epoch 30] step 14/44: loss=-0.5676 
[epoch 30] step 16/44: loss=-0.5667 
[epoch 30] step 18/44: loss=-0.5620 
[epoch 30] step 20/44: loss=-0.5624 
[epoch 30] step 22/44: loss=-0.5640 
[epoch 30] step 24/44: loss=-0.5657 
[epoch 30] step 26/44: loss=-0.5656 
[epoch 30] step 28/44: loss=-0.5658 
[epoch 30] step 30/44: loss=-0.5670 
[epoch 30] step 32/44: loss=-0.5681 
[epoch 30] step 34/44: loss=-0.5691 
[epoch 30] step 36/44: loss=-0.5687 
[epoch 30] step 38/44: loss=-0.5683 
[epoch 30] step 40/44: loss=-0.5651 
[epoch 30] step 42/44: loss=-0.5651 
[epoch 30] step 44/44: loss=-0.5645 
[epoch 30] train_loss(avg per step)=-1.1291 lambda[min,max]=[0.500000,1.000000]
[epoch 30] val_loss=5.0807 qwk=('0.5047', '0.4578', '0.5347') averageQWK=0.4991 macroEMD=0.2399 tailR0=('0.0926', '0.1000', '0.0000') tailR0avg=0.0642
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    8   24    8    0
     1    7   72   48    0
     0    0   34   87    1
     0    0    3   19    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    3    3    0    0
     0   10   29    9    0
     1    5   70   36    1
     0    0   49   98    1
     0    0    2    6    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   25   46    0    0
     0   10  123   18    0
     0    0   51   48    0
     0    0    1    2    0
[epoch 31] step 2/44: loss=-0.5788 
[epoch 31] step 4/44: loss=-0.5822 
[epoch 31] step 6/44: loss=-0.5831 
[epoch 31] step 8/44: loss=-0.5796 
[epoch 31] step 10/44: loss=-0.5777 
[epoch 31] step 12/44: loss=-0.5764 
[epoch 31] step 14/44: loss=-0.5769 
[epoch 31] step 16/44: loss=-0.5772 
[epoch 31] step 18/44: loss=-0.5781 
[epoch 31] step 20/44: loss=-0.5775 
[epoch 31] step 22/44: loss=-0.5758 
[epoch 31] step 24/44: loss=-0.5747 
[epoch 31] step 26/44: loss=-0.5745 
[epoch 31] step 28/44: loss=-0.5756 
[epoch 31] step 30/44: loss=-0.5766 
[epoch 31] step 32/44: loss=-0.5767 
[epoch 31] step 34/44: loss=-0.5770 
[epoch 31] step 36/44: loss=-0.5771 
[epoch 31] step 38/44: loss=-0.5772 
[epoch 31] step 40/44: loss=-0.5763 
[epoch 31] step 42/44: loss=-0.5770 
[epoch 31] step 44/44: loss=-0.5773 
[epoch 31] train_loss(avg per step)=-1.1547 lambda[min,max]=[0.500000,1.000000]
[epoch 31] val_loss=4.9809 qwk=('0.5232', '0.5174', '0.5519') averageQWK=0.5308 macroEMD=0.2382 tailR0=('0.0741', '0.2333', '0.0000') tailR0avg=0.1025
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     0    9   24    7    0
     1    5   83   39    0
     0    0   37   85    0
     0    0    3   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0   15   26    7    0
     2    9   68   32    2
     0    1   50   95    2
     0    0    2    5    3
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   28   41    2    0
     0   16  113   22    0
     0    0   43   56    0
     0    0    1    2    0
[epoch 32] step 2/44: loss=-0.5801 
[epoch 32] step 4/44: loss=-0.5844 
[epoch 32] step 6/44: loss=-0.5856 
[epoch 32] step 8/44: loss=-0.5813 
[epoch 32] step 10/44: loss=-0.5850 
[epoch 32] step 12/44: loss=-0.5854 
[epoch 32] step 14/44: loss=-0.5862 
[epoch 32] step 16/44: loss=-0.5816 
[epoch 32] step 18/44: loss=-0.5796 
[epoch 32] step 20/44: loss=-0.5803 
[epoch 32] step 22/44: loss=-0.5813 
[epoch 32] step 24/44: loss=-0.5794 
[epoch 32] step 26/44: loss=-0.5788 
[epoch 32] step 28/44: loss=-0.5787 
[epoch 32] step 30/44: loss=-0.5797 
[epoch 32] step 32/44: loss=-0.5806 
[epoch 32] step 34/44: loss=-0.5809 
[epoch 32] step 36/44: loss=-0.5800 
[epoch 32] step 38/44: loss=-0.5803 
[epoch 32] step 40/44: loss=-0.5807 
[epoch 32] step 42/44: loss=-0.5806 
[epoch 32] step 44/44: loss=-0.5813 
[epoch 32] train_loss(avg per step)=-1.1627 lambda[min,max]=[0.500000,1.000000]
[epoch 32] val_loss=4.9941 qwk=('0.5201', '0.5139', '0.5489') averageQWK=0.5276 macroEMD=0.2380 tailR0=('0.0741', '0.1833', '0.0000') tailR0avg=0.0858
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    5    3    0    0
     1    9   23    7    0
     1    7   77   43    0
     0    0   37   85    0
     0    0    3   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    4    1    0    0
     0   13   28    7    0
     1    7   69   35    1
     0    0   48   99    1
     0    0    3    5    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   33   37    1    0
     0   27  100   24    0
     0    2   41   56    0
     0    0    1    2    0
[epoch 33] step 2/44: loss=-0.5930 
[epoch 33] step 4/44: loss=-0.5917 
[epoch 33] step 6/44: loss=-0.5942 
[epoch 33] step 8/44: loss=-0.5898 
[epoch 33] step 10/44: loss=-0.5897 
[epoch 33] step 12/44: loss=-0.5891 
[epoch 33] step 14/44: loss=-0.5880 
[epoch 33] step 16/44: loss=-0.5875 
[epoch 33] step 18/44: loss=-0.5888 
[epoch 33] step 20/44: loss=-0.5890 
[epoch 33] step 22/44: loss=-0.5863 
[epoch 33] step 24/44: loss=-0.5863 
[epoch 33] step 26/44: loss=-0.5849 
[epoch 33] step 28/44: loss=-0.5850 
[epoch 33] step 30/44: loss=-0.5848 
[epoch 33] step 32/44: loss=-0.5837 
[epoch 33] step 34/44: loss=-0.5836 
[epoch 33] step 36/44: loss=-0.5835 
[epoch 33] step 38/44: loss=-0.5839 
[epoch 33] step 40/44: loss=-0.5825 
[epoch 33] step 42/44: loss=-0.5819 
[epoch 33] step 44/44: loss=-0.5826 
[epoch 33] train_loss(avg per step)=-1.1653 lambda[min,max]=[0.500000,1.000000]
[epoch 33] val_loss=4.9410 qwk=('0.5197', '0.4919', '0.5475') averageQWK=0.5197 macroEMD=0.2382 tailR0=('0.0926', '0.1000', '0.0000') tailR0avg=0.0642
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    9   26    5    0
     1    7   85   35    0
     0    0   46   74    2
     0    0    5   17    5
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    4    2    0    0
     0   14   27    7    0
     1    8   70   32    2
     0    1   48   96    3
     0    0    3    5    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   32   38    1    0
     0   29   99   23    0
     0    2   40   57    0
     0    0    1    2    0
[epoch 34] step 2/44: loss=-0.5949 
[epoch 34] step 4/44: loss=-0.5885 
[epoch 34] step 6/44: loss=-0.5917 
[epoch 34] step 8/44: loss=-0.5885 
[epoch 34] step 10/44: loss=-0.5903 
[epoch 34] step 12/44: loss=-0.5902 
[epoch 34] step 14/44: loss=-0.5904 
[epoch 34] step 16/44: loss=-0.5895 
[epoch 34] step 18/44: loss=-0.5898 
[epoch 34] step 20/44: loss=-0.5899 
[epoch 34] step 22/44: loss=-0.5903 
[epoch 34] step 24/44: loss=-0.5907 
[epoch 34] step 26/44: loss=-0.5900 
[epoch 34] step 28/44: loss=-0.5908 
[epoch 34] step 30/44: loss=-0.5895 
[epoch 34] step 32/44: loss=-0.5892 
[epoch 34] step 34/44: loss=-0.5892 
[epoch 34] step 36/44: loss=-0.5893 
[epoch 34] step 38/44: loss=-0.5889 
[epoch 34] step 40/44: loss=-0.5893 
[epoch 34] step 42/44: loss=-0.5895 
[epoch 34] step 44/44: loss=-0.5900 
[epoch 34] train_loss(avg per step)=-1.1799 lambda[min,max]=[0.500000,1.000000]
[epoch 34] val_loss=5.2903 qwk=('0.5213', '0.5004', '0.5354') averageQWK=0.5190 macroEMD=0.2369 tailR0=('0.0741', '0.1833', '0.0000') tailR0avg=0.0858
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0    9   24    7    0
     1    6   73   48    0
     0    0   34   87    1
     0    0    3   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0   14   26    8    0
     1    8   63   39    2
     0    1   43  101    3
     0    0    2    6    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   29   41    1    0
     0   22  107   22    0
     0    1   45   53    0
     0    0    1    2    0
[epoch 35] step 2/44: loss=-0.5955 
[epoch 35] step 4/44: loss=-0.5966 
[epoch 35] step 6/44: loss=-0.5879 
[epoch 35] step 8/44: loss=-0.5902 
[epoch 35] step 10/44: loss=-0.5904 
[epoch 35] step 12/44: loss=-0.5858 
[epoch 35] step 14/44: loss=-0.5869 
[epoch 35] step 16/44: loss=-0.5879 
[epoch 35] step 18/44: loss=-0.5880 
[epoch 35] step 20/44: loss=-0.5886 
[epoch 35] step 22/44: loss=-0.5887 
[epoch 35] step 24/44: loss=-0.5892 
[epoch 35] step 26/44: loss=-0.5898 
[epoch 35] step 28/44: loss=-0.5898 
[epoch 35] step 30/44: loss=-0.5897 
[epoch 35] step 32/44: loss=-0.5893 
[epoch 35] step 34/44: loss=-0.5898 
[epoch 35] step 36/44: loss=-0.5899 
[epoch 35] step 38/44: loss=-0.5899 
[epoch 35] step 40/44: loss=-0.5896 
[epoch 35] step 42/44: loss=-0.5887 
[epoch 35] step 44/44: loss=-0.5890 
[epoch 35] train_loss(avg per step)=-1.1780 lambda[min,max]=[0.500000,1.000000]
[epoch 35] val_loss=5.1518 qwk=('0.5293', '0.5025', '0.5353') averageQWK=0.5223 macroEMD=0.2361 tailR0=('0.0741', '0.1833', '0.0000') tailR0avg=0.0858
[content] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    6    2    0    0
     0   10   24    6    0
     0    9   76   43    0
     0    0   40   81    1
     0    0    3   20    4
[organization] confusion matrix (rows=true 1..5, cols=pred 1..5):
     1    3    2    0    0
     0   15   26    7    0
     2    9   65   35    2
     0    2   45   98    3
     0    0    2    6    2
[language] confusion matrix (rows=true 1..5, cols=pred 1..5):
     0    1    0    0    0
     0   31   39    1    0
     0   26  103   22    0
     0    1   46   52    0
     0    0    1    2    0
[oof] wrote ensembled OOF-val predictions: /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-0-conf_gating-0-reassignment-0/fold3/oof_val_T7.csv
[VAL] updated /workspace/MAGeLDR-KL-loss/results/jager--joint-1-mixture-0-conf_gating-0-reassignment-0/fold3/metrics.json
Done.
